[
{"url": "https://wiki.ros.org/rosbridge_server", "package": "rosbridge_server", "package_summary": ["A WebSocket interface to rosbridge."], "package_details": ["\n", "\n", "Rosbridge server is part of the rosbridge_suite of packages, providing a ", " transport layer. A ", " is a low-latency, bidirectional communication layer between clients (web browsers) and servers. By providing a ", " connection, rosbridge server allows webpages to talk ROS using the rosbridge protocol. ", "Rosbridge server creates a ", " connection and passes any JSON messages from the ", " to rosbridge_library, so rosbridge library can convert the JSON strings into ROS calls. The reverse also happens, with rosbridge library converting any ROS responses into JSON, then passing it to rosbridge server to send over the ", " connection. ", "Check out ", " for a ", " library that talks to rosbridge server over ", ". ", "While rosbridge server provides a ", " connection, rosbridge itself is not tied to any particular transport layer. You could add a rosbridge TCP package or node, for example, that communicates with rosbridge using TCP sockets. No ", " or browsers needed. ", " for these additional transport layers are encouraged! "]},
{"url": "https://wiki.ros.org/jsk_rqt_plugins", "package": "jsk_rqt_plugins", "package_summary": ["The jsk_rqt_plugins package"], "package_details": ["Doc: ", " "]},
{"url": "https://wiki.ros.org/ethercat_trigger_controllers", "package": "ethercat_trigger_controllers", "package_summary": ["Controllers to operate the digital output of the motor controller\n    boards and the projector board. This package has not been reviewed and\n    should be considered unstable."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rqt_joint_trajectory_controller", "package": "rqt_joint_trajectory_controller", "package_summary": ["Graphical frontend for interacting with joint_trajectory_controller instances."], "package_details": ["\n", " ", "Graphical frontend for interacting with ", " instances. "], "package_tt": ["joint_trajectory_controller"]},
{"url": "https://wiki.ros.org/zeroconf_msgs", "package": "zeroconf_msgs", "package_summary": ["General ros communications used by the various zeroconf implementations."], "package_details": ["Messages supporting the ", " and ", " stacks. "]},
{"url": "https://wiki.ros.org/asr_msgs", "package": "asr_msgs", "package_summary": ["This package contains all messages that are particular to our Active Scene Recognition - Framework at \n\t\tHumanoids and Intelligence Systems Lab (HIS), Karlsruhe Institute of Technology (KIT).\n\t  These messages make up the interfaces between the different collaborating components of this system.\n\t  They are of critical importance and structured by the ROS communication capabilities."], "package_details": [" ", "\n", "\n", " "]},
{"url": "https://wiki.ros.org/pmb2_controller_configuration_gazebo", "package": "pmb2_controller_configuration_gazebo", "package_summary": ["Gazebo-specifig launch files and scripts needed to configure\n    the controllers of the PMB2 robot in simulation."]},
{"url": "https://wiki.ros.org/ocl", "package": "ocl", "package_summary": ["Orocos component library\n    This package contains standard components for the Orocos Toolchain"], "package_details": ["\n", "\n", "Read the ", " for detailed information on how to use the deployer. "], "package_code": ["rosrun ocl deployer-gnulinux -ldebug -s deploy.ops", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>                                                                                                                            \n", "  <!DOCTYPE properties SYSTEM \"cpf.dtd\">                                                                                                                            \n", "    <properties>\n", "     <simple name=\"init_file\" type=\"string\"><description>Name of the initialisation file</description><value>init.xml</value></simple>\n", "    </properties>  ", " <launch>                                                                                                                                                 \n", "   <node name=\"myNodeName\" pkg=\"ocl\" type=\"deployer-gnulinux\" launch-prefix=\"konsole -e\" args=\"-ldebug -s $(find myRosPkg)/deploy.ops --\">\n", "   </node>           \n", "  </launch> "]},
{"url": "https://wiki.ros.org/lanelet2_routing", "package": "lanelet2_routing", "package_summary": ["Routing module for lanelet2"]},
{"url": "https://wiki.ros.org/multisense", "package": "multisense", "package_summary": ["multisense catkin driver"]},
{"url": "https://wiki.ros.org/pr2_gripper_sensor_controller", "package": "pr2_gripper_sensor_controller", "package_summary": ["The pr2_gripper_sensor_controller package is a real-time controller that integrates signals from the PR2 hand-mounted accelerometer and finger-mounted pressure sensors with motor control of the gripper joint to do highly responsive sensing and low-latency closed-loop control."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "The ", " package is a real-time controller that is intended to support the ", " interface and allow it to: ", "The ", " package continuously publishes several messages defined in the ", " package, which are intended for use in the action servers of ", " and not for normal user usage, but can provide useful information for more advanced users. ", "The ", " ", " two important PR2 sensors to be available: ", "A simple test to check if these sensors exist is to run the command ", " and check to make sure the ", " and ", " fields are present. ", "If you are not using a prebuilt installation you may have to compile the ", " package. Since the ", " package is a real-time controller, it is important to remember to compile the package ", " launching your robot, otherwise it will fail to register and load correctly with ", ". Compiling can be done simply by typing: ", "Or by building any of the higher-level packages (such as ", " which depend on this package) ", " launching your robot. ", "See the ", " launch instructions, which will automatically launch the ", " package for both the left and right PR2 grippers. Specific left/right launch files are available in the ", " package, but it is unecessary for the end user to launch them independently. "], "package_tt": ["rostopic\u00a0list", "/accelerometer", "/pressure"], "package_code": ["rosmake pr2_gripper_sensor_controller"]},
{"url": "https://wiki.ros.org/combined_robot_hw", "package": "combined_robot_hw", "package_summary": ["Combined Robot HW class."], "package_details": ["\n", " ", "High-resolution version can be found ", ". ", "A short summary of CombinedRobotHW can be found in ", " ROScon 2016 talk. "]},
{"url": "https://wiki.ros.org/turtlebot3_description", "package": "turtlebot3_description", "package_summary": ["3D models of the TurtleBot3 for simulation and visualization"], "package_details": [" ", "\n", "\n"], "package_tt": ["turtlebot3_(model).urdf.xacro", "<turtlebot3_(model)/>", "turtlebot3_(model).gazebo.xacro", "<turtlebot3_(model)_sim/>", "common_properties.xacro"]},
{"url": "https://wiki.ros.org/pluginlib", "package": "pluginlib", "package_summary": ["The pluginlib package provides tools for writing and dynamically loading plugins using the ROS build infrastructure.\n    To work, these tools require plugin providers to register their plugins in the package.xml of their package."], "package_tt": ["polygon_interface_package", "rectangle_plugin", "triangle_plugin", "rectangle_plugin", "triangle_plugin", "polygon_interface_package", ".cpp", "pluginlib", "class_list_macros.h", "class_list.cpp", "librectangle", "rectangle_plugin", "rectangle_plugin.xml", "export", "rectangle_plugin", "export", "rectangle_plugin", "manifest.xml", "ClassLoader", "class_loader.h", "ClassLoader", "rectangle", "polygon", "polygon_interface", "rectangle_plugin", "triangle_plugin", "rectangle_plugin", "triangle_plugin", "polygon_interface", "PLUGINLIB_EXPORT_CLASS", "class_list.cpp", "librectangle", "rectangle_plugin", "rectangle_plugin.xml", "export", "rectangle_plugin", "export", "rectangle_plugin", "catkin/package.xml", "ClassLoader", "class_loader.h", "ClassLoader", "rectangle", "polygon", "PLUGINLIB_REGISTER_CLASS", "PLUGINLIB_DECLARE_CLASS", "PLUGINLIB_EXPORT_CLASS"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "<library path=\"lib/librectangle\">\n", "  <class name=\"example_pkg/Rectangle\" type=\"rectangle_namespace::Rectangle\" base_class_type=\"polygon_namespace::Polygon\">\n", "  <description>\n", "  This is a rectangle plugin\n", "  </description>\n", "  </class>\n", "</library>", "<export>\n", "  <polygon_interface_package plugin=\"${prefix}/rectangle_plugin.xml\" />\n", "</export>", "  <depend package=\"polygon_interface_package\" />", "rospack plugins --attrib=plugin nav_core", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "<library path=\"lib/librectangle\">\n", "  <class type=\"rectangle_namespace::Rectangle\" base_class_type=\"polygon_namespace::Polygon\">\n", "  <description>\n", "  This is a rectangle plugin\n", "  </description>\n", "  </class>\n", "</library>", "<export>\n", "  <polygon_interface plugin=\"${prefix}/rectangle_plugin.xml\" />\n", "</export>", "  <build_depend>polygon_interface</build_depend>\n", "  <run_depend>polygon_interface</run_depend>", "rospack plugins --attrib=plugin nav_core", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " plugin_macro_update", "<library path=\"lib/librectangle\">\n", "  <class name=\"rviz/Rectangle\" type=\"rectangle_namespace::Rectangle\" base_class_type=\"polygon_namespace::Polygon\">\n", "  <description>\n", "  This is a rectangle plugin\n", "  </description>\n", "  </class>\n", "</library>"]},
{"url": "https://wiki.ros.org/lanelet2_projection", "package": "lanelet2_projection", "package_summary": ["Lanelet2 projection library for lat/lon to local x/y conversion"]},
{"url": "https://wiki.ros.org/interactive_marker_tutorials", "package": "interactive_marker_tutorials", "package_summary": ["The interactive_marker_tutorials package"], "package_details": ["See ", " for the tutorials based on this package. "]},
{"url": "https://wiki.ros.org/rosauth", "package": "rosauth", "package_summary": ["Server Side tools for Authorization and Authentication of ROS Clients"], "package_details": ["\n", "\n", "\n", "\n", "The rosbridge server is responsible for calling the /authenticate service on a request of the client. This can be done using the authenticate method of roslibjs: ", " "], "package_tt": ["authenticate", "~allowed_time_delta", "float", "~secret_file_location", "string"], "package_code": ["roslaunch rosbridge_server rosbridge_websocket.launch authenticate:=true", "echo \"1234567890abcdef\" > /tmp/secret.txt  # Example secret\n", "rosrun rosauth ros_mac_authentication _secret_file_location:=/tmp/secret.txt _allowed_time_delta:=-1", "echo -n \"1234567890abcdefclientdestrand0level0\" | sha512sum", "rosservice call /authenticate \"mac: '19d9d2166799f1ffd6fee6379f957502aff8716bfebc8cc8b3bac57ade14441bb9678be89d0a7eec9c81291f854d754d7a4de2278bede56f162c2faeb468c68a'\n", "client: 'client'\n", "dest: 'dest'\n", "rand: 'rand'\n", "t: {secs: 0, nsecs: 0}\n", "level: 'level'\n", "end: {secs: 0, nsecs: 0}\"", "authenticated: True", "let secret = 'myawesomesecret1'\n", "let dest = this.url\n", "let rand = randomString(10)\n", "let time = new Date().getTime() / 1000\n", "let timeEnd = time + 1000\n", "let level = \"admin\"\n", "let mac = sha512(secret + client.getUA() + dest + rand + parseInt(time).toString() + level + parseInt(timeEnd).toString())  // using sha512 library js-sha512 and client library clientjs\n", "this.authenticate(mac, client.getUA(), dest, rand, time, level, timeEnd)  // method from roslibjs"]},
{"url": "https://wiki.ros.org/rc_genicam_api", "package": "rc_genicam_api", "package_summary": ["GenICam/GigE Vision Convenience Layer.\n\n      This package combines the Roboception convenience layer for images with the\n      GenICam reference implementation and a GigE Vision transport layer. It is a\n      self contained package that permits configuration and image streaming of\n      GenICam / GigE Vision 2.0 compatible cameras like the Roboception rc_visard.\n\n      This package also provides some tools that can be called from the command line\n      for discovering cameras, changing their configuration and streaming images.\n      Although the tools are meant to be useful when working in a shell or in a\n      script, their main purpose is to serve as example on how to use the API for\n      reading and setting parameters, streaming and synchronizing images.\n\n      See LICENSE.md for licensing terms of the different parts."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "All three options can be seen in the output of ", ". ", "If the given ID contains a colon (i.e. ", "), the part before the (first) ", "colon is interpreted as interface ID and the part after the first colon is ", "treated as device ID. This is the format that ", " shows. A device ", "with the given ID is only sought on the specified interface. This can be ", "useful if there are several ways to reach a device from a host computer, ", "e.g. via wireless and wired network connection, but a certain connection ", "type (e.g. wired) is preferred due to higher bandwidth and lower latency. ", "Examples: ", ", ", " or ", " ", "The ", " script performs some simple checks and should be run while or after streaming images via GigE Vision. ", "These values can be changed during runtime with ", " or written to ", " for persistence across reboots. ", "If the number of UDP ", " increases while streaming, increasing the socket receive buffer size usually fixes the problem. ", "Check the ", " ", " or ", "Check with ", " and increase the values if needed: "], "package_tt": [":", "_", "00_14_2d_2c_6e_bb", "rc_visard", ":my:name", "02911931", "gc_config\u00a0-l", ":", "gc_config\u00a0-l", "eth0:00_14_2d_2c_6e_bb", "eth1:02911931", "wlan0:rc_visard", "net_perf_check.sh", "sysctl", "/etc/sysctl.conf", "RcvbufErrors", "RcvbufErrors\u00a0with", "net_perf_check.sh", "net_perf_check.sh"], "package_code": ["  gc_stream <ID> ComponentSelector=Intensity ComponentEnable=1 ComponentSelector=Disparity ComponentEnable=0 n=10", "./net_perf_check.sh --help", "sudo ifconfig eth0 mtu 9000", "netstat -us | grep RcvbufErrors", "sudo sysctl -w net.core.rmem_max=33554432", "sudo sysctl -w net.core.netdev_max_backlog=2000\n", "sudo sysctl -w net.core.netdev_budget=600"]},
{"url": "https://wiki.ros.org/nav_2d_utils", "package": "nav_2d_utils", "package_summary": ["A handful of useful utility functions for nav_core2 packages."], "package_details": [" "]},
{"url": "https://wiki.ros.org/rqt_py_console", "package": "rqt_py_console", "package_summary": ["rqt_py_console is a Python GUI plugin providing an interactive Python console."]},
{"url": "https://wiki.ros.org/jsk_pr2_startup", "package": "jsk_pr2_startup", "package_summary": ["\n\n     jsk_pr2_startup\n\n  "]},
{"url": "https://wiki.ros.org/sick_scan", "package": "sick_scan", "package_summary": ["A ROS driver for the SICK TiM and SICK MRS series of laser scanners.\n    This package is based on the original sick_tim-repository of Martin G\u00fcnther et al."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "ROS packages for SICK laser scaners. This driver provides the measurement data as ", " and ", " data. The use of ", " data is recommended. ", "The ", " data should only be used for debugging purposes. They provide the raw data for each scan plane in a different coordinate frame. Due to the geometry of the scanning planes of the MRS1104 there is no coordinate transformation between the scan planes that can be described by ", " messages, therefore no ", " messages are published. That is why the ", " data should be used. "], "package_tt": ["nc\u00a0-z\u00a0-v\u00a0-w5\u00a0$SCANNERIPADDRESS\u00a02112"], "package_code": ["source /opt/ros/<rosdistro>/setup.bash\n", "mkdir -p ~/ros_catkin_ws/src/\n", "cd ~/ros_catkin_ws/src/\n", "git clone -b devel --single-branch git://github.com/SICKAG/sick_scan.git\n", "cd ..\n", "catkin_make\n", "source ~/ros_catkin_ws/install/setup.bash", " roslaunch sick_scan sick_mrs_1xxx.launch", " rviz rviz"]},
{"url": "https://wiki.ros.org/moveit_ros_benchmarks", "package": "moveit_ros_benchmarks", "package_summary": ["Enhanced tools for benchmarks in MoveIt!"]},
{"url": "https://wiki.ros.org/novatel_msgs", "package": "novatel_msgs", "package_summary": ["ROS messages which represent raw Novatel SPAN data."], "package_details": ["\n", "\n", "These messages are the low-level binary interface between a NovAtel SPAN unit and ROS. Typical use cases should not require working with these messages. ", "Please see the related package, ", ". "]},
{"url": "https://wiki.ros.org/moveit_planners_chomp", "package": "moveit_planners_chomp", "package_summary": ["The interface for using CHOMP within MoveIt!"]},
{"url": "https://wiki.ros.org/mrpt_map", "package": "mrpt_map", "package_summary": ["The mrpt_map is able to publish a mrpt map as ros occupancy grid like the map_server"], "package_details": ["\n", "\n", "\n", "The ", " node publishes (static, prebuilt) metric maps stored in MRPT formats: ", " or ", ".  ", "Most ROS packages expect the map to be a unique occupancy grid map. This node supports those simple maps, plus all other ", ". "], "package_tt": ["mrpt_map", "map", "~map_file", "map_metadata", "~map_file", "static_map", "~ini_file", "string", "\"map.ini\"", "~map_file", "string", ".simplemap", ".gridmap", "~debug", "bool", "~frequency", "double", "~frame_id", "string"]},
{"url": "https://wiki.ros.org/rosflight_pkgs", "package": "rosflight_pkgs", "package_summary": ["ROS interface for the ROSflight autpilot stack"]},
{"url": "https://wiki.ros.org/velodyne_laserscan", "package": "velodyne_laserscan", "package_summary": ["Extract a single ring of a Velodyne PointCloud2 and publish it as a LaserScan message"]},
{"url": "https://wiki.ros.org/swri_image_util", "package": "swri_image_util", "package_summary": ["swri_image_util"]},
{"url": "https://wiki.ros.org/pr2_mechanism_controllers", "package": "pr2_mechanism_controllers", "package_summary": ["The pr2_mechanism_controllers package contains realtime\n    controllers that are meant for specific mechanisms of the PR2."], "package_details": ["\n", "\n", "At the present time, the controllers in this stack are not intended for direct use. The controllers should be used via their ", " interfaces, e.g., ", ", ", ", ", ", and ", ".    The ", " library is stable. "]},
{"url": "https://wiki.ros.org/qt_gui_cpp", "package": "qt_gui_cpp", "package_summary": ["qt_gui_cpp provides the foundation for C++-bindings for qt_gui and creates bindings for every generator available.\n    At least one specific binding must be available in order to use C++-plugins."]},
{"url": "https://wiki.ros.org/agni_tf_tools", "package": "agni_tf_tools", "package_summary": ["This package provides a gui program as well as a rviz plugin to publish static transforms.\n  Both support the transformation between various Euler angle representations.\n  The rviz plugin also allows to configure the transform with an interactive marker."], "package_details": [" ", "\n", "\n", "\n", " ", "Dependent on the order of rotation axes, there are different sets of Euler angles. One common set is roll-pitch-yaw (the default in ROS), which corresponds to rotations about x, y, and z axes w.r.t. the fixed frame. To specify Euler angles w.r.t. a different set or order of axes, simply specify the desired order instead of rpy. For example, ", " will rotate by 30\u00b0 about the y axis, then by 50\u00b0 about the x axis, and finally by 70\u00b0 about the y axis. In order to transform a given Euler angle representation into another one, simply enter the desired axes order - replacing the whole text field including the angular values. ", "To specify whether rotations should be performed w.r.t. the ", "tatic or the moving / ", "otationg frame (corresponding to left resp. right matrix multiplication), it's possible to prefix the axes order by \"", "\" or \"", "\". Omitting the prefix, corresponds to \"", "\" or right matrix multiplication. ", "The rviz plugin also supports frame transformations. If you want to compute the entered transform w.r.t. another parent frame, simply enable the checkbox \"", "\" and subsequently change the ", ". If the checkbox is not ticked, changing the parent frame doesn't change the relative transform, but moves the interactive marker. ", "The entered transform is published as soon as a empty frame names are provided and the \"", "\" checkbox is enabled. "], "package_tt": ["yxz:\u00a030,\u00a050,\u00a070", "adapt\u00a0transformation", "parent\u00a0frame", "publish\u00a0transform"]},
{"url": "https://wiki.ros.org/wfov_camera_msgs", "package": "wfov_camera_msgs", "package_summary": ["Messages related to the Point Grey camera driver."]},
{"url": "https://wiki.ros.org/py_trees_ros", "package": "py_trees_ros", "package_summary": ["Ros extensions and behaviours for py_trees."], "package_details": ["\n", " ", "\n", "Get started at the ", " for the project. "]},
{"url": "https://wiki.ros.org/ps3joy", "package": "ps3joy", "package_summary": ["Playstation 3 SIXAXIS or DUAL SHOCK 3 joystick driver.\n    Driver for the Sony PlayStation 3 SIXAXIS or DUAL SHOCK 3\n    joysticks. In its current state, this driver is not compatible\n    with the use of other Bluetooth HID devices. The driver listens\n    for a connection on the HID ports, starts the joystick\n    streaming data, and passes the data to the Linux uinput device\n    so that it shows up as a normal joystick."], "package_details": ["\n", "\n", "\n", " is known to work with Ubuntu 12.10, Ubuntu 12.04, Ubuntu Jaunty 9.04, and Ubuntu Hardy 8.04. To make it work with Ubuntu Karmic 9.10, you will have to follow these ", ". ", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", " ", " ", "  ", " ", " ", "\n", "\n", "\n", "\n", " ", " ", " ", " also exposes the joystick's three-axis accelerometer and the single-axis gyroscope: ", "\n", "This driver exists because Linux's native support for the PS3 joystick is unreliable, and does not give access to the joystick's accelerometers and gyroscope. This driver solves both problems. However in its current form, ", ". In future releases, we plan to allow first non-HID and later any bluetooth device to coexist with this driver. If you have a need for such functionality, let it be known. ", "The ", " is a good starting point for how to use this package. ", "This is the same for ", " and ", ". ", "Or you could write a sudo script for sourcing ROS and starting ps3joy_node; I use ", " to automatically start the ", " after booting and a ROS-check. ", "There is ", ". ", "With these #defines you can access the PS3 buttons within the ", " without worrying about magic numbers: "], "package_tt": ["ps3joy.py", "sudo", "joy/set_feedback", "/diagnostics", "ps3joy.py", "ps3joy_node.py", "--inactivity-timeout", "--no-disable-bluetoothd", "ps3joy.py", "--redirect-output", "ps3joy.py", "--continuous-output", "ps3joy_node"], "package_code": ["sudo apt-get install ros-%ROSDISTRO%-joystick-drivers\n", "sudo apt-get install ros-indigo-joystick-drivers       (ROS Indigo for example)", "$ ./ps3joy.py --help\n", "usage: ps3joy.py [--inactivity-timeout=<n>] [--no-disable-bluetoothd] [--redirect-output]=<f>\n", "<n>: inactivity timeout in seconds (saves battery life).\n", "<f>: file name to redirect output to.\n", "Unless --no-disable-bluetoothd is specified, bluetoothd will be stopped.", ".../ps3joy$ sudo bash -c \"source /home/myself/.bashrc; ./scripts/ps3joy_node.py --inactivity-timeout=300\"", "rostopic pub  /joy/set_feedback sensor_msgs/JoyFeedbackArray '[ [0, 3, 1], [1, 1, 0.8] ]'", "// note on plain values:\n", "// buttons are either 0 or 1\n", "// button axes go from 0 to -1\n", "// stick axes go from 0 to +/-1\n", "\n", "#define PS3_BUTTON_SELECT            0\n", "#define PS3_BUTTON_STICK_LEFT        1\n", "#define PS3_BUTTON_STICK_RIGHT       2\n", "#define PS3_BUTTON_START             3\n", "#define PS3_BUTTON_CROSS_UP          4\n", "#define PS3_BUTTON_CROSS_RIGHT       5\n", "#define PS3_BUTTON_CROSS_DOWN        6\n", "#define PS3_BUTTON_CROSS_LEFT        7\n", "#define PS3_BUTTON_REAR_LEFT_2       8\n", "#define PS3_BUTTON_REAR_RIGHT_2      9\n", "#define PS3_BUTTON_REAR_LEFT_1       10\n", "#define PS3_BUTTON_REAR_RIGHT_1      11\n", "#define PS3_BUTTON_ACTION_TRIANGLE   12\n", "#define PS3_BUTTON_ACTION_CIRCLE     13\n", "#define PS3_BUTTON_ACTION_CROSS      14\n", "#define PS3_BUTTON_ACTION_SQUARE     15\n", "#define PS3_BUTTON_PAIRING           16\n", "\n", "#define PS3_AXIS_STICK_LEFT_LEFTWARDS    0\n", "#define PS3_AXIS_STICK_LEFT_UPWARDS      1\n", "#define PS3_AXIS_STICK_RIGHT_LEFTWARDS   2\n", "#define PS3_AXIS_STICK_RIGHT_UPWARDS     3\n", "#define PS3_AXIS_BUTTON_CROSS_UP         4\n", "#define PS3_AXIS_BUTTON_CROSS_RIGHT      5\n", "#define PS3_AXIS_BUTTON_CROSS_DOWN       6\n", "#define PS3_AXIS_BUTTON_CROSS_LEFT       7\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_2      8\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_2     9\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_1      10\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_1     11\n", "#define PS3_AXIS_BUTTON_ACTION_TRIANGLE  12\n", "#define PS3_AXIS_BUTTON_ACTION_CIRCLE    13\n", "#define PS3_AXIS_BUTTON_ACTION_CROSS     14\n", "#define PS3_AXIS_BUTTON_ACTION_SQUARE    15\n", "#define PS3_AXIS_ACCELEROMETER_LEFT      16\n", "#define PS3_AXIS_ACCELEROMETER_FORWARD   17\n", "#define PS3_AXIS_ACCELEROMETER_UP        18\n", "#define PS3_AXIS_GYRO_YAW                19"]},
{"url": "https://wiki.ros.org/libsiftfast", "package": "libsiftfast", "package_summary": ["Library to compute SIFT features"]},
{"url": "https://wiki.ros.org/yocs_velocity_smoother", "package": "yocs_velocity_smoother", "package_summary": ["Bound incoming velocity messages according to robot velocity and acceleration limits.", "Contents", " ", "\n", "\n", "\n", "Take a look to the ", " to learn how yocs_velocity_smoother works together with other components to build up a safe and flexible control system. ", "\n", "By robot feedback we mean the current velocity at which robot \"thinks\" he moves now. The two common ways to know this are: ", "Option 0 of course ignores any robot feedback. There are some reasons to use robot feedback. The two we face more often are: ", "So the recommended option is 2 in most cases (if there aren't concurrent controllers it will have no effect), letting option 1 just for special situations. If people don't find it useful at all, we will probably remove. "], "package_details": [" "], "package_tt": ["~raw_cmd_vel", "~odometry", "~smooth_cmd_vel", "~accel_lim_v", "double", "~accel_lim_w", "double", "~speed_lim_v", "double", "~speed_lim_w", "double", "~decel_factor", "double", "~frequency", "double", "~raw_cmd_vel", "~odometry", "~robot_cmd_vel", "~smooth_cmd_vel", "~accel_lim_v", "double", "~accel_lim_w", "double", "~speed_lim_v", "double", "~speed_lim_w", "double", "~decel_factor", "double", "~frequency", "double", "~robot_feedback", "int", "~raw_cmd_vel", "~odometry", "~robot_cmd_vel", "~smooth_cmd_vel", "~accel_lim_v", "double", "~accel_lim_w", "double", "~speed_lim_v", "double", "~speed_lim_w", "double", "~decel_factor", "double", "~frequency", "double", "~robot_feedback", "int"]},
{"url": "https://wiki.ros.org/map_msgs", "package": "map_msgs", "package_summary": ["This package defines messages commonly used in mapping packages."], "package_details": ["This package provides a preliminary implementation of messages defined in the work-in-progress REP 129. For more information, please have a look at the ", ". "]},
{"url": "https://wiki.ros.org/julius", "package": "julius", "package_summary": ["julius: Open-Source Large Vocabulary CSR Engine (http://julius.sourceforge.jp/index.php)"]},
{"url": "https://wiki.ros.org/controller_manager_msgs", "package": "controller_manager_msgs", "package_summary": ["Messages and services for the controller manager."]},
{"url": "https://wiki.ros.org/rcdiscover", "package": "rcdiscover", "package_summary": ["This package contains tools for the discovery of Roboception devices via GigE Vision."], "package_details": [" "], "package_tt": ["rcdiscover", "rcdiscover-gui"]},
{"url": "https://wiki.ros.org/urg_c", "package": "urg_c", "package_summary": ["The urg_c package"]},
{"url": "https://wiki.ros.org/ros_core", "package": "ros_core", "package_summary": ["A metapackage to aggregate the packages required to use publish / subscribe, services, launch files, and other core ROS concepts."]},
{"url": "https://wiki.ros.org/turtlebot3", "package": "turtlebot3", "package_summary": ["ROS packages for the Turtlebot3 (meta package)"], "package_details": [" ", "\n", " ", " is a new generation mobile robot that is modular, compact and customizable. Let\u2019s explore ROS and create exciting applications for education, research and product development. The goal of ", " is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and ", " can be customized in various ways. ", " is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. ", "\n", "\n", "\n", "\n"], "package_tt": ["TurtleBot3", "TurtleBot3", "TurtleBot3"]},
{"url": "https://wiki.ros.org/rqt_gui_py", "package": "rqt_gui_py", "package_summary": ["rqt_gui_py enables GUI plugins to use the Python client library for ROS."]},
{"url": "https://wiki.ros.org/pr2eus_openrave", "package": "pr2eus_openrave", "package_summary": ["\n\n     pr2eus_openrave\n\n  "], "package_details": ["\n", "\n", " and ", " ", "Documentation is available ", ". ", "Use trac to report ", " or ", ". ", " "]},
{"url": "https://wiki.ros.org/mbf_costmap_core", "package": "mbf_costmap_core", "package_summary": ["This package provides common interfaces for navigation specific robot actions. It contains the CostmapPlanner, CostmapController and CostmapRecovery interfaces. The interfaces have to be implemented by the plugins to make them available for Move Base Flex using the mbf_costmap_nav navigation implementation. That implementation inherits the mbf_abstract_nav implementation and binds the system to a local and a global costmap."]},
{"url": "https://wiki.ros.org/moveit_planners_ompl", "package": "moveit_planners_ompl", "package_summary": ["MoveIt! interface to OMPL"]},
{"url": "https://wiki.ros.org/sr_ethercat_hand_config", "package": "sr_ethercat_hand_config", "package_summary": ["\n\n    sr_ethercat_hand_config contains the different yaml files storing the parameters used on the etherCAT hand.\n\n  "]},
{"url": "https://wiki.ros.org/xdot", "package": "xdot", "package_summary": ["\n    ", ", \n    is an interactive viewer for graphs written in Graphviz's dot\n    language.\n\n    This package adds front-end capabilities to XDot including WX Widget\n    support and a mechanism for receiving callbacks when nodes are clicked. This extension is provided as BSD.\n\n  "], "package_details": ["\n", " ", " ", "\n", " ", "Please see ", " and ", " for more information. "], "package_code": ["rosrun xdot xdot.py [file]"]},
{"url": "https://wiki.ros.org/lidar_camera_calibration", "package": "lidar_camera_calibration", "package_summary": ["ROS package to find a rigid-body transformation between a LiDAR and a camera"], "package_details": [" ", "We maintain a very detailed README and other information regarding the lidar_camera_calibration package at the ", " repo for the package. For more information regarding setting up lidar_camera_calibration, detailed usage, package capabilities and tutorials, please visit the ", " repository at ", ". ", "For technical information please visit: ", " "]},
{"url": "https://wiki.ros.org/roslisp_utilities", "package": "roslisp_utilities", "package_summary": ["Some utility functionality to interact with ROS using roslisp."]},
{"url": "https://wiki.ros.org/moveit_ros_planning", "package": "moveit_ros_planning", "package_summary": ["Planning components of MoveIt! that use ROS"]},
{"url": "https://wiki.ros.org/teleop_tools_msgs", "package": "teleop_tools_msgs", "package_summary": ["The teleop_tools_msgs package"]},
{"url": "https://wiki.ros.org/rqt_logger_level", "package": "rqt_logger_level", "package_summary": ["rqt_logger_level provides a GUI plugin for configuring the logger level of ROS nodes.", "\n   ", "\n  rqt_logger_level takes over `wx`-based tool [[rxloggerlevel]]."], "package_details": ["\n", " is an application for adjusting the logger level of ros nodes ", "\n"], "package_tt": ["rqt_logger_level"], "package_code": ["$ rosrun rqt_logger_level rqt_logger_level"]},
{"url": "https://wiki.ros.org/mbf_msgs", "package": "mbf_msgs", "package_summary": ["The move_base_flex messages package providing the action definition files for the action GetPath, ExePath, Recovery and MoveBase. The action servers providing these action are implemented in ", "."]},
{"url": "https://wiki.ros.org/seed_r7_robot_interface", "package": "seed_r7_robot_interface", "package_summary": ["The seed_r7_robot_interface package"]},
{"url": "https://wiki.ros.org/moveit_plugins", "package": "moveit_plugins", "package_summary": ["Metapackage for moveit plugins."]},
{"url": "https://wiki.ros.org/joystick_interrupt", "package": "joystick_interrupt", "package_summary": ["Interrupt cmd_vel by joystick input"]},
{"url": "https://wiki.ros.org/resource_retriever", "package": "resource_retriever", "package_summary": ["This package retrieves data from url-format files such as http://,\n   ftp://, package:// file://, etc., and loads the data into memory.\n   The package:// url for ros packages is translated into a local\n   file:// url.  The resourse retriever was initially designed to load\n   mesh files into memory, but it can be used for any type of\n   data. The resource retriever is based on the the libcurl library."], "package_details": ["\n", " has an extremely simple C++ API, consisting of two classes and one method. ", " also has a very similar Python API. ", "The ", " class is the gateway into downloading files.  Its ", " method returns a ", " which contains the file in memory.  ", "The ", " tutorial details how to use both classes. "], "package_tt": ["resource_retriever", "get()", "resource_retriever"]},
{"url": "https://wiki.ros.org/jsk_tools", "package": "jsk_tools", "package_summary": ["Includes emacs scripts, ros tool alias generator, and launch doc generator."], "package_details": ["Documentation is available ", ". "]},
{"url": "https://wiki.ros.org/pmb2_gazebo", "package": "pmb2_gazebo", "package_summary": ["Simulation files for the PMB2 robot."]},
{"url": "https://wiki.ros.org/ira_laser_tools", "package": "ira_laser_tools", "package_summary": ["The ira_laser_tools package. These nodes are meant to provide some utils for lasers, like listen to different laser scan sources and merge them in a single scan or generate virtual laser scans from a pointcloud."], "package_details": [" ", "The documentation is at the moment very brief, for any question please contact us at ", " or ", " ", "Paper link: ", " "]},
{"url": "https://wiki.ros.org/stomp_core", "package": "stomp_core", "package_summary": ["This package  provides the core STOMP (Stochastic Trajectory Optimization for Motion Planning) algorithm that can be used for robot motion planning tasks or other similar optimization tasks"]},
{"url": "https://wiki.ros.org/phidgets_ik", "package": "phidgets_ik", "package_summary": ["Driver for the Phidgets InterfaceKit devices"]},
{"url": "https://wiki.ros.org/mrpt_tutorials", "package": "mrpt_tutorials", "package_summary": ["Example files used as tutorials for MRPT ROS packages"], "package_details": ["\n", " comprises demo files for ", ". ", "\n"], "package_tt": ["mrpt_tutorials"]},
{"url": "https://wiki.ros.org/mrpt_localization", "package": "mrpt_localization", "package_summary": ["Package for robot 2D self-localization using dynamic or static (MRPT or ROS) maps.\n\tThe interface is similar to amcl (http://wiki.ros.org/amcl)\n   but supports different particle-filter algorithms, several grid maps at\n   different heights, range-only localization, etc."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " node wraps MRPT particle-filter localization algorithms through a ROS interface. See demo launch-file and tutorials above. "], "package_tt": ["mrpt_localization"], "package_code": ["roslaunch mrpt_localization demo.launch", "roslaunch mrpt_localization demo_ro.launch", "roslaunch mrpt_localization demo.launch"]},
{"url": "https://wiki.ros.org/pmb2_controller_configuration", "package": "pmb2_controller_configuration", "package_summary": ["Launch files and scripts needed to configure\n    the controllers of the PMB2 robot."]},
{"url": "https://wiki.ros.org/yocs_waypoints_navi", "package": "yocs_waypoints_navi", "package_summary": ["Simple tool for waypoints navigation with two functions:\n    ", " * Command the robot to go to a goal by passing through a series of waypoints.\n    ", " * Command the robot to constantly loop through a series of waypoints, useful for patrol."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/zeroconf_avahi", "package": "zeroconf_avahi", "package_summary": ["Provides zeroconf services on avahi for ros systems.\n     This is a c++ implementation."], "package_details": ["\n", "\n", " are used to discover the appearance and disappearance of all  ", "services belong to a specific service type (e.g. _ros-master._tcp). The usual process is to add a listener and then sit back and wait for the callbacks (either c++ or ros subscription) to arrive signifying addition or removal of the specified services. ", " are zeroconf services you wish to publish on the network. They require a name, service type, port and description. If there is a name collision, ", "this package and avahi will rename the service so that it is unique for the lifetime of the current connection. ", "\n", "\n", "\n", " ", "This package provides implementations for ", " on top of linux's ", ". There are two implementations: ", "The c++ library can be manipulated directly through the ", " class whereas the ", " provides similar handles through ros topics, services and parameters exposed by the. ", "Both the c++ and node implementations operate on two entities, ", " and ", ".  ", "If you're using the library, it should be relatively straightforward - simply follow the ", " class documentation. There is also an example in ", ". ", "Alternatively, using the ros node can be done in a variety of ways, refer to the ", ". ", "See the example on static configuration for an illustration of the usage of the  ", " and ", " parameters: "], "package_tt": ["new_connections", "lost_connections", "add_listener", "add_service", "remove_service", "list_discovered_services", "list_published_services", "~services", "array[structs]"]},
{"url": "https://wiki.ros.org/urg_node", "package": "urg_node", "package_summary": ["urg_node"], "package_details": [" ", "\n", "\n", "\n", ": ", ": ", "\n", "\n", " ", "\n", "\n", "Image credit: ", " ", "Allow Unsafe Settings Option is not available, please consider using the legacy ", " for UTM-30LX with certain configurations.  (Or provide a ", " to add support for unsafe_settings.) ", "The ", " program can be used to get information about a hokuyo laser scanner. Each of them can be invoked in a human readable way: ", "The ", " program can be used to get the hardware ID of a Hokuyo device given its port. Combined with udev, this allows a consistent device name to be given to each device, even if the order in which they are plugged in varies. On the PR2 we use the following udev rule: "], "package_tt": ["cluster", "skip", "intensity", "min_ang", "max_ang", "cluster", "skip", "intensity", "min_ang", "max_ang", "getID", "getID"], "package_code": ["$ rosrun urg_node getID /dev/ttyACM0\n", "Device at /dev/ttyACM0 has ID H0807228", "$ rosrun urg_node getID /dev/ttyACM0 --\n", "H0807228", "SUBSYSTEMS==\"usb\", KERNEL==\"ttyACM[0-9]*\", ACTION==\"add\", ATTRS{idVendor}==\"15d1\", ATTRS{idProduct}==\"0000\", MODE=\"666\", PROGRAM=\"/opt/ros/hydro/lib/urg_node/getID /dev/%k q\", SYMLINK+=\"sensors/hokuyo_%c\", GROUP=\"dialout\"", "$ ls -l /etc/ros/sensors/base_hokuyo\n", "lrwxrwxrwx 1 root root 28 2010-01-12 15:53 /etc/ros/sensors/base_hokuyo -> /dev/sensors/hokuyo_H0902620\n", "$ ls -l /dev/sensors/hokuyo_H0902620\n", "lrwxrwxrwx 1 root root 10 2010-04-12 12:34 /dev/sensors/hokuyo_H0902620 -> ../ttyACM1"]},
{"url": "https://wiki.ros.org/ur_dashboard_msgs", "package": "ur_dashboard_msgs", "package_summary": ["Messages around the UR Dashboard server."]},
{"url": "https://wiki.ros.org/jsk_recognition_msgs", "package": "jsk_recognition_msgs", "package_summary": ["ROS messages for jsk_pcl_ros and jsk_perception."]},
{"url": "https://wiki.ros.org/rospatlite", "package": "rospatlite", "package_summary": ["rospatlite"], "package_details": [" is a ROS driver for patlite Signal Tower NHx series. ", "\n", " ", "\n", "\n", "\n"], "package_tt": ["rospatlite", "roslaunch\u00a0rospatlite\u00a0patlite.launch\u00a0IP:=<patlite\u00a0ip>", "patlite\u00a0ip", "~set/red", "~set/yellow", "~set/green", "~set/blue", "~set/white", "~set/buzzer", "~host", "string", "~port", "int", "~timeout", "float"], "package_code": ["$ roslaunch rospatlite patlite.launch IP:=10.68.0.10", "$ rostopic pub /patlite/set/buzzer std_msgs/Int8 1 # <- buzzer ON\n", "$ rostopic pub /patlite/set/buzzer std_msgs/Int8 0 # <- buzzer OFF\n", "$ rostopic pub /patlite/set/red std_msgs/Int8 1 # <- red light ON\n", "$ rostopic pub /patlite/set/yellow std_msgs/Int8 2 # <- yellow light blink"]},
{"url": "https://wiki.ros.org/pr2_controllers_msgs", "package": "pr2_controllers_msgs", "package_summary": ["Messages, services, and actions used in the pr2_controllers stack."], "package_details": ["\n", "\n", " ", "This package seems to be replaced by the PR2-agnostic package ", ", stated by ", ". "]},
{"url": "https://wiki.ros.org/image_view2", "package": "image_view2", "package_summary": ["A simple viewer for ROS image topics with draw-on features"], "package_details": [" ", "Documentation: See ", " "]},
{"url": "https://wiki.ros.org/transmission_interface", "package": "transmission_interface", "package_summary": ["Transmission Interface."], "package_details": ["\n", "  contains data structures for representing mechanical transmissions, and  methods for propagating position, velocity and effort variables between  actuator and joint spaces. ", "In the same spirit as the ", "  package, this package wraps existing raw data (eg. current actuator  position, reference joint command, etc.) under a consistent interface.  By not imposing a specific layout on the raw data, it becomes easier to  support arbitrary hardware drivers to software control. ", "The ", " is ", " used by controllers themselves (it does not implement a ", ") but instead operates before or after the controllers update, in the read() and write() methods (or equivalents) of the robot abstraction. ", "See the ", " page, ", " and the ", " for more information. "]},
{"url": "https://wiki.ros.org/zbar_ros", "package": "zbar_ros", "package_summary": ["Lightweight ROS wrapper for Zbar barcode/qrcode reader library (http://zbar.sourceforge\n    .net/)"], "package_details": ["\n", "\n", "\n", "This package is a lightweight wrapper around the ", " barcode processing library. It provides a node and a nodelet with equivalent interface. The ", " topic is a lazy subscription that is active only when the ", " topic has a client. ", "Same API as node, available as ", ". "], "package_tt": ["image", "barcode", "barcode_reader_node", "image", "barcode", "~throttle_repeated_barcodes", "double", "0.0", "zbar_ros/barcode_reader_nodelet"]},
{"url": "https://wiki.ros.org/yocs_controllers", "package": "yocs_controllers", "package_summary": ["Library for various controller types and algorithms"], "package_details": [" "]},
{"url": "https://wiki.ros.org/pr2_bringup_tests", "package": "pr2_bringup_tests", "package_summary": ["Complete functionality tests for PR2. Contains utilities designed to test and verify devices, mechanicals and sensors."], "package_details": ["\n", " - Information qualifying the mechanical calibration of newly built robots "]},
{"url": "https://wiki.ros.org/ur_robot_driver", "package": "ur_robot_driver", "package_summary": ["The new driver for Universal Robots UR3, UR5 and UR10 robots with CB3 controllers and the e-series."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For robots with Polyscope ", " or older, please see whether ", " is sufficient. ", "Make sure the controller runs ", " or newer for CB3, or ", " or newer for e-Series controllers. ", "Most documentation is handled inside the Githhub ", " files. "], "package_tt": ["v1.8.x", "v3.7", "v5.1"]},
{"url": "https://wiki.ros.org/jsk_calibration", "package": "jsk_calibration", "package_summary": ["The jsk_calibration package"]},
{"url": "https://wiki.ros.org/yocs_ar_pair_tracking", "package": "yocs_ar_pair_tracking", "package_summary": ["The AR pair tracking package"], "package_details": ["\n", "\n", "\n", " explains what to configure. ", "\n", "\n"], "package_tt": ["update_ar_pairs", "~spotted_markers", "~initial_pose", "~relative_target_pose", "publish_transforms", "bool", "global_frame", "string", "marker_frame", "string", "base_frame", "string"]},
{"url": "https://wiki.ros.org/qt_build", "package": "qt_build", "package_summary": ["Currently just maintains a cmake api for simplifying the building\n    of qt apps within the ros framework."], "package_tt": ["package.xml", "CMakeLists.txt", "include/qdude/*.hpp", "src", "ui", "resources"], "package_code": ["  <buildtool_depend>catkin</buildtool_depend>\n", "  <build_depend>qt_build</build_depend>\n", "  <build_depend>roscpp</build_depend>\n", "  <run_depend>roscpp</run_depend>", "find_package(catkin REQUIRED COMPONENTS qt_build roscpp)\n", "rosbuild_prepare_qt4(QtCore QtGui) # Add qt components to the list here\n", "\n", "...", "file(GLOB QT_FORMS RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} ui/*.ui)\n", "file(GLOB QT_RESOURCES RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} resources/*.qrc)\n", "file(GLOB_RECURSE QT_MOC RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} FOLLOW_SYMLINKS include/qdude/*.hpp)\n", "\n", "QT4_ADD_RESOURCES(QT_RESOURCES_CPP ${QT_RESOURCES})\n", "QT4_WRAP_UI(QT_FORMS_HPP ${QT_FORMS})\n", "QT4_WRAP_CPP(QT_MOC_HPP ${QT_MOC})\n", "\n", "file(GLOB_RECURSE QT_SOURCES RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} FOLLOW_SYMLINKS src/*.cpp)", "include_directories(${catkin_INCLUDE_DIRS})\n", "add_executable(qdude ${QT_SOURCES} ${QT_RESOURCES_CPP} ${QT_FORMS_HPP} ${QT_MOC_HPP})\n", "target_link_libraries(qdude ${QT_LIBRARIES} ${catkin_LIBRARIES})", "install(TARGETS qdude RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})"]},
{"url": "https://wiki.ros.org/jsk_footstep_planner", "package": "jsk_footstep_planner", "package_summary": ["jsk_footstep_planner"]},
{"url": "https://wiki.ros.org/sicktoolbox", "package": "sicktoolbox", "package_summary": ["SICK Toolbox drivers for SICK laser rangefinders\n\n    This package contains the ROS fork of the SICK LIDAR Matlab/C++ Toolbox, available from ", ".\n\n    The SICK LIDAR Matlab/C++ Toolbox offers stable and easy-to-use C++ drivers for SICK LMS 2xx and SICK LD LIDARs.  Also included are config utilities, examples, and tutorials."], "package_details": [" ", "\n", "Please see the ", " package to use this library with ROS. "]},
{"url": "https://wiki.ros.org/pr2_gripper_sensor_msgs", "package": "pr2_gripper_sensor_msgs", "package_summary": ["The pr2_gripper_sensor_msgs package contains various actions and messages that are used in the pr2_gripper_sensor* packages. The structure of the API used by pr2_gripper_sensor_action, and pr2_gripper_sensor_controller packages is as follows: \n\nUsers will send a goal to an Action in the message format of PR2Gripper*Command (where * replaces the name of the particular Action from pr2_gripper_sensor_action). Feedback and Result information for the action is then returned in the format of PR2Gripper*Data."], "package_details": [" ", "\n", "Please refer to the ", " and ", " packages for additional information. The messages in this package are largely used for communication between these packages, as indicated by the red arrows in the diagram below.  ", " "]},
{"url": "https://wiki.ros.org/rqt_rviz", "package": "rqt_rviz", "package_summary": ["rqt_rviz provides a GUI plugin embedding ", ".\n    Note that this rqt plugin does NOT supersede RViz but depends on it."]},
{"url": "https://wiki.ros.org/rqt_bag", "package": "rqt_bag", "package_summary": ["rqt_bag provides a GUI plugin for displaying and replaying ROS bag files."], "package_details": [", which is deprecated since ", " ", ". ", "\n", " is an application for recording and managing bag files. Primary features: ", " can be extended via a plugin mechanism.  Core plugins are contained in the ", " package available in the ", " metapackage. ", " ", "\n", "\n", "\n", " ", " Don't forget to use simulation time when republishing from a bag file: ", " ", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", " ", "\n", "\n", " currently has a proof-of-concept plugin API, which is used in the ", " package. ", " ", "and select from ", " --> ", " --> ", ". ", "Or simply the following (with this you can't open ", " with other rqt tools). ", "Right-click on the name of the topic you want to publish, then select ", "  (as in the image below). ", "The messages are shown at the timestamp stored in the bag file.  This timestamp may differ from the message's ", " timestamp (if any), e.g. ", " stores the time the message was received. ", "For details on common message views such as images and plotting, see ", ". "], "package_tt": ["rqt_bag", "ROS", "rqt_bag", "rqt_bag", "Plugins", "Logging", "Bag", "rqt_bag", "Publish", "Header", "rosbag\u00a0record", "rqt_bag"], "package_code": ["$ rqt", "$ rqt_bag"]},
{"url": "https://wiki.ros.org/mrpt1", "package": "mrpt1", "package_summary": ["Mobile Robot Programming Toolkit (MRPT) version 1.5.x"], "package_details": ["The ", " package provides the C++ libraries for MRPT 1.5.x, required in distributions where the official packages are older. "], "package_tt": ["mrpt1"]},
{"url": "https://wiki.ros.org/rqt_tf_tree", "package": "rqt_tf_tree", "package_summary": ["rqt_tf_tree provides a GUI plugin for visualizing the ROS TF frame tree."], "package_details": [" "]},
{"url": "https://wiki.ros.org/actionlib_lisp", "package": "actionlib_lisp", "package_summary": ["actionlib_lisp is a native implementation of the famous actionlib\n   in Common Lisp. It provides a client and a simple server."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "actionlib_lisp is a native implementation of ", " in Common Lisp. It provides a simple server and a client. In contrast to the implementations of actionlib in C++ and Python which provide a simple action client/server and a complex one, the lisp equivalent provides only one server and client implementation. The server is similar to the simple action server and the client is a little bit more powerful than the simple action client but not as complex as the complex C++ equivalent. "], "package_tt": ["(make-action-client\u00a0action-name\u00a0action-type)", "action-name", "action-type", "(wait-for-server\u00a0action-client\u00a0&optional\u00a0timeout)", "timeout", "NIL", "T", "(send-goal\u00a0client\u00a0goal\u00a0&optional\u00a0done-cb\u00a0feedback-cb\u00a0active-cb\u00a0state-change-cb)", "client", "ACTION-CLIENT", "done-cb", "feedback-cb", "active-cb", "state-change-cb", "(cancel-goal\u00a0goal-handle)", "goal-handle", "(wait-for-result\u00a0goal-handle\u00a0&optional\u00a0timeout)", "(send-goal-and-wait\u00a0client\u00a0goal\u00a0&key\u00a0exec-timeout\u00a0result-timeout\u00a0feedback-cb)", "wait-for-result", "feedback-signal", "abort-goal", "client", "goal", "exec-timeout", "result-timeout", "feedback-cb", "send-goal-and-wait", "(call-goal\u00a0client\u00a0goal\u00a0&key\u00a0timeout\u00a0result-timeout\u00a0feedback-cb)", "(connected-to-server\u00a0client)", "T", "(make-action-goal\u00a0client\u00a0&rest\u00a0args)", "client", "make-msg", "(start-action-server\u00a0action-name\u00a0action-type\u00a0exec-callback\u00a0&key\u00a0separate-thread)", "action-name", "action-type", "exec-callback", "separate-thread", "(def-exec-callback\u00a0name\u00a0args\u00a0&body\u00a0body)", "preempt-current", "succeed-current", "abort-current", "cancel-request-received", "publish-feedback", "body", "(succeed-current\u00a0&rest\u00a0args)", "args", "make-msg", "(abort-current\u00a0&rest\u00a0args)", "args", "make-msg", "(preempt-current\u00a0&rest\u00a0args)", "args", "make-msg", "(publish-feedback\u00a0&rest\u00a0args)", "args", "make-msg", "(cancel-request-received)", "T"], "package_code": ["(defparameter *ac* (make-action-client \"/fibonacci\" \"actionlib_tutorials/FibonacciAction\"))\n", "\n", "(send-goal-and-wait *ac* (make-action-goal *ac* :order 10) :exec-timeout 20 :result-timeout 0.5)", "(def-exec-callback fib-callback (order)\n", "  \"This function takes in the FibonacciGoal message and pursues the action.\"\n", "  (ros-debug (fib callback) \"entering callback with goal ~a\" order)\n", "  (let ((a 1) (b 1) (seq (make-array 0 :adjustable t :fill-pointer 0)))\n", "    (dotimes (i order)\n", "      (when (cancel-request-received)\n", "        (ros-debug (fib callback) \"goal ~a canceled\" order)\n", "        (preempt-current :sequence seq)) ;; Note that this exits the callback\n", "        \n", "      (psetq a b b (+ a b))\n", "      (vector-push-extend a seq) \n", "      (ros-debug (fib callback) \"publishing feedback for goal ~a\" order)\n", "      (publish-feedback :sequence seq)\n", "      (sleep 1.0))\n", "    (ros-debug (fib callback) \"succeeding on goal ~a\" order)\n", "    (succeed-current :sequence seq)))\n", "\n", "      \n", "(defun fib-server ()\n", "  (with-ros-node (\"fib\")\n", "    (start-action-server \"fibonacci\" \"actionlib_tutorials/FibonacciAction\" #'fib-callback)))"]},
{"url": "https://wiki.ros.org/mini_maxwell", "package": "mini_maxwell", "package_summary": ["mini_maxwell"]},
{"url": "https://wiki.ros.org/spatio_temporal_voxel_layer", "package": "spatio_temporal_voxel_layer", "package_summary": ["The spatio-temporal 3D obstacle costmap package"], "package_details": ["\n", " ", "The spatio-temporal voxel layer incorporates information from the sensors in the form of ", " or ", ". This information is converted into 3D and populated into an efficient voxel grid for each sensor cycle. ", "More information, ROS API, demos, and resources are given in the ", " page. "]},
{"url": "https://wiki.ros.org/jsk_perception", "package": "jsk_perception", "package_summary": ["ROS nodes and nodelets for 2-D image perception."]},
{"url": "https://wiki.ros.org/qt_gui_core", "package": "qt_gui_core", "package_summary": ["Integration of the ROS package system and ROS-specific plugins for a Qt-based GUI."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/qt_dotgraph", "package": "qt_dotgraph", "package_summary": ["qt_dotgraph provides helpers to work with dot graphs."]},
{"url": "https://wiki.ros.org/ros_controllers", "package": "ros_controllers", "package_summary": ["Library of ros controllers"], "package_details": ["\n", "See ", " for more information. "], "package_code": ["@article{ros_control,\n", "author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\\\"u}dtke, Mathias and Fern{\\'a}ndez Perdomo, Enrique},\n", "title = {ros\\_control: A generic and simple control framework for ROS},\n", "journal = {The Journal of Open Source Software},\n", "year = {2017},\n", "doi = {10.21105/joss.00456},\n", "URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}\n", "}"]},
{"url": "https://wiki.ros.org/rostwitter", "package": "rostwitter", "package_summary": ["The rostwitter package"]},
{"url": "https://wiki.ros.org/pr2_self_test", "package": "pr2_self_test", "package_summary": ["The pr2_self_test package"]},
{"url": "https://wiki.ros.org/rqt_launch", "package": "rqt_launch", "package_summary": ["This rqt plugin ROS package provides easy view of .launch files.\n  User can also start and end node by node that are defined in those files."], "package_details": [" This package is still experimental. Feedback from early users are appreciated. ", "\n", "\n", "\n", "\n", "\n", ", ", " doesn't guarantee that the nodes start running in any order. In ", ", however, nodes get started in the order in the ", " file (still doesn't mean that each process finished initialization procedure in the started order - it depends on how much time they take). ", "\n", "\n", "And choose ", " from ", " menu.  ", "See ", " for more options. ", "Sample image using ", ": ", " ", "Sample image using ", ": ", " ", "This list is just a clarification/disclaimer. Enhancement request is welcomed at Bugtracker (link is available at ", " of this page). "], "package_tt": ["Launch", "Plugins", "KDE", "Gnome", ".launch", ".launch", "ARG", "ARG", ".launch", "Package\u00a0Summary", ".launch", ".launch", "rqt_launch", "rqt_launch", ".launch"], "package_code": ["% rqt"]},
{"url": "https://wiki.ros.org/message_generation", "package": "message_generation", "package_summary": ["Package modeling the build-time dependencies for generating language bindings of messages."]},
{"url": "https://wiki.ros.org/rqt_publisher", "package": "rqt_publisher", "package_summary": ["rqt_publisher provides a GUI plugin for publishing arbitrary messages with fixed or computed field values."], "package_details": [" "]},
{"url": "https://wiki.ros.org/pilz_control", "package": "pilz_control", "package_summary": ["This package provides a specialized joint_trajectory_controller that can be moved into holding state via service call.\n  No further trajectories will be accepted/followed in this state."]},
{"url": "https://wiki.ros.org/xsens_driver", "package": "xsens_driver", "package_summary": ["ROS Driver for XSens MT/MTi/MTi-G devices."], "package_details": ["\n", "\n", " ", "\n", "\n", " ", " is a Python module that is both a library to communicate to devices through the ", " class, and a standalone script to configure such a device. ", "Note that you can use the module in an interactive session to diagnose or configure the device with a bit more flexibility. ", " Changing the baudrate to values other than 115200 might not work for some devices (despite mentioned in the vendor documentation) and might require the emergency procedure to recover communication with the device. ", "\n", "\n", "This package provides a driver for the third and fourth generation of Xsens IMU devices. The driver is in two parts, a small implementation of most of the MT protocol in Python and a ", ". It works both on serial and USB interfaces. ", "These MT* devices can store their configuration and will retrieve it at each boot and then stream data according to this configuration. The node only forwards the data streamed onto ROS topics. In order to configure your device, you can use the ", " script (or the vendor tool on Windows). ", "Compared to the other MTi drivers (", " and ", "), this one can handle other configurations than the default and the GPS module of the MTi-G. It is also a clean rewrite of the communication protocol easier to maintain (and possibly extend) than the old vendor based multi-layered architecture. ", "The ROS node is a wrapper around the ", " class to publish the data that the IMU streams. It can publish the following topics, depending on the configuration of the device (topics are only advertised when there is data to publish): ", "\n", "It also publishes ", " ", "information. ", "If the IMU is set to raw mode, the values in of the ", ", ", " and ", " topics are the 16 bits output of the AD converters. ", "The covariance information in the ", " message are filled with default values from the MTx/MTi/MTi-G documentation but may not be exact; it also does not correspond to the covariance of the internal XKF. ", "It might be necessary to add the user to the ", " group so that the node can communicate with the device. "], "package_tt": ["mtdevice::MTDevice", "imu/data", "fix", "velocity", "imu/mag", "temperature", "pressure", "analog_in1", "analog_in2", "ecef", "time_reference", "imu_data_str", "/imu/data", "/velocity", "/magnetic", "~device", "string", "\"auto\"", "~baudrate", "int", "\"auto\"", "0", "~timeout", "float", "~frame_id", "string", "~frame_local", "string", "~frame_id", "mtdevice.py", "MTDevice", "dialout"], "package_code": ["Usage:\n", "    ./mtdevice.py [commands] [opts]\n", "\n", "Commands:\n", "    -h, --help\n", "        Print this help and quit.\n", "    -r, --reset\n", "        Reset device to factory defaults.\n", "    -a, --change-baudrate=NEW_BAUD\n", "        Change baudrate from BAUD (see below) to NEW_BAUD.\n", "    -c, --configure=OUTPUT\n", "        Configure the device (see OUTPUT description below).\n", "    -e, --echo\n", "        Print MTData. It is the default if no other command is supplied.\n", "    -i, --inspect\n", "        Print current MT device configuration.\n", "    -x, --xkf-scenario=ID\n", "        Change the current XKF scenario.\n", "    -l, --legacy-configure\n", "        Configure the device in legacy mode (needs MODE and SETTINGS arguments\n", "        below).\n", "    -v, --verbose\n", "        Verbose output.\n", "\n", "Generic options:\n", "    -d, --device=DEV\n", "        Serial interface of the device (default: /dev/ttyUSB0). If 'auto', then\n", "        all serial ports are tested at all baudrates and the first\n", "        suitable device is used.\n", "    -b, --baudrate=BAUD\n", "        Baudrate of serial interface (default: 115200). If 0, then all\n", "        rates are tried until a suitable one is found.\n", "\n", "Configuration option:\n", "    OUTPUT\n", "        The format is a sequence of \"<group><type><frequency>?<format>?\"\n", "        separated by commas.\n", "        The frequency and format are optional.\n", "        The groups and types can be:\n", "            t  temperature (max frequency: 1 Hz):\n", "                tt  temperature\n", "            i  timestamp (max frequency: 2000 Hz):\n", "                iu  UTC time\n", "                ip  packet counter\n", "                ii  Integer Time of the Week (ITOW)\n", "                if  sample time fine\n", "                ic  sample time coarse\n", "                ir  frame range\n", "            o  orientation data (max frequency: 400 Hz):\n", "                oq  quaternion\n", "                om  rotation matrix\n", "                oe  Euler angles\n", "            b  pressure (max frequency: 50 Hz):\n", "                bp  baro pressure\n", "            a  acceleration (max frequency: 2000 Hz (see documentation)):\n", "                ad  delta v\n", "                aa  acceleration\n", "                af  free acceleration\n", "                ah  acceleration HR (max frequency 1000 Hz)\n", "            p  position (max frequency: 400 Hz):\n", "                pa  altitude ellipsoid\n", "                pp  position ECEF\n", "                pl  latitude longitude\n", "            n  GNSS (max frequency: 4 Hz):\n", "                np  GNSS PVT data\n", "                ns  GNSS satellites info\n", "            w  angular velocity (max frequency: 2000 Hz (see documentation)):\n", "                wr  rate of turn\n", "                wd  delta q\n", "                wh  rate of turn HR (max frequency 1000 Hz)\n", "            g  GPS (max frequency: 4 Hz):\n", "                gd  DOP\n", "                gs  SOL\n", "                gu  time UTC\n", "                gi  SV info\n", "            r  Sensor Component Readout (max frequency: 2000 Hz):\n", "                rr  ACC, GYR, MAG, temperature\n", "                rt  Gyro temperatures\n", "            m  Magnetic (max frequency: 100 Hz):\n", "                mf  magnetic Field\n", "            v  Velocity (max frequency: 400 Hz):\n", "                vv  velocity XYZ\n", "            s  Status (max frequency: 2000 Hz):\n", "                sb  status byte\n", "                sw  status word\n", "        Frequency is specified in decimal and is assumed to be the maximum\n", "        frequency if it is omitted.\n", "        Format is a combination of the precision for real valued numbers and\n", "        coordinate system:\n", "            precision:\n", "                f  single precision floating point number (32-bit) (default)\n", "                d  double precision floating point number (64-bit)\n", "            coordinate system:\n", "                e  East-North-Up (default)\n", "                n  North-East-Down\n", "                w  North-West-Up\n", "        Examples:\n", "            The default configuration for the MTi-1/10/100 IMUs can be\n", "            specified either as:\n", "                \"wd,ad,mf,ip,if,sw\"\n", "            or\n", "                \"wd2000fe,ad2000fe,mf100fe,ip2000,if2000,sw2000\"\n", "            For getting quaternion orientation in float with sample time:\n", "                \"oq400fw,if2000\"\n", "            For longitude, latitude, altitude and orientation (on MTi-G-700):\n", "                \"pl400fe,pa400fe,oq400fe\"\n", "\n", "Legacy options:\n", "    -m, --output-mode=MODE\n", "        Legacy mode of the device to select the information to output.\n", "        This is required for 'legacy-configure' command.\n", "        MODE can be either the mode value in hexadecimal, decimal or\n", "        binary form, or a string composed of the following characters\n", "        (in any order):\n", "            t  temperature, [0x0001]\n", "            c  calibrated data, [0x0002]\n", "            o  orientation data, [0x0004]\n", "            a  auxiliary data, [0x0008]\n", "            p  position data (requires MTi-G), [0x0010]\n", "            v  velocity data (requires MTi-G), [0x0020]\n", "            s  status data, [0x0800]\n", "            g  raw GPS mode (requires MTi-G), [0x1000]\n", "            r  raw (incompatible with others except raw GPS), [0x4000]\n", "        For example, use \"--output-mode=so\" to have status and\n", "        orientation data.\n", "    -s, --output-settings=SETTINGS\n", "        Legacy settings of the device. This is required for 'legacy-configure'\n", "        command.\n", "        SETTINGS can be either the settings value in hexadecimal,\n", "        decimal or binary form, or a string composed of the following\n", "        characters (in any order):\n", "            t  sample count (excludes 'n')\n", "            n  no sample count (excludes 't')\n", "            u  UTC time\n", "            q  orientation in quaternion (excludes 'e' and 'm')\n", "            e  orientation in Euler angles (excludes 'm' and 'q')\n", "            m  orientation in matrix (excludes 'q' and 'e')\n", "            A  acceleration in calibrated data\n", "            G  rate of turn in calibrated data\n", "            M  magnetic field in calibrated data\n", "            i  only analog input 1 (excludes 'j')\n", "            j  only analog input 2 (excludes 'i')\n", "            N  North-East-Down instead of default: X North Z up\n", "        For example, use \"--output-settings=tqMAG\" for all calibrated\n", "        data, sample counter and orientation in quaternion.\n", "    -p, --period=PERIOD\n", "        Sampling period in (1/115200) seconds (default: 1152).\n", "        Minimum is 225 (1.95 ms, 512 Hz), maximum is 1152\n", "        (10.0 ms, 100 Hz).\n", "        Note that for legacy devices it is the period at which sampling occurs,\n", "        not the period at which messages are sent (see below).\n", "\n", "Deprecated options:\n", "    -f, --deprecated-skip-factor=SKIPFACTOR\n", "        Only for mark III devices.\n", "        Number of samples to skip before sending MTData message\n", "        (default: 0).\n", "        The frequency at which MTData message is send is:\n", "            115200/(PERIOD * (SKIPFACTOR + 1))\n", "        If the value is 0xffff, no data is send unless a ReqData request\n", "        is made."]},
{"url": "https://wiki.ros.org/moveit_resources", "package": "moveit_resources", "package_summary": ["Resources used for MoveIt! testing"]},
{"url": "https://wiki.ros.org/pmb2_bringup", "package": "pmb2_bringup", "package_summary": ["Launch files and scripts needed to bring up the ROS nodes of a PMB2 robot."]},
{"url": "https://wiki.ros.org/rqt_reconfigure", "package": "rqt_reconfigure", "package_summary": ["This rqt plugin succeeds former dynamic_reconfigure's GUI\n    (reconfigure_gui), and provides the way to view and edit the parameters\n    that are accessible via dynamic_reconfigure.", "\n    ", "\n    (12/27/2012) In the future, arbitrary parameters that are not associated\n    with any nodes (which are not handled by dynamic_reconfigure) might\n    become handled.\n    However, currently as the name indicates, this pkg solely is dependent\n    on dynamic_reconfigure that allows access to only those params latched\n    to nodes."], "package_details": ["\n", " ", "To launch reconfigure_gui in Groovy, run: ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "You can also launch the ", " via ", ": ", "Generally speaking, try isolating GUI and non-GUI issue. ", "'s ", " are helpful for doing that. ", "(", ") ", "If nothing returned then the issue is your ", " itself, not ", ". "], "package_tt": ["reconfigure_gui", "dynamic_reconfigure", "dynamic_reconfigure", "rqt-reconfigure"], "package_code": ["rosrun rqt_reconfigure rqt_reconfigure", "rosrun rqt_gui rqt_gui", "rosrun dynamic_reconfigure dynparam list"]},
{"url": "https://wiki.ros.org/xbot_talker", "package": "xbot_talker", "package_summary": ["The xbot_talker package"], "package_details": ["\n", "\n", " ", "\n"], "package_tt": ["xbot_talker", "/xbot/talker_state", "/welcome/leave", "/xbot/play", "/xbot/chat", "~base_path", "string", "\"$(find\u00a0xbot_talker)\""]},
{"url": "https://wiki.ros.org/dynamic_edt_3d", "package": "dynamic_edt_3d", "package_summary": ["The dynamicEDT3D library implements an inrementally updatable Euclidean distance transform (EDT) in 3D. It comes with a wrapper to use the OctoMap 3D representation and hooks into the change detection of the OctoMap library to propagate changes to the EDT."]},
{"url": "https://wiki.ros.org/kdl_parser", "package": "kdl_parser", "package_summary": ["The Kinematics and Dynamics Library (KDL) defines a tree structure\n   to represent the kinematic and dynamic parameters of a robot\n   mechanism. ", " provides tools to construct a KDL\n   tree from an XML robot representation in URDF."], "package_details": [" ", "\n", "\n", " ", "If you want to take advantage of the powerful features of the ", ", the kdl parser provides an easy way to construct a full KDL Tree object. Starting from either a ", " or a Collada xml description of your robot, the kdl parser automatically generates a KDL Tree. "], "package_tt": ["kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser"]},
{"url": "https://wiki.ros.org/roseus_tutorials", "package": "roseus_tutorials", "package_summary": ["roseus_tutorials"], "package_details": ["Documentation is available ", " "]},
{"url": "https://wiki.ros.org/openrtm_tools", "package": "openrtm_tools", "package_summary": ["The openrtm_tools package"]},
{"url": "https://wiki.ros.org/rosconsole_bridge", "package": "rosconsole_bridge", "package_summary": ["rosconsole_bridge is a package used in conjunction with console_bridge and rosconsole for connecting console_bridge-based logging to rosconsole-based logging."], "package_details": ["\n", " is a package used in conjunction with ", " and ", " for connecting ", "-based logging to ", "-based logging. ", "\n", "\n", "If you have an application or library that is utilizing ", " for logging, the logging information will be written to stdout. Applications/libraries that utilize ", " do not follow this behavior, but rather write their output to both stdout (depending on log level) as well as the ROS topic /rosout. ", "If you have a console_bridge application or library, you can have its output be written to /rosout by simply having your package depend on rosconsole_bridge. Additionally, a call to REGISTER_ROSCONOLE_BRIDGE has to be added to the ROS node. (See ", "). "]},
{"url": "https://wiki.ros.org/pmb2_robot", "package": "pmb2_robot", "package_summary": ["PMB2 robot description and launch files"]},
{"url": "https://wiki.ros.org/nav_2d_msgs", "package": "nav_2d_msgs", "package_summary": ["Basic message types for two dimensional navigation, extending from geometry_msgs::Pose2D."]},
{"url": "https://wiki.ros.org/lanelet2_io", "package": "lanelet2_io", "package_summary": ["Parser/Writer module for lanelet2"]},
{"url": "https://wiki.ros.org/seed_r7_navigation", "package": "seed_r7_navigation", "package_summary": ["The seed_r7_navigation package"]},
{"url": "https://wiki.ros.org/summit_xl_sim_bringup", "package": "summit_xl_sim_bringup", "package_summary": ["Launch files for Summit XL simulation."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/force_torque_sensor_controller", "package": "force_torque_sensor_controller", "package_summary": ["Controller to publish state of force-torque sensors"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/rosgraph_msgs", "package": "rosgraph_msgs", "package_summary": ["Messages relating to the ROS Computation Graph. These are generally considered to be low-level messages that end users do not interact with."], "package_details": ["\n", " contains message relating to the ROS Computation Graph. Most users are not expected to interact with messages in this package, and it is strongly advised against.  These messages are generally wrapped in higher level APIs. ", "\n", " is the underlying message data structure for logging to ", ". If you use the client API methods in ", " and ", ", you will be protected against any future revisions to this message. ", " is used for simulated ", " in ROS. Only nodes that provide simulated time sources are expected to use this message. ", " ", " is used by ", " and ", " for publishing statistics on topic connections on /statistics. See ", " for more information. ", "Prior to Diamondback, these messages were in the ", " package.  They were migrated to this package as part of ", ". "], "package_tt": ["rosgraph_msgs"]},
{"url": "https://wiki.ros.org/turtlebot3_slam", "package": "turtlebot3_slam", "package_summary": ["The turtlebot3_slam package provides roslaunch scripts for starting the SLAM"], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["~base_frame", "string", "~odom_frame", "string", "~map_update_interval", "double", "~maxUrange", "double", "~minimumScore", "float", "~linearUpdate", "float", "~angularUpdate", "float", "~temporalUpdate", "float", "~delta", "float", "~lskip", "int", "~particles", "int", "~sigma", "float", "~delta", "float", "~kernelSize", "int", "~lstep", "float", "~astep", "float", "~iterations", "int", "~lsigma", "float", "~ogain", "float", "~srr", "float", "~srt", "float", "~srr", "float", "~stt", "float", "~resampleThreshold", "float", "~xmin", "float", "~ymin", "float", "~xmax", "float", "~ymax", "float", "~llsamplerange", "float", "~llsamplestep", "float", "~lasamplerange", "float", "~lasamplestep", "float"]},
{"url": "https://wiki.ros.org/safe_teleop_base", "package": "safe_teleop_base", "package_summary": ["This package provides automatic collision avoidance and is intended to be used for safer teleoperation of a robot base."], "package_details": ["\n", "\n", "\n", "\n", "\n", " (", ", default: 2.5) ", "This node takes as input commands for a robot base and outputs the nearest safe commands. The core functionality has some similarities to ", ". ", "Many of the parameters are identical to those of the ", " package. "], "package_tt": ["~<name>/safe_vel", "~<name>/user_plan", "~<name>/local_plan", "/base_velocity", "/odom", "~<name>/clear_costmaps", "~<name>/acc_lim_x", "double", "~<name>/acc_lim_y", "double", "~<name>/acc_lim_th", "double", "~<name>/sim_time", "double", "~<name>/sim_granularity", "double", "~<name>/vx_samples", "integer", "~<name>/vy_samples", "integer", "~<name>/vtheta_samples", "integer", "~<name>/user_bias", "double", "~<name>/occdist_scale", "double", "~<name>/max_vel_x", "double", "~<name>/min_vel_x", "double", "~<name>/max_vel_y", "double", "~<name>/min_vel_y", "double", "~<name>/min_vel_y", "double", "~<name>/max_rotational_velocity", "double", "~<name>/world_model", "string", "~<name>/holonomic_robot", "bool", "~<name>/dwa", "bool", "~<name>/safe_backwards", "bool"]},
{"url": "https://wiki.ros.org/gripper_action_controller", "package": "gripper_action_controller", "package_summary": ["The gripper_action_controller package"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/jackal_tutorials", "package": "jackal_tutorials", "package_summary": ["Jackal's tutorials."], "package_details": ["Please see the generated tutorial content ", ". "]},
{"url": "https://wiki.ros.org/seed_r7_description", "package": "seed_r7_description", "package_summary": ["The seed_r7_description package"]},
{"url": "https://wiki.ros.org/rqt_service_caller", "package": "rqt_service_caller", "package_summary": ["rqt_service_caller provides a GUI plugin for calling arbitrary services."]},
{"url": "https://wiki.ros.org/visp_ros", "package": "visp_ros", "package_summary": ["An extension of ViSP library that interfaces ROS into usual ViSP classes and a basket of generic ros nodes based on ViSP."], "package_details": ["\n", " ", " is a library: ", " contains also a set of ROS nodes that allow to control specific hardware such as for the moment robots (Afma6, Pioneer). ", "\n", "\n", " ", "\n", " ", "\n", " ", "\n", "\n", " ", "visp_ros is an extension of ", " library developed by Inria. While ViSP is independent to ROS, in visp_ros we benefit from ROS features. ", "To illustrate ", " behavior let us focus on a visual servoing example. ", "Using ", " allows to completely separate the code that is specific to the material (frame grabber, robot) from the one that does the visual servoing. ", "In ", " we introduce a new class named vpROSGrabber that is able to subscribe to an image topic. This class can be used to replace any ViSP grabber. We also introduce vpROSRobot that is able to publish cmd_vel velocities on a given topic. ", "The tutorial ", " explains how to build and install visp_ros in a catkin workspace. "], "package_code": ["#include <visp/vpImage.h> \n", "#include <visp/vp1394TwoGrabber.h> \n", "#include <visp/vpRobotViper850.h>\n", "\n", "int main() \n", "{\n", "  vpImage<unsigned char> I; \n", "  vpRobotViper850 robot; \n", "  robot.init();\n", "\n", "  vp1394TwoGrabber g; \n", "  g.open(I); \n", "\n", "  while(1) {\n", "    g.acquire(I); \n", "    // Visual servoing code \n", "    robot.setVelocity(vpRobot::CAMERA_FRAME, v);\n", "  }\n", "}", "#include <visp/vpImage.h> \n", "#include <visp_ros/vpROSGrabber.h>\n", "#include <visp_ros/vpROSRobot.h>\n", "\n", "int main() \n", "{\n", "  vpImage<unsigned char> I; \n", "  vpROSRobot robot; \n", "  robot.setCmdVelTopic(\"/myrobot/cmd_vel\");\n", "  robot.init();\n", "\n", "  vpROSGrabber g; \n", "  g.setImageTopic(\"/camera/image_raw\");\n", "  g.open(I); \n", "\n", "  while(1) {\n", "    g.acquire(I); \n", "    // Visual servoing code \n", "    robot.setVelocity(vpRobot::CAMERA_FRAME, v);\n", "  }\n", "}", "  ...\n", "  vpROSGrabber g; \n", "  g.setImageTopic(\"/camera/image_jpg\"); // Name of the compressed topic\n", "  g.setImageTransport(\"jpeg\");          // Type of compression. Must differ from \"raw\"\n", "  g.open(I); \n", "  ...", "#include <visp/vpImage.h> \n", "#include <visp_ros/vpROSGrabber.h>\n", "#include <visp_ros/vpROSRobot.h>\n", "\n", "int main(int argc, char **argv) \n", "{\n", "  vpImage<unsigned char> I; \n", "  vpROSRobot robot; \n", "  robot.setCmdVelTopic(\"/myrobot/cmd_vel\");\n", "  robot.init(argc, argv);\n", "\n", "  vpROSGrabber g; \n", "  g.setImageTopic(\"/camera/image_raw\");\n", "  g.open(argc, argv); \n", "\n", "  while(1) {\n", "    g.acquire(I); \n", "    // Visual servoing code \n", "    robot.setVelocity(vpRobot::CAMERA_FRAME, v);\n", "  }\n", "}"]},
{"url": "https://wiki.ros.org/jsk_recognition", "package": "jsk_recognition", "package_summary": ["Metapackage that contains recognition package for jsk-ros-pkg"]},
{"url": "https://wiki.ros.org/volksbot_driver", "package": "volksbot_driver", "package_summary": ["Driver for the Volksbot robot."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n "], "package_code": ["sudo apt install ros-melodic-volksbot-driver", "SUBSYSTEM==\"usb\",ATTRS{idVendor}==\"0403\",ATTRS{idProduct}==\"a8b0\",MODE=\"0660\",OWNER=\"robot_user\""]},
{"url": "https://wiki.ros.org/xacro", "package": "xacro", "package_summary": ["Xacro (XML Macros)\n\n    Xacro is an XML macro language. With xacro, you can construct shorter and more readable XML files by using macros that expand to larger XML expressions."], "package_details": ["\n", "\n", "\n", ": Properties are local if defined inside of a ", ". See ", ". ", "\n", ": ", "\n", ": The more powerful evaluation capabilities in ROS Jade allow for much more complex expression. Virtually any python expression that evaluates to a Boolean is feasible: ", "\n", ": Since ROS Indigo, it is also possible to define defaults like so: ", "\n", "Comments in front of macros will be removed during processing. ", "They are considered to be related to the macro (e.g. explaining the macro). If you want to keep a comment in the final document, separate it with an empty line from the macro. ", "\n", " Macro parameters can have default values: ", "Often, you need to pass external variables into local macro params (as above for x). To ease this task, you can employ the ^ syntax: ", "\n", "Properties and macros defined within a macro are local to this macro, i.e. not visible outside. Using the optional attribute ", ", a property definition can be exported to the parent scope of a macro (or the global scope). ", "\n", "\n", " Properties can be dictionaries or lists too - manually declared with python syntax, like so: ", "\n", ": While this cmake code provides full control over the target name and build order, there is a conveniency macro too: ", "\n", ": In order to add elements or attributes with a dynamically defined name, you can use the special xacro tags ", " and ", ": ", "\n", ": ", "\n", ": ", " ", "This package is most useful when working with large XML documents such as robot descriptions.  It is heavily used in packages such as the ", ".  See for example, ", " for how xacro is used to simplify urdf files. See ", ", for an example showing the use of the advanced features (python evaluation, yaml integration) introduced in Jade. ", "Many of the features highlighted as \"New in Jade\" below are also accessible from Indigo. To use them, the ", " flag is required. This flag is discussed ", ", and for some background information see this ", ". Put simply, this flag is used to trigger Jade-enabled xacro processing on Indigo. ", "Properties are named values that can be inserted anywhere into the XML document.  Property blocks are named snippets of XML that can be inserted anywhere that XML is allowed.  Both use the property tag to define values. Property tags cannot be declared inside of a ", ". ", "Since ROS Jade, Xacro employs ", " to evaluate expressions enclosed in dollared-braces, ", ". This allows for more complex arithmetic expressions. Functions and constants from the ", " math module (e.g. ", " and trigonometric functions) are available for use. Examples: ", "Xacro allows you to use certain rospack commands with dollared-parentheses (", "). ", "Xacro currently supports all the rospack commands that roslaunch supports using ", ". Arguments need to be specified on the command line using the ", " syntax. ", "You can include other xacro files using the ", " tag: ", "The file \"other_file.xacro\", will be included and expanded by xacro.  ", ": Relative filenames are interpreted relative to the currently processed file. ", ": When including files within a macro, not the macro-defining but the macro-calling file is the one that processes the include! $(cwd) explicitly allows to access files in the current working directory. ", "or loaded from ", " files like so: ", "If you want the generated files to have a ", " extension it is possible to provide input files terminating with ", ", the ", " suffix will be removed by the CMake function. This results in files with a ", " extension. ", "Usage example for ", ": ", "Classicly Xacro first loads all includes, then processes all property and macro definitions and finally instantiates macros and evaluates expressions. Thus, ", ". Additionally, the conditional tags, <if> and <unless>, have no effect on macro or property definitions nor the inclusion of additional files. ", "Since ROS Jade, Xacro provides the command-line option ", ", that allows to process the whole document in read order. Hence the latest definition of a property or macro ", ", will be used. This is a much more intuitive evaluation process that allows for some nice new features as well: ", "If there are any differences shown, you should check and adapt your xacro file. A common reason will be the late loading of calibration data (as properties). In this case, simply move them up front, i.e. before usage. To facilitate search for wrongly placed property definitions, you can run xacro with option ", ". If there are any problematic properties, they will be listed on stderr: ", "Using the command-line option ", " or ", " one can increase verbosity level to log all defintions of properties. ", "To suppress the legacy interpretation of sloppy xacro tags and allow their usage in the target XML, you can use the command line option ", ". "], "package_tt": ["--inorder", "xacro:macro", "xacro:macro", "python", "${}", "python", "pi", "$()", "myvar:=true", "scope=\"parent\u00a0|\u00a0global\"", "xacro:include", "props.yaml", "props", "val1", ".urdf", ".urdf.xacro", ".xacro", ".urdf", "<xacro:element>", "<xacro:attribute>", "<xacro:attribute>", "--inorder", "--check-order", "-vv", "-vvv", "--xacro-ns"], "package_code": ["<xacro:macro name=\"pr2_arm\" params=\"suffix parent reflect\">\n", "  <pr2_upperarm suffix=\"${suffix}\" reflect=\"${reflect}\" parent=\"${parent}\" />\n", "  <pr2_forearm suffix=\"${suffix}\" reflect=\"${reflect}\" parent=\"elbow_flex_${suffix}\" />\n", "</xacro:macro>\n", "\n", "<xacro:pr2_arm suffix=\"left\" reflect=\"1\" parent=\"torso\" />\n", "<xacro:pr2_arm suffix=\"right\" reflect=\"-1\" parent=\"torso\" />", "<pr2_upperarm suffix=\"left\" reflect=\"1\" parent=\"torso\" />\n", "<pr2_forearm suffix=\"left\" reflect=\"1\" parent=\"elbow_flex_left\" />\n", "<pr2_upperarm suffix=\"right\" reflect=\"-1\" parent=\"torso\" />\n", "<pr2_forearm suffix=\"right\" reflect=\"-1\" parent=\"elbow_flex_right\" />", "<xacro:property name=\"the_radius\" value=\"2.1\" />\n", "<xacro:property name=\"the_length\" value=\"4.5\" />\n", "\n", "<geometry type=\"cylinder\" radius=\"${the_radius}\" length=\"${the_length}\" />", "<xacro:property name=\"front_left_origin\">\n", "  <origin xyz=\"0.3 0 0\" rpy=\"0 0 0\" />\n", "</xacro:property>\n", "\n", "<pr2_wheel name=\"front_left_wheel\">\n", "  <xacro:insert_block name=\"front_left_origin\" />\n", "</pr2_wheel>", "<xacro:property name=\"radius\" value=\"4.3\" />\n", "<circle diameter=\"${2 * radius}\" />", "<xacro:property name=\"R\" value=\"2\" />\n", "<xacro:property name=\"alpha\" value=\"${30/180*pi}\" />\n", "<circle circumference=\"${2 * pi * R}\" pos=\"${sin(alpha)} ${cos(alpha)}\" />\n", "<limit lower=\"${radians(-90)}\" upper=\"${radians(90)}\" effort=\"0\" velocity=\"${radians(75)}\" />", "<xacro:if value=\"<expression>\">\n", "  <... some xml code here ...>\n", "</xacro:if>\n", "<xacro:unless value=\"<expression>\">\n", "  <... some xml code here ...>\n", "</xacro:unless>", "<xacro:property name=\"var\" value=\"useit\"/>\n", "<xacro:if value=\"${var == 'useit'}\"/>\n", "<xacro:if value=\"${var.startswith('use') and var.endswith('it')}\"/>\n", "\n", "<xacro:property name=\"allowed\" value=\"${[1,2,3]}\"/>\n", "<xacro:if value=\"${1 in allowed}\"/>", "<foo value=\"$(find xacro)\" />\n", "<foo value=\"$(arg myvar)\" />", "<xacro:arg name=\"myvar\" default=\"false\"/>", "<param name=\"robot_description\" command=\"$(find xacro)/xacro.py $(arg model) myvar:=true\" />", "<xacro:macro name=\"pr2_caster\" params=\"suffix *origin **content **anothercontent\">\n", "  <joint name=\"caster_${suffix}_joint\">\n", "    <axis xyz=\"0 0 1\" />\n", "  </joint>\n", "  <link name=\"caster_${suffix}\">\n", "    <xacro:insert_block name=\"origin\" />\n", "    <xacro:insert_block name=\"content\" />\n", "    <xacro:insert_block name=\"anothercontent\" />\n", "  </link>\n", "</xacro:macro>\n", "\n", "<xacro:pr2_caster suffix=\"front_left\">\n", "  <pose xyz=\"0 1 0\" rpy=\"0 0 0\" />\n", "  <container>\n", "    <color name=\"yellow\"/>\n", "    <mass>0.1</mass>\n", "  </container>\n", "  <another>\n", "    <inertial>\n", "      <origin xyz=\"0 0 0.5\" rpy=\"0 0 0\"/>\n", "      <mass value=\"1\"/>\n", "      <inertia ixx=\"100\"  ixy=\"0\"  ixz=\"0\" iyy=\"100\" iyz=\"0\" izz=\"100\" />\n", "    </inertial>\n", "  </another>\n", "</xacro:pr2_caster>", "<joint name=\"caster_front_left_joint\">\n", "  <axis xyz=\"0 0 1\" />\n", "</joint>\n", "<link name=\"caster_front_left\">\n", "  <pose xyz=\"0 1 0\" rpy=\"0 0 0\" />\n", "  <color name=\"yellow\" />\n", "  <mass>0.1</mass>\n", "  <inertial>\n", "    <origin xyz=\"0 0 0.5\" rpy=\"0 0 0\"/>\n", "    <mass value=\"1\"/>\n", "    <inertia ixx=\"100\"  ixy=\"0\"  ixz=\"0\" iyy=\"100\" iyz=\"0\" izz=\"100\" />\n", "  </inertial>\n", "</link>", "<xacro:macro name=\"reorder\" params=\"*first *second\">\n", "  <xacro:insert_block name=\"second\"/>\n", "  <xacro:insert_block name=\"first\"/>\n", "</xacro:macro>\n", "<reorder>\n", "  <first/>\n", "  <second/>\n", "</reorder>", "<a>\n", "  <xacro:macro name=\"foo\" params=\"x\">\n", "    <in_foo the_x=\"${x}\" />\n", "  </xacro:macro>\n", "\n", "  <xacro:macro name=\"bar\" params=\"y\">\n", "    <in_bar>\n", "      <xacro:foo x=\"${y}\" />\n", "    </in_bar>\n", "  </xacro:macro>\n", "\n", "  <xacro:bar y=\"12\" />\n", "</a>", "<a>\n", "  <in_bar>\n", "    <in_foo the_x=\"12.0\"/>\n", "  </in_bar>\n", "</a>", "<xacro:macro name=\"foo\" params=\"x:=${x} y:=${2*y} z:=0\"/>", "<xacro:macro name=\"foo\" params=\"p1 p2:=expr_a p3:=^ p4:=^|expr_b\">", "<xacro:include filename=\"$(find package)/other_file.xacro\" />\n", "<xacro:include filename=\"other_file.xacro\" />\n", "<xacro:include filename=\"$(cwd)/other_file.xacro\" />", "<xacro:include filename=\"other_file.xacro\" ns=\"namespace\"/>", "${namespace.property}", "<xacro:property name=\"props\" value=\"${dict(a=1, b=2, c=3)}\"/>\n", "<xacro:property name=\"numbers\" value=\"${[1,2,3,4]}\"/>", "<xacro:property name=\"yaml_file\" value=\"$(find package)/config/props.yaml\" />\n", "<xacro:property name=\"props\" value=\"${load_yaml(yaml_file)}\"/>", "val1: 10\n", "val2: 20", "<xacro:property name=\"val1\" value=\"${props['val1']}\" />", "# Generate .world files from .world.xacro files\n", "find_package(xacro REQUIRED)\n", "# You can also add xacro to the list of catkin packages:\n", "#   find_package(catkin REQUIRED COMPONENTS ... xacro)\n", "\n", "# Xacro files\n", "file(GLOB xacro_files ${CMAKE_CURRENT_SOURCE_DIR}/worlds/*.world.xacro)\n", "\n", "foreach(it ${xacro_files})\n", "  # remove .xacro extension\n", "  string(REGEX MATCH \"(.*)[.]xacro$\" unused ${it})\n", "  set(output_filename ${CMAKE_MATCH_1})\n", "\n", "  # create a rule to generate ${output_filename} from {it}\n", "  xacro_add_xacro_file(${it} ${output_filename})\n", "\n", "  list(APPEND world_files ${output_filename})\n", "endforeach(it)\n", "\n", "# add an abstract target to actually trigger the builds\n", "add_custom_target(media_files ALL DEPENDS ${world_files})", "file(GLOB xacro_files worlds/*.world.xacro)\n", "xacro_add_files(${xacro_files} TARGET media_files)", "<xacro:element xacro:name=\"${element_name}\" [other attributes]>\n", " [content]\n", "</xacro:element>\n", "<xacro:attribute name=\"${attribute_name}\" value=\"${attribute_value}\"/>", "<xacro:property name=\"foo\" value=\"my_attribute_name\"/>\n", "<tag>\n", "    <xacro:attribute name=\"${foo}\" value=\"my_attribute_value\"/>\n", "</tag>", "<tag my_attribute_name=\"my_attribute_value\" />", "rosrun xacro xacro file.xacro > /tmp/old.xml\n", "rosrun xacro xacro --inorder file.xacro > /tmp/new.xml\n", "diff /tmp/old.xml /tmp/new.xml", "Document is incompatible to --inorder processing.\n", "The following properties were redefined after usage:\n", "foo redefined in issues.xacro", "find . -iname \"*.xacro\" | xargs sed -i 's#<\\([/]\\?\\)\\(if\\|unless\\|include\\|arg\\|property\\|macro\\|insert_block\\)#<\\1xacro:\\2#g'"]},
{"url": "https://wiki.ros.org/mrpt_rawlog", "package": "mrpt_rawlog", "package_summary": ["This package enables you to record a rawlog from a ROS drive robot.\n  At the moment the package is able to deal with odometry and 2d laser scans."], "package_details": ["\n", "\n", "\n", "\n", "See ", " online. ", "See ", " online. "], "package_tt": ["mrpt_rawlog/rawlog_record_node", "mrpt_rawlog/rawlog_play_node", "rosbag\u00a0play", "rawlog_play_node", "rosbag\u00a0play", "tf", "~base_frame", "string", "\"base_link\"", "map", "odom", "rawlog_record_node", "rosbag\u00a0record", "tf", "~raw_log_folder", "string", "\"~/\""], "package_code": ["roslaunch mrpt_rawlog demo_play.launch", "roslaunch mrpt_rawlog demo_record.launch"]},
{"url": "https://wiki.ros.org/yocs_cmd_vel_mux", "package": "yocs_cmd_vel_mux", "package_summary": ["A multiplexer for command velocity inputs. Arbitrates incoming cmd_vel messages from several topics,\n     allowing one topic at a time to command the robot, based on priorities. It also deallocates current\n     allowed topic if no messages are received after a configured timeout. All topics, together with their\n     priority and timeout are configured through a YAML file, that can be reload at runtime.", "Contents", " ", "\n", "\n", "\n", "We configure the Command Velocity Multiplexer with a YAML file. We reproduce here the example file that comes with the sources: ", "As you can see, for every input we must specify 4 parameters: ", "The last line gives the name for the output topic. ", "\n", "Take a look to the ", " to learn how cmd_vel_mux works together with other components to build up a safe and flexible control system. "], "package_details": [" "], "package_tt": ["~input/cmd_vel", "~output/cmd_vel", "~active", "~yaml_cfg_file", "string", "~input/cmd_vel", "~output/cmd_vel", "~active", "~yaml_cfg_file", "string", "~input/cmd_vel", "~output/cmd_vel", "~active", "~yaml_cfg_file", "string"], "package_code": ["subscribers:\n", "  - name:        \"Default input\"\n", "    topic:       \"input/default\"\n", "    timeout:     0.1\n", "    priority:    0\n", "    short_desc:  \"The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here\"\n", "  - name:        \"Navigation stack\"\n", "    topic:       \"input/navigation\"\n", "    timeout:     0.5\n", "    priority:    1\n", "    short_desc:  \"Navigation stack controller\"\n", "\n", "    ...\n", "\n", "  - name:        \"Web application\"\n", "    topic:       \"input/webapp\"\n", "    timeout:     0.3\n", "    priority:    8\n", "  - name:        \"Keyboard operation\"\n", "    topic:       \"input/keyop\"\n", "    timeout:     0.1\n", "    priority:    7\n", "publisher:       \"output/cmd_vel\"", "subscribers:\n", "  - name:        \"Default input\"\n", "    topic:       \"input/default\"\n", "    timeout:     0.1\n", "    priority:    0\n", "    short_desc:  \"The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here\"\n", "  - name:        \"Navigation stack\"\n", "    topic:       \"input/navigation\"\n", "    timeout:     0.5\n", "    priority:    1\n", "    short_desc:  \"Navigation stack controller\"\n", "\n", "    ...\n", "\n", "  - name:        \"Web application\"\n", "    topic:       \"input/webapp\"\n", "    timeout:     0.3\n", "    priority:    8\n", "  - name:        \"Keyboard operation\"\n", "    topic:       \"input/keyop\"\n", "    timeout:     0.1\n", "    priority:    7\n", "publisher:       \"output/cmd_vel\"", "subscribers:\n", "  - name:        \"Default input\"\n", "    topic:       \"input/default\"\n", "    timeout:     0.1\n", "    priority:    0\n", "    short_desc:  \"The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here\"\n", "  - name:        \"Navigation stack\"\n", "    topic:       \"input/navigation\"\n", "    timeout:     0.5\n", "    priority:    1\n", "    short_desc:  \"Navigation stack controller\"\n", "\n", "    ...\n", "\n", "  - name:        \"Web application\"\n", "    topic:       \"input/webapp\"\n", "    timeout:     0.3\n", "    priority:    8\n", "  - name:        \"Keyboard operation\"\n", "    topic:       \"input/keyop\"\n", "    timeout:     0.1\n", "    priority:    7\n", "publisher:       \"output/cmd_vel\""]},
{"url": "https://wiki.ros.org/mbf_utility", "package": "mbf_utility", "package_summary": ["The mbf_utility package"]},
{"url": "https://wiki.ros.org/voice_text", "package": "voice_text", "package_summary": ["voice_text (www.voicetext.jp)"]},
{"url": "https://wiki.ros.org/checkerboard_detector", "package": "checkerboard_detector", "package_summary": ["Uses opencv to find checkboards and compute their 6D poses with respect to the image. Requires the image to be calibrated.", "\n    Parameters:", "\n    "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/sophus", "package": "sophus", "package_summary": ["C++ implementation of Lie Groups using Eigen."], "package_details": ["\n", "\n", " ", " ", "\n", "This is a ros 3rd party package that provides Hauke Strasdat's ", " library.  ", "See the ", ". "], "package_code": ["$ sudo apt-get install ros-kinetic-sophus", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/turtlebot_gazebo", "package": "turtlebot_gazebo", "package_summary": ["Gazebo launchers and worlds for TurtleBot simulation"], "package_code": ["$ sudo apt-get install ros-indigo-turtlebot-gazebo", "$ source /opt/ros/indigo/setup.bash\n", "$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch"]},
{"url": "https://wiki.ros.org/phidgets_drivers", "package": "phidgets_drivers", "package_summary": ["API and ROS drivers for Phidgets devices"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "Please see the ", " documentation for an example on how to implement new types of Phidgets. ", "For installing from source, it is best to follow the instructions in the README.md file in the ", ". "], "package_tt": ["Phidget"], "package_code": ["\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/libcmt", "package": "libcmt", "package_summary": ["libCMT ROS Wrapper"]},
{"url": "https://wiki.ros.org/pi_tracker", "package": "pi_tracker", "package_summary": ["\n\n    Skeleton Tracker Teleop Package for the Pi Robot Project\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Tracker command requires one or more services from each node it commands.  In its current form, the tracker command node sends simple string commands to control nodes via their ", " service.  For example, sending the command \"STOP\" to the ", " node (see below) tells the base to stop moving. "], "package_tt": ["skeleton_tracker", "/skeleton", "tracker_command", "/skeleton", "tracker_base_controller", "/skeleton", "/cmd_vel", "tracker_joint_controller", "/skeleton", "/cmd_joints", "/skeleton", "~tracking_rate", "int", "~fixed_frame", "string", "fixed_frame", "head", "fixed_frame", "neck", "fixed_frame", "torso", "fixed_frame", "left_shoulder", "fixed_frame", "left_elbow", "fixed_frame", "left_hand", "fixed_frame", "right_shoulder", "fixed_frame", "right\u00a0elbow", "fixed_frame", "right_hand", "fixed_frame", "left_hip", "fixed_frame", "left_knee", "fixed_frame", "left_foot", "fixed_frame", "right_hip", "fixed_frame", "right_knee", "fixed_frame", "right_foot", "/skeleton", "~command_rate", "int", "set_command", "tracker_base_controller", "/skeleton", "/cmd_vel", "~set_command", "~base_controller_rate", "int", "~max_drive_speed", "double", "~maximum_rotation_speed", "double", "~base_control_side", "string", "~scale_drive_speed", "double", "~scale_rotation_speed", "double", "~holonomic", "boolean", "tracker_base_controller", "x", "y", "Twist", "/skeleton", "/cmd_joints", "~set_command", "~joint_controller_rate", "int", "~default_joint_speed", "double", "~use_real_robot", "boolean", "/joint_state", "~skel_to_joint_map", "dict"], "package_code": ["<launch>\n", "  <arg name=\"fixed_frame\" value=\"camera_depth_frame\" />\n", " \n", "  <param name=\"/use_sim_time\" value=\"False\" />\n", " \n", "\n", "  <arg name=\"debug\" value=\"False\" />\n", "  <arg name=\"launch_prefix\" value=\"xterm -e gdb --args\" />\n", " \n", "  <param name=\"robot_description\" command=\"$(find xacro)/xacro.py '$(find pi_tracker)/urdf/pi_robot/pi_robot_with_two_arms.xacro'\" />\n", " \n", "  <node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"state_publisher\">\n", "    <param name=\"publish_frequency\" value=\"20.0\"/>\n", "  </node>\n", "    \n", "  <include file=\"$(find rgbd_launch)/launch/kinect_frames.launch\" />\n", "\n", "  <group if=\"$(arg debug)\">\n", "    <node launch-prefix=\"$(arg launch_prefix)\" pkg=\"skeleton_markers\" name=\"skeleton_tracker\" type=\"skeleton_tracker\" output=\"screen\"    >\n", "      <param name=\"fixed_frame\" value=\"$(arg fixed_frame)\" />\n", "      <param name=\"load_filepath\" value=\"$(find pi_tracker)/params/SamplesConfigNewOpenNI.xml\" />\n", "    </node>\n", "  </group>\n", "  <group unless=\"$(arg debug)\">\n", "    <node name=\"skeleton_tracker\" pkg=\"skeleton_markers\" type=\"skeleton_tracker\">\n", "      <param name=\"fixed_frame\" value=\"$(arg fixed_frame)\" />\n", "      <param name=\"load_filepath\" value=\"$(find pi_tracker)/params/SamplesConfigNewOpenNI.xml\" />\n", "    </node>\n", "  </group>\n", "</launch>", "<launch>\n", "    <node name=\"tracker_command\" pkg=\"pi_tracker\" type=\"tracker_command.py\" output=\"screen\">\n", "        <rosparam command=\"load\" file=\"$(find pi_tracker)/params/tracker_params.yaml\" />\n", "    </node>\n", "    <node name=\"tracker_base_controller\" pkg=\"pi_tracker\" type=\"tracker_base_controller.py\" output=\"screen\">\n", "        <rosparam command=\"load\" file=\"$(find pi_tracker)/params/tracker_params.yaml\" />\n", "    </node>\n", "    <node name=\"tracker_joint_controller\" pkg=\"pi_tracker\" type=\"tracker_joint_controller.py\" output=\"screen\">\n", "        <rosparam command=\"load\" file=\"$(find pi_tracker)/params/tracker_params.yaml\" />\n", "    </node>\n", "</launch>", "command_rate: 2\n", "tracking_rate: 2\n", "base_controller_rate: 2\n", "joint_controller_rate: 2\n", "default_joint_speed: 0.6\n", "max_drive_speed: 0.3\n", "max_rotation_speed: 0.3\n", "base_control_side: right\n", "\n", "use_real_robot: True\n", "\n", "# Use these values for a typical non-holonomic robot.\n", "scale_drive_speed: 1.0\n", "scale_rotation_speed: 1.0\n", "reverse_rotation: False\n", "holonomic: False\n", "\n", "# Use the following scale factors for the Rovio.\n", "#scale_drive_speed: 4.0\n", "#scale_rotation_speed: 0.4\n", "#reverse_rotation: True\n", "#holonomic: True\n", "\n", "fixed_frame: openni_depth\n", "\n", "skel_to_joint_map: {\n", "   head: head_pan_joint,\n", "   neck: head_tilt_joint,\n", "   torso: torso_joint,\n", "   left_shoulder: left_shoulder_lift_joint,\n", "   left_elbow: left_elbow_joint,\n", "   left_hand: left_hand_joint,\n", "   right_shoulder: right_shoulder_joint,\n", "   right_elbow: right_elbow_joint,\n", "   right_hand: right_hand_joint,\n", "   left_hip: no_joint,\n", "   left_knee: no_joint,\n", "   left_foot: no_joint,\n", "   right_hip: no_joint,\n", "   right_knee: no_joint,\n", "   right_foot: no_joint\n", "}"]},
{"url": "https://wiki.ros.org/rqt_web", "package": "rqt_web", "package_summary": ["rqt_web is a simple web content viewer for rqt. Users can show web content in Qt-based window by specifying its URL."]},
{"url": "https://wiki.ros.org/rc_dynamics_api", "package": "rc_dynamics_api", "package_summary": ["The rc_dynamics_api provides an API for easy handling of the dynamic-state data\n      streams provided by Roboception's stereo camera with self-localization.\n      See http://rc-visard.com\n\n      Dynamic-state estimates of the rc_visard relate to its self-localization and\n      ego-motion estimation. These states refer to rc_visard's current pose,\n      velocity, or acceleration and are published on demand via several data streams.\n      For a complete list and descriptions of these dynamics states and the\n      respective data streams please refer to rc_visard's user manual."], "package_details": ["\n", "\n", "\n"], "package_code": ["./tools/rcdynamics_stream -v 10.0.2.99 -s imu", "./tools/rcdynamics_stream -v 10.0.2.99 -s pose_rt -i eth0 -a -t10 -o poses.csv"]},
{"url": "https://wiki.ros.org/webkit_dependency", "package": "webkit_dependency", "package_summary": ["This encapsulates the WebKit dependency for a specific ROS distribution and its Qt version"]},
{"url": "https://wiki.ros.org/jsk_teleop_joy", "package": "jsk_teleop_joy", "package_summary": ["jsk_teleop_joy"]},
{"url": "https://wiki.ros.org/urdfdom_py", "package": "urdfdom_py", "package_summary": ["Python implementation of the URDF parser."], "package_details": ["\n", "\n", " presently has its own package page, which redirects here. ", "\n", " ", "The ", " package provides the ", " Python module providing both functions to parse an URDF model from a file or the parameter server and Python classes mapping the URDF information to a Python structure. ", "The ", " script allows the user to display the parsing result. It can be used either with a path to an URDF file (i.e. ", ") or without any argument. In this case, it connects to the parameter server to retrieve the robot configuration. ", "This package comes from the following prior packages: ", ", ", ", ", ", and ", ". ", "Once you have retrieved the ", " object, please consult the package Python API to know how to browse the structure. "], "package_tt": ["urdfdom_py", "urdf_parser_py", "display_urdf", "rosrun\u00a0urdf_parser_py\u00a0display_urdf\u00a0/tmp/robot.urdf", "robot"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/laser_assembler", "package": "laser_assembler", "package_summary": ["Provides nodes to assemble point clouds from either LaserScan or PointCloud messages"], "package_details": ["\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "Laser Rangefinder sensors (such as Hokuyo's ", ") generally output a stream of scans, where each scan is a set of range readings of detected objects (in polar coordinates) in the plane of the sensor. ", "Many robotic systems, like PR2's tilting laser platform, articulate a laser rangefinder in order to get a 3D view of the world. The ", " package provides nodes that listen to streams of scans and then assemble them into a larger 3D Cartesian coordinate (XYZ) point cloud. ", "The ROS API of this package is considered stable. We don't foresee making any large changes to ", " anytime soon. ", "The ", " subscribes to ", " messages on the ", " topic.  These scans are processed by the Projector and Transformer, which project the scan into Cartesian space and then transform it into the ", ". This results in a ", " that can be added to the rolling buffer. Clouds in the rolling buffer are then assembled on service calls. ", "Note that the Transformer automatically receives ", " data without any user intervention. ", "The ", " looks very similar to the ", ", except that the projection step is skipped, since the input clouds are already in Cartesian coordinates. ", "The main interaction with the assemblers is via ROS services. The ", " and ", " both provide the ", " service, which is documented below. ", "NOTE: For laser_pipeline releases < 0.5.0, this service is called ", ". ", "Launch an assembler operating on ", " ", " messages in the base_link frame, with a buffer of 400 scans.", " ", "Launch an assembler operating on ", " ", " messages in the ", " frame, with a buffer of 400 scans. ", "As of laser_pipeline 0.4.0. A large part of the laser_assembler's ROS API was deprecated. The API reference for the deprecated API is available on the ", " page. "], "package_tt": ["laser_assembler", "laser_scan_assembler", "point_cloud_assembler", "laser_assembler", "laser_scan_assembler", "scan", "fixed_frame", "point_cloud_assembler", "laser_scan_assembler", "laser_scan_assembler", "point_cloud_assembler", "assemble_scans", "build_cloud", "scan", "assemble_scans", "assemble_scans", "begin", "end", "~fixed_frame", "intensities", "index", "distances", "stamps", "assemble_scans2", "~fixed_frame", "string", "~tf_cache_time_secs", "double", "~max_scans", "int", "~ignore_laser_skew", "bool", "true", "cloud", "assemble_scans", "assemble_scans", "begin", "end", "~fixed_frame", "~fixed_frame", "string", "~tf_cache_time_secs", "double", "~max_clouds", "int", "tilt_scan", "my_cloud_in", "base_link"], "package_code": ["<launch>\n", "  <node type=\"laser_scan_assembler\" pkg=\"laser_assembler\"\n", "        name=\"my_assembler\">\n", "    <remap from=\"scan\" to=\"tilt_scan\"/>\n", "    <param name=\"max_scans\" type=\"int\" value=\"400\" />\n", "    <param name=\"fixed_frame\" type=\"string\" value=\"base_link\" />\n", "  </node>\n", "</launch>", "<launch>\n", "  <node type=\"point_cloud_assembler\" pkg=\"laser_assembler\"\n", "        name=\"my_assembler\">\n", "    <remap from=\"cloud\" to=\"my_cloud_in\"/>\n", "    <param name=\"max_clouds\" type=\"int\" value=\"400\" />\n", "    <param name=\"fixed_frame\" type=\"string\" value=\"base_link\" />\n", "  </node>\n", "</launch>", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/safe_teleop_pr2", "package": "safe_teleop_pr2", "package_summary": ["Launch files for running safe_teleop_base on pr2"]},
{"url": "https://wiki.ros.org/position_controllers", "package": "position_controllers", "package_summary": ["position_controllers"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/joint_trajectory_action", "package": "joint_trajectory_action", "package_summary": ["The joint_trajectory_action is a node that exposes an action interface\n     to a joint trajectory controller."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "See: ", " ", "The joint trajectory action provides an action server (see ", ") that takes in goals of the type ", ". ", "You can find an example of using the joint trajectory action in ", " for moving the arm on the PR2. "], "package_tt": ["joints", "Array\u00a0of\u00a0strings", "constraints/goal_time", "double", "constraints/<joint>/goal", "double", "constraints/<joint>/trajectory", "double", "constraints/stopped_velocity_tolerance", "double", "joint_trajectory_action/goal", "joint_trajectory_action/cancel", "joint_trajectory_action/feedback", "joint_trajectory_action/status", "joint_trajectory_action/result", "state", "command"], "package_code": ["joint_trajectory_action_node:\n", "  joints:\n", "    - r_shoulder_pan_joint\n", "    - r_shoulder_lift_joint\n", "    - r_upper_arm_roll_joint\n", "    - r_elbow_flex_joint\n", "    - r_forearm_roll_joint\n", "    - r_wrist_flex_joint\n", "    - r_wrist_roll_joint\n", "  constraints:\n", "    goal_time: 0.3\n", "    r_shoulder_pan_joint:\n", "      goal: 0.04\n", "    r_shoulder_lift_joint:\n", "      goal: 0.04\n", "    r_upper_arm_roll_joint:\n", "      goal: 0.04\n", "    r_elbow_flex_joint:\n", "      goal: 0.04\n", "    r_forearm_roll_joint:\n", "      goal: 0.04\n", "    r_wrist_flex_joint:\n", "      goal: 0.04\n", "    r_wrist_roll_joint:\n", "      goal: 0.04"]},
{"url": "https://wiki.ros.org/moveit_core", "package": "moveit_core", "package_summary": ["Core libraries used by MoveIt!"]},
{"url": "https://wiki.ros.org/rqt_top", "package": "rqt_top", "package_summary": ["RQT plugin for monitoring ROS processes."], "package_details": ["\n", "Originally made as ", ". "]},
{"url": "https://wiki.ros.org/yocs_joyop", "package": "yocs_joyop", "package_summary": ["Joystick teleoperation for your robot robot core"]},
{"url": "https://wiki.ros.org/rospy_message_converter", "package": "rospy_message_converter", "package_summary": ["Converts between Python dictionaries and JSON to rospy messages."], "package_details": ["\n", "Check out the ", " for examples. "]},
{"url": "https://wiki.ros.org/pilz_testutils", "package": "pilz_testutils", "package_summary": ["This package contains testing utilities used by Pilz packages."], "package_details": ["\n", "For package documentation please see the ", ". "]},
{"url": "https://wiki.ros.org/libpointmatcher", "package": "libpointmatcher", "package_summary": ["\n\n     Fetches libpointmatcher through git submodule and makes it available to ROS\n\n  "], "package_details": ["\n", "Tutorials on how to use libpointmatcher can be found ", ". "]},
{"url": "https://wiki.ros.org/nlopt", "package": "nlopt", "package_summary": ["nlopt"]},
{"url": "https://wiki.ros.org/rosapi", "package": "rosapi", "package_summary": ["Provides service calls for getting ros meta-information, like list of\n    topics, services, params, etc."]},
{"url": "https://wiki.ros.org/roslisp_common", "package": "roslisp_common", "package_summary": ["Common libraries to control ROS based robots. This stack contains\n    an implementation of actionlib (client and server) in Common Lisp,\n    a transformation library and an implementation of tf in Common\n    Lisp."], "package_details": ["\n", "\n", "  ", "Contains commonly used libraries for ", ", including Lisp implementations of ", " and ", ". "]},
{"url": "https://wiki.ros.org/lanelet2_examples", "package": "lanelet2_examples", "package_summary": ["Examples for working with Lanelet2"]},
{"url": "https://wiki.ros.org/lanelet2_python", "package": "lanelet2_python", "package_summary": ["Python bindings for lanelet2"]},
{"url": "https://wiki.ros.org/ackermann_steering_controller", "package": "ackermann_steering_controller", "package_summary": ["Controller for a steer drive mobile base."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 50.0) ", "\n", " (", ", default: base_link) ", "\n", " (", ", default: 1.0) ", "\n", " (", ", default: false) ", "\n", " (", ") ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "An example of using the packages can be seen in ", ". ", "The controller inherits ", " to work with wheel joints through a ", " interface for a linear wheel and a ", " interface for a front steer wheel, which is the the most basic configuration for the ackermann steering driving mechanism. ", "If you want ", " to show states of robot's actual joint interfaces' ", " through ", " and ", ", you need to convert the two interfaces of ", " to your robot's specific ones via ", " or RobotHWSim (generally used for ", "). This is because the controller only update it's basic interfaces mentioned in the previous section. ", "The controller main input is a ", " topic in the namespace of the controller. ", "An example for usage of ", " with ", " can be grabbed from ", ". ", "We developped a general RobotHWSim plugin for usage of ", ". You can get the plugin from ", " and also see an example of application on ", ". ", "We also provide a recovery behavior plugin of ", " specifically desigined for ackermann steering mechanism base robots in ", ". Feel free to see ", " to learn how to use it. "], "package_tt": ["ackermann_steering_controller", "cmd_vel", "odom", "/tf", "rear_wheel", "string", "front_steer", "string", "pose_covariance_diagonal", "double[6]", "twist_covariance_diagonal", "double[6]", "publish_rate", "double", "cmd_vel_timeout", "double", "base_frame_id", "string", "odom_frame_id", "string", "enable_odom_tf", "bool", "wheel_separation_h_multiplier", "double", "wheel_radius_multiplier", "double", "steer_pos_multiplier", "double", "linear/x/has_velocity_limits", "bool", "linear/x/max_velocity", "double", "linear/x/min_velocity", "double", "linear/x/has_acceleration_limits", "bool", "linear/x/max_acceleration", "double", "linear/x/min_acceleration", "double", "linear/x/has_jerk_limits", "bool", "linear/x/max_jerk", "double", "angular/z/has_velocity_limits", "bool", "angular/z/max_velocity", "double", "angular/z/min_velocity", "double", "angular/z/has_acceleration_limits", "bool", "angular/z/max_acceleration", "double", "angular/z/min_acceleration", "double", "angular/z/has_jerk_limits", "bool", "angular/z/max_jerk", "double", "wheel_separation_h", "double", "wheel_radius", "double", "ackermann_steering_controller"], "package_code": ["mobile_base_controller:\n", "  type: \"ackermann_steering_controller/AckermannSteeringController\"\n", "  rear_wheel: 'rear_wheel_joint'\n", "  front_steer: 'front_steer_joint'\n", "  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]", "mobile_base_controller:\n", "  type        : \"ackermann_steering_controller/AckermannSteeringController\"\n", "  rear_wheel: 'rear_wheel_joint'\n", "  front_steer: 'front_steer_joint'\n", "  publish_rate: 50.0               # default: 50\n", "  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "\n", "  # Wheel separation between the rear and the front, and diameter of the rear. \n", "  # These are both optional.\n", "  # ackermann_steering_controller will attempt to read either one or both from the\n", "  # URDF if not specified as a parameter.\n", "  wheel_separation_h : 1.0\n", "  wheel_radius : 0.3\n", "\n", "  # Wheel separation and radius multipliers for odometry calibration.\n", "  wheel_separation_h_multiplier: 1.0 # default: 1.0\n", "  wheel_radius_multiplier    : 1.0 # default: 1.0\n", "\n", "  # Steer position angle multipliers for fine tuning.\n", "  steer_pos_multiplier       : 1.0\n", "\n", "  # Velocity commands timeout [s], default 0.5\n", "  cmd_vel_timeout: 0.25\n", "\n", "  # Base frame_id\n", "  base_frame_id: base_footprint #default: base_link\n", "\n", "  # Odom frame_id\n", "  odom_frame_id: odom\n", "\n", "  # Velocity and acceleration limits\n", "  # Whenever a min_* is unspecified, default to -max_*\n", "  linear:\n", "    x:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.0  # m/s\n", "      min_velocity           : -0.5 # m/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 0.8  # m/s^2\n", "      min_acceleration       : -0.4 # m/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 5.0 # m/s^3\n", "\n", "  angular:\n", "    z:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.7  # rad/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 1.5  # rad/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 2.5 # rad/s^3"]},
{"url": "https://wiki.ros.org/opt_camera", "package": "opt_camera", "package_summary": ["opt_camera"]},
{"url": "https://wiki.ros.org/pilz_industrial_motion", "package": "pilz_industrial_motion", "package_summary": ["The pilz_industrial_motion package"], "package_details": ["\n", "\n", "For package documentation please see the ", ". "]},
{"url": "https://wiki.ros.org/interactive_markers", "package": "interactive_markers", "package_summary": ["3D interactive marker communication library for RViz and similar tools."], "package_details": ["\n", " ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The tutorials can be found in ", ". For an overview an further links, see ", ". ", "An app that uses interactive markers for controlling the PR2 is ", ". "]},
{"url": "https://wiki.ros.org/mrpt_icp_slam_2d", "package": "mrpt_icp_slam_2d", "package_summary": ["mrpt_icp_slam_2d contains a wrapper on MRPT's 2D ICP-SLAM algorithms."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The sections below describe the API of this package which allows ICP-based SLAM in 2D ", ". ", "The SLAM algorithm is a simple ", " using ICP to align 2D laser scans to the map, which can be either a ", " or an  ", ". [For now, only point maps] ", "Using this technique allows building ", ", as long as errors do not grow excessively before closing any long loop. Building larger maps requires more advanced SLAM techniques. However, this simple icp-slam algorithm is an efficient and well-tested method which suffices for many practical situations. ", "The ROS node ", " is a wrapper for the C++ class ", ",  part of MRPT. Thus, check out the documentation of that class for further  details. ", "This node has been designed to provide an interface similar to that of ", "  for the convenience of users which already knew that package. ", "For the convention on coordinate frames see ", ". ", "Using ", " requires a horizontally-mounted, fixed, laser range-finder. Odometry is optional. ", "The ", " node will attempt to transform each incoming scan  into the ", " (odometry) ", " frame.  See the \"", "\"  for more on required transforms. ", "In order to use mrpt_icp_slam_2d package it is necessary to install the last ", " build and the", "(see also the ", ") . "], "package_tt": ["mrpt_icp_slam_2d", "mrpt_icp_slam_2d", "mrpt_icp_slam_2d", "odom", "mrpt_icp_slam_2d", "tf", "scan", "PointCloudMap", "map", "robot_pose", "~global_frame_id", "string", "\"map\"", "~base_frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~sensor_source", "string", "\"scan\"", "\"scan\"", "~ini_filename", "string", "~rawlog_filename", "string", "~rawlog_play_delay", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["roslaunch mrpt_icp_slam_2d icp_slam.launch", "roslaunch mrpt_icp_slam_2d icp_slam_rawlog.launch"]},
{"url": "https://wiki.ros.org/tts", "package": "tts", "package_summary": ["Package enabling a robot to speak with a human voice by providing a Text-To-Speech ROS service"], "package_details": ["\n", ": Amazon Polly is a service that turns text into lifelike speech, allowing you to create applications that talk, ", "and build entirely new categories of speech-enabled products. Amazon Polly is a Text-to-Speech service that uses advanced deep learning technologies to synthesize speech that sounds like a human voice. ", "With dozens of lifelike voices across a variety of languages, you can select the ideal voice and build speech-enabled applications that work in many different countries. ", ": ", "\n", "\n", "The ", " ROS node enables a robot to speak with a human voice by providing a Text-To-Speech service. ", "Out of the box this package listens to a speech topic, submits text to the Amazon Polly cloud service to generate an audio stream file, ", "retrieves the audio stream from Amazon Polly, and plays the audio stream via the default output device. ", "The nodes can be configured to use different voices as well as custom lexicons and SSML tags which enable you to control aspects of speech, ", "such as pronunciation, volume, pitch, speed rate, etc. A ", " with this node, ", "and more details on speech customization are available within the ", ". ", "The source code is released under an ", ". "], "package_tt": ["tts"]},
{"url": "https://wiki.ros.org/yocs_math_toolkit", "package": "yocs_math_toolkit", "package_summary": ["Math toolkit for Yujin open control system. This package is intended to contain common use functions,\n    mostly for simple mathematics but also for tf-related conversions.\n    By no means it pretends to be an efficient and robust, widely used math library, but a play ground where\n    to put common code that is typically repeated in many robot control programs."], "package_details": [" "]},
{"url": "https://wiki.ros.org/jsk_pr2eus", "package": "jsk_pr2eus", "package_summary": ["Metapackage that contains robot eus client package for jsk-ros-pkg"]},
{"url": "https://wiki.ros.org/skeleton_markers", "package": "skeleton_markers", "package_summary": ["\n    Skeleton Markers: Publish a list of joint markers for viewing in RViz\n  ", "Display the skeleton joints returned by the ", " package (or using the skeleton_tracker node included in this package) as markers in RViz.  This package contains two nodes for reading the tracked skeleton in two different ways:  the ", " node subscribes to the Skeleton message topic returned by the skeleton_tracker node included in the package.  The ", " node can read the transforms directly from the ", " package or the included skeleton_tracker node. ", "\n", "\n", "\n", "Use the ", " file: ", "Note: use the ", " RViz configuration file. ", "Note: use the ", " RViz configuration file. "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "To make this package work with ROS Indigo, you will need the Kinect drivers for Ubuntu 14.04.  The following instructions were taken from ", ".  The steps below are for a 64-bit system.  Use the 32-bit files for a 32-bit system. ", "Use the ", " file: "], "package_tt": ["/skeleton", "/skeleton_markers", "~fixed_frame", "str", "~rate", "int", "~scale", "float", "~lifetime", "float", "~ns", "str", "~id", "int", "~color", "dictionary", "/skeleton", "/skeleton_markers", "~fixed_frame", "str", "~rate", "int", "~scale", "float", "~lifetime", "float", "~ns", "str", "~id", "int", "~color", "dictionary", "/skeleton_markers", "~fixed_frame", "str", "~rate", "int", "~scale", "float", "~lifetime", "float", "~ns", "str", "~id", "int", "~color", "dictionary", "~tf_prefix", "str"], "package_code": [" $ mkdir ~/src\n", " $ cd ~/src\n", " $ git clone https://github.com/avin2/SensorKinect\n", " $ cd SensorKinect/Bin\n", " $ tar xjf SensorKinect093-Bin-Linux-x64-v5.1.2.1.tar.bz2\n", " $ cd Sensor-Bin-Linux-x64-v5.1.2.1\n", " $ sudo ./install.sh", "$ cd ~/ros_workspace (change to match your rosbuild workspace directory)\n", "$ svn co http://pi-robot-ros-pkg.googlecode.com/svn/trunk/skeleton_markers\n", "$ cd skeleton_markers\n", "$ rosmake", "$ cd ~/ros_workspace (change to match your rosbuild workspace directory)\n", "$ git clone https://github.com/pirobot/skeleton_markers.git\n", "$ cd skeleton_markers\n", "$ git checkout groovy-devel\n", "$ rosmake", "$ cd ~/catkin_ws/src (change to match your catkin workspace directory)\n", "$ git clone -b hydro-devel https://github.com/pirobot/skeleton_markers.git\n", "$ cd ~/catkin_ws\n", "$ catkin_make\n", "$ rospack profile", "$ roscd skeleton_markers\n", "$ rosrun rviz rviz -d markers.vcg\n", "$ roslaunch skeleton_markers markers.launch", "$ roscd skeleton_markers\n", "$ rosrun rviz rviz -d markers.rviz\n", "$ roslaunch skeleton_markers markers.launch", "$ roslaunch skeleton_markers markers_from_tf.launch\n", "$ roscd skeleton_markers\n", "$ rosrun rviz rviz -d markers_from_tf.vcg", "$ roslaunch skeleton_markers markers_from_tf.launch\n", "$ roscd skeleton_markers\n", "$ rosrun rviz rviz -d markers_from_tf.rviz", "<launch>\n", "  <include file=\"$(find skeleton_markers)/launch/skeleton.launch\" />\n", "\n", "  <node pkg=\"skeleton_markers\" name=\"skeleton_markers\" type=\"skeleton_markers.py\" output=\"screen\">\n", "    <rosparam file=\"$(find skeleton_markers)/params/marker_params.yaml\" command=\"load\" />\n", "  </node>\n", "</launch>", "<launch>\n", "  <include file=\"$(find skeleton_markers)/launch/skeleton.launch\" />\n", "\n", "  <node pkg=\"skeleton_markers\" name=\"skeleton_markers\" type=\"markers_from_skeleton_msg.py\" output=\"screen\">\n", "    <rosparam file=\"$(find skeleton_markers)/params/marker_params.yaml\" command=\"load\" />\n", "  </node>\n", "</launch>", "<launch>\n", "  <include file=\"$(find openni_camera)/launch/openni_node.launch\" />\n", "  \n", "  <node pkg=\"openni_tracker\" name=\"openni_tracker\" type=\"openni_tracker\" output=\"screen\">\n", "    <param name=\"tf_prefix\" value=\"skeleton\" />\n", "  </node>\n", "  \n", "  <node pkg=\"skeleton_markers\" name=\"skeleton_markers\" type=\"markers_from_tf.py\" output=\"screen\">\n", "    <rosparam file=\"$(find skeleton_markers)/params/marker_params.yaml\" command=\"load\" />\n", "  </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/joy_teleop", "package": "joy_teleop", "package_summary": ["A (to be) generic joystick interface to control a robot"], "package_details": ["\n", " takes the output of the ", ", and publishes topics or calls actions according to it's configuration. ", "An example of using ", " with TIAGo can be found on the video below. ", " ", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["joy_teleop", "joy_teleop", "~teleop", "array", "~joy"], "package_code": ["teleop:\n", "  move:\n", "    type: topic\n", "    message_type: geometry_msgs/Twist\n", "    topic_name: cmd_vel\n", "    axis_mappings:\n", "      -\n", "        axis: 1\n", "        target: linear.x\n", "        scale: 1.0\n", "      -\n", "        axis: 2\n", "        target: angular.z\n", "        scale: 1.0\n", "\n", "  joy_priority:\n", "    type: action\n", "    action_name: joy_priority_action\n", "    buttons: [9]\n", "\n", "  joy_turbo_decrease:\n", "    type: action\n", "    action_name: joy_turbo_decrease\n", "    buttons: [1, 4, 5]\n", "\n", "  joy_turbo_increase:\n", "    type: action\n", "    action_name: joy_turbo_increase\n", "    buttons: [3, 4, 5]\n", "\n", "  torso_up:\n", "    type: action\n", "    action_name: /torso_controller/increment\n", "    action_goal:\n", "      increment_by: [0.05]\n", "    buttons: [4] # right pad, top button\n", "\n", "  torso_down:\n", "    type: action\n", "    action_name: /torso_controller/increment\n", "    action_goal:\n", "      increment_by: [-0.05]\n", "    buttons: [6] # right pad, bottom button\n", "\n", "  close_hand:\n", "    type: action\n", "    action_name: /play_motion\n", "    action_goal:\n", "      motion_name: 'close_hand'\n", "      skip_planning: True\n", "    buttons: [7]"]},
{"url": "https://wiki.ros.org/rqt_pose_view", "package": "rqt_pose_view", "package_summary": ["rqt_pose_view provides a GUI plugin for visualizing 3D poses."], "package_details": [" ", " "]},
{"url": "https://wiki.ros.org/urdf_tutorial", "package": "urdf_tutorial", "package_summary": ["This package contains a number of URDF tutorials."], "package_details": ["\n", "This package is intended to be used in conjunction with the ", ". "]},
{"url": "https://wiki.ros.org/julius_ros", "package": "julius_ros", "package_summary": ["The julius_ros package"]},
{"url": "https://wiki.ros.org/moveit_ros_visualization", "package": "moveit_ros_visualization", "package_summary": ["Components of MoveIt! that offer visualization"]},
{"url": "https://wiki.ros.org/librealsense", "package": "librealsense", "package_summary": ["Library for capturing data from the Intel(R) RealSense(TM) F200, SR300, R200, LR200 and ZR300 cameras. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of RealSense(TM); devices are implemented in this project, including multi-camera capture."], "package_details": ["\n", " is a cross-platform library (Linux, OSX, Windows) for capturing data from the Intel\u00ae ", "\u2122 R200, F200, and SR300 cameras. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of ", "\u2122 devices are implemented in this project, including multi-camera capture. ", "\n", "\n", " requires patches to the ", " loadable kernel module to support various cameras. Intel\u00ae ", "\u2122 R200 camera support is upstreamed in the 4.4.x linux kernel, but older kernels and all other Intel\u00ae ", "\u2122 cameras require patches. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "  ", "\n", "  ", "\n", "\n", " ", "Developer kits containing the necessary hardware to use this library are ", ". This project is separate from the production software stack available in the ", ", namely that this library only encompasses camera capture functionality without additional computer vision algorithms. ", "Update your ", " file and/or ", " to uncomment (or add) the ", " entries for all of the entries for the ", " repositories. Below is an ", " for ubuntu 16.04 (Xenial). ", "The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS ", " packages. Please ", " concerning this package to the realsense_camera ", " Issues. ", "For updated details on this library see the ", ". "], "package_tt": ["librealsense", "librealsense", "uvcvideo", "/etc/apt/sources.list", "/etc/apt/sources.list.d/*.list", "deb-src", "main"], "package_code": ["wget -O enable_kernel_sources.sh https://raw.githubusercontent.com/IntelRealSense/librealsense/rosdebian/scripts/enable_kernel_sources.sh\n", "bash ./enable_kernel_sources.sh", "deb-src http://us.archive.ubuntu.com/ubuntu/ xenial main restricted\n", "deb-src http://us.archive.ubuntu.com/ubuntu/ xenial-updates main restricted\n", "deb-src http://us.archive.ubuntu.com/ubuntu/ xenial-backports main restricted universe multiverse\n", "deb-src http://security.ubuntu.com/ubuntu xenial-security main restricted", "sudo apt-get update", "sudo apt-get install linux-image-generic-lts-xenial\n", "sudo reboot", "sudo apt-get dist-upgrade", "sudo apt-get --reinstall install 'ros-*-librealsense'", "roslaunch realsense_camera [cam_type]_nodelet_[mode].launch", "sudo modprobe uvcvideo", "make KERNELRELEASE=4.4.0-43-generic -C /var/lib/dkms/uvcvideo/1.1.1-3-realsense/build/linux-src M=drivers/media/usb/uvc/....(bad exit status: 2)\n", "Error! Bad return status for module build on kernel: 4.4.0-43-generic (x86_64)", "dkms remove -m uvcvideo -v \"1.1.1-3-realsense\" --all"]},
{"url": "https://wiki.ros.org/sr_config", "package": "sr_config", "package_summary": ["sr_config"], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/pr2_self_test_msgs", "package": "pr2_self_test_msgs", "package_summary": ["Messages used in PR2 hardware testing."], "package_details": ["\n", "Messages/Services used by the ", " and ", " stacks. These messages are ", " and not API reviewed. "]},
{"url": "https://wiki.ros.org/kobuki_dock_drive", "package": "kobuki_dock_drive", "package_summary": ["Dock driving library for Kobuki. Users owning a docking station for Kobuki \n\t    can use this tool to develop autonomous docking drive algorithms."]},
{"url": "https://wiki.ros.org/random_numbers", "package": "random_numbers", "package_summary": ["This  library contains wrappers for generating floating point values, integers, quaternions using boost libraries.\n\n  The constructor of the wrapper is guaranteed to be thread safe and initialize its random number generator to a random seed.\n  Seeds are obtained using a separate and different random number generator."]},
{"url": "https://wiki.ros.org/moveit_fake_controller_manager", "package": "moveit_fake_controller_manager", "package_summary": ["A fake controller manager plugin for MoveIt."]},
{"url": "https://wiki.ros.org/turtlebot_simulator", "package": "turtlebot_simulator", "package_summary": ["Catkin metapackage for the turtlebot_simulator stack"], "package_code": ["$ sudo apt-get install ros-indigo-turtlebot-simulator", "$ sudo apt-get install ros-hydro-turtlebot-simulator", "$ source /opt/ros/hydro/setup.bash\n", "$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch", "$ sudo apt-get install ros-fuerte-turtlebot-simulator", "$ source /opt/ros/fuerte/setup.bash\n", "$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch"]},
{"url": "https://wiki.ros.org/jsk_robot", "package": "jsk_robot", "package_summary": ["Metapackage that contains robot packages for jsk-ros-pkg"]},
{"url": "https://wiki.ros.org/hardware_interface", "package": "hardware_interface", "package_summary": ["Hardware Interface base class."], "package_details": ["\n", "See the ", " page and the ", " for more information. "]},
{"url": "https://wiki.ros.org/phidgets_high_speed_encoder", "package": "phidgets_high_speed_encoder", "package_summary": ["Driver for the Phidgets high speed encoder devices"], "package_details": ["\n", "\n"], "package_tt": ["joint_states", "JointState", "joint_states_ch{0,1,2,3}_decim_speed", "EncoderDecimatedSpeed", "serial_name", "joint{0,1,2,3}_name", "name", "JointState", "joint{0,1,2,3}_tick2rad", "PUBLISH_RATE", "SPEED_FILTER_SAMPLES_LEN", "SPEED_FILTER_IDLE_ITER_LOOPS_BEFORE_RESET"], "package_code": ["\n"]},
{"url": "https://wiki.ros.org/nmea_msgs", "package": "nmea_msgs", "package_summary": ["The nmea_msgs package contains messages related to data in the NMEA format."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/jsk_network_tools", "package": "jsk_network_tools", "package_summary": ["jsk_network_tools"]},
{"url": "https://wiki.ros.org/jsk_roseus", "package": "jsk_roseus", "package_summary": ["Metapackage that contains roseus package for jsk-ros-pkg"]},
{"url": "https://wiki.ros.org/swri_console_util", "package": "swri_console_util", "package_summary": ["swri_console_util"]},
{"url": "https://wiki.ros.org/jackal_msgs", "package": "jackal_msgs", "package_summary": ["Messages exclusive to Jackal, especially for representing low-level motor commands and sensors."], "package_details": ["\n", "These messages are the low-level interface between ", "'s ARM MCU and integrated PC. Most users of Jackal should be able to use standard ROS interfaces (eg. ", ", ", ") to command and monitor the robot. Possible exceptions are: "]},
{"url": "https://wiki.ros.org/moveit_runtime", "package": "moveit_runtime", "package_summary": ["moveit_runtime meta package contains MoveIt! packages that are essential for its runtime (e.g. running MoveIt! on robots)."]},
{"url": "https://wiki.ros.org/moveit_ros_control_interface", "package": "moveit_ros_control_interface", "package_summary": ["ros_control controller manager interface for MoveIt!"]},
{"url": "https://wiki.ros.org/task_compiler", "package": "task_compiler", "package_summary": ["task_compiler Compiler that translate task description in PDDL (Planning Domain Description Language) to SMACH (state machine based execution and coordination system) description."]},
{"url": "https://wiki.ros.org/moveit_simple_controller_manager", "package": "moveit_simple_controller_manager", "package_summary": ["A generic, simple controller manager plugin for MoveIt."]},
{"url": "https://wiki.ros.org/pilz_extensions", "package": "pilz_extensions", "package_summary": ["The pilz_extensions package. Here are classes extending the functionality of other packages.\n  On the long run these extensions should become pull requests on the respective packages."]},
{"url": "https://wiki.ros.org/resized_image_transport", "package": "resized_image_transport", "package_summary": ["ROS nodes to publish resized images."]},
{"url": "https://wiki.ros.org/kinesis_video_msgs", "package": "kinesis_video_msgs", "package_summary": ["Messages for transmitting video frames to Kinesis Video Streams"]},
{"url": "https://wiki.ros.org/zeroconf_avahi_demos", "package": "zeroconf_avahi_demos", "package_summary": ["Several demos and launch-tests for the avahi based zero-configuration."], "package_details": ["\n", " for getting the launchers up and running with some scripts. ", " "]},
{"url": "https://wiki.ros.org/jsk_tilt_laser", "package": "jsk_tilt_laser", "package_summary": ["The jsk_tilt_laser package"]},
{"url": "https://wiki.ros.org/rqt_bag_plugins", "package": "rqt_bag_plugins", "package_summary": ["rqt_bag provides a GUI plugin for displaying and replaying ROS bag files."], "package_details": ["\n", " ", "\n", "\n", " ", "\n", " ", " ", "To access these plugins, launch the ", " GUI tool (see ", " for details), right-click on the timeline of the desired topic select a view type from the context menu. ", "The following plugins are currently provided for ", ": ", "The image view displays raw image data for ", " and ", " messages: ", "The plot view displays a time series plot of numeric fields in a ROS message. The view inherits from the ", " code base, so all plotting options are the same as with ", ". "], "package_tt": ["rqt_bag", "rqt_bag", "rqt_plot", "rqt_plot"]},
{"url": "https://wiki.ros.org/mbf_costmap_nav", "package": "mbf_costmap_nav", "package_summary": ["The mbf_costmap_nav package contains the costmap navigation server implementation of Move Base Flex (MBF). The costmap navigation server is bound to the ", " representation. It provides the Actions for planning, controlling and recovering. At the time of start MBF loads all defined plugins. Therefor, it loads all plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions. \n\n        Additionally the mbf_costmap_nav package comes with a wrapper for the old navigation stack and the plugins which inherits from the ", " base classes. Preferably it tries to load plugins for the new API. However, plugins could even support both ", " and ", " by inheriting both base class interfaces located in the ", " package and in the ", " package."]},
{"url": "https://wiki.ros.org/costmap_queue", "package": "costmap_queue", "package_summary": ["Tool for iterating through the cells of a costmap to find the closest distance to a subset of cells."], "package_details": [" "]},
{"url": "https://wiki.ros.org/prbt_support", "package": "prbt_support", "package_summary": ["Mechanical, kinematic and visual description\n  of the Pilz light weight arm PRBT."]},
{"url": "https://wiki.ros.org/lanelet2_validation", "package": "lanelet2_validation", "package_summary": ["Package for sanitizing lanelet maps"], "package_details": ["To test a map, simply run ", ", or better ", ", where lat/lon is an origin close to your map data. The tool will output errors and warnings that were found in your map. ", "For advanced usage like running only a fraction of the tests, try ", ". "], "package_tt": ["rosrun\u00a0lanelet_validation\u00a0lanelet2_validate\u00a0<mymap>", "rosrun\u00a0lanelet2_validation\u00a0lanelet2_validate\u00a0<mymap>\u00a0--lat\u00a0<lat>\u00a0--lon\u00a0<lon>", "rosrun\u00a0lanelet2_validation\u00a0lanelet2_validate\u00a0--help"]},
{"url": "https://wiki.ros.org/dynamic_tf_publisher", "package": "dynamic_tf_publisher", "package_summary": ["dynamically set the tf trensformation"]},
{"url": "https://wiki.ros.org/pr2_gripper_sensor_action", "package": "pr2_gripper_sensor_action", "package_summary": ["The pr2_gripper_sensor_action package provides an action interface for talking to the pr2_gripper_sensor_controller real-time controller.\n\n  It provides several different actions for getting high-level sensor information from the PR2 palm-mounted accelerometers, fingertip pressure arrays, and gripper motor/encoder, as well as several sensor-based gripper control actions that respond with low-latency in real-time."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Tactile feedback provides critical information for completing any sensitive manipulation task. Often this tactile feedback needs to be used for closed-loop control to obtain a responsive and reliable system. The package ", " achieves this by bypassing the ROS messaging system and integrating sensory feedback with gripper control in real-time. This ", " package is used to communicate with the ", " at a higher level, and allows the user to send target goals to the real-time controller. Currently this package provides several capabilities in the form of action servers including: ", "Below you can see a diagram of how these various action servers communicate with the real-time ", ". ", "Users who merely want to open or close the gripper with maximum joint effort do ", " need to use this package. If you are not worried about damaging the object being grasped, and are not interested in the signals generated during this interaction, you should refer to the simpler ", " package. ", "The ", " package contains a set of action nodes. The ", " nodes provide implementations of ", " (see ", ").  The various actions subscribe and publish to a series of messages found in ", ", but this API is not intended for use outside of the pr2_gripper_sensor_* packages. The public API for the various action servers is described in the following subsections, as well as a high-level description of what the node does. ", "This package relies on several parameters being loaded onto the ROS ", ". Currently this is done when the node is ", " by invoking the ", " file from the ", " package. If you wish to permanently edit any of the below values you should see this file. ", "Many users may wish to modify some of these values temporarily and repeatedly during program run time. This can be done by loading a new value for the parameter below onto the param server, and then invoking the ", " to push these changes into the real-time controller. ", "All the parameters listed below are currently loaded within the namespace of the real-time controller for each of the two PR2 grippers, ", " and ", ". A ", " below indicates that the parameter is not reloadable with the ", ". ", "Users should refer to the ", " section for specific examples on using the action nodes defined below. ", "Currently three ", " are provided to the user. These services communicate directly with the ", " package. Most users will generally not need to use them, however, advanced users may find them to come in handy. All services communicate using the standard Empty Request and Response message types. ", "Please refer to the ", " page to understand the hardware dependencies necessary for this package to run properly. ", "If you are not using pre-built libraries it is necessary to compile the real-time controller ", " ", " to launching the PR2. By compiling the ", " library before launching the robot the ", " package will be automatically included as a dependency. "], "package_tt": ["SimpleActionServer", "pr2_gripper_sensor_controller.yaml", "r_gripper_sensor_controller", "l_gripper_sensor_controller", "*", "close_speed", "double", "max_joint_effort", "double", "fingertip_force_limit", "double", "deformation_limit", "double", "force_lightest", "double", "hp_force_trigger", "double", "force_servo_force_tolerance", "double", "force_servo_velocity_tolerance", "double", "slip_servo_start_force", "double", "position_servo_position_tolerance", "double", "position_open", "double", "joint_name*", "string", "accelerometer_name*", "string", "left_pressure_sensor_name*", "string", "right_pressure_sensor_name*", "string", "grab", "position_open", "close_speed", "slip_servo", "grab", "gripper_action", "find_contact", "force_servo", "slip_servo", "find_contact", "force_servo", "/r_gripper_sensor_controller/grab", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "position_open", "release", "event_detector", "release", "position_open", "gripper_action", "/r_gripper_sensor_controller/release", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "position_open", "/r_gripper_sensor_controller/gripper_action", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "max_effort", "max_joint_effort", "max_joint_effort", "position_servo_position_tolerance", "force_servo_force_tolerance", "force_servo_velocity_tolerance", "/r_gripper_sensor_controller/force_servo", "find_contact", "force_lightest", "force_lightest", "fingertip_force", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "max_joint_effort", "fingertip_force_limit", "deformation_limit", "force_lightest", "force_servo_force_tolerance", "force_servo_velocity_tolerance", "close_speed", "contact_conditions", "/r_gripper_sensor_controller/find_contact", "zero_fingertip_sensors", "find_contact", "true", "force_lightest", "hp_force_trigger", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "close_speed", "max_joint_effort", "hp_force_trigger", "force_servo", "slip_servo", "/r_gripper_sensor_controller/slip_servo", "slip_servo_gain", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "max_joint_effort", "fingertip_force_limit", "deformation_limit", "force_lightest", "slip_servo_force_tolerance", "slip_servo_start_force", "trigger_conditions", "/r_gripper_sensor_controller/event_detector", "gripper_action", "force_servo", "find_contact", "slip_servo", "grab", "find_contact", "zero_fingertip_sensors", "true", "find_contact", "/r_gripper_sensor_controller/zero_fingertip_sensors", "/r_gripper_sensor_controller/reload_params", "/r_gripper_sensor_controller/stop_motor_output"], "package_code": ["rosmake pr2_gripper_sensor_action", "roslaunch pr2_gripper_sensor_action pr2_gripper_sensor_actions.launch"]},
{"url": "https://wiki.ros.org/jsk_robot_startup", "package": "jsk_robot_startup", "package_summary": ["The jsk_robot_startup package"]},
{"url": "https://wiki.ros.org/rqt_topic", "package": "rqt_topic", "package_summary": ["rqt_topic provides a GUI plugin for displaying debug information about ROS topics including publishers, subscribers, publishing rate, and ROS Messages."], "package_details": ["\n", "\n"], "package_tt": ["sensor_msgs/Image", "rqt"]},
{"url": "https://wiki.ros.org/nerian_stereo", "package": "nerian_stereo", "package_summary": ["Driver node for SceneScan and SP1 stereo vision sensors by Nerian Vision GmbH"], "package_details": ["\n", " ", "\n", "\n", " ", "\n", " (", ") ", "\n", " (", ", default: ", ") ", "\n", " ", "\n", "\n", " ", " ", "The ", " by Nerian Vision Technologies is a stand-alone processing system for performing stereo matching in real time. It is connected to two industrial USB cameras that provide input image data.  ", " correlates the images of both cameras and produces a disparity map, which is transmitted through gigabit ethernet. The disparity map describes a mapping of image points from the left camera image to corresponding image points in the right camera image. With this information it is possible to reconstruct the 3D location of the corresponding scene points. ", "The data delivered by ", " can be received using the available open source API. Using the API directly is recommended for high performance applications. Alternatively the ", " ROS node can be used for publishing the received data as ROS messages. A Nodelet version is also provided. ", "The behaviour of the node can be configured through various parameters. An example parameterization can be found in the included launch file ", ". The following parameters are supported: ", "The topics published by the nerian_stereo node can be viewed with ", ". The disparity map can also be visualized with the ", " node. In this case color coding should be activated such that the disparity map can be displayed on a screen. In order to do so, please launch the image_view node as follows: "], "package_tt": ["nerian_stereo", "/nerian_stereo/point_cloud", "/nerian_stereo/disparity_map", "/nerian_stereo/left_image", "/nerian_stereo/right_image", "/nerian_stereo/stereo_camera_info", "nerian_stereo.launch", "~point_cloud_intensity_channel", "string", "\"mono8\"", "~ros_coordinate_system", "bool", "\"true\"", "~ros_timestamps", "bool", "\"true\"", "~color_code_disparity_map", "string", "\"none\"", "~color_code_legend", "bool", "\"true\"", "~frame", "string", "\"world\"", "~remote_host", "string", "\"0.0.0.0\"", "~remote_port", "string", "\"7681\"", "~use_tcp", "bool", "\"false\"", "~calibration_file", "string", "\"\"", "~delay_execution", "double", "0", "~max_depth", "double", "-1"], "package_code": ["sudo apt-get update\n", "sudo apt-get install ros-`rosversion -d`-nerian-stereo", "roslaunch nerian_stereo nerian_stereo.launch device_address:=192.168.10.10 node_name:=nerian_stereo_01", "rosrun image_view image_view image:=/nerian_stereo/disparity_map", "rosrun image_view image_view image:=/nerian_stereo/left_image", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/rqt", "package": "rqt", "package_summary": ["rqt is a Qt-based framework for GUI development for ROS. It consists of three parts/metapackages", "\n    "], "package_details": [" (also builds against fuerte) ", " ", "\n", " is a software framework of ", " that implements the various GUI tools in the form of plugins. One can run all the existing GUI tools as dockable windows within rqt! The tools can still run in a traditional standalone method, but rqt makes it easier to manage all the various windows on the screen at one moment. ", " supercedes the former GUI tools of ROS ", ", which now is deprecated since ROS ", ". ", "\n", " consists of three (+1) ", ": ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "You can run any ", " tools/plugins easily by: ", "Users can create their own plugins for rqt with either ", " or ", ". ", " (as of Feb 2013) have already been created and more are slated for development. ", "There's a policy for the development repositories of ", " and ", " (", "): "], "package_tt": ["ROS", "rqt", "rosrun", "rqt", "Python", "C++", "rqt", "metapackages", "Qt", "rqt", "Qt\u00a04.8", "Qt\u00a05.3", "rqt", "rqt", "Python", "C++", "rqt", "rqt", "rqt", "rqt_**", "rqt", "ros-users", "groovy-devel", "master"], "package_code": ["$ rqt", "$ rosrun rqt_gui rqt_gui"]},
{"url": "https://wiki.ros.org/rviz_python_tutorial", "package": "rviz_python_tutorial", "package_summary": ["Tutorials showing how to call into rviz internals from python scripts."]},
{"url": "https://wiki.ros.org/qt_ros", "package": "qt_ros", "package_summary": ["Simple qt cmake build tools and master-chooser style application template."], "package_details": ["\n", "\n", "Refer to the ", ". ", "Use github to ", " or ", ". "], "package_tt": ["roscreate-qt-legacy-pkg"], "package_code": ["> sudo apt-get install ros-electric-qt-ros", "- git:\n", "    uri: https://github.com/stonier/qt_ros.git\n", "    local-name: qt_ros\n", "    version: electric", "> sudo apt-get install ros-fuerte-qt-ros", "> sudo apt-get install python-pip\n", "> sudo pip install --upgrade roscreate", "- git:\n", "    uri: https://github.com/stonier/qt_ros.git\n", "    local-name: qt_ros\n", "    version: fuerte"]},
{"url": "https://wiki.ros.org/imu_sensor_controller", "package": "imu_sensor_controller", "package_summary": ["Controller to publish state of IMU sensors"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/youbot_gazebo_worlds", "package": "youbot_gazebo_worlds", "package_summary": ["Gazebo worlds configurations"]},
{"url": "https://wiki.ros.org/xbot_tools", "package": "xbot_tools", "package_summary": ["The xbot_tools package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/turtlebot3_example", "package": "turtlebot3_example", "package_summary": ["This package provides four TurtleBot3 basic example include move using interactive marker, move and stop using LDS, move to goal position, move to custom routes. The interactions node is that you can control the TurtleBot3 front and back side or rotate to goal position. The obstacle node is that when the robot meets an obstacle, it stops. The patrol node is that TurtleBot3 move to custom route. There are 3 route(square, triangle, circle) in this package. You can add your route and move the TurtleBot3. The pointop node is that you can insert goal position include distance x-axis, y-axis and angluar z-axis."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n"], "package_tt": ["turtlebot3_marker_server", "cmd_vel", "turtlebot3_marker_server/update", "turtlebot3_marker_server/update_full", "joint_states", "tf", "tf_static", "scan", "cmd_vel", "odom", "cmd_vel", "turtlebot3/result", "turtlebot3/goal", "turtlebot3_server/goal", "turtlebot3_server/result", "turtlebot3_server/feedback", "joint_states", "odom"]},
{"url": "https://wiki.ros.org/joint_trajectory_controller", "package": "joint_trajectory_controller", "package_summary": ["Controller for executing joint-space trajectories on a group of joints."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " Even when a goal has been aborted, the controller will still attempt to execute the trajectory as best as possible. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The controller is templated to work with multiple hardware interface types.  Currently joints with ", ", ", " and ", " interfaces are supported. For position-controlled joints, desired positions are simply forwarded to the joints; while for velocity (effort) joints, the position+velocity trajectory following error is mapped to velocity (effort) commands through a PID loop. Example controller configurations can be found ", ". ", "There are two mechanisms for sending trajectories to the controller: by means of the ", " or the ", ". Both use the ", " message to specify trajectories, and require specifying values for ", " the controller joints (as opposed to only a subset) if allow_partial_joints_goal is not set to True. ", "The primary way to send trajectories is through the ", ", and should be favored when execution monitoring is desired. Action goals allow to specify not only the trajectory to execute, but also (optionally) path and goal tolerances. When no tolerances are specified, the defaults given in the parameter server are used (see ", " below). If tolerances are violated during trajectory execution, the action goal is aborted and the client is notified. ", "The ", " is a fire-and-forget alternative. Use this interface if you don't care about execution monitoring. The controller's path and goal tolerance specification is ", " used in this case, as there is no mechanism to notify the sender about tolerance violations. Note that although some degree of monitoring is available through the ", " service and ", " topic (see ", " below), it is much more cumbersome to realize than with the action interface. ", "Only one action goal can be active at any moment, or none if the topic interface is used. Path and goal tolerances are checked ", " for the trajectory segments of the active goal. ", "Sending an ", " message from the ", " (not the action interface) will stop the execution of all queued trajectories and enter position hold mode. The ", " parameter controls the duration of the stop motion. ", "Joint trajectory messages allow to specify the time at which a new trajectory should start executing by means of the header timestamp, where zero time (the default) means ", ". ", "The arrival of a new trajectory command does ", " mean that the controller will completely discard the currently running trajectory and substitute it with the new one. Rather, the controller will take the useful parts of both and combine them appropriately. Please refer to the ", " page for a detailed description of this behavior. ", "The controller exposes a ", " interface in the ", " namespace of the controller. See the action definition for more information on what to send. "], "package_tt": ["query_state", "state", "stop_trajectory_duration", "follow_joint_trajectory", "command", "state", "query_state", "joints", "string[]", "constraints/goal_time", "double", "constraints/stopped_velocity_tolerance", "double", "constraints/<joint>/goal", "double", "constraints/<joint>/trajectory", "double", "gains/<joint>", "associative\u00a0array", "velocity_ff/<joint>", "double", "stop_trajectory_duration", "double", "state_publish_rate", "double", "action_monitor_rate", "double", "allow_partial_joints_goal", "bool"], "package_code": ["head_controller:\n", "  type: \"position_controllers/JointTrajectoryController\"\n", "  joints:\n", "    - head_1_joint\n", "    - head_2_joint", "head_controller:\n", "  type: \"velocity_controllers/JointTrajectoryController\"\n", "  joints:\n", "    - head_1_joint\n", "    - head_2_joint\n", "\n", "  gains: # Required because we're controlling a velocity interface\n", "    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}\n", "    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}", "head_controller:\n", "  type: \"velocity_controllers/JointTrajectoryController\"\n", "  joints:\n", "    - head_1_joint\n", "    - head_2_joint\n", "\n", "  gains: # Required because we're controlling a velocity interface\n", "    head_1_joint: {p: 10,  d: 1, i: 1, i_clamp: 1} # Smaller 'p' term, since ff term does most of the work\n", "    head_2_joint: {p: 10,  d: 1, i: 1, i_clamp: 1} # Smaller 'p' term, since ff term does most of the work\n", "\n", "  velocity_ff:\n", "    head_1_joint: 1.0\n", "    head_2_joint: 1.0", "head_controller:\n", "  type: \"effort_controllers/JointTrajectoryController\"\n", "  joints:\n", "    - head_1_joint\n", "    - head_2_joint\n", "\n", "  gains: # Required because we're controlling an effort interface\n", "    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}\n", "    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}", "head_controller:\n", "  type: \"effort_controllers/JointTrajectoryController\"\n", "  joints:\n", "    - head_1_joint\n", "    - head_2_joint\n", "\n", "  constraints:\n", "    goal_time: 0.5                   # Override default\n", "    stopped_velocity_tolerance: 0.02 # Override default\n", "    head_1_joint:\n", "      trajectory: 0.05               # Not enforced if unspecified\n", "      goal: 0.02                     # Not enforced if unspecified\n", "    head_2_joint:\n", "      goal: 0.01                     # Not enforced if unspecified\n", "\n", "  gains: # Required because we're controlling an effort interface\n", "    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}\n", "    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}\n", "\n", "  state_publish_rate:  25            # Override default\n", "  action_monitor_rate: 30            # Override default\n", "  stop_trajectory_duration: 0        # Override default"]},
{"url": "https://wiki.ros.org/rtmbuild", "package": "rtmbuild", "package_summary": ["Build scripts for OpenRTM and OpenHRP"]},
{"url": "https://wiki.ros.org/lanelet2_traffic_rules", "package": "lanelet2_traffic_rules", "package_summary": ["Package for interpreting traffic rules in a lanelet map"]},
{"url": "https://wiki.ros.org/mavros_extras", "package": "mavros_extras", "package_summary": ["Extra nodes and plugins for ", "."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " only. ", "Require ", " package, use ", ". ", "\n", "\n", "This package provides additional nodes and plugins not included to ", ". ", "All utilities provides <util> --help and <util> <command> --help information.  ", "Extra set of communication plugins loaded by ", ". "], "package_tt": ["mavlink/from", "mavlink/gcs_image", "mavlink/to", "~gcs_url", "string", "~jpeg_quality", "int", "local_position", "local_setpoint", "track_markers", "vehicle_marker", "wp_markers", "~fixed_frame_id", "string", "~child_frame_id", "string", "~marker_scale", "double", "~num_rotors", "int", "~arm_len", "double", "~body_width", "double", "~body_height", "double", "~max_track_size", "int", "sudo\u00a0pip\u00a0install\u00a0fusepy", "~distance_sensor/<sensor_name>", "~distance_sensor/<sensor_name>", "~distance_sensor/<sensor_name>/subscriber", "bool", "~distance_sensor/<sensor_name>/id", "int", "~distance_sensor/<sensor_name>/orientation", "string", "~image/camera_image", "~image/frame_id", "string", "~mocap/pose", "~mocap/tf", "~mocap/use_tf", "bool", "~mocap/use_pose", "bool", "OPTICAL_FLOW_RAD", "~px4flow/raw/optical_flow_rad", "~px4flow/ground_distance", "~px4flow/temperature", "~px4flow/frame_id", "string", "~px4flow/ranger_fov", "double", "~px4flow/ranger_min_range", "double", "~px4flow/ranger_max_range", "double", "~vision_pose/pose", "~vision_pose/pose_cov", "~vision_pose/tf/listen", "bool", "~vision_pose/tf/frame_id", "string", "~vision_pose/tf/child_frame_id", "string", "~vision_pose/tf/rate_limit", "double", "~vision_speed/speed_vector", "~vision_speed/speed_twist", "~vision_speed/listen_twist", "bool"], "package_code": ["usage: mavteleop [-h] [-n MAVROS_NS] [-v] (-rc | -att | -vel | -pos)\n", "\n", "Teleoperation script for Copter-UAV\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  -rc, --rc-override    use rc override control type\n", "  -att, --sp-attitude   use attitude setpoint control type\n", "  -vel, --sp-velocity   use velocity setpoint control type\n", "  -pos, --sp-position   use position setpoint control type", "usage: mavftpfuse [-h] [-n MAVROS_NS] [-v] [-d] path\n", "\n", "FUSE for MAVLink-FTP mavros plugin\n", "\n", "positional arguments:\n", "  path                  mount point\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  -d, --debug           libfuse debug"]},
{"url": "https://wiki.ros.org/rosping", "package": "rosping", "package_summary": ["rosping is the tool to send ICMP ECHO_REQUEST to network hosts where roscore is running, and send back to you as rostopic message. ", "\n    For echoing ROS node, use ", "."], "package_details": [" is the tool to send ICMP ECHO_REQUEST to network hosts and send back to you as rostopic message ", "\n", " ", "\n", "\n", "\n", " ", "send ICMP ECHO_REQUEST to <host> "], "package_tt": ["rosping", "rosping\u00a0<host>", "host", "rosping", "~delay", "~rate", "float"], "package_code": ["$ rosrun rosping rosping 8.8.8.8\n", "32 bytes from 8.8.8.8: icmp_seq=131, ttl=45, time=40.958 ms\n", "32 bytes from 8.8.8.8: icmp_seq=132, ttl=45, time=40.856 ms\n", "$ rostopic echo ping/delay\n", "data: 40.903\n", "---\n", "data: 40.961"]},
{"url": "https://wiki.ros.org/rosflight_firmware", "package": "rosflight_firmware", "package_summary": ["Firmware library for software-in-the-loop of the ROSflight ROS stack"], "package_details": ["\n", "This package provides a ROS wrapper for the ", ", and also provides a board implementation with UDP serial communication functionality. These are used by the ", " package for software-in-the-loop simulation. "]},
{"url": "https://wiki.ros.org/rqt_srv", "package": "rqt_srv", "package_summary": ["A Python GUI plugin for introspecting available ROS message types.\n  Note that the srvs available through this plugin is the ones that are stored\n  on your machine, not on the ROS core your rqt instance connects to."]},
{"url": "https://wiki.ros.org/py_trees_msgs", "package": "py_trees_msgs", "package_summary": ["Messages used by py_trees_ros and some extras for the mock demos/tests."]},
{"url": "https://wiki.ros.org/velodyne_msgs", "package": "velodyne_msgs", "package_summary": ["ROS message definitions for Velodyne 3D LIDARs."], "package_details": ["\n", "\n", "This package collects all ROS messages that are specific to Velodyne 3D LIDARs, simplifying the dependencies between ", " stack components and their users.  ", "It also provides bag migration scripts for translating old captured data to the latest format using the ", " command. "]},
{"url": "https://wiki.ros.org/yocs_virtual_sensor", "package": "yocs_virtual_sensor", "package_summary": ["Virtual sensor that uses semantic map information to \"see\" obstacles undetectable by robot sensors.\n      \n      Current implementation cannot read obstacles from YAML files. Until this feature gets implemented, we\n      use auxiliary scripts to read and publish files' content. Data directory contains some example files."]},
{"url": "https://wiki.ros.org/roslisp", "package": "roslisp", "package_summary": ["Lisp client library for ROS, the Robot Operating System."], "package_details": ["\n", "\n", "\n", "\n", "\n", "See the ", " for a guide to roslisp's features. ", "Roslisp is part of the stable ROS core distribution, and follows the ", ".   ", "See the ", " for future changes. ", "Roslisp is based on the ", " version of Common Lisp. It is defined as a system dependency in the roslisp ROS package. "]},
{"url": "https://wiki.ros.org/bayesian_belief_networks", "package": "bayesian_belief_networks", "package_summary": ["The bayesian_belief_networks package form https://github.com/eBay/bayesian-belief-networks, Authored by Neville Newey, Anzar Afaq, Copyright 2013 eBay Software Foundation"]},
{"url": "https://wiki.ros.org/nav2_bringup", "package": "nav2_bringup", "package_summary": ["ROS launch files for Nav2 Robot Platform bringup"]},
{"url": "https://wiki.ros.org/rosbridge_library", "package": "rosbridge_library", "package_summary": ["The core rosbridge package, repsonsible for interpreting JSON andperforming\n    the appropriate ROS action, like subscribe, publish, call service, and\n    interact with params."], "package_details": ["Rosbridge library is a Python library responsible for taking JSON strings and converting them to ROS messages, and vice versa. Rosbridge library is meant to be used as a library for transport layer packages. For example, the rosbridge_server package creates a ", " connection and uses the rosbridge library to handle the JSON to ROS conversion. "]},
{"url": "https://wiki.ros.org/qt_gui", "package": "qt_gui", "package_summary": ["qt_gui provides the infrastructure for an integrated graphical user interface based on Qt.\n    It is extensible with Python- and C++-based plugins (implemented in separate packages) which can contribute arbitrary widgets.\n    It requires either PyQt or PySide bindings."]},
{"url": "https://wiki.ros.org/seed_r7_typef_moveit_config", "package": "seed_r7_typef_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the SEED-Noid-Mover-typeF with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/rqt_joint_trajectory_plot", "package": "rqt_joint_trajectory_plot", "package_summary": ["The rqt_joint_trajectory_plot package"], "package_details": ["\n", " ", " ", " ", " ", "This package is to plot ", " message and ", " action in real time. ", "Then launch ", "! ", "Now you can control the UR5 using ", ". ", "Then run rqt and add ", " plugin. Choose the trajectory topic. "], "package_tt": ["\u00a0$\u00a0roslaunch\u00a0fake_joint_launch\u00a0ur5.launch\u00a0", "\u00a0$\u00a0roslaunch\u00a0ur5_moveit_config\u00a0ur5_moveit_planning_execution.launch\u00a0sim:=true\u00a0", "\u00a0$\u00a0rqt\u00a0"]},
{"url": "https://wiki.ros.org/librealsense2", "package": "librealsense2", "package_summary": ["Library for capturing data from the Intel(R) RealSense(TM) SR300, D400 Depth cameras and T2xx Tracking devices. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of RealSense(TM); devices are implemented in this project."], "package_details": ["\n", " is a cross-platform library (Linux, OSX, Windows) for capturing data from the Intel\u00ae ", "\u2122 SR300 and D400 cameras. It allows depth and color streaming, and provides intrinsic and extrinsic calibration information. The library also offers synthetic streams (pointcloud, depth aligned to color and vise-versa), and a built-in support for record and playback of streaming sessions. ", "This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of ", "\u2122 devices are implemented in this project, including multi-camera capture. ", "\n", "\n", "\n", " ", "The Intel\u00ae ", "\u2122 D415 and D435 cameras are ", ". ", "Installation instructions can be found ", ". ", "The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS ", " packages. Please ", " concerning this package to the realsense2_camera ", " Issues. ", "For updated details on this library see the ", ". "]},
{"url": "https://wiki.ros.org/moveit_ros_warehouse", "package": "moveit_ros_warehouse", "package_summary": ["Components of MoveIt! connecting to MongoDB"]},
{"url": "https://wiki.ros.org/jsk_common", "package": "jsk_common", "package_summary": ["Metapackage that contains commonly used toolset for jsk-ros-pkg"], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/astra_camera", "package": "astra_camera", "package_summary": ["Drivers for Orbbec Astra Devices."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "If you didn't add source $YOUR_WORKSPACE/devel/setup.bash to your .bashrc, remember to source it when open a new terminal ", " ", "This package provides multiple ", " for users to get useful information and set up devices. To know more about using these services, please check ", ". "], "package_code": ["sudo apt install ros-*-rgbd-launch ros-*-libuvc ros-*-libuvc-camera ros-*-libuvc-ros", "mkdir -p\n", "/catkin_ws/src\n", "/catkin_ws/\n", "catkin_make", "/catkin_ws/src\n", "git clone https://github.com/orbbec/ros_astra_camera", "roscd astra_camera\n", "./scripts/create_udev_rules", "/catkin_ws\n", "catkin_make --pkg astra_camera", "rosservice call /camera/get_ir_exposure", "rosservice call /camera/set_ir_exposure", "rosservice call /camera/set_laser\n", "rosservice call /camera/set_laser", "rosservice call /camera/switch_ir_camera\n", "rosservice call /camera/switch_ir_camera", " echo 64 > /sys/module/usbcore/parameters/usbfs_memory_mb"]},
{"url": "https://wiki.ros.org/swri_yaml_util", "package": "swri_yaml_util", "package_summary": ["Provides wrappers around the yaml-cpp library for various utility functions\n    and to abstract out the API changes made to yaml-cpp between ubuntu:precise\n    and ubuntu:trusty."]},
{"url": "https://wiki.ros.org/wireless_msgs", "package": "wireless_msgs", "package_summary": ["Messages for describing a wireless network such as bitrate, essid, and link quality."]},
{"url": "https://wiki.ros.org/mavros", "package": "mavros", "package_summary": ["MAVROS -- MAVLink extendable communication node for ROS\n    with proxy for Ground Control Station."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " only. ", "\n", "\n", "\n", "\n", "\n", "\n", "Main node can be extended by plugins (see ", "). See also ", " package. ", "If you unsure what firmware your FCU runs start apm.launch and see ", ". ", "Starting from 0.11 mavros knows string representation for autopilot mavlink enum. ", "For older you shall manually find autopilot type value in mavlink documentation.  ", "All utilities provides ", " and ", " information. ", "Supported custom modes listed at ", ". ", "Standard set of communication plugins loaded by ", ". ", "Note: this list for ", " version. ", "Older versions: ", ", ", ", ", ", ", ", ", ", ", ", ", ". "], "package_tt": ["mavlink/to", "mavlink/from", "diagnostics", "~system_id", "int", "~component_id", "int", "~target_system_id", "int", "~target_component_id", "int", "~startup_px4_usb_quirk", "bool", "~plugin_blacklist", "string[]", "~plugin_whitelist", "string[]", "~fcu_url", "string", "~fcu_protocol", "string", "~gcs_url", "string", "ros_udp", "mavlink/from", "mavlink/to", "~gcs_url", "string", "mavros/state", "<trigger_event>", "~<event_name>/service", "string", "~<event_handler>/event", "string[]", "~<event_handler>/action", "string[]", "~<event_handler>/shell", "string", "~<event_handler>/logfile", "string", "/path/to/serial/device[:baudrate]", "serial:///path/to/serial/device[:baudrate][/?ids=sysid,compid]", "serial-hwfc:///path/to/serial/device[:baudrate][?ids=sysid,compid]", "udp://[bind_host][:port]@[remote_host][:port][/?ids=sysid,compid]", "udp-b://[bind_host][:port]@[:port][/?ids=sysid,compid]", "tcp://[server_host][:port][/?ids=sysid,compid]", "tcp-l://[bind_host][:port][/?ids=sysid,compid]", "~system_id", "~component_id", "baudrate", "bind_host", "remote_host", "server_host", "port", "<util>\u00a0--help", "<util>\u00a0<command>\u00a0--help", "~radio_status", "~actuator_control", "~hil_controls/hil_controls", "~frame_id", "string", "~cmd/command", "~cmd/command_int", "~cmd/arming", "~cmd/set_home", "~cmd/takeoff", "~cmd/land", "~cmd/trigger_control", "~cmd/use_comp_id_system_control", "bool", "SYSTEM_CONTROL", "~ftp/open", "~ftp/close", "~ftp/read", "~ftp/write", "~ftp/list", "~ftp/truncate", "~ftp/remove", "~ftp/rename", "~ftp/mkdir", "~ftp/rmdir", "~ftp/checksum", "~ftp/reset", "~global_position/global", "~global_position/local", "~global_position/gp_vel", "~global_position/rel_alt", "~global_position/compass_hdg", "~global_position/raw/fix", "~global_position/raw/gps_vel", "~global_position/frame_id", "string", "~global_position/tf/send", "bool", "~global_position/tf/frame_id", "string", "~global_position/tf/child_frame_id", "string", "~imu/data", "~imu/data_raw", "~imu/mag", "~imu/temperature", "~imu/atm_pressure", "~imu/frame_id", "string", "~imu/linear_acceleration_stdev", "double", "~imu/angular_velocity_stdev", "double", "~imu/orientation_stdev", "double", "~imu/magnetic_stdev", "double", "~local_position/pose", "~local_position/velocity", "~local_position/frame_id", "string", "~local_position/tf/send", "bool", "~local_position/tf/frame_id", "string", "~local_position/tf/child_frame_id", "string", "~manual_control/send", "~manual_control/control", "~param/", "~param/pull", "~param/push", "~param/get", "~param/set", "~rc/override", "SYSID_MYGCS", "~rc/in", "~rc/out", "~safety_area/set", "~safety_area/p1/x", "double", "~safety_area/p1/y", "double", "~safety_area/p1/z", "double", "~safety_area/p2/x", "double", "~safety_area/p2/y", "double", "~safety_area/p2/z", "double", "~setpoint_accel/accel", "~setpoint_accel/send_force", "bool", "~setpoint_attitude/cmd_vel", "~setpoint_attitude/attitude", "~setpoint_attitude/thrust", "~setpoint_attitude/reverse_throttle", "bool", "~setpoint_attitude/use_quaternion", "bool", "~setpoint_attitude/tf/listen", "bool", "~setpoint_attutude/tf/frame_id", "string", "~setpoint_attitude/tf/child_frame_id", "string", "~setpoint_attitude/tf/rate_limit", "double", "~setpoint_position/global", "~setpoint_position/local", "~setpoint_position/tf/listen", "bool", "~setpoint_position/tf/frame_id", "string", "~setpoint_position/tf/child_frame_id", "string", "~setpoint_position/tf/rate_limit", "double", "~setpoint_raw/local", "~setpoint_raw/global", "~setpoint_raw/attitude", "~setpoint_raw/target_local", "~setpoint_raw/target_global", "~setpoint_raw/target_attitude", "~setpoint_velocity/cmd_vel_unstamped", "~state", "~battery", "~battery", "~extended_state", "~set_stream_rate", "~set_mode", "~conn/timeout", "double", "~conn/heartbeat_rate", "double", "~sys/min_voltage", "double", "~sys/disable_diag", "bool", "~time_reference", "~conn/system_time_rate", "double", "SYSTEM_TIME", "~conn/timesync_rate", "double", "~time/time_ref_source", "string", "~time/timesync_avg_alpha", "double", "~vfr_hud", "~wind_estimation", "~mission/reached", "~mission/waypoints", "~mission/pull", "~mission/push", "~mission/clear", "~mission/set_current", "~mission/pull_after_gcs", "bool", "tf/"], "package_code": ["roslaunch mavros px4.launch", "roslaunch mavros apm.launch", "usage: mavcmd [-h] [-n MAVROS_NS] [-v] [--wait]\n", "              {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "              ...\n", "\n", "Commad line tool for sending commands to MAVLink device.\n", "\n", "positional arguments:\n", "  {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "    long                Send any command (COMMAND_LONG)\n", "    int                 Send any command (COMMAND_INT)\n", "    sethome             Request change home position\n", "    takeoff             Request takeoff\n", "    land                Request land\n", "    takeoffcur          Request takeoff from current GPS coordinates\n", "    landcur             Request land on current GPS coordinates\n", "    trigger_control     Control onboard camera trigerring system (PX4)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavftp [-h] [-n MAVROS_NS] [-v]\n", "              {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "              ...\n", "\n", "File manipulation tool for MAVLink-FTP.\n", "\n", "positional arguments:\n", "  {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "    cd                  change directory\n", "    list                list files and dirs\n", "    cat                 cat file\n", "    remove              remove file\n", "    mkdir               create direcotory\n", "    rmdir               remove directory\n", "    download            download file\n", "    upload              upload file\n", "    verify              verify files\n", "    reset               reset\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavparam [-h] [-n MAVROS_NS] [-v] {load,dump,get,set} ...\n", "\n", "Commad line tool for getting, setting, parameters from MAVLink device.\n", "\n", "positional arguments:\n", "  {load,dump,get,set}\n", "    load                load parameters from file\n", "    dump                dump parameters to file\n", "    get                 get parameter\n", "    set                 set parameter\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsafety [-h] [-n MAVROS_NS] [-v] {arm,disarm,safetyarea} ...\n", "\n", "Commad line tool for manipulating safty on MAVLink device.\n", "\n", "positional arguments:\n", "  {arm,disarm,safetyarea}\n", "    arm                 Arm motors\n", "    disarm              Disarm motors\n", "    safetyarea          Send safety area\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsetp [-h] [-n MAVROS_NS] [-V] {local} ...\n", "\n", "Commad line tool for control the device by setpoints.\n", "\n", "positional arguments:\n", "  {local}\n", "    local               Send local setpoint\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -V, --verbose         verbose output", "usage: mavsys [-h] [-n MAVROS_NS] [-v] [--wait] {mode,rate} ...\n", "\n", "Change mode and rate on MAVLink device.\n", "\n", "positional arguments:\n", "  {mode,rate}\n", "    mode                Set mode\n", "    rate                Set stream rate\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavwp [-h] [-n MAVROS_NS] [-v]\n", "             {show,load,pull,dump,clear,setcur,goto} ...\n", "\n", "Commad line tool for manipulating mission on MAVLink device.\n", "\n", "positional arguments:\n", "  {show,load,pull,dump,clear,setcur,goto}\n", "    show                Show waypoints\n", "    load                load waypoints from file\n", "    pull                pull waypoints from FCU\n", "    dump                dump waypoints to file\n", "    clear               clear waypoints on device\n", "    setcur              set current waypoints on device\n", "    goto                send goto waypoint (APM only)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output"]},
{"url": "https://wiki.ros.org/jackal_control", "package": "jackal_control", "package_summary": ["Controllers for Jackal"], "package_details": ["\n", "'s mobility is controlled by ", ". "]},
{"url": "https://wiki.ros.org/joint_qualification_controllers", "package": "joint_qualification_controllers", "package_summary": ["Controllers used in PR2 hardware testing. For testing counterbalance of PR2, and for internal WG use."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/velocity_controllers", "package": "velocity_controllers", "package_summary": ["velocity_controllers"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/moveit", "package": "moveit", "package_summary": ["Meta package that contains all essential package of MoveIt!. Until Summer 2016 MoveIt! had been developed over multiple repositories, where developers' usability and maintenance effort was non-trivial. See ", "."], "package_details": ["All documentation for MoveIt! is on the ", ". "]},
{"url": "https://wiki.ros.org/jackal_navigation", "package": "jackal_navigation", "package_summary": ["Launch files and code for autonomous navigation of the Jackal"], "package_details": ["\n", "The jackal_navigation package contains configuration and launch files for running ", " on ", ". ", "For usage, please see ", ".  "]},
{"url": "https://wiki.ros.org/perception_pcl", "package": "perception_pcl", "package_summary": ["PCL (Point Cloud Library) ROS interface stack. PCL-ROS is the preferred\n  bridge for 3D applications involving n-D Point Clouds and 3D geometry\n  processing in ROS."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "Please see ", " for documentation and tutorials on using PCL with ROS. "]},
{"url": "https://wiki.ros.org/jsk_baxter_startup", "package": "jsk_baxter_startup", "package_summary": ["The jsk_baxter_startup package"]},
{"url": "https://wiki.ros.org/velodyne_driver", "package": "velodyne_driver", "package_summary": ["ROS device driver for Velodyne 3D LIDARs."], "package_details": ["\n", "\n", ": the ", " parameter now expects an exact name: \"VLP16\", \"32C\", \"32E\", \"64E\", \"64E_S2\", \"64E_S2.1\", or \"64E_S3\", and generates the correct packet rates for them.", "\n ", ": The VLP-16 (\"Puck\") model is now supported.", "\n ", ": The VLP-32C (\"Ultra Puck\") model is now supported.", "\n ", ": The HDL-64E S3 model is now supported. ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "This package provides basic device handling for Velodyne 3D LIDARs. For a list of all supported models refer to the ", " section. ", "The driver publishes device-dependent ", " data. The ", " package provides nodes and nodelets to convert those data into more-convenient ", " messages. ", "The ", " describes the evolution of these interfaces. ", "Read the Velodyne HDL-64E (default) input socket as fast as possible. Publish each complete revolution to ", ". ", "Read the Velodyne Velodyne HDL-32E input socket as fast as possible. Publish each complete revolution to ", ". ", "Read previously captured Velodyne packets from dump.pcap file. Publish messages to ", " at approximately 10 Hz rate. Dump files can be grabbed by ", ", Velodyne's DSR software, ", ", ", ", ", ", or the ", " command. ", "The ", " command dumps raw data from the Velodyne LIDAR in PCAP format. It is a shell script wrapper providing some obscure options for the powerful ", " command. ", "Other methods of acquiring PCAP data include using ", " directly, ", ", Velodyne's DSR software, and programming with ", ". ", "Dump Velodyne packets from the ", " interface to a series of files named ", ", ", ", etc. Each file will be about 100MB. The time span that a single 100MB file covers depends on packet size and sampling rate of a particular model (for VLP-16 that is about 100 seconds worth of packets). Type ", " when finished. ", "Start a ", " process running the driver nodelet. Other nodelets using the same nodelet manager process will have zero-copy access to the raw data messages the driver publishes. ", "Start a ", " process for a Velodyne HDL-32E. ", "Start a driver nodelet with input from ", ", in the current directory. The ", " provides a full path name, as required for ", ". "], "package_tt": ["model", "/velodyne", "tf_prefix", "velodyne_packets", "velodyne_packets", "velodyne_packets", "libpcap", "ethereal", "wireshark", "tcpdump", "vdump", "tcpdump", "tcpdump", "wireshark", "libpcap", "eth1", "pcap-000", "pcap-001", "^C", "velodyne_nodelet_manager", "velodyne_nodelet_manager", "tcpdump.pcap", "pwd", "roslaunch"], "package_code": ["$ rosrun velodyne_driver velodyne_node", " $ rosrun velodyne_driver velodyne_node _model:=32E", "$ rosrun velodyne_driver velodyne_node _pcap:=dump.pcap", "  rosrun velodyne_driver vdump <file_prefix> [ <interface> ]\n", "\n", "        <file_prefix>   file name to dump (with 3-digit number suffix)\n", "        <interface>     interface to read from (default: \"eth0\")", "$ rosrun velodyne_driver vdump pcap- eth1", " $ roslaunch velodyne_driver nodelet_manager.launch", " $ roslaunch velodyne_driver nodelet_manager.launch model:=32E", " $ roslaunch velodyne_driver nodelet_manager.launch pcap:=$(pwd)/tcpdump.pcap"]},
{"url": "https://wiki.ros.org/ypspur_ros", "package": "ypspur_ros", "package_summary": ["ROS wrapper for the mobile robot control platform YP-Spur"]},
{"url": "https://wiki.ros.org/rqt_runtime_monitor", "package": "rqt_runtime_monitor", "package_summary": ["rqt_runtime_monitor provides a GUI plugin viewing DiagnosticsArray messages."], "package_details": ["\n"], "package_code": ["rosrun rqt_runtime_monitor rqt_runtime_monitor"]},
{"url": "https://wiki.ros.org/seed_r7_ros_pkg", "package": "seed_r7_ros_pkg", "package_summary": ["The seed_r7_ros_pkg package"]},
{"url": "https://wiki.ros.org/mrpt_navigation", "package": "mrpt_navigation", "package_summary": ["Tools related to the Mobile Robot Programming Toolkit (MRPT).\n    Refer to http://wiki.ros.org/mrpt_navigation for further documentation."], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "See also: ", ". "], "package_tt": ["rosbag\u00a0play", "rosbag\u00a0record"], "package_code": ["# This will install all packages in the mrpt_navigation metapackage\n", "# Alternatively, install individual packages only as you need them\n", "sudo apt-get install ros-$ROS_DISTRO-mrpt-navigation"]},
{"url": "https://wiki.ros.org/yujin_maps", "package": "yujin_maps", "package_summary": ["The yujin_maps package"]},
{"url": "https://wiki.ros.org/rqt_controller_manager", "package": "rqt_controller_manager", "package_summary": ["The rqt_controller_manager package"]},
{"url": "https://wiki.ros.org/diff_drive_controller", "package": "diff_drive_controller", "package_summary": ["Controller for a differential drive mobile base."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The controller works with wheel joints through a ", " interface. ", "The controller main input is a ", " topic in the namespace of the controller. ", "The current implementation allows you to register multiple wheels per side and will average those wheel positions in its odometry calculations. For more info read the code and ", ". "], "package_tt": ["cmd_vel", "odom", "/tf", "publish_cmd", "left_wheel", "string\u00a0|\u00a0string[...]", "right_wheel", "string\u00a0|\u00a0string[...]", "pose_covariance_diagonal", "double[6]", "twist_covariance_diagonal", "double[6]", "publish_rate", "double", "wheel_separation_multiplier", "double", "wheel_radius_multiplier", "double", "cmd_vel_timeout", "double", "base_frame_id", "string", "linear/x/has_velocity_limits", "bool", "linear/x/max_velocity", "double", "linear/x/min_velocity", "double", "linear/x/has_acceleration_limits", "bool", "linear/x/max_acceleration", "double", "linear/x/min_acceleration", "double", "linear/x/has_jerk_limits", "bool", "linear/x/max_jerk", "double", "angular/z/has_velocity_limits", "bool", "angular/z/max_velocity", "double", "angular/z/min_velocity", "double", "angular/z/has_acceleration_limits", "bool", "angular/z/max_acceleration", "double", "angular/z/min_acceleration", "double", "angular/z/has_jerk_limits", "bool", "angular/z/max_jerk", "double", "enable_odom_tf", "bool", "wheel_separation", "double", "wheel_radius", "double", "odom_frame_id", "string", "publish_cmd", "bool", "allow_multiple_cmd_vel_publishers", "bool"], "package_code": ["mobile_base_controller:\n", "  type: \"diff_drive_controller/DiffDriveController\"\n", "  left_wheel: 'wheel_left_joint'\n", "  right_wheel: 'wheel_right_joint'\n", "  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]", "mobile_base_controller:\n", "  type        : \"diff_drive_controller/DiffDriveController\"\n", "  left_wheel  : 'wheel_left_joint'\n", "  right_wheel : 'wheel_right_joint'\n", "  publish_rate: 50.0               # default: 50\n", "  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "\n", "  # Wheel separation and diameter. These are both optional.\n", "  # diff_drive_controller will attempt to read either one or both from the\n", "  # URDF if not specified as a parameter\n", "  wheel_separation : 1.0\n", "  wheel_radius : 0.3\n", "\n", "  # Wheel separation and radius multipliers\n", "  wheel_separation_multiplier: 1.0 # default: 1.0\n", "  wheel_radius_multiplier    : 1.0 # default: 1.0\n", "\n", "  # Velocity commands timeout [s], default 0.5\n", "  cmd_vel_timeout: 0.25\n", "\n", "  # Base frame_id\n", "  base_frame_id: base_footprint #default: base_link\n", "\n", "  # Velocity and acceleration limits\n", "  # Whenever a min_* is unspecified, default to -max_*\n", "  linear:\n", "    x:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.0  # m/s\n", "      min_velocity           : -0.5 # m/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 0.8  # m/s^2\n", "      min_acceleration       : -0.4 # m/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 5.0  # m/s^3\n", "  angular:\n", "    z:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.7  # rad/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 1.5  # rad/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 2.5  # rad/s^3", "jackal_velocity_controller:\n", "  type: \"diff_drive_controller/DiffDriveController\"\n", "  left_wheel: ['front_left_wheel', 'rear_left_wheel']\n", "  right_wheel: ['front_right_wheel', 'rear_right_wheel']\n", "  publish_rate: 50\n", "  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 0.03]\n", "  twist_covariance_diagonal: [0.001, 0.001, 0.001, 1000000.0, 1000000.0, 0.03]\n", "  cmd_vel_timeout: 0.25\n", "\n", "  # Odometry fused with IMU is published by robot_localization, so\n", "  # no need to publish a TF based on encoders alone.\n", "  enable_odom_tf: false\n", "\n", "  # Wheel separation and radius multipliers\n", "  wheel_separation_multiplier: 1.5 # default: 1.0\n", "  wheel_radius_multiplier    : 1.0 # default: 1.0\n", "\n", "  # Velocity and acceleration limits\n", "  # Whenever a min_* is unspecified, default to -max_*\n", "  linear:\n", "    x:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 2.0   # m/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 20.0   # m/s^2\n", "  angular:\n", "    z:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 4.0   # rad/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 25.0   # rad/s^2"]},
{"url": "https://wiki.ros.org/serial", "package": "serial", "package_summary": ["Serial is a cross-platform, simple to use library for using serial ports on computers.\n    This library provides a C++, object oriented interface for interacting with RS-232\n    like devices on Linux and Windows."], "package_details": ["The serial package is documented on its website: ", " "]},
{"url": "https://wiki.ros.org/jackal_robot", "package": "jackal_robot", "package_summary": ["Metapackage of software to install on Jackal."], "package_details": ["\n", "Metapackage capturing software to be installed on ", ". "]},
{"url": "https://wiki.ros.org/librviz_tutorial", "package": "librviz_tutorial", "package_summary": ["Tutorial showing how to compile your own C++ program with RViz displays and features."], "package_details": [" ", "Please see the ", " page. "]},
{"url": "https://wiki.ros.org/yocs_ar_marker_tracking", "package": "yocs_ar_marker_tracking", "package_summary": ["Collecting, tracking and generating statistics for ar markers from ar_track_alvar."]},
{"url": "https://wiki.ros.org/hrpsys_tools", "package": "hrpsys_tools", "package_summary": ["The hrpsys_tools package"]},
{"url": "https://wiki.ros.org/stomp_plugins", "package": "stomp_plugins", "package_summary": ["This package provides additional plugins that can be used by the STOMP MoveIt planner"]},
{"url": "https://wiki.ros.org/mrpt_reactivenav2d", "package": "mrpt_reactivenav2d", "package_summary": ["Reactive navigation for 2D robots using MRPT navigation algorithms (TP-Space)"], "package_details": ["\n", "\n", "\n", "\n", "After installing ", " and ", ", run: "], "package_code": ["roslaunch mrpt_reactivenav2d reactive_nav_demo_with_mvsim.launch"]},
{"url": "https://wiki.ros.org/ff", "package": "ff", "package_summary": ["ff: pddl planner. see http://www.loria.fr/~hoffmanj/ff.html"]},
{"url": "https://wiki.ros.org/yumi_moveit_config", "package": "yumi_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the yumi with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/xv_11_laser_driver", "package": "xv_11_laser_driver", "package_summary": ["Neato XV-11 Laser Driver. This driver works with the laser when it is removed from the XV-11 Robot as opposed to reading scans from the Neato's USB port."], "package_details": ["\n", "\n", "\n", "\n", " is a C++ library for reading the data from the XV11's laser and packing that data into a ", ". As a standalone library, it has no ROS API. "], "package_tt": ["neato_laser_publisher", "xv11_laser_driver", "scan", "~port", "string", "~baud_rate", "int", "~firmware_version", "int", "~frame_id", "string", "xv11_laser_driver"]},
{"url": "https://wiki.ros.org/plotjuggler", "package": "plotjuggler", "package_summary": ["PlotJuggler: juggle with data"], "package_details": [" ", " ", "Find out more here: ", " "]},
{"url": "https://wiki.ros.org/controller_manager_tests", "package": "controller_manager_tests", "package_summary": ["controller_manager_tests"]},
{"url": "https://wiki.ros.org/single_joint_position_action", "package": "single_joint_position_action", "package_summary": ["The single joint position action is a node that provides an action\n  interface for commanding a trajectory to move a joint to a particular\n  position. The action reports success when the joint reaches the desired\n  position."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "See also ", ", which is used by this action. ", "You can find an example of using the single joint position action on the PR2 in the ", ". ", "The joint trajectory action provides an action server (see ", ") that takes in goals of the type ", ". "], "package_tt": ["~joint", "string", "~goal_threshold", "double", "~position_joint_action/goal", "~position_joint_action/cancel", "~position_joint_action/feedback", "~position_joint_action/status", "~position_joint_action/result", "~state", "~command"]},
{"url": "https://wiki.ros.org/web_video_server", "package": "web_video_server", "package_summary": ["HTTP Streaming of ROS Image Topics in Multiple Formats"], "package_details": ["\n", "\n", "\n", "\n", "\n", " (", ", default: original width) ", "\n", " (", ", default: 95) ", "\n", " (", ", default: mjpeg) ", "\n", " (", ", default: 95) ", "\n", " (", ", default: 100000) ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Several parameters can be configure via the video stream URL - Example: ", " ", "More information on the quality and profile parameter of the VP8 codec can be found here: ", " ", "Rate at which ", " subscribes a image topic depends on the publisher's publish rate. With a fast publish rate, a client host may unintentionally get busy. ", "As of version 0.2.1, ", " does not come with a feature to control the rate at which the frontend subscribes to an image topic. You can work this around on your client. ", "One way is to republish the image topic with a lower rate. You can use ", ". ", "View compressed stream at: ", " ", "Source code is available at ", ". ", "Please send bug reports to the ", ". Feel free to contact us at any point with questions and comments. "], "package_tt": ["~port", "integer", "~address", "string", "~server_threads", "integer", "~ros_threads", "integer", "http://localhost:8080/", "http://localhost:8080/stream_viewer?topic={ROS_TOPIC}", "http://localhost:8080/stream?topic={ROS_TOPIC}", "http://localhost:8080/snapshot?topic={ROS_TOPIC}", "width", "integer", "height", "integer", "quality", "integer", "invert", "none", "default_transport", "string", "quality", "integer", "type", "string", "quality", "integer", "bitrate", "integer", "qmin", "integer", "qmax", "integer", "gop", "integer", "quality", "string", "web_video_server", "web_video_server", "http://localhost:8080/stream?topic=/usb_cam/image_raw&type=ros_compressed"], "package_code": ["$ rostopic list\n", "/usb_cam/camera_info\n", "/usb_cam/image_raw/compressed"]},
{"url": "https://wiki.ros.org/moveit_ros_planning_interface", "package": "moveit_ros_planning_interface", "package_summary": ["Components of MoveIt! that offer simpler interfaces to planning and execution"]},
{"url": "https://wiki.ros.org/xpp_examples", "package": "xpp_examples", "package_summary": ["Examples of how to use the xpp framework."], "package_details": ["\n ", " ", "\n"], "package_code": ["$ sudo apt-get update\n", "$ sudo apt-get install ros-[distro-name]-xpp\n", "$ roslaunch xpp_examples hyq_ex.launch\n", "$ roslaunch xpp_examples biped_ex.launch\n", "$ roslaunch xpp_examples quadrotor_ex.launch\n", "$ roslaunch xpp_examples monoped_ex_bag.launch\n", "$ roslaunch xpp_examples monoped_ex_generate.launch"]},
{"url": "https://wiki.ros.org/leap_motion", "package": "leap_motion", "package_summary": ["ROS driver for the Leap Motion gesture sensor"], "package_details": ["\n", " is a ROS wrapper for interfacing with the Leap Motion 3D gesture sensor API (", "). For the most up to date information you can check our Github repository ", ". "]},
{"url": "https://wiki.ros.org/laser_proc", "package": "laser_proc", "package_summary": ["laser_proc"]},
{"url": "https://wiki.ros.org/nao_meshes", "package": "nao_meshes", "package_summary": ["meshes for the Aldebaran Robotics NAO"]},
{"url": "https://wiki.ros.org/pr2_head_action", "package": "pr2_head_action", "package_summary": ["The PR2 head action is a node that provides an action interface for\n  pointing the head of the PR2.  It passes trajectory goals to the\n  controller, and reports success when they have finished executing."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "See ", " for information on the controller that the head action communicates with. ", "An example of using the head action on the PR2 can be found in the ", ". ", "The joint trajectory action provides an action server (see ", ") that takes in goals of the type ", ".  It reports success when the head is pointed at the target. "], "package_tt": ["~pan_link", "string", "~tilt_link", "string", "~success_angle_threshold", "double", "~point_head_action/goal", "~point_head_action/cancel", "~point_head_action/feedback", "~point_head_action/status", "~point_head_action/result", "~state", "~command"]},
{"url": "https://wiki.ros.org/jackal_description", "package": "jackal_description", "package_summary": ["URDF robot description for Jackal"], "package_details": ["\n", " ", "\n", "\n", " ", "This package provides a ", " model of ", ". For an example launchfile to use in visualizing this model, see ", ". ", "Jackal has a suite of optional payloads called accessories. These payloads can be enabled and placed on Jackal using environment variables specified at the time the ", " is rendered to URDF. Available accessory vars are: ", "As an alternative to individually specifying each accessory, some fixed configurations are provided in the package. These can be specified using the ", " arg to ", ", and are intended especially as a convenience for simulation launch. ", "Please see ", " for more information on simulating Jackal. "], "package_tt": ["JACKAL_LASER", "0", "JACKAL_LASER_MOUNT", "front", "JACKAL_LASER_OFFSET", "\"0\u00a00\u00a00\"", "JACKAL_LASER_RPY", "\"0\u00a00\u00a00\"", "JACKAL_LASER_HOST", "192.168.1.14", "JACKAL_NAVSAT", "0", "JACKAL_NAVSAT_MOUNT", "rear", "JACKAL_NAVSAT_HEIGHT", "0.1", "JACKAL_NAVSAT", "0", "JACKAL_NAVSAT_MOUNT", "rear", "JACKAL_NAVSAT_HEIGHT", "0.1", "JACKAL_FLEA3", "0", "JACKAL_FLEA3_MOUNT", "front", "JACKAL_FLEA3_OFFSET", "\"0\u00a00\u00a00\"", "JACKAL_FLEA3_RPY", "\"0\u00a00\u00a00\"", "JACKAL_FLEA3_TILT", "\"0.5236\"", "JACKAL_BB2", "0", "JACKAL_BB2_MOUNT", "front", "JACKAL_BB2_OFFSET", "\"0\u00a00\u00a00\"", "JACKAL_BB2_RPY", "\"0\u00a00\u00a00\"", "JACKAL_BB2_TILT", "0", "JACKAL_BB2_CALIBRATION", "0", "JACKAL_BB2_SERIAL", "0", "config", "description.launch", "base", "front_laser", "front_bumblebee2", "front_flea3"]},
{"url": "https://wiki.ros.org/youbot_gazebo_control", "package": "youbot_gazebo_control", "package_summary": ["Controller"]},
{"url": "https://wiki.ros.org/qwt_dependency", "package": "qwt_dependency", "package_summary": ["This encapsulates the Qwt dependency for a specific ROS distribution and its Qt version"]},
{"url": "https://wiki.ros.org/um7", "package": "um7", "package_summary": ["The um7 package provides a C++ implementation of the CH Robotics serial protocol, and a\n    corresponding ROS node for publishing standard ROS orientation topics from a UM7."], "package_details": ["\n", "\n", " ", "\n", " the \"port\" assignment actually defaults to \"/dev/ttyUSB0\", so if your sensor is on that port, the parameter setting shown above is unnecessary. ", "  if you get a \"Couldn't find executable named um7_driver below /opt/ros/$ROS_DISTRO/share/um7\" message, try restarting linux.  I don't know why; but it has happened to me a couple times.  It should only happen on the first attempt to run. ", "\n", "\n", "\n", "\n", "\n", "\n", " To clarify data polarities, I will describe them in terms of aircraft motion.  NU/ND is aircraft nose up (as in climbing or nose down as in descent.   RWD/LWD is right wing down as in an aircraft turning to the right in flight; left wing down to turn to the left.  NR/NL is nose right as if the aircraft is turning right on the ground, and nose left for turn to the left. ", "\n", "\n", " "], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-um7", "rosrun um7 um7_driver _port:=/dev/ttyUSB0"]},
{"url": "https://wiki.ros.org/libuvc_ros", "package": "libuvc_ros", "package_summary": ["libuvc_ros metapackage"]},
{"url": "https://wiki.ros.org/marker_rviz_plugin", "package": "marker_rviz_plugin", "package_summary": ["The marker_rviz_plugin package contains RViz plugins to visualize messages of the marker_msgs package using RViz."]},
{"url": "https://wiki.ros.org/downward", "package": "downward", "package_summary": ["fast downward: PDDL Planner (http://www.fast-downward.org)"]},
{"url": "https://wiki.ros.org/mrpt_graphslam_2d", "package": "mrpt_graphslam_2d", "package_summary": ["Implement graphSLAM using the mrpt-graphslam library, in an online fashion\n  \tby directly reading measurements off ROS Topics."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "mrpt_graphslam_2d provides support for running either single-robot or multi-robot pose-only graphSLAM, using simulated data (e.g. from Gazebo) or in a real-time setup. Algorithm practically utilises the ", " to execute graphSLAM, using the ROS communication mechanisms and the ", " stack. ", "Information on how to use the algorithm for either simulation or real-time usage is provided in the Appendix of ", " ", "Additional support for running real-time graphSLAM with either one or with multiple agents is provided in the ", " ROS package. The latter provides launchfiles and generic scripts for setting up common tasks in real robot agents (setting up sensor data acquisition processes, processes for starting robot motors etc.) Package is specialized for the robots and equipment of the ", " of the ", " but can be easily extended to suppport different platforms, sensors etc. ", "Additional support for running simulations in Gazebo is provided in the ", " ROS package ", "See ", " ", "Package also contains sample datasets, along with the corresponding roslaunch files for easy execution, for both the single- and multi-robot SLAM cases. For more on this see the ", ". ", "Use the ", " tool to generate the complete API of this package: ", "* ", " ", "* ", " ", "* ", " "], "package_tt": ["rosdoc_lite"]},
{"url": "https://wiki.ros.org/velodyne", "package": "velodyne", "package_summary": ["Basic ROS support for the Velodyne 3D LIDARs."], "package_details": ["\n", ": the ", " parameter now expects an exact name: \"VLP16\", \"32C\", \"32E\", \"64E\", \"64E_S2\", \"64E_S2.1\", or \"64E_S3\" and generates the correct packet rates for them.", "\n ", ": The VLP-16 (\"Puck\") model is now supported.", "\n ", ": The VLP-32C (\"Ultra Puck\") model is now supported. ", "\n", "\n", "ROS packages for ", ". "], "package_tt": ["model", "velodyne"]},
{"url": "https://wiki.ros.org/mrpt_ekf_slam_3d", "package": "mrpt_ekf_slam_3d", "package_summary": ["This package is a wrapper for the implementation of EKF-based SLAM with range-bearing sensors, odometry, a full 6D robot pose, and 3D landmarks."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "The ROS node mrpt_ekf_slam_3d is a wrapper for the C++ class ", ", part of MRPT. Thus, check out the documentation of that class for further details. ", "For the convention on coordinate frames see ", ". ", "In order to use mrpt_ekf_slam_3d package it is necessary to install the last ", " build and the", "(see also the ", ") . "], "package_tt": ["mrpt_ekf_slam_3d", "tf", "landmark", "state_viz", "data_association_viz", "~global_frame_id", "string", "\"map\"", "~base_frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~sensor_source", "string", "\"scan\"", "\"scan\"", "\"beacon\"", "~ini_filename", "string", "~rawlog_filename", "string", "~rawlog_play_delay", "float", "~ellipse_scale", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["roslaunch mrpt_ekf_slam_3d ekf_slam_3d.launch", "roslaunch mrpt_ekf_slam_3d ekf_slam_3d_rawlog.launch"]},
{"url": "https://wiki.ros.org/youbot_gazebo_robot", "package": "youbot_gazebo_robot", "package_summary": ["Launch the KUKA youBot in the Gazebo simulation"]},
{"url": "https://wiki.ros.org/warehouse_ros", "package": "warehouse_ros", "package_summary": ["Persistent storage of ROS messages"], "package_details": ["\n", "\n", "\n", " "]},
{"url": "https://wiki.ros.org/roseus", "package": "roseus", "package_summary": ["EusLisp client for ROS Robot Operating System."], "package_details": ["\n", "\n", "See ", " for tutorials, also you may look at ", " packages for example codes. ", "Please send bug report to ", ". "]},
{"url": "https://wiki.ros.org/moveit_ros_manipulation", "package": "moveit_ros_manipulation", "package_summary": ["Components of MoveIt! used for manipulation"]},
{"url": "https://wiki.ros.org/sick_safetyscanners", "package": "sick_safetyscanners", "package_summary": ["Provides an Interface to read the sensor output of a SICK\n  Safety Scanner"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "In the following instructions, replace ", " with the name of your ROS distro (e.g., ", "). ", "In case of technical support please open a new issue. Under ", " "], "package_tt": ["<rosdistro>", "kinetic"], "package_code": ["sudo apt-get install ros-<rosdistro>-sick-safetyscanners", "source /opt/ros/<rosdistro>/setup.bash\n", "mkdir -p ~/catkin_ws/src/\n", "cd ~/catkin_ws/src/\n", "git clone https://github.com/SICKAG/sick_safetyscanners.git\n", "cd ..\n", "catkin_make install\n", "source ~/catkin_ws/install/setup.bash", "roslaunch sick_safetyscanners sick_safetyscanners.launch sensor_ip:=192.168.1.10 host_ip:=192.168.1.9", "rosrun rviz rviz", "/scan (type: sensor_msgs/LaserScan)", "/extended_laser_scan (type sick_safetyscanners/ExtendedLaserScanMsg)", "/output_paths (type sick_safetyscanners/OutputPathMsg)", "/raw_data (type: sick_safetyscanners/RawMicroScanDataMsg)", "/field_data"]},
{"url": "https://wiki.ros.org/pilz_robot_programming", "package": "pilz_robot_programming", "package_summary": ["An Easy to use API to execute standard industrial robot commands like Ptp, Lin, Circ and Sequence using Moveit."], "package_details": ["\n", "\n", "For package documentation please see the ", ". "]},
{"url": "https://wiki.ros.org/yocs_diff_drive_pose_controller", "package": "yocs_diff_drive_pose_controller", "package_summary": ["A controller for driving a differential drive base to a pose goal or along a path specified by multiple poses.\n    A pose consists of a 2D position (x,y) and a 1D orientation (theta)."], "package_details": [" "]},
{"url": "https://wiki.ros.org/moveit_setup_assistant", "package": "moveit_setup_assistant", "package_summary": ["Generates a configuration package that makes it easy to use MoveIt!"]},
{"url": "https://wiki.ros.org/ros_base", "package": "ros_base", "package_summary": ["A metapackage which extends ros_core and includes other basic non-robot tools like actionlib, dynamic reconfigure, nodelets, and pluginlib."]},
{"url": "https://wiki.ros.org/rqt_image_view", "package": "rqt_image_view", "package_summary": ["rqt_image_view provides a GUI plugin for displaying images using image_transport."], "package_details": [" is an ", " version of ", " (however, as of Mar 2015, they are separately implemented and there's no dependency in-between each package. See ", " for more info). ", " ", " allows you to open multiple ", " windows and dock into a single window like this. ", " "], "package_tt": ["rqt_image_view", "rqt", "rqt_image_view"]},
{"url": "https://wiki.ros.org/jsk_topic_tools", "package": "jsk_topic_tools", "package_summary": ["jsk_topic_tools"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["topic_buffer_server", "<topic_name>", "<topic_type>", "~update", "<topic_name>_update", "<topic_type>", "~list", "~update", "topic_buffer_client", "<topic_name>_update", "<topic_type>", "<topic_name>_buffered", "<topic_type>", "transform_merger", "tf", "tf_merged", "~loop_hz", "double,\u00a0default:\u00a01.0", "specific_transform_publisher", "tf", "specific_transform", "~parent_frame", "string", "~child_frame", "string", "specific_transform_subscriber", "specific_transform"], "package_code": [" rosrun jsk_topic_tools topic_buffer_server IN_TOPIC1 [IN_TOPIC2 [...]]", " rosrun jsk_topic_tools topic_buffer_client /list:=<topic_buffer_server_name>/list  /update:=<topic_buffer_server_name>/update", " rosrun jsk_topic_tools transform_merger", "roslaunch jsk_topic_tools topic_buffer_server_sample.launch  ", "roslaunch jsk_topic_tools topic_buffer_client_sample.launch  ", "roslaunch jsk_topic_tools tf_buffer_server_sample.launch  ", "roslaunch jsk_topic_tools tf_buffer_client_sample.launch  ", "roslaunch jsk_topic_tools specific_transform_publisher_sample.launch ", "roslaunch jsk_topic_tools specific_transform_subscriber_sample.launch "]},
{"url": "https://wiki.ros.org/qt_gui_app", "package": "qt_gui_app", "package_summary": ["qt_gui_app provides the main to start an instance of the integrated graphical user interface provided by qt_gui."]},
{"url": "https://wiki.ros.org/visualization_marker_tutorials", "package": "visualization_marker_tutorials", "package_summary": ["The visulalization_marker_tutorials package"]},
{"url": "https://wiki.ros.org/laser_filters", "package": "laser_filters", "package_summary": ["Assorted filters designed to operate on 2D planar laser scanners,\n    which use the sensor_msgs/LaserScan type."], "package_details": ["\n", "\n", " are configured from the parameter server.  They expect a parameter which is a list made up of repeating blocks of filter configurations.  These should almost always  be specified in a ", " file to be pushed to the parameter server.  Each filter specified in the chain will be applied in order. ", " that the ", " should be specified as ", " as the ", " is ", ", if only the ", " is used. ", ": ", "\n", " ", "\n", " ", "\n", " (list) ", " (string) ", "\n", " (", ") ", "\n", " (", ") ", "\n", ": ", ": ", " ", "\n", " ", "\n", " (list) ", " (list) ", " (string) ", " (bool, default: false) ", "\n", " (", ") ", "\n", " (", ") ", "\n", ": ", ": ", ": ", " ", "\n", "\n", "\n", " (", ") ", " (", ") ", " ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "The primary content of the ", " package is a number of general purpose filters for processing ", " messages.  These filters are exported as plugins designed to work with with the ", ".  At the moment all of these filters run directly on ", ", but filters may be added in the future which process ", " instead.  Please review the ", " for an overview of how filters and filter chains are intended to work. ", "This package provides two nodes that can run multiple filters internally. Using these nodes to run your filters is considered best practice, since it allows multiple nodes to consume the output while only performing the filtering computation once.  The nodes are minimal wrappers around filter chains of the given type.  The ", " applies a series of filters to a ", ".  The ", " first applies a series of filters to a ", ", transforms it into a ", ", and then applies a series of filters to the ", ". ", "Each ", " is a separate plugin exported by the laser_filters package.  This allows them to be specified in a configuration file which can be loaded into an arbitrary filter_chain templated on a ", ". You can instantiate a laser filter into a filter_chain in C++ (", "), or you can use the ", " and ", " nodes which contain appropriate filter chains internally (", "). ", "The individual filters configurations contain a ", " which is used for debugging purposes, a ", " which is used to locate the plugin, and a ", " which is a dictionary of additional variables.  Consult the documentation for the particular filter plugin to see what variables may be set in the params field. ", "For example, in a package, ", ", to launch a ", " with two filters: ", " and ", ", you could use the file: ", "You could then push this configuration to the parameter server using ", " by running: ", "And then launching the ", ": ", "The scan_to_scan_filter_chain is a very minimal node which wraps an instance of a ", ".  This node can be used to run any filter in this package on an incoming laser scan.  If the ", " parameter is set, it will wait for the transform between the laser and the target_frame to be available before running the filter chain. ", "The scan_to_cloud_filter_chain is a very minimal node which wraps an instances of ", " and ", ".  This node can be used to run any filter in this package on an incoming laser scan.  After performing the laser filtering, it will use the ", " from ", " to transform each scan into a point cloud.  It will then run any cloud-based filtering, and finally publish the resultant cloud. ", "This filter internally makes use of the the ", " implementation of float-array filters.  It extracts the range and intensity values and treats each as an independent float array passed through an internal filter chain. ", "This filter removes laser readings that are most likely caused by the veiling effect when the edge of an object is being scanned.  For any two points ", " and ", ", we do this by computing the perpendicular angle.  That is, assuming the origin of the laser is ", ", the angle formed ", ".  If the perpendicular angle is less than a particular min or greater than a particular max, we remove all neighbors further away than that point. ", "This filter removes all measurements from the ", " which have an intensity greater than ", " or less than ", ".  These points are \"removed\" by setting the corresponding range value to ", " + 1, which is assumed to be an error case. ", "This filter removes all measurements from the ", " which are greater than ", " or less than ", ".  These points are \"removed\" by setting the corresponding range value to ", ", which is assumed to be an error case or ", "/", ". If ", " is true, the range within the laserscan message is used. ", "This filter removes points in a ", " outside of certain angular bounds by changing the minimum and maximum angle. ", "This filter removes points in a ", " inside of certain angular bounds. These points are \"removed\" by setting the corresponding range value to ", " + 1, which is assumed to be an error case. ", "This filter removes points in a ", " inside of a cartesian box. These points are \"removed\" by setting the corresponding range value to NaN which is assumed to be an error case. "], "package_tt": ["laser_filters", ".yaml", "name", "type", "params", "type", "pkg_name/FilterClass", "FilterClass", "mypkg", "LaserFilterClass1", "LaserFilterClass2", "my_laser_config.yaml", "scan_to_scan_filter_chain", "filters::FilterChain<sensor_msgs::LaserScan>", "~tf_message_filter_target_frame", "~scan_filter_chain", "~tf_message_filter_target_frame", "tf::MessageFilter", "scan", "scan_filtered", "my_laser_filter.launch", "my_laser_config.yaml", "filters::FilterChain<sensor_msgs::LaserScan>", "filters::FilterChain<sensor_msgs::PointCloud>", "LaserProjection", "~scan_filter_chain", "~cloud_filter_chain", "~target_frame", "~high_fidelity", "scan", "cloud_filtered", "my_laser_cloud_filter.launch", "my_laser_config.yaml", "my_cloud_config.yaml", "range_filter_chain", "FilterChain", "MultiChannelMedianFilterFloat", "intensity_filter_chain", "FilterChain", "MultiChannelMedianFilterFloat", "min_angle", "double", "max_angle", "double", "window", "int", "neighbors", "int", "upper_threshold", "lower_threshold", "range_max", "lower_threshold", "double", "upper_threshold", "double", "disp_histogram", "int", "upper_threshold", "lower_threshold", "NaN", "lower_replacement_value", "upper_replacement_value", "use_message_range_limits", "lower_threshold", "double", "upper_threshold", "double", "use_message_range_limits", "bool", "range_min", "range_max", "false", "lower_replacement_value", "double", "lower_threshold", "NaN", "upper_replacement_value", "double", "upper_threshold", "NaN", "lower_angle", "double", "upper_angle", "double", "range_max", "lower_angle", "double", "upper_angle", "double", "box_frame", "string", "min_x", "double", "max_x", "double", "min_y", "double", "max_y", "double", "min_z", "double", "max_z", "double"], "package_code": ["scan_filter_chain:\n", "- name: unique_name1\n", "  type: mypkg/LaserFilterClass1\n", "  params:\n", "    param1: a\n", "    param2: b\n", "- name: unique_name2\n", "  type: mypkg/LaserFilterClass2\n", "  params:\n", "    param1: a\n", "    param2: b", "$ rosparam load my_laser_config.yaml scan_to_scan_filter_chain", "$ rosrun laser_filters scan_to_scan_filter_chain", "<launch>\n", "  <node pkg=\"laser_filters\" type=\"scan_to_scan_filter_chain\"\n", "      name=\"laser_filter\">\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_laser_config.yaml\" />\n", "    <remap from=\"scan\" to=\"base_scan\" />\n", "  </node>\n", "</launch>", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1\n", "- name: dark_shadows\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 100\n", "    upper_threshold: 10000\n", "    disp_histogram: 0", "<launch>\n", "  <node pkg=\"laser_filters\" type=\"scan_to_cloud_filter_chain\"\n", "      name=\"tilt_shadow_filter\">\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_laser_config.yaml\" />\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_cloud_config.yaml\" />\n", "    <param name=\"high_fidelity\" value=\"true\" />\n", "    <param name=\"target_frame\" type=\"string\" value=\"base_link\" />\n", "    <remap from=\"scan\" to=\"tilt_scan\" />\n", "    <remap from=\"cloud_filtered\" to=\"tilt_scan_cloud_filtered\" />\n", "  </node>\n", "</launch>", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1\n", "- name: dark_shadows\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 100\n", "    upper_threshold: 10000\n", "    disp_histogram: 0", "cloud_filter_chain:\n", "- type: PR2PointCloudFootprintFilter\n", "  name: footprint_filter\n", "  params:\n", "    inscribed_radius: 0.325", "scan_filter_chain:\n", "- type: laser_filters/LaserArrayFilter\n", "  name: laser_median_filter\n", "  params:\n", "    range_filter_chain:\n", "      - name: median_5\n", "        type: filters/MultiChannelMedianFilterFloat\n", "        params:\n", "          number_of_observations: 5\n", "          unused: 10\n", "    intensity_filter_chain:\n", "      - name: median_5\n", "        type: filters/MultiChannelMedianFilterFloat\n", "        params:\n", "          number_of_observations: 5\n", "          unused: 10", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1", "scan_filter_chain:\n", "- name: interpolation\n", "  type: laser_filters/InterpolationFilter", "scan_filter_chain:\n", "- name: intensity\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 8000\n", "    upper_threshold: 100000\n", "    disp_histogram: 0", "scan_filter_chain:\n", "- name: range\n", "  type: laser_filters/LaserScanRangeFilter\n", "  params:\n", "    use_message_range_limits: false\n", "    lower_threshold: 0.3\n", "    upper_threshold: .inf\n", "    lower_replacement_value: -.inf\n", "    upper_replacement_value: .inf", "scan_filter_chain:\n", "- name: angle\n", "  type: laser_filters/LaserScanAngularBoundsFilter\n", "  params:\n", "    lower_angle: -1.57\n", "    upper_angle: 1.57", "scan_filter_chain:\n", "- name: angle\n", "  type: laser_filters/LaserScanAngularBoundsFilterInPlace\n", "  params:\n", "    lower_angle: 0.685398163\n", "    upper_angle: 0.885398163", "scan_filter_chain:\n", "- name: box\n", "  type: laser_filters/LaserScanBoxFilter\n", "  params:\n", "    box_frame: scan_link\n", "    min_x: -1.0\n", "    max_x: 1.0\n", "    min_y: -1.0\n", "    max_y: 1.0\n", "    min_z: -1.0\n", "    max_z: 1.0"]},
{"url": "https://wiki.ros.org/rosdoc_lite", "package": "rosdoc_lite", "package_summary": ["This ROS package wraps documentation tools like doxygen, sphinx,\n    and epydoc, making it convenient to generate ROS package\n    documentation.\n\n    It also generates online documentation for the ROS wiki."], "package_details": ["\n", " is a simple program that runs an external documentation tool, like ", ", ", ", or ", ", on a single ROS ", ". It was built as a light-weight replacement to the ", " tool and uses the same ", " file format to assist in porting. We recommend trying ", " instead of attempting to setup those tools manually, as it provides shortcuts for configuring those tools and can also import additional ROS information. Configuring your package to be documented by ", " also has the additional benefit of allowing your package to be indexed for inclusion on the ROS wiki. ", " makes a best effort at providing good default settings to these tools, and in some cases allows these settings to be customized further. ", " is used as part of an automated process for updating documentation on ros.org. It is frequently run on repositories that have ", " files listed in the ", " repository, with the resulting documentation linked to in the \"Code API\" link of many packages' on ", ". ", " contains some additional functionality for generating machine-readable documentation files, as well as ", "/", " documentation, that are used by the ros.org wiki system and elsewhere. This functionality is mainly only of use to those maintaining documentation Web sites. ", "\n", "\n", "\n", ": ", "\n", "\n", "\n", "\n", "\n", ": Epydoc's \"introspection\" capability currently breaks when trying to process some ros python modules, so this feature should not be enabled in a custom epydoc config file. ", "\n", "\n", "\n", " provides support for cross-referencing with external ", " documentation using tag files. For more information on using tag files with ", " to link to external documentation, see this ", ". ", "\n", "\n", " can be passed a yaml file containing a list of tagfiles with the ", " option. This yaml file should contain a list of dictionaries, where each dictionary has the following standard keys: ", "\n", "\n", " is automatically run for packages in repositories that have rosinstall files listed in the ", " repository. The resulting documentation is uploaded to ", " and is linked in the \"Code API\" links that you see on various package pages, like ", ". ", "\n", " ", "See also: ", ", ", ", and ", " ", "By default, ", " will use ", " to generate the documentation for a package. If you wish to use another tool, like ", " or ", ", you must use a rosdoc configuration file. This is described below.  For C/C++, only Doxygen is advised. ", "The documentation that is generated will depend on which tool is used, as each tool behaves differently.  For example, Doxygen will extract API details from all source files found in the package (see ", " for more). ", "You can use ", " to generate local copies of documentation. When you run the ", " command, it will generate documentation into the 'doc' folder of the local directory. ", "In order to enable the rosdoc configuration file, simply have a ", " file in the root of your package. If you wish to name it something else, you must place the following tag in the ", " section of the ", ", but this behavior is old: ", "Here is an example from the ", " package, which performs both C++ and Python API documentation: ", "The \"doxygen\" builder will enable running ", " on a package. As Doxygen is the default builder for any package, it is only necessary to configure this option if: ", "The \"epydoc\" builder will enable running ", " on a package. ", "The \"sphinx\" builder will enable running ", " on a package. ", "The \"external\" builder specifies that you wish to link to externally generated documentation. ", " will generate a landing page with the link to the specified URL. ", "To generate a tag file during a documentation run, simply pass the ", " option to rosdoc lite with a path to the desired location of the tagfile. For example: ", "Running ", " with this file to get cross references might look something like this: ", "Even if ", " is automatically generated for your package, we recommend regularly running ", " on your own computer to verify what your documentation looks like before checking it in. ", "It is also used to generate the data for the ", ", ", " and ", " wiki macros that you see on many of the ros.org wiki pages. ", "The ", " tool itself is stable, though it has many internal features and functionality that are changed to support the documentation needs of ", ". In the future, the ", " tool will hopefully be evolved to better support the configuration requirements of the documentation tools it invokes (i.e. Doxygen). ", "The code API of ", " should ", " be used as it is an internal library that is frequently changed. "], "package_tt": ["rosdoc_lite", "rosdoc.yaml", "rosdoc_lite", "rosdoc_lite", "rosdoc_lite", "rosdoc_lite", "rosdoc_lite", "wiki.ros.org", "rosdoc_lite", "msg", "srv", "rosdoc_lite", "rosdoc_lite", "doc", "doc/html/index.html", "doxygen", "sudo\u00a0apt-get\u00a0install\u00a0doxygen", "rosdoc.yaml", "<export>...</export>", "package.xml", "doxygen", "epydoc", "sphinx", "FILE_PATTERNS", "EXCLUDE", "EXCLUDE_PATTERNS", "JAVADOC_AUTOBRIEF", "NO", "MULTILINE_CPP_IS_BRIEF", "NO", "TAB_SIZE", "8", "ALIASES", "EXAMPLE_PATTERNS", "IMAGE_PATH", "EXCLUDE_SYMBOLS", "PREDEFINED", "--exclude", "--config", "index.rst", "conf.py", "index.rst", "rosdoc_lite", "rosdoc_lite", "-g", "rosdoc_lite", "-t", "rosdoc_lite", "rosdoc_lite", "ros.org", "rosdoc_lite", "rosdoc_lite", "PackageHeader", "StackHeader", "MsgSrvDoc", "rosdoc_lite", "ros.org", "rosdoc_lite", "rosdoc_lite"], "package_code": ["apt-get install ros-$ROS_DISTRO-rosdoc-lite", "Usage: rosdoc_lite [options] [package_path]\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  -q, --quiet           Suppress doxygen errors.\n", "  -o OUTPUT_DIRECTORY   The directory to write documentation to.\n", "  -t TAGFILE, --tagfile=TAGFILE\n", "                        Path to tag configuration file for Doxygen cross\n", "                        referencing support. Ex: /home/user/tagfiles_list.yaml\n", "  -g GENERATE_TAGFILE, --generate_tagfile=GENERATE_TAGFILE\n", "                        If specified, will generate a doxygen tagfile in this\n", "                        location. Ex: /home/user/tags/package.tag", "rosdoc_lite <path_of_package>", "<export>\n", "  <rosdoc config=\"rosdoc.yaml\" />\n", "</export>", " - builder: epydoc\n", "   output_dir: python\n", " - builder: doxygen\n", "   name: C++ API\n", "   output_dir: c++\n", "   file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox'", "- builder: doxygen\n", "  name: C++ API\n", "  output_dir: c++\n", "  file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox'\n", "  exclude_patterns: '*/ARDroneLib/*'", "- builder: doxygen\n", "  file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox *.md'\n", "  use_mdfile_as_mainpage: README.md", "- builder: epydoc\n", "  config: epydoc.config", "- builder: sphinx           # specify document generator. e.g) doxygen, epidoc, sphinx\n", "  sphinx_root_dir: doc      # document directory", "rosdoc_lite -o doc -g doc/tags/my_package.tag /path/to/my/package", " - docs_url: http://www.ros.org/doc/api/package_name/html\n", "   location: file:///path/to/package_name/doc/tags/package_name.tag\n", " - docs_url: http://www.ros.org/doc/api/package_name2/html\n", "   location: http://www.ros.org/doc/api/package_name2/tags/package_name2.tag", "rosdoc_lite -o doc -t /path/to/example_tags.yaml", "<export>\n", "  <doxymaker external=\"http://link.to.external/page.html\"/>\n", "</export>"]},
{"url": "https://wiki.ros.org/controller_interface", "package": "controller_interface", "package_summary": ["Interface base class for controllers"], "package_details": ["\n", "See the ", " page and the ", " for more information. "]},
{"url": "https://wiki.ros.org/slic", "package": "slic", "package_summary": ["SLIC-Superpizel ROS Wrapper\n  This file contains the class elements of the class Slic. This class is an\n  implementation of the SLIC Superpixel algorithm by Achanta et al. [PAMI'12,\n  vol. 34, num. 11, pp. 2274-2282].\n\n  This implementation is created for the specific purpose of creating\n  over-segmentations in an OpenCV-based environment."]},
{"url": "https://wiki.ros.org/jsk_apc", "package": "jsk_apc", "package_summary": ["Metapackage for Amazon Picking Challenge"]},
{"url": "https://wiki.ros.org/urdf_geometry_parser", "package": "urdf_geometry_parser", "package_summary": ["Extract geometry value of a vehicle from urdf."]},
{"url": "https://wiki.ros.org/pilz_msgs", "package": "pilz_msgs", "package_summary": ["The pilz_msgs package"]},
{"url": "https://wiki.ros.org/pr2_controllers", "package": "pr2_controllers", "package_summary": ["Contains the controllers that run in realtime on the PR2 and supporting packages."], "package_details": ["\n", "\n", "\n", "The ", " stack has the components which must run in the realtime loop of the PR2, components which communicate with the realtime controllers, and a few supporting packages.  Realtime controllers run in the ", " at a guaranteed update rate and are used for moving the mechanism and triggering sensing components.  The supporting nodes provide a more user-friendly interface to the realtime components, often providing notification on success or failure of commands. ", "A full set of controllers and supporting nodes has been configured to come up on the PR2 by default.  See ", " for instruction on how to use them. ", "Report new issues on ", " "], "package_tt": ["pr2_controllers"]},
{"url": "https://wiki.ros.org/dwb_critics", "package": "dwb_critics", "package_summary": ["Implementations for dwb_local_planner TrajectoryCritic interface"], "package_details": [" "]},
{"url": "https://wiki.ros.org/jsk_visualization", "package": "jsk_visualization", "package_summary": ["Metapackage that contains visualization package for jsk-ros-pkg"], "package_details": ["Document: ", " "]},
{"url": "https://wiki.ros.org/rqt_msg", "package": "rqt_msg", "package_summary": ["A Python GUI plugin for introspecting available ROS message types.\n  Note that the msgs available through this plugin is the ones that are stored\n  on your machine, not on the ROS core your rqt instance connects to."]},
{"url": "https://wiki.ros.org/rqt_shell", "package": "rqt_shell", "package_summary": ["rqt_shell is a Python GUI plugin providing an interactive shell."], "package_details": [" "]},
{"url": "https://wiki.ros.org/staro_moveit_config", "package": "staro_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the STARO with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/ros_environment", "package": "ros_environment", "package_summary": ["The package provides the environment variables `ROS_VERSION`, `ROS_DISTRO`, `ROS_PACKAGE_PATH`, and `ROS_ETC_DIR`."]},
{"url": "https://wiki.ros.org/velodyne_pointcloud", "package": "velodyne_pointcloud", "package_summary": ["Point cloud conversions for Velodyne 3D LIDARs."], "package_details": ["\n", ": the default ", " value is now 0.9 meters. ", ": a new pair of parameters ", " and ", " may be used to reduce the output point cloud to a subset of angular directions. By default, every angle is included in the point cloud. Setting ", " to ", " radians will limit the output to 90 degrees around the forward direction of the device (from -45 degrees to +45). Also setting ", " to ", " would return output only from the device's rear facing, instead. Similarly, setting ", " to ", " would limit output to 90 degrees around the right facing in the XY plane of the device frame of reference. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides point cloud conversions for Velodyne 3D LIDARs. For a list of all supported models refer to the ", " section. ", "The ", " describes the evolution of these interfaces.  ", "Continuously convert raw Velodyne packets into ", " messages. ", " ", "This launch file runs the cloud nodelet in the same process with the device driver. ", " The full path name of the calibration file ", " be provided. This example uses one of the package test files for calibration. ", "Continuously convert raw Velodyne packets into ", " messages. ", "Transform raw Velodyne packets into ", " messages into the ", " frame. ", " ", "This launch file runs the transform nodelet in the same process with the device driver. ", " The full path name of the calibration file ", " be provided. This example uses one of the package test files. ", "Transform raw Velodyne packets into ", " messages into the ", " frame. ", "Transform raw Velodyne packets into ", " messages into the ", " frame. ", "In two separate terminal windows, start a ", " process running the driver nodelet and the cloud nodelet, which will have zero-copy access to the raw data messages the driver publishes. ", "Start a driver nodelet with input from ", ", in the current directory. The ", " provides a full path name, as required for ", ". In another terminal, start the transform nodelet, to publish the data points transformed into the /odom frame of reference. ", "Start a ", " process for a Velodyne HDL-32E. This script runs both the driver and the point cloud conversion, providing the standard HDL-32E calibration. ", "Start another ", " for the Velodyne HDL-32E, but provide a PCAP dump file as input. ", "This script generates a YAML calibration file for use by this package from the ", " file that was provided by Velodyne with the device. ", "Read ", " from the current directory, writing the required calibration data to ", ". ", "Save generated 32E calibration data in ", ". "], "package_tt": ["~min_range", "~view_direction", "~view_width", "~view_width", "~view_direction", "view_direction", "velodyne_packets", "velodyne_points", "/velodyne", "velodyne_packets", "velodyne_points", "~model", "string", "~max_range", "double", "~min_range", "double", "~calibration", "string", "~view_direction", "double", "~view_width", "double", "CloudNodelet", "velodyne_packets", "velodyne_points", "/odom", "velodyne_packets", "velodyne_points", "frame_id", "~frame_id", "str", "tf_prefix", "~model", "string", "~max_range", "double", "~min_range", "double", "~calibration", "string", "~view_direction", "double", "~view_width", "double", "/odom", "TransformNodelet", "/odom", "/map", "velodyne_nodelet_manager", "tcpdump.pcap", "pwd", "roslaunch", "velodyne_nodelet_manager", "velodyne_nodelet_manager", "db.xml", "db.xml", "db.yaml", "my_calibration.yaml", "velodyne_pointcloud::PointXYZIR", "pcl::PointXYZI"], "package_code": ["$ rosrun nodelet nodelet standalone velodyne_pointcloud/CloudNodelet", "<launch>\n", "  <!-- start nodelet manager and driver nodelets -->\n", "  <include file=\"$(find velodyne_driver)/launch/nodelet_manager.launch\" />\n", "\n", "  <!-- start cloud nodelet -->\n", "  <include file=\"$(find velodyne_pointcloud)/launch/cloud_nodelet.launch\">\n", "    <arg name=\"calibration\"\n", "         value=\"$(find velodyne_pointcloud)/params/64e_utexas.yaml\"/>\n", "  </include>\n", "\n", "</launch>", "$ rosrun velodyne_pointcloud cloud_node _calibration:=calibration.yaml", "$ rosrun nodelet nodelet standalone velodyne_pointcloud/TransformNodelet", "<launch>\n", "  <!-- start nodelet manager and driver nodelets -->\n", "  <include file=\"$(find velodyne_driver)/launch/nodelet_manager.launch\" />\n", "\n", "  <!-- start transform nodelet -->\n", "  <include file=\"$(find velodyne_pointcloud)/launch/transform_nodelet.launch\">\n", "    <arg name=\"calibration\"\n", "         value=\"$(find velodyne_pointcloud)/params/64e_utexas.yaml\"/>\n", "  </include>\n", "</launch>", "$ rosrun velodyne_pointcloud transform_node _calibration:=calibration.yaml", "$ rosrun velodyne_pointcloud transform_node _frame_id:=/map", " $ roslaunch velodyne_driver nodelet_manager.launch ", " $ roslaunch velodyne_pointcloud cloud_nodelet.launch calibration:=~/mydata.yaml", " $ roslaunch velodyne_driver nodelet_manager.launch pcap:=$(pwd)/tcpdump.pcap ", " $ roslaunch velodyne_pointcloud transform_nodelet.launch calibration:=~/mydata.yaml", " $ roslaunch velodyne_pointcloud 32e_points.launch", " $ roslaunch velodyne_pointcloud 32e_points.launch pcap:=$(pwd)/tcpdump.pcap", " $ rosrun velodyne_pointcloud gen_calibration.py db.xml", " $ rosrun velodyne_pointcloud gen_calibration.py 32db.xml my_calibration.yaml "]},
{"url": "https://wiki.ros.org/robot_mechanism_controllers", "package": "robot_mechanism_controllers", "package_summary": ["Generic Mechanism Controller Library"], "package_details": ["\n", "\n", "The controllers in this package should not be used directly.  The controllers should instead by used via their ", " interfaces, e.g., ", ", ", ", ", ", and ", ". "]},
{"url": "https://wiki.ros.org/teleop_twist_keyboard", "package": "teleop_twist_keyboard", "package_summary": ["Generic keyboard teleop for twist robots."], "package_details": ["\n", "\n", "\n"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-teleop-twist-keyboard", "rosrun teleop_twist_keyboard teleop_twist_keyboard.py", "Reading from the keyboard  and Publishing to Twist!\n", "---------------------------\n", "Moving around:\n", "   u    i    o\n", "   j    k    l\n", "   m    ,    .\n", "\n", "q/z : increase/decrease max speeds by 10%\n", "w/x : increase/decrease only linear speed by 10%\n", "e/c : increase/decrease only angular speed by 10%\n", "anything else : stop\n", "\n", "CTRL-C to quit"]},
{"url": "https://wiki.ros.org/mapviz", "package": "mapviz", "package_summary": ["mapviz"], "package_details": ["\n", " ", "\n", "Mapviz is a ROS-based visualization tool with a plug-in system similar to ", " focused on visualization 2D data. ", "See ", " for a list of existing plugins. "]},
{"url": "https://wiki.ros.org/yoctopuce_altimeter", "package": "yoctopuce_altimeter", "package_summary": ["ROS publisher for the Yoctopuce altimeter"], "package_details": ["\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", " ", " ", "This package provides a publisher that interfaces with the yoctopuce altimeter: ", ". ", "To use, you must have the following dependencies: ", ", ", ", ", ", ", ", ", ". "], "package_tt": ["ros_cpp", "ros_py", "std_msgs", "nav_msgs", "sensor_msgs", "export\u00a0LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/yocto/cpp/api/Binaries/linux/64bits", "rosrun\u00a0yoctopuce_altimeter\u00a0yoctopuce_altimeter", "/yocto/raw", "yocto_msg", "/yocto/odom", "nav_msgs/odom"]},
{"url": "https://wiki.ros.org/prbt_ikfast_manipulator_plugin", "package": "prbt_ikfast_manipulator_plugin", "package_summary": ["The prbt_ikfast_manipulator_plugin package"]},
{"url": "https://wiki.ros.org/youbot_driver", "package": "youbot_driver", "package_summary": ["driver for the KUKA youBot robot"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains the drivers for the Kuka youBot. This is required for ", ". It is recommended to use ", " instead of this package for any real application. ", "Install the debian package using ", ": ", "This will install the code, set the permissions of the binaries, copy the config files to a set location, and install the ", " rules for the Hokuyo sensor. ", "You must set the environment variable YOUBOT_CONFIG_FOLDER_LOCATION to point to the config folder before running the package. The debian install will have put it at /opt/ros/groovy/etc/youbot_driver/config/, so set the variable to that. ", "If you do not wish to do this every time you start a new terminal, you can put that line in ", " in the home directory, ", ". That way, the variable will be defined for every terminal you start. ", "\n", "To install from source, get the package from the git repository in the typical way. First, create a folder for the package within the ", " folder of your catkin workspace. ", " to the folder, then do ", "The binaries need to have the proper capabilites to run. If they do not have the right permissions, they will be unable to communicate over Ethercat, and the drivers will not run. To set the capabilities to their proper values, use ", " on each binary: ", "If you do not wish to do this every time you start a new terminal, you can put that line in ", " in the home directory, ", ". That way, the variable will be defined for every terminal you start. ", "\n", "Finally, you should also install the ", " rules for the Hokuyo sensor. These are important for any other youBot packages which use the Hokuyo, such as ", ". These rules do two things whenever you plug in the Hokuyo: ", "To install the rules, copy the ", " file from the udev_rules folder included in the source to /etc/udev/rules.d/ ", "If you wish to confirm that the rules work, run ", " and plug in the Hokuyo. The output should reflect the fact that the port has been given read and write access and a symbolic link in ", " was created. You may also do ", "It is recommended to use ", " instead of this package for any actual application. ", "You can test the base, arm, and gripper motors by running the base_arm_gripper_test. Be sure to have the robot off the ground because it will move around some while testing the base. ", "If this fails with the message that there was no socket connection on ", " or ", ", go into the ", " config file and change ", " to ", " or ", ". "], "package_tt": ["apt-get", "udev", ".bashrc", "~/.bashrc", "src", "cd", "setcap", ".bashrc", "~/.bashrc", "udev", "/dev/sensors/hokuyo", "/dev/ttyACM0", "/dev/ttyACM1", "47-hokuyo.rules", "udevadm\u00a0monitor", "/dev/sensors/hokuyo", "eth1", "eth0", "youbot-ethercat.cfg", "EthernetDevice", "eth0", "eth1"], "package_code": ["sudo apt-get install ros-groovy-youbot-driver", "export YOUBOT_CONFIG_FOLDER_LOCATION=/opt/ros/groovy/etc/youbot_driver/config/", "git init\n", "git pull http://github.com/WPI-RAIL/youbot_driver.git", "catkin_make", "sudo setcap cap_net_raw+ep [your_catkin_workspace]/devel/lib/youbot_driver/base_arm_gripper_test\n", "sudo setcap cap_net_raw+ep [your_catkin_workspace]/devel/lib/youbot_driver/displayIpAddress", "export YOUBOT_CONFIG_FOLDER_LOCATION=[your_catkin_workspace]/src/youbot_driver/config", "sudo cp [your_catkin_workspace]/src/youbot_driver/udev_rules/47-hokuyo.rules /etc/udev/rules.d/", "ls -all /dev/sensors/hokuyo", "lrwxrw-rw- 1 root root 11 Jun 11 11:11 /dev/sensors/hokuyo -> ../ttyACM0", "rosrun youbot_driver base_arm_gripper_test", "rosrun youbot_driver displayIpAddress /dev/ttyACM0 eth1 wlan0"]},
{"url": "https://wiki.ros.org/summit_xl_gazebo", "package": "summit_xl_gazebo", "package_summary": ["Launch files and world files to start the models in gazebo"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/vision_msgs", "package": "vision_msgs", "package_summary": ["Messages for interfacing with various computer vision pipelines, such as\n    object detectors."]},
{"url": "https://wiki.ros.org/mav_comm", "package": "mav_comm", "package_summary": ["Contains messages and services for MAV communication"], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n  ", "ROS communication meta-package for Micro Aerial Vehicles (MAV) containing ", ". ", "\n"]},
{"url": "https://wiki.ros.org/message_filters", "package": "message_filters", "package_summary": ["A set of message filters which take in messages and may output those messages at a later time, based on the conditions that filter needs met."], "package_details": ["\n", " is a utility library for use with ", " and ", ". It collects commonly used message \"filtering\" algorithms into a common space.  A message filter is defined as something which a message arrives into and may or may not be spit back out of at a later point in time. ", "\n", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " ", "\n", " ", " ", "\n", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", " ", " ", "\n", " ", " ", " ", "\n", " ", " ", " ", " ", "\n", " is most useful for cases where you want to determine which filters to apply at runtime rather than compile-time. ", "\n", " ", " ", "\n", " ", " ", " ", " ", "All message filters follow the same pattern for connecting inputs and outputs.  Inputs are connected either through the filter's constructor or through the ", " method.  Outputs are connected through the ", " method. ", "For example, given two filters ", " and ", " where ", "'s output is compatible with ", "'s input, connecting foo to bar could be (in C++): ", "The signature of ", " is dependent on the definition of ", ". ", "You can register multiple callbacks with the ", " method.  They will get called in the order they are registered. ", "See also: ", " ", " ", "The ", " filter is simply a wrapper around a ROS subscription that provides a source for other filters.  The ", " filter cannot connect to another filter's output, instead it uses a ROS topic as its input. ", "See also: ", ", ", " ", "The ", " filter synchronizes incoming channels by the timestamps contained in their headers, and outputs them in the form of a single callback that takes the same number of channels.  The C++ implementation can synchronize up to 9 channels. ", "(Note: In this particular case you could use the ", " class from ", ", which essentially wraps the filtering code above.) ", "See also: ", " ", "The ", " filter guarantees that messages will be called in temporal order according to their header's timestamp.  The ", " is constructed with a specific delay which specifies how long to queue up messages before passing them through.  A callback for a message is never invoked until the messages' time stamp is out of date by at least delay. However, for all messages which are out of date by at least the delay, their callback are invoked and guaranteed to be in temporal order. If a message arrives from a time prior to a message which has already had its callback invoked, it is thrown away. ", "See also: ", " ", " ", "Given a stream of messages, the most recent N messages are cached in a ring buffer, from which time intervals of the cache can then be retrieved by the client. The timestamp of a message is determined from its ", " field. ", "In this example, the ", " stores the last 100 messages received on ", ", and ", " is called on the addition of every new message. The user can then make calls like ", " to extract part of the cache. ", "The ", " filter synchronizes incoming channels by the timestamps contained in their headers, and outputs them in the form of a single callback that takes the same number of channels.  The C++ implementation can synchronize up to 9 channels. ", "The ", " filter is templated on a policy that determines how to synchronize the channels.  There are currently two policies: ", " and ", ". ", "The ", " policy requires messages to have exactly the same timestamp in order to match.  Your callback is only called if a message has been received on all specified channels with the same exact timestamp. The timestamp is read from the ", " field of all messages (which is required for this policy). ", "The ", " policy uses ", " to match messages based on their timestamp. ", "See also: ", " ", "The ", " filter allows you to dynamically chain together multiple single-input/single-output (simple) filters.  As filters are added to it they are automatically connected together in the order they were added.  It also allows you to retrieve added filters by index. ", "It is possible to pass bare pointers in.  These will ", " be automatically deleted when Chain is destructed. "], "package_tt": ["message_filters", "connectInput()", "registerCallback()", "FooFilter", "BarFilter", "FooFilter", "BarFilter", "myCallback", "BarFilter", "registerCallbacks()", "registerCallback()", "disconnect()", "Subscriber", "Subscriber", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "callback(msg)", "TimeSynchronizer", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "callback(msg)", "M0", "M8", "void\u00a0callback(const\u00a0boost::shared_ptr<M0\u00a0const>&,\u00a0...,\u00a0const\u00a0boost::shared_ptr<M8\u00a0const>&)", "callback(msg0..\u00a0msgN)", "TimeSequencer", "TimeSequencer", "TimeSequencer", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "header", "header", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "callback(msg)", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "callback(msg)", "Cache", "my_topic", "myCallback", "cache.getInterval(start,\u00a0end)", "header", "Cache", "allow_headerless=True", "Synchronizer", "Synchronizer", "ExactTime", "ApproximateTime", "message_filters/synchronizer.h", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "callback(msg)", "M0", "M8", "void\u00a0callback(const\u00a0boost::shared_ptr<M0\u00a0const>&,\u00a0...,\u00a0const\u00a0boost::shared_ptr<M8\u00a0const>&)", "callback(msg0..\u00a0msgN)", "message_filters::sync_policies::ExactTime", "header", "message_filters/sync_policies/exact_time.h", "message_filters::sync_policies::ApproximateTime", "header", "message_filters/sync_policies/approximate_time.h", "header", "ApproximateTimeSynchronizer", "allow_headerless=True", "header.stamp", "Chain", "Chain", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)", "void\u00a0callback(const\u00a0boost::shared_ptr<M\u00a0const>&)"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rqt_gui", "package": "rqt_gui", "package_summary": ["rqt_gui provides the main to start an instance of the ROS integrated graphical user interface provided by qt_gui."], "package_details": ["\n", " upon using multiple ", " plugins has following advantages: "], "package_tt": ["rqt_gui", "rqt", "rqt", "rqt_gui"]},
{"url": "https://wiki.ros.org/chomp_motion_planner", "package": "chomp_motion_planner", "package_summary": ["chomp_motion_planner"], "package_details": ["\n", "\n", "\n", "This package implements the motion planner interface that the move_arm package requires. This interface is described in detail in the ", ". To use CHOMP, simply launch the pr2_arm_navigation_planning/launch/chomp_planning.launch file instead of any of the other planners. ", "To check out tutorials for this package, just follow the general set of Tutorials on the ", " page. Replace the launch file for OMPL with the launch file for CHOMP (the launch file for CHOMP can be found in pr2_arm_navigation_planning/launch). "]},
{"url": "https://wiki.ros.org/octomap", "package": "octomap", "package_summary": ["The OctoMap library implements a 3D occupancy grid mapping approach, providing data structures and mapping algorithms in C++. The map implementation is based on an octree. See\n  http://octomap.github.io for details."], "package_details": ["\n", "\n", "General information about OctoMap is available at ", " and in the publication ", " by A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard (Autonomous Robots Journal, 2013). ", "Please cite our paper if you use OctoMap in your research. ", "Doxygen documentation based on the latest OctoMap release is available at ", ". ", "If you want to use OctoMap in ROS, ", " and ", " provide messages, wrappers and conversion methods. ", " provides map building and serving capabilities. A visualization tool is available at ", ". ", "Report bugs or request features ", ". For questions and discussions, use the mailing list at ", " "], "package_tt": ["find_package()", "link_directories(${OCTOMAP_LIBRARY_DIRS})", "package.xml", "<rosdep\u00a0name=\"octomap\"\u00a0/>\u00a0", "stack.xml"], "package_code": ["@ARTICLE{hornung13auro,\n", "  author = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill\n", "  Stachniss and Wolfram Burgard},\n", "  title = {{OctoMap}: An Efficient Probabilistic {3D} Mapping Framework Based\n", "  on Octrees},\n", "  journal = {Autonomous Robots},\n", "  year = 2013,\n", "  url = {http://octomap.github.com},\n", "  doi = {10.1007/s10514-012-9321-0},\n", "  note = {Software available at \\url{http://octomap.github.com}}\n", "}", "sudo apt-get install ros-$ROS_DISTRO-octomap", "find_package(octomap REQUIRED)\n", "include_directories(${OCTOMAP_INCLUDE_DIRS})\n", "target_link_libraries(${OCTOMAP_LIBRARIES})", "<build_depend>octomap</build_depend>\n", "<run_depend>octomap</run_depend>"]},
{"url": "https://wiki.ros.org/slam_toolbox", "package": "slam_toolbox", "package_summary": ["This package provides a sped up improved slam karto with updated SDK and visualization and modification toolsets"], "package_details": ["\n", "The Slam Toolbox package incorporates information from laser scanners in the form of a ", " message and TF transforms from odom->base link, and creates a map 2D map of a space. This package will allow you to fully serialize the data and pose-graph of the SLAM map to be reloaded to continue mapping, localize, merge, or otherwise manipulate. We allow for SLAM Toolbox to be run in synchronous (process all valid sensor measurements, regardless of lag) and asynchronous (process valid sensors measurements on an as-possible basis) modes. ", "More information, ROS API, demos, and resources are given in the ", " page. "]},
{"url": "https://wiki.ros.org/industrial_ci", "package": "industrial_ci", "package_summary": ["This package contains CI (Continuous Integration) configuration that any ROS-powered packages can commonly use. Some notable feature:\n    "], "package_details": ["See ", ". "]},
{"url": "https://wiki.ros.org/ximea_camera", "package": "ximea_camera", "package_summary": ["ROS drivers for the ximea xiQ USB 3.0 Cameras"], "package_details": ["\n", "\n", "\n", "\n", ", which is of ROS message type ", ". This message carries all of the camera specific calibration information. ", ", which of of ROS message type ", ". This message carries the image data. ", "This software requires the Ximea Linux Software Package. See ", " for details. "], "package_tt": ["serial_no", "cam_name", "yaml_url", "exposure_time", "rect_left,\u00a0rect_top,\u00a0rect_height,\u00a0rect_width", "image_data_format", "frame_rate", "camera_param_file_paths", "camera_param_file_paths", "/camera_info", "sensor_msgs/CameraInfo", "/image_raw/", "sensor_msgs/Image"], "package_code": ["serial_no: 32301951\n", "cam_name: \"camera1\"\n", "yaml_url: \"package://mcptam/calibrations/camera1.yaml\"\n", "exposure_time: 30000\n", "rect_left: 200\n", "rect_top: 200\n", "rect_height: 600\n", "rect_width: 900\n", "image_data_format: \"XI_MONO8\"", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/swri_console", "package": "swri_console", "package_summary": ["A rosout GUI viewer developed at Southwest Research Insititute as an\n     alternative to rqt_console."]},
{"url": "https://wiki.ros.org/amcl", "package": "amcl", "package_summary": ["\n            amcl is a probabilistic localization system for a robot moving in\n            2D. It implements the adaptive (or KLD-sampling) Monte Carlo\n            localization approach (as described by Dieter Fox), which uses a\n            particle filter to track the pose of a robot against a known map.\n        ", "\n            This node is derived, with thanks, from Andrew Howard's excellent\n            'amcl' Player driver.\n        "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 100) ", "\n", " (", ", default: -1.0) ", "\n", " (", ", default: ", ") ", "\n", " transforms incoming laser scans to the odometry frame (", ").  So there must exist a path through the ", " tree from the frame in which the laser scans are published to the odometry frame.   ", " ", "To localize using laser data on the ", " topic: ", "There are three categories of ROS ", " that can be used to configure the ", " node: overall filter, laser model, and odometery model. ", "If ", " is ", " then we use the ", " from Probabilistic Robotics, p136; this model uses the noise parameters ", " through ", ", as defined in the book. ", "If ", " is ", " then we use a custom model for an omni-directional base, which uses ", " through ", ". The meaning of the first four parameters is similar to that for the ", " model. The fifth parameter capture the tendency of the robot to translate (without rotating) perpendicular to the observed direction of travel. ", "A ", " was found and fixed. But fixing the old models would have changed or broken the localisation of already tuned robot systems, so the new fixed odometry models were added as new types ", " and ", ". ", "The default settings of the ", " parameters only fit the old models, for the new model these values probably need to be a lot smaller, see ", ". ", "Also, another ", " was found but only fixed after Navigation 1.16, while the current release for Kinetic is Navigation 1.14.1. This bug only affects robot with type ", " and ", ", where ", " and ", " are actually reversed. I.e. ", " is for the translation odometry noise from robot translation-al motion, and ", " represents the odometry rotation noise from robot's rotation motion. ", "An implementation detail: on receipt of the first laser scan, ", " looks up the transform between the laser's frame and the base frame (~base_frame_id), and latches it forever.  So ", " cannot handle a laser that moves with respect to the base. ", "The drawing below shows the difference between localization using odometry and ", ". During operation ", " estimates the transformation of the base frame (~base_frame_id) in respect to the global frame (", ") but it only publishes the transform between the global frame and the odometry frame (", "). Essentially, this transform accounts for the drift that occurs using Dead Reckoning. The published transforms are ", ". "], "package_tt": ["sample_motion_model_odometry", "beam_range_finder_model", "likelihood_field_range_finder_model", "Augmented_MCL", "KLD_Sampling_MCL", "base_scan", "amcl", "amcl", "scan", "tf", "initialpose", "map", "use_map_topic", "amcl_pose", "particlecloud", "tf", "odom", "map", "global_localization", "request_nomotion_update", "set_map", "static_map", "amcl", "~min_particles", "int", "~max_particles", "int", "~kld_err", "double", "~kld_z", "double", "kld_err", "~update_min_d", "double", "~update_min_a", "double", "~resample_interval", "int", "~transform_tolerance", "double", "~recovery_alpha_slow", "double", "disabled", "~recovery_alpha_fast", "double", "disabled", "~initial_pose_x", "double", "~initial_pose_y", "double", "~initial_pose_a", "double", "~initial_cov_xx", "double", "~initial_cov_yy", "double", "~initial_cov_aa", "double", "~gui_publish_rate", "double", "~save_pose_rate", "double", "~use_map_topic", "bool", "map", "~first_map_only", "bool", "~laser_min_range", "double", "~laser_max_range", "double", "~laser_max_beams", "int", "~laser_z_hit", "double", "~laser_z_short", "double", "~laser_z_max", "double", "~laser_z_rand", "double", "~laser_sigma_hit", "double", "~laser_lambda_short", "double", "~laser_likelihood_max_dist", "double", "~laser_model_type", "string", "\"likelihood_field\"", "beam", "likelihood_field", "likelihood_field_prob", "likelihood_field", "~odom_model_type", "\"diff\"", "sample_motion_model_odometry\u00a0algorithm", "odom_alpha1", "odom_alpha4", "~odom_model_type", "\"omni\"", "odom_alpha1", "odom_alpha5", "\"diff\"", "\"diff-corrected\"", "\"omni-corrected\"", "odom_alpha", "\"omni\"", "\"omni-corrected\"", "odom_alpha1", "odom_alpha4", "odom_alpha1", "odom_alpha4", "~odom_model_type", "string", "\"diff\"", "\"diff\"", "\"omni\"", "\"diff-corrected\"", "\"omni-corrected\"", "~odom_alpha1", "double", "~odom_alpha2", "double", "~odom_alpha3", "double", "~odom_alpha4", "double", "~odom_alpha5", "double", "\"omni\"", "~odom_frame_id", "string", "\"odom\"", "~base_frame_id", "string", "\"base_link\"", "~global_frame_id", "string", "\"map\"", "~tf_broadcast", "bool", "false", "amcl", "~odom_frame_id", "amcl", "amcl", "amcl", "amcl", "~global_frame_id", "~odom_frame_id"], "package_code": ["amcl scan:=base_scan"]},
{"url": "https://wiki.ros.org/safe_teleop_stage", "package": "safe_teleop_stage", "package_summary": ["Launch files for running safe_teleop_base on pr2"]},
{"url": "https://wiki.ros.org/joy_listener", "package": "joy_listener", "package_summary": ["Translates joy msgs"]},
{"url": "https://wiki.ros.org/ros_numpy", "package": "ros_numpy", "package_summary": ["A collection of conversion function for extracting numpy arrays from messages"], "package_details": ["See the ", " on github for a quick usage summary. "]},
{"url": "https://wiki.ros.org/turtlebot3_navigation", "package": "turtlebot3_navigation", "package_summary": ["The turtlebot3_navigation provides roslaunch scripts for starting the navigation."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides parameters from ", " in ", " directory. "], "package_code": ["<arg name=\"scan_topic\"     default=\"scan\"/>     # topic name for the sensor values from \n", "                                                  the distance sensor\n", "<arg name=\"initial_pose_x\" default=\"0.0\"/>      # initial x-coordinate value\n", "<arg name=\"initial_pose_y\" default=\"0.0\"/>      # initial y-coordinate value\n", "<arg name=\"initial_pose_a\" default=\"0.0\"/>      # initial yaw coordinate value\n", "\n", "#---- execute the amcl node by referring to the parameter settings below. ----#\n", "\n", "<node pkg=\"amcl\" type=\"amcl\" name=\"amcl\">\n", "\n", "<param name=\"min_particles\" value=\"500\"/>         # min number of particles allowed\n", "<param name=\"max_particles\" value=\"3000\"/>        # max number of particles allowed\n", "<param name=\"kld_err\"       value=\"0.02\"/>        # max error between the actual distribution \n", "                                                    and the estimated distribution\n", "<param name=\"update_min_d\" value=\"0.2\"/>          # translational motion required for filter \n", "                                                    update (meter)\n", "<param name=\"update_min_a\" value=\"0.2\"/>          # rotational motion required for filter \n", "                                                    update (radian) \n", "<param name=\"resample_interval\" value=\"1\"/>       # resampling interval \n", "<param name=\"transform_tolerance\" value=\"0.5\"/>   # conversion allowed time (by sec) \n", "<param name=\"recovery_alpha_slow\" value=\"0.0\"/>   # index drop rate(slow average weight \n", "                                                    filter), deactivated if 0.0 \n", "<param name=\"recovery_alpha_fast\" value=\"0.0\"/>   # index drop rate(fast average weight \n", "                                                    filter), deactivated if 0.0 \n", "<param name=\"initial_pose_x\" value=\"$(arg initial_pose_x)\"/>  # refer to above initial_pose_x \n", "<param name=\"initial_pose_y\" value=\"$(arg initial_pose_y)\"/>  # refer to above initial_pose_y \n", "<param name=\"initial_pose_a\" value=\"$(arg initial_pose_a)\"/>  # refer to above initial_pose_a \n", "<param name=\"gui_publish_rate\" value=\"50.0\"/>     # max period to visually displaying scan and                                                    path info \n", "<param name=\"use_map_topic\" value=\"$(arg use_map_topic)\"/>    # same as the explanation for                                                                   use_map_topic \n", "\n", "#---------------------- distance sensor parameter --------------------------#\n", "\n", "<remap from=\"scan\" to=\"$(arg scan_topic)\"/>       # change the sensor topic name \n", "<param name=\"laser_max_range\" value=\"3.5\"/>       # max distance of laser sensing distance \n", "<param name=\"laser_max_beams\" value=\"180\"/>       # max number of laser beams used during \n", "                                                    filter update \n", "<param name=\"laser_z_hit\" value=\"0.5\"/>           # z_hit mixed weight of sensor model   \n", "<param name=\"laser_z_short\" value=\"0.05\"/>        # z_short mixed weight of sensor model   \n", "<param name=\"laser_z_max\" value=\"0.05\"/>          # z_max mixed weight of sensor model  \n", "<param name=\"laser_z_rand\" value=\"0.5\"/>          # x_rand mixed weight of sensor model   \n", "<param name=\"laser_sigma_hit\" value=\"0.2\"/>       # standard deviation of Gaussian model \n", "                                                    using z_hit of sensor\n", "<param name=\"laser_lambda_short\" value=\"0.1\"/>    # index drop rate parameter for z_short \n", "                                                    of sensor \n", "<param name=\"laser_likelihood_max_dist\" value=\"2.0\"/>     # max distance and obstacle for \n", "                                                            likelihood_field method sensor \n", "<param name=\"laser_model_type\" value=\"likelihood_field\"/> # select likelihood_field or beam \n", "\n", "#---------------------- parameter related to odometry --------------------------#\n", "\n", "<param name=\"odom_model_type\"value=\"diff\"/>       # robot driving methods. \"diff\" or \"omni\" can be selected\n", "<param name=\"odom_alpha1\" value=\"0.1\"/>           # estimated rotational motion noise of \n", "                                                    the odometry during rotational motion\n", "<param name=\"odom_alpha2\" value=\"0.1\"/>           # estimated rotational motion noise of \n", "                                                    the odometry during translation motion\n", "<param name=\"odom_alpha3\" value=\"0.1\"/>           # estimated translation motion noise of \n", "                                                    the odometry during translation motion \n", "<param name=\"odom_alpha4\" value=\"0.1\"/>           # estimated translation motion noise of \n", "                                                    the odometry during rotational motion  \n", "<param name=\"odom_frame_id\" value=\"odom\"/>             # odometry frame \n", "<param name=\"base_frame_id\" value=\"base_footprint\"/>   # robot base frame ", "base_local_planner_params.yaml              # The parameter of the speed command to the robot\n", "costmap_common_params_burger.yaml           # The parameter of costmap configuration consists\n", "costmap_common_params_waffle.yaml           # The parameter of costmap configuration consists\n", "costmap_common_params_waffle_pi.yaml        # The parameter of costmap configuration consists\n", "dwa_local_planner_params.yaml               # The parameter of the speed command to the robot\n", "global_costmap_params.yaml                  # The parameter of the global area motion planning\n", "local_costmap_params.yaml                   # The parameter of the local area motion planning\n", "move_base_params.yaml                       # parameter setting file of move_base that \n", "                                              supervises the motion planning."]},
{"url": "https://wiki.ros.org/xpp_quadrotor", "package": "xpp_quadrotor", "package_summary": ["The URDF file for a quadrotor to be used with the xpp packages and a \n    simple rviz publisher of quadrotor tfs.\n     \n    Adapted from Daniel Mellinger, Nathan Michael, Vijay Kumar, \n    \"Trajectory Generation and Control for Precise Aggressive Maneuvers\n    with Quadrotors\"."], "package_details": ["\n ", " "]},
{"url": "https://wiki.ros.org/rqt_plot", "package": "rqt_plot", "package_summary": ["rqt_plot provides a GUI plugin visualizing numeric values in a 2D plot using different plotting backends."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", ". ", " curve is not supported either. ", " ", "Also if you're on Ubuntu and like to know the most recommended plotting result, simply get a ", " file of ", " ", ", which is not available via ", ". And run it by something like: ", "There are two ways to give the topic names to ", " as explained in following sections. In both ways, topics that are set in previous run is resumed (as far as the program was shut down without error). ", "Type in the \"Topic\" input field the full path of the topic name, and press \"+\" button. ", " ", "The input value should be the full path to the value, not only the topic name. E.g., in above case the topic ", " is a member \"x\" in a published topic \"/turtle1/pose\", which is defined as ", ". ", "New short example to show this; say you want to plot a topic called position ", " of ", " topic, which is a type of ", " message. This can be plotted by ", ". Possiblly you can figure out this plot name by following steps like this: ", "Currently ", " has three plotting backend options (", ") which can be configured using the setting dialog available via the gear icon in the window title bar: ", "By default, backend option is chosen in the order above; the first one found on your system gets used (eg. if your system has ", " but not ", ", your ", " runs with the ", "). ", "See ", ". "], "package_tt": [".deb", "pyqtgraph", "rosdep", "rqt_plot", "/turtle1/pose/x", "x", "/your_robot/pose", "/your_robot/pose/position/x", "position", "geometry_msgs/Point", "x", "geometry_msgs/Point", "rqt_plot", "pyqtgraph", "Ubuntu", "qwt\u00a0plot", "matplotlib", "pyqtgraph", "rqt_plot", "matplotlib", "topic"], "package_code": ["$ sudo apt-get install ros-$ROS_DISTRO-rqt\n", "$ sudo apt-get install ros-$ROS_DISTRO-rqt-common-plugins", "$ rosdep install rqt_plot", "$ dpkg -i %NAME_OF_DOT_DEB_FILE%.deb", "$ rqt_plot", "$ rostopic list\n", "/rosout         #  these are only example topics.\n", "/rosout_agg\n", "/turtle1/cmd_vel\n", "/turtle1/color_sensor\n", "/turtle1/pose", "$ rqt_plot /turtle1/pose/x:y:z\n", "$ rqt_plot /turtle1/pose/x /turtle1/pose/y /turtle1/pose/z"]},
{"url": "https://wiki.ros.org/rosabridge", "package": "rosabridge", "package_summary": ["Metapackage for core of rosabridge."], "package_details": ["\n", " ", " "]},
{"url": "https://wiki.ros.org/yocs_keyop", "package": "yocs_keyop", "package_summary": ["Keyboard teleoperation for your robot"]},
{"url": "https://wiki.ros.org/rqt_gui_cpp", "package": "rqt_gui_cpp", "package_summary": ["rqt_gui_cpp enables GUI plugins to use the C++ client library for ROS."]},
{"url": "https://wiki.ros.org/rqt_graph", "package": "rqt_graph", "package_summary": ["rqt_graph provides a GUI plugin for visualizing the ROS\n      computation graph.", "\n      Its components are made generic so that other packages\n      where you want to achieve graph representation can depend upon this pkg\n      (use ", " to find out\n      the pkgs that depend. rqt_dep itself depends on rqt_graph too)."], "package_details": ["\n", " ", " is the successor of ", ". ", "\n", " ", " and ", " can measure certain statistics for every topic connection (see ", " for more details. This has to be enabled beforehand through: ", "\n", " ", "Note: rqt_graph currently does not automatically update the statistics annotations. You have to hit the ", " button to update them. "], "package_tt": ["rqt_graph", "Refresh"], "package_code": ["$ rosparam set enable_statistics true"]},
{"url": "https://wiki.ros.org/mrpt_rbpf_slam", "package": "mrpt_rbpf_slam", "package_summary": ["This package is used for gridmap SLAM. The interface is similar to gmapping (http://wiki.ros.org/gmapping) but the package supports different particle-filter algorithms, range-only SLAM, can work with several grid maps simultaneously and more."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "The sections below describe the API of the package. The interface is similar to gmapping (", ") but the package supports different particle filter algorithms, range-only SLAM and can work with several grid maps simultaneously. ", "This package supports the following Particle Filter SLAM algorithms (more details at ", "): ", "These algorithms allow building ", ". ", "The ROS node ", " is a wrapper for the C++ class", ", part of MRPT. Check out the documentation of this class for further details. ", "This node has been designed to provide an interface similar to that of ", " for the convenience of users who already know this package. ", "The coordinate frames are implemented according to the convention ", ". ", "In order to use mrpt_rbpf_slam package it is necessary to install the latest ", " build and the ", " (see also the ", "). Additionally, it is possible to install ", " simulator which allows to make simulations with RBPF SLAM. "], "package_tt": ["mrpt_rbpf_slam", "mrpt_rbpf_slam", "tf", "scan", "beacon", "particlecloud_beacons", "map", "particlecloud", "beacon_viz", "~global_frame_id", "string", "\"map\"", "~base_frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~sensor_source", "string", "\"scan\"", "\"scan\"", "\"beacon\"", "~ini_filename", "string", "~rawlog_filename", "string", "~rawlog_play_delay", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["roslaunch mrpt_rbpf_slam rbpf_slam.launch", "roslaunch mrpt_rbpf_slam rbpf_slam_rawlog.launch", "roslaunch mrpt_rbpf_slam rbpf_slam_rawlog.launch example:=2", "roslaunch mrpt_rbpf_slam ro_slam.launch", "roslaunch mrpt_rbpf_slam ro_slam_rawlog.launch", "roslaunch mrpt_rbpf_slam mvsim_slam.launch"]},
{"url": "https://wiki.ros.org/ros_control", "package": "ros_control", "package_summary": ["A set of packages that include controller interfaces, controller managers, transmissions and hardware_interfaces."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ros_control packages are a rewrite of the ", " packages to make controllers generic to all robots beyond just the PR2. ", "A high-level overview of the project can be found in the ROScon 2014 talk entitled ", " (", ", ", "). ", "A short summary of CombinedRobotHW can be found in ", " ROScon 2016 talk. ", "Additional documentation is available at the ", " ", "A list of available controller plugins, contained in ", ", as of this writing. You can of course create your own and are not limited to the below list. All controllers use the ", " to send commands to a hardware interface. ", "Take a look at the ", " to understand how the joint_trajectory_controller is namespaced with the position_controller, velocity_controller, etc. ", "Also refer to the ", " of the hardware_interface and the ", ". ", "From the above it can be seen that power remains constant between input and output. Complementary ", " (first part will do). ", "See ", ". ", "Transmission-specific code (not robot-specific) implementing bidirectional (actuator <-> joint) effort and flow maps under a uniform interface shared across transmission types. This is hardware-interface-agnostic. A list of available transmission types as of this writing: ", "See ", " ", "The ", " contains data structures for representing joint limits, methods for populating them from common formats such as URDF and rosparam, and methods for enforcing limits on different kinds of joint commands. ", "The joint_limits_interface is not used by controllers themselves (it does not implement a ", ") but instead operates after the controllers have updated, in the ", " method (or equivalent) of the robot abstraction. Enforcing limits will ", " the commands set by the controllers, it does not operate on a separate raw data buffer. ", "See ", " ", "Or on Ubuntu and other platforms from source. To ease installing from source a ", " file is provided: ", "Not exactly a roadmap, but this ", " contains discussion and proposed solutions to allow ros_control to better accommodate more complex control setups and address shortcomings in the current implementation. ", "A ", " exists with a mailing list for discussing ros_control issues and features. You are encouraged to join and help with ros_control's development! "], "package_code": ["@article{ros_control,\n", "author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\\\"u}dtke, Mathias and Fern{\\'a}ndez Perdomo, Enrique},\n", "title = {ros\\_control: A generic and simple control framework for ROS},\n", "journal = {The Journal of Open Source Software},\n", "year = {2017},\n", "doi = {10.21105/joss.00456},\n", "URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}\n", "}", "P_in        = P_out\n", "\n", "F_in x V_in = F_out x V_out", "effort map: F_joint = F_actuator * n\n", "\n", "flow map:   V_joint = V_actuator / n", "sudo apt-get install ros-$ROS_DISTRO-ros-control ros-$ROS_DISTRO-ros-controllers", "cd CATKIN_WORKSPACE/src\n", "wstool init\n", "wstool merge https://raw.github.com/ros-controls/ros_control/$ROS_DISTRO-devel/ros_control.rosinstall\n", "wstool update\n", "cd ..\n", "rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO -y\n", "catkin_make"]},
{"url": "https://wiki.ros.org/rosflight_sim", "package": "rosflight_sim", "package_summary": ["Software-in-the-loop (SIL) simulator for the ROSflight firmware"], "package_details": ["\n", "This package provides a Gazebo plugin for software-in-the-loop (SIL) simulations with the ", ". "]},
{"url": "https://wiki.ros.org/mrpt_local_obstacles", "package": "mrpt_local_obstacles", "package_summary": ["Maintains a local obstacle map (point cloud,\n   voxels or occupancy grid) from recent sensor readings within a\n   configurable time window."], "package_details": ["\n", "\n", "\n", "\n", " ", "This demo requires ", ". It simulates one robot with 2 laser scanners and builds and publish the local obstacle maps to ", ": "], "package_tt": ["local_map_pointcloud", "odom", "~frameid_reference", "string", "\"odom\"", "~frameid_robot", "string", "\"base_link\"", "~source_topics_2dscan", "string", "\"scan,laser1\"", "~topic_local_map_pointcloud", "string", "\"local_map_pointcloud\"", "~time_window", "double", "~publish_period", "double", "~show_gui", "bool", "<value\u00a0of\u00a0~frameid_robot>\u00a0(typ:\u00a0", ")", "<each\u00a0sensor\u00a0frameid>\u00a0(typ:\u00a0", ",\u00a0etc)", "<value\u00a0of\u00a0~frameid_reference>\u00a0(typ:\u00a0", ")", "<value\u00a0of\u00a0~frameid_robot>\u00a0(typ:\u00a0", ")", "/local_map_pointcloud"], "package_code": ["roslaunch mrpt_local_obstacles demo_with_mvsim.launch"]},
{"url": "https://wiki.ros.org/rqt_common_plugins", "package": "rqt_common_plugins", "package_summary": ["rqt_common_plugins metapackage provides ROS backend graphical tools suite that can be used on/off of robot runtime.", "\n    ", "\n    To run any rqt plugins, just type in a single command \"rqt\", then select any plugins you want from the GUI that launches afterwards.", "\n    ", "\n    rqt consists of three following metapackages:", "\n    "], "package_details": [". ", "\n", "\n", "See ", ". "]},
{"url": "https://wiki.ros.org/kinesis_video_streamer", "package": "kinesis_video_streamer", "package_summary": ["Kinesis Video Streams producer node"], "package_details": ["\n", ": Amazon Kinesis Video Streams makes it easy to securely stream video from connected ", "devices to AWS for analytics, machine learning (ML), playback, and other processing. Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions ", "of devices. It also durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. Kinesis Video Streams enables you to playback video for live and on-demand ", "viewing, and quickly build applications that take advantage of computer vision and video analytics through integration with Amazon Recognition Video, and libraries for ML frameworks such as Apache Mx", "Net, Tensor", "Flow, and Open", "CV. ", ": The easy-to-use Rekognition API allows you to automatically identify objects, people, text, scenes, and activities, as well as detect any inappropriate content. Developers can quickly build a searchable ", "content library to optimize media workflows, enrich recommendation engines by extracting text in images, or integrate secondary authentication into existing applications to enhance end-user security. With a wide variety of use ", "cases, Amazon Rekognition enables you to easily add the benefits of computer vision to your business. ", ": ROS, AWS, Kinesis Video Streams ", "\n", "\n", "The Amazon Kinesis Video Streams ROS package enables robots to stream video to the cloud for analytics, playback, and archival use. Out of the box, the nodes provided make it possible to encode & stream image data (e.g. video feeds and LIDAR scans) ", "from a ROS \u201cImage\u201d topic to the cloud, enabling you to view the live video feed through the Kinesis Video Console, consume the stream via other applications, or perform intelligent analysis, face detection and face recognition ", "using Amazon Rekognition. ", "The node will transmit standard ", " data from ROS topics to Kinesis Video streams, optionally encoding the images as h264 video frames along the way (using the included h264_video_encoder), ", "and optionally fetches Amazon Rekognition results from corresponding Kinesis Data Streams and publishing them to local ROS topics. ", "The source code is released under ", ". "], "package_tt": ["sensor_msgs/Image", "codec", "Keywords"]},
{"url": "https://wiki.ros.org/octovis", "package": "octovis", "package_summary": ["octovis is visualization tool for the OctoMap library based on Qt and libQGLViewer. See\n  http://octomap.github.io for details."], "package_details": ["octovis provides visualization for ", " based on Qt and libQGLViewer. ", "octovis is available in the ", " debian package. As an alternative, you can download the package yourself from ", " and compile it with the library stand-alone or against a locally installed ", " library. ", "This will install OctoMap and octovis as stand-alone libraries with no ROS dependencies, so they can be also used in a non-ROS setting. ", "Use GitHub to ", ". For questions and discussions, check the ", ". "], "package_tt": ["ros-$ROS_DISTRO-octomap"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-octovis"]},
{"url": "https://wiki.ros.org/jackal_base", "package": "jackal_base", "package_summary": ["Jackal's mobility and sensor base."], "package_details": ["\n", "\n", "This package contains the primary binary which runs on ", ", providing the ", "-based comms to the MCU, as well as diagnostic support, and other basic services. ", "Jackal includes a built-in magnetometer, which is used by ", " to estimate orientation. To calibrate the magnetometer using scripts provided by this package, see ", ". "]},
{"url": "https://wiki.ros.org/mavros_msgs", "package": "mavros_msgs", "package_summary": ["mavros_msgs defines messages for ", "."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/pgm_learner", "package": "pgm_learner", "package_summary": ["Parameter/Structure Estimation and Inference for Bayesian Belief Network"]},
{"url": "https://wiki.ros.org/multisense_ros", "package": "multisense_ros", "package_summary": ["multisense_ros"]},
{"url": "https://wiki.ros.org/rosbaglive", "package": "rosbaglive", "package_summary": ["Plays rosbags as though they were happening NOW."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/rqt_launchtree", "package": "rqt_launchtree", "package_summary": ["An RQT plugin for hierarchical launchfile configuration introspection."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "In case you want to make sure that you get the latest updates and fixes, the source repository is available on ", " and can be checked out by running (in the /src folder of your workspace): ", "If you are using ROS Kinetic, you will need to switch the branch first. This is required because ", " has been replaced by ", ", which has a few different bindings. "], "package_code": ["sudo apt-get install ros-indigo-rqt-launchtree", "git clone https://github.com/pschillinger/rqt_launchtree.git \n", "cd ..\n", "catkin_make", "git checkout kinetic"]},
{"url": "https://wiki.ros.org/laser_geometry", "package": "laser_geometry", "package_summary": ["This package contains a class for converting from a 2D laser scan as defined by\n    sensor_msgs/LaserScan into a point cloud as defined by sensor_msgs/PointCloud\n    or sensor_msgs/PointCloud2. In particular, it contains functionality to account\n    for the skew resulting from moving robots or tilting laser scanners."], "package_details": ["\n", "\n", "\n", " To convert a ", " to a ", " ", "\n", " To convert a ", " to a ", " in the base_link frame, using a high fidelity transform: ", "\n", "\n", "\n", "The laser_geometry package contains a single C++ class: ", ".  There is no ROS API. ", "This class has two relevant functions for transforming from ", " to ", " or ", ". ", "Both of these functions have a final optional argument that augments the ", " which is created to include extra channels.  These channels may include intensities, distances, timestamps, the index or thew viewpoint from the original laser array. ", "There is a simple Python implementation here (", "). ", "The method ", " does the simplest possible projection of the laser.  Each ray is simply projected out along the appropriate angle according to: ", "The appropriate sine and cosine values are cached, making this a very efficient operation.  However, the generated ", " is in the same frame as the original ", ". While this has the advantage that it does not require an instance of a ", " or message notifier, it does not hold up in situations where the laser is moving and skew needs to be accounted for. ", "Please consult the ", " for full usage details. ", "The ", " method does a more advanced projection, but requires that you have set up a ", " transform listener. (If you are unfamiliar with ", ", it is recommended you go through the ", " first.) ", "Because the stamp of a ", " is the time of the ", " measurement, one cannot simply wait for a transform ", "to target_frame at this stamp. Instead one also has to wait for a transform at the ", " measurement of the scan. ", "Please consult the ", " for full usage details.  ", "The method ", " projects a single laser scan from a linear array into a 3D ", ". The generated cloud will be in the same frame as the original laser scan. "], "package_tt": ["projectLaser()", "transformLaserScanToPointCloud()", "projectLaser()", "tf::transformer", "transformLaserScanToPointCloud()", "projectLaser()"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/mbf_abstract_core", "package": "mbf_abstract_core", "package_summary": ["This package provides common interfaces for navigation specific robot actions. It contains the AbstractPlanner, AbstractController and AbstractRecovery plugin interfaces. This interfaces have to be implemented by the plugins to make the plugin available for Move Base Flex. The abstract classes provides a meaningful interface enabling the planners, controllers and recovery behaviors to return information, e.g. why something went wrong. Derivided interfaces can, for example, provide methods to initialize the planner, controller or recovery with map representations like costmap_2d, grid_map or other representations."]},
{"url": "https://wiki.ros.org/xpp_vis", "package": "xpp_vis", "package_summary": ["Visualization for the XPP Motion Framework."], "package_details": ["\n ", " "]},
{"url": "https://wiki.ros.org/xpp", "package": "xpp", "package_summary": ["Visualization of motion-plans for legged robots. It draws support areas, \n    contact forces and motion trajectories in RVIZ and displays URDFs for \n    specific robots, including a one-legged, a two-legged hopper and\n    ", ". \n    Example motions were generated by\n    ", "."], "package_details": ["\n ", " ", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "Also you can always clone the repo into your catkin workspace and build from source, as described ", ". ", "The more involved example trajectories shown have been generated with ", ", an optimizer for legged robot motions. However, simple motion plans can also be generated by hand as shown below. This example is taken from ", ". Run it using  ", "Then simply right-click on ", " and ", " -> ", ". ", "Or load the rosbag in ", " ", "To visualize your own URDF is very easy to setup. A minimal example to follow can be seen here:", ". ", "We would be happy to see a ", " to add your robot. Apart from benefitting the open-source community, this also adds publicity and visibility to you / your lab. The ROS page you can then design for your robot could look similar to this: ", ". ", "This software has been used in the following ", ": ", "Please post any questions you have at ", " using the tag ", ". "], "package_tt": ["xpp/state_des", "View", "Plot", "xpp"], "package_code": ["$ sudo apt-get install ros-kinetic-xpp\n", "$ roslaunch xpp_examples hyq_bag.launch", "$ roslaunch xpp_examples monoped_ex_generate.launch ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ roscd xpp_examples/bags/\n", "$ rqt_bag hyq.bag ", "\n", "\n", "@misc{xpp_ros,\n", "  author = {Alexander W. Winkler},\n", "  title  = {{Xpp - A collection of ROS packages for the visualization of legged robots}},\n", "  year   = {2017},\n", "  doi    = {10.5281/zenodo.1037901},\n", "  url    = {https://doi.org/10.5281/zenodo.1037901}\n", "}"]},
{"url": "https://wiki.ros.org/pose_cov_ops", "package": "pose_cov_ops", "package_summary": ["C++ library for SE(2/3) pose and 2D/3D point\n    composition operations with uncertainty"], "package_details": ["\n", "\n", "\n", "See the C++ API documentation for the namespace ", ". ", "This module provides implementations for the ", " between poses (", ",", ",", ") and points (", "), which are the following (using the \"o plus\" and \"o minus\" notation): "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/naoqi_driver", "package": "naoqi_driver", "package_summary": ["Driver module between Aldebaran's NAOqiOS and ROS. It publishes all sensor and actuator data as well as basic diagnostic for battery, temperature. It subscribes also to RVIZ simple goal and cmd_vel for teleop."], "package_details": ["\n", "This package provides a bridge between ROS and ", ". It is the officially supported by  Aldebaran. The package is based on C++ implementation of the former python edition ", ".  ", "All documentation can be found on ", ". "]},
{"url": "https://wiki.ros.org/cl_transforms", "package": "cl_transforms", "package_summary": ["Homogeneous transform library for Common Lisp."]},
{"url": "https://wiki.ros.org/zeroconf_jmdns_suite", "package": "zeroconf_jmdns_suite", "package_summary": ["An implementation of zeroconf in pure java."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package compiles the ", " sources and includes a convenience class for interfacing jmdns with ros. Jmdns is a 100% java implementation of the ", " standard. ", "It is currently being used and tested for android devices, however it is perfectly ok to use (and we may extend it more fully later) for pc implementations. ", "Jmdns has a multi-homed interface (JmmDNS) which could almost be used directly, but it is still experimental - there are a few catches, broken api and a bit of black magic. To make the library easier to use and to interface it with ros, it also provides ", " class. ", "This package also includes three demo programs in ", ", to help quickly experiment with this package. "], "package_code": ["sudo apt-get install avahi-utils", "> avahi-browse _ros-master._tcp", "./build/install/jmdns_tutorials/bin/jmdns_tutorials --publisher", "> avahi-publish -s DudeMaster _ros-master._tcp 8882", "./build/install/jmdns_tutorials/bin/jmdns_tutorials --polling", "./build/install/jmdns_tutorials/bin/jmdns_tutorials --discovery"]},
{"url": "https://wiki.ros.org/yocs_safety_controller", "package": "yocs_safety_controller", "package_summary": ["A controller ensuring the safe operation of your robot.\n\n    The SafetyController listens to ranger readings in order to stop (and move back), if obstacles get to close.\n\n    This controller can be enabled/disabled."]},
{"url": "https://wiki.ros.org/dwb_plugins", "package": "dwb_plugins", "package_summary": ["Standard implementations of the GoalChecker\n      and TrajectoryGenerators for dwb_local_planner"], "package_details": [" "]},
{"url": "https://wiki.ros.org/joint_state_publisher", "package": "joint_state_publisher", "package_summary": ["This package contains a tool for setting and publishing joint state values for a given URDF."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "This package publishes ", " messages for a robot.  The package reads the ", " parameter from the ", ", finds all of the non-fixed joints and publishes a JointState message with all those joints defined. ", "This package can be used in conjunction with the ", " node to also publish transforms for all joint states. ", "There are four possible sources for the value of each JointState: ", "Set the ", " parameter, see below. ", "This is can be specified through the ", " parameter or the ", " tag in the ", ". ", "The default value is zero. If zero is not a permissible value ", " is used. To override the default value for some joints, use the ", " parameter. An example YAML file is seen below. ", "The following YAML snippets show examples of how to set the ", " and the ", " parameters using YAML syntax. These can be loaded to the parameter server using the ", " in a launch file. "], "package_tt": ["groovy-devel", "robot_description", "joint_state_publisher", "joint_state_publisher_gui", "use_gui", "joint_state_publisher", "joint_state_publisher_gui", "joint_state_publisher_gui", "<exec_depend>", "joint_state_publisher_gui", "joint_state_publisher", "use_gui", "source_list", "dependent_joints", "mimic", "zeros", "dependent_joints", "zeros"], "package_code": ["dependent_joints:\n", "  joint_D: {parent: joint_A, factor: 3 }\n", "  joint_E: {parent: joint_B }\n", "  joint_F: {parent: joint_C, factor: -1 }", "zeros:\n", "  joint_A: 1.57\n", "  joint_B: 0.785"]},
{"url": "https://wiki.ros.org/qt_gui_py_common", "package": "qt_gui_py_common", "package_summary": ["qt_gui_py_common provides common functionality for GUI plugins written in Python."]},
{"url": "https://wiki.ros.org/openrtm_ros_bridge", "package": "openrtm_ros_bridge", "package_summary": ["openrtm_ros_bridge package provides basic functionalities to bind\n    two robotics framework: ", " and ROS.", "\n    By using this package, you can write your ROS packages that communicate with your\n    non-ROS robots that run on OpenRTM.\n  \t\t\n    For communicating with the robots that run on hrpsys, you can use\n    ", " package."], "package_details": ["Documentation is available ", ". "]},
{"url": "https://wiki.ros.org/pr2_counterbalance_check", "package": "pr2_counterbalance_check", "package_summary": ["pr2_counterbalance_check"], "package_details": ["\n", "The ", " package contains utilities for checking the counterbalance of the PR2. It is used by the production testing systems, and can be run onboard a PR2. "], "package_tt": ["pr2_counterbalance_check"]},
{"url": "https://wiki.ros.org/marker_msgs", "package": "marker_msgs", "package_summary": ["The marker_msgs package contains messages usable to setup a marker/fiducial system. \n    The package distinguishes between two types of messages. \n    First messages to describe the properties of a marker/fiducial detection system and the detected markers. \n    Secondly messages used to represent a map of markers/features with covariances as it would be produced by a SLAM system or published by a map server for self-localization."], "package_details": ["\n", " ", "\n", " ", "With the help of the ", " the msgs can be visualized in rviz. "]},
{"url": "https://wiki.ros.org/jsk_interactive_marker", "package": "jsk_interactive_marker", "package_summary": ["jsk interactive markers"]},
{"url": "https://wiki.ros.org/visualization_tutorials", "package": "visualization_tutorials", "package_summary": ["Metapackage referencing tutorials related to rviz and visualization."], "package_details": ["\n", "\n", "  ", "This is the stack that provides the code for the ", " "]},
{"url": "https://wiki.ros.org/pmb2_description", "package": "pmb2_description", "package_summary": ["Mechanical, kinematic, visual, etc. description of the PMB2 robot.\n      The files in this package are parsed and used by\n      a variety of other components.  Most users will not interact directly\n      with this package."]},
{"url": "https://wiki.ros.org/video_stream_opencv", "package": "video_stream_opencv", "package_summary": ["The video_stream_opencv package contains a node to publish a video stream (the protocols that\n    opencv supports are supported, including rtsp, webcams on /dev/video and video files) in ROS image topics, it supports camera info and basic image flipping (horizontal, vertical or both) capabilities, also adjusting publishing rate."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "A package to view video streams based on the ", ", easy way to publish on a ROS Image topic (including camera info) usb cams, ethernet cameras, video streams or video files. It also supports flipping of images and fps throttling. ", "Example usages in launch folder (only the argument ", " is mandatory): ", "So if you want the very latest image published from a camera, set ", " to 1, ", " to the max the camera allows and ", " to that same max. ", "If you want to publish all images (don't drop any and you don't mind some possible delay from real time), set ", " big enough for your case (1000?), ", " and ", " to whatever FPS it has. ", "If you want to test quickly if your desired input may work with this node you can use a simple python script called ", " which just tries to open the video resource (no ROS involved, just copy the file to your computer and try). ", "Just do any of those: "], "package_tt": ["video_stream_provider", "/dev/videoX", "/dev/video0", "rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov", "myvideo.avi", "set_camera_fps", "CV_CAP_PROP_FPS", "buffer_queue_size", "fps", "buffer_queue_size", "set_camera_fps", "fps", "buffer_queue_size", "set_camera_fps", "fps", "video_stream_provider", "camera_name", "frame_id", "camera_info_url", "flip_horizontal", "flip_vertical", "loop_videofile", "loop_videofile", "true", "width", "height"], "package_code": ["<launch>\n", "   <!-- launch video stream -->\n", "   <include file=\"$(find video_stream_opencv)/launch/camera.launch\" >\n", "        <!-- node name and ros graph name -->\n", "        <arg name=\"camera_name\" value=\"webcam\" />\n", "        <!-- means video device 0, /dev/video0 -->\n", "        <arg name=\"video_stream_provider\" value=\"0\" />\n", "        <!-- set camera fps to (if the device allows) -->\n", "        <arg name=\"set_camera_fps\" value=\"30\"/>\n", "        <!-- set buffer queue size of frame capturing to -->\n", "        <arg name=\"buffer_queue_size\" value=\"100\" />\n", "        <!-- throttling the querying of frames to -->\n", "        <arg name=\"fps\" value=\"30\" />\n", "        <!-- setting frame_id -->\n", "        <arg name=\"frame_id\" value=\"webcam\" />\n", "        <!-- camera info loading, take care as it needs the \"file:///\" at the start , e.g.:\n", "        \"file:///$(find your_camera_package)/config/your_camera.yaml\" -->\n", "        <arg name=\"camera_info_url\" value=\"\" />\n", "        <!-- flip the image horizontally (mirror it) -->\n", "        <arg name=\"flip_horizontal\" value=\"false\" />\n", "        <!-- flip the image vertically -->\n", "        <arg name=\"flip_vertical\" value=\"false\" />\n", "        <!-- visualize on an image_view window the stream generated -->\n", "        <arg name=\"visualize\" value=\"true\" />\n", "   </include>\n", "</launch>", "rosrun video_stream_opencv test_video_resource.py 0\n", "rosrun video_stream_opencv test_video_resource.py rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\n", "rosrun video_stream_opencv /home/youruser/myvideo.mkv", "Trying to open resource: /dev/video0\n", "Correctly opened resource, starting to show feed."]},
{"url": "https://wiki.ros.org/xmlrpcpp", "package": "xmlrpcpp", "package_summary": ["XmlRpc++ is a C++ implementation of the XML-RPC protocol. This version is\n    heavily modified from the package available on SourceForge in order to\n    support roscpp's threading model. As such, we are maintaining our\n    own fork."]},
{"url": "https://wiki.ros.org/pmb2_simulation", "package": "pmb2_simulation", "package_summary": ["PMB2-specific simulation components. These include plugins\n               and launch scripts necessary for running PMB2 in simulation."]},
{"url": "https://wiki.ros.org/pr2_calibration_controllers", "package": "pr2_calibration_controllers", "package_summary": ["The pr2_calibration_controllers package contains the controllers\n     used to bring all the joints in the PR2 to a calibrated state."], "package_details": [" "]},
{"url": "https://wiki.ros.org/jsk_rviz_plugins", "package": "jsk_rviz_plugins", "package_summary": ["The jsk_rviz_plugins package"], "package_details": ["Document: ", " "]},
{"url": "https://wiki.ros.org/mavlink", "package": "mavlink", "package_summary": ["MAVLink message marshaling library.\n  This package provides C-headers and C++11 library\n  for both 1.0 and 2.0 versions of protocol.\n\n  For pymavlink use separate install via rosdep (python-pymavlink)."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/rosflight", "package": "rosflight", "package_summary": ["Package for interfacing to the ROSflight autopilot firmware over MAVLink"], "package_details": ["\n", "\n", "\n", " ", "\n", " ", "ROSflight provides a simple, low-latency interface between a flight controller running the ROSflight firmware and ROS. ROSflight can stream both sensor data and motor commands at high speed. ROSflight is written to work with a variety of airframes, including multirotor and fixed-wing aircraft. The ROSflight package provided the interface for autopilots, but does not include any control code. For examples of autopilots using ROSflight, see ", " or ", ". For documentation on the firmware, see ", ". "], "package_tt": ["command", "mode", "ignore", "aux_command", "type_array", "values", "external_attitude", "external_attitude", "attitude", "airspeed", "attitude", "attitude/euler", "baro", "battery", "gnss", "gnss_raw", "imu/data", "imu/temperature", "magnetometer", "navsat_compat/fix", "navsat_compat/time_reference", "time", "navsat_compat/vel", "linear", "output_raw", "rc_raw", "rosflight_errors", "sonar", "status", "unsaved_params", "version", "named_value/int/<name>", "named_value/float/<name>", "param_get", "param_set", "param_write", "param_save_to_file", "param_load_from_file", "calibrate_imu", "calibrate_rc_trim", "calibrate_baro", "calibrate_airspeed", "reboot", "reboot_to_bootloader", "~port", "string", "~baud_rate", "int", "~frame_id", "string", "~udp", "bool", "~bind_host", "string", "~bind_port", "int", "~remote_host", "string", "~remote_port", "int"], "package_code": ["$ rosrun rosflight rosflight_io _port:=/dev/ttyUSB0"]},
{"url": "https://wiki.ros.org/multi_object_tracking_lidar", "package": "multi_object_tracking_lidar", "package_summary": ["ROS package for Multiple objects detection, tracking and classification from LIDAR scans/point-clouds"], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", " (", ") ", " ", "PCL based ROS package to Detect/Cluster --> Track --> Classify static and dynamic objects in real-time from LIDAR scans implemented in C++. ", "Follow the steps below to use this (", ") package: ", "If all went well, the ROS node should be up and running! As long as you have the point clouds published on to the ", " rostopic, you should see outputs from this node published onto the ", ", ", ", ", ", \u2026, ", " topics along with the markers on ", " topic which you can visualize using RViz. ", "1. ", " "], "package_tt": ["multi_object_tracking_lidar", "src", "cd\u00a0~/catkin_ws/src", "git\u00a0clone\u00a0https://github.com/praveen-palanisamy/multiple-object-tracking-lidar.git", "cd\u00a0~/catkin_ws\u00a0&&\u00a0catkin_make", "source\u00a0~/catkin_ws/devel/setup.bash", "kf_tracker", "rosrun\u00a0multi_object_tracking_lidar\u00a0kf_tracker", "filtered_cloud", "obj_id", "cluster_0", "cluster_1", "cluster_5", "viz"], "package_code": ["@software{praveen_palanisamy_2019_3559187,\n", "  author       = {Praveen Palanisamy},\n", "  title        = {{praveen-palanisamy/multiple-object-tracking-lidar:\n", "                   Multiple-Object-Tracking-from-Point-Clouds_v1.0.2}},\n", "  month        = dec,\n", "  year         = 2019,\n", "  publisher    = {Zenodo},\n", "  version      = {1.0.2},\n", "  doi          = {10.5281/zenodo.3559187},\n", "  url          = {https://doi.org/10.5281/zenodo.3559186}\n", "}"]},
{"url": "https://wiki.ros.org/jsk_pepper_startup", "package": "jsk_pepper_startup", "package_summary": ["The jsk_pepper_startup package"]},
{"url": "https://wiki.ros.org/rqt_robot_monitor", "package": "rqt_robot_monitor", "package_summary": ["rqt_robot_monitor displays diagnostics_agg topics messages that\n   are published by ", ".\n   rqt_robot_monitor is a direct port to rqt of\n   ", ". All\n   diagnostics are fall into one of three tree panes depending on the status of\n   diagnostics (normal, warning, error/stale). Status are shown in trees to\n   represent their hierarchy. Worse status dominates the higher level status.", "\n   "]},
{"url": "https://wiki.ros.org/pepper_meshes", "package": "pepper_meshes", "package_summary": ["meshes for the Aldebaran Robotics Pepper"]},
{"url": "https://wiki.ros.org/joystick_drivers", "package": "joystick_drivers", "package_summary": ["This metapackage depends on packages for interfacing common\n    joysticks and human input devices with ROS."], "package_details": ["\n", "\n", " "]},
{"url": "https://wiki.ros.org/sbg_driver", "package": "sbg_driver", "package_summary": ["ROS driver package for communication with the SBG navigation systems."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "  "], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-sbg-driver", "roslaunch sbg_driver sbg_device.launch", "roslaunch sbg_driver sbg_device_mag_calibration.launch", "# Configuration of the device with ROS.\n", "confWithRos: true", "sudo adduser $USER dialout", "$ roslaunch sbg_driver sbg_device_mag_calibration.launch\n", "$ rosservice call /sbg/mag_calibration\n", "// Proceed rotations on the IMU\n", "$ rosservice call /sbg/mag_calibration\n", "// If the magnetic calibration results are satisfaying, it could be uploaded\n", "$ rosserive call /sbg/mag_calibration_save"]},
{"url": "https://wiki.ros.org/mbf_abstract_nav", "package": "mbf_abstract_nav", "package_summary": ["The mbf_abstract_nav package contains the abstract navigation server implementation of Move Base Flex (MBF). The abstract navigation server is not bound to any map representation. It provides the actions for planning, controlling and recovering. MBF loads all defined plugins at the program start. Therefor, it loads all plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions."]},
{"url": "https://wiki.ros.org/rqt_console", "package": "rqt_console", "package_summary": ["rqt_console provides a GUI plugin for displaying and filtering ROS messages."], "package_details": [" ", "\n", " is a viewer in the ", " package that displays messages being published to ", ".  It collects messages over time, and lets you view them in more detail, as well as allowing you to filter messages by various means. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Sending messages to ", " is done differently in each client library: ", ", ", " ", "Assuming you have ROS installed, you can invoke ", " by just typing: ", "The list view shows all of the messages, updating in real time as they arrive.  The list displays all the information in the ", " message broadcast on ", ": ", "There are two operations you can use on the items in the list.  A ", " will bring up all the information about that message in a separate box. ", "A ", " will pop up a menu allowing you to filter the list based on some aspect of the selected message  ", "See the ", " page. It will help you use ", " to publish error, info and debug messages and view them in rqt_console. "], "package_tt": ["rqt_console", "rqt_console", "rqt_console", "/u/jfaust/ros/base/pkgs/ros_tutorials/roscpp_tutorials/talker/talker.cpp:main:92"], "package_code": ["rqt_console"]},
{"url": "https://wiki.ros.org/json_transport", "package": "json_transport", "package_summary": ["JSON transport for ROS"]},
{"url": "https://wiki.ros.org/pr2_gripper_action", "package": "pr2_gripper_action", "package_summary": ["The pr2_gripper_action provides an action interface for using the\n  gripper. Users can specify what position to move to (while limiting the\n  force) and the action will report success when the position is reached or\n  failure when the gripper cannot move any longer."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Users interested in grasping more delicate objects may want to checkout the alternative ", " package. ", "You can see an example of using the pr2 gripper action on the PR2 in the ", ". ", "The ", " provides more context on how the ", " and how ", ". "], "package_tt": ["~goal_threshold", "double", "~stall_timeout", "double", "~stall_velocity_threshold", "double", "~gripper_action/goal", "~gripper_action/cancel", "~gripper_action/status", "action", "~gripper_action/result", "~state", "~command"]},
{"url": "https://wiki.ros.org/novatel_gps_driver", "package": "novatel_gps_driver", "package_summary": ["Driver for NovAtel receivers"]},
{"url": "https://wiki.ros.org/pcl_ros", "package": "pcl_ros", "package_summary": ["PCL (Point Cloud Library) ROS interface stack. PCL-ROS is the preferred\n  bridge for 3D applications involving n-D Point Clouds and 3D geometry\n  processing in ROS."], "package_details": ["\n", "\n", " includes several ", " packaged as ROS nodelets. These links provide details for using those interfaces: ", "\n", " extends the ROS ", " to support message passing with ", " native data types. Simply add the following include to your ROS node source code: ", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "This header allows you to publish and subscribe ", " objects as ROS messages. These appear to ROS as ", " messages, offering seamless interoperability with non-PCL-using ROS nodes. For example, you may publish a ", " in one of your nodes and visualize it in ", " using a ", ". It works by hooking into the ", " infrastructure. ", "The old format ", " is not supported in PCL. ", "You may publish PCL point clouds using the standard ", ": ", "You may likewise subscribe to PCL point clouds using the standard ", ": ", "Read messages from the ", " topic in ", ", saving a PCD file for each message into the ", " subdirectory. ", "Read the point cloud in <cloud.pcd> and publish it in ROS image messages at 5Hz. ", "Subscribe to the ", " topic and republish each message on the ", " topic. ", "To view the images created by the previous command, use ", ". ", "Publish the contents of ", " once in the ", " frame of reference. ", "Publish the contents of ", " approximately ten times a second in the ", " frame of reference. ", "Subscribe to the ", " topic and save each message in the current directory. File names look like ", ", the exact names depending on the message time stamps. ", "Set the ", " parameter in the current namespace, save messages to files with names like ", ". ", "We have more examples on ", " page "], "package_tt": ["pcl_ros", "pcl_ros", "pcl::PointCloud<T>", "ros::Publisher", "ros::Subscriber", "/laser_tilt_cloud", "data.bag", "./pointclouds", "output", "input", "output", "/my_cloud", "/my_image", "cloud_pcd", "~frame_id", "str", "point_cloud_file.pcd", "/base_link", "cloud_file.pcd", "/odom", "prefix", ".pcd", "input", "~prefix", "str", "~fixed_frame", "str", "~binary", "bool", "~compressed", "bool", "/velodyne/pointcloud2", "1285627014.833100319.pcd", "prefix", "/tmp/pcd/vel_1285627015.132700443.pcd"], "package_code": ["#include <pcl_ros/point_cloud.h>", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " $ rosrun pcl_ros bag_to_pcd <input_file.bag> <topic> <output_directory>", " $ rosrun pcl_ros bag_to_pcd data.bag /laser_tilt_cloud ./pointclouds", " $ rosrun pcl_ros convert_pcd_to_image <cloud.pcd>", " $ rosrun pcl_ros convert_pointcloud_to_image input:=/my_cloud output:=/my_image", " $ rosrun image_view image_view image:=/my_image", " $ rosrun pcl_ros pcd_to_pointcloud <file.pcd> [ <interval> ]", " $ rosrun pcl_ros pcd_to_pointcloud point_cloud_file.pcd", " $ rosrun pcl_ros pcd_to_pointcloud cloud_file.pcd 0.1 _frame_id:=/odom", " $ rosrun pcl_ros pointcloud_to_pcd input:=/velodyne/pointcloud2", " $ rosrun pcl_ros pointcloud_to_pcd input:=/my_cloud _prefix:=/tmp/pcd/vel_"]},
{"url": "https://wiki.ros.org/joint_limits_interface", "package": "joint_limits_interface", "package_summary": ["Interface for enforcing joint limits."], "package_details": ["\n", "See the ", " page and the ", " for more information. "]},
{"url": "https://wiki.ros.org/zivid_camera", "package": "zivid_camera", "package_summary": ["Driver for using the Zivid 3D cameras in ROS."], "package_details": ["\n", "For more information about the zivid_camera ROS driver, read the ", ". "]},
{"url": "https://wiki.ros.org/xpp_states", "package": "xpp_states", "package_summary": ["Common definitions (positions, velocities, angular angles,\n    angular rates) and robot definitions in Cartesian and joint state\n    used in the Xpp Motion Framework, as well as conversions to/from\n    xpp_msgs."], "package_details": ["\n ", " ", "\n", "\n", "\n", "\n", "This package provides two ways to describe an articulated robot state, one in cartesian (=task) space, the other in joint (=configuration) space. Each of these states has a corresponding ROS message ", ", where conversion function are provided in ", ".  ", "\n", "In this representation (", "), the robot is described by the position, velocity and acceleration of it's endeffectors and the Cartesian force they exert. ", "In this representation (", ") the endeffector state is only indirectly given through the joint values. Instead of forces acting on the endeffectors, this state equivalently represents this as torques acting on the joints. ", "The core difference between the above representations is how the articulated limbs and the force they exert are described (task or joint space). In order to make these states most interchangeable, we create a class (", ") that parameterizes each endeffector. This can be done in two ways: "], "package_tt": ["convert.h"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/jackal_bringup", "package": "jackal_bringup", "package_summary": ["Scripts for installing Jackal's robot software."], "package_details": ["\n", "See ", " for information on Jackal configurations. "]},
{"url": "https://wiki.ros.org/libuvc_camera", "package": "libuvc_camera", "package_summary": ["USB Video Class camera driver"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", " ", " ", "This package provides a ROS interface for digital cameras meeting the USB Video Class standard (UVC) using ", ". Most webcams are UVC-compliant. ", "Under Linux, the user that runs camera_node must have write permissions to the ", " device that corresponds to the camera. You may run the node as root: ", "However, use of ", " rules is recommended. In ", ", to give every user camera access: ", "Alternatively, set ", " to grant access for any user in that group. ", "You may need to disable your operating system's builtin USB video or audio drivers. On Linux, the ", " and ", " modules conflict with libuvc. Try unloading them with ", " and consider blacklisting them -- e.g., add the lines ", " and ", " to an ", " file. (Applications that don't use libuvc will be unable to stream from the camera.) "], "package_tt": ["/dev/bus/usb/...", "/etc/udev/rules.d/99-uvc.rules", "GROUP=\"mygroup\"", "snd-usb-audio", "uvcvideo", "sudo\u00a0rmmod\u00a0snd-usb-audio;\u00a0sudo\u00a0rmmod\u00a0uvcvideo", "blacklist\u00a0uvcvideo", "blacklist\u00a0snd-usb-audio", "/etc/modprobe.d/uvc.conf"], "package_code": ["$ sudo -E rosrun libuvc_camera camera_node vendor:=...", "   lsusb -v", "# UVC cameras\n", "SUBSYSTEMS==\"usb\", ENV{DEVTYPE}==\"usb_device\", ATTRS{idVendor}==\"046d\", ATTRS{idProduct}==\"08cc\", MODE=\"0666\"\n", "# ^ Change the vendor and product IDs to match your camera.", "# UVC cameras\n", "SUBSYSTEMS==\"usb\", ENV{DEVTYPE}==\"usb_device\", ATTRS{idVendor}==\"046d\", ATTRS{idProduct}==\"08cc\", OWNER=\"myuser\"\n", "# ^ Change the owner and the vendor and product IDs to match your camera.", "#UVC cameras\n", "SUBSYSTEMS==\"usb\", ATTRS{idVendor}==\"046d\", MODE=\"0666\"", "sudo chmod o+w /dev/bus/usb/001/024 <-- where 024 is port# from the error code", "   v4l2-ctl --list-formats-ext", "<launch>\n", "  <group ns=\"camera\">\n", "    <node pkg=\"libuvc_camera\" type=\"camera_node\" name=\"mycam\">\n", "      <!-- Parameters used to find the camera -->\n", "      <param name=\"vendor\" value=\"0x0\"/>\n", "      <param name=\"product\" value=\"0x0\"/>\n", "      <param name=\"serial\" value=\"\"/>\n", "      <!-- If the above parameters aren't unique, choose the first match: -->\n", "      <param name=\"index\" value=\"0\"/>\n", "\n", "      <!-- Image size and type -->\n", "      <param name=\"width\" value=\"640\"/>\n", "      <param name=\"height\" value=\"480\"/>\n", "      <!-- choose whichever uncompressed format the camera supports: -->\n", "      <param name=\"video_mode\" value=\"uncompressed\"/> <!-- or yuyv/nv12/mjpeg -->\n", "      <param name=\"frame_rate\" value=\"15\"/>\n", "\n", "      <param name=\"timestamp_method\" value=\"start\"/> <!-- start of frame -->\n", "      <param name=\"camera_info_url\" value=\"file:///tmp/cam.yaml\"/>\n", "\n", "      <param name=\"auto_exposure\" value=\"3\"/> <!-- use aperture_priority auto exposure -->\n", "      <param name=\"auto_white_balance\" value=\"false\"/>\n", "    </node>\n", "  </group>\n", "</launch>"]},
{"url": "https://wiki.ros.org/virtual_force_publisher", "package": "virtual_force_publisher", "package_summary": ["publish end effector's force, which is estmated from joint torque value"]},
{"url": "https://wiki.ros.org/multi_map_server", "package": "multi_map_server", "package_summary": ["multi_map_server provides the"], "package_tt": ["map_server", "map_saver"]},
{"url": "https://wiki.ros.org/mrpt_slam", "package": "mrpt_slam", "package_summary": ["mrpt_slam"], "package_details": ["\n", "\n", "\n", "  ", "See also: ", ", ", " "], "package_code": ["# This will install all packages in the mrpt_slam metapackage\n", "# Alternatively, install individual packages only as you need them\n", "sudo apt-get install ros-$ROS_DISTRO-mrpt-slam"]},
{"url": "https://wiki.ros.org/moveit_ros_perception", "package": "moveit_ros_perception", "package_summary": ["Components of MoveIt! connecting to perception"]},
{"url": "https://wiki.ros.org/cl_utils", "package": "cl_utils", "package_summary": ["Common Lisp utility libraries"]},
{"url": "https://wiki.ros.org/youbot_simulation", "package": "youbot_simulation", "package_summary": ["Packages to run the KUKA youBot in the Gazebo simulation with ROS"]},
{"url": "https://wiki.ros.org/imagesift", "package": "imagesift", "package_summary": ["For every image, computes its sift features and send a new message with the image, its intrinsic parameters, and the features.\n    Parameters include:\n    display - shows the image on the local computer"]},
{"url": "https://wiki.ros.org/joy_mouse", "package": "joy_mouse", "package_summary": ["The joy_mouse package"]},
{"url": "https://wiki.ros.org/moveit_planners", "package": "moveit_planners", "package_summary": ["Metapacakge that installs all available planners for MoveIt"]},
{"url": "https://wiki.ros.org/move_base_msgs", "package": "move_base_msgs", "package_summary": ["Holds the action description and relevant messages for the move_base package"], "package_details": ["\n", "\n", "\n", "This package contains the messages used to communicate with the ", " node. These messages are auto-generated from the ", " action specification. For more information on actions see ", ", for more information on the ", " node see ", ". ", "The ", " is the goal that the navigation stack attempts to achieve. The ", " given as feedback is the current position of the base in the world as reported by ", ". For the ", " node, the ", " is projected into the XY plane with the Z axis pointing up when attempting to achieve a goal. "], "package_tt": ["MoveBase.action", "target_pose", "base_position", "target_pose"], "package_code": ["geometry_msgs/PoseStamped target_pose\n", "---\n", "---\n", "geometry_msgs/PoseStamped base_position"]},
{"url": "https://wiki.ros.org/mbf_simple_nav", "package": "mbf_simple_nav", "package_summary": ["The mbf_simple_nav package contains a simple navigation server implementation of Move Base Flex (MBF). The simple navigation server is bound to no map representation. It provides actions for planning, controlling and recovering. MBF loads all defined plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions. \n\n        It tries to load the defined plugins which implements the defined interfaces in ", "."]},
{"url": "https://wiki.ros.org/py_trees", "package": "py_trees", "package_summary": ["Pythonic implementation of behaviour trees."], "package_details": ["\n", " ", "Get started at the ", " for the project. ", "If using this in ROS 1, see also ", ", ", ", ", " "]},
{"url": "https://wiki.ros.org/vision_opencv", "package": "vision_opencv", "package_summary": ["Packages for interfacing ROS with OpenCV, a library of programming functions for real time computer vision."], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", "The ", " stack provides packaging of the popular OpenCV library for ROS. For information about the OpenCV library, please see the OpenCV main page at ", " ", "links to complete documentation for OpenCV, as well as other OpenCV resources (like the bug tracker on ", ") ", "In order to use ROS with OpenCV, please see the ", " package. ", "Since Indigo, there is a package for OpenCV3. Information about it is detailed at ", ". "], "package_tt": ["vision_opencv", "vision_opencv"], "package_code": ["   find_package(OpenCV)\n", "   include_directories(${OpenCV_INCLUDE_DIRS})\n", "   target_link_libraries(my_awesome_library ${OpenCV_LIBRARIES})", "   find_package(OpenCV 2 REQUIRED)"]},
{"url": "https://wiki.ros.org/pointgrey_camera_driver", "package": "pointgrey_camera_driver", "package_summary": ["Point Grey camera driver based on libflycapture2."], "package_details": [" ", "\n", "\n", "\n", "\n", "When multiple Point Grey cameras are in use at a time, specify the serial number given by ", ": ", "Until better documentation is produced, please see the ", " file for the available parameters.  ", "When using Point Grey's GigE cameras, you may experience an issue with dropped packets which results in ", " being thrown by the FlyCapture2 SDK. You can adjust the receive buffer settings in Linux using ", " to correct this. See ", " for more details. ", "Similarly, multiple USB cameras may require raising the amount of memory allocated to the USB subsystem.  The usbcore variable ", " should be set suitably large. ", " describes two common ways of setting it, via the kernel command line (edit ", "), or module loading (", " for current session, or adding ", " to an appropriate ", " file).  It should also be settable at runtime via ", " "], "package_tt": ["list_cameras", "IMAGE_CONSISTENCY_ERROR", "sysctl", "usbfs_memory_mb", "/boot/grub.conf", "modprobe\u00a0usbcore\u00a0usbfs_memory_mb=1024", "options\u00a0usbcore\u00a0usbfs_memory_mb=1000", "/etc/modprobe.d", "/sys/module/usbcore/parameters/usbfs_memory_mb"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-pointgrey-camera-driver", "rosrun pointgrey_camera_driver list_cameras", "roslaunch pointgrey_camera_driver bumblebee.launch\n", "roslaunch pointgrey_camera_driver camera.launch", "roslaunch pointgrey_camera_driver camera.launch camera_serial:=12345678"]},
{"url": "https://wiki.ros.org/xbot_safety_controller", "package": "xbot_safety_controller", "package_summary": ["A controller ensuring the safe operation of Xbot.\n\n    The SafetyController keeps track of bumper, cliff and wheel drop events. In case of the first two,\n    Xbot is commanded to move back. In the latter case, Xbot is stopped.\n    \n    This controller can be enabled/disabled.\n    The safety states (bumper pressed etc.) can be reset. WARNING: Dangerous!"]},
{"url": "https://wiki.ros.org/roslint", "package": "roslint", "package_summary": ["CMake lint commands for ROS packages.\n\n    The lint commands perform static checking of Python or C++ source\n    code for errors and standards compliance."], "package_details": ["\n", "\n", "\n", "You might also check ", " for checking package configuration. ", "Add a ", " dependency on roslint to your package's ", ":  ", "In your package's ", " file, include roslint as one of your catkin component dependencies: ", "Then, invoke the roslint functions from your ", ", eg: ", "To run roslint against your package you must invoke catkin_make with your package's roslint target. For example, for a package named ", " you would run: ", "Each ", " function create a catkin build target called ", ", which runs all specified lint operations for the package. Each additionally creates (if it does not yet exist) a master ", " target, which depends on all other ", " targets. ", "To fix basic whitespace issues in C++, try using ", ". Example invocation within your package: ", "For similar fixes in Python, try ", ". Example: "], "package_tt": ["package.xml", "CMakeLists.txt", "CMakeLists.txt", "my_fancy_package", "roslint_*", "roslint_''pkgname''", "roslint", "roslint_*", "roslint_cpp([files\u00a0...])", "cpp", "h", "roslint_python([files\u00a0...])", "py", "roslint_custom(linter\u00a0linter_opts\u00a0file\u00a0[...])", "roslint_add_test()"], "package_code": ["<build_depend>roslint</build_depend>", "find_package(catkin REQUIRED COMPONENTS roslint ...)", "roslint_cpp()", "roslint_cpp(src/foo.cpp src/bar.cpp src/baz.cpp)", "catkin_make roslint_my_fancy_package", "catkin build my_fancy_package --make-args roslint", "cd ~/catkin_ws\n", "catkin build\n", "cd build/my_fancy_package\n", "make roslint", "sudo apt-get install astyle\n", "find -regextype egrep -regex '.*\\.[ch](pp)?$' -exec astyle '{}' --style=allman --indent=spaces=2 --pad-oper --unpad-paren --pad-header --convert-tabs \\;", "sudo pip install pep8ify\n", "pep8ify -nw .", "set(ROSLINT_CPP_OPTS \"--filter=-runtime/references,-runtime/int\")\n", "roslint_cpp()\n", "set(ROSLINT_PYTHON_OPTS \"--max-line-length=180\")\n", "roslint_python()", "// There's just no other way; I don't control the location of this header.\n", "#include \"my_silly_header.h\"  // NOLINT(build/include)"]},
{"url": "https://wiki.ros.org/easy_markers", "package": "easy_markers", "package_summary": ["Python library to assist in publishing markers easily"], "package_details": ["\n", " ", "\n", " "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/image_geometry", "package": "image_geometry", "package_summary": ["`image_geometry` contains C++ and Python libraries for interpreting images\n    geometrically. It interfaces the calibration parameters in sensor_msgs/CameraInfo\n    messages with OpenCV functions such as image rectification, much as cv_bridge\n    interfaces ROS sensor_msgs/Image with OpenCV data types."], "package_details": ["\n", " contains Python and C++ libraries that simplifies interpreting images geometrically using the parameters from ", ". Although ", " contains all the information required to rectify a raw image and project points onto it, ", ", since performing these operations correctly over the space of all camera options can be non-trivial. ", "\n", "\n", "\n", "The camera parameters in ", " are for a full-resolution image; region-of-interest alone significantly complicates the creation of rectification maps and requires adjusting the projection matrix. Adding options such as subsampling (binning) to ", " would further complicate the correct interpretation of the corresponding Images. Using ", " simplifies and future-proofs imaging code. ", "The ", " classes are written to be used in an ", "/", " message callback similar to ", ". ", "In order to maintain invariance, the ", " classes offer read-only access to specific parameters and matrices. Setting a ", " can only be performed with full information using the ", " functions. ", "Please see the ", " documentation. ", "Please see the ", " documentation. "], "package_tt": ["CameraInfo", "CameraInfo", "CameraInfo", "image_geometry", "image_geometry", "Image", "CameraInfo", "CameraModel", "CameraModel", "fromCameraInfo()"]},
{"url": "https://wiki.ros.org/jsk_pcl_ros", "package": "jsk_pcl_ros", "package_summary": ["ROS nodelets for pointcloud perception."], "package_details": ["\n", "\n", "Documentation is available ", ". ", "Use github issue to report ", " or ", ".  "]},
{"url": "https://wiki.ros.org/peppereus", "package": "peppereus", "package_summary": ["The pepper_bringup package"]},
{"url": "https://wiki.ros.org/combined_robot_hw_tests", "package": "combined_robot_hw_tests", "package_summary": ["The combined_robot_hw_tests package"]},
{"url": "https://wiki.ros.org/jsk_baxter_desktop", "package": "jsk_baxter_desktop", "package_summary": ["The jsk_baxter_desktop package"]},
{"url": "https://wiki.ros.org/qt_create", "package": "qt_create", "package_summary": ["Provides templates and scripts for creating qt-ros packages\n     (similar to roscreate-pkg).", "Currently we're installing a simple script, ", " to the global bin directory. In the future we may move this to a rosdistro independant python package. ", "Refer to the ", " tutorials for an example on how to use it and details on the kind of package template it generates.  "], "package_tt": ["roscreate-pkg", "/usr/local/bin", "ROS", "Qt\u00a0Creator", "qt_ros", "Qt\u00a0Creator", "Qt", "qt_ros", "pkg", "Qt\u00a0Creator", "ROS\u00a0pkg", "Qt\u00a0Creator", "ROS", "project", "Qt\u00a0Creator", "ROS", "Qt", "Qt\u00a0Creator", "CMakeLists.txt", "Qt\u00a0Creator", "Qt", "Makefile", "cmake", "rosmake", "cmake", "Qt\u00a0Creator", "Makefile", "%PKG_TOP%/resources/images.qrc", "%PKG_TOP%/resources/", "Qt", "images.qrc", "catkin_create_qt_pkg"], "package_code": ["> rosrun qt_create roscreate-qt-pkg my_package_foo", "> roscd qt_create\n", "# The following will ask for your password (sudo)\n", "> make install\n", "# To remove\n", "> make uninstall"]},
{"url": "https://wiki.ros.org/key_teleop", "package": "key_teleop", "package_summary": ["A text-based interface to send a robot movement commands"], "package_details": [" ", "\n", " ", "\n", "\n"], "package_tt": ["key_vel"]},
{"url": "https://wiki.ros.org/apriltag_ros", "package": "apriltag_ros", "package_summary": ["A ROS wrapper of the AprilTag 3 visual fiducial detection\n    algorithm. Provides full access to the core AprilTag 3 algorithm's\n    customizations and makes the tag detection image and detected tags' poses\n    available over ROS topics (including tf). The core AprilTag 3 algorithm is\n    extended to allow the detection of tag bundles and a bundle calibration\n    script is provided (bundle detection is more accurate than single tag\n    detection). Continuous (camera image stream) and single image detector nodes\n    are available."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", " ", "The behavior of the ROS wrapper is fully defined by the two configuration files ", " (which defines the tags and tag bundles to look for) and ", " (which configures the core AprilTag 2 algorithm itself). Then, the following topics are output: ", "The ", " teach you how to operate the wrapper. The main idea is to fill out ", " with the standalone tags and tag bundles which you would like to detect (bundles potentially require a calibration process) and ", " with the wrapper and AprilTag 2 core parameters. Then, you simply run the continuous or single image detector. The tutorials walk you through how to do this. ", "While this ROS wrapper is original code originating from the author's master thesis, the core AprilTag 2 algorithm in ", " is wholly the work of the ", " at The University of Michigan. If you use this package, please kindly cite: "], "package_tt": ["/camera/image_rect", "/camera/camera_info", "/camera/camera_info/K", "K", "config/tags.yaml", "config/settings.yaml", "/tf", "tags.yaml", "publish_tf:\u00a0true", "config/settings.yaml", "/tag_detections", "/tf", "/tag_detections_image", "/camera/image_rect", "publish_tag_detections_image==true", "launch/continuous_detection.launch", "config/tags.yaml", "config/settings.yaml", "apriltags2/", "image_rect", "camera_info", "K", "tag_detections", "tag_detections_image", "image_rect", "tag_family", "string", "tag36h11", "tag36h11", "tag36h10", "tag25h9", "tag25h7", "tag16h5", "tag_border", "int", "tag_threads", "int", "tag_decimate", "double", "tag_blur", "double", "tag_refine_edges", "int", "tag_decimate==1.0", "tag_refine_decode", "int", "tag_refine_pose", "int", "tag_refine_decode", "publish_tf", "bool", "/tf", "camera_frame", "string", "publish_tag_detections_image", "bool", "/tag_detections_image", "tag", "camera", "config/tags.yaml", "tag_ID", "bundle_COUNT", "config/tags.yaml", "/tag_detections_image", "camera_frame", "publish_tag_detections_image", "single_image_tag_detection", "K", "camera_frame", "publish_tag_detections_image", "single_image_tag_detection", "single_image_tag_detection", "image_load_path", "string", "image_save_path", "string", "fx", "double", "fy", "double", "cx", "double", "cy", "double"], "package_code": ["@mastersthesis{malyuta:2017mt,\n", "  author = {Danylo Malyuta},\n", "  title = {{Guidance, Navigation, Control and Mission Logic for Quadrotor Full-cycle Autonomy}},\n", "  language = {english},\n", "  type = {Master thesis},\n", "  school = {Jet Propulsion Laboratory},\n", "  address = {4800 Oak Grove Drive, Pasadena, CA 91109, USA},\n", "  month = dec,\n", "  year = {2017}\n", "}\n", "@inproceedings{Wang2016,\n", "  author = {Wang, John and Olson, Edwin},\n", "  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n", "  doi = {10.1109/IROS.2016.7759617},\n", "  isbn = {978-1-5090-3762-9},\n", "  month = {oct},\n", "  pages = {4193--4198},\n", "  publisher = {IEEE},\n", "  title = {{AprilTag 2: Efficient and robust fiducial detection}},\n", "  year = {2016}\n", "}"]},
{"url": "https://wiki.ros.org/turtlebot_stdr", "package": "turtlebot_stdr", "package_summary": ["Stdr version of turtlebot simulation. Convenient to test 2D-navigation related stuffs"], "package_details": ["\n", "]] ", "\n", "\n", " ", "This package contains launchers, maps and world descriptions for the ", " simulation with ", ". ", "Refer to the ", " for help on how to run. "]},
{"url": "https://wiki.ros.org/effort_controllers", "package": "effort_controllers", "package_summary": ["effort_controllers"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/wu_ros_tools", "package": "wu_ros_tools", "package_summary": ["A collection of tools for making a variety of generic ROS-related tasks easier."]},
{"url": "https://wiki.ros.org/xpp_hyq", "package": "xpp_hyq", "package_summary": ["HyQ-robot specific functions for visualization in the  XPP Motion Framework.\n    \n    These include inverse kinematics as well as urdf files for a one-legged,\n    two-legged and four legged robot with ", "\n    legs.\n        \n    The dynamic model can be found \n    ", ".  \n    \n    See also ", "."], "package_details": ["\n ", " ", "The Robot \"HyQ\" from the ", ". ", "(Picture credit to Agnese Abrusci) "]},
{"url": "https://wiki.ros.org/opencv_tests", "package": "opencv_tests", "package_summary": ["Tests the enumerants of the ROS Image message, and functionally tests the Python and C++ implementations of CvBridge."], "package_details": ["Package opencv_test tests the enumerants of the ROS Image message, and functionally tests the Python and C++ implementations of CvBridge. "]},
{"url": "https://wiki.ros.org/rqt_dep", "package": "rqt_dep", "package_summary": ["rqt_dep provides a GUI plugin for visualizing the ROS dependency graph."], "package_details": [" ", "\n", "\n", "\n", "As of version 0.4.1, only the packages in ", " can be inquired on ", ". "], "package_tt": ["ROS_PACKAGE_PATH", "rqt_dep"]},
{"url": "https://wiki.ros.org/turtlebot_stage", "package": "turtlebot_stage", "package_summary": ["Stage version of turtlebot simulation. Convenient to test 2D-navigation related stuffs"], "package_details": ["\n", "\n", "Tutorial link for now: ", " ", "Install the turtlebot package as described in the turtlebot ", " and source the setup.bash to your needs. ", "How to change things you can find in the ", ". "], "package_code": ["$ source ~/turtlebot/devel/setup.bash", "$ roslaunch turtlebot_stage turtlebot_in_stage.launch "]},
{"url": "https://wiki.ros.org/dwb_msgs", "package": "dwb_msgs", "package_summary": ["Message/Service definitions specifically for the dwb_local_planner"]},
{"url": "https://wiki.ros.org/rqt_action", "package": "rqt_action", "package_summary": ["rqt_action provides a feature to introspect all available ROS\n  action (from actionlib) types. By utilizing rqt_msg, the output format is\n  unified with it and rqt_srv. Note that the actions shown on this plugin\n  is the ones that are stored on your machine, not on the ROS core your rqt\n  instance connects to."]},
{"url": "https://wiki.ros.org/swri_nodelet", "package": "swri_nodelet", "package_summary": ["This package provides a simple script to write simple launch files\n    that can easily switch between running nodelets together or as\n    standalone nodes."]},
{"url": "https://wiki.ros.org/prbt_moveit_config", "package": "prbt_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the prbt with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/rqt_robot_steering", "package": "rqt_robot_steering", "package_summary": ["rqt_robot_steering provides a GUI plugin for steering a robot using Twist messages."], "package_details": ["\n", " ", "This tool starts publishing ", " message as soon as it's launched. ", "\n", "As noted, ", " publishes ", " as a name of ", " by default. This name may vary per robot/application; e.g. ", " also publishes ", " but as ", " (see ", ". So, type that name into the topic field at the top of ", " GUI and it gets applied immediately. ", "To verify, use also ", " (or run from commandline ", ") to see if the topics ", " are actually published. "], "package_tt": ["rqt_robot_steering", "geometry_msgs/Twist", "/cmd_vel", "geometry_msgs/Twist", "base_controller/command", "rqt_robot_steering", "rostopic\u00a0echo", "base_controller/command"]},
{"url": "https://wiki.ros.org/teleop_tools", "package": "teleop_tools", "package_summary": ["A set of generic teleoperation tools for any robot."]},
{"url": "https://wiki.ros.org/yocs_msgs", "package": "yocs_msgs", "package_summary": ["Yujin's Open Control System messages, services and actions"], "package_details": [" "]},
{"url": "https://wiki.ros.org/swri_rospy", "package": "swri_rospy", "package_summary": ["This package provides added functionaliy on top of rospy, including a\n  single-threaded callback queue."]},
{"url": "https://wiki.ros.org/cv_bridge", "package": "cv_bridge", "package_summary": ["This contains CvBridge, which converts between ROS\n    Image messages and OpenCV images."], "package_details": [" ", "To learn how to interface OpenCV with ROS using CvBridge, please see the  ", ". "]},
{"url": "https://wiki.ros.org/youbot_description", "package": "youbot_description", "package_summary": ["Robot descriptions in form of URDF files and meshes"]},
{"url": "https://wiki.ros.org/wireless_watcher", "package": "wireless_watcher", "package_summary": ["A Python-based which publishes connection information about a linux wireless interface."]},
{"url": "https://wiki.ros.org/phidgets_api", "package": "phidgets_api", "package_summary": ["A C++ Wrapper for the Phidgets C API"], "package_details": ["\n", "\n", "\n", " ", "The ", " package contains a C++ API built on top of the ", " package. ", "The package provides a base ", " class, from which all other Phidgets inherit. Currently, we have implemented classes for the following devices: ", "* IMU sensor (", ")  ", "* IR sensor (", ")  ", "We first define the Imu class, which is inherited from the base ", " class: ", "The ", " class has a ", ", which is a special handle for the Phidget Spatial device. Different devices will have different handle types. ", "The ", " and ", " functions implement sepcific calls to the IMU device using the C API. The data handler function receives spatial data events.  ", "The ", " is a static callback function which forwards the data to the correct ", " class instance.  ", "Finally, the virtual ", " function is the one which is called back when Spatial data arrives. In this example, the function just prints out a message. However, you can create a class which inherits from the ", " class and overwrites this behavior. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["Phidget", "Phidget", "Imu", "CPhidgetSpatialHandle", "zero()", "setDataRate", "SpatialDataHandler", "Imu", "dataHandler", "Imu"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/zeroconf_avahi_suite", "package": "zeroconf_avahi_suite", "package_summary": ["Suite of packages supporing the avahi implementation of zeroconf for ros."], "package_details": ["\n", "\n", "\n", "For more detailed notes, refer to the relevant ", ". "], "package_tt": ["<d\u00a0DOT\u00a0stonier\u00a0AT\u00a0gmail\u00a0DOT\u00a0com>"], "package_code": ["> sudo apt-get install ros-xxx-zeroconf-avahi-suite"]},
{"url": "https://wiki.ros.org/rosnode_rtc", "package": "rosnode_rtc", "package_summary": ["This package gives transparency between RTM and ROS.\n\n     rtmros-data-bridge.py is a RT-Component for dataport/topic.\n     This automatically convert ROS/topic into RTM/dataport."], "package_details": ["Documentation is available ", ". "]},
{"url": "https://wiki.ros.org/assimp_devel", "package": "assimp_devel", "package_summary": ["assimp library"]},
{"url": "https://wiki.ros.org/teleop_twist_joy", "package": "teleop_twist_joy", "package_summary": ["Generic joystick teleop for twist robots."], "package_details": ["\n", "\n", "\n", "\n", "The purpose of this package is to provide a generic facility for tele-operating Twist-based ROS robots with a standard joystick. Examples of such platforms include ", ", ", ", and ", ". ", "This node provides no rate limiting or autorepeat functionality. It is expected that you take advantage of the features built into ", " for this. ", "The teleop translation functionality is embeddable, if you'd like to compile it into a larger \"base\" node for your robot. See the ", " class for details or ", " for an example. "], "package_tt": ["joy", "cmd_vel", "~enable_button", "int", "~enable_turbo_button", "int", "~axis_linear", "int", "~scale_linear", "double", "~scale_linear_turbo", "double", "~axis_angular", "int", "~scale_angular", "double"]},
{"url": "https://wiki.ros.org/joint_state_controller", "package": "joint_state_controller", "package_summary": ["Controller to publish joint state"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/turtlebot3_bringup", "package": "turtlebot3_bringup", "package_summary": ["roslaunch scripts for starting the TurtleBot3"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "motor_power", "reset", "sound", "battery_state", "cmd_vel_rc100", "diagnostics", "imu", "joint_states", "magnetic_field", "odom", "sensor_state", "tf", "version_info", "~baud", "int", "~port", "string", "imu", "scan", "sensor_state", "version_info", "diagnostics", "rpms", "scan", "~frame_id", "string", "~port", "string"]},
{"url": "https://wiki.ros.org/moveit_ros_robot_interaction", "package": "moveit_ros_robot_interaction", "package_summary": ["Components of MoveIt! that offer interaction via interactive markers"]},
{"url": "https://wiki.ros.org/controller_manager", "package": "controller_manager", "package_summary": ["The controller manager."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", " ", " allows developers to switch controllers at run time, but it is not so convenient when you want to switch from a group of controllers to another for some special purposes. The ", " script makes this easy if such groups are defined in ROS parameter ", ". It knows all controllers involved, and then controllers that need to be stopped and started when it switches from one group to another. Therefore, different groups can share some controllers. ", "\n", "\n", "\n", "\n", "The ", " provides a ", "-compatible loop to control a robot mechanism, which is represented by a ", " instance (see the ", " package).  The ", " provides the infrastructure to load, unload, start and stop controllers. ", "When loading a controller, the ", " will use the controller name as the root for all controller specific parameters, most importantly, ", " which identifies which plugin to load. ", "You can interact with the ", " from the command line, using the ", " script. To interact with a specific controller, use: ", "To automatically load and start a set of controllers at once, and automatically stop and unload those same controllers at once, use the ", " tool: ", "To automatically stop a set of controllers, and restart them later, you can use the ", " tool: ", "The listed controllers will be ", ", but not unloaded. Once spawner is shut down, the controllers will be restarted. ", "An example of ", " parameter: ", "To run the ", " script:: ", "You could run ", " to start controllers from within a launch file. However, the controller would then stay up even after the launch file is taken down. Instead, use the ", "tool to automatically load, start, stop and unload a controller from within a launch file. When you start ", ", it will load and start the controller. When you stop ", " (when the launch file is taken down) it will stop and unload the controller. Your launch file would look something like this: ", "The ", " is a rqt plugin that allows to graphically load, unload, start and stop controllers, as well as to display information about loaded controllers. "], "package_tt": ["controller_manager", "hardware_interface::RobotHW", "controller_manager", "controller_manager", "type", "controller_manager", "controller_manager", "load", "unload", "start", "stop", "spawn", "kill", "list", "list-types", "reload-libraries", "reload-libraries\u00a0--restore", "spawner", "unspawner", "controller_manager", "controller_group", "controller_groups", "controller_groups", "controller_group", "list", "controller_groups", "spawn\u00a0<group>", "<group>", "switch\u00a0<group>", "<group>", "controller_manager", "spawner\u00a0", "spawner", "spawner", "controller_manager/load_controller", "controller_manager/unload_controller", "controller_manager/switch_controller", "BEST_EFFORT", "STRICT", "STRICT", "BEST_EFFORT", "controller_manager/list_controllers", "controller_manager/list_controller_types", "controller_manager/reload_controller_libraries"], "package_code": [" $ rosrun controller_manager controller_manager <command> <name1> <name2> ...", " $ rosrun controller_manager controller_manager <command>", "  $ rosrun controller_manager spawner [--stopped] <name1> <name2> ...", "  $ rosrun controller_manager unspawner <name1> <name2> ...", "    controller_groups:\n", "      production:\n", "        - prod_controller_1\n", "        - prod_controller_2\n", "      development:\n", "        - devel_controller_1\n", "        - devel_controller_2\n", "        - shared_controller_3\n", "      diagnostics:\n", "        - diag_controller_1\n", "        - diag_controller_2\n", "        - shared_controller_3", " $ rosrun controller_manager controller_group <command> <args>", " <launch>\n", "   <node pkg=\"controller_manager\"\n", "         type=\"spawner\"\n", "         args=\"controller_name1 controller_name2\" />\n", " </launch>", " <launch>\n", "   <node pkg=\"controller_manager\"\n", "         type=\"spawner\"\n", "         args=\"--stopped controller_name1 controller_name2\" />\n", " </launch>", "rosrun rqt_controller_manager rqt_controller_manager"]},
{"url": "https://wiki.ros.org/spacenav_node", "package": "spacenav_node", "package_summary": ["ROS interface to the 3Dconnexion SpaceNavigator 6DOF joystick."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This package should support any hardware that is supported by the upstream ", " package. "], "package_tt": ["spacenav_node", "spacenav/offset", "spacenav/rot_offset", "spacenav/twist", "offset", "rot_offset", "spacenav/joy"], "package_code": ["$ sudo apt install spacenavd\n", "$ sudo apt install ros-indigo-spacenav-node", "$ roslaunch spacenav_node classic.launch "]},
{"url": "https://wiki.ros.org/rosflight_msgs", "package": "rosflight_msgs", "package_summary": ["Message and service definitions for the ROSflight ROS stack"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ffha", "package": "ffha", "package_summary": ["ffha: PDDL Planner (http://ipc.informatik.uni-freiburg.de)"]},
{"url": "https://wiki.ros.org/forward_command_controller", "package": "forward_command_controller", "package_summary": ["forward_command_controller"], "package_details": ["\n", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/libmavconn", "package": "libmavconn", "package_summary": ["MAVLink communication library.\n    This library provide unified connection handling classes\n    and URL to connection object mapper.\n\n    This library can be used in standalone programs."], "package_details": ["\n", "It is ", " connection and communication library used in ", ". "]},
{"url": "https://wiki.ros.org/rqt_multiplot", "package": "rqt_multiplot", "package_summary": ["rqt_multiplot provides a GUI plugin for visualizing numeric values in multiple 2D plots using the Qwt plotting backend."], "package_details": ["\n", " ", "\n", " ", "\n", " ", "\n", " ", " "]},
{"url": "https://wiki.ros.org/lgsvl_msgs", "package": "lgsvl_msgs", "package_summary": ["The lgsvl_msgs package for ground truth data."]},
{"url": "https://wiki.ros.org/nmea_navsat_driver", "package": "nmea_navsat_driver", "package_summary": ["Package to parse NMEA strings and publish a very simple GPS message. Does not \n    require or use the GPSD deamon."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package provides a ROS interface for GPS devices that output compatible NMEA sentences. See the ", " for details on the raw format. Of the thousands of NMEA-compatible GPS devices, we are compiling a list of ", ". ", "This package is compatible with the ", " project as well as any other nodes that support ", " and/or ", ".  ", "This package replaces the ", " package present in Fuerte and Groovy. ", "To get up and running quickly, you can use the following command to start outputting your GPS data onto ROS topics. This assumes your GPS is outputting GGA NMEA sentences, is connected to ", " and is communicating at 38400 baud. ", "If you are using this package for the first time and encountering problems you should first check that the package installed correctly and in the right location. Then consult ", ", ", " and ", " to see if a solution has already been identified for your problem. ", "If you are having trouble with nmea_serial_driver and connecting to a serial port, ensure that the user has permission to access the port by checking to see if the user is part of the \"dialout\" group. See ", " for more information.  "], "package_tt": ["/dev/ttyUSB0", "nmea_sentence", "fix", "vel", "time_reference", "time_ref", "~time_ref_source", "string", "~useRMC", "bool", "True", "False", "fix", "vel", "time_reference", "time_ref", "~port", "string", "~baud", "int", "~frame_id", "string", "frame_id", "tf_prefix", "~time_ref_source", "string", "~useRMC", "bool", "True", "False", "nmea_sentence", "~port", "string", "~baud", "int", "~frame_id", "string", "frame_id", "tf_prefix"], "package_code": ["$ rosrun nmea_navsat_driver nmea_serial_driver _port:=/dev/ttyUSB0 _baud:=38400"]},
{"url": "https://wiki.ros.org/kobuki_driver", "package": "kobuki_driver", "package_summary": ["C++ driver library for Kobuki:\n    Pure C++ driver library for Kobuki. This is for those who do not wish to use ROS on their systems."], "package_tt": ["src/tools", "version_info", "src/tools", "version_info", "src/tools", "version_info"], "package_code": ["$ rosrun kobuki_driver version_info\n", "Version Info:\n", " * Hardware Version: 1.0.4\n", " * Firmware Version: 1.1.4\n", " * Software Version: 0.3.4\n", " * Unique Device ID: 736034612-892621875-1125147971", "$ rosrun kobuki_driver version_info\n", "Version Info:\n", " * Hardware Version: 1.0.4\n", " * Firmware Version: 1.2.0\n", " * Software Version: 0.5.3\n", " * Unique Device ID: 736034612-892621875-1125147971", "$ rosrun kobuki_driver version_info\n", "Version Info:\n", " * Hardware Version: 1.0.4\n", " * Firmware Version: 1.2.0\n", " * Software Version: 0.5.3\n", " * Unique Device ID: 736034612-892621875-1125147971"]},
{"url": "https://wiki.ros.org/rviz_plugin_tutorials", "package": "rviz_plugin_tutorials", "package_summary": ["Tutorials showing how to write plugins for RViz."], "package_details": ["Please see the ", " page for your distribution. Follow the link and replace ", " with your preferred ROS distribution (i.e. ", ") in the URL. "]},
{"url": "https://wiki.ros.org/moveit_commander", "package": "moveit_commander", "package_summary": ["Python interfaces to MoveIt"]},
{"url": "https://wiki.ros.org/yocs_rapps", "package": "yocs_rapps", "package_summary": ["Yujin open control system rapps for use with the app manager and rocon concert"]},
{"url": "https://wiki.ros.org/pilz_robots", "package": "pilz_robots", "package_summary": ["The metapackage"], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", " contains Moveit ", " plugins for Linear, Circular and Point-To-Point movements. You can plan industrial ", "motion commands respecting the joint limits with trapezoidal velocity profiles. ", " is an easy to use API to execute standard industrial robot commands like Ptp, Lin, Circ and Sequence in a python script. ", "\n", " contains additional description and launch files to use the Manipulator PRBT combined with a gripper. ", "\n", " provide a launch file for your custom application package. If you want to use all configuration options, download this repository and use the files as template. ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", "We created a set of ", " that walk you through using the Pilz Manipulator Module PRBT, step by step. For example you can learn how to model your own machine layout and how to test if the manipulator can reach your machine. ", "For package documentation please see the ", ".  "], "package_tt": ["PlannerManager"]},
{"url": "https://wiki.ros.org/moveit_python", "package": "moveit_python", "package_summary": ["A pure-python interaface to the MoveIt! ROS API."]},
{"url": "https://wiki.ros.org/mav_msgs", "package": "mav_msgs", "package_summary": ["Package containing messages for communicating with rotary wing MAVs"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/hrpsys_ros_bridge", "package": "hrpsys_ros_bridge", "package_summary": ["hrpsys_ros_bridge package provides basic functionalities to bind\n  \t", ", a \n  \t", "-based controller, and ROS.", " \n    By using this package, you can write your ROS packages that communicate with your\n    non-ROS robots that run on hrpsys.\n  \t\t\n    For communicating with the robots that run on OpenRTM without hrpsys,\n  \tyou can use ", "\n  \tpackage."], "package_details": ["\n", "\n", "\n", "\n", "Other than API documentation being available ", ", this package is missing document and your contribution is appreciated. Please contact through ", ". ", "In its downstream package, you might see a folder for conf files (e.g. ", ") where only template files with suffix ", " are stored. Once you build the package the concrete files are generated into the same folder. ", "There are 3 types of conf files of which the distinction may not be very clear (", "): ", "While in current design the package depends on ", " that's catkinized from ", " onward and not available in ", ", some hacks allow the package not to separate ", " (regardless it's good or not, doing so is the decision as of March 2014). This requires another hack during release process using ", " as follows: "], "package_tt": [".in", "_nosim", "_real", "_realrobot", "branches", "bloom", "$\u00a0bloom-release\u00a0--rosdistro\u00a0groovy\u00a0--track\u00a0groovy\u00a0rtmros_common", "bloom", "package.xml", "pr2-controllers", "package.xml", "git\u00a0add", "$\u00a0git\u00a0am\u00a0--skip", "git\u00a0commit", "exit\u00a00", "bloom"], "package_code": ["$ bloom-release --rosdistro groovy --track groovy rtmros_common\n", ":\n", ">>> Resolve any conflicts and when you have resolved this problem run 'git am --resolved' and then exit the shell using 'exit 0'. <<<\n", "    To abort use 'exit 1'\n", "(bloom)emacs package.xml ", ":  \n", "<!-- <build_depend>pr2_controllers</build_depend> -->\n", ":\n", "<!-- <run_depend>pr2_controllers</run_depend> -->\n", ":", "(bloom)git add package.xml\n", "(bloom)git am --skip\n", "Resolve operation not in progress, we are not resuming.\n", "(bloom)git commit -m \"3rd trial commentout pr2 pkg\" -a\n", "[release/groovy/hrpsys_ros_bridge 1c05bbc] 3rd trial commentout pr2 pkg\n", " 1 file changed, 1 insertion(+), 1 deletion(-)\n", "(bloom)git status\n", "# On branch release/groovy/hrpsys_ros_bridge\n", "# Your branch is ahead of 'origin/release/groovy/hrpsys_ros_bridge' by 8 commits.\n", "#\n", "nothing to commit (working directory clean)\n", "(bloom)exit 0\n", "exit\n", " [git-bloom-patch import]: User reports that conflicts have been resolved, continuing.\n", " [git-bloom-patch import]: Applied 2 patches\n", ":\n", "(bloom continues)"]},
{"url": "https://wiki.ros.org/moveit_kinematics", "package": "moveit_kinematics", "package_summary": ["Package for all inverse kinematics solvers in MoveIt!"]},
{"url": "https://wiki.ros.org/prbt_hardware_support", "package": "prbt_hardware_support", "package_summary": ["Control hardware functions of the PRBT manipulator like RUN_PERMITTED for Stop1 functionality."]},
{"url": "https://wiki.ros.org/rtmros_common", "package": "rtmros_common", "package_summary": ["A package suite that provides all the capabilities for\n    the ROS users to connect to the robots that run on\n    ", "\n    or RTM-based controllers."], "package_details": ["\n", "\n", "\n", "\n", ": TBD ", "\n", ": Wait and re-trigger ", ", as recommended (", "). ", "\n", ": Wait and re-trigger ", ", or improve test code ", "\n", ": This has been fixed in 1.0.21, please report error to ", " ", "\n", "For discussions, updates, announcements, please subscribe to the ", ". ", "Here are some common errors and workarounds (if found any) on either of your local machine / ", " (buildfarm at ROS infra) / ", ". ", "This is failure in the test, in the test, happens in for example ", ". ", "hironx_ros_bridge/test_LArm and hironx_ros_bridge/test_RArm report errors (", ") ", "When ", " fails no matter what value you use in launch files, look at Environment Variables ", ", which might be most likely set as ", " (", " default). In that case re-define it as you want: "], "package_tt": ["jenkins", "travis", "travis", "travis", "rostest", "RTCTREE_NAMESERVERS", "15005"], "package_code": [":\n", "Executing command 'make run_tests'\n", "Scanning dependencies of target clean_test_results\n", "Built target clean_test_results\n", "Built target tests\n", "Scanning dependencies of target _run_tests_hironx_ros_bridge_rostest_test_test-hironx-ros-bridge.test\n", "IDL:omg.org/CORBA/TRANSIENT:1.0\n", "IDL:omg.org/CORBA/TRANSIENT:1.0\n", ":\n", "IDL:omg.org/CORBA/TRANSIENT:1.0\n", "[ERROR] Connection Failed with the Nameserver (hostname=localhost port=2809).\n", "Make sure the hostname is correct and the Nameserver is running.\n", "CORBA.TRANSIENT(omniORB.TRANSIENT_ConnectFailed, CORBA.COMPLETED_NO)\n", "terminate called after throwing an instance of 'std::bad_alloc'\n", "  what():  std::bad_alloc\n", "IDL:omg.org/CORBA/TRANSIENT:1.0\n", "[sensor_ros_bridge_connect.py]  start\n", "configuration ORB with  localhost : 2809\n", "[ERROR] Connection Failed with the Nameserver (hostname=localhost port=2809).\n", "Make sure the hostname is correct and the Nameserver is running.\n", "CORBA.TRANSIENT(omniORB.TRANSIENT_ConnectFailed, CORBA.COMPLETED_NO)\n", "IDL:omg.org/CORBA/TRANSIENT:1.0\n", "[rtmlaunch] starting...  /opt/ros/hydro/share/hrpsys_ros_bridge/launch/hrpsys_ros_bridge.launch\n", "[rtmlaunch] RTCTREE_NAMESERVERS localhost:2809 localhost:2809\n", "[rtmlaunch] SIMULATOR_NAME HiroNX(Robot)0\n", "[rtmlaunch] check connection/activation\n", "[31m[rtmlaunch] [ERROR] Could not Connect ( /localhost:2809/HiroNX(Robot)0.rtc:q , /localhost:2809/HrpsysSeqStateROSBridge0.rtc:rsangle ):  Invalid CORBA naming service: localhost:2809 [0m\n", "[31m[rtmlaunch] Could not Activate ( localhost:2809/HrpsysSeqStateROSBridge0.rtc ) :  Invalid CORBA naming service: localhost:2809 [0m\n", "IDL:omg.org/CORBA/TRANSIENT:1.0", "[0m[ 79%] Building CXX object rtc/VirtualCamera/CMakeFiles/VirtualCameraComp.dir/GLscene.o\n", "[0m[ 79%] Building CXX object rtc/VirtualCamera/CMakeFiles/VirtualCamera.dir/GLscene.o\n", "[0mg++: internal compiler error: Killed (program cc1plus)\n", "[0mPlease submit a full bug report,\n", "[0mwith preprocessed source if appropriate.\n", "[0mSee <file:///usr/share/doc/gcc-4.6/README.Bugs> for instructions.\n", "[0mmake[3]: *** [rtc/VirtualCamera/CMakeFiles/VirtualCameraComp.dir/VirtualCamera.o] Error 4\n", "[0mmake[3]: *** Waiting for unfinished jobs....\n", "[0mg++: internal compiler error: Killed (program cc1plus)\n", "[0mPlease submit a full bug report,\n", "[0mwith preprocessed source if appropriate.\n", "[0mSee <file:///usr/share/doc/gcc-4.6/README.Bugs> for instructions.\n", "[0mmake[3]: *** [rtc/VirtualCamera/CMakeFiles/VirtualCamera.dir/Virt", "self.check_log_data(data, 6, 9, -135, -100.0)", "[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAnglesOfGroup_Override_Acceleration][FAILURE]\n", "File \"/usr/lib/python2.7/unittest/case.py\", line 327, in run\n", "    testMethod()\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 494, in test_rarm_setJointAnglesOfGroup_Override_Acceleration\n", "    self.check_log_data(data, 6, 9, -135, -100.0)\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 132, in check_log_data\n", "    self.assertTrue(abs(_tm_data - tm_data) < tm_data*_tm_thre)\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 358, in assertTrue\n", "    assert(a)\n", "--------------------------------------------------------------------------------\n", "\n", "[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAnglesOfGroup_minus][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_Clear][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_NoWait][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_Wait][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx_ik/test_ik_left][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx_ik/test_ik_right][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx_ik/test_set_target_pose][passed]\n", "\n", "SUMMARY\n", "[1;31m * RESULT: FAIL[0m\n", " * TESTS: 14\n", " * ERRORS: 0\n", "[1;31m * FAILURES: 1[0m", "</testsuite>\n", "=== /home/travis/.ros/test_results/hironx_ros_bridge/rosunit-test_hironx.xml ===\n", "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n", "<testsuite errors=\"0\" failures=\"1\" name=\"unittest.suite.TestSuite\" tests=\"11\" time=\"152.451\">\n", "  <testcase classname=\"__main__.TestHiro\" name=\"testSetTargetPoseBothArm\" time=\"8.2143\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_fullbody_setJointAngles_Clear\" time=\"34.9962\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_fullbody_setJointAngles_NoWait\" time=\"27.1437\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_fullbody_setJointAngles_Wait\" time=\"5.4608\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_fullbody_setJointAngles_minus\" time=\"5.1352\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_goInitial\" time=\"2.4177\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_rarm_setJointAnglesOfGroup_Override_Acceleration\" time=\"5.8956\">\n", "    <failure type=\"AssertionError\">\n", "  File \"/usr/lib/python2.7/unittest/case.py\", line 327, in run\n", "    testMethod()\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 494, in test_rarm_setJointAnglesOfGroup_Override_Acceleration\n", "    self.check_log_data(data, 6, 9, -135, -100.0)\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 132, in check_log_data\n", "    self.assertTrue(abs(_tm_data - tm_data) &lt; tm_data*_tm_thre)\n", "  File \"/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py\", line 358, in assertTrue\n", "    assert(a)\n", "    </failure>\n", "  </testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_rarm_setJointAnglesOfGroup_minus\" time=\"2.6168\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_rarm_setJointAngles_Clear\" time=\"28.5729\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_rarm_setJointAngles_NoWait\" time=\"22.7938\"></testcase>\n", "  <testcase classname=\"__main__.TestHiro\" name=\"test_rarm_setJointAngles_Wait\" time=\"6.7109\"></testcase>\n", "  <system-out><![CDATA[configuration ORB with  localhost : 2809", "[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_LArm][FAILURE]-----------\n", "Arrays are not almost equal to 3 decimals\n", "\n", "(mismatch 22.2222222222%)\n", " x: array([[  2.49888699e-03,   1.23574328e-03,  -9.99996114e-01],\n", "       [  2.31512602e-04,   9.99999209e-01,   1.23632563e-03],\n", "       [  9.99996851e-01,  -2.34601140e-04,   2.49859893e-03]])\n", " y: array([[ 0,  0, -1],\n", "       [ 0,  1,  0],\n", "       [ 1,  0,  0]])\n", "  File \"/usr/lib/python2.7/unittest/case.py\", line 327, in run\n", "    testMethod()\n", "  File \"/opt/ros/hydro/share/hironx_ros_bridge/test/test_hironx_ros_bridge.py\", line 185, in test_LArm\n", "    [ 1, 0, 0]]), decimal=3)\n", "  File \"/usr/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 800, in assert_array_almost_equal\n", "    header=('Arrays are not almost equal to %d decimals' % decimal))\n", "  File \"/usr/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 636, in assert_array_compare\n", "    raise AssertionError(msg)\n", "--------------------------------------------------------------------------------\n", "\n", "[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_LArmIK][passed]\n", "[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_RArm][FAILURE]-----------\n", "Arrays are not almost equal to 3 decimals\n", "\n", "(mismatch 22.2222222222%)\n", " x: array([[  2.49888699e-03,  -1.23574328e-03,  -9.99996114e-01],\n", "       [ -2.31512602e-04,   9.99999209e-01,  -1.23632563e-03],\n", "       [  9.99996851e-01,   2.34601140e-04,   2.49859893e-03]])\n", " y: array([[ 0,  0, -1],\n", "       [ 0,  1,  0],\n", "       [ 1,  0,  0]])\n", "  File \"/usr/lib/python2.7/unittest/case.py\", line 327, in run\n", "    testMethod()\n", "  File \"/opt/ros/hydro/share/hironx_ros_bridge/test/test_hironx_ros_bridge.py\", line 202, in test_RArm\n", "    [ 1, 0, 0]]), decimal=3)\n", "  File \"/usr/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 800, in assert_array_almost_equal\n", "    header=('Arrays are not almost equal to %d decimals' % decimal))\n", "  File \"/usr/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 636, in assert_array_compare\n", "    raise AssertionError(msg)\n", "--------------------------------------------------------------------------------", "$ unset RTCTREE_NAMESERVERS\n", "$ export RTCTREE_NAMESERVERS=localhost:2809"]},
{"url": "https://wiki.ros.org/qt_tutorials", "package": "qt_tutorials", "package_summary": ["Example qt programs, generated from code similar to that used by the \n     roscreate-qt-pkg script and styled on roscpp_tutorials."], "package_details": ["\n", "\n", "Simple package to test/demo the ", " tools. Demo features: ", "Compile in place with the usual ", " to generate native linux binaries or  ", "use rosbuild2 to build windows binaries with the mingw cross compiler (refer to  ", "the ", " and  ", " tutorials). "], "package_tt": ["make"]},
{"url": "https://wiki.ros.org/pcl_conversions", "package": "pcl_conversions", "package_summary": ["Provides conversions from PCL data types and ROS message types"]},
{"url": "https://wiki.ros.org/novatel_span_driver", "package": "novatel_span_driver", "package_summary": ["Python driver for NovAtel SPAN devices."], "package_details": [" ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This is a driver for ", ", especially the ", ". ", "This driver publishes GNSS data as a ", ", and inertial navigation system (INS) data as ", ". You can plot this using ", ", as well as monitoring your overall system using ", ": ", "This driver assumes that your unit has been configured with the ethernet port enabled for TCP. There are various ways this can be set up, but the easiest is to connect to your receiver with ", " (", "), using the serial or USB interface. Then, using the device's console: ", "From the ", " menu, select ", ", which will take you through the position and orientation of the IMU relative to your vehicle's base_link, and the relative position of the GNSS antenna(s). ", "Note that if you only need the console and won't need to run the SPAN setup wizard, you may bypass Novatel Connect and just use an ordinary serial console at 9600 baud. If you are configuring multiple units, you can run the SPAN wizard only once, and enter the supplied SPAN setup commands into the other devices using the console or the ", " rosparam. ", "You should see topics come up for ", ", ", ", ", ", ", ", etc. These will publish data once the system has acquired an initial GNSS fix. ", "The source repository includes example captures from a ", " mounted on a ", ". To create your own captures, use ", ": ", "The following documents from NovAtel are helpful in understanding what this driver is about and how it works: ", "If you'd like more information about ", " or would like a quote for Husky equipped with SPAN, please use ", ". "], "package_tt": ["configuration/command", "navsat/fix", "navsat/odom", "imu/data", "/diagnostics", "odom", "tcpdump"], "package_code": ["wificonfig state disabled\n", "ethconfig etha auto auto auto auto\n", "icomconfig icom1 tcp :3001\n", "ipconfig etha static [address] 255.255.255.0 [gateway]\n", "saveconfig\n", "saveethernetdata etha", "log wificonfig once\n", "log ethconfig once\n", "log icomconfig once\n", "log ipconfig once", "roslaunch novatel_span_driver example.launch ip:=[address] --screen", "sudo tcpdump -i br0 port 3001 -w capture.pcap\n", "gzip capture.pcap"]},
{"url": "https://wiki.ros.org/turtlebot3_teleop", "package": "turtlebot3_teleop", "package_summary": ["Provides teleoperation using keyboard for TurtleBot3."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["cmd_vel"]},
{"url": "https://wiki.ros.org/urdf", "package": "urdf", "package_summary": ["This package contains a C++ parser for the Unified Robot Description\n    Format (URDF), which is an XML format for representing a robot model.\n    The code API of the parser has been through our review process and will remain\n    backwards compatible in future releases."], "package_details": ["\n", "\n", " A number of different packages and components make up urdf. The following diagram attempts to explain the relationship between these components: ", " ", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", "In Indigo, the ", " tool has moved to the ", " package. You may need to run ", " if you can't use ", "  ", " ", " ", "\n", "This package contains a number of ", " for robot models, sensors, scenes, etc. Each XML specification has a corresponding parser in one or more languages. ", "There is large set of ", " on how to build up your own robot models using the URDF specification. Check out the ", " page.  ", "We also developed a macro language called ", " to make it easier to maintain the robot description files, increase their readability, and to avoid duplication in the robot description files. ", "See ", " for a list of robots described by a URDF model.  ", "A command line tool ", "check_urdf", " attempts to parse a file as a URDF description, and either prints a description of the resulting kinematic chain, or an error message. ", "Note: You may need to run ", ". "], "package_tt": ["sudo\u00a0apt-get\u00a0install\u00a0liburdfdom-tools", "urdf_to_graphiz", "liburdfdom-tools", "sudo\u00a0apt-get\u00a0install\u00a0liburdfdom-tools", "urdf_to_graphiz"], "package_code": ["rosrun xacro xacro.py `rospack find pr2_description`/robots/pr2.urdf.xacro -o /tmp/pr2.urdf", "check_urdf pr2.urdf", "rosrun urdfdom check_urdf /tmp/pr2.urdf", "robot name is: pr2\n", "---------- Successfully Parsed XML ---------------\n", "root Link: base_footprint has 1 child(ren)\n", "    child(1):  base_link\n", "        child(1):  base_laser_link\n", "        child(2):  bl_caster_rotation_link\n", "            child(1):  bl_caster_l_wheel_link\n", "            child(2):  bl_caster_r_wheel_link\n", "        child(3):  br_caster_rotation_link\n", "            child(1):  br_caster_l_wheel_link\n", "            child(2):  br_caster_r_wheel_link\n", "        child(4):  fl_caster_rotation_link\n", "            child(1):  fl_caster_l_wheel_link\n", "            child(2):  fl_caster_r_wheel_link\n", "        child(5):  fr_caster_rotation_link\n", "            child(1):  fr_caster_l_wheel_link\n", "            child(2):  fr_caster_r_wheel_link\n", "        child(6):  torso_lift_link\n", "            child(1):  head_pan_link\n", "                child(1):  head_tilt_link\n", "                    child(1):  head_plate_frame\n", "                        child(1):  sensor_mount_link\n", "                            child(1):  double_stereo_link\n", "                                child(1):  narrow_stereo_link\n", " ...", "urdf_to_graphiz pr2.urdf", "urdf_to_graphiz pr2.urdf"]},
{"url": "https://wiki.ros.org/joy", "package": "joy", "package_summary": ["ROS driver for a generic Linux joystick.\n    The joy package contains joy_node, a node that interfaces a\n    generic Linux joystick to ROS. This node publishes a \"Joy\"\n    message, which contains the current state of each one of the\n    joystick's buttons and axes."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "For an example of using ", " to control a teleoperation node with a joystick, see the ", ". ", "In some cases, multiple joysticks may control a single robot. For example, a user may use the default joystick to drive a robot, but a second user may wish to use a different kind. Since the button mappings on each joystick may be different, it will be necessary to remap buttons on one joystick so they can match. See the  ", " package for details. ", "Table of index number of ", ": ", "Table of index number of ", ": ", "Table of index number of ", ": ", "Table of index number of ", ": ", "Table of index number of ", ": ", "Table of index number of ", ": ", "Table of index number of ", ": "], "package_tt": ["joy", "~dev", "str", "~deadzone", "double", "~autorepeat_rate", "double", "~coalesce_interval", "double", "/joy.buttons", "/joy.buttons", "/joy.axes", "/joy.buttons", "/joy.axes", "/joy.buttons", "/joy.axes"]},
{"url": "https://wiki.ros.org/mrpt_ekf_slam_2d", "package": "mrpt_ekf_slam_2d", "package_summary": ["This package is a wrapper for the implementation of EKF-based SLAM with range-bearing sensors, odometry, and a 2D (+heading) robot pose, and 2D landmarks."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "The ROS node mrpt_ekf_slam_2d is a wrapper for the C++ class", ", part of MRPT. Thus, check out the documentation of that class for further details. ", "For the convention on coordinate frames see ", ". ", "In order to use mrpt_ekf_slam_2d package it is necessary to install the last ", " build and the", " (see also the ", ") . "], "package_tt": ["mrpt_ekf_slam_2d", "tf", "landmark", "state_viz", "data_association_viz", "~global_frame_id", "string", "\"map\"", "~base_frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~sensor_source", "string", "\"scan\"", "\"scan\"", "\"beacon\"", "~ini_filename", "string", "~rawlog_filename", "string", "~rawlog_play_delay", "float", "~ellipse_scale", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["roslaunch mrpt_ekf_slam_2d ekf_slam_2d.launch", "roslaunch mrpt_ekf_slam_2d ekf_slam_2d_rawlog.launch"]},
{"url": "https://wiki.ros.org/webots_ros", "package": "webots_ros", "package_summary": ["The ROS package containing examples for interfacing ROS with the standard ROS controller of Webots"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "webots_ros is a package that provides the necessary interfaces to simulate a robot in the ", " open-source 3D rigid body simulator for robots. It integrates with ROS using ROS messages and services. ", "Webots is a prerequisite to use the webots_ros package. It can be downloaded from the ", ". The installation is straightforward, but if need the installation instructions can be found ", ". ", "The following instructions assume that a ", " is already available: ", "Refer to the ", " for more information on building catkin workspaces. ", "See the ", " page for an overview of the available tutorials. ", "For questions about this package or Webots in general, get in touch with the developers on ", ". "], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-webots-ros", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/trajectory_tracker", "package": "trajectory_tracker", "package_summary": ["Path following control package for wheeled mobile robot"]},
{"url": "https://wiki.ros.org/moveit_experimental", "package": "moveit_experimental", "package_summary": ["Experimental packages for moveit."], "package_details": ["See ", " for the detail. "]},
{"url": "https://wiki.ros.org/youbot_driver_ros_interface", "package": "youbot_driver_ros_interface", "package_summary": ["ROS wrapper for the youBot driver"]},
{"url": "https://wiki.ros.org/move_base_flex", "package": "move_base_flex", "package_summary": ["Move Base Flex (MBF) is a backwards-compatible replacement for move_base. MBF can use existing plugins for move_base, and provides an enhanced version of the planner, controller and recovery plugin ROS interfaces. It exposes action servers for planning, controlling and recovering, providing detailed information of the current state and the plugin\u2019s feedback. An external executive logic can use MBF and its actions to perform smart and flexible navigation strategies. Furthermore, MBF enables the use of other map representations, e.g. meshes or grid_map\n       \n       This package is a meta package and refers to the Move Base Flex stack packages.The abstract core of MBF \u2013 without any binding to a map representation \u2013 is represented by the ", " and the ", ". For navigation on costmaps see ", " and ", "."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "Move Base Flex (MBF) is a backwards-compatible replacement for move_base. MBF can use existing plugins for move_base, and provides an enhanced version of the same ROS interface. It exposes action servers for planning, controlling and recovering, providing detailed information of the current state and the plugin's feedback. An external executive logic can use MBF and its actions to perform smart and flexible navigation strategies. For example, ", " has successfully deployed MBF at customer facilities to control TORU robots in highly dynamical environments. Furthermore, MBF enables the use of other map representations, e.g. meshes. The core features are: ", "We have created Move Base Flex for a larger target group besides the standard developers and users of move_base and 2D navigation based on costmaps, as well as addressed move_base's limitations. Since robot navigation can be separated into planning and controlling in many cases, even for outdoor scenarios without the benefits of flat terrain, we designed MBF based on abstract planner-, controller- and recovery behavior-execution classes. To accomplish this goal, we created abstract base classes for the nav core ", ", ", " and ", " plugin interfaces, extending the API to provide a richer and more expressive interface without breaking the current move_base plugin API. The new abstract interfaces allow plugins to return valuable information in each execution cycle, e.g. why a valid plan or a velocity command could not be computed. This information is then passed to the external executive logic through MBF planning, navigation or recovering actions\u2019 feedback and result. The planner, controller and recovery behavior execution is implemented in the abstract execution classes without binding the software implementation to 2D costmaps. In our framework, ", " is just a particular implementation of a navigation system: its execution classes implement the abstract ones, bind the system to the costmaps. Thereby, the system can easily be used for other approaches, e.g. navigation on meshes or 3D occupancy grid maps. However, we provide a ", " class without a binding to costmaps. ", "Move Base Flex provides four actions which can be used by external executives to perform various navigation tasks and embed these into high-level applications. In the following the four actions get_path, exe_path, recovery and move_base are described in detail. The action definition files are stores here in the ", " package. ", "\n", "See ", " ", "See ", " ", "See ", " ", "\n", "See ", " ", "See ", " for details. ", "See ", " for details. ", "See ", " for details. ", "See ", " for details. ", "See ", " for details. ", "See ", ". "], "package_code": ["@inproceedings{puetz18mbf,\n", "  author = {Sebastian P\u00fctz and Jorge Santos Sim\u00f3n and Joachim Hertzberg},\n", "  title = {{Move Base Flex}: A Highly Flexible Navigation Framework for Mobile Robots},\n", "  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n", "  year = 2018,\n", "  month = {October},\n", "  url = {https://github.com/magazino/move_base_flex},\n", "  note = {Software available at \\url{https://github.com/magazino/move_base_flex}}\n", "}"]},
{"url": "https://wiki.ros.org/swri_transform_util", "package": "swri_transform_util", "package_summary": ["The swri_transform_util package contains utility functions and classes for\n     transforming between coordinate frames."]},
{"url": "https://wiki.ros.org/four_wheel_steering_controller", "package": "four_wheel_steering_controller", "package_summary": ["Controller for a four wheel steering mobile base."]},
{"url": "https://wiki.ros.org/pr2_motor_diagnostic_tool", "package": "pr2_motor_diagnostic_tool", "package_summary": ["pr2_motor_diagnostic_tool"], "package_details": [" on Willow Garage blog. "]},
{"url": "https://wiki.ros.org/moveit_ros_move_group", "package": "moveit_ros_move_group", "package_summary": ["The move_group node for MoveIt"]},
{"url": "https://wiki.ros.org/rviz_visual_tools", "package": "rviz_visual_tools", "package_summary": ["Utility functions for displaying and debugging data in Rviz via published markers"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/pointcloud_to_laserscan", "package": "pointcloud_to_laserscan", "package_summary": ["Converts a 3D Point Cloud into a 2D laser scan. This is useful for making devices like the Kinect appear like a laser scanner for 2D-based algorithms (e.g. laser-based SLAM)."], "package_details": ["\n", "\n", "\n", "If you're trying to create a virtual laserscan from your RGBD device, and your sensor is forward-facing, you'll find ", " will be much more straightforward and efficient since it operates on image data instead of bulky pointclouds. However, if your sensor is angled, or you have some other esoteric use case, you may find this node to be very helpful! ", "Please check the ", " for common problems, or open an ", " if still unsolved. ", "Same API as node, available as ", ". "], "package_tt": ["pointcloud_to_laserscan_node", "cloud_in", "scan", "~min_height", "double", "~max_height", "double", "~angle_min", "double", "~angle_max", "double", "~angle_increment", "double", "~scan_time", "double", "~range_min", "double", "~range_max", "double", "~target_frame", "str", "~concurrency_level", "int", "~use_inf", "boolean", "range_max\u00a0+\u00a01", "+inf", "inf_is_valid", "pointcloud_to_laserscan/pointcloud_to_laserscan_nodelet"]},
{"url": "https://wiki.ros.org/xpp_msgs", "package": "xpp_msgs", "package_summary": ["ROS messages used in the XPP framework."], "package_details": ["\n ", " ", "\n", "Each of the messages has a corresponding C++ class and conversion from/to it defined in ", ". "]},
{"url": "https://wiki.ros.org/fanuc_post_processor", "package": "fanuc_post_processor", "package_summary": ["Fanuc post-processor"], "package_details": ["\n", "Documentation is here: ", " "]},
{"url": "https://wiki.ros.org/yujin_ocs", "package": "yujin_ocs", "package_summary": ["Yujin Robot's open-source control software"], "package_details": [" "]},
{"url": "https://wiki.ros.org/moveit_ros", "package": "moveit_ros", "package_summary": ["Components of MoveIt! that use ROS"]},
{"url": "https://wiki.ros.org/ypspur", "package": "ypspur", "package_summary": ["YP-Spur is a mobile robot motion control software with coordinate frame based commands."]},
{"url": "https://wiki.ros.org/swri_serial_util", "package": "swri_serial_util", "package_summary": ["swri_serial_util"]},
{"url": "https://wiki.ros.org/jsk_interactive", "package": "jsk_interactive", "package_summary": ["jsk_interactive"]},
{"url": "https://wiki.ros.org/wiimote", "package": "wiimote", "package_summary": ["The wiimote package allows ROS nodes to communicate with a Nintendo Wiimote\n    and its related peripherals, including the Nunchuk, Motion Plus, and\n    (experimentally) the Classic. The package implements a ROS node that uses\n    Bluetooth to communicate with the Wiimote device, obtaining accelerometer\n    and gyro data, the state of LEDs, the IR camera, rumble (vibrator),\n    buttons, joystick, and battery state. The node additionally enables ROS\n    nodes to control the Wiimote's LEDs and vibration for feedback to the human\n    Wiimote operator. LEDs and vibration may be switched on and off, or made to\n    operate according to a timed pattern."], "package_details": [" ", "\n", "\n", " The cwiid library currently only recognizes Wiimotes which report the name as \"Nintendo RVL-CNT-01\"; the latest Wiimotes will not be discovered. See ", ". ", "\n", "\n", "\n", " ", "\n", " ", "The ", " array shows which buttons are currently depressed on the ", "Wiimtoe device. The position mapping is as follows: ", "This package should be considered as ", " except for support of the Classic controller, which requires additional testing. ", "Check out the wiimote package, and ", " to ready the package for ", "operation. Plug the Bluetooth dongle into your machine's USB port. ", "The ", " message communicates all data that is available from ", "your Wiimote device. Samples are taken and broadcast at 100Hz. Here ", "are comments on some of the fields: ", "The message header's time ", " is set to reflect the time when the respective message's sample was taken from the Wiimote device. ", "The ", " shows the Motion+ gyroscope ", "reading. These values are valid only if the Motion+ attachment is ", "plugged into the Wiimote. Else they are held at constant zero, and ", "matrix entry [0,0] in message field angular_velocity_covariance is set ", "to -1. ", "The ", " are four sets of x/y/[z], and size measures, for the four ", "infrared light sources that the Wiimote device can track. When no ", "lights are detected, the respective values are set to -1. The z axis ", "is always -1, as it is not measured. ", "The ", " array are four intensity measures of the lights that ", "the camera observes. The meaning of these measures are unclear to the ", "author. ", "The ", " entry is the battery charge reading. The unit of ", "this number is unclear. Field ", " returns the remaining ", "charge as a percentage of full charge. ", "The ", " is the time of the most recent device calibration. ", "The ", " field is currently not used. "], "package_tt": ["cwiid", "rosmake", "wiimote_node.py", "set_feedback", "joy", "imu/data", "wiimote/state", "wiimote/nunchuk", "wiimote/classic", "imu/is_calibrated", "imu/calibrate", "State", "stamp", "angular_velocity_zeroed", "angular_velocity_raw", "buttons", "ir_tracking", "ir_sizes", "raw_battery", "percent_battery", "zeroing_time", "errors"], "package_code": ["Position   Button Name\n", "0         1\n", "1         2\n", "2         A\n", "3         B (toggle button on back of device)\n", "4         Plus\n", "5         Minus\n", "6         Rocker Left\n", "7         Rocker Right\n", "8         Rocker Up\n", "9         Rocker Down\n", "10        HOME"]},
{"url": "https://wiki.ros.org/python_qt_binding", "package": "python_qt_binding", "package_summary": ["This stack provides Python bindings for Qt.\n    There are two providers: pyside and pyqt.  PySide is released under\n    the LGPL.  PyQt is released under the GPL.\n\n    Both the bindings and tools to build bindings are included from each\n    available provider.  For PySide, it is called \"Shiboken\".  For PyQt,\n    this is called \"SIP\".\n\n    Also provided is adapter code to make the user's Python code\n    independent of which binding provider was actually used which makes\n    it very easy to switch between these."], "package_details": ["\n", "\n", "This ", " pkg is planned to become standalone (= separated from ROS). See ", ". It is already available via ", ". "], "package_tt": ["python_qt_binding", "python_qt_binding"]},
{"url": "https://wiki.ros.org/teb_local_planner", "package": "teb_local_planner", "package_summary": ["The teb_local_planner package implements a plugin\n    to the base_local_planner of the 2D navigation stack.\n    The underlying method called Timed Elastic Band locally optimizes\n    the robot's trajectory with respect to trajectory execution time,\n    separation from obstacles and compliance with kinodynamic constraints at runtime."], "package_details": ["\n", " ", "Use GitHub to ", ". [", "]", "\n ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 0.5) ", " (", ", default: 0.0) ", " (", ", default: \"point\") ", "\n", " (", ", default: 0.2) ", "\n", " (", ", default: 0.3) ", "\n", " (", ", default: 0.5) ", " (", ", default: \"\") ", "\n", " (", ", default: 5) ", "\n", " (", ", default: true) ", "\n", " (", ", default: \"odom\") ", "\n", "This package implements an online optimal local trajectory planner for navigation and control of mobile robots as a plugin for the ROS ", " package. ", "The initial trajectory generated by a global planner is optimized during runtime w.r.t. minimizing the trajectory execution time (time-optimal objective), ", "separation from obstacles and compliance with kinodynamic constraints such as satisfying maximum velocities and accelerations. ", "Get started by completing the tutorials in the ", " section. ", "Features introduced in ", " are presented in the following video (supporting car-like robots and costmap conversion). ", "The teb_local_planner package allows the user to set ", " in order to customize the behavior. These parameters are grouped into several categories: robot configuration, goal tolerance, trajectory configuration, obstacles, optimization, planning in distinctive topologies and miscellaneous parameters. Some of them are chosen to be compliant with the ", ". Many (but not all) parameters can be modified at runtime using ", ". ", "The following parameters are relevant for the footprint model used for optimization (see ", "). ", " ", "The following parameters are relevant only if ", " plugins are desired (see tutorial): "], "package_tt": ["~<name>/global_plan", "~<name>/local_plan", "~<name>/teb_poses", "~<name>/teb_markers", "~<name>/teb_feedback", "~<name>/publish_feedback", "~<name>/odom", "~<name>/odom_topic", "~<name>/obstacles", "~<name>/via_points", "~<name>/global_plan_viapoint_sep", "~<name>/acc_lim_x", "double", "~<name>/acc_lim_theta", "double", "~<name>/max_vel_x", "double", "~<name>/max_vel_x_backwards", "double", "weight_kinematics_forward_drive", "~<name>/max_vel_theta", "double", "~<name>/min_turning_radius", "double", "~<name>/wheelbase", "double", "~<name>/cmd_angle_instead_rotvel", "true", "~<name>/cmd_angle_instead_rotvel", "bool", "~<name>/weight_kinematics_nh", "~<name>/max_vel_y", "double", "~<name>/acc_lim_y", "double", "~<name>/footprint_model/type", "string", "~<name>/footprint_model/radius", "double", "~<name>/footprint_model/line_start", "double[2]", "~<name>/footprint_model/line_end", "double[2]", "~<name>/footprint_model/front_offset", "double", "~<name>/footprint_model/front_radius", "double", "~<name>/footprint_model/rear_offset", "double", "~<name>/footprint_model/rear_radius", "double", "~<name>/footprint_model/vertices", "double[]", "~<name>/is_footprint_dynamic", "bool", "~<name>/xy_goal_tolerance", "double", "~<name>/yaw_goal_tolerance", "double", "~<name>/free_goal_vel", "bool", "~<name>/dt_ref", "double", "dt_ref", "~<name>/dt_hysteresis", "double", "dt_ref", "~<name>/min_samples", "int", "~<name>/global_plan_overwrite_orientation", "bool", "~<name>/global_plan_viapoint_sep", "double", "weight_viapoint", "~<name>/max_global_plan_lookahead_dist", "double", "~<name>/force_reinit_new_goal_dist", "double", "~<name>/feasibility_check_no_poses", "int", "~<name>/publish_feedback", "bool", "~<name>/shrink_horizon_backup", "bool", "shrink_horizon_min_duration", "~<name>/allow_init_with_backwards_motion", "bool", "~<name>/exact_arc_length", "bool", "~<name>/shrink_horizon_min_duration", "double", "shrink_horizon_backup", "~<name>/min_obstacle_dist", "double", "~<name>/include_costmap_obstacles", "bool", "~<name>/costmap_obstacles_behind_robot_dist", "double", "~<name>/obstacle_poses_affected", "int", "legacy_obstacle_association", "~<name>/inflation_dist", "double", "min_obstacle_dist", "weight_inflation", "~<name>/include_dynamic_obstacles", "bool", "~/obstacles", "~<name>/legacy_obstacle_association", "bool", "true", "~<name>/obstacle_association_force_inclusion_factor", "double", "min_obstacle_dist", "enforce\u00a0the\u00a0consideration\u00a0obstacles\u00a0within\u00a0a\u00a0radius\u00a0of\u00a02.0*", "legacy_obstacle_association", "false", "~<name>/obstacle_association_cutoff_factor", "double", "obstacle_association_force_inclusion_factor", "min_obstacle_dist", "obstacle_association_force_inclusion_factor", "legacy_obstacle_association", "false", "~<name>/costmap_converter_plugin", "string", "~<name>/costmap_converter_spin_thread", "bool", "~<name>/costmap_converter_rate", "double", "~<name>/no_inner_iterations", "int", "no_outer_iterations", "~<name>/no_outer_iterations", "int", "dt_ref", "no_inner_iterations", "~<name>/penalty_epsilon", "double", "~<name>/weight_max_vel_x", "double", "~<name>/weight_max_vel_theta", "double", "~<name>/weight_acc_lim_x", "double", "~<name>/weight_acc_lim_theta", "double", "~<name>/weight_kinematics_nh", "double", "~<name>/weight_kinematics_forward_drive", "double", "~<name>/weight_kinematics_turning_radius", "double", "~<name>/weight_optimaltime", "double", "~<name>/weight_obstacle", "double", "~<name>/weight_viapoint", "double", "~<name>/weight_inflation", "double", "~<name>/weight_adapt_factor", "double", "weight_obstacle", "~<name>/enable_homotopy_class_planning", "bool", "~<name>/enable_multithreading", "bool", "~<name>/max_number_classes", "int", "~<name>/selection_cost_hysteresis", "double", "~<name>/selection_obst_cost_scale", "double", "~<name>/selection_viapoint_cost_scale", "double", "~<name>/selection_alternative_time_cost", "bool", "~<name>/roadmap_graph_no_samples", "int", "~<name>/roadmap_graph_area_width", "double", "~<name>/h_signature_prescaler", "double", "~<name>/h_signature_threshold", "double", "~<name>/obstacle_heading_threshold", "double", "~<name>/visualize_hc_graph", "bool", "~<name>/viapoints_all_candidates", "bool", "~<name>/switching_blocking_period", "double", "~<name>/odom_topic", "string", "~<name>/map_frame", "string"]},
{"url": "https://wiki.ros.org/urdfdom", "package": "urdfdom", "package_summary": ["A library to access URDFs using the DOM model."], "package_details": ["This is now an upstream package. Source can be found here: ", " "]},
{"url": "https://wiki.ros.org/pr2eus", "package": "pr2eus", "package_summary": ["pr2eus"]},
{"url": "https://wiki.ros.org/stomp_moveit", "package": "stomp_moveit", "package_summary": ["This package wraps the STOMP planner functionality in stomp_core so that it can be used within the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/cl_tf", "package": "cl_tf", "package_summary": ["Client implementation to use TF from Common Lisp"], "package_details": ["Implementation of ", " for ", " nodes. "]},
{"url": "https://wiki.ros.org/rqt_py_common", "package": "rqt_py_common", "package_summary": ["rqt_py_common provides common functionality for rqt plugins written in Python.\n    Despite no plugin is provided, this package is part of the rqt_common_plugins\n    repository to keep refactoring generic functionality from these common plugins\n    into this package as easy as possible.\n\n    Functionality included in this package should cover generic ROS concepts and\n    should not introduce any special dependencies beside \"ros_base\"."]},
{"url": "https://wiki.ros.org/rosbridge_suite", "package": "rosbridge_suite", "package_summary": ["Rosbridge provides a JSON API to ROS functionality for non-ROS programs.\n    There are a variety of front ends that interface with rosbridge, including\n    a WebSocket server for web browsers to interact with.\n\n    Rosbridge_suite is a meta-package containing rosbridge, various front end\n    packages for rosbridge like a WebSocket package, and helper packages."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " is a specification for sending JSON based commands to ROS (and in theory, any other robot middleware). An example of the protocol for subscribing to a topic: ", "The rosbridge_suite package is a collection of packages that implement the rosbridge protocol and provides a ", " transport layer. ", "Source code is available at ", ". Please file issues and pull requests there. ", "Rosbridge is a community project and involvement is encouraged! In addition to the ", " repository, check out the ", " and ", ". "], "package_code": ["{ \"op\": \"subscribe\",\n", "  \"topic\": \"/cmd_vel\",\n", "  \"type\": \"geometry_msgs/Twist\"\n", "}", "sudo apt-get install ros-<rosdistro>-rosbridge-server"]},
{"url": "https://wiki.ros.org/rosflight_utils", "package": "rosflight_utils", "package_summary": ["Supporting utilities for ROSflight packages"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/summit_xl_sim", "package": "summit_xl_sim", "package_summary": ["The summit_xl_sim metapackage"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", " simulation.  ", "This package contains the launch and configuration files to spawn the joint controllers with the ROS controller_manager. It allows to launch the joint controllers for the Summit XL (4 axes skid steering + 2 axes ptz), Summit XL OMNI (4 axes skid steering, 4 axes swerve drive), Summit X-WAM (4 axes skid steering, 4 axes swerve drive, 1 linear axis for scissor mechanism). The Summit XL simulation stack follows the gazebo_ros controller manager scheme described in ", " ", "Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "]},
{"url": "https://wiki.ros.org/lanelet2_maps", "package": "lanelet2_maps", "package_summary": ["Example maps in the lanelet2-format"]},
{"url": "https://wiki.ros.org/ublox", "package": "ublox", "package_summary": ["Provides a ublox_gps node for u-blox GPS receivers, messages, and serialization packages for the binary UBX protocol.", "\n", "\n", "\n", "Launch the ", " node. Since there are many parameters, load the parameters from a ", " file. For example: ", "An example parameter file is shown below. Note that if the baudrate, rate, nav_rate or GNSS are not configured correctly for your device, the launch may fail. "], "package_details": ["\n", "\n", "The driver publishes ", " and ", " messages. The ublox_gps package provides a node to subscribe to various u-blox messages. "], "package_tt": ["~<node_name>/fix", "gps", "~<node_name>/fix_velocity", "gps", "~<node_name>/diagnostics", "~<node_name>/frame_id", "string", "tf_prefix", "~<node_name>/device", "string", "~<node_name>/uart1/baudrate", "uint16", "~<node_name>/uart1/in", "uint32", "~<node_name>/uart1/out", "uint16", "~<node_name>/rate", "float", "~<node_name>/nav_rate", "uint16", "~<node_name>/enable_ppp", "bool", "~<node_name>/gnss/sbas", "bool", "~<node_name>/sbas/usage", "uint8", "~<node_name>/dynamic_model", "string", "portable", "stationary", "pedestrian", "automotive", "sea", "airborne1", "airborne2", "airborne4", "wristwatch", "~<node_name>/fix_mode", "string", "~<node_name>/dr_limit", "uint8", "~<node_name>/save_on_shutdown", "bool", "~<node_name>/clear_bbr", "bool", "raw_data", "bool", "~<node_name>/save/mask", "uint32", "~<node_name>/save/device", "uint8", "~<node_name>/load/mask", "uint32", "~<node_name>/load/device", "uint8", "~<node_name>/dat/set_dat", "bool", "~<node_name>/dat/majA", "float64", "~<node_name>/dat/flat", "float64", "~<node_name>/dat/shift", "[float32,\u00a0float32,\u00a0float32]", "~<node_name>/dat/rot", "[float32,\u00a0float32,\u00a0float32]", "~<node_name>/dat/scale", "float32", "~<node_name>/gnss/gps", "bool", "~<node_name>/gnss/glonass", "bool", "~<node_name>/gnss/beidou", "bool", "~<node_name>/gnss/qzss", "bool", "~<node_name>/gnss/qzss_sig_cfg", "uint32", "~<node_name>/gnss/galileo", "bool", "~<node_name>/gnss/imes", "bool", "~<node_name>/nmea/set", "bool", "~<node_name>/nmea/version", "uint8", "nmea/set", "~<node_name>/nmea/num_sv", "uint8", "nmea/set", "~<node_name>/nmea/sv_numbering", "uint8", "nmea/set", "~<node_name>/nmea/compat", "bool", "nmea/set", "~<node_name>/nmea/consider", "bool", "nmea/set", "~<node_name>/nmea/limit82", "bool", "~<node_name>/nmea/high_prec", "bool", "~<node_name>/nmea/filter/pos", "bool", "~<node_name>/nmea/filter/msk_pos", "bool", "~<node_name>/nmea/filter/time", "bool", "~<node_name>/nmea/filter/date", "bool", "~<node_name>/nmea/filter/gps_only", "bool", "~<node_name>/nmea/filter/track", "bool", "~<node_name>/nmea/gnssToFilt/gps", "bool", "~<node_name>/nmea/gnssToFilt/sbas", "bool", "~<node_name>/nmea/gnssToFilt/qzss", "bool", "~<node_name>/nmea/gnssToFilt/glonass", "bool", "~<node_name>/nmea/gnssToFilt/beidou", "bool", "~<node_name>/nmea/main_talker_id", "uint8", "~<node_name>/nmea/gsv_talker_id", "uint8", "~<node_name>/nmea/bds_talker_id", "[0,\u00a00]", "~<node_name>/nmea/set", "bool", "~<node_name>/nmea/version", "uint8", "nmea/set", "~<node_name>/nmea/num_sv", "uint8", "nmea/set", "~<node_name>/nmea/compat", "bool", "nmea/set", "~<node_name>/nmea/consider", "bool", "nmea/set", "~<node_name>/nmea/filter/pos", "bool", "~<node_name>/nmea/filter/msk_pos", "bool", "~<node_name>/nmea/filter/time", "bool", "~<node_name>/nmea/filter/date", "bool", "~<node_name>/nmea/filter/sbas", "bool", "~<node_name>/nmea/filter/track", "bool", "~<node_name>/use_adr", "bool", "~<node_name>/nav_rate", "\u00a0(", "~<node_name>/tmode3", "uint8", "~<node_name>/arp/lla_flag", "bool", "tmode3", "~<node_name>/arp/position", "float32[3]", "tmode3", "~<node_name>/arp/position_hp", "int8[3]", "tmode3", "~<node_name>/arp/acc", "float32", "tmode3", "~<node_name>/sv_in/reset", "bool", "~<node_name>/sv_in/min_dur", "uint8", "tmode3", "~<node_name>/sv_in/acc_lim", "float32", "tmode3", "~<node_name>/dgnss_mode", "uint8", "INF", "~<node_name>/inf/all", "bool", "INF", "~<node_name>/inf/debug", "bool", "INF-Debug", "ROS_DEBUG", "~<node_name>/inf/error", "bool", "INF-Error", "ROS_ERROR", "~<node_name>/inf/notice", "bool", "INF-Notice", "ROS_INFO", "~<node_name>/inf/test", "bool", "INF-Test", "ROS_INFO", "~<node_name>/inf/warning", "bool", "INF-Warning", "ROS_WARN", "~<node_name>/publish/all", "bool", "RXM", "AID", "MON", "publish/<class>/all", "~<node_name>/publish/aid/all", "bool", "AID", "AID", "~<node_name>/publish/aid/alm", "bool", "~aidalm", "~<node_name>/publish/aid/eph", "bool", "~aideph", "~<node_name>/publish/aid/hui", "bool", "~aidhui", "~<node_name>/publish/rxm/all", "bool", "RXM", "RXM", "~<node_name>/publish/rxm/alm", "bool", "~rxmalm", "~<node_name>/publish/rxm/raw", "bool", "~rxmraw", "~<node_name>/publish/rxm/rtcm", "bool", "~rxmrtcm", "~<node_name>/publish/rxm/sfrb", "bool", "~rxmsfrb", "~<node_name>/publish/rxm/eph", "bool", "~rxmeph", "~<node_name>/publish/mon/all", "bool", "MON", "~<node_name>/publish/mon/hw", "bool", "~monhw", "~<node_name>/publish/nav/att", "bool", "~navatt", "~<node_name>/publish/nav/clock", "bool", "~<node_name>/publish/nav", "~navclock", "~<node_name>/publish/nav/posecef", "bool", "NavPOSECEF", "~navposecef", "~<node_name>/publish/nav/posllh", "bool", "NavPOSLLH", "~navposllh", "~<node_name>/publish/nav/pvt", "bool", "~navpvt", "~<node_name>/publish/nav/relposned", "bool", "NavRELPOSNED", "~navrelposned", "~<node_name>/publish/nav/sat", "bool", "~navsat", "~<node_name>/publish/nav/sol", "bool", "~navsol", "~<node_name>/publish/nav/status", "bool", "~navstatus", "~<node_name>/publish/nav/svin", "bool", "~navsvin", "~<node_name>/publish/nav/svinfo", "bool", "~navsvinfo", "~<node_name>/publish/nav/velned", "bool", "ublox_msgs/NavVELNED", "~navvelned", "ublox_msgs/NavPVT", "~<node_name>/publish/esf/all", "bool", "ESF", "~<node_name>/publish/esf/ins", "bool", "~esfins", "~<node_name>/publish/esf/meas", "bool", "~esfmeas", "~<node_name>/publish/esf/raw", "bool", "~esfraw", "~<node_name>/publish/esf/status", "bool", "~esfstatus", "~<node_name>/publish/hnr/pvt", "bool", "~hnrpvt", "ublox_gps", ".yaml"], "package_code": ["<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n", "\n", "<launch>\n", "  <arg name=\"param_file_name\" doc=\"name of param file, e.g. rover\" />\n", "  <node pkg=\"ublox_gps\" type=\"ublox_gps\" name=\"ublox_gps\">\n", "    <rosparam command=\"load\" file=\"$(find ublox_gps)/config/$(arg param_file_name).yaml\" />\n", "  </node>\n", "</launch>", "debug: 1                    # Range 0-4 (0 means no debug statements will print)\n", "\n", "device: /dev/ttyACM0\n", "frame_id: gps\n", "dynamic_model: portable\n", "fix_mode: auto              # Switches between 2D/3D automatically\n", "dr_limit: 0                 # Dead reckoning limit\n", "enable_ppp: false           # Advanced setting not supported by all devices\n", "\n", "rate: 4                     # Measurement rate in Hz\n", "nav_rate: 4                 # in number of measurement cycles\n", "\n", "uart1:\n", "  baudrate: 19200           # baudrate is device specific, check the device manual\n", "  in: 1                     # UBX\n", "  out: 4                    # RTCM\n", "\n", "# RTCM out config\n", "rtcm:\n", "  ids: [5, 87, 77, 230]     # RTCM Messages to configure\n", "  rates: [1, 1, 1, 10]      # Rates of RTCM messages above,\n", "                            # in number of navigation solutions\n", "dat:\n", "  set: false                # Do not set the user configured datum\n", "\n", "# GNSS Config, verify which GNSS are supported by your device\n", "gnss:\n", "  gps: true                 # (not required since it defaults to true)\n", "  glonass: true\n", "  beidou: false\n", "  qzss: false\n", "  sbas: false\n", "\n", "inf:\n", "  all: true                   # Whether to display INF messages\n", "\n", "# Message subscriptions\n", "subscribe:\n", "  all: true                 # Subscribe to all messages\n", "  aid:\n", "    all: false                # ... except AID messages"]},
{"url": "https://wiki.ros.org/pilz_trajectory_generation", "package": "pilz_trajectory_generation", "package_summary": ["The pilz_trajectory_generation package containing the MoveIt! plugin pilz_command_planner."], "package_details": ["\n", "\n", "For package documentation please see the ", ". "]},
{"url": "https://wiki.ros.org/map_server", "package": "map_server", "package_summary": ["map_server provides the ", " ROS ", ", which offers map data as a ROS ", ". It also provides the ", " command-line utility, which allows dynamically generated maps to be saved to file."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " retrieves map data and writes it out to ", " and ", ".  Use the ", " option to provide a different base name for the output files. The ", " and ", " options take values between 0 and 100. To save different map topic set ", " to your costmap topic. ", "\n", "\n", "Image data is read in via ", "; supported formats vary, depending on what SDL_Image provides on a specific platform.  Generally speaking, most popular image formats are widely supported.  A notable exception is that PNG is not supported on OS X. ", "Given a pixel that has a COLOR value ", " in the range ", ", how should we interpret this value when put into the ROS message? First we convert integer ", " to a floating point number ", " depending on the interpretation of the ", " flag from the yaml.  ", "This will allow you to output a full gradient of values ranging from ", ". To output ", ", simply use the alpha channel of a png, where any transparency will be interpreted as unknown. ", "This mode will output ", " for each pixel, so output values are ", ".  "], "package_tt": ["map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "map_server", "map_saver", "x", "[0,\u00a0256)", "x", "p", "negate", "negate", "p\u00a0=\u00a0(255\u00a0-\u00a0x)\u00a0/\u00a0255.0", "negate", "p\u00a0=\u00a0x\u00a0/\u00a0255.0", "p\u00a0>\u00a0occupied_thresh", "100", "p\u00a0<\u00a0free_thresh", "0", "-1", "255", "p\u00a0>\u00a0occupied_thresh", "100", "p\u00a0<\u00a0free_thresh", "0", "99\u00a0*\u00a0(p\u00a0-\u00a0free_thresh)\u00a0/\u00a0(occupied_thresh\u00a0-\u00a0free_thresh)", "[0,\u00a0100]", "-1", "x", "[0,\u00a0255]", "map_server", "map_metadata", "map", "static_map", "~frame_id", "string", "\"map\"", "map_saver", "map_saver", "map"], "package_code": ["image: testmap.png\n", "resolution: 0.1\n", "origin: [0.0, 0.0, 0.0]\n", "occupied_thresh: 0.65\n", "free_thresh: 0.196\n", "negate: 0", "map_server <map.yaml>", "rosrun map_server map_server mymap.yaml", "rosrun map_server map_saver [--occ <threshold_occupied>] [--free <threshold_free>] [-f <mapname>] map:=/your/costmap/topic", "rosrun map_server map_saver -f mymap", "rosrun map_server map_saver --occ 90 --free 10 -f mymap map:=/move_base/global_costmap/costmap"]},
{"url": "https://wiki.ros.org/tf2_eigen", "package": "tf2_eigen", "package_summary": ["tf2_eigen"], "package_details": ["\n", "\n", "\n", " ", " ", " ", "Please see the ", " for use. "]},
{"url": "https://wiki.ros.org/pocketsphinx", "package": "pocketsphinx", "package_summary": ["This package is a simple wrapper around the pocketsphinx speech recognizer, \n    using gstreamer and a Python-based interface."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This package provides access to the ", " speech recognizer. It uses gstreamer to automatically split the incoming audio into utterances to be recognized, and offers services to start and stop recognition.  ", "Currently, the recognizer ", " a language model and dictionary file. These can be automatically built from a corpus of sentances using the ", ". Example launch files, language models, and dictionary files can be found in the ", " directory of the package. The ", " example controls a mobile base using commands such as \"", "\" or \"", "\". The ", " example uses some of the standard items and names from the ", "@Home contest, for instance, it should recognize \"", "\" or \"", "\".  "], "package_tt": ["~output", "~start", "~stop", "~lm", "str", "~dict", "str"], "package_code": ["sudo apt-get install ros-groovy-pocketsphinx", "sudo apt-get install ros-hydro-pocketsphinx", "sudo apt-get install ros-indigo-pocketsphinx", "sudo apt-get install ros-jade-pocketsphinx", "git clone https://github.com/mikeferguson/pocketsphinx\n", "sudo apt-get install gstreamer0.10-pocketsphinx"]},
{"url": "https://wiki.ros.org/katana_gazebo_plugins", "package": "katana_gazebo_plugins", "package_summary": ["This package provides Gazebo plugins to simulate the Katana arm."], "package_details": ["\n", "\n", "Currently, there is only one plugin available that simulates the gripper. See packages ", " and ", " for usage examples and for information on the Gazebo parameters (not documented here). "], "package_tt": ["posture_action_name/goal", "posture_action_name/result", "gripper_controller_state", "grasp_query_name", "~gripper_object_presence_threshold", "double"]},
{"url": "https://wiki.ros.org/rsv_balance_msgs", "package": "rsv_balance_msgs", "package_summary": ["RoboSavvy's balancing platform messages and services definitions."]},
{"url": "https://wiki.ros.org/state_exchanger", "package": "state_exchanger", "package_summary": ["A package that exchanges behavioral states between multiple cyber physical systems (CPSs) in a swarm."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The communication between CPSs is based on the ", ". ", "The state that is exchanged is read from a ", " state machine. ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["state_exchanger", "id", "integer", "output", "string", "screen", "screen", "log", "param", "state_exchanger.yaml", "state_exchanger", "state_exchanger", "smach_server/smach/container_status", "bridge/events/state", "state", "swarm_state", "~loop_rate", "real", "~queue_size", "integer", "~timeout", "real", "~sm_path", "string"], "package_code": ["roslaunch state_exchanger state_exchanger.launch"]},
{"url": "https://wiki.ros.org/wifi_ddwrt", "package": "wifi_ddwrt", "package_summary": ["Access to the DD-WRT wifi"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides tools for logging statistics from a router using ", " OpenSource firmware and publishing them over ROS. ", "The ddwrt ", " publishes information about the Access Point that the router is currently connected to as well as survey information about all the Access Points that the router can see. ", "The monitor node publishes a visualization marker to ", " that displays between 1-5 bars over the robot's head according to the signal strength of the Access Point the robot is currently connected to. "], "package_tt": ["ddwrt/sitesurvey", "ddwrt/accesspoint", "~router", "string", "~username", "string", "~password", "string", "ddwrt/sitesurvey", "ddwrt/accesspoint", "visualization_marker", "ddwrt/sitesurvey", "ddwrt/accesspoint", "visualization_marker"]},
{"url": "https://wiki.ros.org/turtlebot3_autorace_camera", "package": "turtlebot3_autorace_camera", "package_summary": ["TurtleBot3 AutoRace ROS package that controls Raspberry Pi Camera, and process the image"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Refer to parameters for ", " with picamera. This package is provided parameters from .", " files.  "], "package_tt": ["camera/image_input/compressed", "camera/image_output", "camera/image_output/compressed", "camera/image_output", "camera/image_input/compressed", "camera/image_output", "camera/image_output/compressed", "camera/image_output", "camera_info", "image/compressed"], "package_code": ["#------------------------ parameter for image compensation ------------------------#\n", "gen.add(\"clip_hist_percent\", double_t, 0, \n", "        \"Percentage of Histogram Cut-Off\", 1.0, 0.0, 10.0)", "#-------------------------- parameter for image warping --------------------------# \n", "gen.add(\"top_x\",        int_t,      0,      \"Top X Pos\",        60,  0, 120)\n", "gen.add(\"top_y\",        int_t,      0,      \"Top Y Pos\",        50,  0, 120)\n", "gen.add(\"bottom_x\",     int_t,      0,      \"Bottom X Pos\",     140,  0, 320)\n", "gen.add(\"bottom_y\",     int_t,      0,      \"Bottom Y Pos\",     120,  0, 320)", " camera.yaml                          # default configuration for camera\n", " compensation.yaml                    # parameters for image compensation\n", " projection.yaml                      # parameters for image warping\n", " camerav2_320x240_30fps.yaml          # default configuration for lense"]},
{"url": "https://wiki.ros.org/wheeled_robin_node", "package": "wheeled_robin_node", "package_summary": ["The wheeled_robin_node package"], "package_details": ["\n", "\n", "\n", " ", "To start the ", " driver node use the launch files in wheeled_robin_bringup. "], "package_tt": ["cmd_vel", "odom", "joint_states", "~sensor_state", "diagnostics", "~set_operation_mode", "~set_digital_outputs", "~update_rate", "double", "~drive_mode", "string", "~cmd_vel_timeout", "double", "~odom_angular_scale_correction", "double", "~odom_linear_scale_correction", "double", "~min_abs_yaw_vel", "double", "~max_abs_yaw_vel", "double", "~port", "string", "~publish_tf", "bool", "~odom_frame", "string", "~base_footprint_frame", "string", "~base_link_frame", "string", "~operation_mode", "integer", "odom", "base_footprint", "base_footprint", "base_link"]},
{"url": "https://wiki.ros.org/rail_pick_and_place", "package": "rail_pick_and_place", "package_summary": ["Grasp Training and Pick and Place Methods Developed by the RAIL Lab"], "package_details": ["\n", "\n", "The ", " metapackage contains packages for object recognition, grasp selection, and placement.  Also included are packages for collecting demonstration grasps, generating models for recognition and manipulation, and training to determine the effectiveness of learned grasps. ", "To install the ", " package, you can install from source with the following commands: "], "package_tt": ["rail_pick_and_place", "rail_pick_and_place"], "package_code": ["\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/object_recognition_msgs", "package": "object_recognition_msgs", "package_summary": ["Object_recognition_msgs contains the ROS message and the actionlib definition used in object_recognition_core"]},
{"url": "https://wiki.ros.org/schunk_sdh", "package": "schunk_sdh", "package_summary": ["This package provides an interface for operating the schunk dexterous hand (SDH), including the tactile sensors."], "package_details": ["\n", "\n", "\n", "\n", "\n", "To use this package you need a schunk dexterous hand ", " with ", ". Other firmware versions may work, but are not officially supported. Alternatively you can use a simulated version without any hardware, see ", ". ", "The installation is tested for Ubuntu 10.04, 10.10, 11.04 and 11.10 using ROS ", ". If you discover problems installing them on other platforms, please ", ". ", "The ", " package provides a configurable node for operating a schunk dexterous hand. ", "\n", "This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g. ", " in the ", " stack. ", "For using only the sdh use ", "All hardware configuration is done in the ", " package. A sample parameter file for the sdh in \"schunk_hardware_config/sdh/config/sdh.yaml\" could look like this "], "package_tt": ["schunk_sdh", "follow_joint_trajectory_action/goal", "follow_joint_trajectory_action/result", "follow_joint_trajectory_action/feedback", "command", "/joint_states", "init", "stop", "recover", "set_operation_mode", "~sdhdevicetype", "string", "~sdhdevicestring", "string", "~dsadevicestring", "string", "~baudrate", "int", "~joint_names", "list\u00a0of\u00a0strings", "/robot_description", "urdf\u00a0model", "dsa_only", "tactile_data", "~dsadevicestring", "string", "~polling", "bool", "~publish_frequency", "float"], "package_code": ["roslaunch schunk_bringup sdh_solo.launch", "<include file=\"$(find schunk_bringup)/components/sdh.launch\" />", "sdhdevicetype: PCAN\n", "sdhdevicestring: /dev/pcan0\n", "baudrate: 1000000\n", "joint_names: ['sdh_knuckle_joint', 'sdh_thumb_2_joint', 'sdh_thumb_3_joint', 'sdh_finger_12_joint', 'sdh_finger_13_joint', 'sdh_finger_22_joint', 'sdh_finger_23_joint']\n", "OperationMode: position", "dsadevicestring: /dev/ttyS0\n", "polling: false\n", "use_rle: true\n", "frequency: 30"]},
{"url": "https://wiki.ros.org/laser_scan_splitter", "package": "laser_scan_splitter", "package_summary": ["The laser_scan_splitter takes in a LaserScan message and splits it into a number of other LaserScan messages. Each of the resulting laser scans can be assigned an arbitrary coordinate frame, and is published on a separate topic."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "The ", " takes in a ", " message and splits it into a number of other ", " messages. Each of the resulting laser scans can be assigned an arbitrary coordinate frame, and is published on a separate topic.  ", "You can run the ", " on a pre-recorded bag file that comes with the package. First, make sure you have the ", " stack downloaded and installed by following the instructions ", ". ", "You should see a result similar to the video below. The 3 laser scan messages displayed in ", " are obtained by splitting the original scan. ", "Two drivers are available: ", " and ", ". Their parameters and topics are identical. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["LaserScan", "laser_scan_splitter_node", "laser_scan_splitter_nodelet", "laser_scan_splitter_node", "scan", "~scan_[n]", "LaserScan", "~scan_1", "~scan_2", "~sizes", "string", "\"256\u00a0256\"", "~topics", "string", "\"scan_1\u00a0scan_2\"", "~frames", "string", "\"laser\u00a0laser\""], "package_code": ["\n", "\n"]},
{"url": "https://wiki.ros.org/manifest_cleaner", "package": "manifest_cleaner", "package_summary": ["Examines package and stack manifests. Currently only can output statistics, doesn't actually clean."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "If the ", " tag is not used, the summary will contain whether the URL tag is specified or not.  ", "If the ", " tag is used, the summary will contain the HTTP response numbers obtained when the given URL is downloaded. Note that this option will take a bit longer to run.  ", "A list of all the authors and the number and list of all the stacks/packages they maintain. Minor parsing is done to separate comma delineated lists and email addresses when they are of the form 'My name/", "'. "], "package_tt": ["-web", "-web"], "package_code": ["rosrun manifest_cleaner stats.py (some/directory/containing/packages) [-web]", "name                     description brief    license url       review       author                     \n", "======================== =========== ======== ======= ========= ============ ===========================\n", "pr2_common               detailed    detailed BSD     specified Doc reviewed Maintained by John Hsu  ", "name                     description brief    license url       review       author                     \n", "======================== =========== ======== ======= ========= ============ ===========================\n", "pr2_msgs                 detailed    detailed BSD     specified Doc reviewed Eric Berger and many others"]},
{"url": "https://wiki.ros.org/rtt_diagnostic_msgs", "package": "rtt_diagnostic_msgs", "package_summary": ["Provides an rtt typekit for ROS diagnostic_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/diagnostic_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/rosmsg", "package": "rosmsg", "package_summary": ["rosmsg contains two command-line tools: ", " and\n    ", ". ", " is a command-line tool for\n    displaying information about ", ". ", " is a command-line tool for displaying\n    information about ", "."], "package_details": ["\n", " and ", " are handy command-line tools that provide reference information for developers and also serve as a powerful introspection tool for learning more about data being transmitted in ROS.  ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", " and ", " are stable tools. There is currently no plan to add new features to them. ", "For example, if you are using a message in your code, you can type ", " at the command-line to look up its fields: ", "For even quicker typing, you can omit \"", "\", and ", " will search all packages for a matching message. ", "You can also use this in an online system with tools like ", ". For example, ", " will tell you the message type of a topic: ", "You can pass this to ", " to quickly see the fields of the message: ", "Once you know more about the fields of a particular message, you can then listen them at the command-line, e.g. ", "The ", " command-line tool displays information about ROS ", ". The following sections describe the commands that are available. ", "Note that messages in a subfolder may not be listed as of March 2017 (", "). ", "The ", " command-line tool displays information about ROS services. It has the exact same usage as ", " (see what it offers when it runs without sub-command below): "], "package_tt": ["rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg\u00a0show", "my_pkg", "rosmsg", "rostopic\u00a0type", "rosmsg", "rosmsg", "show\u00a0<message\u00a0type>", "rosmsg", "-r", "-b\u00a0BAGFILE", "list", ".msg", "package\u00a0<package-name>", "-s", "packages", ".msg", "-s", "users\u00a0<message\u00a0type>", "rosmsg\u00a0users", "md5\u00a0<message\u00a0type>", "rossrv", "rosmsg", "rosmsg", "rossrv"], "package_code": ["$ rosmsg show sensor_msgs/CameraInfo\n", "Header header\n", "  uint32 seq\n", "  time stamp\n", "  string frame_id\n", "uint32 height\n", "uint32 width\n", "RegionOfInterest roi\n", "  uint32 x_offset\n", "  uint32 y_offset\n", "  uint32 height\n", "  uint32 width\n", "float64[5] D\n", "float64[9] K\n", "float64[9] R\n", "float64[12] P", "$ rostopic type rosout\n", "roslib/Log", "rostopic type rosout | rosmsg show\n", "byte DEBUG=1\n", "byte INFO=2\n", "byte WARN=4\n", "byte ERROR=8\n", "byte FATAL=16\n", "Header header\n", "  uint32 seq\n", "  time stamp\n", "  string frame_id\n", "byte level\n", "string name\n", "string msg\n", "string file\n", "string function\n", "uint32 line\n", "string[] topics", "$ rostopic echo rosout/msg", "$ rosmsg show std_msgs/String", "$ rosmsg show Pose", "$ rostopic type /topic_name | rosmsg show", "$ rosmsg show -r robot_msgs/Quaternion\n", "# xyz - vector rotation axis, w - scalar term (cos(ang/2))\n", "float64 x\n", "float64 y\n", "float64 z\n", "float64 w", "$ rosmsg list\n", "nav_msgs/GridCells\n", "nav_msgs/MapMetaData\n", "nav_msgs/OccupancyGrid\n", "nav_msgs/Odometry\n", "nav_msgs/Path\n", "...", "$ rosmsg package nav_msgs\n", "nav_msgs/OccupancyGrid\n", "nav_msgs/Path\n", "nav_msgs/MapMetaData\n", "nav_msgs/Odometry\n", "nav_msgs/GridCells", "$ rosmsg packages\n", "std_msgs\n", "roscpp\n", "roslib\n", "...", "$ rosmsg users sensor_msgs/CameraInfo\n", "Files using sensor_msgs/CameraInfo:\n", "Usages directly depended upon:sensor_msgs/CameraInfo\n", "/home/user/ros-pkg/pr2_simulator/pr2_gazebo_plugins/include/pr2_gazebo_plugins/gazebo_ros_prosilica.h\n", "...", "$ rossrv\n", "rossrv is a command-line tool for displaying information about ROS Service types.\n", "\n", "Commands:\n", "        rossrv show     Show service description\n", "        rossrv list     List all services\n", "        rossrv md5      Display service md5sum\n", "        rossrv package  List services in a package\n", "        rossrv packages List packages that contain services\n", "\n", "Type rossrv <command> -h for more detailed usage"]},
{"url": "https://wiki.ros.org/maxwell_calibration", "package": "maxwell_calibration", "package_summary": ["\n    Launch and configuration files for calibrating Maxwell using the new generic 'calibration' stack.\n  "], "package_details": ["\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/camera_handler", "package": "camera_handler", "package_summary": ["The camera_handler package"], "package_details": ["\n", " ", "\n", "In V-REP it is possible to simulate a vision sensor. Vision sensors are added to the scene with [menu bar --> Add --> Vision sensor]. After a double-click on a vision-sensor, we can set some parameters like the resolution and the field of view of the camera. In addition we added a GUI to set the frequency of acquisition and the type of color coding (RGB or grayscale) that should be used. "], "package_code": [" /vrep/Vision_sensor_0\n", " /vrep/Vision_sensor_0/Camerainfo\n", " /vrep/Vision_sensor_0/compressed\n", " /vrep/Vision_sensor_0/compressed/parameter_descriptions\n", " /vrep/Vision_sensor_0/compressed/parameter_updates\n", " /vrep/Vision_sensor_0/compressedDepth\n", " /vrep/Vision_sensor_0/compressedDepth/parameter_descriptions\n", " /vrep/Vision_sensor_0/compressedDepth/parameter_updates\n", " /vrep/Vision_sensor_0/theora\n", " /vrep/Vision_sensor_0/theora/parameter_descriptions\n", " /vrep/Vision_sensor_0/theora/parameter_updates"]},
{"url": "https://wiki.ros.org/jog_launch", "package": "jog_launch", "package_summary": ["Collection of the launch files for jog_controller"]},
{"url": "https://wiki.ros.org/ridgeback_description", "package": "ridgeback_description", "package_summary": ["URDF robot description for Ridgeback"], "package_details": ["\n", " ", "\n", "\n", "This package provides a ", " model of ", ". For an example launchfile to use in visualizing this model, see ", ". ", "Ridgeback has a suite of optional payloads called accessories. These payloads can be enabled and placed on Ridgeback using environment variables specified at the time the ", " is rendered to URDF. Available accessory vars are: ", "As an alternative to individually specifying each accessory, some fixed configurations are provided in the package. These can be specified using the ", " arg to ", ", and are intended especially as a convenience for simulation launch. "], "package_tt": ["RIDGEBACK_FRONT_LASER", "0", "RIDGEBACK_FRONT_LASER_MOUNT", "front", "RIDGEBACK_FRONT_LASER_OFFSET", "\"0\u00a00\u00a00\"", "RIDGEBACK_FRONT_LASER_RPY", "\"0\u00a00\u00a00\"", "RIDGEBACK_FRONT_LASER_HOST", "192.168.131.14", "RIDGEBACK_REAR_LASER", "0", "RIDGEBACK_REAR_LASER_MOUNT", "rear", "RIDGEBACK_REAR_LASER_OFFSET", "\"0\u00a00\u00a00\"", "RIDGEBACK_REAR_LASER_RPY", "\"0\u00a00\u00a00\"", "RIDGEBACK_REAR_LASER_HOST", "192.168.131.13", "config", "description.launch", "base", "dual_laser"]},
{"url": "https://wiki.ros.org/rtt_std_msgs", "package": "rtt_std_msgs", "package_summary": ["Provides an rtt typekit for ROS std_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/std_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/jog_control", "package": "jog_control", "package_summary": ["This metapackage depends on packages related to jog control."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/steer_bot_hardware_gazebo", "package": "steer_bot_hardware_gazebo", "package_summary": ["steer bot hardware for gazebo simulation"], "package_details": ["\n", " inherits ", " so that the plugin is integrated to ", ". ", "\n", "\n", " is designed to have two joint interfaces, one is velocity_joint_interface for the single rear wheel joint and the other is position_joint_interface for the single front steer joint. This concept keeps the controller's abstraction to be applied in various types of configuration by converting the joint interfaces in the controller to ones on an actual robot via ", " or ", ". ", "\n", " ", "\n", " ", " ", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", " has an example launch file to spawn ", " with ", " named ", ". ", "An example of usage of this plugin can be seen in ", ", especially in ", ". ", "This package provides 4-wheel car-like robot model with steer mechanism for Gazebo simulation, by using ", " plugin. ", "We developed this plugins assuming that ", " is selected as the driving controller. ", "Now we need to do it for a Gazebo model too, which is the main role of this plugin. The following figure shows how a velocity command of ", " converted to a joint command to ", " via ", ". ", "Each type of joint interface on ", " is split into two interface for right and left. This is because ", " doesn't support closed links (e.g. parallel link or Ackermann link), which means we need to virtually imitate such links by software. ", "In order to achieve the conversion mentioned above, you need to register joint interfaces for both ", " and ", " in ", ". ", "For ", ", it's simple to just register two joint interface for a rear wheel and a front steer as mentioned previously. ", "For ", ", 4 more velocity joint interfaces for wheels and 2 more position joint interface for front steers (in total 2 + 4 + 2 = 8 joint interface are registered in this plugin).  ", "An example of registering such joint interfaces can be seen in ", ". ", "In ", " in your robot, add the following tag to apply ", ". ", "An example of a xacro is ", " in ", ". "], "package_tt": ["gazebo_ros_control", "steer_bot_hardware_gazebo::SteerBotHardwareGazebo", "gazebo_ros_control::RobotHWSim", "Gazebo", "RobotHW", "RobotHWSim", "geometry_msgs::Twist", "Gazebo", "URDF", "Gazebo", "steer_bot_hardware_gazebo", "steer_drive_controller", "Gazebo", "Gazebo", "URDF", "description.gazebo.xacro", "rear_wheel", "string", "front_steer", "string", "virtual_rear_wheels", "string\u00a0[2]", "Gazebo", "virtual_front_wheels", "string\u00a0[2]", "Gazebo", "virtual_front_steers", "string\u00a0[2]", "Gazebo", "enable_ackermann_link", "bool", "wheel_separation_w", "double", "wheel_separation_h", "double", "cirkit_unit03_world.launch"], "package_code": ["  <!-- Gazebo plugin for ROS Control -->\n", "  <gazebo>\n", "    <plugin name=\"gazebo_ros_control\" filename=\"libgazebo_ros_control.so\">\n", "      <robotNamespace>/</robotNamespace>\n", "      <robotSimType>steer_bot_hardware_gazebo/SteerBotHardwareGazebo</robotSimType>\n", "    </plugin>\n", "  </gazebo>", "gains:\n", "  base_to_right_rear_wheel  :  {p: 100000.0, d: 10.0, i: 0.50, i_clamp: 3.0}\n", "  base_to_left_rear_wheel   :  {p: 100000.0, d: 10.0, i: 0.50, i_clamp: 3.0}"]},
{"url": "https://wiki.ros.org/turtlebot_dashboard", "package": "turtlebot_dashboard", "package_summary": ["Launchers for the base-specific dashboards"], "package_tt": ["turtlebot_dashboard", "Stale", "Stale", "Stale", "Stale"], "package_code": ["rosrun turtlebot_dashboard turtlebot_dashboard", "export ROS_MASTER_URI=http://MY_ROBOT:11311", "roslaunch turtlebot_dashboard turtlebot_dashboard.launch", "roslaunch turtlebot_dashboard turtlebot_dashboard.launch", "roslaunch turtlebot_dashboard turtlebot_dashboard.launch"]},
{"url": "https://wiki.ros.org/perception_oru", "package": "perception_oru", "package_summary": ["Perception packages from the MRO lab at AASS, Orebro University", "All packages in this stack for fuerte can be downloaded from the project svn trunk. "], "package_details": ["\n", "\n", " ", "For documentation, please check the package pages. Description of the NDT data structures and related papers can be found in ", ". Usage of the NDT for registration is documented in the ", " package. Visualization tools can be found at ", ". Finally, the truncated SDF tracking package is documented at ", ". "]},
{"url": "https://wiki.ros.org/tra1_description", "package": "tra1_description", "package_summary": ["This package contains the description (mechanical, kinematic, visual,  etc.) of the TRA1 robot. The files in this package are parsed and used by a variety of other components.  Most users will not interact directly with this package."], "package_details": ["\n", " ", "\n", " "], "package_code": ["$ roslaunch tra1_description tra1.launch"]},
{"url": "https://wiki.ros.org/svenzva_msgs", "package": "svenzva_msgs", "package_summary": ["Svenzva arm and state related messages."], "package_details": [" ", " ", " ", "\n", " ", " ", "\n", " ", " "]},
{"url": "https://wiki.ros.org/lockfree", "package": "lockfree", "package_summary": ["The lockfree package contains lock-free data structures for use in multithreaded programming.  These\n     kinds of data structures are generally not as easy to use as single-threaded equivalents, and are not\n     always faster.  If you don't know you need to use one, try another structure with a lock around it\n     first."], "package_details": ["\n", "\n", "\n", "\n", "The ", " package contains ", " generally meant to be used in realtime or high-performance multithreaded systems. ", "Currently ", " contains 2 data structures, ", " and ", ". ", "The ", " class provides a fixed number of fixed-size blocks that you can allocate and free from multiple threads.  ", " is lock-free but not wait-free. ", "While the ", " class simply provides allocation of specific-sized blocks of memory, the ", " class builds on top of that to provide allocation of specific object types, initialized using a template object.  It also allows you to allocate either ", "s or bare pointers, depending on your needs.  ", " is lock-free but not wait-free. "], "package_tt": ["FreeList", "FreeList", "boost::shared_ptr", "ObjectPool"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/ridgeback_base", "package": "ridgeback_base", "package_summary": ["Ridgeback's mobility and sensor base."], "package_details": ["\n", "\n", "This package contains the primary binary which runs on ", ", providing the ", "-based communication the MCU, as well as diagnostic support, and other basic services such as lighting and cooling.  In addition, it provides the CAN based communication to the ", ". ", "Ridgeback includes a built-in magnetometer, which is used by ", " to estimate orientation. To calibrate the magnetometer using scripts provided by this package, see ", ". "]},
{"url": "https://wiki.ros.org/roscpp_core", "package": "roscpp_core", "package_summary": ["Underlying data libraries for roscpp messages."], "package_details": [" "]},
{"url": "https://wiki.ros.org/realtime_tools", "package": "realtime_tools", "package_summary": ["Contains a set of tools that can be used from a hard\n    realtime thread, without breaking the realtime behavior.  The\n    tools currently only provides the realtime publisher, which makes\n    it possible to publish messages to a ROS topic from a realtime\n    thread. We plan to add a basic implementation of a realtime\n    buffer, to make it possible to get data from a (non-realtime)\n    topic callback into the realtime loop. Once the lockfree buffer is\n    created, the realtime publisher will start using it, which will\n    result in major API changes for the realtime publisher (removal of\n    all lock methods)."], "package_details": ["\n", "The ", " allows users that write C++ ", " to publish messages on a ROS topic from a hard realtime loop. The normal ROS publisher is not realtime safe, and should not be used from within the update loop of a realtime controller. The realtime publisher is a wrapper around the ROS publisher; the wrapper creates an extra non-realtime thread that publishes messages on a ROS topic. The example below shows a typical usage of the realtime publisher in the ", " and ", " methods of a realtime controller: "], "package_tt": ["realtime_tools::RealtimePublisher", "init()", "update()"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/turtlebot3_msgs", "package": "turtlebot3_msgs", "package_summary": ["Message and service types: custom messages and services for TurtleBot3 packages"], "package_details": [" ", "\n", "\n", " ", "\n  ", " ", "\n ", " ", "\n ", " ", "\n ", "\n", " ", "\n ", " ", "\n "]},
{"url": "https://wiki.ros.org/people_msgs", "package": "people_msgs", "package_summary": ["Messages used by nodes in the people stack."], "package_details": ["\n", " - Generic message for detecting the location of a person. Includes a 3-D point estimate, reliability estimate and covariance matrix. ", " - An array of PositionMeasurements as well as a co-occurence array. ", " - A position estimate with an added velocity vector, as well as the ability to add tags to the person. Has no header, should only be used in conjunction with PersonStamped or People. ", " - A header + a person ", " - A header + an array of persons ", " "]},
{"url": "https://wiki.ros.org/spur_gazebo", "package": "spur_gazebo", "package_summary": ["3D simulation package for SPUR omni-directional mobile manipulator robot made at Tamagawa University."]},
{"url": "https://wiki.ros.org/touch_skill_msgs", "package": "touch_skill_msgs", "package_summary": ["touch_skill messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"touch_skill_msgs\" in rosdoc: /home/rosbot/docs/api/touch_skill_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/katana_tutorials", "package": "katana_tutorials", "package_summary": ["This package contains test and demo programs for the katana_driver stack."]},
{"url": "https://wiki.ros.org/uavc_v4lctl", "package": "uavc_v4lctl", "package_summary": ["ROS wrapper for the v4lctl tool"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", "This ROS node is just a wrapper for the ", " tool. It provides two services, to set and to get particular ", " video device parameter. If a yaml file will be provided a save and restore capability will be enabled. Parameter are then loaded and set automatically in the capture device when starting the node. Changed parameter are stored to a yaml file when the program ends. Additionally a dynamic reconfigure rqt gui is available to manipulate v4l parameter. ", "The below v4lctl list output is based on an Osprey 440 bttv capture card. ", " is optimized for this card (but the services provided by this ROS node are generic and can be used for any hardware related available v4l parameter). Your card may output other options. To support them as well feel free to adapt the files v4lctl_node.cpp and v4lctlNodeDyn.cfg in the repository to your needs. ", "The sources can be found here: ", " "], "package_tt": ["v4lctlSet", "v4lctlGet", "~device", "string", "~yaml", "string"], "package_code": ["$ v4lctl list\n", "  attribute  | type   | current | default | comment\n", "  -----------+--------+---------+---------+-------------------------------------\n", "  norm       | choice | PAL-I   | NTSC    | NTSC NTSC-M NTSC-M-JP NTSC-M-KR PAL PAL-BG PAL-H PAL-I PAL-DK PAL-M PAL-N PAL-Nc PAL-60 SECAM SECAM-B SECAM-G SECAM-H SECAM-DK SECAM-L SECAM-Lc\n", "  input      | choice | Composi | Composi | Composite0 Composite1 Composite2 Composite3\n", "  bright     | int    |   32768 |   32768 | range is 0 => 65280\n", "  contrast   | int    |   32768 |   27648 | range is 0 => 65408\n", "  color      | int    |   32768 |   32768 | range is 0 => 65408\n", "  hue        | int    |   32768 |   32768 | range is 0 => 65280\n", "  mute       | bool   | on      | off     |\n", "  Chroma AGC | bool   | off     | off     |\n", "  Color Kill | bool   | off     | off     |\n", "  Comb Filte | bool   | off     | off     |\n", "  Auto Mute  | bool   | on      | on      |\n", "  Luma Decim | bool   | off     | off     |\n", "  AGC Crush  | bool   | on      | on      |\n", "  VCR Hack   | bool   | off     | off     |\n", "  Whitecrush | int    |     127 |     127 | range is 0 => 255\n", "  Whitecrush | int    |     207 |     207 | range is 0 => 255\n", "  UV Ratio   | int    |      51 |      50 | range is 0 => 100\n", "  Full Luma  | bool   | off     | off     |\n", "  Coring     | int    |       0 |       0 | range is 0 => 3", "$ roslaunch uavc_v4lctl v4lctl.launch device:=/dev/video1", "$ rosservice call /v4lctlSet bright \"77%\"\n", "$ rosservice call /v4lctlGet bright\n", "\n", "$ rosservice call /v4lctlSet hue '!!str 40000'\n", "$ rosservice call /v4lctlGet hue\n", "\n", "$ rosservice call /v4lctlSet 'setattr \"UV Ratio\"' 30%\n", "$ rosservice call /v4lctlGet \"UV Ratio\"", "cd ~/catkin_ws/src\n", "git clone https://github.com/meuchel/uavc_v4lctl\n", "cd ~/catkin_ws\n", "catkin build # depending on your workspace it could also be catkin_make"]},
{"url": "https://wiki.ros.org/turtlesim", "package": "turtlesim", "package_summary": ["turtlesim is a tool made for teaching ROS and ROS packages."], "package_details": ["\n", "\n", " As of ", " turtlesim uses the ", "/Twist message instead of its own custom one (", " in ", " and older). Also the topic has been changed to ", " (instead of ", " before). ", "\n", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "command_velocity", "turtlesim_node", "turtleX/cmd_vel", "turtleX/pose", "clear", "reset", "kill", "spawn", "turtleX/set_pen", "turtleX/teleport_absolute", "turtleX/teleport_relative", "~background_b", "int", "~background_g", "int", "~background_r", "int", "mimic", "input", "mimic", "pose", "output", "mimic", "cmd_vel"], "package_code": ["$ roscore", "$ sudo apt-get install ros-$(rosversion -d)-turtlesim", "$ rosrun turtlesim turtlesim_node"]},
{"url": "https://wiki.ros.org/acado", "package": "acado", "package_summary": ["ACADO Toolkit"], "package_details": [" is a software environment and algorithm collection for automatic control and dynamic optimization. It provides a general framework for using a great variety of algorithms for direct optimal control, including model predictive control, state and parameter estimation and robust optimization. ACADO Toolkit is implemented as self-contained C++ code and comes along with user-friendly Matlab interfaces. The object-oriented design allows for convenient coupling of existing optimization packages and for extending it with user-written optimization routines. ", "The ACADO Toolkit is made available in ROS Indigo by ", ". You can install it on Ubuntu like so: "], "package_code": ["sudo apt-get install ros-indigo-acado"]},
{"url": "https://wiki.ros.org/visp_tracker", "package": "visp_tracker", "package_summary": ["Wraps the ViSP moving edge tracker provided by the ViSP visual\n    servoing library into a ROS package.\n\n    This computer vision algorithm computes the pose (i.e. position\n    and orientation) of an object in an image. It is fast enough to\n    allow object online tracking using a camera."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", " is part of ", " stack.  ", "\n", " ", "\n", "\n", "\n", "\n", "\n", " even if a nodelet is available for the client and viewer, one should avoid running them in the same process than the vision pipeline to avoid crashing the whole pipeline if something goes wrong. ", "\n", "\n", " ", "The package is composed of one node called ", " that does the tracking and two additional nodes ", " (that allows to set the initial pose by user mouse click) and ", " that allows to visualize the result of the tracking. ", "The ", " node tries to track the object as fast as possible but needs to be initialized using the client. The viewer can be used to monitor the tracking result. ", "When the nodelet version is used, no-copy intraprocess publishing is used. See the ", " documentation for more information. ", "Use GitHub to ", ". "], "package_tt": ["tracker", "client", "viewer", "tracker", "~camera_prefix/camera_info", "~camera_prefix/image_rect", "object_position_hint", "object_position", "object_position_covariance", "moving_edge_sites", "klt_points_positions", "init_tracker", "tracking_meta_data", "~camera_prefix", "std_msgs/String", "~first_threshold", "float64", "~lambda", "float64", "~mask_size", "int64", "~min_samplestep", "float64", "~model_name", "std_msgs/String", ".wrl", "~model_path", "std_msgs/String", "package://", "http://", "~mu1", "float64", "~mu2", "float64", "~n_mask", "int64", "~n_total_sample", "int64", "~range", "int64", "~sample_step", "int64", "~strip", "int64", "~threshold", "float64", "~aberration", "float64", "~init_aberration", "float64", "~compensate_robot_motion", "bool", "~world_frame_id", "string", "~compensate_robot_motion", "~world_frame_id", "<camera\u00a0frame>", "~compensate_robot_motion", "<camera\u00a0frame>", "visp_tracker", "~camera_prefix", "std_msgs/String", "~tracker_prefix", "std_msgs/String", "~model_path", "std_msgs/String", "~model_name", "std_msgs/String", "~tracker_prefix", "std_msgs/String", "~image_transport", "string", "visp_tracker/Tracker", "visp_tracker/TrackerClient", "visp_tracker/TrackerViewer"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-visp-tracker", "sudo apt-get install ros-$ROS_DISTRO-vision-visp", "roslaunch visp_tracker tutorial-nodelet.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/sr_edc_muscle_tools", "package": "sr_edc_muscle_tools", "package_summary": ["\n\n     sr_edc_muscle_tools - Usefull commands and basic demo for the ethercat muscle hand.\n\n  "]},
{"url": "https://wiki.ros.org/pr2_calibration_launch", "package": "pr2_calibration_launch", "package_summary": ["Launch files and configuration files needed to run the calibration pipeline on PR2. This package is\n     still experimental. Expect large changes tp occur."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/staubli_tx90_support", "package": "staubli_tx90_support", "package_summary": ["\n      ROS-Industrial support for the Staubli TX90 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for Staubli TX90 manipulators. This includes the base model,\n      as well as models with extended arm and forearm links.\n    ", ":", "\n      Joint limits, torque limits, and maximum joint velocities are based on the\n      information in the ", " version ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise (ie: no support for high speed joints, extended /\n      limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      ", ": Masses, center of mass and moments of inertia were calculated\n      using Solidworks and the official Staubli CAD models, and may not be\n      accurate.\n    ", "\n      ", ": In order to allow maximum torque on axis 6, effort limit on\n      axis 5 was set to 29 Nm, rather than a feasible 58 Nm if torque on\n      axis 6 = 0 Nm (see superscripts (1) and (2) from table in Section 2.6.2\n      -Torque Limits- of the instruction manual for details).\n    ", ":", "\n      This support package has received contributions from: Panagiotis \n      Sotiropoulos (Ocado Technology) (TX90/TX90L/TX90XL).\n    "]},
{"url": "https://wiki.ros.org/basic_states_skill_msgs", "package": "basic_states_skill_msgs", "package_summary": ["basic_states_skill messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"basic_states_skill_msgs\" in rosdoc: /home/rosbot/docs/api/basic_states_skill_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/nao_extras", "package": "nao_extras", "package_summary": ["\n    This stack contains tools for the Nao robot (in addition to the nao_robot stack) to run\n  remotely on the PC. It provides teleoperation with a gamepad and path following. Renamed\n    from the nao_common stack.\n  "], "package_details": ["This stack replaces parts of the ", " stack since version 0.2. "]},
{"url": "https://wiki.ros.org/rtt_geometry_msgs", "package": "rtt_geometry_msgs", "package_summary": ["Provides an rtt typekit for ROS geometry_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/geometry_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/linksys_access_point", "package": "linksys_access_point", "package_summary": ["\n    A ROS node that controls a Linksys access point with\n    a Linksys WRT610n-compatible web interface.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package implements the ", " dynamic_reconfigure interface for controlling an access point for Linksys access points.  "], "package_tt": ["txpower_auto", "False", "Manual", "Wireless/Basic\u00a0Wireless\u00a0Settings", "Wi-Fi\u00a0Protected\u00a0Setup", "update_configuration()", "wmm", "a", "b", "g", "n", "a", "a-only", "a", "n", "mixed", "b", "b-only", "b", "n", "g", "g-only", "g", "n", "mixed", "linksys_apcontrol_node.py", "~interface", "string", "wl0", "wl0", "wl1", "~ip", "string", "192.168.1.1", "~user", "string", "~password", "string", "admin"]},
{"url": "https://wiki.ros.org/std_msgs", "package": "std_msgs", "package_summary": ["Standard ROS Messages including common message types representing primitive data types and other basic message constructs, such as multiarrays.\n    For common, generic robot-specific message types, please see ", "."], "package_details": ["\n", " contains wrappers for ROS primitive types, which are documented in the ", ". It also contains the ", " type, which is useful for sending an empty signal. However, these types do not convey semantic meaning about their contents: every message simply has a field called \"", "\". Therefore, while the messages in this package can be useful for quick prototyping, they are ", ". For ease of documentation and collaboration, we recommend that existing messages be used, or new messages created, that provide meaningful field name(s). ", "\n", "\n", "Note that this package also contains the \"MultiArray\" types, which can be useful for storing sensor data. ", ", the same caveat applies: it's usually \"better\" (in the sense of making the code easier to understand, etc.) when developers use or create non-generic message types (see ", " for more detail). ", "There are currently no plans to add new data types to the ", " package.  "], "package_tt": ["std_msgs", "Empty", "data", "std_msgs"]},
{"url": "https://wiki.ros.org/ridgeback_bringup", "package": "ridgeback_bringup", "package_summary": ["Scripts for installing Ridgeback's robot software."], "package_details": ["\n", "See ", " for information on Ridgeback configurations. "]},
{"url": "https://wiki.ros.org/asr_mild_calibration_tool", "package": "asr_mild_calibration_tool", "package_summary": ["A tool to calibrate the relative frames between the mild's laserscanner and the cameras"], "package_details": [" ", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", " ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides a tool to collect transformation data between the mild's laserscanner sensor and it's camera head. This data can then used calibrate the mild's kinematic chain using the ", ". ", "The calibration object in the form of a ", "could be recognized by a 2D laserscanner and, using its detected edges p", ", p", "and p", " as well as the priorly known proportions, the pose of its top point ", " can be calculated. ", "All relevant specifications for the calibration object can be retrieved and even changed using the ", " file. ", "Two ", " have been integrated into the calibration software: ", "Both the ", " (left), which is used in the mild platform, as well as the ", " (right), which has been used for evaluation of the calibration tool, have been integrated into the package and can be selected by changing a single parameter (", " ", "The supported types of ", " units depend on the ", "  package and are described there. ", "All ", " supported by the ", " package can be used for calibration. "], "package_code": ["roslaunch asr_mild_calibration_tool calibration_tool.launch"]},
{"url": "https://wiki.ros.org/turtlebot_2dnav", "package": "turtlebot_2dnav", "package_summary": ["The turtlebot_2dnav package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " application can be run with the following command: ", "The ", " stack that is the core of the turtlebot_2dnav application can be commanded via ", ", ", ", or through code. "], "package_code": ["roslaunch turtlebot_2dnav turtlebot_2dnav.launch map_file:=/my_map.yaml", "roslaunch turtlebot_rviz_launchers view_navigation.launch --screen", "roslaunch rosbridge_server rosbridge_websocket.launch"]},
{"url": "https://wiki.ros.org/automotive_platform_msgs", "package": "automotive_platform_msgs", "package_summary": ["Generic Messages for Communication with an Automotive Autonomous Platform"]},
{"url": "https://wiki.ros.org/tedusar_box_detection_msgs", "package": "tedusar_box_detection_msgs", "package_summary": ["Action definition for the tedusar_box_detection package."]},
{"url": "https://wiki.ros.org/spinnaker_sdk_camera_driver", "package": "spinnaker_sdk_camera_driver", "package_summary": ["Point Grey (FLIR) Spinnaker based camera driver (Blackfly S etc.)"], "package_details": ["\n", "\n", "\n", "\n", "  ", "Modify the ", " file replacing the cam-ids and master cam serial number to match your camera's serial number. Then run the code as: "], "package_tt": ["params/test_params.yaml"], "package_code": ["# after installing spinnaker verify that you can run your cameras with SpinView\n", "# after installing ros, install other pre-requisites with:\n", "sudo apt install libunwind-dev ros-kinetic-cv-bridge ros-kinetic-image-transport", "bash mkdir -p ~/spinnaker_ws/src cd spinnaker_ws/src\n", "git clone https://github.com/neufieldrobotics/spinnaker_sdk_camera_driver.git\n", "cd ~/spinnaker_ws/\n", "catkin_make\n", "source ~/spinnaker_ws/devel/setup.bash\n", "# add this to ~/.bashrc to make this permanent", "roslaunch spinnaker_sdk_camera_driver acquisition.launch\n", "\n", "# Test that the images are being published by running rqt_image_view"]},
{"url": "https://wiki.ros.org/staubli", "package": "staubli", "package_summary": ["ROS-Industrial support for Staubli manipulators (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This repository is part of the ", " program. It currently contains robot support packages for Staubli manipulators and associated ", " packages. ", "See the ", " metapackage for additional packages. ", "See ", " for a VAL 3 based driver for use with CS8 controllers and Staubli 6-axis manipulators. See the ", " and the ", " for more information. ", "For the generic ROS-Industrial tutorials, please see the ROS-Industrial ", ". ", "For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/termcolor", "package": "termcolor", "package_summary": ["C++ library for printing colours in ansii consoles."]},
{"url": "https://wiki.ros.org/task_allocation", "package": "task_allocation", "package_summary": ["A package that offers action servers for assigning tasks between cyber physical system (CPS)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The communication between CPSs is based on the ", ". ", "The following packages of the ", " are required: ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the auction process. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["id", "integer", "output", "string", "screen", "screen", "log", "param", "task_allocation.yaml", "auction_action", "task_allocation_auction", "cmd/task_allocation_auction/goal", "cmd/task_allocation_auction/result", "bridge/events/cps_selection", "cps_selected", "~loop_rate", "real", "~queue_size", "integer", "~timeout", "real", "bid_action", "task_allocation_bid", "cmd/task_allocation_bid/goal", "cmd/task_allocation_bid/result", "pos_provider/pose", "bridge/uuid", "bridge/events/cps_selected", "cps_selection", "~loop_rate", "real", "~queue_size", "integer"], "package_code": ["roslaunch task_allocation task_allocation.launch"]},
{"url": "https://wiki.ros.org/asr_halcon_bridge", "package": "asr_halcon_bridge", "package_summary": ["This package is used to convert between image-messages of the ROS environment and HALCON-images."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This Package contains a library which is used to convert point clouds and images between ROS and ", " specific data structures. ", "The structure of this library is mostly based on the ", "-package, for more information you can check out the documentation for that. ", "To be able to build this package and use it in your project you will need to have a version of the ", " image processing library installed. So far it was tested mainly with version 11 but in theory it should work with higher versions as well as the basic structure of the data types has not changed (build tests have been conducted with version 12 as well). ", "The environment variables ", " and ", " need to be set correctly, otherwise cmake won't be able to find your HALCON installation. Usually this should be the case if you have followed the installation guide of HALCON. ", "To convert a ", " to a ", " call one of the following functions: ", "The return-value is a ", "object, which contains a", "-Pointer as a member called ", ". ", "To convert a ", " to ROS again call one of the following member functions: ", "to convert a ", " to a", " (the member in the returned ", " is called ", "). "], "package_code": ["HalconImagePtr toHalconCopy(const sensor_msgs::ImageConstPtr& source)\n", "HalconImagePtr toHalconCopy(const sensor_msgs::Image& source);", "sensor_msgs::ImagePtr toImageMsg() const;\n", "void toImageMsg(sensor_msgs::Image& ros_image) const;", "HalconPointcloudPtr toHalconCopy(const sensor_msgs::PointCloud2ConstPtr& source);\n", "HalconPointcloudPtr toHalconCopy(const sensor_msgs::PointCloud2& source);", "sensor_msgs::PointCloud2Ptr toPointcloudMsg() const;\n", "void toPointcloudMsg(sensor_msgs::PointCloud2& ros_pointcloud) const;"]},
{"url": "https://wiki.ros.org/stdr_parser", "package": "stdr_parser", "package_summary": ["Provides a library to STDR Simulator, to parse yaml and xml description files."], "package_details": ["\n", " is a Yaml/XML parser created for ", ". Its job is to parse resource files (robots and sensors) and create the according stdr_msgs. Also, provided a stdr_msgs message ", " can save it to a Yaml or XML file. The parser structure is such that it can be \"easily\" extended with more file types (such as JSON f.e.) by changing only specific source files (the filetype parser and writer). A brief overview of the parsing steps follow. ", "\n", "\n", " takes as input a Yaml or XML file and initially does a \"blind\" parsing of the file, meaning that no validation is performed. Of course if the file does not exist or is malformed, a ", " is thrown. This initial parsing creates a tree consisting of stdr_parser::Node objects and represents the initial file. As the following sections describe, for convenience reasons you can have ", " tags in your robot or sensor file, which are used for including  other resources (for example in a robot you can include laser and sonar sensors without writing them from the scratch). During the parsing the specific filenames are parsed also recursively. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "When a ", " tag is found, during the parsing step, a stdr_parser::Node is created tagged as ", ". For example a robot XML resource follows: ", "and the ", " ", "In addition, every ", " contains a level value that is increased when the recurrent file depth increases. After the first step, the tree will look like that (the levels in [ ]): ", "The second step is to eliminate the ", " tags from the tree. To do so a sanity check is performed: the parent node and the child node of a ", " node must be the same. If the above holds, the ", " node is eliminated, as well as its child and the child's children are connected to ", "'s parent. The result follows: ", "The third step is the recursive node merging. In this step the ", " file under ", " is of crucial importance. There, the tags that can have multiple occurrences under a specific tag are placed. The current implementation allows multiple occurrences in these tags: ", "This is the final parsing step where the validation is performed. Crucial role plays the ", " file under ", ". There for every valid tag, the allowed and required children are specified. (Look at the end of the page for the file's contents). The validation step reads this file and performs ", " and ", " checks for all tree nodes.  ", "After the tree is fully created, ", " can create the according ", ". This is performed seamlessly by using templates. An example of creating a ", " follows: ", "In a similar way a ", " message can be saved to a Yaml or XML file: ", "If anything goes wrong an ", " is thrown. The way to use it in a source code file follows: ", "The ", " exceptions hold a trail of the error for better debugging. Example: "], "package_tt": ["ParserException", "hokuyo.xml", "stdr_parser::Node", "filename", "filename", "filename", "filename", "stdr_resources/resources/specifications", "stdr_resources/resources/specifications", "ParserException", "ParserException", "stdr_specifications.xml"], "package_code": ["<robot>\n", "  <robot_specifications>\n", "    <footprint>\n", "      <radius>0.3</radius>\n", "    </footprint>\n", "    <laser>\n", "      <filename>hokuyo.xml</filename>\n", "      <laser_specifications>\n", "        <pose>\n", "          <theta>1.57</theta>\n", "        </pose>\n", "      </laser_specifications>\n", "    </laser>\n", "  </robot_specifications>\n", "<robot>", "<laser>\n", "  <laser_specifications>\n", "    <max_range>4</max_range>\n", "    <pose>\n", "      <x>0</x>\n", "      <y>0</y>\n", "      <theta>0</theta>\n", "    </pose>\n", "    <noise>\n", "      <filename>gauss_small.xml</filename>\n", "    </noise>\n", "  </laser_specifications>\n", "</laser>", "<noise>\n", "  <noise_specifications>\n", "    <noise_mean>0</noise_mean>\n", "    <noise_std>0.03</noise_std>\n", "  </noise_specifications>\n", "</noise>", "\u251c robot [0]\n", "\u2502 \u251c robot_specifications [0]\n", "\u2502 \u2502 \u251c footprint [0]\n", "\u2502 \u2502 \u2502 \u251c radius [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c 0.3 [0]\n", "\u2502 \u2502 \u251c laser [0]\n", "\u2502 \u2502 \u2502 \u251c  filename [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c laser [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c laser_specifications [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c max_range [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 4 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c pose [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c x [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c y [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c filename [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_specifications [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_mean [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_std [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0.03 [2]\n", "\u2502 \u2502 \u2502 \u251c laser_specifications [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c pose [0]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [0]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 1.57 [0]", "\u251c robot [0]\n", "\u2502 \u251c robot_specifications [0]\n", "\u2502 \u2502 \u251c footprint [0]\n", "\u2502 \u2502 \u2502 \u251c radius [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c 0.3 [0]\n", "\u2502 \u2502 \u251c laser [0]\n", "\u2502 \u2502 \u2502 \u251c laser_specifications [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c max_range [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c 4 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c pose [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c x [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c y [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c noise [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_specifications [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_mean [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_std [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0.03 [2]\n", "\u2502 \u2502 \u2502 \u251c laser_specifications [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c pose [0]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [0]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 1.57 [0]", "\u251c robot [0]\n", "\u2502 \u251c robot_specifications [0]\n", "\u2502 \u2502 \u251c footprint [0]\n", "\u2502 \u2502 \u2502 \u251c radius [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c 0.3 [0]\n", "\u2502 \u2502 \u251c laser [0]\n", "\u2502 \u2502 \u2502 \u251c laser_specifications [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c max_range [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c 4 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c pose [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c x [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c y [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 1.57 [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c noise [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_specifications [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_mean [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_std [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0.03 [2]", "\u251c robot [0]\n", "\u2502 \u251c robot_specifications [0]\n", "\u2502 \u2502 \u251c footprint [0]\n", "\u2502 \u2502 \u2502 \u251c radius [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c 0.3 [0]\n", "\u2502 \u2502 \u251c laser [0]\n", "\u2502 \u2502 \u2502 \u251c laser_specifications [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c max_range [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c 4 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u251c pose [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c x [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c y [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c theta [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 1.57 [0]\n", "\u2502 \u2502 \u2502 \u2502 \u251c noise [1]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_specifications [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_mean [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0 [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c noise_std [2]\n", "\u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c 0.03 [2]", "stdr_msgs::RobotMsg msg = stdr_parser::Parser::createMessage<stdr_msgs::RobotMsg>(\"simple_robot.yaml\");", "stdr_msgs::RobotMsg msg = stdr_parser::Parser::createMessage<stdr_msgs::RobotMsg>(\"simple_robot.yaml\");\n", "stdr_parser::Parser::saveMessage(msg,\"test.xml\");", "  try\n", "  {\n", "    stdr_parser::Parser::saveMessage(\n", "      stdr_parser::Parser::createMessage\n", "      <stdr_msgs::RobotMsg>      //!< Type\n", "      (\"pandora_robot.yaml\"),    //!< Input file\n", "      \"test.xml\"            //!< Output file\n", "    );\n", "  }\n", "  catch(ParserException ex)\n", "  {\n", "    ROS_ERROR(\" === STDR PARSER ERROR ===\\n%s\",ex.what());\n", "  }", "STDR parser : noidse_mean is not allowed in a noise_specifications tag\n", "Trail: \n", "  [noidse_mean] Line 17 of file 'hokuyo_laser_4L.xml'\n", "  [noise] Line 16 of file 'hokuyo_laser_4L.xml'\n", "  [laser_specifications] Line 14 of file 'hokuyo_laser_4L.xml'\n", "  [laser] Line 14 of file 'pandora_robot.xml'\n", "  [robot_specifications] Line 52 of file 'pandora_robot.xml'\n", "  [robot] Line 2 of file 'pandora_robot.xml'\n", "  [STDR_Parser_Root_Node] Line 1 of file 'pandora_robot.xml'", "noise:\n", "  noise_specifications:\n", "    mean: 0.5\n", "    std: 0.200000002980232", "footprint:\n", "  footprint_specifications:\n", "    radius: 0.5", "laser:\n", "  laser_specifications:\n", "    max_angle: 2.35619258880615\n", "    min_angle: -2.35619258880615\n", "    max_range: 4\n", "    min_range: 0\n", "    num_rays: 270\n", "    noise:\n", "      noise_specifications:\n", "        mean: 0.5\n", "        std: 0.200000002980232\n", "    frequency: 10\n", "    frame_id: laser_0\n", "    pose:\n", "      x: 0.100000001490116\n", "      y: 0\n", "      theta: 0", "sonar:\n", "  sonar_specifications:\n", "    max_range: 3\n", "    min_range: 0.300000011920929\n", "    cone_angle: 0.523598313331604\n", "    noise:\n", "      filename: noises/noise_gauss.yaml\n", "    frequency: 10\n", "    frame_id: sonar_0\n", "    pose:\n", "      x: 0.100000001490116\n", "      y: 0\n", "      theta: 0", "robot:  \n", "  robot_specifications:\n", "    - footprint:\n", "        footprint_specifications:\n", "          radius: 0.15\n", "    - initial_pose:\n", "        theta: 0\n", "        x: 0\n", "        y: 0\n", "    - laser:\n", "        filename: laser_sensors/hokuyo_laser_4L.yaml\n", "        laser_specifications: \n", "          max_range: 10\n", "    - sonar:\n", "        filename: range_sensors/standard_sonar.yaml\n", "        sonar_specifications:\n", "          frame_id: sonar_0\n", "          pose:\n", "            x: 0.100000001490116\n", "            y: 0\n", "            theta: 0\n", "    - sonar:\n", "        filename: range_sensors/standard_sonar.yaml\n", "        sonar_specifications:\n", "          frame_id: sonar_1\n", "          pose:\n", "            x: 0\n", "            y: 0.100000001490116\n", "            theta: 1.570795\n", "    - sonar:\n", "        filename: range_sensors/standard_sonar.yaml\n", "        sonar_specifications:\n", "          frame_id: sonar_2\n", "          pose:\n", "            x: 0\n", "            y: -0.100000001490116\n", "            theta: -1.570795\n", "    - sonar:\n", "        filename: range_sensors/standard_sonar.yaml\n", "        sonar_specifications:\n", "          frame_id: sonar_3\n", "          pose:\n", "            x: -0.100000001490116\n", "            y: -0.100000001490116\n", "            theta: 2.79252444444444\n", "    - sonar:\n", "        filename: range_sensors/standard_sonar.yaml\n", "        sonar_specifications:\n", "          frame_id: sonar_4\n", "          pose:\n", "            x: -0.100000001490116\n", "            y: 0.100000001490116\n", "            theta: 3.49065555555556", "<noise>\n", "  <noise_specifications>\n", "    <noise_mean>0.1</noise_mean>\n", "    <noise_std>0.01</noise_std>\n", "  </noise_specifications>\n", "</noise>", "<footprint>\n", "  <footprint_specifications>\n", "    <radius>0.5</radius>\n", "  </footprint_specifications>\n", "</footprint>", "<laser>\n", "  <laser_specifications>\n", "    <max_angle>1.570795</max_angle>\n", "    <min_angle>-1.570795</min_angle>\n", "    <max_range>4.0</max_range>\n", "    <min_range>0.1</min_range>\n", "    <num_rays>270</num_rays>\n", "    <frequency>10</frequency>\n", "    <pose>\n", "      <x>0</x>\n", "      <y>0</y>\n", "      <theta>0</theta>\n", "    </pose>\n", "    <noise>\n", "      <filename>noises/noise_gauss.xml</filename>\n", "      <noise_specifications>\n", "        <noise_mean>0.5</noise_mean>\n", "        <noise_std>0.05</noise_std>\n", "      </noise_specifications>\n", "    </noise>\n", "  </laser_specifications>\n", "</laser>", "<sonar>\n", "  <sonar_specifications>\n", "    <cone_angle>0.87</cone_angle>\n", "    <max_range>3.0</max_range>\n", "    <min_range>0.15</min_range>\n", "    <frequency>10</frequency>\n", "    <pose>\n", "      <x>0.1</x>\n", "      <y>0</y>\n", "      <theta>0</theta>\n", "    </pose>\n", "    <noise>\n", "      <filename>noises/noise_gauss.xml</filename>\n", "    </noise>\n", "  </sonar_specifications>\n", "</sonar>", "<robot>\n", "  <robot_specifications>\n", "    <footprint>\n", "      <footprint_specifications>\n", "        <radius>0.2</radius>\n", "      </footprint_specifications>\n", "    </footprint>\n", "    <initial_pose>\n", "      <x>0</x>\n", "      <y>0</y>\n", "      <theta>0</theta>\n", "    </initial_pose>\n", "    <laser>\n", "      <filename>laser_sensors/hokuyo_laser_4L.xml</filename>\n", "    </laser>\n", "    <sonar>\n", "      <filename>range_sensors/standard_sonar.xml</filename>\n", "      <sonar_specifications>\n", "        <pose>\n", "          <x>0.1</x>\n", "        </pose>\n", "      </sonar_specifications>\n", "    </sonar>\n", "    <sonar>\n", "      <filename>range_sensors/standard_sonar.xml</filename>\n", "      <sonar_specifications>\n", "        <pose>\n", "          <y>0.1</y>\n", "          <theta>1.570795</theta>\n", "        </pose>\n", "      </sonar_specifications>\n", "    </sonar>\n", "    <sonar>\n", "      <filename>range_sensors/standard_sonar.xml</filename>\n", "      <sonar_specifications>\n", "        <pose>\n", "          <y>-0.1</y>\n", "          <theta>-1.570795</theta>\n", "        </pose>\n", "      </sonar_specifications>\n", "    </sonar>\n", "    <sonar>\n", "      <filename>range_sensors/standard_sonar.xml</filename>\n", "      <sonar_specifications>\n", "        <pose>\n", "          <x>-0.1</x>\n", "          <y>-0.1</y>\n", "          <theta>2.79252444444444</theta>\n", "        </pose>\n", "      </sonar_specifications>\n", "    </sonar>\n", "    <sonar>\n", "      <filename>range_sensors/standard_sonar.xml</filename>\n", "      <sonar_specifications>\n", "        <pose>\n", "          <x>-0.1</x>\n", "          <y>0.1</y>\n", "          <theta>3.49065555555556</theta>\n", "        </pose>\n", "      </sonar_specifications>\n", "    </sonar>\n", "  </robot_specifications>\n", "</robot>"]},
{"url": "https://wiki.ros.org/sr_gui_grasp_controller", "package": "sr_gui_grasp_controller", "package_summary": ["\n\n     sr_gui_grasp_controller - gui plugin for interpolating between grasps.\n\n  "], "package_details": [" ", "You can also save a current hand pose (obtained either by interpolating between two grasps, or by moving then hand with the sliders) by clicking on the ", " button. "]},
{"url": "https://wiki.ros.org/teraranger_array", "package": "teraranger_array", "package_summary": ["This package provides ros nodes for multi-sensor arrays from Terabee"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "*", " ", "*", " ", "*", " ", "*", " ", "*", " "], "package_tt": ["/ranges", "/imu_euler", "/imu_quat", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "_baudrate", "int,\u00a0default:\u00a0\"115200\"", "~Rate_enum", "int", "~Sequence_mode_enum", "int", "~IMU_enum", "int", "~Sensor_type", "int", "/ranges", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "~Mode", "int", "/ranges", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "~Sensor_X", "bool"], "package_code": ["rosrun teraranger_array <teraranger_one|teraranger_multiflex> [_portname:=<device_path>]"]},
{"url": "https://wiki.ros.org/rc_roi_manager_gui", "package": "rc_roi_manager_gui", "package_summary": ["The ros client for the region of interest manager of the itempick and boxpick modules"], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", "See ", " and ", " for more details. ", "For the ", " module: ", "For the ", " module: "], "package_tt": ["device", "02912345", ":02912345"], "package_code": ["$ roslaunch rc_roi_manager_gui interactive_roi_selection.launch device:=:<serial_number> pick_module=rc_itempick", "$ roslaunch rc_roi_manager_gui interactive_roi_selection.launch device:=:<serial_number> pick_module=rc_boxpick"]},
{"url": "https://wiki.ros.org/asr_descriptor_surface_based_recognition", "package": "asr_descriptor_surface_based_recognition", "package_summary": ["This package contains a 6-DoF object localizer for textured household objects"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains an object localization system that returns 6-DoF poses for textured objects in RGBD-data. ", " ", "There are two types of parameters which can be set, static and dynamic ones. The static ones can be found in the .yaml file in the param-directory and the dynamic ones in the launch-file (or during runtime by using ", "). "], "package_code": ["roslaunch asr_descriptor_surface_based_recognition descriptor_surface_based_recognition.launch"]},
{"url": "https://wiki.ros.org/tf_publisher_gui", "package": "tf_publisher_gui", "package_summary": ["This is a simple GUI for publishing a single TF transform."], "package_details": ["\n", " ", "\n", "\n"], "package_tt": ["~rate", "double", "~parent_frame", "string", "~child_frame", "string", "~parent_frame", "~child_frame"], "package_code": ["rosrun tf_publisher_gui tf_publisher_gui _parent_frame:=/odom_combined _child_frame:=/head_mount_kinect_link"]},
{"url": "https://wiki.ros.org/blort_msgs", "package": "blort_msgs", "package_summary": ["This package defines messages used by BLORT ROS interface"]},
{"url": "https://wiki.ros.org/automotive_navigation_msgs", "package": "automotive_navigation_msgs", "package_summary": ["Generic Messages for Navigation Objectives in Automotive Automation Software"]},
{"url": "https://wiki.ros.org/vrep_ros_bridge", "package": "vrep_ros_bridge", "package_summary": ["The main application of the plugin is to provide a communication interface between V-Rep and (ROS). The aim is to control the V-Rep simulation externally using ROS messages and ROS services."], "package_details": ["\n", " ", " ", " ", "\n", " is a plugin for V-Rep developed by the Inria ", " team located at ", ". ", ", developed by ", ", is an open-source state-of-the-art (and freely available for academic use) 3D physical simulation engine which is becoming more and more widespread in the robotics community thanks to its flexibility (possibility to simulate many different robotic platforms), dynamical engine (it supports ODE, Bullet and Vortex), and finally customizability (it offers many different possibilities to include one's own code or to interface it with the external world). ", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "ROS V-Rep Bridge uses the ", " package. Pluginlib is a C++ library for loading and unloading plugins from within a ROS package. Plugins are dynamically loadable classes that are loaded from a runtime library (i.e. shared object, dynamically linked library). In this way our handlers are actually plugins with some dependencies. If we don't need a handler or we don't have installed its dependencies we are still able to build our bridge (that plugin will not be available). For example, the ", " needs ", ". If we don't want to install Telekyb we can just add a file called CATKIN_IGNORE in the quadrotor_tk_handler folder and it will not be considered. In spite of this the other handlers will be available. ", "We have an object in the scene (let's say a quadrotor) and we want that the plugin ", " manage it. To do it we will have to tag the object with a predefined string. If we don't do it the plugin will not act on the object. We will show how to tag a quadrotor but the procedure for the other objects will be similar. ", "The function 'simExtSetFloatCustomDataFromHeader()' adds a custom data to the object related to 'sim_ext_ros_bridge_set_obj_twist_data_main'. As we can see, the function requires a third input. If requested, we can add a value to our custom data, setting the third input of the function. In our case, since we don't want to use this additional parameter we set it to zero (it will be ignored). We can add float and int values. If you want to add an int value you have to use the function 'simExtSetIntCustomDataFromHeader()'. You can find the list of the Custom Lua Variables in the description of each handler. Moreover you will find the complete list in the file ", " (From line 149). In certain case the third values will be important (for instance to set the frequency of the camera acquisition). You will find more information about these commands in each wiki.ros page dedicated to the packages. ", "You will find a guide for the installation in the ", ". ", "You can find info about this demo ", ". "], "package_code": ["if (simGetScriptExecutionCount()==0) then\n", "-- Put your Initialization code, executed only once (at the beginning of the simulation)\n", "end\n", "\n", "simHandleChildScript(sim_handle_all_except_explicit)\n", "\n", "-- Put your main code here. It will act at each iteration of the simulation.\n", "\n", "if (simGetSimulationState()==sim_simulation_advancing_lastbeforestop) then\n", "-- Put some restoration code here\n", "end", "quadrotor = simGetObjectAssociatedWithScript(sim_handle_self)\n", "simExtSetFloatCustomDataFromHeader(quadrotor, sim_ext_ros_bridge_quadrotor_data_main, 0.0)", " Add-on script 'vrepAddOnScript-addOnScriptDemo.lua' was loaded.\n", " Simulator launched.\n", " (...)\n", " Plugin 'RosBridge': loading...\n", " Plugin 'RosBridge': load succeeded.\n", " (...)", " rqt_graph", " rostopic list", " /command/quadrotor_0\n", " /rosout\n", " /rosout_agg\n", " /tf\n", " /vrep/IMU/quadrotor_0\n", " /vrep/Vision_sensor_0\n", " /vrep/Vision_sensor_0/Camerainfo\n", " /vrep/Vision_sensor_0/compressed\n", " /vrep/Vision_sensor_0/compressed/parameter_descriptions\n", " /vrep/Vision_sensor_0/compressed/parameter_updates\n", " /vrep/Vision_sensor_0/compressedDepth\n", " /vrep/Vision_sensor_0/compressedDepth/parameter_descriptions\n", " /vrep/Vision_sensor_0/compressedDepth/parameter_updates\n", " /vrep/Vision_sensor_0/theora\n", " /vrep/Vision_sensor_0/theora/parameter_descriptions\n", " /vrep/Vision_sensor_0/theora/parameter_updates\n", " /vrep/base/pose\n", " /vrep/camera_info\n", " /vrep/end_eff/pose\n", " /vrep/info\n", " /vrep/pose/quadrotor_0\n", " /vrep/twist/quadrotor_0\n", " /vrep/viper_0/jointCommand\n", " /vrep/viper_0/jointStatus"]},
{"url": "https://wiki.ros.org/tuw_marker_server", "package": "tuw_marker_server", "package_summary": ["The tuw_marker_server package contains a map server for saving and providing marker maps based on MarkerWithCovarianceArray messages from the marker_msgs package."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["map", "mapfile", "string", "\"map.yaml\"", "tuw_marker_server", "map", "mapfile", "string", "frame_id", "string", "\"map\""], "package_code": ["rosrun tuw_marker_server tuw_marker_saver.py", "roslaunch tuw_marker_server saver.launch", "rosrun tuw_marker_server tuw_marker_server.py", "roslaunch tuw_marker_server server.launch"]},
{"url": "https://wiki.ros.org/rosserial_embeddedlinux", "package": "rosserial_embeddedlinux", "package_summary": ["rosserial for embedded Linux enviroments"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the ", " support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  ", "Using the ", " package, you can use ROS directly with the these systems. ", " provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. ", "The ", " package supports the following major connection types and capabilities: ", "This package contains embedded-linux-specific extensions required to run ", " on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  ", "Go to the ", " to learn how to install and use the package to connect your embedded linux system to ROS. ", "Please file new bugs on the project's ", ". The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "]},
{"url": "https://wiki.ros.org/tuw_ellipses", "package": "tuw_ellipses", "package_summary": ["The tuw_ellipses package contains a computer vision library which is able to detect ellipses within images.  \n    The package is able to estimate the pose of the circle related to the ellipse the circle diameter as well as the camera parameter are known.\n    A dynamic reconfigure interface allows the user to tune the parameter of the system to ones needs.\n    But be aware that the pose of a projected circle within a image (ellipse) has two solutions and only one is published as TF."], "package_details": ["\n", "\n", "\n", "This package detects ellipses in camera images and computes the 3D pose of the related circle if the radius of the circle is given. The current 3D pose estimation is based on the [Chen2004] and the successor of the  ", " package. Various Parameter and algorithm used to find ellipses can be tuned via ROS shared parameters or by using the dynamic reconfigure interface. ", "Chen2004) Chen, Q.; Wu, H. & Wada, T. Pajdla, T. & Matas, J. (Eds.) Camera Calibration with Two Arbitrary Coplanar Circles Computer Vision - ECCV 2004, Springer Berlin Heidelberg, 2004, 3023, 521-532,  ", " "], "package_code": ["rosrun tuw_ellipses tuw_ellipses_node image:=/camera/image_raw camera_info:=/camera/camera_info", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/graspdb", "package": "graspdb", "package_summary": ["Grasp Training SQL Database Client Library"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/svenzva_moveit", "package": "svenzva_moveit", "package_summary": ["An automatically generated package with all the configuration and launch files for using the revel with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/sr_hand", "package": "sr_hand", "package_summary": ["\n\n     This is a ROS interface to the Shadow Robot's robotic hand. It\n     contains both an interface to the real hand (communicating via\n     a CAN interface) and a simulated version of the hand. It also\n     contains an interface to Shadow Robot's muscle arm.\n\n  ", "\n", "This package provides a ROS interface to the ", ". Its aim is not only to provide a complete ROS integration to our hardware, but also to provide the user with a simulated and a dummy interface (the dummy interface is a really simple simulated interface, without any physics computation). Changing between those 3 interfaces is transparent for the end user, thus allowing you to test your algorithm in simulation, and then run them on the real hardware without changing any code. ", "This package also provides a (deprecated) compatibility interface for the ", ". For more information, you can have a look at this ", ". ", "\n", "Here is an overview of the ROS system: ", " ", "As you can see, the topics are similar on the arm and hand.  ", "\n", ": The sendupdate message is defined in ", ". It is used to send one or a vector of new targets to the robot. For an example on how to publish on this topic, please refer to the ", " tutorial. ", ": The contrlr message is defined in ", ". This topic is used to set new controller parameters when you use our real hardware. To see how to publish on this topic, go to the ", " tutorial. ", " ", "\n", ": Publish a ", "/joint_states message containing the current positions of the robot. A ", " subscribes to this topic, in order to publish to the ", " topic, with a ", " prefix.  ", ": Publish a ", "/joint_states message containing the current targets for the robot. This is not so important, but it can be used to ", " in rviz. A ", " subscribes to this topic, in order to publish to the ", " topic, with a ", " prefix.  ", ": This topic publishes more information than the ", " topics. It's based on the ", "/joints_data. There is a duplication of the information sent on those topics, but we can't really get rid of any of them as they may be needed in different situations. ", ": Diagnostics data (motor status, etc...) are published on this topic, and then aggregated by a ", ". You can look at the diagnostics using the ", ". ", "\n", "You can specify the following parameters for the Hand or for the Arm: ", ": You can change the publishing frequency of the main robot data (", " and ", "). Default is 20Hz. ", ": You can change the rate at which diagnostics are being published for the robot. Default is 1Hz. ", ": If using gazebo, what's the prefix of the joint_states published by gazebo. ", "\n", "Please refer to the ", " page. ", "\n", "We always welcome contributions. If you want to contribute, please refer to the ", " stack. "]},
{"url": "https://wiki.ros.org/people_tracking_filter", "package": "people_tracking_filter", "package_summary": ["A collection of filtering tools for tracking people's locations"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/pr2_calibration", "package": "pr2_calibration", "package_summary": ["The pr2_calibration package"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "The following aspects of the PR2 are ", " calibrated by the pr2_calibration stack ", "Follow instructions in the ", " Tutorial. ", "The algorithm implemented in this stack is described in the following paper: ", "\n ", " "]},
{"url": "https://wiki.ros.org/xbot_node", "package": "xbot_node", "package_summary": ["ROS nodelet for Xbot: ROS wrapper for the Xbot driver."], "package_details": ["\n", "\n", "xbot_node\u529f\u80fd\u5305\u4e3a", "\u63d0\u4f9bROS API\u3002 "], "package_tt": ["/commands/motor_disable", "/commands/velocity", "/commands/yaw_platform", "/commands/pitch_platform", "/commands/sound_enable", "/commands/led", "/commands/lift", "/commands/reset_odometry", "/joint_states", "/sensors/core", "/sensors/extra", "/sensors/yaw_platform_degree", "/sensors/pitch_platform_degree", "/sensors/motor_disabled", "/sensors/sound_enabled", "/sensors/battery", "/sensors/echo", "/sensors/infrared", "/sensors/imu_data", "/sensors/raw_imu_data", "/xbot/state", "/commands/velocity", "/xbot/chat", "~base_path", "string", "\"$(find\u00a0xbot_talker)\""]},
{"url": "https://wiki.ros.org/rsv_balance", "package": "rsv_balance", "package_summary": ["Common packages for RoboSavvy's balancing platform"], "package_details": ["'s ", " common package. ", " ", "Tutorials ", ". "]},
{"url": "https://wiki.ros.org/pysdf", "package": "pysdf", "package_summary": ["Python library to parse SDF into class hierarchy and export URDF"], "package_details": ["\n"], "package_tt": ["check_urdf"]},
{"url": "https://wiki.ros.org/ndt_map", "package": "ndt_map", "package_summary": ["\n\n     Contains the definitions of the 3D Normal Distributions Transform data structures, \n     used for mapping, registration, etc.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "NDT maps can be created either using a regular grid data structure (", ") or using an irregular grid (", "). The recommended mode is to use ", ", as most of the subsequent algorithms have been optimized for that data structure.  "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/srv_tools", "package": "srv_tools", "package_summary": ["Stack with interesting ROS tools"], "package_details": ["\n", "\n", "\n", "\n", "  "], "package_code": ["cd catkin_ws/src\n", "mkdir srv_tools\n", "cd srv_tools\n", "git clone https://github.com/srv/srv_tools.git .\n", "cd ../..\n", "rosdep install --from-paths src --ignore-src --rosdistro kinetic # install dependencies\n", "catkin_make"]},
{"url": "https://wiki.ros.org/wpi_jaco_msgs", "package": "wpi_jaco_msgs", "package_summary": ["Messages Used with the JACO Arm"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"wpi_jaco_msgs\" in rosdoc: /home/rosbot/docs/api/wpi_jaco_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/jsk_footstep_msgs", "package": "jsk_footstep_msgs", "package_summary": ["jsk_footstep_msgs"]},
{"url": "https://wiki.ros.org/canopen_master", "package": "canopen_master", "package_summary": ["CiA(r) CANopen 301 master implementation with support for interprocess master synchronisation."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["canopen::SimpleMaster::Allocator", "canopen::ExternalMaster::Allocator", "canopen::SharedMaster::Allocator", "canopen::UnrestrictedMaster::Allocator", "canopen::LocalMaster::Allocator"]},
{"url": "https://wiki.ros.org/summit_xl_navigation", "package": "summit_xl_navigation", "package_summary": ["Navigation launch and config files for Summit XL robot."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/canopen_402", "package": "canopen_402", "package_summary": ["This implements the CANopen device profile for drives and motion control. CiA(r) 402"], "package_details": ["\n", " ", "\n", "\n", "\n", " ", " ", "\n", "\n", " ", "This package contains the implementation of the CiA 402 DSP protocol. It just communicates via objects (", ", no direct CAN communication is needed. "]},
{"url": "https://wiki.ros.org/asr_flir_ptu_driver", "package": "asr_flir_ptu_driver", "package_summary": ["asr_flir_ptu_driver is a package for controlling a flir ptu via (external) msg\n     authors: Valerij Wittenbeck, Joachim Gehrung, Pascal Meissner, Patrick Schlosser"], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", "\n", "\n", " ", "\n", "Using the ptu_left.launch launchfile the topics shown below will be found under ", ". ", "Using the ptu_left.launch launchfile the topics shown below will be found under ", ". ", "Using the ptu_left.launch launchfile all parameters shown below will be found under ", ". ", "There are no external services needed. Nevertheless, if the GUI is used, it uses a few services offered by the driver, therefore always start ", " before ", " ", "Using the ptu_left.launch launchfile the services shown below will be found under ", ". ", "needs to be invoked from the terminal to start the PTU. Make sure it is connected. Configure the forbidden areas in the ", "as you need them (details on forbidden areas in Chapter 2). Then continue with the tutorials below: "], "package_code": ["roslaunch asr_flir_ptu_driver ptu_gui.launch", "roslaunch asr_flir_ptu_driver ptu_gui.launch path_prediction:=true", "roslaunch asr_flir_ptu_driver ptu_left_mock.launch", "roslaunch asr_flir_ptu_driver ptu_left.launch", "roslaunch asr_flir_ptu_driver ptu_left.launch"]},
{"url": "https://wiki.ros.org/segbot_gazebo", "package": "segbot_gazebo", "package_summary": ["bwi_gazebo"]},
{"url": "https://wiki.ros.org/turtlebot3_automatic_parking", "package": "turtlebot3_automatic_parking", "package_summary": ["Package for turtlebot3 automatic_parking. You need a reflective tape and real robots. You can see parking spot using this pacakge on rviz."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["scan", "odom", "cmd_vel", "scan_spot", "reset"]},
{"url": "https://wiki.ros.org/tuw_marker_detection", "package": "tuw_marker_detection", "package_summary": ["The tuw_marker_detection package"]},
{"url": "https://wiki.ros.org/pr2_arm_ik_tests", "package": "pr2_arm_ik_tests", "package_summary": ["\n\n     pr2_arm_ik_tests\n\n  "]},
{"url": "https://wiki.ros.org/toposens_pointcloud", "package": "toposens_pointcloud", "package_summary": ["PCL integration for TS sensors mounted on Turtlebot3."], "package_details": ["\n", "\n", "\n", "\n", "This package enables conversion of messages of type ", " into messages of type ", ". ", "Due to the specular reflection behavior of ultrasound, the surface normal of the detected object can be represented by a vector pointing from the detected point towards the sensor\u2019s position while the point was recorded. This normal vector is added to the ", " representation. For a more detailed explanation of the physics behind Toposens sensors see ", ". "], "package_tt": ["ts_scans", "ts_cloud", "ts_cloud_normals", "~scans_topic", "std_msgs/String", "~target_frame", "std_msgs/String", "~pcd_save_interval", "int", "~pcd_path", "std_msgs/String", "~lifetime_normals_vis", "float"]},
{"url": "https://wiki.ros.org/nao_control", "package": "nao_control", "package_summary": ["The nao_control package"], "package_details": ["Is used within ", " and ", " packages  "]},
{"url": "https://wiki.ros.org/ros3djs_experimental", "package": "ros3djs_experimental", "package_summary": ["The ros3djs_experimental package"]},
{"url": "https://wiki.ros.org/rostopic", "package": "rostopic", "package_summary": ["rostopic contains the rostopic command-line tool for displaying\n    debug information about\n    ROS ", ", including\n    publishers, subscribers, publishing rate,\n    and ROS ", ". It also\n    contains an experimental Python library for getting information about\n    and interacting with topics dynamically. This library is for\n    internal-use only as the code API may change, though it does provide\n    examples of how to implement dynamic subscription and publication\n    behaviors in ROS."], "package_details": ["\n", ", like several other ROS tools, uses YAML-syntax at the command line for representing the contents of a message. For information on how to use this YAML syntax for commands like ", ", please see the ", " guide. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " is a stable command-line tool within the ROS core toolchain. The underlying code may undergo refactoring for easier library use, but the external API is expected to be fairly stable. ", "The ", " command-line tool displays information about ROS topics. Currently, it can display a list of active topics, the publishers and subscribers of a specific topic, the publishing rate of a topic, the bandwidth of a topic, and messages published to a topic. The display of messages is configurable to output in a plotting-friendly format. ", "or on Windows ", " ", "Publish a geometry_msgs/Twist message with a rate of 10Hz.  ", " ", "One area in which ", " is expected to see development is with the output format of ", " and input format of ", ". The planned feature is to make both compatible with YAML syntax, which will enable "], "package_tt": ["rostopic", "rostopic", "rostopic\u00a0pub", "bw\u00a0<topic-name>", "delay\u00a0<topic-name>", "echo\u00a0<topic-name>", "--offset", "--filter", "m", "frame_id", "-c", "-p", "-b", "-p", "-c", "-w\u00a0NUM_WIDTH", "--nostr", "--noarr", "-n\u00a0COUNT", "echo\u00a0<topic-name/field>", "find\u00a0<msg-type>", "hz\u00a0<topic-name>", "-w", "-w\u00a0WINDOW_SIZE", "--filter\u00a0FILTER_EXPR", "info\u00a0<topic-name>", "list", "list\u00a0<namespace>", "rostopic\u00a0info", "-b", "-p", "-s", "-v", "--host", "pub\u00a0<topic-name>\u00a0<topic-type>\u00a0[data...]", "rostopic", "/topic_name", "rostopic", "ctrl-C", "ctrl-C", "rostopic", "rostopic", "-r\u00a010", "-l,\u00a0--latch", "-r\u00a0RATE", "-1", "--once", "-f\u00a0FILE", "rostopic\u00a0echo", "---", "--latch", "type\u00a0<topic-name>", "rostopic", "rostopic", "rostopic\u00a0echo", "rostopic\u00a0pub"], "package_code": ["rostopic bw     display bandwidth used by topic\n", "rostopic delay display delay for topic which has header\n", "rostopic echo   print messages to screen\n", "rostopic find   find topics by type\n", "rostopic hz     display publishing rate of topic\n", "rostopic info   print information about active topic\n", "rostopic list   print information about active topics\n", "rostopic pub    publish data to topic\n", "rostopic type   print topic type", "$ rostopic bw /topic_name", "$ rostopic delay /topic_name", "$ rostopic echo /topic_name", "$ rostopic echo --offset /topic_name", "$ rostopic echo --filter \"m.data=='foo'\"  /topic_name", "$ rostopic echo --filter \"m.transforms[0].child_frame_id == 'my_frame'\" /tf", "$ rostopic echo -c /topic_name", "$ rostopic echo -b log_file.bag /topic_name", "$ rostopic echo -p /topic_name", "$ rostopic echo -p --nostr --noarr /topic_name", "$ rostopic echo /my_topic/field_name", "$ rostopic find std_msg/String", "$ rostopic hz /topic_name", "$ rostopic info clock", "$ rostopic list", "$ rostopic list /namespace", "$ rostopic list -v", "$ rostopic pub /topic_name std_msgs/String hello", "$ rostopic pub my_topic std_msgs/String \"hello there\"", "$ rostopic echo chatter | rostopic pub bar std_msgs/String", "$ rostopic echo chatter > chatter.bagy\n", "Collect messages, then Ctrl-C\n", "$ rostopic pub -f chatter.bagy bar std_msgs/String", "$ rostopic pub -r 10 /cmd_vel geometry_msgs/Twist  '{linear:  {x: 0.1, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0,z: 0.0}}'", "$ rostopic pub -r 10 /cmd_vel geometry_msgs/Twist  \"{linear:  {x: 0.1, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0, z: 0.0}}\"", "$ rostopic type /topic_name", "$ rostopic type /topic_name | rosmsg show"]},
{"url": "https://wiki.ros.org/laser_pipeline", "package": "laser_pipeline", "package_summary": ["Meta-package of libraries for processing laser data, including converting laser data\n      into 3D representations."], "package_details": ["\n", "\n", " ", "\n", "\n", "  ", " ", "The ", " stack is intended to do the necessary processing to get from the output of a scanning laser rangefinder to a more useful 3D representation of a point cloud.  This processing takes three distinct steps: ", "For an end-user higher up the system, the ", " is actually capable of performing all 3 of these steps, implementing an arbitrary filter chain on its input, performing a high-fidelity transformation to a point cloud internally, and then making clouds available via a ", ". ", "Point clouds generated using the laser pipeline results in a ", " or (", ") ", " message.  This point cloud can have the following channels attached to it: ", "The ", " assumes that you have a scanning laser rangefinger.  The most common examples of these are the Hokuyo UTM and the Sick LMS.  The ", " stack provides drivers for these particular models.  However, any driver which outputs the ", ", including ", ", can be used as the input to this pipeline. "], "package_tt": ["laser_pipeline", "\"intensities\"", "\"index\"", "\"distances\"", "\"stamps\"", "laser_pipeline"]},
{"url": "https://wiki.ros.org/katana", "package": "katana", "package_summary": ["This package provides ROS interfaces to the Neuronics Katana 450 arm.\n    It wraps the ", " library for low-level communication\n    with the Katana arm."], "package_details": ["\n", "\n", "This package provides the ", " ROS node, which provides four sets of functionality at once: the ", ", the ", ", the ", " and the ", ". They are combined into one single node for technical reasons (only one single process can access the Katana), but documented separately below for clarity. ", "Also there is a second node in this package, called ", ", documented at the end. "], "package_tt": ["katana", "joint_state_publisher", "joint_movement_controller", "joint_trajectory_action_controller", "gripper_grasp_controller", "katana_arm_kinematics", "switch_motors_off", "switch_motors_on", "test_speed", "~simulation", "bool", "false", "katana_joints", "Array\u00a0of\u00a0strings", "katana_gripper_joints", "Array\u00a0of\u00a0strings", "robot_description", "String", "~use_serial", "bool", "false", "true", "~ip", "String", "~port", "int", "~serial_port", "int", "/dev/ttyUSB3", "~serial_port", "~config_file_path", "String", "katana_type", "string", "katana_300_6m180", "katana_400_6m180", "katana_450_6m90a", "katana_450_6m90b", "joint_states", "katana_arm_controller/joint_movement_action/goal", "katana_arm_controller/joint_movement_action/result", "katana_arm_controller/joint_movement_action/feedback", "command", "state", "query_state", "katana_arm_controller/joint_trajectory_action/goal", "katana_arm_controller/joint_trajectory_action/result", "katana_arm_controller/joint_trajectory_action/feedback", "katana_arm_controller/command", "katana_arm_controller/state", "query_state", "joint_trajectory_action_node/constraints/<joint>/goal", "double", "joint_trajectory_action_node/constraints/stopped_velocity_tolerance", "double", "posture_action_name/goal", "posture_action_name/result", "grasp_query_name", "~gripper_object_presence_threshold", "double", "get_kinematic_solver_info", "get_fk", "get_ik", "~config_file_path", "String", "robot_description", "String", "katana_joints", "Array\u00a0of\u00a0strings"]},
{"url": "https://wiki.ros.org/puma_motor_driver", "package": "puma_motor_driver", "package_summary": ["A ROS driver for Puma single-channel motor control board."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/turtlebot3_applications_msgs", "package": "turtlebot3_applications_msgs", "package_summary": ["Message and service types: custom messages and services for TurtleBot3 Applications packages"], "package_details": [" ", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosh_core", "package": "rosh_core", "package_summary": ["\n     Main ROSH scripting and interpreter environment.\n  "], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/turtlebot_arm", "package": "turtlebot_arm", "package_summary": ["The turtlebot arm meta package.", "\n", " - Bill of materials and instructions on how to assemble the hardware for the ", " arm. ", "\n", " - Instructions for installing the ", " stack and dependencies. ", " - Instructions for numbering the Dynamixel servos correctly. ", "\n", " - A tutorial explaining how to calibrate the physical position of a kinect to the arm for more precise manipulation. ", " - controlling the arm through rviz. ", " - A tutorial for setting up a demo to move small blocks around a surface using the arm. "], "package_details": [" ", " ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "The ", " arm is a low-cost arm that you can build and mount on the ", " to give it some basic manipulation capabilities. ", "Kinetic release is pending on ", ". "]},
{"url": "https://wiki.ros.org/pr2_delivery", "package": "pr2_delivery", "package_summary": ["This package contains scripts for making a PR2 deliver a small\n  object from one place to another, and return to a home base."], "package_details": ["See: ", " "]},
{"url": "https://wiki.ros.org/rosserial_xbee", "package": "rosserial_xbee", "package_summary": ["Allows multipoint communication between rosserial\n     nodes connected to an xbee. All nodes communicate back\n     to a master xbee connected to a computer running ROS.\n\n     This software currently only works with Series 1 Xbees.\n\n     This pkg includes python code from the python-xbee project:\n     http://code.google.com/p/python-xbee/"], "package_details": [" ", "\n", "\n", " "], "package_code": ["./setup_xbee.py [options] port my_adr\n", "\n", "    port :    serial port of port of the xbee (/dev/ttyUSB0)\n", "    my_adr:   MY address is the 16 bit address of this xbee in the\n", "              network. This must be a unique address in the network.\n", "              This address is always 0 for the coordinator.\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  -P PAN_ID, --pan_id=PAN_ID\n", "                        Pan ID of the xbee network.  This ID must be the same\n", "                        for all XBees in your network.\n", "  -c CHANNEL, --channel=CHANNEL\n", "                        Frequency channel for the xbee network. The channel\n", "                        value must be the same for all XBees in your network.\n", "  -C, --coordinator     Configures the XBee as Coordinator for the network.\n", "                        Only make the XBee connected to the computer a\n", "                        coordiantor", "./xbee_network.py <xbee_serial_port> ID1 [ ID2 ID3 ....]"]},
{"url": "https://wiki.ros.org/katana_arm_gazebo", "package": "katana_arm_gazebo", "package_summary": ["This package starts a Neuronics Katana robot arm in the Gazebo simulation environment. It is modeled after the ", " package by John Hsu."]},
{"url": "https://wiki.ros.org/widowx_arm", "package": "widowx_arm", "package_summary": ["The widowx_arm package"], "package_details": ["\n", " ", "\n", "\n", "\n", "This package contains the different controllers and description files for ", " "]},
{"url": "https://wiki.ros.org/widowx_arm_description", "package": "widowx_arm_description", "package_summary": ["The widowx_arm_description package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rtt_sensor_msgs", "package": "rtt_sensor_msgs", "package_summary": ["Provides an rtt typekit for ROS sensor_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/sensor_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/staubli_rx160_gazebo", "package": "staubli_rx160_gazebo", "package_summary": ["\n      ROS-Industrial Gazebo support package for the Staubli RX160 (and variants).\n    ", "\n      This package contains the configuration data and launch files required\n      to simulate the Staubli RX160 manipulator in Gazebo. This includes the base\n      model and the RX160L.\n    ", "\n      Before using any of the configuration files included in this package, be\n      sure to check they are correct for the particular robot model and\n      configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/sql_database", "package": "sql_database", "package_summary": ["\n    Provides an easy way to use SQL databases from the ROS environment.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Note that an interface to a full-fledged database used for manipulation can be found in the ", " package, which does not live in this stack. ", "Report bugs on the ", ". "]},
{"url": "https://wiki.ros.org/summit_x_sim", "package": "summit_x_sim", "package_summary": ["The summit_x_sim metapackage"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", " simulation.  ", "Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "]},
{"url": "https://wiki.ros.org/srdf", "package": "srdf", "package_summary": ["\n\n    SRDF (Semantic Robot Description Format) is a representation of\n    semantic information about robots.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "Proposer: ", " ", "This format is intended to represent information about the robot that is not in the URDF file, but it is useful for a variety of applications. The intention is to include information that has a semantic aspect to it.  A review of this format is available ", ". "], "package_code": ["<?xml version=\"1.0\"?>\n", "\n", " <!-- This does not replace URDF, and is not an extension of URDF.\n", "      This is a format for representing semantic information about the robot structure.\n", "      A URDF file must exist for this robot as well, where the joints and the links that are referenced are defined -->\n", " <robot name=\"some robot\">\n", "\n", "   <group name=\"group1\">\n", "      <!-- when a link is specified, the parent joint of that link (if it exists) is automatically included -->\n", "      <link name=\"...\"/>\n", "      <link name=\"...\"/>\n", "\n", "      <!-- when a joint is specified, the child link of that joint (which will always exist) is automatically included -->\n", "      <joint name=\"...\" />\n", "\n", "      <!-- when a chain is specified, all the links along the chain (including endpoints) are included in the group. Additionally, all the joints that are parents to included links are also included. This means that joints along the chain and the parent joint of the base link are included in the group -->\n", "      <chain base_link=\"l_shoulder_pan_link\" tip_link=\"l_wrist_roll_link\"/>\n", "      <chain base_link=\"r_shoulder_pan_link\" tip_link=\"r_wrist_roll_link\"/>\n", "   </group>\n", "\n", "   <!-- groups can also be formed by referencing to already defined group names -->\n", "   <group name=\"arms\">\n", "      <group name=\"left_arm\"/>\n", "      <group name=\"right_arm\"/>\n", "      <link name=\"...\" />\n", "   </group>\n", "\n", "   <!-- define a named state/configuration of a group -->\n", "   <group_state name=\"name of this state\" group=\"name of group the state is for\">\n", "      <joint name=\"name of joint in group\" value=\"\" />\n", "      <!-- all joints must be specified for the state to be valid -->\n", "   </group_state>\n", "\n", "   <!-- Define how the robot moves in its environment, i.e., connection to robot's root link -->\n", "   <virtual_joint name=\"world_joint\" type=\"planar\" parent_frame=\"some fixed frame\" child_link=\"robot's root link name\"/> <!-- type can be planar, floating or fixed -->\n", "\n", "   <!-- We can then include the virtual joint in groups -->\n", "   <group name=\"whole_body\">\n", "      <group name=\"arms\"/>\n", "      <joint name=\"world_joint\"/>\n", "   </group>\n", "\n", "\n", "   <!-- define end effectors -->\n", "   <end_effector name=\"some diff name\" parent_link=\"...\" group=\"group_name\"/>\n", "\n", "   <!-- By default it is assumed that any link of the robot could potentially come into collision with any other link in the robot. This tag disables collision checking between a specified pair of links. There can be many such tags in this file.-->\n", "   <disable_collisions link1=\"link1\" link2=\"link2\" />\n", "\n", "</robot>", "<?xml version=\"1.0\"?>\n", "\n", "<robot name=\"pr2\">\n", "\n", "   <virtual_joint name=\"world_joint\" type=\"planar\" parent_frame=\"odom\" child_link=\"base_footprint\"/>\n", "\n", "   <group name=\"right_arm\">\n", "      <chain base_link=\"torso_lift_link\" tip_link=\"r_wrist_roll_link\"/>\n", "   </group>\n", "\n", "   <group name=\"left_arm\">\n", "      <chain base_link=\"torso_lift_link\" tip_link=\"l_wrist_roll_link\"/>\n", "   </group>\n", "\n", "   <group name=\"arms\">\n", "      <group name=\"left_arm\"/>\n", "      <group name=\"right_arm\"/>\n", "   </group>\n", "\n", "   <group_state name=\"tuck_arms\" group=\"arms\">\n", "      <joint name=\"l_shoulder_pan_joint\" value=\"0.2\" />\n", "      <!-- ... the rest of the joint values... -->\n", "   </group_state>\n", "\n", "   <group name=\"base\">\n", "      <joint name=\"world_joint\"/>\n", "   </group>\n", "\n", "   <group name=\"whole_body\">\n", "      <group name=\"arms\"/>\n", "      <group name=\"base\"/>\n", "      <joint name=\"torso_lift_joint\"/>\n", "   </group>\n", "\n", "   <group name=\"l_end_effector\">\n", "      <joint name=\"l_gripper_palm_joint\" />\n", "      <joint name=\"l_gripper_l_finger_joint\" />\n", "      <joint name=\"l_gripper_l_finger_tip_joint\" />\n", "      <joint name=\"l_gripper_led_joint\" />\n", "      <joint name=\"l_gripper_motor_accelerometer_joint\" />\n", "      <joint name=\"l_gripper_motor_slider_joint\" />\n", "      <joint name=\"l_gripper_motor_screw_joint\" />\n", "      <joint name=\"l_gripper_r_finger_joint\" />\n", "      <joint name=\"l_gripper_r_finger_tip_joint\" />\n", "      <joint name=\"l_gripper_joint\" />\n", "      <joint name=\"l_gripper_tool_joint\" />\n", "   </group>\n", "\n", "   <group name=\"r_end_effector\">\n", "      <joint name=\"r_gripper_palm_joint\" />\n", "      <joint name=\"r_gripper_l_finger_joint\" />\n", "      <joint name=\"r_gripper_l_finger_tip_joint\" />\n", "      <joint name=\"r_gripper_led_joint\" />\n", "      <joint name=\"r_gripper_motor_accelerometer_joint\" />\n", "      <joint name=\"r_gripper_motor_slider_joint\" />\n", "      <joint name=\"r_gripper_motor_screw_joint\" />\n", "      <joint name=\"r_gripper_r_finger_joint\" />\n", "      <joint name=\"r_gripper_r_finger_tip_joint\" />\n", "      <joint name=\"r_gripper_joint\" />\n", "      <joint name=\"r_gripper_tool_joint\" />\n", "   </group>\n", "\n", "   <end_effector name=\"r_end_effector\" parent_link=\"r_wrist_roll_link\" group=\"r_end_effector\"/>\n", "   <end_effector name=\"l_end_effector\" parent_link=\"l_wrist_roll_link\" group=\"l_end_effector\"/>\n", "\n", "   <disable_collisions link1=\"r_shoulder_pan_link\" link2=\"r_shoulder_lift_link\" />\n", "   <!-- and many more disable_collisions tags -->\n", "\n", "</robot>"]},
{"url": "https://wiki.ros.org/maggie_devices_msgs", "package": "maggie_devices_msgs", "package_summary": ["maggie_devices_msgs metapackage"], "package_details": ["\n", "\n", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_eyelids_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_eyelids_msgs/manifest.yaml ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_ir_controller_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_ir_controller_msgs/manifest.yaml ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_motor_controller_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_motor_controller_msgs/manifest.yaml ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_rfid_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_rfid_msgs/manifest.yaml ", "This package defines ", "-specific message and service types for the devices. Most users will not use these types directly, but rather through Maggie-specific visualizations and utilities. "]},
{"url": "https://wiki.ros.org/rtt_rospack", "package": "rtt_rospack", "package_summary": ["rtt_rospack provides an RTT plugin to use rospack to find packages in your ROS_PACKAGE_PATH"]},
{"url": "https://wiki.ros.org/rtt_rosnode", "package": "rtt_rosnode", "package_summary": ["This package provides an RTT plugin to add a ROS node to the RTT process."]},
{"url": "https://wiki.ros.org/moveit_pr2", "package": "moveit_pr2", "package_summary": ["All PR2-specific packages for MoveIt"]},
{"url": "https://wiki.ros.org/kdl_typekit", "package": "kdl_typekit", "package_summary": ["This package contains the KDL RTT bindings"]},
{"url": "https://wiki.ros.org/svenzva_joy", "package": "svenzva_joy", "package_summary": ["The svenzva_joy package"], "package_details": ["\n", " ", "\n"], "package_tt": ["joy", "/joy", "joy", "Xbox\u00a0360", "Svenzva\u00a06-Axis\u00a0Joystick", "/joy", "joy", "/revel/gripper_action", "/joy", "joy", "/revel/eef_velocity"]},
{"url": "https://wiki.ros.org/pr2_moveit_config", "package": "pr2_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the pr2 with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/underwater_sensor_msgs", "package": "underwater_sensor_msgs", "package_summary": ["Common messages for underwater robotics"]},
{"url": "https://wiki.ros.org/pr2_navigation_self_filter", "package": "pr2_navigation_self_filter", "package_summary": ["Filters the robot's body out of point clouds."], "package_details": ["\n", "\n", "\n", " ", "The pr2_navigation_self_filter package provides a node that filters hits on the robot's body out of ", " messages and republishes them. ", "Due to the fact that ", " messages will soon be deprecated, the pr2_navigation_self_filter has no stable API. A new version of the node will be written and supported long term with the new PointCloud structure, but until the ", " stack moves to support the new PointCloud's this package will remain in ", ". Overall, you can use this package, but its at your own risk. ", "The pr2_navigation_self_filter package has been moved to the robot_self_filter package as it is no longer PR2 specific. It is hosted at ", ". This change will not fully go into affect until ROS Jade which the pr2_navigation_self_filter package will then be removed from the pr2_navigation metapackage. This means in Indigo, we will support both packages. In Hydro, there will be no relaese of robot_self_filter. Please see ", " for discussion on the matter. "]},
{"url": "https://wiki.ros.org/ur_bringup", "package": "ur_bringup", "package_summary": ["The ur_bringup package"], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/turtlebot_arm_kinect_calibration", "package": "turtlebot_arm_kinect_calibration", "package_summary": ["turtlebot_arm_kinect_calibration allows calibration of a kinect to a TurtleBot arm,\n    including a kinect on-board and off-board the TurtleBot for more precise manipulation."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "Refer to the ", " for instructions on how to calibrate a Kinect to the ", ". ", " ", " "], "package_tt": ["calibrate.launch", "/camera/rgb/image_mono", "/camera/rgb/camera_info", "~calibration_pattern_out", "~detector_cloud", "~physical_points", "~fixed_frame", "string", "~camera_frame", "string", "~target_frame", "string", "~tip_frame", "string", "~checkerboard_width", "int", "~checkerboard_height", "int", "~checkerboard_grid", "double", "~gripper_tip_x", "double", "~gripper_tip_y", "double", "~gripper_tip_z", "double", "<fixed_frame>", "<tip_frame>", "<camera_frame>", "<target_frame>"]},
{"url": "https://wiki.ros.org/rosserial", "package": "rosserial", "package_summary": ["Metapackage for core of rosserial."], "package_details": ["\n", " is a ", " for wrapping standard ROS serialized messages and multiplexing multiple topics and services over a character device such as a serial port or network socket. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Client libraries allow users to easily get ROS nodes up and running on various systems. These clients are ports of the general ANSI C++ ", " library.  Currently, these packages include: ", "Refer to ", " for details on how to add a new hardware platform. ", "Devices running ", " code require a node on the host machine to bridge the connection from the serial protocol to the more general ROS network: ", "The number of Publishers and Subscribers are limited at 25, and the size of serialization and deserialization buffers are limited at 512 bytes by default for ", ". ", "However, those numbers and sizes are too big for microcontroller with limited ", ". The buffer sizes, and numbers of Publisher/Subscriber for ", " now vary depending on the chip used: ", "You can change these numbers and sizes, refer to tutorial ", " for more informaiton. ", "To conserve precious AVR memory, strings are not stored inside a message instance, instead an ", " is stored. This has two impacts: ", "Therefore, to send an array message, we have to set the length and pointer. When deserializing, we cannot deserialize in-place like the string (since the bytes of the message are actually packed, unlike a string which is passed in plain form). Therefore, the deserialization function will automatically allocate enough storage using ", ", attempting to reuse the memory location whenever possible and only expanding it when the new message received is larger than the largest previous message. ", "The ", " protocol is aimed at point-to-point ROS communications over a serial transmission line. We use the same serialization/de-serialization as standard ROS messages, simply adding a packet header and tail which allows multiple topics to share a common serial link. This page describes the low-level details of the packet header and tail, and several special topics used for synchronization. ", "The Protocol version byte was ", " on ROS Groovy, ", " on ROS Hydro, Indigo, and Jade. ", "Topics ID 0-100 are reserved for system functions, as defined in the ", " message. ", "Report bugs, ask questions in the issues list on ", " "], "package_tt": ["rosserial", "unsigned\u00a0char\u00a0*", "realloc()", "0xff", "0xfe"], "package_code": ["typedef NodeHandle_<HardwareType, MAX_PUBLISHERS, MAX_SUBSCRIBERS, IN_BUFFER_SIZE, OUT_BUFFER_SIZE> NodeHandle;", "\n", "\n", "\n", "\n", "Header header\n", "geometry_msgs/Pose[] poses", "\n", "\n", "\n", "\n", "\n", "\n", "  1st Byte - Sync Flag (Value: 0xff)\n", "  2nd Byte - Sync Flag / Protocol version\n", "  3rd Byte - Message Length (N) - Low Byte\n", "  4th Byte - Message Length (N) - High Byte\n", "  5th Byte - Checksum over message length\n", "  6th Byte - Topic ID - Low Byte\n", "  7th Byte - Topic ID - High Byte\n", "  x Bytes  - Serialized Message Data\n", "  Byte x+1 - Checksum over Topic ID and Message Data", "Message Length Checksum = 255 - ((Message Length High Byte + \n", "                                   Message Length Low Byte) % 256 )", "Message Data Checksum = 255 - ((Topic ID Low Byte +\n", "                                Topic ID High Byte + \n", "                                Data byte values) % 256)", "  0xff 0xfe 0x00 0x00 0xff 0x00 0x00 0xff", "  uint16 topic_id\n", "  string topic_name\n", "  string message_type\n", "  string md5sum\n", "  int32 buffer_size"]},
{"url": "https://wiki.ros.org/target_monitor", "package": "target_monitor", "package_summary": ["A package that manages information about targets in a swarm of cyber physical systems (CPSs)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The communication between CPSs is based on the ", ". ", "The following packages of the ", " are required: ", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there are two parameter files ", " and ", " that allows to configure the behavior of the ", " node. The ", " contains the coordinates of the simulated targets. It is only used when the parameter ", " is set to ", ". They are given as two list parameters where the list index is the ID of the target. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["target_monitor", "id", "integer", "output", "string", "screen", "screen", "log", "param", "target_monitor.yaml", "targets.yaml", "target_monitor", "targets.yaml", "simulation", "true", "target_monitor", "target_tracking", "simulation", "true", "targets.yaml", "cmd/target_done/goal", "pos_provider/pose", "target_tracking", "cps_selected", "target_done", "bridge/events/target_found", "bridge/events/target_update", "bridge/events/cps_selected", "bridge/events/target_lost", "bridge/events/target_done", "bridge/uuid", "target_tracking", "simulation", "true", "fov", "target_found", "target_update", "target_lost", "target_done", "~loop_rate", "real", "~queue_size", "integer", "~tracking_timeout", "real", "~target_tolerance", "real", "~fov", "real", "~simulation", "boolean", "~targets_x", "real\u00a0list", "~targets_y", "real\u00a0list"], "package_code": ["roslaunch target_monitor target_monitor.launch"]},
{"url": "https://wiki.ros.org/rosservice", "package": "rosservice", "package_summary": ["rosservice contains the rosservice command-line tool for listing\n    and querying ROS ", ". It also\n    contains a Python library for retrieving information about\n    Services and dynamically invoking them. The Python library is\n    experimental and is for internal-use only."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " is a stable command-line tool within the ROS core toolchain. It's currently feature set is not expected expand much. Currently, the only major feature planned is the ability to use YAML text files as well as piped YAML input with the ", " command. This feature is currently not scheduled. ", "The ", " tool provides information about ", " files. ", "The ", " command implements a variety of commands that let you discover which services are currently online from which nodes and further drill down to get specific information about a service, such as its type, URI, and arguments. You can also call a service directly from the command line. ", "Please see ", " for a detailed description and examples of how to specify service arguments to ", ". ", "Please see ", " for a detailed description and examples of how to call ", " with negative-number arguments. "], "package_tt": ["rosservice", "args\u00a0<service-name>", "call\u00a0<service-name>\u00a0[service-args]", "--wait", "call", "rosservice", "find\u00a0<service-type>", "list", "list\u00a0<namespace>", "-n", "info\u00a0<service-name>", "node\u00a0<service-name>", "type\u00a0<service-name>", "uri\u00a0<service-name>", "rosservice", "rosservice\u00a0call"], "package_code": ["rosservice call call the service with the provided args\n", "rosservice find find services by service type\n", "rosservice info print information about service\n", "rosservice list list active services\n", "rosservice type print service type\n", "rosservice uri  print service ROSRPC uri", "$ rosservice args /service_name ", "$ rosservice call /service_name service-args", "$ rosservice call /add_two_ints 1 2", "$ rosservice find rospy_tutorials/AddTwoInts", "$ rosservice list", "$ rosservice list /rosout", "$ rosservice list -n", "$ rosservice info /rosout", "$ rosservice node /service_name", "$ rosservice type /service_name ", "$ rossrv show `rosservice type /service_name`", "$ rosservice type add_two_ints | rossrv show\n", "int64 a\n", "int64 b\n", "---\n", "int64 sum", "$ rosservice uri /service_name "]},
{"url": "https://wiki.ros.org/asr_lib_pose_prediction_ism", "package": "asr_lib_pose_prediction_ism", "package_summary": ["This package contains classes and algorithms to predict poses of searched objects by the help of a tree of ISMs. It is organized as a library and contains only a small program to evaluate the performance of different algorithms."], "package_details": [" ", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", "#include <asr_msgs/AsrObject.h> ", "#include <pose_prediction_ism/pose_predictor.h> #include <pose_prediction_ism/shortest_path.h> ", "pose_prediction_ism::PosePredictor* pose_predictor; ", "//use shortest path pose prediction. You can also use BestPath, RandomPath, PaperPredictionNormalized or PaperPredictionNonNormalized pose_predictor = new pose_prediction_ism::ShortestPath(db_filename); ", "//enables the random functionallity to simulate some noise (in mm, deg) //pose_predictor_->enableRandom(random_position, random_orientation); ", "//Buffer for already found objects in scene pose_prediction_ism::FoundObjects fos; ", "//add all already found objects to buffer for(std::size_t i = 0; i < BUFFERED_OBJECTS.size(); i++) { asr_msgs::AsrObject asr_o; asr_o.type = BUFFERED_OBJECTS[i]->type; asr_o.identifier = BUFFERED_OBJECTS[i]->observedId; fos.push_back(asr_o); } ", "//add buffter to predictor pose_predictor_->setFoundObjects(fos); ", "//ISM::PosePtr of ISM reference ISM::PosePtr referencePosePtr = MY_REFERENCE; ", "//name of pattern representing ISM std::string = \"MyPattern\"; ", "//call actually prediction here with parameters: pose_predictor_->predictUnfoundPoses(referencePosePtr, pattern_name, samplefactor); ", "//get the resulting attributed point cloud (which contains the prediction-results as labed points) pose_prediction_ism::AttributedPointCloud current_point_cloud = pose_predictor_->getAttributedPointCloud(); ", "//disables the random functionallity //pose_predictor_->disableRandom(); "]},
{"url": "https://wiki.ros.org/nextage_description", "package": "nextage_description", "package_summary": ["As a part of rtmros_nextage package that is a ROS interface for ", " dual-armed robot from Kawada Robotics Inc, this package provides its 3D model that can be used in simulation and ", "-based motion planning tasks."]},
{"url": "https://wiki.ros.org/turtle_actionlib", "package": "turtle_actionlib", "package_summary": ["turtle_actionlib demonstrates how to write an action server and client with the turtlesim. The shape_server provides and action interface for drawing regular polygons with the turtlesim."], "package_details": ["\n", "\n", "This tutorial package provides a ", " and example ", " for drawing regular polygons with the ", ". The default client will draw a pentagon in ", ".  ", "The ", " is defined below:  ", "Then in separate terminals ", " the following nodes: "], "package_tt": ["shape_server", "shape_client", "turtlesim_node", "turtlesim", "Shape.action", "rosrun"], "package_code": ["#goal definition\n", "int32 edges\n", "float32 radius\n", "---\n", "#result definition\n", "float32 interior_angle\n", "float32 apothem\n", "---\n", "#feedback", "$ rosdep install turtle_actionlib\n", "$ rosmake turtle_actionlib ", "$ rosrun turtlesim turtlesim_node\n", "$ rosrun turtle_actionlib shape_server\n", "$ rosrun turtle_actionlib shape_client"]},
{"url": "https://wiki.ros.org/m4atx_battery_monitor", "package": "m4atx_battery_monitor", "package_summary": ["Battery Monitor for the M4-ATX Power Module"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package will read the information from a m4atx battery supply and publish it as a ros message. ", "Locate the bus and device number of the device called \"", " Technology, Inc.\". ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["m4atx_battery_monitor", "m4atx_battery_monitor_node", "battery_status_m4atx", "~diag_frequency", "~input_nominal", "~battery_dead_voltage", "m4atx_battery_monitor", "ros_ethernet_rmp", "m4atx-battery-monitor.launch", "m4atx_battery_monitor_node"], "package_code": ["lsusb ", "sudo chmod a+rw /dev/bus/usb/<bus_num>/<device_num>", "\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-m4atx-battery-monitor", "roslaunch m4atx_battery_monitor_node m4atx_battery_monitor_node.launch "]},
{"url": "https://wiki.ros.org/wheeled_robin_teleop", "package": "wheeled_robin_teleop", "package_summary": ["The wheeled_robin_teleop package provides nodes and launch files for teleoperating WheeledRobin"], "package_details": ["\n", "\n", " ", "This package contains a launch file for the ", "node in  ", " to teleoperate a robot with a Thrustmaster T-Wireless gamepad. The launch file also includes the ", " file. A ", "node from ", " is also loaded. "], "package_tt": ["turtlebot_teleop_joy\u00a0", "turtlebot_teleop/launch/includes/velocity_smoother.launch.xml", "joy_node\u00a0"], "package_code": ["roslaunch wheeled_robin_teleop thrustmaster_teleop.launch"]},
{"url": "https://wiki.ros.org/turtlebot_navigation", "package": "turtlebot_navigation", "package_summary": ["turtlebot_navigation"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/constrained_ik", "package": "constrained_ik", "package_summary": ["Constraint-based IK solver.  Good for high-DOF robots or underconstrained tasks."]},
{"url": "https://wiki.ros.org/schunk_grippers", "package": "schunk_grippers", "package_summary": ["Schunk_grippers stack contains packages for PG70 and EZN64 grippers"], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack contains packages to control EZN64 and PG70 Schunk grippers from ROS. It is a basic implementation of Schunk Motion protocol in combination with ", " and ", " library, which allows user to interface grippers through standard ROS services. Xacro models of EZN64 and PG70 grippers are included as well. ", "Schunk EZN64 (libusb1.0 implementation) - ", " ", "Schunk  PG70  (serial implementation)                  - ", " "]},
{"url": "https://wiki.ros.org/sr_description", "package": "sr_description", "package_summary": ["\n\n     sr_description contains the description for Shadow Robot's Hand and Arm, as well as some additional models used in our robot (kinect, etc...).\n\n  "]},
{"url": "https://wiki.ros.org/ur3_moveit_config", "package": "ur3_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the ur3 with the MoveIt Motion Planning Framework"], "package_details": ["\n", "\n", "\n", "This package is part of the ", " program. It is the ", "! configuration for the UR3 arm, generated automatically by the ", " Setup Assistant. ", "Install the package from package management, and run the MoveIt! planning demo: ", "This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR3, see the ", " package. ", "See also the relevant sections in the ", " on Github. "], "package_tt": ["moveit_simple_controller_manager"], "package_code": ["$ sudo apt-get install ros-$ROS_DISTRO-ur3-moveit-config\n", "\n", "$ roslaunch ur3_moveit_config demo.launch"]},
{"url": "https://wiki.ros.org/waypoint_touring", "package": "waypoint_touring", "package_summary": ["Tours around the waypoints"]},
{"url": "https://wiki.ros.org/roscpp_traits", "package": "roscpp_traits", "package_summary": ["roscpp_traits contains the message traits code as described in\n    ", ".\n\n    This package is a component of ", "."], "package_details": [" ", "Please see ", ". ", "roscpp_traits is an internal library used in ", " and should not be used directly.  "]},
{"url": "https://wiki.ros.org/python_ethernet_rmp", "package": "python_ethernet_rmp", "package_summary": ["Segway RMP Ethernet Python Driver"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains the drivers for interfacing to a Segway RMP via an Ethernet connection. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["python_ethernet_rmp", "python_ethernet_rmp"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-python-ethernet-rmp"]},
{"url": "https://wiki.ros.org/moveit_ros_benchmarks_gui", "package": "moveit_ros_benchmarks_gui", "package_summary": ["MoveIt GUI tools for benchmarking"]},
{"url": "https://wiki.ros.org/staubli_tx90_gazebo", "package": "staubli_tx90_gazebo", "package_summary": ["\n      ROS-Industrial Gazebo support package for the Staubli TX90 (and variants).\n    ", "\n      This package contains the configuration data and launch files required\n      to simulate the Staubli TX90 manipulator in Gazebo. This includes the base\n      model, the TX90L and the TX90XL.\n    ", "\n      Before using any of the configuration files included in this package, be\n      sure to check they are correct for the particular robot model and\n      configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/roscpp_serialization", "package": "roscpp_serialization", "package_summary": ["roscpp_serialization contains the code for serialization as described in\n    ", ".\n\n    This package is a component of ", "."], "package_details": [" ", "\n", "Please see ", ". ", "roscpp_serialization provides the ", " API used in ", " and should not be used directly.   "], "package_tt": ["ros::serialization"]},
{"url": "https://wiki.ros.org/sr_gui_motor_resetter", "package": "sr_gui_motor_resetter", "package_summary": ["\n\n     sr_gui_motor_resetter - gui plugin for resetting motors on the shadow hand.\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/wheeled_robin_core_apps", "package": "wheeled_robin_core_apps", "package_summary": ["The core set of wheeled_robin 'app manager' apps are defined in this package."], "package_details": ["\n", "\n", "\n", " ", "This package contains various robot apps (rapps) that can be used by WheeledRobin or any ", " compatible robot. Rapps are used by the appmanager started by 'minimal_with_appmanager' or 'bringup.concert' in ", " package. ", "Control the ", " with a Thrustmaster Joystick. Rapp Platform: linux.ros.turtlebot "]},
{"url": "https://wiki.ros.org/tra1_bringup", "package": "tra1_bringup", "package_summary": ["Package contains bringup scripts/config/tools for tra1 robto"], "package_details": ["\n", " ", "\n", " ", "Now you can see ", "! rviz interface to control the robot. "], "package_code": ["$ roslaunch tra1_bringup tra1_bringup.launch simulation:=true", "$ roslaunch tra1_bringup tra1_moveit.launch"]},
{"url": "https://wiki.ros.org/pr2_navigation_config", "package": "pr2_navigation_config", "package_summary": ["This package holds common configuration files for running the"], "package_details": ["\n", "\n", "This package holds a number of common configuration files for the ", " node on the PR2 robot. In particular, it holds parameter settings for the ", ", ", ", and ", " components of the ", " node that are shared between many different configurations of the ", " stack run on the PR2. "], "package_tt": ["move_base/base_local_planner_params.yaml", "move_base/costmap_common_params.yaml", "move_base/move_base_params.yaml"]},
{"url": "https://wiki.ros.org/pr2_mechanism_model", "package": "pr2_mechanism_model", "package_summary": ["\n        This package contains the robot model that is used by the realtime\n        controllers\n        inside ", ". This robot model focuses on controlling the robot\n        mechanism in a realtime control loop, and therefore it only contains\n        the components of a robot that are relevant in realtime: the robot\n        joints (with encoders, transmisisons and actuators) and the\n        kinematic/dynamic model of the robot.\n     ", "\n        The pr2_mechanism_model package is well tested and is released with a stable API.\n     "], "package_details": ["\n", " ", "\n", "\n", " is the main class in this package.  When a controller gets initialized, the ", " passes the controller a pointer to the ", " (see the ", "). The robot state describes both the kinematic/dynamic model of the robot and the current state of the robot. The state of the robot is defined by the position/velocity/effort of the joints in the robot. The model of the robot is a ", " object, as defined in the ", ". Additionally, the ", " provides access to the 'controller time', the time at which a controller cycle is started. To see an example on how to use the ", ", check out the ", ". ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains the ", " C++ class, which is an interface to the robot joints and a description of the robot model. The ", " gives easy access to individual joints. To work with a kinematic chain that contains multiple joints, ", " contains a ", " tool that represents a full kinematic chain and interfaces with the ", ". ", "The ", " provides access by name to all the ", "s it contains. To get access to a ", ", use the following method: ", "From a ", " you can extract joint position, effort, velocity, and command the desired joint effort: ", "To get e.g. the measured joint position from the ", ", use: ", "or, to set the commanded effort on ", ", use: ", "The ", " give more examples on how to use the ", ". ", "The ", " also gives access to the joint model, which contains things like the joint type, axis, reference position, etc. To e.g. get the joint type, use: ", "The ", " API documentation provides all details. ", "For reference documentation, check out the  ", ". From a ", " you can read the measured position, measured velocity and measured effort effort, and write the commanded effort. ", "Class member ", " ", "The ", " also provides access to the transmissions between the motors and the joints. Typically you should not need the transmissions, unless you are using some advanced dynamic model, or you are calibrating the joints. To get access to a ", ", use the following method: ", "See the ", " for more details. ", "For details on the transmission description format, check out the ", " page. ", "Every time a controller cycle is started, the ", " records the time. This time can be accessed by all controllers through the ", ". When a controller e.g. needs to compute the duration between two consecutive update loops, it should ", ". In contrast to the system time, the controller time is not affected by the time other controllers consume in their update loop. Moreover, the controller time is the best measure of when the communication with the hardware actually occurs. To get access to the controller time, use: ", "The ", " contains a ", " robot description object. There is lots of ", " on the urdf model, and there are even a number of ", " you could look at. To get access to the urdf model use: ", "The ", " class provides an easy way to work with a kinematic chain that consists of multiple joints. Instead of finding all the joints by iterating through the ", ", the ", " will pull out all the joints between a given root and tip link: ", "From a ", " you can get the positions/velocities/efforts of all the joints, and set the efforts of all joints: ", "From a chain you can also extract a ", ": ", "See the ", " for more details. ", "The ", " is used when writing a realtime controller. For example code on how to use the ", " and the ", " classes, check out ", ". To see an example on how to use the ", " object for Cartesian control, check out ", ". "], "package_tt": ["pr2_mechanism_model", "pr2_mechanism_model::RobotState", "RobotState", "pr2_mechanism_model", "pr2_mechanism_model::Chain", "RobotState", "pr2_mechanism_model::RobotState", "RobotState", "RobotState", "RobotState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "urdf::Joint::safety", "pr2_mechanism_model::RobotState", "JointState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::Chain", "RobotState", "Chain", "Chain", "KDL::Chain", "pr2_mechanism_model", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::JointState", "pr2_mechanism_model::Chain"], "package_code": ["JointState* js = robot_state_->getJointState(name);", "double position = js->position_;", "js->commanded_effort_ = my_command;", "if (js->joint_->type == urdf::Joint::Continuous)\n", "ROS_INFO(\"This is a continuous joint\");", "js->joint_->safety", "Transmission* tr = robot_state_->getTransmission(name);", "ros::Time time = robot_state_->getTime();", "urdf::Model m = robot_state_->robot_->robot_model_;", "pr2_mechanism_model::Chain chain;\n", "chain.init(robot_state, root_name, tip_name);", "KDL::JointArray jnt_pos;\n", "chain.getPositions(jnt_pos);\n", "\n", "KDL::JointArrayVel jnt_pos_vel;\n", "chain.getVelocities(jnt_pos_vel);\n", "\n", "KDL::JointArray jnt_eff;\n", "chain.getEfforts(jnt_eff);\n", "\n", "KDL::JointArray jnt_eff;\n", "chain.setEfforts(jnt_eff);", "KDL::Chain kdl_chain;\n", "chain.toKDK(kdl_chain);"]},
{"url": "https://wiki.ros.org/turtlebot3_simulations", "package": "turtlebot3_simulations", "package_summary": ["ROS packages for the turtlebot3 simulation (meta package)"], "package_details": [" ", "\n", " ", " is a new generation mobile robot that is modular, compact and customizable. Let\u2019s explore ROS and create exciting applications for education, research and product development. The goal of ", " is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and ", " can be customized in various ways. ", " is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. ", "\n", "\n", "\n", "\n"], "package_tt": ["TurtleBot3", "TurtleBot3", "TurtleBot3"]},
{"url": "https://wiki.ros.org/rc_visard_driver", "package": "rc_visard_driver", "package_summary": ["The rc_visard_driver provides data from a Roboception rc_visard 3D sensor on several ROS topics."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", " ", "Official ROS driver for ", " rc_visard 3D sensor. ", "See ", " and ", " for more details. ", "The ", " is the world\u2019s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. ", "The ", " is the official ROS driver for the ", " which provides ROS parameters (configuration), ROS services (control of rc_visards dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF).  ", "If the connected rc_visard has an ", " license, then the following ", "topics are additionally provided for images where the GPIO out1 is either low ", "or high. These topics only useful if ", " is set to the special mode ", ". ", "For color sensors with an ", " license, the following topics are ", "additionally available: ", "If the parameter ", " is set to true, the node subscribes to the ", "rc_visard's pose stream (same data published on ", " topic) and publishes them on tf. ", "The trajectory constructed and stored by the ", " node ", "can be retrieved by ", "The onboard map of the ", " node can be saved on the rc_visard for loading it ", "after a SLAM restart or power cycle: ", "The onboard ", " node can be \"reset\" (clears the internal state of the SLAM component, ", "including the trajectory) to free the memory with "], "package_tt": ["device", "02912345", ":02912345", "gev_access", "control", "exclusive", "off", "max_reconnects", "enable_tf", "enable_visualization_markers", "/dynamics_visualization_markers", "autostart_dynamics", "autostart_dynamics_with_slam", "autostop_dynamics", "autopublish_trajectory", "/trajectory", "ptp_enabled", "camera_fps", "camera_exp_auto", "camera_exp_max", "camera_exp_value", "camera_gain_value", "camera_exp_width", "camera_exp_height", "camera_exp_offset_x", "camera_exp_offset_y", "depth_acquisition_mode", "SingleFrame", "Continuous", "S", "C", "depth_quality", "Low", "Medium", "High", "StaticHigh", "L", "M", "H", "S", "StaticHigh", "High", "Medium", "Low", "High", "depth_static_scene", "depth_disprange", "depth_fill", "depth_seg", "depth_smooth", "depth_median", "depth_minconf", "depth_mindepth", "depth_maxdepth", "depth_maxdeptherr", "out1_mode", "Low", "High", "ExposureActive", "ExposureAlternateActive", "IO\u00a0Control", "ExposureActive", "out2_mode", "out1_mode", "Low", "camera_wb_auto", "camera_wb_ratio_red", "camera_wb_auto", "camera_wb_ratio_blue", "camera_wb_auto", "IO\u00a0Control", "out1_mode", "ExposureAlternateActive", "IO\u00a0Control", "enable_tf", "enable_tf", "/pose", "camera", "world", "camera", "imu", "my_visard", "my_visard_world", "my_visard_camera", "dynamics_start", "dynamics_restart", "dynamics_stop", "dynamics_start_slam", "dynamics_restart_slam", "dynamics_stop_slam", "rc_slam", "slam_get_trajectory", "rc_slam", "slam_save_map", "slam_load_map", "slam_remove_map", "rc_slam", "slam_reset", "my_visard", "my_visard_camera", "my_visard_world", "my_visard_imu"], "package_code": ["rosrun rc_visard_driver rc_visard_driver _device:=:02912345 _enable_tf:=True _autostart_dynamics:=True _autostop_dynamics:=True", "ROS_NAMESPACE=my_visard rosrun nodelet nodelet standalone rc_visard_driver _device:=:02912345"]},
{"url": "https://wiki.ros.org/rosh_common", "package": "rosh_common", "package_summary": ["\n\n     ROSH plugin for packages in the common stack\n\n  "], "package_details": ["\n", "\n", " provides an index of all ", " actions in a running ROS graph. The API is currently very simple right now and only supports display action goal arguments and synchronous invocation. ", " ", " ", "\n", " provides an index of cameras that support the general ROS camera interface, which is commonly used in ", ". With the ", " object, you can easily inspect which cameras are available, retrieve their camera info, and show camera images. ", " ", "\n", "\n", " "], "package_tt": ["cameras", "actions", "actions", "actions.action_name", "actions.action_name(args)", "cameras", "cameras", "show(cameras.camera)", "rviz/image_view", "rosh_common.PLUGIN_CAMERA_SHOW", "show()", "cameras"]},
{"url": "https://wiki.ros.org/test_nodelet", "package": "test_nodelet", "package_summary": ["A package for nodelet unit tests"]},
{"url": "https://wiki.ros.org/turtlebot3_follow_filter", "package": "turtlebot3_follow_filter", "package_summary": ["turtlebot3_follow_filter package using laser_filters for turtlebot3_follower package"], "package_details": [" ", "\n", "\n", "\n", "\n", "This package provides parameters from ", " in ", " directory. "], "package_tt": ["scan", "scan_filtered"], "package_code": ["scan_filter_chain:\n", "\n", "- name: Remove over 0.35 meters on the right\n", "  type: laser_filters/LaserScanBoxFilter\n", "  params:\n", "    box_frame: odom\n", "    min_x: -3.5\n", "    max_x: 3.5\n", "    min_y: -3.5\n", "    max_y: -0.35\n", "    min_z: -0.1\n", "    max_z: 0.1\n", "\n", "- name: Remove over 0.35 meters on the left\n", "  type: laser_filters/LaserScanBoxFilter\n", "  params:\n", "    box_frame: odom\n", "    min_x: -3.5\n", "    max_x: 3.5\n", "    min_y: 0.35\n", "    max_y: 3.5\n", "    min_z: -0.1\n", "    max_z: 0.1\n", "\n", "- name: Remove 90 to 270 degree\n", "  type: laser_filters/LaserScanAngularBoundsFilterInPlace\n", "  params:\n", "    lower_angle: 1.57\n", "    upper_angle: 4.71\n", "\n", "- name: exist range 0.12 to 0.7 meter\n", "  type: laser_filters/LaserScanRangeFilter\n", "  params:\n", "    lower_threshold: 0.12\n", "    upper_threshold: 0.7\n", "\n", "- name: exist intensity 500 to 4000\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 500\n", "    upper_threshold: 4000\n", "    disp_histogram: 0\n", "\n", "- name: interpolation\n", "  type: laser_filters/InterpolationFilter"]},
{"url": "https://wiki.ros.org/sr_gui_joint_slider", "package": "sr_gui_joint_slider", "package_summary": ["\n\n     sr_gui_joint_slider is a rosgui plugin to change the position of the different joints.\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/pr2_hardware_interface", "package": "pr2_hardware_interface", "package_summary": ["This package contains the C++ interfaces to the PR2 hardware\n  components that are controlled over EtherCAT. This includes the\n  motors and encoders needed to control the PR2 mechanism, as well as\n  components like the pressure sensors in the fingertips, camera\n  triggers, etc... All of the hardware components in this interface are\n  directly available to the controllers inside the hard realtime\n  control loop."], "package_details": ["\n", "The PR2 hardware interface provides a C++ abstraction layer for the PR2 hardware that is controlled over the ", " that runs through the robot. Most users should not have to deal directly with this interface. If you are only interested in controlling the robot joints, you should directly interact with ", ". Only very advanced users that need direct access to the hardware should be using the PR2 hardware interface.  "], "package_tt": ["HardwareInterface"]},
{"url": "https://wiki.ros.org/staubli_experimental", "package": "staubli_experimental", "package_summary": ["Experimental packages for Staubli manipulators within ROS-Industrial (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This repository is part of the ", " program. It contains experimental packages that will be moved to the ", " package once they've received sufficient testing and review. ", "Due to the experimental nature of these packages, they have not been released and are not part of any ROS distribution. In order to use this stack, it has to be checked out into a catkin workspace and has to be build manually. Refer to the ", " for more information. ", "See the ", " page for more information. ", "For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "]},
{"url": "https://wiki.ros.org/jog_msgs", "package": "jog_msgs", "package_summary": ["The jog_msgs package"]},
{"url": "https://wiki.ros.org/turtlebot3_autorace", "package": "turtlebot3_autorace", "package_summary": ["AutoRace ROS packages for AutoRace with TurtleBot3 (meta package)"], "package_details": [" ", "\n", " ", " is a new generation mobile robot that is modular, compact and customizable. Let\u2019s explore ROS and create exciting applications for education, research and product development. The goal of ", " is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and ", " can be customized in various ways. ", " is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. ", "\n", "\n", "\n", "\n"], "package_tt": ["TurtleBot3", "TurtleBot3", "TurtleBot3"]},
{"url": "https://wiki.ros.org/turtlebot_teleop", "package": "turtlebot_teleop", "package_summary": ["Provides teleoperation using joysticks or keyboard."], "package_details": ["\n", "\n", "\n", "The ", " package provides launch files for teleoperation with different input devices. "], "package_tt": ["turtlebot_teleop", "turtlebot_teleop_key", "turtlebot_telop_keyboard/cmd_vel", "~scale_linear", "double", "~scale_angular", "double", "turtlebot_teleop_joy", "joy", "turtlebot_telop_joystick/cmd_vel", "~scale_linear", "double", "~scale_angular", "double", "~axis_deadman", "int", "~axis_linear", "int", "~axis_angular", "int"], "package_code": ["roslaunch turtlebot_teleop keyboard_teleop.launch", "roslaunch turtlebot_teleop ps3_teleop.launch", "roslaunch turtlebot_teleop xbox360_teleop.launch"]},
{"url": "https://wiki.ros.org/allocators", "package": "allocators", "package_summary": ["Contains aligned allocation functions, as well as an STL-compatible AlignedAllocator class."], "package_details": ["\n", "General aligned allocation is done through the ", " and ", " functions.  For example: "], "package_tt": ["alignedMalloc()", "alignedFree()"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/pr2_mechanism", "package": "pr2_mechanism", "package_summary": ["The pr2_mechanism stack contains the infrastructure to control the PR2 robot in a hard realtime control loop."], "package_details": ["\n", "\n", "The ", " stack contains useful libraries if you want to write a realtime controller to interact with the PR2 (or similar) robot. These libraries are contained in the following ROS packages: ", "Report new issues on ", " "], "package_tt": ["pr2_mechanism", "pr2_mechanism", "pr2_mechanism", "pr2_mechanism"]},
{"url": "https://wiki.ros.org/turtlebot_capabilities", "package": "turtlebot_capabilities", "package_summary": ["Capabilities for the TurtleBot"]},
{"url": "https://wiki.ros.org/sync_params", "package": "sync_params", "package_summary": ["Synchronises parameters across multiple masters."], "package_details": ["\n", " provides a means to synchronize parameter servers between multiple ROS masters. The parameter server is polled, and new parameters are published as a topic. The topic is then synchronized across masters using ", ". The topic is received and written to the parameter server on the other ROS master. ", "\n", "\n", "\n", "By default, all parameters will be synchronized. The ", " excludes parameters based on their name. The ", " parameters are exempt from the ", ". These can both be regular expressions. For example: ", "Would only synchronize ", ". ", "The parameter ", " is designed for spawning robots in Gazebo. Gazebo pauses the ROS clock when loading a robot, and waits for the ", " parameter. But that parameter might not get synchronized if ", " uses the ROS clock. ", "Examples can be found in the ", ". "], "package_tt": ["sync_params", "blacklist", "whitelist", "blacklist", "my_parameter", "use_wall_time", "robot_description", "sync_params", "/params", "/params", "~debug", "boolean", "~rate", "double", "~death_timer", "double", "~use_wall_time", "boolean", "death_timer", "~blacklist", "array", "~whitelist", "array", "blacklist"], "package_code": ["blacklist = [\"/*\"]\n", "whitelist = [/my_parameter]"]},
{"url": "https://wiki.ros.org/ncd_parser", "package": "ncd_parser", "package_summary": ["The ncd_parser package reads in .alog data files from the New College Dataset and broadcasts scan and odometry messages to ROS."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " used with the permission of Dr. Paul Newman, Oxford University. ", "\n", " ", "The ", " package reads in .alog data files from the New College Dataset and broadcasts the data in ROS. The messages are broadcast in real time. Currently, the data extracted includes the odometry of the robot and the readings from the left and right SICK laser scanners. Additional transforms are provided between the odometric frame and the two lasers, as described in the NCD paper. ", "To use the ", ", you need to obtain an .alog file from the New College Dataset ", ". ", "You can run the ", " on a small .alog file included in the package for demo purposes. First, make sure you have the ", " stack downloaded and installed by following the instructions ", ". ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["ncd_parser", "scan_left", "scan_right", "start", "double", "0.0", "end", "double", "-1.0", "-1", "rate", "double", "1.0", "1.0", "map", "odom", "odom", "laser_left", "odom", "laser_right", "QuadTree_Alog.alog"], "package_code": ["\n", "\n"]},
{"url": "https://wiki.ros.org/swarm_functions", "package": "swarm_functions", "package_summary": ["The swarm functions library provides simple functionalities that enable swarm algorithms to work. It is part of the swarm library."], "package_details": ["\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "The swarm functions library provides simple functionalities that enable swarm algorithms to work. It is part of the ", ". ", "This work is supported by the European Commission through the ", " under grant no. 731946. "]},
{"url": "https://wiki.ros.org/librms", "package": "librms", "package_summary": ["Client libraries for the RMS API."], "package_details": ["\n", "\n", "\n", "\n", "\n", "To install the ", " stack, you can choose to either install from source, or from the Ubuntu package: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["librms", "librms"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-librms"]},
{"url": "https://wiki.ros.org/sr_robot_lib", "package": "sr_robot_lib", "package_summary": ["\n\n     sr_robot_lib contains the robot library used in the sr_edc_ethercat_drivers. The\n     library is used to store the incoming etherCAT messages in an easy to access format,\n     and prepare the messages to be send through etherCAT.\n\n  "], "package_details": ["\n", "\n", "This package also contains a class which builds the etherCAT command we want to send to the hand, based on the configuration file ", ", the data is updated at different rates. ", "The ", " folder contains most of the configuration for the hand driver (except the controller configuration): "]},
{"url": "https://wiki.ros.org/ur_kinematics", "package": "ur_kinematics", "package_summary": ["Provides forward and inverse kinematics for Universal Robots designs.\n     See http://hdl.handle.net/1853/50782 for details."], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/tf_tools", "package": "tf_tools", "package_summary": ["ROS tools and scripts relates to tf"], "package_details": ["\n", "\n", "\n", "tf_logger will record the changes of frames published through ", " each with respect to a given reference frame. ", "E.g. if you want to log both the transforms /world -> /odom and /odom -> /base_link at a frequency of 5 Hz, run "], "package_code": ["    $ rosrun tf_tools tf_logger FREQUENCY REF_FRAME LOG_FRAME [REF_FRAME LOG_FRAME ...]", "    $ rosrun tf_tools tf_logger 5 /world /odom /odom /base_link"]},
{"url": "https://wiki.ros.org/rc_hand_eye_calibration_client", "package": "rc_hand_eye_calibration_client", "package_summary": ["The rc_hand_eye_calibration_client package"], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", "See ", " and ", " for more details. ", "The default behavior is to request the existing calibration of the rc_visard once on startup, broadcast it (latched) on ", " and only broadcast again if the advertised ROS services ", " or ", " are called. ", "After the calibration transform is calculated and tested, it should be saved to the rc_visard (", "). ", "For detailed instructions on the calibration routine consult the rc_visard manual: ", ". "], "package_tt": ["/tf", "/tf_static", "/tf_static", "calibrate", "get_calibration", "set_pose", "calibrate", "save_calibration", "host", "rc_visard_frame_id", "end_effector_frame_id", "robot_mounted", "base_frame_id", "robot_mounted\u00a0==\u00a0false", "calibration_request_period", "calibrate", "get_calibration", "calibration_publication_period", "/tf", "/tf_static", "/tf_static", "device", "02912345", ":02912345", "grid_width", "grid_height", "robot_mounted", "reset_calibration", "set_pose", "calibrate", "set_pose", "/tf", "/tf_static", "get_calibration", "/tf", "/tf_static", "save_calibration", "get_calibration", "remove_calibration", "get_calibration", "/tf"], "package_code": ["rosrun rc_hand_eye_calibration_client rc_hand_eye_calibration_client_node _host:=<sensor_ip>", "rosrun rc_hand_eye_calibration_client rc_hand_eye_calibration_client_node _device:=:<serial_number>"]},
{"url": "https://wiki.ros.org/laser_scan_matcher", "package": "laser_scan_matcher", "package_summary": ["\n     An incremental laser scan matcher, using Andrea Censi's Canonical Scan Matcher (CSM) implementation. See ", " for more about CSM. NOTE the CSM library is licensed under the GNU Lesser General Public License v3, whereas the rest of the code is released under the BSD license.\n    "], "package_details": [" ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: ", ") ", "\n", " (", ", default: ", ") ", "\n", " (", ", default: ", ") ", "\n", " (", ", default: 0.10) ", "\n", " (", ", default: ", ") ", "\n", " (", ", default: 10) ", "\n", " (", ", default: 0.010) ", "\n", "\n", " ", "The ", " package is an incremental laser scan registration tool.  The package allows to scan match between consecutive ", " messages, and publish the estimated position of the laser as a ", " or a ", " transform. ", "The ", " can operate using ", " messages or ", " messages. When using ", ", make sure they have no ", " values.  ", "While the ", " can operate by just using scan data, we can speed up the scan registration process by providing a guess for the current position of the sensor every time a new scan message arrives. When no guess is available, a reasonable (and widely-used) assumption is that the sensor didn't move (zero-velocity model). Below is a list of inputs that ", " accepts: ", "We can use combinations of the above such as IMU together with wheel odometry or IMU together with alpha beta tracking. When several prediction modes are enabled, the priority is IMU > Odometry > Constant Velocity > Zero Velocity. ", "Setting the tolerance for updating the keyframe can be achieved via the ", " and ", " parameters. Their default values give a more robust performance, both while standing still and moving. ", "You can run the ", " on a pre-recorded bag file that comes with the package. First, make sure you have the ", " stack downloaded and installed by following the ", ". ", "Two drivers are available: ", " and ", ". Their parameters and topics are identical. ", "Parameters when using ", " instead of ", " messages. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["nan", "delta-theta", "yaw", "imu/data", "odom", "vel", "kf_dist_linear", "kf_dist_angular", "laser_scan_matcher_nodelet", "laser_scan_matcher_node", "scan", "cloud", "imu/data", "use_imu", "true", "odom", "use_odom", "true", "pose2D", "base_link", "laser", "world", "base_link", "publish_tf", "~fixed_frame", "string", "\"world\"", "~base_frame", "string", "\"base_link\"", "~use_imu", "bool", "true", "/imu/data", "~use_odom", "bool", "true", "odom", "~use_vel", "bool", "false", "vel", "~use_cloud_input", "bool", "false", "/cloud", "/scan", "~cloud_range_min", "double", "~cloud_range_max", "double", "~kf_dist_linear", "double", "~kf_dist_angular", "double", "~publish_tf", "bool", "true", "~publish_pose", "bool", "true", "~publish_pose_stamped", "bool", "false", "~max_iterations", "int", "~max_correspondence_dist", "double", "~max_angular_correction_deg", "double", "~max_linear_correction", "double", "~epsilon_xy", "double", "~epsilon_theta", "double", "~outliers_maxPerc", "double", "~sigma", "double", "~use_corr_tricks", "int", "~restart", "int", "~restart_threshold_mean_error", "double", "~restart_dt", "double", "~restart_dtheta", "double", "~clustering_threshold", "double", "~orientation_neighbourhood", "int", "~use_point_to_line_distance", "int", "~do_alpha_test", "int", "~do_alpha_test_thresholdDeg", "double", "~outliers_adaptive_order", "double", "outliers_adaptive_order", "outliers_adaptive_mult", "~outliers_adaptive_mul", "double", "outliers_adaptive_order", "outliers_adaptive_mult", "~do_visibility_test", "int", "~outliers_remove_doubles", "int", "~do_compute_covariance", "int", "~debug_verify_trick", "int", "~use_ml_weights", "int", "~use_sigma_weights", "int"], "package_code": ["\n"]},
{"url": "https://wiki.ros.org/summit_xl_description", "package": "summit_xl_description", "package_summary": ["URDF description of the Summit XL and Summit XL HL and omni versions"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/turtlebot", "package": "turtlebot", "package_summary": ["The turtlebot meta package provides all the basic drivers for running and using a TurtleBot."]},
{"url": "https://wiki.ros.org/acc_finder", "package": "acc_finder", "package_summary": ["This package contains two small tools to help configure the navigation pipeline. The node min_max_finder.py prints the minimum and maximum linear and angular speed of the robot; the node acc_finder.py prints the time needed to achieve maximum speed."]},
{"url": "https://wiki.ros.org/quadrotor_handler", "package": "quadrotor_handler", "package_summary": ["The quadrotor_handler package"], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/ros_type_introspection", "package": "ros_type_introspection", "package_summary": ["The ros_type_introspection package allows the user to parse and deserialize\n  ROS messages which type is unknown at compilation time."], "package_details": ["\n", "\n", "\n", "\n", " ", "The ROS Message Types can be described as a ", ". This approach is very well known and commonly used on the web and in distributed systems in general. ", "A ", " is defined by the user; an \"IDL compiler\", i.e. ", ", reads this schema and generates a header file that contains the source code that the user shall include in his/her applications. The inclusion of this header file is needed on both the publisher ", " the subscriber sides. ", "The only \"problem\" is that in very few use cases (for instance if you want to build a plugin to ", ") you don't know in advance which ROS Messages you will need to read. Therefore, you won't be able to include the necessary header files. ", "1. ", ": a type used to subscribe to any topic, regardless of the original type. ", "2. ", ": the generic type commonly used to read data from a ROS bag. ", "Please refer to ", ". "], "package_tt": ["ros::message_traits::Definition"]},
{"url": "https://wiki.ros.org/batteries_skill_msgs", "package": "batteries_skill_msgs", "package_summary": ["batteries_skill messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"batteries_skill_msgs\" in rosdoc: /home/rosbot/docs/api/batteries_skill_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/launch_tools", "package": "launch_tools", "package_summary": ["ROS tools and scripts related to launchfiles"], "package_details": ["\n", "\n", " "], "package_code": ["    $ rosrun srv_tools launchViz ", "    $ rosrun srv_tools launchViz -pkg PKG_A [PKG_B ...]"]},
{"url": "https://wiki.ros.org/wsg_32_description", "package": "wsg_32_description", "package_summary": ["URDF and Xacro description files for the Weiss WSG 32 gripper with force sensing fingers."], "package_details": [" "]},
{"url": "https://wiki.ros.org/visp_camera_calibration", "package": "visp_camera_calibration", "package_summary": ["visp_camera_calibration allows easy calibration of\n     cameras using a customizable pattern and ViSP library."], "package_details": ["\n", "\n", "\n", " is part of ", " stack.  ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "visp_camera_calibration is a ROS package that allows a highly customisable camera calibration using calibration tools from the ViSP library avalaible from ", ". ", "The image feed used for calibration is a set of clearly distinguishible points. The planar disposition of the points is of no importance. ", "This package uses ViSP's camera model described in ", " and camera calibration capabilities described in ", ". The output camera parameters are given in the ", " format. ", "visp_camera_calibration will work with any camera driver node satisfying the standard ROS camera interface. See the ", ". "], "package_tt": ["image", "point_correspondence", "gray_level_precision", "double", "size_precision", "double", "pause_at_each_frame", "bool", "model_points_x", "array", "model_points_y", "array", "model_points_z", "array", "selected_points_x", "array", "selected_points_y", "array", "selected_points_z", "array", "calibration_path", "string", "point_correspondence", "point_correspondence", "set_camera_info", "image", "calibrate"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-visp-camera_calibration", "sudo apt-get install ros-$ROS_DISTRO-vision-visp", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/spur", "package": "spur", "package_summary": ["Meta package for SPUR omni-directional mobile manipulator robot made at Tamagawa University."], "package_details": ["Document is available in ", ". "]},
{"url": "https://wiki.ros.org/multirobot_map_merge", "package": "multirobot_map_merge", "package_summary": ["Merging multiple maps without knowledge of initial\n  positions of robots."], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " ", " does not depend on any particular communication between robots. ", "\n", " finds robot maps dynamically and new robots can be added to system at any time. ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides global map for multiple robots. It can merge maps from arbitrary number of robots. It expects maps from individual robots as ROS topics. If your run multiple robots under the same ROS master then ", " will probably work for you out-of-the-box. It is also very easy to setup an simulation experiment. ", "To make this dynamic behaviour possible there are some constrains placed on robots. First all robots must publish map under ", ", where topic name (", ") is configurable, but must be same for all robots. For each robot ", " will be of cause different. ", "Two merging modes are currently supported as orthogonal options. If you know initial positions of robots you may preferably use the first mode and get exact results (rigid transformation will be computed according to initial positions). If you don't know robot's starting points you are still able to use the second mode where transformation between grids will be determined using heuristic algorithm. You can choose between these two modes using the ", " parameter. ", "This is preferred mode whenever you are able to determine exact starting point for each robot. You need to provide initial position for each robot. You need to provide set of ", " parameters. These positions should be in ", ". See ", ". ", "Estimating transforms between grids is cpu-intesive so you might want to tune ", " parameter to run re-estimation less often if it causes any troubles. ", "This package was developed as part of my bachelor thesis at ", " in Prague. ", "Idea for dynamic robot discovery is from ", " package from Zhi Yan. Merging algorithm and configuration are different. "], "package_tt": ["multirobot_map_merge", "multirobot_map_merge", "multirobot_map_merge", "<robot_namespace>/map", "map", "<robot_namespace>", "known_init_poses", "<robot_namespace>/map_merge/init_pose", "world_frame", "estimation_rate", "<robot_namespace>/map", "<robot_namespace>/map_updates", "map", "known_init_poses", "true", "<robot_namespace>/map_merge/init_pose_x", "double", "<no_default>", "x", "world_frame", "<robot_namespace>/map_merge/init_pose_y", "double", "<no_default>", "y", "world_frame", "<robot_namespace>/map_merge/init_pose_z", "double", "<no_default>", "z", "world_frame", "<robot_namespace>/map_merge/init_pose_yaw", "double", "<no_default>", "yaw", "world_frame", "~robot_map_topic", "string", "map", "~robot_map_updates_topic", "string", "map_updates", "robot_map_topic", "robot_map_topic", "~robot_namespace", "string", "<empty\u00a0string>", "robot_map_topic", "robot_namespace", "~known_init_poses", "bool", "true", "true", "~merged_map_topic", "string", "map", "~world_frame", "string", "world", "~merging_rate", "double", "4.0", "~discovery_rate", "double", "0.05", "~estimation_rate", "double", "0.5", "~estimation_confidence", "double", "1.0"], "package_code": ["@masterthesis{H\u00f6rner2016,\n", "  author = {Ji\u0159\u00ed H\u00f6rner},\n", "  title = {Map-merging for multi-robot system},\n", "  address = {Prague},\n", "  year = {2016},\n", "  school = {Charles University in Prague, Faculty of Mathematics and Physics},\n", "  type = {Bachelor's thesis},\n", "  URL = {https://is.cuni.cz/webapps/zzp/detail/174125/},\n", "}"]},
{"url": "https://wiki.ros.org/network_control_tests", "package": "network_control_tests", "package_summary": ["\n    Test suite for the packages that are part of the \"WiFi Test Setup\" project:\n    network_monitor_udp, network_traffic_control, hostapd_access_point, linksys_access_point,\n    ddwrt_access_point.\n  "]},
{"url": "https://wiki.ros.org/turtlebot_interactions", "package": "turtlebot_interactions", "package_summary": ["Catkin meta-package for turtlebot_interactions"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/wifi_drivers", "package": "wifi_drivers", "package_summary": ["\n   This stack contains WiFi drivers\n  "]},
{"url": "https://wiki.ros.org/toposens_driver", "package": "toposens_driver", "package_summary": ["ROS device driver for communication with TS sensors."], "package_details": ["\n", "\n", "\n", "This package functions as a device driver for a Toposens 3D ultrasonic sensor. It can be used to setup a serial connection to the sensor, parse the received data string and publish it as a ", ". ", "Most of the parameters are used by the sensors firmware and are therefore sent to the sensor via the serial port. For a more detailed description of these parameters see ", ".  "], "package_tt": ["ts_scans", "~port", "std_msgs/String", "~frame_id", "std_msgs/String", "~echo_rejection_threshold", "int", "~noise_indicator_threshold", "int", "~num_pulses", "int", "~peak_detection_window", "int", "~external_temperature", "double", "~use_external_temperature", "bool"]},
{"url": "https://wiki.ros.org/tra1_moveit_config", "package": "tra1_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the tra1 with the MoveIt! Motion Planning Framework"], "package_details": ["\n", " ", " ", "To try ", "! with this package, type below command: ", "You can see the ", " rviz screen and make it move with GUI. "], "package_code": ["$ roslaunch tra1_moveit_config demo.launch"]},
{"url": "https://wiki.ros.org/wire_msgs", "package": "wire_msgs", "package_summary": ["wire_msgs"], "package_details": ["\n", " contains all message types used in the ", " stack. ", "Newly proposed, mistyped, or obsolete package. Could not find package \"wire_msgs\" in rosdoc: /home/rosbot/docs/api/wire_msgs/manifest.yaml "], "package_tt": ["wire_msgs"]},
{"url": "https://wiki.ros.org/roswiki_node", "package": "roswiki_node", "package_summary": ["Creates CS/NodeAPI clearsilver documentation from source code files. Typical usage: rosrun roswiki_node roswiki src/*"], "package_details": ["\n", "\n", "\n", "\n", "Using the source code of your packages, this package applies a set of regular expressions and parses out the basic node information, particularly the type of information used by the ", " template, (", ").  ", "Are you a regular expression whiz? Tickets and patches are welcome for adding new patterns. ", " or contact ", " "], "package_code": ["rosrun roswiki_node roswiki [source code files]"]},
{"url": "https://wiki.ros.org/turtlebot_apps", "package": "turtlebot_apps", "package_summary": ["turtlebot_apps is a group of simple demos and exmaples to run on your TurtleBot to help you get started with ROS and TurtleBot."], "package_details": ["\n", "This stack is a supporting stack for the ", " providing example applications.   "]},
{"url": "https://wiki.ros.org/pr2_navigation_perception", "package": "pr2_navigation_perception", "package_summary": ["This package holds navigation-specific sensor configuration options and launch files for the PR2."], "package_details": ["\n", "\n", "\n"], "package_tt": ["lasers_and_filters.xml", "ground_plane.xml", "config/base_self_filter.yaml", "config/point_cloud_footprint_filter.yaml", "config/tilt_self_filter.yaml", "config/tilt_laser_filters.yaml", "config/shadow_filter.yaml"]},
{"url": "https://wiki.ros.org/rosh_desktop", "package": "rosh_desktop", "package_summary": ["\n\n     ROSH meta-plugin for the ROS 'desktop' variant.\n\n  "], "package_details": ["\n", "rosh_desktop is a meta-plugin that makes it easy to automatically load all desktop-related ", " plugins.  See the ", " documentation on how to automatically load rosh_desktop when you start rosh. ", "Please see the ", " documentation to find out more about rosh. "]},
{"url": "https://wiki.ros.org/rail_recognition", "package": "rail_recognition", "package_summary": ["Construction and Use of a Recognition Database for Grasping Purposes"], "package_details": ["\n", "\n", "\n", "\n", "   ", "\n", "\n", "\n", "\n", " ", "The ", " package contains nodes for object recognition and demonstration grasp selection using models from a grasp database, handled by ", ".  The package also contains a node used for generating object models from grasp demonstrations collected with the ", " package.  The recognizer has support for a 2D image recognizer to run first in the full recognition pipeline, significantly increasing the runtime of the point cloud recognizer by limiting the number of candidate classes to test with point cloud registration.  This package also contains nodes for data collection, training, and testing of the 2D recognizer. ", "The full recognition pipeline takes in a list of unrecognized segmented objects, such as what the ", " package provides.  Each unrecognized object will first be classified by the 2D image classifier to determine a set of candidate object classes of high probability.  These candidate classes will then be retrieved from the object model database, handled by ", ", which are then used by the point cloud recognizer to provide a final object label and set of example grasps for picking up the now-recognized object. ", "The 2D image recognizer can be trained in a few steps.  First, an image set representative of the objects in the environment must be collected.  This can be accomplished by running a segmentation node, such as the one found in ", ", and the collect_images node as follows: ", "See the tutorials section of ", " for details on how to set up an object model database, provide grasp demonstrations, train new object models, and refine existing object models. ", "To install the ", " package, you can install from source with the following commands: ", "The ", " package contains a launch file for launching the object_recognition_listener node with the various database, segmentation, and recognition parameters set, executed with: ", "Model generation can be run with an rviz plugin for visualization found in ", ". "], "package_tt": ["rail_recognition", "model_generator/generate_models", "model_generator/generate_models", "model_generator/debug_pc", "model_generator/debug_poses", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "debug", "bool", "rail_recognition/recognize_object/goal", "rail_recognition/recognize_object/result", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "rail_recognition/recognize", "rail_recognition/recognize_all", "rail_recognition/recognize", "rail_recognition/recognize_all", "object_topic\u00a0param", "object_recognition_listener/recognized_objects", "object_recognition_listener/debug", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "object_topic", "string", "debug", "bool", "use_image_recognition", "bool", "rail_grasp_model_retriever/retrieve_grasp_model/goal", "rail_grasp_model_retriever/retrieve_grasp_model/result", "rail_grasp_model_retriever/point_cloud", "rail_grasp_model_retriever/poses", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "metric_trainer/train_metrics/goal", "metric_trainer/train_metrics/result", "metric_trainer/get_yes_no_feedback", "metric_trainer/base_pc", "metric_trainer/aligned_pc", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "rail_segmentation/segmented_objects", "collect_images/saved_data_dir", "string", "collect_images/images_dir", "string", "collect_images/test_images_dir", "string", "collect_images/new_images_dir", "string", "collect_images/save_new_images", "bool", "collect_images/segmented_objects_topic", "string", "rail_segmentation/segmented_objects", "save_image_recognizer_features/saved_data_dir", "string", "save_image_recognizer_features/images_dir", "string", "save_image_recognizer_features/test_images_dir", "string", "save_image_recognizer_features/new_images_dir", "string", "save_image_recognizer_features/save_new_images", "bool", "save_image_recognizer_features/segmented_objects_topic", "string", "rail_segmentation/segmented_objects", "train_image_recognizer/saved_data_dir", "string", "train_image_recognizer/images_dir", "string", "train_image_recognizer/test_images_dir", "string", "train_image_recognizer/new_images_dir", "string", "train_image_recognizer/save_new_images", "bool", "train_image_recognizer/segmented_objects_topic", "string", "rail_segmentation/segmented_objects", "test_image_recognizer/saved_data_dir", "string", "test_image_recognizer/images_dir", "string", "test_image_recognizer/test_images_dir", "string", "test_image_recognizer/new_images_dir", "string", "test_image_recognizer/save_new_images", "bool", "test_image_recognizer/segmented_objects_topic", "string", "rail_pick_and_place", "rail_recognition"], "package_code": ["roslaunch rail_recognition collect_images.launch", "rosrun rail_recognition save_image_recognizer_features", "rosrun rail_recognition train_image_recognizer", "rosrun rail_recognition test_image_recognizer", "\n", "\n", "\n", "\n", "\n", "roslaunch rail_recognition object_recognition_listener.launch", "roslaunch rail_recognition collect_images.launch", "roslaunch rail_recognition metric_trainer.launch", "roslaunch rail_recognition model_generator.launch", "roslaunch object_recognizer.launch", "roslaunch rail_recognition rail_grasp_model_retriever.launch", "rosrun rail_recognition save_image_recognizer_features\n", "rosrun rail_recognition train_image_recognizer\n", "rosrun rail_recognition test_image_recognizer"]},
{"url": "https://wiki.ros.org/swarm_behaviors", "package": "swarm_behaviors", "package_summary": ["The swarm behaviors library contains implementations of swarm algorithms. It is part of the swarm library."], "package_details": ["\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "The swarm behaviors library contains implementations of swarm algorithms. It is part of the ", ". ", "This work is supported by the European Commission through the ", " under grant no. 731946. "]},
{"url": "https://wiki.ros.org/summit_xl_pad", "package": "summit_xl_pad", "package_summary": ["The summit_xl_pad package allows to control the summit_xl product range (summit_xl, summit_xl_omni, x_wam) teleoperation"], "package_details": ["\n", "This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux (", ") so that the final command to the robot can be set by different components (move_base, etc.) "]},
{"url": "https://wiki.ros.org/topological_tools", "package": "topological_tools", "package_summary": ["The topological_tools package contains utilities to ease the deployment\n               of the MDM Library in topological navigation problems."]},
{"url": "https://wiki.ros.org/turtlebot_description", "package": "turtlebot_description", "package_summary": ["turtlebot_description provides a complete 3D model of the TurtleBot for simulation and visualization. The files in this package are parsed and used by a variety of other components. Most users will not interact directly with this package."], "package_details": ["\n", " ", "This package contains robot description files for ", ", organized into subdirectories as follows: "], "package_tt": ["urdf/", "meshes/", ".stl", ".dae", ".3ds"]},
{"url": "https://wiki.ros.org/asr_ivt", "package": "asr_ivt", "package_summary": ["Ros wrapper for the Integrated Vision Toolkit (IVT) library (version 1.3.22)"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "This package contains a ROS-wrapper for the ", " library (version 1.3.22). "]},
{"url": "https://wiki.ros.org/visualization_osg", "package": "visualization_osg", "package_summary": ["visualization_osg is a metapackage providing support for visualization of geometry using the OpenSceneGraph rendering engine."], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/web_interface", "package": "web_interface", "package_summary": ["The web_interface package"], "package_details": ["\n", "\n", "  (where ", " is the name of computer 1 on your robot) ", "\n", "\n", " ", "If you want to install the web interface on a new computer or non-PR2 robot, there are experimental instructions on the ", " page. "], "package_tt": ["http://c1:9090", "c1"]},
{"url": "https://wiki.ros.org/teraranger_array_converter", "package": "teraranger_array_converter", "package_summary": ["Package that handle conversion from RangeArray messsages"], "package_details": [" ", "\n", ": This package depends on URDF description of the sensor setup. Please use the ", " package for this disponible here: ", " ", "\n", "\n", "\n", " "], "package_tt": ["/ranges", "/scan", "/point_cloud", "/ranges", "converter_mode", "string", "sensor_mask", "bool[]"], "package_code": ["rosrun teraranger_array_converter teraranger_array_converter _converter_mode:=<laser_scan>|<point_cloud>|<individual_ranges>|<sequential_ranges>"]},
{"url": "https://wiki.ros.org/asr_flir_ptu_controller", "package": "asr_flir_ptu_controller", "package_summary": ["asr_flir_ptu_controller is a package to control a flir ptu unit from a action server"], "package_details": [" ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", "\n", " ", " ", " ", "\n", " ", " ", " ", " ", " ", " ", "\n", " ", "\n", "\n", "The asr_flir_ptu_controller is closely connected to the ", " as it grants access to the PTU just as the mentioned package. The difference between both packages is that asr_flir_ptu_controller uses ", " to make the PTU accessible for actionservers by offering an action client that takes new position commands for the pan and tilt values of the pan and executes them with the help of ", ". The package supports the taking of new position goals, constant feedback of the movement and a check if the movement ended successfully. Not fulfillabe goals get filtered out from the beginning - they get rejected. ", "The asr_flir_ptu_controller serves a single purpose: It makes the movement of a Flir pan-tilt-unit accessable by a ", ". The functionality by asr_flir_ptu_controller will be shown below in a sequence diagram. For knowledge of the invoked functions check out ", ". ", "Basic knowledge of the PTU movement (e.g. orientation of axis, movement area, etc.) can be obtained from the documentation of asr_flir_ptu_driver. A lot of functionalities, especially the configuration of forbidden areas, are only available in the asr_flir_ptu_driver and cannot be accessed from here. asr_flir_ptu_controller extends the basic functionalities of movement and forbidden area checking by wrapping them them inside an Action offered by an ActionServer, making invocations easy and offering the opportunity to use the ActionServer in context of a more complex control logic. However, the controller restricts the opportunities of the asr_flir_ptu_driver somehow as it forces the check for forbidden areas and does not allow path_prediction. ", "Being mounted upon the ", " it is necessary that you have a running instance of asr_flir_ptu_driver, so start it ", ". ", "After starting the asr_flir_ptu_driver, start the asr_flir_ptu_controller. Interaction is then done over the ", " launched by asr_flir_ptu_controller. ", "As the ", " has no simulation mode itself, launching it real is the only option you have. Little to no configuration needs to be done before launch if you did not change the topic names used by asr_flir_ptu_driver. Otherwise you need to adjust the corrsponding topic names found in the ptu_controller_settings.yaml file in the param folder. Most of the values there should be fine, nevertheless two should be reconsidered: ", " and ", "The first one describes the maximum amount of steps that will be done before a movement is considered a failure. A step means hereby a spin of ROS (to be totally fair, it means a publishing from the asr_flir_ptu_driver about his current position, what happens each spin). The second one describes the margin parameter known from asr_flir_ptu_driver. You can set this parameter freely, it is limited by the minimum of the width/height of the pan/tilt movement area divided by 2. ", "From that point on you can use the ActionServer offered by asr_flir_ptu_controller. ", "All topics below are subscribed by the ActionServer of asr_flir_ptu_controller by default. They use a custom defined message which can be found inside the action folder of the package. ", "All published topics by the asr_flir_ptu_controller are related to the ActionServer and should not be invoked from the command line. Use an ActionClient or some tool design for interacting with ActionServers. Most of them are based on a custom ActionServer message that can be found inside the action folder of the package. ", "Nevertheless there exists a very long code example on how to use the Goal/....-callbacks offered by the asr_flir_ptu_controller. Move to the src folder of the package and have a look at the PTUControllerClient.cpp. It is a piece of code that was used to test the behaviour of the ActionServer provided during development and remained here as an example for the usage. Be aware that some of the expected reactions of this program depend on the configuration of the ", " and the PTU you are using - executing it without adapting it to your data is not recommended. Just use it as an example for usage. ", "If you do not know how to use a ActionServer check out the ", ". "]},
{"url": "https://wiki.ros.org/scan_tools", "package": "scan_tools", "package_summary": ["Laser scan processing tools."], "package_details": ["\n", "\n", " ", "\n", "This stack contains tools for manipulating ", " and ", " messages. ", "See ", " on the development repository. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "]},
{"url": "https://wiki.ros.org/cpp_common", "package": "cpp_common", "package_summary": ["cpp_common contains C++ code for doing things that are not necessarily ROS\n    related, but are useful for multiple packages. This includes things like\n    the ROS_DEPRECATED and ROS_FORCE_INLINE macros, as well as code for getting\n    backtraces.\n\n    This package is a component of ", "."], "package_details": [" "]},
{"url": "https://wiki.ros.org/rostest", "package": "rostest", "package_summary": ["Integration test suite based on roslaunch that is compatible with xUnit frameworks."], "package_details": ["\n", "rostest is an extension to ", " that enables ", " files to be used as test fixtures. As a fully running system has more complex behaviors than an individual ROS ", ", this allows you to do full integration testing across multiple nodes.  "], "package_tt": ["roslaunch"]},
{"url": "https://wiki.ros.org/sr_gui_muscle_driver_bootloader", "package": "sr_gui_muscle_driver_bootloader", "package_summary": ["A GUI plugin for bootloading the muscle drivers on the etherCAT muscle shadow hand."], "package_details": [" ", "This is similar to ", " but is used for the version of the hand that employs air pressure actuated muscles instead of electric motors. Select one or more muscle driver(s) and a hex file and the click Bootload Motors. "]},
{"url": "https://wiki.ros.org/teb_local_planner_tutorials", "package": "teb_local_planner_tutorials", "package_summary": ["The teb_local_planner_tutorials package"], "package_details": ["\n", "\n", "This package contains supplementary material and examples for the ", " package.  ", "Refer to the ", " wiki page for more information and the ", " section. "], "package_code": ["cd ~/catkin-ws/src\n", "git clone https://github.com/rst-tu-dortmund/teb_local_planner_tutorials.git\n", "# install dependencies, e.g.\n", "sudo apt-get install ros-$ROS_DISTRO-stage-ros", "sudo apt-get install ros-$ROS_DISTRO-teb-local-planner-tutorials"]},
{"url": "https://wiki.ros.org/tf2_ros", "package": "tf2_ros", "package_summary": ["This package contains the ROS bindings for the tf2 library, for both Python and C++."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " is designed both as a command-line tool for manual use, as well as for use within ", " files for setting static transforms. For example: ", " ", "Please refer to the ", " or ", " ", "Please refer to the ", " or ", " ", "For most purposes using tf2_ros will be done using ", ". It's main public API is defined by ", ". Typically it will be populated using a ", " which subscribes to the appropriate topics.  ", "Please refer to the ", " or ", " ", "Please refer to the ", " or ", " ", "For more information see ", " or ", " "], "package_tt": ["tf2_ros::TransformBroadcaster()", "tf2_ros::TransformBroadcaster::sendTransform", "tf2_ros::StaticTransformBroadcaster()", "tf2_ros::StaticTransformBroadcaster::sendTransform", "tf2_ros::Buffer", "tf2_ros::BufferInterface", "tf2_ros::TransformListener", "tf2_ros::Buffer::transform", "canTransform", "lookupTransform", "getFrames", "tf2_ros::MessageFilter()", "connectInput()", "setTargetFrame()", "setTargetFrames()", "setTolerance()", "clear", "setQueueSize()", "tf2::ConnectivityException", "tf2::LookupException", "tf2::ExtrapolationException", "tf2::InvalidArgumentException", "tf2::TimeoutException", "tf2::TransformException", "static_transform_publisher\u00a0x\u00a0y\u00a0z\u00a0yaw\u00a0pitch\u00a0roll\u00a0frame_id\u00a0child_frame_id", "static_transform_publisher\u00a0x\u00a0y\u00a0z\u00a0qx\u00a0qy\u00a0qz\u00a0qw\u00a0frame_id\u00a0child_frame_id", "static_transform_publisher"], "package_code": ["\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/sr_tactile_sensors", "package": "sr_tactile_sensors", "package_summary": ["\n\n    An interface to the tactile sensors used in the Shadow Dextrous Hand. Also Contains a virtual set of sensors.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "To ensure the same versatile use as the ", " package, the sr_tactile_sensors come in three flavours: dummy sensors, simulated sensors and real sensors.  ", "There's a good example on how to use the data coming from the tactile sensors in the ", " ", "When you start the interface, two topics per sensors will be published (10 topics in all). Each sensor publishes a pressure value. Each of the topic is publishing a ", "/float64 value. ", "By default, when you run ", ", the tactiles are compiled as a set of dummy sensors.  ", "To compile the interface to the real tactile sensors, run: ", ".  ", "If you want to compile the Gazebo tactile sensors: ", ". "]},
{"url": "https://wiki.ros.org/staubli_rx160_support", "package": "staubli_rx160_support", "package_summary": ["\n      ROS-Industrial support for the Staubli RX160 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for Staubli RX160 manipulators. This includes the base model and the\n      RX160L.\n    ", ":", "\n      Joint limits, torque limits, and maximum joint velocities are based on the\n      information in the ", " version ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise (ie: no support for high speed joints, extended /\n      limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      ", ": Masses, center of mass and moments of inertia were calculated\n      using Solidworks and the official Staubli CAD models, and may not be\n      accurate.\n    ", "\n      ", ": In order to allow maximum torque on axis 6, effort limit on\n      axis 5 was set to 29 Nm, rather than a feasible 58 Nm if torque on\n      axis 6 = 0 Nm (see superscripts (1) and (2) from table in Section 2.6.2\n      -Torque Limits- of the instruction manual for details).\n    ", ":", "\n      This support package has received contributions from: S. van Elderen\n      (RX160) and Murilo Martins (Ocado Technology) (RX160/RX160L).\n    "]},
{"url": "https://wiki.ros.org/osg_utils", "package": "osg_utils", "package_summary": ["osg_utils is a library that contains some classes that may be useful in ROS-OSG applications."]},
{"url": "https://wiki.ros.org/win_pyyaml", "package": "win_pyyaml", "package_summary": ["\n\nBuild script for python yaml parser.\n\n  "]},
{"url": "https://wiki.ros.org/plot_tools", "package": "plot_tools", "package_summary": ["plot_tools"]},
{"url": "https://wiki.ros.org/jsk_hark_msgs", "package": "jsk_hark_msgs", "package_summary": ["jsk_hark_msgs"]},
{"url": "https://wiki.ros.org/stdr_resources", "package": "stdr_resources", "package_summary": ["Provides robot and sensor descripiton files for STDR Simulator."], "package_details": ["\n", " package is the container for the resources needed by ", " to operate. The resources are divided in two main groups: ", " and ", ". ", "\n", "\n", "In the maps section six indicative maps are provided. Note that each ", " is actually a pair of files: ", "In this section the files under the ", " folder are described. These are Yaml or XML files that describe robots and sensors. The available folders, each holding some sample resource files, are: ", "For more information about the use of resource files please visit ", " or the following tutorial : ", "  "]},
{"url": "https://wiki.ros.org/pr2_surrogate", "package": "pr2_surrogate", "package_summary": ["\n    The pr2_surrogate package allows you to use a PR2\n    as a surrogate for your physical body using the Oculus RIFT\n    virtual reality headset and the Razer Hydra controller."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The button assignment is similar to one used for the PS3 joystick in ", ". "], "package_tt": ["ntpdate", "robot\u00a0start", "roslaunch\u00a0pr2_surrogate\u00a0robot.launch", "roslaunch\u00a0pr2_surrogate\u00a0desktop.launch"]},
{"url": "https://wiki.ros.org/stepback_and_steerturn_recovery", "package": "stepback_and_steerturn_recovery", "package_summary": ["This package provides a recovery behavior for the navigation stack which\n        steps back and proceed with a specified steer angle"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", " (", ", default: false) ", "\n", "\n", "The ", " is designed for a robot with a car-like steering mechanism. It adheres to the ", " interface found in the ", " package and can be used as a recovery behavior ", " for the ", " node. ", "The C++ ", " class adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". "], "package_tt": ["stepback_and_steerturn_recovery::StepbackAndSteerturnRecovery", "nav_core::RecoveryBehavior", "recover_run", "~<name>/only_single_steering", "bool", "~<name>/trial_times", "int", "~<name>/obstacle_patience", "double", "~<name>/obstacle_check_frequency", "double", "~<name>/sim_angle_resolution", "double", "~<name>/simulation_frequency", "int", "~<name>/linear_vel_back", "double", "~<name>/step_back_length", "double", "~<name>/step_back_timeout", "double", "~<name>/linear_vel_steer", "double", "~<name>/angular_speed_steer", "double", "~<name>/steering_timeout", "double", "~<name>/linear_vel_forward", "double", "~<name>/step_forward_timeout", "double", "rotate_recovery::RotateRecovery", "nav_core::RecoveryBehavior"]},
{"url": "https://wiki.ros.org/world_canvas_utils", "package": "world_canvas_utils", "package_summary": ["C++/Python utilities library for the world canvas framework."]},
{"url": "https://wiki.ros.org/laser_ortho_projector", "package": "laser_ortho_projector", "package_summary": ["The laser_ortho_projector package calculates orthogonal projections of LaserScan messages."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "The package is intended as an intermediary step to transform laser data, before passing it to another node that performs scan-matching (for example, ", " or ", "). It works under the assumption that the environment is rectilinear in the z-dimension, meaning that obstacles look the same, regardless of the height where they are observed. This assumption typically holds for indoor spaces. ", "We also calculate a transformation between the world frame and a orthogonally-projected base frame of the robot (labeled ", " in the figure above), and publish it as a ", " transform. ", "Note that projecting the scan from an arbitrary roll and pitch results in points that are no longer equal angles apart. Thus, we pubish the projected scan as a ", ". The point cloud is published in the base_ortho frame of reference. ", "You can run the ", " on a pre-recorded bag file that comes with the package. First, make sure you have the ", " stack downloaded and installed by following the instructions ", ". ", "You should see the input laser scan and the orthogonally projected scan displayed in ", ", similar to the video below: ", "Two drivers are available: ", " and ", ". Their parameters and topics are identical. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["/base_ortho", "laser_ortho_projector_node", "laser_ortho_projector_nodelet", "laser_ortho_projector_node", "scan", "imu", "base_link", "base_link", "tf", "~cloud_ortho", "base_ortho", "base_link", "~fixed_frame", "string", "\"/world\"", "~base_frame", "string", "\"base_link\"", "~publish_tf", "bool", "false", "fixed_frame", "base_ortho", "tf", "~use_imu", "bool", "true", "base_link", "false", "base_link", "tf", "base_link", "laser", "world", "base_link", "world", "base_ortho"], "package_code": ["\n", "\n"]},
{"url": "https://wiki.ros.org/octomap_rviz_plugins", "package": "octomap_rviz_plugins", "package_summary": ["A set of plugins for displaying occupancy information decoded from binary octomap messages."]},
{"url": "https://wiki.ros.org/katana_description", "package": "katana_description", "package_summary": ["This package contains an URDF description of the Katana arm and all supporting mesh files."], "package_details": [" "]},
{"url": "https://wiki.ros.org/win_empy", "package": "win_empy", "package_summary": ["\n\nBuild script for python expressions module.\n\n  "]},
{"url": "https://wiki.ros.org/katana_teleop", "package": "katana_teleop", "package_summary": ["This package provides tele-operation nodes to control the Neuronics Katana 450 arm via keyboard commands or with a playstation 3 controller."], "package_details": ["\n", "\n", "\n", " ", "This package provides the ", " ROS node, which provides a keyboard-based teleoperation for the Neuronics Katana 450 arm. "], "package_tt": ["katana_teleop_key", "joint_states", "increment", "double", "increment_stepsize", "double", "increment_step_scaling", "double"]},
{"url": "https://wiki.ros.org/wheeled_robin", "package": "wheeled_robin", "package_summary": ["The wheeled_robin stack provides all the basic drivers for running and using a WheeledRobin robot."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "Please refer main ", " page. "]},
{"url": "https://wiki.ros.org/twist_mux", "package": "twist_mux", "package_summary": ["Twist multiplexer, which multiplex several velocity commands (topics) and allows to priorize or disable them (locks)."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "When there are more than a single source to move a robot with a ", " message, it is important to multiplex all those input sources into a single one that goes to the controller (e.g. ", "). ", "This package provides a node that subscribes to a list of topics publishing ", " messages and multiplexes them using a priority-based scheme. It also supports timeouts for each input and locking by means of topics that publish ", " messages. ", "The main node of this package is ", ", which provides a multiplexer for ", " messages. It takes N input twist topics and outputs the messages from a single one. For selecting the topic they are prioritized based on their priority, the messages timeout and M input lock topics that can inhibit one input twist topic. This is illustrated in the diagram below. ", "In the ", " folder there are example yaml files with configuration parameters. ", "The ", " subscribes to the N input twist topics and M input lock topics specified in the parameters ", " and ", " described below. ", "The ", " parameter contains a list of structs with the following fields that specify each input twist topics: ", "Example configuration to multiplex the autonomous navigation from ", ", a joystick from ", ", a keyboard from ", " and a tablet: ", "The ", " parameter contains a list of structs with the following fields that specify each input lock topics: ", "The next plot shows one input twist topic vs. the output one. The delay is usually 0, and always ", ". ", " ", "In order to make it easier to use a joystick input from ", " with ", ", the package comes with a joystick relay. See ", ". "], "package_tt": ["twist_mux", "twist_mux", "topics", "locks", "timeout\u00a0==\u00a00.0", "timeout\u00a0==\u00a00.0", "0", "255", "<\u00a01ms"], "package_code": ["roslaunch twist_mux twist_mux.launch", "topics:\n", "-\n", "  name    : navigation\n", "  topic   : nav_vel\n", "  timeout : 0.5\n", "  priority: 10\n", "-\n", "  name    : joystick\n", "  topic   : joy_vel\n", "  timeout : 0.5\n", "  priority: 100\n", "-\n", "  name    : keyboard\n", "  topic   : key_vel\n", "  timeout : 0.5\n", "  priority: 90\n", "-\n", "  name    : tablet\n", "  topic   : tab_vel\n", "  timeout : 0.5\n", "  priority: 100", "locks:\n", "-\n", "  name    : pause\n", "  topic   : pause_navigation\n", "  timeout : 0.0\n", "  # Same priority as joystick control, so it'll not block it.\n", "  priority: 100\n", "-\n", "  name    : joystick \n", "  topic   : joy_priority\n", "  timeout : 0.0\n", "  priority: 100"]},
{"url": "https://wiki.ros.org/libcreate", "package": "libcreate", "package_summary": ["C++ library for interfacing with iRobot's Create 1 and Create 2"], "package_details": ["\n", " is a C++ library for interfacing with iRobot Create and Roomba platforms. For ROS bindings, see ", ". ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n "]},
{"url": "https://wiki.ros.org/uos_rotunit", "package": "uos_rotunit", "package_summary": ["A driver for the uos-rotunit."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/manipulation_msgs", "package": "manipulation_msgs", "package_summary": ["The manipulation_msgs package"], "package_details": [" This package is ", ". You probably want to use ", " where some have been moved to. See also ", ". "]},
{"url": "https://wiki.ros.org/swiftnav", "package": "swiftnav", "package_summary": ["ROS release of swiftnav library"], "package_details": ["\n", "\n", "This package is a ROS release of ", "'s libswiftnav. It offers a variety of functionality related to linear algebra and spacial processing. ", "All libswiftnav releases are here: ", " ", "Note that because libswiftnav is a plain CMake project and not a ", " one, you can't use it in a regular catkin workspace\u2014 you must build and install using ", ", and then overlay the resulting workspace with a regular catkin one. "], "package_tt": ["catkin_make_isolated"]},
{"url": "https://wiki.ros.org/rosrt", "package": "rosrt", "package_summary": ["rosrt provides classes for interfacing with ROS from within realtime systems, such as realtime-safe Publisher and Subscriber classes."], "package_details": ["\n", "\n", " starts three threads, one for publishing, one for subscribing and one for garbage collection.  The publisher thread uses a lock-free multi-writer single-reader queue with a fixed limit on the # of messages specified by ", ". ", "\n", "\n", " will never return the same message twice.  This means: ", "\n", "rosrt is a package that contains realtime-safe tools for interacting with ROS.  It is currently ", " and ", ", so use at your own risk. ", "Used together with a Xenomai Kernel the ROS processes get guaranteed CPU time and are not affected by other processes. ", "rosrt can also slightly improve performance by avoiding memory allocations by preallocating. Those speed-ups should probably be helpful even if not running a real time system if small margins are important. ", "There is an optional ", " argument to ", ". ", "See also: ", " ", "Using the ", " is very similar to the standard ", " but with some realtime-specific requirements.  First, it provides you with a fixed-size buffer of messages (10 in the example below).  To be realtime safe you must allocate your messages out of this ", " you're publishing it with.  Second, you must initialize each of those messages with a template message when you initialize the ", ".  Anything that needs to be preallocated should be preallocated in this template. ", "Deallocation of the ", "'s pool of memory is done by a separate garbage collection thread, and will not happen until all messages allocated out of the ", " have been freed (or on program exit). ", "See also: ", " ", "Using the ", " is a bit different from the standard ", ", mainly because it's polling based instead of callback based: ", "As with the ", ", you must specify a message pool size.  If you are not going to be storing off received messages the optimal size for this is 3 (1 for the ROS-side subscription queue, 1 waiting in the Subscriber, 1 in use by realtime). ", "Deallocation of the ", "'s pool of memory is done by a separate garbage collection thread, and will not happen until all messages allocated out of the ", " have been freed (or on program exit). ", "rosrt also provides a way of tracking allocations and frees per thread.  See the ", ", ", ", ", " functions in ", ", as well as the ", ". "], "package_tt": ["rosrt::init()", "rosrt::init()", "InitOptions::pubmanager_queue_size", "rosrt::Publisher", "ros::Publisher", "rosrt::Publisher", "rosrt::Publisher", "Publisher", "Publisher", "rosrt::Subscriber", "ros::Subscriber", "rosrt::Publisher", "poll()", "Subscriber", "Subscriber", "getThreadAllocInfo()", "resetThreadAllocInfo()", "setThreadBreakOnAllocOrFree()"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "<message received>\n", "sub.poll()  <---  returns a message\n", "sub.poll()  <---  returns NULL\n", "<message received>\n", "sub.poll()  <---  returns a message\n", "..."]},
{"url": "https://wiki.ros.org/laser_joint_projector", "package": "laser_joint_projector", "package_summary": ["Projects laser readings into a point cloud, based on a set of recorded joint angles\n     This package is experimental and unstable.\n     Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/summit_xl_localization", "package": "summit_xl_localization", "package_summary": ["The summit_xl_localization package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/schunk_powercube_chain", "package": "schunk_powercube_chain", "package_summary": ["This packages provides a configurable driver of a chain\n  of Schunk powercubes. The powercube chain is configured\n  through parameters. Most users will not directly interact\n  with this package but with the corresponding launch files\n  in other packages, e.g. schunk_bringup, cob_bringup, ..."], "package_details": ["\n", "\n", "\n", "\n", "To use this package you need one or more powercubes ", ". Alternatively you can use a simulated version without any hardware, see ", ". ", "The installation is tested for Ubuntu 14.04 using ROS ", ". If you discover problems installing them on other platforms, please ", ". ", "The ", " package provides a configurable node for operating a chain of powercube modules. ", "\n", "This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g. ", " in the ", " stack. ", "For starting only the lwa use ", "All hardware configuration is done in the ", " package. A sample parameter file in \"schunk_hardware_config/lwa/config/lwa.yaml\" could look like this "], "package_tt": ["schunk_powercube_chain", "joint_group_velocity_controller/command", "joint_group_position_controller/command", "/joint_states", "joint_trajectory_controller/state", "driver/current_operationmode", "/diagnostics", "driver/init", "driver/stop", "driver/recover", "driver/set_operation_mode", "can_module", "string", "can_device", "string", "can_baudrate", "int", "module_ids", "list\u00a0of\u00a0ints", "force_use_movevel", "bool", "joint_names", "list\u00a0of\u00a0strings", "max_accelerations", "list\u00a0of\u00a0doubles", "horizon", "double", "frequency", "double", "min_publish_duration", "double", "/robot_description", "urdf\u00a0model"], "package_code": ["roslaunch schunk_bringup lwa_solo.launch", "<include file=\"$(find schunk_bringup)/components/lwa.launch\" />", "can_module: PCAN\n", "can_device: /dev/pcan1\n", "can_baudrate: 1000\n", "modul_ids: [1,2,3,4,5,6,7]\n", "joint_names: [arm_1_joint, arm_2_joint, arm_3_joint, arm_4_joint, arm_5_joint, arm_6_joint, arm_7_joint]\n", "max_accelerations: [0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n", "frequency: 68\n", "OperationMode: position\n", "ptp_vel: 0.4 # rad/sec\n", "ptp_acc: 0.1 # rad/sec^2\n", "max_error: 0.2 # rad"]},
{"url": "https://wiki.ros.org/tuw_checkerboard", "package": "tuw_checkerboard", "package_summary": ["The tuw_checkerboard package is designed to detect one \n    checkerboard and to estimate the pose of the checkerboard relative to the camera.\n    The detection itself is based on the opencv functions for checkerboards."], "package_details": ["\n", "\n", "\n", " ", "This package detects one checkerboard in camera images and computes the 3D pose. The current 3D pose estimation is based on the OpenCV ", " function. Various Parameter and algorithm used to detect the checkerboard can be tuned via ROS shared parameters or by using the dynamic reconfigure interface. ", "This package allows you to publish the checkerboard pose as tf, marker msg, or pose. "], "package_code": ["rosrun tuw_checkerboard tuw_checkerboard_node image:=/camera/image_raw camera_info:=/camera/camera_info", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/pr2_common", "package": "pr2_common", "package_summary": ["URDF description of the robot kinematics and dynamics, 3D models of robot components, information required for gazebo to simulate the PR2, and messages specific to the PR2 such as detailed information about its power board and fingertip pressure sensors."], "package_details": ["\n", "\n", "\n", "  ", "This stack is not intended for user consumption. Check the ", " documentation for how to interpret this data, or  look at the examples in ", " "]},
{"url": "https://wiki.ros.org/kobuki_gazebo_plugins", "package": "kobuki_gazebo_plugins", "package_summary": ["Kobuki-specific ROS plugins for Gazebo"], "package_details": [" ", "\n", "\n", "\n", "\n", "The plugin is configured throught the parameters given in the URDF description. See the ", " for details. ", "Have a look at the ", " package to find out how to use this plugin. "]},
{"url": "https://wiki.ros.org/staubli_rx160_moveit_plugins", "package": "staubli_rx160_moveit_plugins", "package_summary": ["\n      MoveIt plugins for the Staubli RX160 (and variants).\n    ", "\n      This package contains plugins for use with MoveIt and Staubli RX160\n      manipulators. Plugins included support the base model. See the Staubli\n      RX160 support package for information on used joint angle and velocity\n      limits.\n    ", "\n      Before using any of the plugins included in this package, be sure to \n      check they are correct for the particular robot model and configuration \n      you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " metapackage page. "]},
{"url": "https://wiki.ros.org/can_msgs", "package": "can_msgs", "package_summary": ["CAN related message types."]},
{"url": "https://wiki.ros.org/asr_gazebo_models", "package": "asr_gazebo_models", "package_summary": ["This package provides our gazebo_models"], "package_details": [" ", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", " ", " ", "To use these models with gazebo, copy the according folder to \"~/.gazebo/models\" following ", ". ", "One need ", " to use the models. ", "To use these models with gazebo, copy the according folder to \"~/.gazebo/models\" following ", ". "]},
{"url": "https://wiki.ros.org/pr2_map_navigation_app", "package": "pr2_map_navigation_app", "package_summary": ["\n    Map nav for the PR2.\n  "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/semantic_point_annotator", "package": "semantic_point_annotator", "package_summary": ["A node which annotates 3D point cloud data with semantic labels."], "package_details": ["\n", "\n", "This package provides a node that the ", " package uses for removing hits on the ground from ", " messages. ", "Since the ", " message will be deprecated in the near future, and the code in this package will be replaced with code using the new PointCloud format, there are no guarantees about the stability of this package. After the ", " stack switches to the new PointCloud structure, this package will likely be removed. You should feel free to use the code in this package, but it will not be supported and is at your own risk. "]},
{"url": "https://wiki.ros.org/maggie_rfid_msgs", "package": "maggie_rfid_msgs", "package_summary": ["rfid messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_rfid_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_rfid_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/tuw_aruco", "package": "tuw_aruco", "package_summary": ["This is a wrapper around the marker detection library ArUco."], "package_details": ["\n", "\n", "\n ", " ", "\n", "\n", "\n", " live demo using the ", " (uvc camera driver) package as a video source. Default settings (marker_dictonary=ARTOOLKITPLUSBCH, marker_size=0.06) are used. ", "The ", " plugin ", " provides visualization for the ", " message. "], "package_tt": ["image", "marker", "fiducials", "show_debug_image", "boolean", "true", "marker_dictonary", "string", "marker_size", "double", "0.06", "publish_tf", "boolean", "true", "publish_markers", "boolean", "true", "publish_fiducials", "boolean", "false", "pose_estimation_enabled", "boolean", "true", "camera", "t#id"], "package_code": ["rosrun tuw_aruco aruco_node", "roslaunch tuw_aruco demo_single_marker_live.launch"]},
{"url": "https://wiki.ros.org/rtt_stereo_msgs", "package": "rtt_stereo_msgs", "package_summary": ["Provides an rtt typekit for ROS stereo_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/stereo_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/robot", "package": "robot", "package_summary": ["A metapackage which extends ros_base and includes ROS libaries for any robot hardware. It may not contain any GUI dependencies."]},
{"url": "https://wiki.ros.org/turtlebot_actions", "package": "turtlebot_actions", "package_summary": ["turtlebot_actions provides several basic actionlib actions for the TurtleBot."], "package_details": ["\n", " This package is still experimental.  ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["~cmd_vel", "~base_frame", "string", "~odom_frame", "string", "~turn_rate", "double", "~forward_rate", "double", "odom_frame", "base_frame"], "package_code": ["#goal definition\n", "float32 turn_distance     # in radians, ccw = +, cw = -\n", "float32 forward_distance  # in meters, forward = +, backward = -\n", "---\n", "#result definition\n", "float32 turn_distance\n", "float32 forward_distance\n", "---\n", "#feedback\n", "float32 turn_distance\n", "float32 forward_distance", "#goal definition\n", "uint8   CHESSBOARD = 1\n", "uint8   CIRCLES_GRID = 2\n", "uint8   ASYMMETRIC_CIRCLES_GRID =3\n", "\n", "string    camera_name       # name of the camera \n", "uint8     pattern_width     # number of objects across\n", "uint8     pattern_height    # number of objects down\n", "float32   pattern_size      # size the object pattern (square size or circle size)\n", "uint8     pattern_type      # type of pattern (CHESSBOARD, CIRCLES_GRID, ASYMMETRIC_CIRCLES_GRID)\n", "---\n", "#result definition\n", "geometry_msgs/PoseStamped pose\n", "---\n", "#feedback"]},
{"url": "https://wiki.ros.org/tf2_py", "package": "tf2_py", "package_summary": ["The tf2_py package"], "package_details": ["\n", "This package allows to convert tf2 and geometry_msgs data to ", ". Also binds the tf2 functions and exceptions to python. ", "This is an implementation package, please refer to ", " for more information. "]},
{"url": "https://wiki.ros.org/posedetection_msgs", "package": "posedetection_msgs", "package_summary": ["posedetection_msgs provides messages and services to facilitate passing pose detection results and features."]},
{"url": "https://wiki.ros.org/pr2_msgs", "package": "pr2_msgs", "package_summary": ["Messages for representing PR2 state, such as battery information and the PR2 fingertip sensors."], "package_details": ["\n", ": Added ", " ", "Where two versions of a message or service are defined, the version defined with a suffix of ", " is preferred; the non-suffix version is deprecated (e.g., we use ", " instead of ", "). "], "package_tt": ["2"]},
{"url": "https://wiki.ros.org/power_msgs", "package": "power_msgs", "package_summary": ["ROS messages for power measurement and breaker control."], "package_details": [" "]},
{"url": "https://wiki.ros.org/schunk_pg70", "package": "schunk_pg70", "package_summary": ["Xacro model and RS232 control node for basic communication with Schunk PG70 gripper"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "This package is part of ", "  stack. It allows user to control Schunk PG70 gripper over RS232 link using standard ROS services and  provides Xacro model for easier integration with various robots. ", "This package depends on ", " library by William Woodall, git clone and catkin_make if not already in your workspace. Then you can proceed to clone and build of schunk_pg70", ". ", "The right to access a serial port is determined by the permissions of the device file (e.g. /dev/ttyS0). Serial ports are usualy owned by root and group dialout, so to access the serial device as non-root user it is convenient to add yourself to ", " group: ", "These services are ROS user interface to Schunk PG70 gripper. Except \"set_position\" all of them use ", " requests, so you don't need to specify any values, just \"rosservice call\" as in the example below. ", "To test the driver start by calling the ", " service (", "  request): ", "To get actual gripper position, call ", " service (", "  request): ", "Service respond with actual position value is in ", " format: ", "To move the gripper to target position, call ", " service (", " request): ", "where \"", "\" is within a range of <0 - 69> mm, velocity <0-83>mm/s and acceleration <0-320>mm/s2. The gripper should respond with goal_position being accepted or not and move to goal position: ", "To reference gripper, call ", "  service (empty request). Referencing may also help in cases when you are not  able to move the gripper although everything else looks okay: "], "package_tt": ["joint_states", "schunk_pg70/reference", "schunk_pg70/get_error", "schunk_pg70/acknowledge_error", "schunk_pg70/get_position", "schunk_pg70/set_position", "schunk_pg70/stop", "gripper_id", "std_msgs/UInt8", "portname", "std_msgs/String", "baudrate", "std_msgs/Int16", "robot_end_link", "schunk_pg70_base_link", "schunk_pg70_base_link", "schunk_pg70_finger_1_link", "schunk_pg70_base_link", "schunk_pg70_finger_2_link"], "package_code": ["$ usermod -a -G dialout USER_NAME", "$ roslaunch schunk_pg70 pg70_rs232_control.launch", "$ rostopic echo /joint_states", "header:\n", "  seq: 21\n", "  stamp:\n", "    secs: 1443075477\n", "    nsecs: 409227511\n", "  frame_id: ''\n", "name: ['pg70_finger1_joint', 'pg70_finger2_joint']\n", "position: [0.010000248908996583, 0.010000248908996583]\n", "velocity: []\n", "effort: []\n", "---\n", "header:\n", "  seq: 22\n", "  stamp:\n", "    secs: 1443075477\n", "    nsecs: 511969796\n", "  frame_id: ''\n", "name: ['pg70_finger1_joint', 'pg70_finger2_joint']\n", "position: [0.010000248908996583, 0.010000248908996583]\n", "velocity: []\n", "effort: []", "$ rosservice list", "schunk_pg70/reference\n", "schunk_pg70/get_error\n", "schunk_pg70/acknowledge_error\n", "schunk_pg70/get_position\n", "schunk_pg70/set_position\n", "schunk_pg70/stop", "$ rosservice call /schunk_pg70/get_error", "error_code: 0", "$ rosservice call /schunk_pg70/get_position", "actual_position: 20.000497818", "$ rosservice call /schunk_pg70/set_position position velocity acceleration", "goal position accepted: True", "$ rosservice call schunk_pg70/reference", "$ roslaunch schunk_pg70 pg70_visualize_standalone.launch"]},
{"url": "https://wiki.ros.org/tedusar_manipulation", "package": "tedusar_manipulation", "package_summary": ["A set of packages related to semi-autonomous manipulation of objects using an arm with a simple gripper."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/maxwell", "package": "maxwell", "package_summary": ["\n    Maxwell is a custom mobile manipulator. The Maxwell stack contains configuration, launch, and demo applications for the Maxwell robot.\n  "], "package_details": [" ", "\n", "\n", "The development of Maxwell has been covered on my blog (", "). "]},
{"url": "https://wiki.ros.org/wire_tutorials", "package": "wire_tutorials", "package_summary": ["wire_tutorials"], "package_details": ["Package containing data for ", " stack tutorials. The tutorials can be found ", " "]},
{"url": "https://wiki.ros.org/ridgeback_msgs", "package": "ridgeback_msgs", "package_summary": ["Messages exclusive to Ridgeback, especially for representing low-level motor commands and sensors."], "package_details": ["\n", "\n", "These messages are the low-level interface between ", "'s ARM MCU and integrated PC. Most users of Ridgeback should be able to use standard ROS interfaces (eg. ", ", ", ") to command and monitor the robot. A possible exception is to programmatically monitor system state such as voltage, current, battery, faults, etc. "]},
{"url": "https://wiki.ros.org/sr_external_dependencies", "package": "sr_external_dependencies", "package_summary": ["\n\n     sr_external_dependencies package is a \"dummy\" package used to synchronize the includes for the protocol communication between the host and the PIC for Shadow's EtherCAT hardware. It contains a script that automatically downloads the latest h file from our pic32 svn.\n\n  "], "package_details": ["\n", "\n", "' ", "When you run make in this package, it simply copies the files from the released directory to the include and compiled_firmware directories. The protocol headers are then used in the ", " and ", " to interpret the incoming packets. ", "The compiled firmware can be used in the bootloader plugin of the ", " to update the firmware of the motors.  ", "If you set the ", " environment variable to 1, then we'll download the latest version of the protocol and also the latest compiled firmware from our internal svn (this is only possible if you're working for Shadow).  "]},
{"url": "https://wiki.ros.org/sr_gui_change_controllers", "package": "sr_gui_change_controllers", "package_summary": ["\n\n     sr_gui_change_controllers is a rosgui plugin for loading the different controllers.\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/visp_hand2eye_calibration", "package": "visp_hand2eye_calibration", "package_summary": ["visp_hand2eye_calibration estimates the camera position with respect\n     to its effector using the ViSP library."], "package_details": ["\n", " ", "visp_hand2eye_calibration is a ROS package that computes extrinsic camera parameters : the constant transformation from the hand to the camera coordinates.  ", "\n", " is part of ", " stack.  ", "\n", "\n", " ", "An example client is shipped with this package. It feeds different transformations (camera->object and world->hand) to the calibrator which computes the relative transformation between the the camera and the hand. ", "\n", " ", "\n", "To do so, two sets of transformations are fed to the ", " node. ", "The package consists of a ", " node and an experimental client doing a sample calibration from a few poses.  ", "To run the ", " node: "], "package_tt": ["calibrator", "calibrator", "calibrator", "world_effector", "camera_object", "compute_effector_camera", "compute_effector_camera_quick", "reset"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-visp-hand2eye-calibration", "sudo apt-get install ros-$ROS_DISTRO-vision-visp", "rosrun visp_hand2eye_calibration visp_hand2eye_calibration_calibrator", "roscore", "rosrun visp_hand2eye_calibration visp_hand2eye_calibration_client", "rosrun visp_hand2eye_calibration visp_hand2eye_calibration_calibrator", "[ INFO] [1329226083.184531090]: Waiting for topics...\n", "[ INFO] [1329226084.186233704]: 1) GROUND TRUTH:\n", "[ INFO] [1329226084.186327570]: hand to eye transformation: \n", "translation: \n", "  x: 0.1\n", "  y: 0.2\n", "  z: 0.3\n", "rotation: \n", "  x: 0.96875\n", "  y: 0.0863555\n", "  z: -0.0863555\n", "  w: 0.215889\n", "\n", "\n", "[ INFO] [1329226085.186682976]: 2) QUICK SERVICE:\n", "[ INFO] [1329226085.188853282]: hand_camera: \n", "translation: \n", "  x: 0.1\n", "  y: 0.2\n", "  z: 0.3\n", "rotation: \n", "  x: 0.96875\n", "  y: 0.0863555\n", "  z: -0.0863555\n", "  w: 0.215889\n", "\n", "[ INFO] [1329226085.188915366]: 3) TOPIC STREAM:\n", "[ INFO] [1329226085.190303537]: hand_camera: \n", "translation: \n", "  x: 0.1\n", "  y: 0.2\n", "  z: 0.3\n", "rotation: \n", "  x: 0.96875\n", "  y: 0.0863555\n", "  z: -0.0863555\n", "  w: 0.215889"]},
{"url": "https://wiki.ros.org/win_roscpp_tutorials", "package": "win_roscpp_tutorials", "package_summary": ["\n    This package attempts to show the features of ROS step-by-step,\n    including using messages, servers, parameters, etc.\n    It is a copy of the roscpp_tutorials (because catkin\n    won't handle turtlesim in the same package).\n  "]},
{"url": "https://wiki.ros.org/maggie_eyelids_msgs", "package": "maggie_eyelids_msgs", "package_summary": ["eyelids messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_eyelids_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_eyelids_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/svenzva_description", "package": "svenzva_description", "package_summary": ["Svenzva robot description files"]},
{"url": "https://wiki.ros.org/face_detector", "package": "face_detector", "package_summary": ["Face detection in images."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", " and ", " together consists the namespace prefix, and ", " makes the body of the topic to subscribe. In the example above, you're looking for: ", "\n", "\n", " ", " ", "See ", " to see how to run the face detector continuously, or ", " to run it as an action. ", " files above are stored ", ". ", "Possible pitfall may be the argument names (in ", " for example): ", "See  ", " for the name of the topics you need to correct. ", "No doubt ", " works on the robots on simulator. Examples below show how you can run this package using stereo camera on ", " and ", ". Additionally, using some other useful packages, you can visualize face detection result on ", ". "], "package_tt": ["face_positions", "<camera>/left/<image>", "<camera>/disparity", "<camera>/left/camera_info", "<camera>/right/camera_info", "<camera>/rgb/<image>", "<camera>/depth_registered/<image>", "<camera>/rgb/camera_info", "<camera>/depth_registered/camera_info", "face_detector/people_tracker_measurements", "pos", "fixed_frame", "face_detector/faces_cloud", "~classifier_name", "string", "~classifier_filename", "string", "~classifier_reliability", "double\u00a0(0-1)", "~do_continuous", "bool", "~do_publish_faces_of_unknown_size", "bool", "~do_display", "bool", "~face_size_min_m", "double", "~face_size_max_m", "double", "~max_face_z_m", "double", "~face_separation_dist_m", "double", "~use_rgbd", "bool", "~approx_sync", "bool", "face_detector/launch/face_detector.<camera>.launch", "face_detector/launch/face_detector_action.<camera>.launch", "launch", "camera", "depth_ns", "*_topic", "face_detector", "face_detector", "RViz", "PR2", "Turtlebot", "standing\u00a0person", "Insert", "Standing\u00a0person", "Image", "RViz", "/head_mount_kinect/rgb/image_raw", "Image\u00a0Topic"], "package_code": ["  <arg name=\"camera\" default=\"camera\" />\n", "  <arg name=\"depth_ns\" default=\"depth_registered\" />\n", "  <arg name=\"image_topic\" default=\"image_rect_color\" />\n", "  <arg name=\"depth_topic\" default=\"image_rect_raw\" />\n", "  <arg name=\"fixed_frame\" default=\"camera_rgb_optical_frame\" />", "<launch>\n", "  <arg name=\"camera\" default=\"camera\" />\n", "  <arg name=\"image_topic\" default=\"image_raw\" />\n", "  <arg name=\"depth_topic\" default=\"image_raw\" />\n", "  <arg name=\"fixed_frame\" default=\"camera_rgb_optical_frame\" />\n", "  <arg name=\"depth_ns\" default=\"depth_registered\" />\n", ":\n", "</launch>", "apt-get install jsk_pr2_startup ", "roslaunch pr2_gazebo pr2_empty_world.launch\n", "roslaunch face_detector facedetector_rgb_pr2.launch  (*a)", "roslaunch turtlebot_gazebo turtlebot_world.launch\n", "roslaunch turtlebot_miscsample_cpp facedetector_rgb.launch (*b)", "roslaunch jsk_pr2_startup rviz.launch"]},
{"url": "https://wiki.ros.org/pr2_controller_manager", "package": "pr2_controller_manager", "package_summary": ["The controller manager (CM) package provides the infrastructure to run controllers in a hard realtime loop."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " provides a ", " loop to control the robot mechanism. The robot mechanism is represented by a set of effort controlled joints (see ", " for details).  For the PR2 robot, we run the control loop at 1000 Hz. The controller manager provides the infrastructure to load your own realtime controller into its control loop. Every controller that is loaded into the controller manager will get triggered once every mili-second. To find out how to write your own hard realtime controller, take a look at ", ". ", "The controller manager ensures that none of the loaded controllers can command a joint past its ", ". If necessary, the controller manager reduces the commanded joint effort, or even applies an effort in the opposite direction. For more details, take a look at the ", " page. ", "The controller manager publishes the state of all joints over ROS, as ", " messages. These messages appear on the ", " topic, at 100 Hz. You can change this publishing frequency by setting the ", " parameter. ", "To interact with controllers from the command line, use the ", " tool. To interact with a specific controller, use: ", "To automatically load and start a set of controllers at once, and automatically stop and unload those same controllers at once, use the ", " tool: ", "To automatically stop a set of controllers, and restart them later, you can use the ", " tool: ", "The listed controllers will be ", ", but not unloaded. Once spawner is shut down, the controllers will be restarted. ", "You could run ", " to start controllers from within a launch file. However, the controller would then stay up even after the launch file is taken down. Instead, use the ", "tool to automatically load, start, stop and unload a controller from within a launch file. When you start ", ", it will load and start the controller. When you stop ", " (when the launch file is taken down) it will stop and unload the controller. Your launch file would look something like this: "], "package_tt": ["pr2_controller_manager", "joint_state", "joint_state_publish_rate", "pr2_controller_manager", "load", "unload", "start", "stop", "spawn", "kill", "list", "list-types", "list-joints", "reload-libraries", "reload-libraries\u00a0--restore", "spawner", "unspawner", "pr2_controller_manager", "spawner\u00a0", "spawner", "spawner", "joint_states", "mechanism_statistics", "pr2_controller_manager/load_controller", "pr2_controller_manager/unload_controller", "pr2_controller_manager/switch_controller", "BEST_EFFORT", "STRICT", "STRICT", "BEST_EFFORT", "pr2_controller_manager/list_controllers", "pr2_controller_manager/list_controller_types", "pr2_controller_manager/reload_controller_libraries", "pr2_controller_manager/joint_state_publish_rate", "double", "pr2_controller_manager/mechanism_statistics_publish_rate", "double"], "package_code": [" $ rosrun pr2_controller_manager pr2_controller_manager <command> <controller_name>", " $ rosrun pr2_controller_manager pr2_controller_manager <command>", "  $ rosrun pr2_controller_manager spawner [--stopped] name1 name2 name3 ", "  $ rosrun pr2_controller_manager unspawner name1 name2 name3", " <launch>\n", "   <node pkg=\"pr2_controller_manager\" \n", "         type=\"spawner\" \n", "         args=\"controller_name1 controller_name2\" />\n", " </launch>", " <launch>\n", "   <node pkg=\"pr2_controller_manager\" \n", "         type=\"spawner\" \n", "         args=\"--stopped controller_name1 controller_name2\" />\n", " </launch>"]},
{"url": "https://wiki.ros.org/sr_gui_self_test", "package": "sr_gui_self_test", "package_summary": ["A GUI plugin for running self diagnostics of a robot."], "package_details": [" ", "You can select one of the available self tests of the hand to be executed. Follow the on screen instructions. This will take some time! This is the front-end of ", " package. "]},
{"url": "https://wiki.ros.org/turtlebot_msgs", "package": "turtlebot_msgs", "package_summary": ["Turtlebot messages, services and actions"], "package_details": [" ", "\n", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"turtlebot_msgs\" in rosdoc: /home/rosbot/docs/api/turtlebot_msgs/manifest.yaml "], "package_code": ["$ sudo apt-get install ros-hydro-turtlebot-msgs", "$ sudo apt-get install ros-indigo-turtlebot-msgs"]},
{"url": "https://wiki.ros.org/sr_mechanism_model", "package": "sr_mechanism_model", "package_summary": ["\n\n    sr_mechanism_model contains the transmissions used in the robot model. We needed specific\n    transmission as we're using our own actuator. We also needed to take care of the joint 0s\n    which combine the distal and middle phalanges.\n\n  "], "package_details": ["\n", "We needed to redefine the ", " used in the ", ", to be able to combine the distal and middle phalanges of the fingers into joint 0s. The new transmissions are defined in this package. They're using the actuators which are defined in ", ".  "]},
{"url": "https://wiki.ros.org/sr_gui_hand_calibration", "package": "sr_gui_hand_calibration", "package_summary": ["\n\n     This is a rosgui plugin for calibrating the Shadow EtherCAT Hand.\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/win_ros", "package": "win_ros", "package_summary": ["\n    Setup and utilities for ros on windows.\n  ", "Contents", " ", " ", "\n", "ROS Fuerte is EOL, and these instructions for getting it to work on Windows are severely outdated. They are only kept here for historical reasons. ", "Please do not expect these steps to work, or try to follow them. ", "For future Windows support, see the relevant ", ". ", "We now have enough functionality and enough to be useful in some situations. The mingw cross compiles are fairly stable and the msvc is now native thanks to a 100% cmake build environment codenamed ", ". To be practical, we are not targeting the windows environment as a full blown replacement for linux-ros as windows doesn't have the mechanisms to handle the scaling of complexity (e.g. rosdeps), but it needs to be useful in some simple use case scenarios. For example, ", "\n", " to the ", " page to keep track of progress by email. ", " - Windows on Ros slides. ", "\n", "\n", "This is for native windows development with the ", ". Currently supporting either windows sdk 7.1 (cl/nmake) or visual studio 10.0. ", " - what's working and what's not. ", " - installing, configuring and verifying a pre-built sdk. ", " - developing projects with visual studio and the sdk. ", " - developing new ros msg types with the sdk. ", " - rosmaster, roslaunch'ers, rosparam and ros logging with the sdk. ", "For more advanced usage: ", " - compiling the sdk/building your packages catkin style! ", " - how to hack an existing catkin stack for winros. ", " - how to create msvc packages and stacks, ros style. ", " - debugging msvc with win_ros. ", "\n", "This is for the control roboticists who love working in linux and get flustered when asked to build windows apps for the rest of the world (namely users/test engineers) there is the ", ". There is also qt support here - write the code once and compile your qt app for both windows and linux without any changes. ", " - setting up the mingw-cross build environment. ", " - how to create mingw packages and stacks, ros style. ", " - how to create mingw qt packages in ros. ", "\n", "/", " ", " - if you're interested in helping, either with the infrastructure or porting stacks, start here. ", " ", " "]},
{"url": "https://wiki.ros.org/summit_x_description", "package": "summit_x_description", "package_summary": ["The summit_x_description package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/uwsim", "package": "uwsim", "package_summary": ["UWSim is an UnderWater SIMulator for marine robotics research and development. UWSim visualizes an underwater virtual scenario that can be configured using standard modeling software. Controllable underwater vehicles, surface vessels and robotic manipulators, as well as simulated sensors, can be added to the scene and accessed externally through ROS interfaces. This allows to easily integrate the visualization tool with existing control architectures."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "You will need a decent PC, with a good graphics card. It should work well on recent NVidia and ATI cards with good driver support in GNU/Linux. Have a look to the ", " list of cards that are known to be working]. If you see strange visualization effects, or it just crashes before beginning, it probably means your card does not meet the requirements (if this is the case, try with the <tt>--disableShaders</tt> option). As an example, it runs fluently on a ", " Pro 2.26 Ghz Intel Core 2 Duo, 4 GB DDR3 with an NVIDIA ", " 9400M, running Ubuntu 11.04. ", "and subscribe/publish to them with rostopic and rospub, or with your custom ros control nodes. The are some example ROS interface nodes in the <tt>interface_examples</tt> folder. For example, the following command should update the vehicle position in the default scenario (2 meters along positive X axis): ", "Create a ", " and place a .rosinstall file inside it with the following contents: "], "package_code": ["apt-get install ros-groovy-uwsim", "roscore", "rosrun uwsim uwsim", "rostopic list", "rosrun uwsim setVehiclePosition /dataNavigator 2 0 0 0 0 0", "git clone https://github.com/uji-ros-pkg/underwater_simulation.git", "rosdep install UWSim", "rosmake UWSim", "- other: {local-name: /opt/ros/groovy/share/ros}\n", "- other: {local-name: /opt/ros/groovy/share}\n", "- other: {local-name: /opt/ros/groovy/stacks}\n", "- setup-file: {local-name: /opt/ros/groovy/setup.sh}\n", "- git: {local-name: src/uwsim_osgocean, \n", "        uri: 'https://github.com/uji-ros-pkg/uwsim_osgocean.git', \n", "        version: groovy-devel}\n", "- git: {local-name: src/uwsim_osgworks, \n", "        uri: 'https://github.com/uji-ros-pkg/uwsim_osgworks.git', \n", "        version: groovy-devel}\n", "- git: {local-name: src/uwsim_bullet, \n", "        uri: 'https://github.com/uji-ros-pkg/uwsim_bullet.git', \n", "        version: groovy-devel}\n", "- git: {local-name: src/uwsim_osgbullet, \n", "        uri: 'https://github.com/uji-ros-pkg/uwsim_osgbullet.git', \n", "        version: groovy-devel}\n", "- git: {local-name: src/underwater_simulation, \n", "        uri: 'https://github.com/uji-ros-pkg/underwater_simulation.git', \n", "        version: groovy-devel}", "rosws update", " rosdep install --from-paths src --ignore-src --rosdistro groovy -y\n", " catkin_make_isolated --install"]},
{"url": "https://wiki.ros.org/pr2_mechanism_diagnostics", "package": "pr2_mechanism_diagnostics", "package_summary": ["The `pr2_mechanism_diagnostics` node subscribes to `mechanism_statistics` and publishes diagnostics data for joints and controllers on `/diagnostics`."], "package_details": [" ", "\n", "\n", "\n", "The ", " package publishes data from the ", " topic onto diagnostics. This data is published by ", ". The joints and controllers diagnostics come from this package. ", "The ", " topic contains statistics and information from the joints, actuators and controllers. "], "package_tt": ["pr2_mechanism_diagnostics", "mechanism_statistics", "mechanism_statistics", "mechanism_statistics", "/diagnostics", "~disable_controller_warnings", "bool", "/use_sim_time", "bool"]},
{"url": "https://wiki.ros.org/pheeno_ros_sim", "package": "pheeno_ros_sim", "package_summary": ["Gazebo simulation ROS package for Pheeno system!"], "package_details": ["\n", "Documentation for our package can be found ", ". We will also be adding documentation to this ROS page in the coming weeks. "]},
{"url": "https://wiki.ros.org/pr2_dense_laser_snapshotter", "package": "pr2_dense_laser_snapshotter", "package_summary": ["Stores the data from a series of laser scan messages in a dense representation, allowing\n     users to easily perform image-like operations on intensity or range data. This package is\n     experimental. Expect APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/maxwell_defs", "package": "maxwell_defs", "package_summary": ["\n    Maxwell is a custom mobile manipulator, this package contains his configuration and launch files. \n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The base uses a standard ", " message on the ", " topic to set desired velocity. ", "See ", " and ", ". ", "Use of ", " is not recommended as most of our demos will use the topics in the ", " namespace.  "]},
{"url": "https://wiki.ros.org/rosjava_core", "package": "rosjava_core", "package_summary": ["An implementation of ROS in pure-Java with Android support."], "package_details": ["\n ", "\n", "\n", "For core library and example documentation, refer to the ", ". ", "For more general documentation on all things rosjava-android, refer to the ", " and ", " wiki pages. ", "Some outdated tutorials can be found in the ", ". "]},
{"url": "https://wiki.ros.org/wheeled_robin_bringup", "package": "wheeled_robin_bringup", "package_summary": ["wheeled_robin_bringup provides roslaunch scripts for starting the WheeledRobin base functionality."], "package_details": ["\n", "\n", "\n", " ", "This package starts the ", ". There are several launch files for different applications. "]},
{"url": "https://wiki.ros.org/asr_ism", "package": "asr_ism", "package_summary": ["This package contains nodes which make up the Passive-Scene-Recognition interface to Implicit Shape Model (ISM) trees. The Active-Scene-Recognition interface to ISM trees is located in asr_recognizer_prediction_ism, instead. A short outline of the functionalities provided by the nodes are:\n      1. Recording of scenes\n      2. Training of an ISM tree (Implicit shape model tree)\n      3. Recognition of scenes\n      4. Visualization of ISM (tree) data \n\t  etc."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", ": Visualize recorded data of a given pattern as a path for each object on which these objects moved while recording. ", ": Expand the ", " visualization with vectors from positions of an object on its path at a certain point in time to its reference path at the same point in time. This visualization can help the user to understand how the model was created from each record data point. ", ": Provide two different vote visualizations, the first just visualizes all votes from a fixed pose for a selected object in a selected subpattern and the second visualizes a given configuration with each object's votes that the model of a selected pattern provides. ", "\n", ": This class can be used for custom nodes to convert ros messages (", ") to data-types used by the ", " library. This class is implemented in the ", " file. ", ": This class expands a node with the functionality to configure an object configuration interactively. Main features of this class are the multi-threaded processing of incoming messages (number of threads set by the user) and the processing of keyboard input (polling on its own dedicated thread). With this approach the actual node runs on its own thread(s) and decouples the ", " logically and computationally from the node. ", ": This node republishes recorded data from a given database as ros messages (", "). ", ": This node generates an object configuration by editing object data from a given database or XML-file and writes it to an XML-file. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", "\n", " ", " ", " ", " ", "\n", ": This service is only called by the ObjectConverter class and provides it with additional information about recognizable objects from the ", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", " ", "\n", " Missing object estimations when using a SceneConfigurator -Node and the ", "_driver GUI. ", " Make sure to uncheck the \u201cupdate current angle immediately\u201d option if you want to work with the current view. ", "This package serves as the Passive-Scene-Recognition interface to the functionality provided by the ", " library in the ROS environment. The Active-Scene-Recognition interface to ISM trees is located in ", ", instead. The core functions of this package are the training and recognition of scenes which consist of various objects using Implicit Shape Model (ISM) trees. In addition to the implementation of the tools provided by ", " there are several visualization (based on ", ") and utility tools to make the usage of the scene recognition system more convenient. ", "There are two training approaches implemented, one simply being called ", ", the other ", ". They are interchangeable but as they use different algorithms the trained models result in a difference in recognition quality mostly in terms of speed as the latter has a shorter computation time. The input of both trainers is a recording of a scene consisting of multiple objects which is stored in a sqlite database and can be created using the \"Recorder\" tool. The \"Recognizer\" tool uses the trained models and tries to find the most likely match given a set of objects. ", "In general the steps required are the recording of a scene, training a model from this recording and then using the recognizer to get the most likely scene match from a new object configuration. Below you can see a list of all tools this package provides including the mentioned ones and tutorials on how to use them. For more information about the functionality see the ", " package. ", "The nodes in this list wrap tools from ", " to provide them in the ROS environment: ", "Although many nodes of this package publish some kind of visualization, the purpose of these nodes is solely to visualize ism data in ", ". ", "If you are using the ", " from ", " and you checked the option \u201cupdate current angle immediately\u201d, it may happen that the SceneConfigurator clears the object estimations in the current view, because the ptu toggles its \u201creached_desired_position\u201d parameter. "]},
{"url": "https://wiki.ros.org/rosserial_python", "package": "rosserial_python", "package_summary": ["A Python-based implementation of the rosserial protocol."], "package_details": ["\n", "\n", "\n", "\n", "The ", " package contains a Python implementation of the host-side rosserial connection. It automatically handles setup, publishing, and subscribing for a connected rosserial-enabled device.  ", "To run the node with a different port and baud rate, for example on /dev/ttyACM1, you must specify the ", " and ", " parameters on the command line: "], "package_tt": ["~port", "str", "~baud", "int", "~port", "~baud"], "package_code": ["rosrun rosserial_python serial_node.py _port:=/dev/ttyACM1 _baud:=115200", "<launch>\n", "  <node pkg=\"rosserial_python\" type=\"serial_node.py\" name=\"serial_node\">\n", "    <param name=\"port\" value=\"/dev/ttyACM1\"/>\n", "    <param name=\"baud\" value=\"115200\"/>\n", "  </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/tedusar_box_detection", "package": "tedusar_box_detection", "package_summary": ["Node for detecting boxes with square base in point clouds by detecting their top plane. Detection is started via an action interface."]},
{"url": "https://wiki.ros.org/pr2_machine", "package": "pr2_machine", "package_summary": ["This package contains the xxx.machine files that describe the different hosts a node can be spawned on. Currently there is one machine file for the pr2 robot, and one for the simulated pr2 robot."], "package_details": ["\n", "These files are intended to be included by ", " files.  The intended usage is: ", "The user sets the ", " environment variable to ", " when working with a physical PR2, and ", " when working in simulation.  In this way, ", " files that refer to machines ", " and ", " will distribute computation appropriately on the robot, but still work on a single machine in simulation (assuming that the single machine can support the processing requirements). "], "package_tt": ["pr2.machine", "c1", "c2", "c1", "c2", "sim.machine", "c1", "c2", "localhost", "ROBOT", "pr2", "sim", "c1", "c2"], "package_code": ["  <include file=\"$(find pr2_machine)/$(env ROBOT).machine\" />"]},
{"url": "https://wiki.ros.org/tum_ardrone", "package": "tum_ardrone", "package_summary": ["The tum_ardrone package"], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The code works for both the AR.Drone 1.0 and 2.0, the default-parameters however are optimized for the AR.Drone 2.0 by now. You can find more details on my research on my ", ". ", "This Package builds on the well known monocular SLAM framework ", " presented by Klein & Murray in their ", " at ISMAR07.  ", "Please study the original ", " and the corresponding ", " for more information on this part of the software. Also, be aware of the ", " that comes with it. ", "1. Install the ", " package: ", " To do this, run: ", "The major part of this software package - that is everything except PTAM - is licensed under the GNU General Public License Version 3 (GPLv3), see ", ".  ", "PTAM (comprised of all files in /src/stateestimation/PTAM) has it's own licence, see ", ". This licence in particular prohibits commercial use of the software. "], "package_tt": ["rosrun\u00a0joy\u00a0joy_node", "aggressiveness", "Kp_rp"], "package_code": ["# cd into ros root dir\n", "roscd\n", "\n", "# clone repository\n", "git clone git://github.com/tum-vision/ardrone_autonomy.git ardrone_autonomy\n", "\n", "# add to ros path (if required)\n", "export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/ardrone_autonomy\n", "\n", "# build SDK (might require your confirmation to install some system libraries)\n", "cd ardrone_autonomy\n", "./build_sdk.sh\n", "\n", "# build package\n", "rosmake", "# cd into ros root dir\n", "roscd\n", "\n", "# clone repository\n", "git clone git://github.com/tum-vision/tum_ardrone.git tum_ardrone\n", "\n", "# add to ros path (if required)\n", "export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/tum_ardrone\n", "\n", "# build package (may take up to 10 minutes)\n", "rosmake tum_ardrone", "# run driver\n", "rosrun ardrone_autonomy ardrone_driver\n", "\n", "# run stateestimation node\n", "rosrun tum_ardrone drone_stateestimation\n", "\n", "# run autopilot node\n", "rosrun tum_ardrone drone_autopilot\n", "\n", "# run gui node\n", "rosrun tum_ardrone drone_gui"]},
{"url": "https://wiki.ros.org/segbot_simulation_apps", "package": "segbot_simulation_apps", "package_summary": ["Applications designed specifically to be used in a\n    simulation environment, such as opening and closing doors inside the\n    building simulation."]},
{"url": "https://wiki.ros.org/pyros_config", "package": "pyros_config", "package_summary": ["Configuration package for Pyros"]},
{"url": "https://wiki.ros.org/smart_battery_msgs", "package": "smart_battery_msgs", "package_summary": ["Smart Battery Messages"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"smart_battery_msgs\" in rosdoc: /home/rosbot/docs/api/smart_battery_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/uos_rotunit_driver", "package": "uos_rotunit_driver", "package_summary": ["driver for the uos-rotunit"]},
{"url": "https://wiki.ros.org/srdfdom", "package": "srdfdom", "package_summary": ["Parser for Semantic Robot Description Format (SRDF)."]},
{"url": "https://wiki.ros.org/wpi_jaco", "package": "wpi_jaco", "package_summary": ["Metapackage for the ROS Packages for the JACO Arm Developed at WPI"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "Not all of the functionality of the meta-package is implemented yet for the JACO2.  There's no jaco2_description package yet, providing a urdf for the arm.  Similarly, there is no sample ", "! configuration either, which is waiting on the urdf before configuration is possible.  As such, the motion planning functionality found in the two moveit packages have not yet been extended to the JACO2.  All of the other functionality should work as intended for the new arm. ", "To install the ", " package, you can install from source with the following commands: ", "The ", " package contains a launch file, ", ", to start all of the nodes required to communicate with the JACO arm.  Once these nodes are launched, further launch files can be run from the other packages, all of which are documented in their respective wiki pages. ", "Please send bug reports to the ", ". "], "package_tt": ["wpi_jaco", "wpi_jaco", "arm.launch"], "package_code": ["\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rtmros_nextage", "package": "rtmros_nextage", "package_summary": ["The rtmros_nextage package is a ROS interface for ", " dual-armed robot from Kawada Robotics Inc."], "package_details": [" ", " ", "\n", " ", "\n", "\n", "\n", "\n", " ", " The content of this DVD has become obsolete. Please refer to ", " tutorial page and get the software. ", " might ask you this password: ", " ", " ", "See ", ". ", "Please read the ", ". ", "When you insert the DVD into your Ubuntu computer, ", " package, which is a basis of ", ", and its dependency will be installed. ", "Once installation is done, you can try it by following ", " (which is ogirinally made for the robot from the same manufacturor called ", "). Since installation should be done by this point, you can skip installation section and move forward to ", ". ", "(New 2013/11/07) Now ", " is installable from ROS repository. See ", ". "], "package_tt": ["rtmros_nextage", "Hiro", "rtmros_nextage", "Ubuntu", "opensource"]},
{"url": "https://wiki.ros.org/phidgets_imu", "package": "phidgets_imu", "package_summary": ["Driver for the Phidgets Spatial 3/3/3 devices"], "package_details": ["\n", " ", "\n", "\n", " ", "The ", " package contains a  ROS driver for the ", " IMU sensor. The driver publishes the following data: ", "You can use this driver in conjunction with ", " or a similar IMU filter to get an estimate for the orientation of the sensor from the fused sensor readings. ", "An example ", " for using the driver together with a filter is included in the package. "], "package_tt": ["phidgets_imu_node_node", "imu/data_raw", "imu/mag", "imu/is_calibrated", "imu/calibrate", "imu/is_calibrated", "imu/calibrate", "~frame_id", "string", "\"imu\"", "~period", "double", "~angular_velocity_stdev", "double", "~linear_acceleration_stdev", "double", "~magnetic_field_stdev", "double"]},
{"url": "https://wiki.ros.org/rosserial_arduino", "package": "rosserial_arduino", "package_summary": ["rosserial for Arduino/AVR platforms."], "package_details": ["\n", "\n", "This package contains Arduino-specific extensions required to run ", " on an Arduino. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors into your ROS project using an Arduino. The Tutorials of this package will walk you through setting up your Arduino environment, creating a few example sketches and explain where to purchase the additional hardware. ", "Some features can be enabled depending of ", " statements added before including ", " in the sketch. ", "For example, to use the ", " define, see the ", " example. "], "package_tt": ["#define", "ros.h", "#define", "USE_USBCON", "ROSSERIAL_ARDUINO_TCP", "USE_TEENSY_HW_SERIAL", "USE_STM32_HW_SERIAL", "STM32ETHERNET", "ROSSERIAL_ARDUINO_TCP"]},
{"url": "https://wiki.ros.org/sr_gui_change_muscle_controllers", "package": "sr_gui_change_muscle_controllers", "package_summary": ["A GUI plugin for loading the different muscle controllers."], "package_details": [" ", "This is similar to ", " but is used for the version of the hand that uses air pressure actuated muscles instead of electric motors. You may select Valve or position control mode. "]},
{"url": "https://wiki.ros.org/linux_peripheral_interfaces", "package": "linux_peripheral_interfaces", "package_summary": ["Simple scripts which help utilise, monitor, interact with computer\n     hardware abstracted by a linux OS."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/turtlebot_rapps", "package": "turtlebot_rapps", "package_summary": ["The core set of turtlebot 'app manager' apps are defined in this package."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/spur_controller", "package": "spur_controller", "package_summary": ["A package for mobile base control for SPUR omni-directional mobile manipulator robot made at Tamagawa University."]},
{"url": "https://wiki.ros.org/pr2_navigation", "package": "pr2_navigation", "package_summary": ["The pr2_navigation stack holds common configuration options for running the"], "package_details": ["\n", "\n", "\n", "  "]},
{"url": "https://wiki.ros.org/rosserial_msgs", "package": "rosserial_msgs", "package_summary": ["Messages for automatic topic configuration using rosserial."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/wheeled_robin_description", "package": "wheeled_robin_description", "package_summary": ["The wheeled_robin_description package"], "package_details": ["\n", " ", "This package contains the robot description file for ", " as URDF file (compare ", "). The file can be loaded by the ", " and the ", ". "]},
{"url": "https://wiki.ros.org/turtlebot_bringup", "package": "turtlebot_bringup", "package_summary": ["turtlebot_bringup provides roslaunch scripts for starting the TurtleBot base functionality."], "package_details": ["\n", "\n", "Follow the ", " to start your TurtleBot. "]},
{"url": "https://wiki.ros.org/tedusar_cartesian_arm_teleop", "package": "tedusar_cartesian_arm_teleop", "package_summary": ["Node for teleoperating an arm and gripper in a cartesian coordinate frame using a joystick."]},
{"url": "https://wiki.ros.org/hironx_ros_bridge", "package": "hironx_ros_bridge", "package_summary": ["ROS-OpenRTM interfacing package for the opensource version of Kawada's Hiro/NEXTAGE dual-arm robot.\n\n  NOTE: This package is multi-license -- pay attention to file header in each file where license is declared. For Creative Commons nc 4.0 applied, see ", ".\n\n  ", "This package also contains some sensor driver software (as of April 2016 they are the following force sensors such as ", " and ", ") for QNX. These drivers are stored in this robot-specific package for not many reasons than they are slightly customized for the robot. So if you can separate those as a standalone, generic package that'll be appreciated (please just let us know if you will)."], "package_details": ["\n", "\n", " is supported by the opensource community per best-effort basis. If you find anything wrong, or would like to add more documentation, please consider opening a ticket and providing patches ", ". ", "\n", "\n", "Dependency graph (that's yielded by ", ") of ", ". ", " ", "Tutorial for ", " is integrated into ", "'s page. ", "User can get a the most control of the ", " robot through the Python class ", ", where the large part of methods are derived from ", ". Some of their methods are overridden specifically for Hironx at ", " (that is a derived class of ", "). ", "For some of those methods derived from ", ", unit test cases are available in ", ". Download it and run: ", "As of today (Jan 31, 2014), you might want to modify the file to adjust to your environment. Open the file with the editor, replace ", " with the QNX hostname of your robot. "], "package_tt": ["hironx_ros_bridge", "Hironx", "hironx_ros_bridge", "Hironx", "hironx_ros_bridge.hironx_client.HIRONX", "hrpsys.HrpsysConfigurator"], "package_code": ["$ mv test_hironx_derivedmethods_rostest.py `rospack find nextage_ros_bridge`/test\n", "$ chmod 755 test_hironx_derivedmethods_rostest.py\n", "$ rosrun nextage_ros_bridge test_hironx_derivedmethods_rostest.py "]},
{"url": "https://wiki.ros.org/manipulator_handler", "package": "manipulator_handler", "package_summary": ["The manipulator_handler package"], "package_details": ["\n", "The manipulator handler looks for a manipulator tag and it finds all its joints. After it creates a ROS publisher of ", " messages: ", "In addition it gives us the possibility to control the joints using commands from ROS in several ways (see ", " for more details): ", "In the folder ", " you will find the model of a manipulator with the joints controlled in velocity:  ", ". "], "package_code": ["sim_ext_ros_bridge_manipulator_ctrl_mode_Passive_mode", "sim_ext_ros_bridge_manipulator_ctrl_mode_MOT_velocity", "sim_ext_ros_bridge_manipulator_ctrl_mode_Passive_mode_velocity", "sim_ext_ros_bridge_manipulator_ctrl_mode_TF_position", "sim_ext_ros_bridge_manipulator_ctrl_mode_TF_velocity", "sim_ext_ros_bridge_manipulator_ctrl_mode_TF_effort"]},
{"url": "https://wiki.ros.org/turtlebot_create_desktop", "package": "turtlebot_create_desktop", "package_summary": ["Catkin meta-package for turtlebot_create_desktop"], "package_details": [" "]},
{"url": "https://wiki.ros.org/tuw_marker_noise", "package": "tuw_marker_noise", "package_summary": ["The tuw_marker_noise package provides nodes\n      for adding artificial noise to MarkerDetection messages from the marker_msgs package and\n      for recording MarkerDetection messages in order to obtain a measurement noise model."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["tuw_record", "record.csv", "markers", "input", "string", "output_dir", "string", "record.csv", "frame_id_odom", "string", "\"odom\"", "variance.py", "variance.csv", "parameter.m", "parameter.csv", "recordfile", "string", "precision", "double", "variance.csv", "parameter.csv", "file", "string", "marker", "marker_noise", "beta_1/18", "double", "plot_data", "boolean", "false"], "package_code": ["rosrun tuw_marker_noise tuw_record.py", "roslaunch tuw_marker_noise record.launch", "./variance.py -r ../output/record.csv -p 1.0", "octave> parameter('../output/variance.csv')", "rosrun tuw_marker_noise tuw_marker_noise.py", "roslaunch tuw_marker_noise noise.launch"]},
{"url": "https://wiki.ros.org/sr_mechanism_controllers", "package": "sr_mechanism_controllers", "package_summary": ["\n\n     The sr_mechanism_controllers package contains different types of\n     controllers for the etherCAT hand:(fake) calibration controllers,\n     position controllers, velocity controllers, force controllers, ...\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The different controllers are implemented in this package. The controllers have access to an actuator which contains the hand data updated in real time by ", " and ", ". ", "The ", " package is used to record and interpolate the friction compensation map. Based on this map, we just add a value to the output of the controller as illustrated below (we have two different maps, one for each direction): ", " "]},
{"url": "https://wiki.ros.org/stdr_server", "package": "stdr_server", "package_summary": ["Implements synchronization and coordination functionalities of STDR Simulator."], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", " can run without any command-line arguments and simply waits until someone calls either ", " or ", " service. There is an option to run ", " passing an image file to load as the static map or you can include it to a launch file using the ", " option. ", "\n", "\n", "\n", "The ", " node implements the synchronization and coordination functionalities of ", ". It is used to serve the static map, which represents the simulated environment and keeps track of active robots. ", "The ", " node provides several action server implementations used for robot handling and coordination. ", "The ", " node uses ", "'s ", " library to load an map image from a file, fill a ", " message, call ", " service and load it to the simulator. The loading functionality is also provided in ", " library and can be used by other packages.  ", "For tutorials see ", ". "], "package_tt": ["stdr_server_node", "stdr_simulator", "stdr_server_node", "spawn_robot", "delete_robot", "register_robot", "stdr_robot", "map", "map_metadata", "active_robots", "load_static_map", "load_static_map_external", "robot_manager/load_nodelet", "robot_manager/unload_nodelet", "world", "map", "world", "map_static", "stdr_server_node", "load_static_map", "load_static_map_external", "stdr_server_node", "args", "map_loader_node", "image_loader", "load_static_map_external", "map_loader"], "package_code": ["$ rosrun stdr_server stdr_server_node <map_file.yaml>", "$ rosrun stdr_server load_map <map_file.yaml>"]},
{"url": "https://wiki.ros.org/vtec_ros", "package": "vtec_ros", "package_summary": ["The vtec_ros metapackage that installs VisioTec packages"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "A ", " ", "A technical report is available here: ", ". It describes the tracker software and its working principles. If you use this software in an academic context, please cite the technical report, using: ", "Download the dataset from here: ", " "], "package_tt": ["camera/image", "track_cmd", "annotated_image", "stabilized_image", "reference_image", "tracking", "bbox_size_x", "int", "bbox_size_y", "int", "bbox_pos_x", "int", "bbox_pos_y", "int", "image_topic", "string", "max_nb_iter_per_level", "int", "max_nb_pyr_level", "int", "sampling_rate", "double", "homography_type", "string", "robust_flag", "bool"], "package_code": ["@TechReport{nogueira2019,\n", "  author = {Lucas Nogueira and Ely de Paiva and Geraldo Silveira},\n", "  title  = {Visio{T}ec robust intensity-based homography optimization software},\n", "  number = {CTI-VTEC-TR-01-19},\n", "  institution = {CTI},\n", "  year = {2019},\n", "  address = {Brazil}\n", "}", "sudo apt-get install ros-[kinetic|melodic]-usb-cam", "mkdir -p ~/catkin_ws/src", "cd ~/catkin_ws/src\n", "git clone https://github.com/visiotec/vtec.git\n", "cd vtec\n", "mkdir build\n", "cd build\n", "cmake ..\n", "make", "cd ~/catkin_ws/src\n", "git clone https://github.com/visiotec/vtec_ros.git\n", "cd ~/catkin_ws\n", "catkin_make\n", "source devel/setup.bash", "roslaunch vtec_tracker tracker.launch", "rosbag play vtec_test_tracker.bag", "roslaunch vtec_tracker tracker_live.launch", "roslaunch vtec_tracker tracker_live_occlusion.launch "]},
{"url": "https://wiki.ros.org/schunk_modular_robotics", "package": "schunk_modular_robotics", "package_summary": ["This stack includes packages that provide access to the Schunk hardware through ROS messages, services and actions."], "package_details": ["\n", "\n", "\n", "For the Schunk Powercubes, see ", ". ", "For the Schunk SDH, see ", ". ", "Please consult ", " to see if your problem is already known. ", "Please use the ", " for additional support or feature discussion. ", "Use ", " to report bugs or request features. ", " "]},
{"url": "https://wiki.ros.org/trac_ik_python", "package": "trac_ik_python", "package_summary": ["The trac_ik_python package contains a python wrapper using SWIG\n  for trac_ik_lib"]},
{"url": "https://wiki.ros.org/media_export", "package": "media_export", "package_summary": ["Placeholder package enabling generic export of media paths."]},
{"url": "https://wiki.ros.org/kobuki_dashboard", "package": "kobuki_dashboard", "package_summary": ["The Kobuki dashboard is a RQT-based plug-in for visualising data from Kobuki and giving easy access\n    to basic functionalities."], "package_details": [" ", "\n", "\n", "The kobuki_dashboard is also part of the ", ". In order to get the battery statuses, you need to launch the ", ". "], "package_code": ["$ roslaunch kobuki_node minimal.launch", "$ rosrun kobuki_dashboard kobuki_dashboard"]},
{"url": "https://wiki.ros.org/tf2_geometry_msgs", "package": "tf2_geometry_msgs", "package_summary": ["tf2_geometry_msgs"], "package_details": ["\n", "\n", "\n", "\n", " "]},
{"url": "https://wiki.ros.org/ur_msgs", "package": "ur_msgs", "package_summary": ["The ur_msgs package"]},
{"url": "https://wiki.ros.org/twist_mux_msgs", "package": "twist_mux_msgs", "package_summary": ["The twist_mux msgs and actions package"], "package_details": ["\n", " ", " "]},
{"url": "https://wiki.ros.org/rosout", "package": "rosout", "package_summary": ["System-wide logging mechanism for messages sent to the /rosout topic."], "package_details": ["\n", " ", "\n", "\n", " ", "\n", "\n", " ", "\n", " ", "\n", " is an aggregated feed for subscribing to console logging messages. This aggregated topic is offered as a performance improvement: instead of connecting to individual ROS nodes to receive their console messages, the aggregated message feed can instead be received directly from the ", " node. ", "\n", " node by default logs all messages into ", " in the ROS log directory. ", " ", "This can be disabled by setting environment variable ", " to ", " when launching ", ". ", " ", "This behavior can be changed by setting boolean ROS parameter ", " at any time. ", "\n", "The ", " ", " only provides the ", " node. ", "Please see ", ". ", "The ", " node is part of ", " and has preferential startup order. ", "ROS ", " are required to publish console logging messages to the ", " topic as a standard interface. ", "By default, ", " prints ", " name for every message. ", "No future development on ", " is currently planned. "], "package_tt": ["rosout", "rosout", "/rosout", "/rosout", "/rosout_agg", "/rosout", "/rosout_agg", "/rosout", "/rosout", "/rosout_agg", "rosout", "rosout", "rosout.log", "ROSOUT_DISABLE_FILE_LOGGING", "True", "rosout.log", "topic", "/rosout/omit_topics", "rosout"]},
{"url": "https://wiki.ros.org/stdr_samples", "package": "stdr_samples", "package_summary": ["Provides sample codes to demonstrate STDR simulator functionalities."], "package_details": ["\n", "\n", "The ", " package provides code and launchers to demonstrate the ", " functionalities. The available samples follow. "], "package_code": ["rosrun stdr_obstacle_avoidance robotX laser_Y"]},
{"url": "https://wiki.ros.org/rosh_visualization", "package": "rosh_visualization", "package_summary": ["\n\n     ROSH plugin for the visualization stack.\n\n  "], "package_details": ["\n", " ", "\n", ": ", " "], "package_tt": ["show(cameras.camera)", "rviz/image_view", "cameras"]},
{"url": "https://wiki.ros.org/rosnode", "package": "rosnode", "package_summary": ["rosnode is a command-line tool for displaying debug information\n    about ROS ", ",\n    including publications, subscriptions and connections. It also\n    contains an experimental library for retrieving node\n    information. This library is intended for internal use only."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " is a stable command-line tool within the ROS core toolchain. No major feature development is currently scheduled for this tool. ", "The ", " command-line tool displays information about ROS ", ". The currently supported commands are: ", "IMPORTANT: ", " is not guaranteed to succeed. If a node is hung or set to \"respawn\" in ", ", it may either fail to die or may quickly reappear. ", "IMPORTANT: ", " was meant as a temporary solution and its use was not encouraged in normal operation. Its benefit is aesthetic and it has the downside of potentially unregistering functioning nodes. ", ". "], "package_tt": ["rosnode", "info\u00a0<node-name>", "rosnode\u00a0kill", "kill\u00a0<node-name>...", "kill", "kill\u00a0-a", "kill\u00a0--all", "list", "list\u00a0<namespace>", "/namespace", "list\u00a0-u", "list\u00a0-a", "list\u00a0--all", "machine\u00a0<machine-name>", "machine", "ping\u00a0<node-name>", "ping\u00a0--all", "-c", "-a", "ping\u00a0-c\u00a0COUNT", "--all", "rosnode\u00a0cleanup", "cleanup", "rosnode"], "package_code": ["rosnode info    print information about node\n", "rosnode kill    kill a running node\n", "rosnode list    list active nodes\n", "rosnode machine list nodes running on a particular machine or list machines\n", "rosnode ping    test connectivity to node\n", "rosnode cleanup purge registration information of unreachable nodes", "$ rosnode info /node_name", "$ rosnode kill rosout add_two_ints_server", "$ rosnode kill\n", "1. /rosout\n", "\n", "Please enter the number of the node you wish to kill.\n", "> ", "$ rosnode list", "$ rosnode list /my_ns", "$ rosnode list -u", "$ rosnode list -a", "$ rosnode machine ninja.local\n", "/talker-ninja.local-72266-1257921234733\n", "/rosout\n", "/listener-ninja.local-72615-1257921238320", "$ rosnode ping /node_name", "$ rosnode ping --all", "$ rosnode ping -c 4 rosout\n", "rosnode: node is [/rosout]\n", "pinging /rosout with a timeout of 3.0s\n", "xmlrpc reply from http://ann:46635/     time=1.195908ms\n", "xmlrpc reply from http://ann:46635/     time=1.123905ms\n", "xmlrpc reply from http://ann:46635/     time=1.144886ms\n", "xmlrpc reply from http://ann:46635/     time=1.137018ms\n", "ping average: 1.150429ms", "$ rosnode cleanup"]},
{"url": "https://wiki.ros.org/sr_edc_launch", "package": "sr_edc_launch", "package_summary": ["\n\n    Package with launch files to start the needed nodes for the Shadow Robot EtherCAT hand.\n\n  "], "package_details": ["\n", "This package contains the main launch files used to start the etherCAT Hand ROS driver. For more information on how to start the interface, please go to the ", ". "]},
{"url": "https://wiki.ros.org/nextage_ik_plugin", "package": "nextage_ik_plugin", "package_summary": ["IKFast package for NEXTAGE Open"], "package_details": ["See ", " tutorial for the usage of this package. "]},
{"url": "https://wiki.ros.org/asr_lib_ism", "package": "asr_lib_ism", "package_summary": ["This package contains the ROS-independent library which provides the actual scene-recognition functionality of Implicit Shape Model (ISM) trees. It is referred to both by asr_ism for Passive Scene Recognition and by asr_recognizer_prediction_ism for Active Scene Recognition."], "package_details": [" ", "\n", "\n", "\n", " Provides an interface to store sets of  objects to a sqlite database. Each set of objects represents a  configuration of objects for a certain scene. ", "The Trainer and the CombinatorialTrainer  are interchangeable, both create a scene model represented by an ISM  from the object poses stored in the recorded database and write it into a  sqlite database. The ISM created by the CombinatorialTrainer should have a shorter computing time when it comes to recognizing a scene compared to the one created by the Trainer. ", "Given a set of objects, the Recognizer calculates the  most likely scenes that those objects are part of. These calculations  use the scene models created by the Trainer/CombinatorialTrainer. ", "\n", "Delete the recordings or the models or both from the database. ", "Merge multiple databases into one. ", " Rotate the pose of objects which are determined by a marker e.g. ", ". ", " Generates additional recording data  between objects by interpolating the pose of two objects between  consecutive recorded object sets. ", " Transform the absolute pose of an entire scene relative to a world coordinate frame. ", " Rotate Objects in the  database which are rotation invariant to the y-Axis around this y-Axis  to a given direction. As result these objects get distinct object poses. ", "\n", "\n", "\n", "- Stores the representing name for a pattern. ", " - Stores a recorded object set at a point in time for a certain pattern. ", " ", " - Stores the object estimation pose obtained from a object recognizer during the recording process. ", " ", " - Stores the object estimation meta-data obtained from an object recognizer during the recording process. ", "\n", " - Stores trained patterns. ", "- Store all objects which appeared while training the model. ", " - Stores the votes generated by the trainer. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " Include ", " ", " Create a new Recorder instance: ", " Insert objects of a recorded object configuration into the database: ", "\n", " Include ", " ", " Create a new Trainer instance: ", "Train ism for all patterns inside the database: ", "Train ism only for the given pattern (patternName): ", "Before using the trainPattern method, the training parameters  should be set. An example how to set those parameters can be found at asr_ism/src/trainer.cpp ", "\n", " Include ", " ", " Create a new CombinatorialTrainer instance: ", "Train ism for all patterns inside the database: ", "\n", " Include ", " ", " Create a new ", " instance: ", "Recognize most likely pattern for a given object configuration: ", "\n", "This package contains the ROS-independent library which provides the actual scene-recognition functionality of Implicit Shape Model (ISM) trees. It is referred to both by ", " for Passive Scene Recognition and by ", " for Active Scene Recognition. ", "XML is used to represent a scene, a pattern or just a set of objects for convenient use in simulation or to just store a certain configuration of objects for further use. E.g. use the XML to publish the contained object-set as recognized object estimations with the provided tool of the ", " package. ", "This package only provides the library without any nodes, however the package ", " implements nodes for the actual usage of the recognition system.  "], "package_code": ["<Objects>\n", "\n", "  <Object type=\"\" id=\"\" mesh=\"\" angles=\"quaternion\"> x, y, z, qw, qx, qy, qz</Object>\n", "  <Object type=\"\" id=\"\" mesh=\"\" angles=\"euler\"> x, y, z, alpha, beta, gamma</Object>\n", "\n", "  ...\n", "\n", "</Objects>", "Recorder(const std::string& dbfilename)", "void insert(const ObjectSetPtr& set, const std::string& patternName)", "Trainer(std::string dbfilename, bool dropOldModelTables)", "void trainPattern()", "void trainPattern(const std::string& patternName)", "CombinatorialTrainer(CombinatorialTrainerParameters params)", "std::map<std::string, std::pair<double, TreePtr> > learn()", "Recognizer(const std::string& dbfilename, double bin_size, double maxProjectionAngleDeviation, int raterType = 0)", "const std::vector<RecognitionResultPtr> recognizePattern(const ObjectSetPtr& _objectSet_, const double filterThreshold = 0.0, const int resultsPerPattern = -1, const std::string targetPatternName == \"\")"]},
{"url": "https://wiki.ros.org/ndt_registration", "package": "ndt_registration", "package_summary": ["\n\n    Contains a new implementation of 3D NDT registration. \n    Used to find the relative positions of two point clouds.\n\n  "], "package_details": ["\n", "\n", "\n", "This package implements point cloud registration, using the Normal Distributions Transform. Two basic classes are available - point to distributiuon registration (NDTMatcherP2D) and distribution to distribution registration (NDTMatcherD2D). The point to distribution algorithm is described ", " and the distribution to distribution ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/network_autoconfig", "package": "network_autoconfig", "package_summary": ["ROS Networking Autoconfiguration"]},
{"url": "https://wiki.ros.org/wire", "package": "wire", "package_summary": ["The wire meta package is implements a framework that \n     generates and maintains one consistent world state estimate based \n     on object detections. It solves the data association problem by \n     maintaining multiple hypotheses and facilitates tracking of various\n     object attributes. The state estimators used for estimation and the\n     probabilistic models used for association can be configured."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "J. Elfring, S. van den Dries, M.J.G. van de Molengraft, M. Steinbuch, Semantic world modeling using probabilistic multiple hypothesis anchoring, Robotics and Autonomous Systems, Volume 61, Issue 2, February 2013, Pages 95-105, (", ") ", "To install the ", " software, clone the source into your workspace: ", "We have created a set of ", " explaining how to use, tune and interpret the world model and the resulting world state estimate. "], "package_code": ["git clone https://github.com/tue-robotics/wire.git", "catkin_make"]},
{"url": "https://wiki.ros.org/maxwell_moveit_config", "package": "maxwell_moveit_config", "package_summary": ["maxwell_moveit_config"]},
{"url": "https://wiki.ros.org/maggie_ir_controller_msgs", "package": "maggie_ir_controller_msgs", "package_summary": ["ir_controller messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_ir_controller_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_ir_controller_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/rail_ceiling", "package": "rail_ceiling", "package_summary": ["Overhead Camera System for Tracking AR Tags"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Rail_ceiling is an overhead camera system for tracking the positions of obstacles in a closed space and publishing maps containing those obstacles for use in robot navigation. Rail_ceiling supports multiple cameras and can publish multiple maps with different obstacle footprints. Obstacle tracking is accomplished using ar tags and the ", " ros package.  ", "The ", " node will run an automatic calibration procedure where each camera will take sample poses of an associated marker of known position in the environment.  Once a sufficient number of samples have been taken for each camera, the transforms will be calculated and written to the ", " file in your home directory, and must then be copied into the ", " directory of the ", " package if you wish to use it. ", "The ", " node provides a method of calibrating the camera transforms from a marker placed on a localized mobile robot, such as the CARL platform.  This calibration method is executed as follows: ", "Next, the robot must be driven into the field of view of a camera to be calibrated.  Once the robot is in the camera's field of view and it is confirmed to be accurately localized, publishing to the ", " topic with the id number of the camera to be calibrated replacing [camera_id]: ", "Once sufficient samples are collected for all of the cameras, the transforms will be calculated and written to the ", " file in your home directory, and must then be copied into the ", " directory of the ", " package if you wish to use it. ", "The transforms can also be edited directly in the human-readable urdf file, ", ".  This should only be done if the camera positions and orientations can be accurately measured. ", "Furniture footprints and marker information can be configured in the ", " and ", " file in the ", " directory.  The ", " configuration file defines general pieces of furniture with convex polygon footprints for localization and navigation, and the ", " configuration file defines instances of furniture with attached markers and their associated poses. ", "To add a new type of furniture, simply add a new entry to the ", " file.  Each entry must have a name (for identifying the type of furniture) a localization footprint (a set of convex polygons that a laser scanner will detect), and a navigation footprint (a set of convex polygons that represent the full area occupied by the piece of furniture that should be avoided during navigation).  The entry format is as follows: ", "Points composing the polygons are defined with respect to the center of the piece of furniture, according to a coordinate system with x increasing right, y increasing forward, and z increasing up.  In practice, the reference frame's position does not have to be at the center of the furniture piece, as long as it is consistent with the reference frame defined for instances of the furniture type in the ", " file. ", "Each piece of furniture in th eenvironment must have its own entry in the ", " file.  Each entry consists of a required type (corresponding with the furniture names defined in ", "), an optional initial_pose (an initial pose for the piece of furniture in the global coordinate frame), and a required set of markers.  Markers are defined with the unique id used to generate them, and the pose of the marker with respect to the furniture reference frame.  The entry format is as follows: ", "The main functionality of the ", " package is furniture tracking.  This can be launched with: ", "Please send bug reports to the ", ". "], "package_tt": ["ceiling_cam_tracker_[i]/ar_pose_marker", "fixed_frame", "string", "camera_frame_id_prefix", "string", "num_cameras", "int", "num_samples", "int", "ceiling_cam_[i]_pos_x", "double", "ceiling_cam_[i]_pos_y", "double", "ceiling_cam_[i]_pos_z", "double", "ceiling_cam_[i]_rot_x", "double", "ceiling_cam_[i]_rot_y", "double", "ceiling_cam_[i]_rot_z", "double", "ceiling_cam_[i]_rot_w", "double", "ceiling_cam_tracker_[i]/ar_pose_marker", "start_calibration", "num_cameras", "int", "calibration_marker_id", "int", "ceiling_cam_tracker_[i]/ar_pose_marker", "start_calibration", "furniture_layer/update_obstacles", "furniture_tracker/get_all_poses", "num_marker_topics", "int", "read_initial_poses", "bool", "markers_config", "string", "furniture_footprints_config", "string", "calibration", "ceiling.urdf.xacro", "urdf", "rail_ceiling", "calibration_from_carl", "start_calibration", "ceiling.urdf.xacro", "urdf", "rail_ceiling", "urdf/ceiling.urdf.xacro", "furniture_footprints.yaml", "markers.yaml", "config", "furniture_footprints.yaml", "markers.yaml", "furniture_footprints.yaml", "markers.yaml", "markers.yaml", "furniture_footprints.yaml", "rail_ceiling"], "package_code": ["cd /(your catkin workspace)/src\n", "git clone https://github.com/WPI-RAIL/rail_ceiling.git\n", "cd ..\n", "catkin_make", "roslaunch rail_ceiling calibration.launch", "roslaunch rail_ceiling view_calibration.launch", "roslaunch rail_ceiling cameras.launch\n", "roslaunch rail_ceiling ar_trackers.launch marker_size:=12.0\n", "roslaunch rail_ceiling calibration_from_carl.launch", "rostopic pub /start_calibration std_msgs::Int16 \"data: [camera_id]\"", "- name: furniture_name\n", "  localization_footprint:\n", "    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]\n", "    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]\n", "    - ...\n", "  navigation_footprint:\n", "    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]\n", "    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]\n", "    - ...", "- type: furniture_name\n", "  initial_pose: [x0, y0, theta0]\n", "  markers:\n", "    - id: 1\n", "      x: x1\n", "      y: y1\n", "      theta: theta1\n", "    - id: 2\n", "      x: x2\n", "      y: y2\n", "      theta: theta2\n", "    - ...", "roslaunch rail_ceiling ceiling_description.launch", "roslaunch rail_ceiling furniture_tracker.launch", "roslaunch rail_ceiling cameras.launch\n", "roslaunch rail_ceiling ar_trackers.launch"]},
{"url": "https://wiki.ros.org/xbot_description", "package": "xbot_description", "package_summary": ["The urdf model description package for xbot robot."], "package_details": ["\n"], "package_code": ["roslaunch xbot_description display.launch", "roslaunch xbot_description gazebo.launch"]},
{"url": "https://wiki.ros.org/stop_base", "package": "stop_base", "package_summary": ["Stop base controller for any robot using the cmd_vel interface."], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/rtt_trajectory_msgs", "package": "rtt_trajectory_msgs", "package_summary": ["Provides an rtt typekit for ROS trajectory_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/trajectory_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/turtlebot3_panorama", "package": "turtlebot3_panorama", "package_summary": ["This app utilises pano_ros for taking snapshots and stitching them together to create panorama pictures."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["odom", "camera/rgb/image_raw", "cmd_vel", "panorama", "camera_info", "image/compressed", "image/compressed", "camera/rgb/image_raw"]},
{"url": "https://wiki.ros.org/teleop_twist_keyboard_cpp", "package": "teleop_twist_keyboard_cpp", "package_summary": ["Generic keyboard teleop for twist robots (in C++)! Based off of the teleop_twist_keyboard Python ROS node."], "package_details": ["\n", "\n", "\n", "\n", "C++ Implementation of the Generic Keyboard Teleop for ROS: ", " "], "package_code": ["$ git clone https://github.com/methylDragon/teleop_twist_keyboard_cpp.git\n", "$ cd ..\n", "$ catkin_make\n", "\n", "$ source devel/setup.bash", "# In one terminal, run\n", "$ roscore\n", "\n", "# In another terminal, run\n", "$ rosrun teleop_twist_keyboard_cpp teleop_twist_keyboard\n", "\n", "# If you want to see the outputs, check the /cmd_vel topic\n", "$ rostopic echo /cmd_vel", "Reading from the keyboard  and Publishing to Twist!\n", "---------------------------\n", "Moving around:\n", "   u    i    o\n", "   j    k    l\n", "   m    ,    .\n", "\n", "For Holonomic mode (strafing), hold down the shift key:\n", "---------------------------\n", "   U    I    O\n", "   J    K    L\n", "   M    <    >\n", "\n", "t : up (+z)\n", "b : down (-z)\n", "\n", "anything else : stop\n", "\n", "q/z : increase/decrease max speeds by 10%\n", "w/x : increase/decrease only linear speed by 10%\n", "e/c : increase/decrease only angular speed by 10%\n", "\n", "CTRL-C to quit"]},
{"url": "https://wiki.ros.org/ros_canopen", "package": "ros_canopen", "package_summary": ["A generic canopen implementation for ROS"], "package_details": ["\n", " ", " "]},
{"url": "https://wiki.ros.org/pr2_make_a_map_app", "package": "pr2_make_a_map_app", "package_summary": ["\n   Make maps using the PR2 robot.\n  "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/steer_drive_controller", "package": "steer_drive_controller", "package_summary": ["Controller for a steer drive mobile base."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 50.0) ", "\n", " (", ", default: base_link) ", "\n", " (", ", default: 1.0) ", "\n", " (", ", default: false) ", "\n", " (", ") ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "An example of using the packages can be seen in ", ". ", "The controller inherits ", " to work with wheel joints through a ", " interface for a linear wheel and a ", " interface for a front steer wheel, which is the the most basic configuration for the steer driving mechanism. ", "If you want ", " to show states of robot's actual joint interfaces' ", " through ", " and ", ", you need to convert the two interfaces of ", " to your robot's specific ones via ", " or RobotHWSim (generally used for ", "). This is because the controller only update it's basic interfaces mentioned in the previous section. ", "The controller main input is a ", " topic in the namespace of the controller. ", "An example for usage of ", " with ", " can be grabbed from ", ". ", "We developped a general RobotHWSim plugin for usage of ", ". You can get the plugin from ", " and also see an example of application on ", ". ", "We also provide a recovery behavior plugin of ", " specifically desigined for steer mechanism base robots in ", ". Feel free to see ", " to learn how to use it. "], "package_tt": ["steer_drive_controller", "cmd_vel", "odom", "/tf", "rear_wheel", "string", "front_steer", "string", "pose_covariance_diagonal", "double[6]", "twist_covariance_diagonal", "double[6]", "publish_rate", "double", "cmd_vel_timeout", "double", "base_frame_id", "string", "odom_frame_id", "string", "enable_odom_tf", "bool", "wheel_separation_h_multiplier", "double", "wheel_radius_multiplier", "double", "steer_pos_multiplier", "double", "linear/x/has_velocity_limits", "bool", "linear/x/max_velocity", "double", "linear/x/min_velocity", "double", "linear/x/has_acceleration_limits", "bool", "linear/x/max_acceleration", "double", "linear/x/min_acceleration", "double", "linear/x/has_jerk_limits", "bool", "linear/x/max_jerk", "double", "angular/z/has_velocity_limits", "bool", "angular/z/max_velocity", "double", "angular/z/min_velocity", "double", "angular/z/has_acceleration_limits", "bool", "angular/z/max_acceleration", "double", "angular/z/min_acceleration", "double", "angular/z/has_jerk_limits", "bool", "angular/z/max_jerk", "double", "wheel_separation_h", "double", "wheel_radius", "double", "steer_drive_controller"], "package_code": ["mobile_base_controller:\n", "  type: \"steer_drive_controller/SteerDriveController\"\n", "  rear_wheel: 'rear_wheel_joint'\n", "  front_steer: 'front_steer_joint'\n", "  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]", "mobile_base_controller:\n", "  type        : \"diff_drive_controller/DiffDriveController\"\n", "  rear_wheel: 'rear_wheel_joint'\n", "  front_steer: 'front_steer_joint'\n", "  publish_rate: 50.0               # default: 50\n", "  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]\n", "\n", "  # Wheel separation between the rear and the front, and diameter of the rear. \n", "  # These are both optional.\n", "  # steer_drive_controller will attempt to read either one or both from the\n", "  # URDF if not specified as a parameter.\n", "  wheel_separation_h : 1.0\n", "  wheel_radius : 0.3\n", "\n", "  # Wheel separation and radius multipliers for odometry calibration.\n", "  wheel_separation_h_multiplier: 1.0 # default: 1.0\n", "  wheel_radius_multiplier    : 1.0 # default: 1.0\n", "\n", "  # Steer position angle multipliers for fine tuning.\n", "  steer_pos_multiplier       : 1.0\n", "\n", "  # Velocity commands timeout [s], default 0.5\n", "  cmd_vel_timeout: 0.25\n", "\n", "  # Base frame_id\n", "  base_frame_id: base_footprint #default: base_link\n", "\n", "  # Odom frame_id\n", "  odom_frame_id: odom\n", "\n", "  # Velocity and acceleration limits\n", "  # Whenever a min_* is unspecified, default to -max_*\n", "  linear:\n", "    x:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.0  # m/s\n", "      min_velocity           : -0.5 # m/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 0.8  # m/s^2\n", "      min_acceleration       : -0.4 # m/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 5.0 # m/s^3\n", "\n", "  angular:\n", "    z:\n", "      has_velocity_limits    : true\n", "      max_velocity           : 1.7  # rad/s\n", "      has_acceleration_limits: true\n", "      max_acceleration       : 1.5  # rad/s^2\n", "      has_jerk_limits        : true\n", "      max_jerk               : 2.5 # rad/s^3"]},
{"url": "https://wiki.ros.org/sr_visualization", "package": "sr_visualization", "package_summary": ["This stack contains the different gui and gui plugins used with the shadow robot stacks."], "package_details": ["\n", " is a package with GUI plugins which can be used to control the different nodes of the ", " stack. The GUI plugins are programmed in Python and can be started from within rqt. A ROS master must be running before starting rqt. ROS master and rqt can be started by simply typing in linux command line: ", " ", "\n", " "], "package_code": ["$ roscore", "$ rqt"]},
{"url": "https://wiki.ros.org/turtlebot3_fake", "package": "turtlebot3_fake", "package_summary": ["Package for TurtleBot3 fake node. With this package, simple tests can be done without a robot.\n    You can do simple tests using this package on rviz without real robots."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "joint_states", "magnetic_field", "tf"]},
{"url": "https://wiki.ros.org/lyap_control", "package": "lyap_control", "package_summary": ["A node to control nonlinear dynamic systems"], "package_details": ["\n", " ", "\n", "\n", "\n", "The lyap_control package provides a sophisticated and relatively easy-to-use control node. It can handle regulation or tracking problems of any order and with any number of inputs... from simple first order dynamic systems where a PID controller would typically be used... up to complex, large, higher-order systems. There is also a ", " which can be used to visualize, tune, and simulate the control algorithm beforehand. The default example of the MATLAB toolbox shows the simultaneous tracking of seven motors. The theory behind the algorithm is explained ", ". ", "(You may have to do this every time you open a new terminal window, or add this line to your bashrc: ", ") ", "This launches a simulation of a 2nd-order system with (1,-2) setpoints. The displayed ", " is the sum-of-squares of the error for all states (it should drop exponentially). ", "You may wish to tune the controller at this point. You can adjust its 'aggressiveness', called ", ", in controller.h. Generally a more negative value performs better, unless the time step is too small and it becomes unstable. The saturation limits on the control effort (maximum and minimum) and the controller's model of the system are also adjusted here. ", "The time step for the simulation is adjusted as the variable ", " in second_order_plant_header.h. A smaller time step will perform better. ", "To demonstrate how to switch to a different dynamic system, a first-order single-input example is included (", "). Here are the changes that must be made to control this other system: ", "1. In ", ", change ", " and ", " to one-vectors since there is one input now. ", "2. Edit the model definition in ", " to update the controller's model of the system. Comment the second equation so there is just one state variable ", "3. Since there are fewer states and inputs, the messages that the nodes pass must be shorter. In ", ", update ", " to a 1-vector. In ", ", update ", " and ", " to 1-vectors. ", "If you wish to change the initial conditions or the setpoints, or even make a time-varying setpoint, you can do so in ", ". If you want more aggressive gain, again, change ", " in ", " ", "In general, the best results are achieved with a very high control rate and a very large 'gain.' Set the loop rate of your plant and the controller as fast as the hardware will allow, then set the gain (a.k.a. ", ") as high as stability allows. These changes are made in ", " "], "package_code": ["$ mkdir -p ~/Desktop/catkin_ws/src\n", "$ cd ~/Desktop/catkin_ws/src\n", "$ catkin_init_workspace", "$ git clone https://bitbucket.org/AndyZe/lyap_control.git\n", "$ cd ..", "$ catkin_make", "$ source devel/setup.bash", "$ roslaunch lyap_control lyap_control.launch", "$ roscore\n", "$ rosrun lyap_control controller (publishes data on the control_effort topic)\n", "$ rosrun lyap_control second_order_plant (publishes data on the state topic)", "$ catkin_make", "$ roscore", "$ rosrun lyap_control controller", "$ rosrun lyap_control first_order_plant"]},
{"url": "https://wiki.ros.org/spatial_world_model", "package": "spatial_world_model", "package_summary": ["Spatial World Model for Object Tracking"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "As a basic example for the types of end-user interfaces that can be created with the Spatial World Model, we look at the Map annotation interface. Information on this interface can be found on the ", ". Below is a video demonstrating its capabilities: ", "The following steps are written for ", " but apply to most Linux systems. ", "To begin, we must install ", " and the Python libraries that will talk to it. To do so, run the following command: ", "Finally, we are able to install the database schema. This is provided in a script found in the ", " package. This script can be used to both install a new database and to update an existing one. ", "In many cases, you will be installing the Spatial World Model database on a central server so that multiple clients (and robots) can talk to it. As of now, the ROS nodes communicate via SQL to the database; however, due to security risks this will eventually be changed. To allow remote connections, we must modify the configuration scripts on the system. Using your choice of editor, modify ", " with root privileges and add the following line: ", "Next, modify ", " with root privileges and add the following line: ", "At its core, the Spatial World Model is designed to be a persistent, multi-robot model to keep track of both the robot's working memory as well as keeping track of properties, affordances, and activities that can be associated with each object. To manage persistence, the world model is stored in a ", " database  At a high level, currently the Spatial World Model allows for two sets of entities: a ", " and a ", ". ", "A ", ", defined in the ", " message, can be thought of as a robot's working memory. At a basic level, such an entity contains a relative pose in the world with associated tags and timestamps. These entities describe a particular, specific instance of an object in the world (e.g., the cup sitting on the desk in the conference room). Each instance is linked to a single ", " which contains a set of spatial descriptors for the object (e.g., mesh, bounding box, point-cloud cluster, etc...). Below is a detailed explanation of the fields in the ", ". Note that some fields will be blank depending on the type of object or what you know about the world.  ", "The second implemented entity is the ", ". This entity, defined in the ", " message, contains spatial descriptors of objects in the world. These are shared models that are common between all instances of such an object (e.g., a 3D mesh of the object itself). Each descriptions contains a set of tags and an array of actual ", "s. The genericness of the descriptor model allows for models to come from a variety of sources (point cloud segmentation, 3D model warehouses and databases) with few-to-no restrictions. The main idea is to associate an appropriate ", " and ", " field with each descriptor to determine how the data should be treated. In a sense, the ", " field can be thought up as a non-standard MIME type (PNG, Collada, but also ", " as a type). Future goals of the project set out to create a standard set of accepted type fields. Below is a detailed description of the fields associated with a ", ". ", "The first design decision was to use a ", " database for storage. Given the highly relational components associated with the world model (e.g., ", " and ", "), it made sense to use such a database over other types of databases. For efficiency in searching and storage, the database schema itself is broken into finer grains than the APIs allow for. It is intended that developers make user of these higher-level APIs when dealing with the Spatial World Model as apposed to making raw SQL queries. ", "The current implementation includes several layers of APIs. As mentioned previously, it is not intended for a developer to use the world model by directly making SQL queries. At the lowest level, the ", " Python API should be used. This level of the API is responsible for talking SQL to the world model database and is able to make basic insertion and search queries while maintaining the correct structure. This level of the API allows for non-ROS processes to make use of the world model (another future goal of the project). By using an SQL connection between this library and the database, remote connections can be made and a central database can be used (such as one hosted in the cloud). This, of course, requires your server to allow remote SQL connections which is not ideal. Therefore, future plans hope to create a server-side API to allow for remote queries (think REST as an example but this would require polling). With such an API in place, the interface between the robot or client and the database could be made with this new service. ", "Furthermore, a ", " library is provided in ", " to allow remote web clients to interact with the world model. This API currently uses ", " and ", " to communicate with the world mode; however, as discussed above, the eventual goal is to have a standard server-side API to communicate with directly instead of using ROS. ", "Within ROS, the intended use of the APIs into the world model was to create a series of what are being called listener nodes. Such nodes listen to a set of defined topics, make the appropriate inferences on the information, and update the world model accordingly. Below are three examples included in ", ".  ", "To allow for multiple robots, a notion of namespacing must be kept. To support this feature early on, this information is currently held inside of the ", " of the instance. It is up to the developer to maintain this namespace. For example, the above listeners take an optional argument to define the namespace. If no namespace is given, it will default to the hostname of the machine the node is running on. In most cases, this is good enough since the hostname of the robot is usually a good namepsace. Then, when searching for things like a particular robot, we can do a tag search for ", ". Future improvements should be made to make this clearer and enforce unique namespacing.  ", "One improvement to the current system would be to separate the ", " array into its own separate database. The idea behind properties is to define relationships such as ", " or ", " between entities in the world model. Current thoughts are to point to entries within a graph database. By doing so, powerful search queries to can written such as \"give me all the objects inside the bedroom?\" or \"is the book on my bookshelf?\" in an efficient way.  ", "One large piece of the world model that is missing is the notice of affordances. The goal of the Spatial World Model is to not only keep track of particular instances of objects, but to also manage what types of actions can be taken on certain objects. For example, a door can be opened, a cup can be grasped, and a robot can grasp (assuming it has a gripper, of course). Furthermore, pre-conditions should also be stored here. For example, the cup must be on the table to be picked up (or any number of other conditions). This would rely on the implementation of the graph database described above. These types of attributes should be stored in a separate table in the database and linked to a particular ", ".  ", "In addition to the affordances, a notion of activities, must be stored as well. Such a structure would be used to figure out how to perform such an action on such an object. For example, if you wanted to use a ", " action on a coffee cup, the associated activity would be some action call to a grasping pipeline. Each activity can be thought of as a node with some kind of transition model incorporated to provide feedback and belief states. An updated diagram of the Spatial World Model would be the following: ", "In addition to abstracting out the ", " as defined above, several improvements are needed with respect to the instances. For one, belief states should be associated with most attributes. While the current ", " does allow for this, beliefs about things just as timestamps are just as important.  ", "A second major component is a cleanser process for the database. Currently, descriptions can be linked to multiple instances. This is the main idea behind the descriptions itself. Additionally, these descriptions can potentially contain massive amounts of data (Collada models for example). If there are no longer any instances linked to a given description, it should be removed not only from the database itself, but from the disk as well (since the large data portions are kept in ", ". Care should be taken to ensure thread safety in the removal. ", "Perhaps the largest piece needed in the project is a more robust, efficient, and flexible server-side API for the world model. Currently, the ", " Python API is used by the main ROS node and speaks SQL to the database. For many reasons, security being one, this is not ideal. Efforts should be made to create a server-side API that allows for multiple remote connections to interact with the world model. Not only would this still allow the robots to communicate with the world model, but clients could now directly connect to the world model instead of using ", " as a \"proxy\". While at first glance it may seem appropriate, this API should not be response-based such as a REST API. A more robust socket-level connection should be made to allow for bi-directional communication. By standardizing a server-side interface, we can also create a more powerful query system. The protocol between clients and the server could include things like searching descriptions or descriptors without having to return the data associated with them. This allows clients to subscribe to changes in the world model without the need of polling. A diagram of the updated API levels is shown below. ", "Discussions and contributions are welcome! To get involved, check out the ", " for current feature requests and discussions.  ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["spatial_world_model", "/etc/postgresql/9.1/main/pg_hba.conf", "/etc/postgresql/9.1/main/postgresql.conf", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "instance_id", "name", "creation", "update", "expected_ttl", "perceived_end", "source", "origin", "creator", "pose", "frame_id", "instance_id", "description_id", "WorldObjectDescription", "properties", "on(45)", "tags", "WorldObjectDescription", "Discriptor", "type", "ref", "type", "nav_msgs/OccupancyGrid", "WorldObjectDescription", "description_id", "name", "descriptors", "type", "data", "ref", "tags", "tags", "WorldObjectInstance", "WorldObjectDescription", "JavaScript", "map_listener", "/map", "map", "robot_pose_listener", "robot_pose_listener", "/robot_pose", "/initpose", "tags", "[\"robot\",\u00a0\"myRobotName\"]", "properties", "on", "in", "WorldObjectDescription", "pickup", "properties", "pose"], "package_code": ["sudo apt-get install git postgresql python-psycopg2", "sudo -u postgres createdb world_model", "sudo -u postgres createuser -D -A -P <username>", "\n", "\n", "\n", "\n", "\n", "\n", "host     world_model     <username>      0.0.0.0/0               md5", "listen_addresses = '*'", "sudo service postgresql restart"]},
{"url": "https://wiki.ros.org/imu_handler", "package": "imu_handler", "package_summary": ["The imu_handler package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/stdr_msgs", "package": "stdr_msgs", "package_summary": ["Provides msgs, services and actions for STDR Simulator."], "package_details": ["\n", " package provides the essential ROS messages, services and actions for the ", " to operate. ", "Newly proposed, mistyped, or obsolete package. Could not find package \"stdr_msgs\" in rosdoc: /home/rosbot/docs/api/stdr_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/staubli_val3_driver", "package": "staubli_val3_driver", "package_summary": ["\n     ROS-Industrial VAL3 driver for interfacing with Staubli CS8 robot controllers.\n   ", "\n     This package is part of the ROS-Industrial program and contains a VAL3\n     application and libraries that implement an industrial_robot_client\n     compatible server program.\n   ", "\n     See the readme and wiki for more information.\n   "], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This is a VAL 3 based driver for use with CS8 controllers and Staubli 6-axis manipulators. See the ", " for more information. ", "For the generic ROS-Industrial tutorials, please see the ROS-Industrial ", ". ", "For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "]},
{"url": "https://wiki.ros.org/turtlebot_exploration_3d", "package": "turtlebot_exploration_3d", "package_summary": ["Autonomous Exploration package for a Turtulebot equiped with RGBD Sensor(Kinect, Xtion)"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Please follow the turtlebot network ", " to setup network between turtlebot and remote PC. "], "package_tt": ["tf", "/camera/depth_registered/points", "octomap_3d"], "package_code": ["@inproceedings{bai2016information,\n", "  title={Information-theoretic exploration with Bayesian optimization},\n", "  author={Bai, Shi and Wang, Jinkun and Chen, Fanfei and Englot, Brendan},\n", "  booktitle={Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},\n", "  pages={1816--1822},\n", "  year={2016},\n", "  organization={IEEE}\n", "}", "@inproceedings{bai2015inference,\n", "  title={Inference-Enabled Information-Theoretic Exploration of Continuous Action Spaces},\n", "  author={Bai, S. and Wang, J. and Doherty, K. and Englot, B.},\n", "  booktitle={International Symposium of Robotics Research},\n", "  year={2015}\n", "}", "sudo apt-get install ros-indigo-octomap*", "git clone https://github.com/RobustFieldAutonomyLab/turtlebot_exploration_3d.git", "catkin_make", "sudo apt-get update", "sudo apt-get install ros-indigo-turtlebot-exploration-3d", "$ roslaunch turtlebot_exploration_3d minimal_explo.launch\n", "$ roslaunch turtlebot_exploration_3d turtlebot_gmapping.launch\n", "$ rosrun turtlebot_exploration_3d turtlebot_exploration_3d", "roslaunch turtlebot_exploration_3d exploration_rviz.launch"]},
{"url": "https://wiki.ros.org/tello_driver", "package": "tello_driver", "package_summary": [">This package provides a ROS interface for the TelloPy library. Development of this ROS package pursues not to modify the TelloPy library, instead apply any modification or addition to the ros_driver package in an encapsulated manner."], "package_details": ["Use GitHub to ", ". [", "]", "\n  ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Communicating with the Tello drone can be done either using official ", " or one of the unofficial libraries. The unofficial libraries originated from the reverse-engineering the raw packages broadcasted by the Tello. This ROS package is build on top of the unofficial ", " library. The ", " library is used at this moment since it offers more functionalities than the official ", " or any other unofficial library. ", "Developing of the tello_driver ROS package is inspired by ", ", which by now diverged considerately from the original work. Furthermore, development of this ROS package pursues not to modify the ", " library, but instead apply any modification or addition to the ros_driver package in an encapsulated manner. This prevents breaking functionalities when updating the ", " library. ", "Main node running as interface for the ", " library ", "Converting gamepad input controls from ", " to commands for ", " ", "Receive input from gamepad controller and publish into ", " message "], "package_tt": ["TELLO_XXXXXX", "/tello/cmd_vel", "/tello/emergency", "/tello/fast_mode", "/tello/flattrim", "/tello/flip", "/tello/land", "/tello/palm_land", "/tello/takeoff", "/tello/throw_takeoff", "/tello/camera/camera_info", "/tello/image_raw", "/tello/imag/raw/h264", "/tello/odom", "/tello/imu", "/tello/status", "~/tello_driver_node/connect_timeout_sec", "~/tello_driver_node/fixed_video_rate", "~/tello_driver_node/local_cmd_client_port", "~/tello_driver_node/local_vid_server_port", "~/tello_driver_node/stream_h264_video", "~/tello_driver_node/tello_cmd_server_port", "~/tello_driver_node/tello_ip", "~/tello_driver_node/vel_cmd_scale", "~/tello_driver_node/video_req_sps_hz", "~/tello_driver_node/altitude_limit", "~/tello_driver_node/attitude_limit", "~/tello_driver_node/low_bat_threshold", "joy_node", "tello_driver_node", "/joy", "/tello/agent_cmd_vel_in", "/tello/cmd_vel", "/tello/emergency", "/tello/fast_mode", "/tello/flattrim", "/tello/flip", "/tello/land", "/tello/palm_land", "/tello/takeoff", "/tello/throw_takeoff", "sensor_msgs/Joy", "/joy", "~/joy_node/deadzone", "~/joy_node/dev", "tello_driver_node"], "package_code": ["$ sudo apt install ros-kinetic-tello-driver", "$ cd <CATKIN_WS/SRC>", "$ git clone --recursive https://github.com/appie-17/tello_driver.git", "$ cd ..", "$ catkin_make", "$ source devel/setup.bash", " $ roslaunch tello_driver tello_node.launch", "$ pip install av --user", "$ sudo add-apt-repository ppa:jonathonf/ffmpeg-3   \n", "$ sudo apt update && sudo apt install ffmpeg"]},
{"url": "https://wiki.ros.org/tf_conversions", "package": "tf_conversions", "package_summary": ["This package contains a set of conversion functions to convert\ncommon tf datatypes (point, vector, pose, etc) into semantically\nidentical datatypes used by other libraries. The conversion functions\nmake it easier for users of the transform library (tf) to work with\nthe datatype of their choice. Currently this package has support for\nthe Kinematics and Dynamics Library (KDL) and the Eigen matrix\nlibrary. This package is stable, and will get integrated into tf in\nthe next major release cycle (see roadmap)."], "package_details": ["\n", "\n", "We plan to replace this package with a more advanced template-based data conversion package, as part of the redesign of the ", " API. See the ", " for more details. "]},
{"url": "https://wiki.ros.org/win_appupdater", "package": "win_appupdater", "package_summary": ["\n\n     win_appupdater\n\n  "], "package_details": ["Some scripts to help out with setting up the ", " repositories, namely key signing. "]},
{"url": "https://wiki.ros.org/katana_driver", "package": "katana_driver", "package_summary": ["This stack contains all descriptions, drivers and bringup facilities for Neuronics Katana 450 arm."], "package_details": ["\n", "\n", "\n", ": This will move the robot arm without any obstacle avoidance whatsoever, so if you run this on a physical arm, make sure the workspace of the robot is clear. ", "\n", " has to be configured individually for each robot. At Osnabr\u00fcck University, we have Calvin, a robot that consists of a Volksbot base and a Katana arm. You can see instructions how to run the full ", " stack in Gazebo, including motion planning, inverse kinematics, collision environment etc. on the ", " wiki page. ", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "You should set your Katana type as an environment variable, for example in your ", "/", ". At the moment, only the Katana 450 6M90A and the Katana 300 6M180 (experimental) are supported. Include one of the following lines: "], "package_tt": [".bashrc", ".zshrc"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-katana-driver", "export KATANA_TYPE=\"katana_300_6m180\"\n", "export KATANA_TYPE=\"katana_450_6m90a\"", "roslaunch katana katana.launch", "roslaunch katana_arm_gazebo katana_arm.launch", "roslaunch katana_teleop katana_teleop_key.launch", "roslaunch katana_tutorials follow_joint_trajectory_client.launch"]},
{"url": "https://wiki.ros.org/win_boost", "package": "win_boost", "package_summary": ["\n\n  Scripts to help download, patch and compile cmake boost.\n\n  "]},
{"url": "https://wiki.ros.org/canopen_chain_node", "package": "canopen_chain_node", "package_summary": ["Base implementation for CANopen chains node with support for management services and diagnostics"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This packages contains the ROS interface for ", " and ", ". It can be used as a stand-alone ROS node, but as well as a base class for profile specific ROS interfaces, e.g. ", ". ", "The bus settings consists of a CAN interface (", ") and the shared bus settings for ", ". ", "Each node (or in the defaults) can be passed a publish parameter with a list of object names. The topic types correspond to the object types, e.g. UNSIGNED16 to ", ". It is meant for debugging or for simple CANopen interfaces, since it blocks the control loop. Each entry can have an exclamation mark appended that forces the driver to reread the object form the node in each step. ", "The ", " can be passed the diagnostic_period parameter in fractional seconds. ", "This package provides a ", " class that implements a ", " interface and takes care of the parameter parsing and the life-cycle. ", "It can be customized via its virtual interface, especially with ", " "], "package_tt": ["/diagnostics", "driver/init", "driver/halt", "driver/recover", "driver/shutdown", "driver/get_object", "driver/set_object", "~diagnostic_period", "double", "~bus", "struct", "~sync", "struct", "~heartbeat", "struct", "~defaults", "struct", "~nodes", "struct/list", "canopen::RosChain", "canopen::LayerStack", "RosChain::nodeAdded"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/turtlebot_viz", "package": "turtlebot_viz", "package_summary": ["turtlebot_viz", "\n", "This stack contains visualization tools for TurtleBot.   ", " - a display panel for monitoring the status of a running TurtleBot.  ", " - tools for interacting with the TurtleBot in rviz.  ", "\n", "  "]},
{"url": "https://wiki.ros.org/tuw_marker_filter", "package": "tuw_marker_filter", "package_summary": ["The tuw_marker_filter package"]},
{"url": "https://wiki.ros.org/stereo_wall_detection", "package": "stereo_wall_detection", "package_summary": ["\n    Detects planar structures (e.g., walls) from stereo cameras point clouds (usually generated using a texture projector).\n  "]},
{"url": "https://wiki.ros.org/osg_markers", "package": "osg_markers", "package_summary": ["osg_markers can be used to create Markers geometry in OSG."]},
{"url": "https://wiki.ros.org/turtlebot3_gazebo", "package": "turtlebot3_gazebo", "package_summary": ["Gazebo simulation package for the TurtleBot3"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["scan", "joint_states", "cmd_vel", "/model", "String", "/cmd_vel", "String", "/name", "string"]},
{"url": "https://wiki.ros.org/vicon_bridge", "package": "vicon_bridge", "package_summary": ["\n\n     This is a driver providing data from VICON motion capture systems. It is based on the vicon_mocap package from the starmac stacks. \n     Additionally, it can handle multiple subjects / segments and allows to calibrate an origin of the vehicle(s) as this is somehow tedious with the VICON Tracker.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "All available subjects and segments are recognized automatically and are published as tf transform and ", " as ", ".  ", "Sometimes vicon data is too perfect ", " This motivated ", ", which adds different types of noise, adds delay or reduces the framerate to test how robots work with bad data.  ", "Then run ", " to set the parameters. This is work in progress, suggestions are welcome.  "], "package_tt": ["~stream_mode", "SetStreamMode()", "ServerPush", "ClientPull", "ServerPush", "ClientPull", "vicon/<subject_name>/<segment_name>", "tf_distort", "vicon/<subject_name>/<segment_name>", "vicon/markers", "~/calibrate_segment", "~/grab_vicon_pose", "~stream_mode", "string", "~datastream_hostport", "string", "~tf_ref_frame_id", "string", "~/<subject_name>/<segment_name>/zero_pose/orientation/w", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/x", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/y", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/z", "double", "~/<subject_name>/<segment_name>/zero_pose/position/x", "double", "~/<subject_name>/<segment_name>/zero_pose/position/y", "double", "~/<subject_name>/<segment_name>/zero_pose/position/z", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/w", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/x", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/y", "double", "~/<subject_name>/<segment_name>/zero_pose/orientation/z", "double", "~/<subject_name>/<segment_name>/zero_pose/position/x", "double", "~/<subject_name>/<segment_name>/zero_pose/position/y", "double", "~/<subject_name>/<segment_name>/zero_pose/position/z", "double", "world", "vicon/<subject_name>/<segment_name>", "from", "~tf_ref_frame_id", "~/calibrate_segment"], "package_code": ["roslaunch vicon_bridge vicon.launch", "rosrun vicon_bridge calibrate <subject name> <segment name> <z offset>", "rosrun vicon_bridge tf_distort"]},
{"url": "https://wiki.ros.org/world_canvas_msgs", "package": "world_canvas_msgs", "package_summary": ["World canvas framework messages package"]},
{"url": "https://wiki.ros.org/summit_xl_control", "package": "summit_xl_control", "package_summary": ["This package contains the launch files that load the required controller interfaces for simulation in Gazebo."], "package_details": ["\n", "This package contains the launch and configuration files to spawn the joint controllers with the ROS controller_manager. It allows to launch the joint controllers for the Summit XL (4 axes skid steering + 2 axes ptz), Summit XL OMNI (4 axes skid steering, 4 axes swerve drive), Summit X-WAM (4 axes skid steering, 4 axes swerve drive, 1 linear axis for scissor mechanism). The Summit XL simulation stack follows the gazebo_ros controller manager scheme described in ", " "]},
{"url": "https://wiki.ros.org/rc_visard_description", "package": "rc_visard_description", "package_summary": ["Visualization package for rc_visard"], "package_details": ["\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rmp_msgs", "package": "rmp_msgs", "package_summary": ["The rmp_msgs package defines rmp specific messages such as motor status, audio command, ..."], "package_details": ["\n", " contains message types for interacting with and receiving feedback from a Segway RMP. ", "Newly proposed, mistyped, or obsolete package. Could not find package \"rmp_msgs\" in rosdoc: /home/rosbot/docs/api/rmp_msgs/manifest.yaml "], "package_tt": ["rmp_msgs"]},
{"url": "https://wiki.ros.org/asr_ism_visualizations", "package": "asr_ism_visualizations", "package_summary": ["This package provides visualization logic for ism data, e.g. visualization with marker in rviz."], "package_details": [" ", "\n", ": ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", " ", "\n", " ", " ", " ", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains several classes for visualization of the ISM-datastructures. There are visualizations for the ISM itself, the pose prediction, the voting space, as well as for the reconstruction of the scene and basic visualizations of objects and object-overlays in RVIZ. It doesn't contain any nodes and its more like a library. ", "Normally this package is used by another package like ", " and provides no independent components. ", "Only topics of dynamic reconfigure are being subscribed to. (e. g. ", ") ", "All generated markers of ISM-result-visualization, pose-prediction-visualization and voting-space-visualization are published (by default) on ", " (msg-Type: Markerarray) "]},
{"url": "https://wiki.ros.org/summit_xl_common", "package": "summit_xl_common", "package_summary": ["URDF description of the Summit XL and Summit XL HL, platform messages and other files for simulation."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", ", shared for real robot and simulation.  ", "This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux (", ") so that the final command to the robot can be set by different components (move_base, etc.) "]},
{"url": "https://wiki.ros.org/siftgpu", "package": "siftgpu", "package_summary": ["\n\n    The SiftGPU library is an implementation of SIFT for GPU.\n     \n  "], "package_details": ["\n", " ", " ", " ", " ", " ", "For more details go to the ", " "]},
{"url": "https://wiki.ros.org/tf_keyboard_cal", "package": "tf_keyboard_cal", "package_summary": ["Allows manual control of a TF through the keyboard"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/asr_direct_search_manager", "package": "asr_direct_search_manager", "package_summary": ["This package can be used to generate and manage poses for the direct mode of 3-D\n    object search. The direct mode is used as an opening procedure for Active Scene Recognition.\n    The poses will be generated so that they cover the current environment map.\n    There are different modes to generate these poses. One is based on a grid and a\n    second on a recording of the \"cropbox record\" mode in the asr_state_machine."], "package_details": [" ", "\n", "\n", "\n", " ", "\n", " ", "\n", " ", "\n", ": the ", " which are search at the moment ", "\n", ": ", ": ", " ", "\n", " ", " ", " ", " ", " ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", " ", ": the path to the config.xml generated by the ", ", which contains", " of the grid ", ": the path to the initialized grid, which contains ", " of the grid. Can be generated by the ", " of the asr_state_machine ", "\n", " ", ": camera fiels of view angles (will be used in ", ") ", ": camera fiels of view angles (will be used in ", ") ", ": PTU angle free of vision obstacles (will be used in ", ") ", ": can be 1 for ", ", 2 for ", " and 3 for ", " ", ": the distance function to use. 1 for the service call ", " of ", " (accurate, slow) or 2: the euclidean distance (approximative, fast) ", ": enables the use of prior knwolege by reordering the poses by ", ", so that poses which have a higher chance to detect an object will be taken first. The reordering takes place on the basis of the ", " from the current SQL-database ", ": if the poses of the ", " should be reordered with TSP (", " and ", ") ", ": the threshold when two positions of ", " will be seen as approx equale. This will be used to filter poses depending on already seen viewports taken from other search modes (", ") The threshold for orientation will be /nbv/mHypothesisUpdaterAngleThreshold ", ": remove all ", " which have not at least this number of normals deleted while the poses were recorded ", ": remove all ", " which the robot can not reach (this was need due a bug in asr_next_best_view). It could also be neccessary if the colThresh (asr_next_best_viewparam) has changed since the recording of the poses ", ": concatenate ", " which are approx equale to one with multiple ", " As a result the robot will move less. ", ": the threshold when two ", " of ", " will be seen as approx equale for concatenating two ", " ", "\n", " : ", ", ", ", ", ", ", " ", ": ", ", ", ", ", " ", ": ", " ", "\n", "The ", " is used to manage the views for the direct mode of Active Scene Recognition. The direct search is one of the implemented mode in the 3-D object search we interrelated with scene recognition. The main goal of the direct search is to generate views which should cover the search space, i.e., the robot's environment. It provides a possibility to search for objects without prior knowledge. The direct search can be started in the ", " with mode 1 or 3. ", "One implementation is the grid mode. The grid can be generated with the ", ". The idea is to devide the search space with a grid. The grid is made up of grid points which have an equidistant distance between each. On each grid point the asr_direct_search_manager generates a subset of views which are neccessary to cover the room around that grid point. The number of views depens on the size of the frustum. ", "#goal definition ", ": the command which should be executed: ", "#result definition ", ": the next ", " ", ": the next ", " (belonging to the goalRobotPose) if present ", ": the next pan to take ", ": the next tilt to take ", ": the PTU poses which are left for this goalRobotPose (just as information) ", ": the ", " which are left (just as information) ", ": the remaining distance for the remainingRobotPoses to take (just as information) ", ": if goalRobotPose is the same as the one from the call before ", ": if there are no poses left at all ", ": if there are poses left after this one, which are sorted based on the prior knwoledge ", ": the searchedObjectTypesAndIds which were filtered. It will be filtered, if at the goalCameraPose were already some objects searched or if it is more likely to find a subset of objects ", "This package is part of the active_scene_recognition. When using the ", ", this node will be started automatically. ", "Generating the views for the gridMode: ", " ", "Generating the views for the recordMode: ", " ", "To execute the direct search: ", " "]},
{"url": "https://wiki.ros.org/rviz_backdrop", "package": "rviz_backdrop", "package_summary": ["rviz_backdrop"]},
{"url": "https://wiki.ros.org/kobuki_qtestsuite", "package": "kobuki_qtestsuite", "package_summary": ["An rqt plugin that provides a graphical, interactive testsuite for Kobuki."], "package_details": [" ", " "], "package_code": ["> sudo apt-get install ros-$ROS_DISTRO-kobuki-qtestsuite", "> . /opt/ros/$ROS_DISTRO/setup.bash\n", "> kobuki_qtestsuite"]},
{"url": "https://wiki.ros.org/static_transform_mux", "package": "static_transform_mux", "package_summary": ["A helper node that makes sure everybody knows about all static transforms, even if they are published by multiple publishers."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This ROS node subscribes to ", ", collects all the transforms that are ever published there, and re-sends a ", "message that contains not only the transforms from the last publisher, but all transforms ever encountered. ", "This is a workaround for e.g. ", ", or for anybody else who ", "needs to have multiple static transform publishers in the system. "], "package_tt": ["/tf_static", "/tf_static", "/tf_static", "tf2_msgs/TFMessage", "ready", "std_msgs/Bool", "/tf_static", "~update_only_with_newer", "bool", "False", "~forbidden_callerid_prefix", "str", "None", "None", "/tf_static", "/tf_static", "callerid"]},
{"url": "https://wiki.ros.org/pointcloud_tools", "package": "pointcloud_tools", "package_summary": ["pointcloud_tools"]},
{"url": "https://wiki.ros.org/kni", "package": "kni", "package_summary": ["This package provides the third-party KNI (Katana Native Interface) library for Katana\n     robot arms.\n\n     Instead of using the KNI library directly, the ", "\n     package should be used for communication with the Katana arm."]},
{"url": "https://wiki.ros.org/stdr_gui", "package": "stdr_gui", "package_summary": ["A gui in Qt for visualizing purposes in STDR Simulator."], "package_details": ["\n", "The ", " package provides a Graphical User Interface for ", " developed with QT4. ", "A detailed description of ", " can be examined through the following tutorials: "]},
{"url": "https://wiki.ros.org/bag_tools", "package": "bag_tools", "package_summary": ["ROS tools and scripts related to bagfiles"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Install this package by first cloning and building the srv_tools package, as described on the ", " page. Next, install this package to make it available to rosrun. ", "Parses camera info yaml files and returns the content as sensor_msgs.msg.", ". "], "package_code": ["catkin_make install --pkg bag_tools", "rosrun bag_tools extract_stereo_images OUT_DIR FILETYPE STEREO_BASE_TOPIC BAGFILE [BAGFILE...]", "usage: bag_add_time_offset.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE\n", "                              [INPUT_BAGFILE ...] -of OFFSET -t TOPIC\n", "                              [TOPIC ...]\n", "\n", "Shift the publishing time of given topics in input bagfile.\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -o OUTPUT_BAGFILE     output bagfile\n", "  -i INPUT_BAGFILE [INPUT_BAGFILE ...]\n", "                        input bagfile(s)\n", "  -of OFFSET            time offset to add in seconds\n", "  -t TOPIC [TOPIC ...]  topic(s) to change", "usage: change_camera_info.py [-h] inbag outbag replacement [replacement ...]\n", "\n", "Change camera info messages in a bagfile.\n", "\n", "positional arguments:\n", "  inbag        input bagfile\n", "  outbag       output bagfile\n", "  replacement  replacement in form \"TOPIC=CAMERA_INFO_FILE\", e.g.\n", "               /stereo/left/camera_info=my_new_info.yaml\n", "\n", "optional arguments:\n", "  -h, --help   show this help message and exit", "usage: check_delay.py [-h] inbag [inbag ...]\n", "\n", "Checks the delay in a bagfile between publishing (recording) time and the time\n", "stamp in the header (if exists). Prints out min, max and mean delays.\n", "\n", "positional arguments:\n", "  inbag       input bagfile(s)\n", "\n", "optional arguments:\n", "  -h, --help  show this help message and exit", "usage: cut.py [-h] --inbag INBAG [INBAG ...] --outbag OUTBAG --start START\n", "              --duration DURATION\n", "\n", "Cuts out a section from an input bagfile and writes it to an output bagfile\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  --inbag INBAG [INBAG ...]\n", "                        input bagfile(s)\n", "  --outbag OUTBAG       output bagfile\n", "  --start START         start time\n", "  --duration DURATION   duration of the resulting part", "usage: replace_msg_time_with_hdr.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE\n", "\n", "Create a new bagfile from an existing one replacing the message time for the\n", "header time.\n", "\n", "optional arguments:\n", "  -h, --help         show this help message and exit\n", "  -o OUTPUT_BAGFILE  output bagfile\n", "  -i INPUT_BAGFILE   input bagfile", "usage: add_header_time_offset.py [-h] -o OFFSET -i BAGFILE [BAGFILE ...] -t\n", "                                 TOPIC [TOPIC ...]\n", "\n", "Changes header timestamps using given offset, can change /tf as well.\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -o OFFSET             time offset to add in seconds\n", "  -i BAGFILE [BAGFILE ...]\n", "                        input bagfile(s)\n", "  -t TOPIC [TOPIC ...]  topics to change", "usage: change_frame_id.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE -f FRAME_ID\n", "                          -t TOPIC [TOPIC ...]\n", "\n", "reate a new bagfile from an existing one replacing the frame id of requested\n", "topics.\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -o OUTPUT_BAGFILE     output bagfile\n", "  -i INPUT_BAGFILE      input bagfile\n", "  -f FRAME_ID           desired frame_id name in the topics\n", "  -t TOPIC [TOPIC ...]  topic(s) to change", "<launch>\n", "  <node name=\"img_pub\" pkg=\"bag_tools\" type=\"image_sequence_publisher.py\" output=\"screen\">\n", "    <param name=\"image_dir\" value=\"/tmp/seq\"/>\n", "    <param name=\"file_pattern\" value=\"*.png\"/>\n", "    <param name=\"camera_info_file\" value=\"/tmp/seq/camera_info.yaml\"/>\n", "    <param name=\"frequency\" value=\"10\"/>\n", "  </node>\n", "</launch>", "usage: make_video.py [-h] [--output OUTPUT] [--fps FPS]\n", "                     topic inbag [inbag ...]\n", "\n", "Creates a video from sensor_msgs/Image messages from a bagfile. This script\n", "uses the extract_images binary to extract color images from bagfiles and calls\n", "ffmpeg afterwards to combine them together to form a video. Note that ffmpeg\n", "must be installed on your system.\n", "\n", "positional arguments:\n", "  topic            topic of the images to use\n", "  inbag            input bagfile(s)\n", "\n", "optional arguments:\n", "  -h, --help       show this help message and exit\n", "  --output OUTPUT  name of the output video. Note that the file ending defines\n", "                   the codec to use.\n", "  --fps FPS        frames per second in the output video, as long as codec\n", "                   supports this"]},
{"url": "https://wiki.ros.org/rail_pick_and_place_tools", "package": "rail_pick_and_place_tools", "package_summary": ["RViz Plugins for Collecting Grasps and Generating Models"], "package_details": ["\n", "\n", "\n", "\n", " ", "The ", " package contains rviz plugins to aid in the grasp demonstration collection and model generation process.  This package also contains launch files for easier running of this process. ", "To install the ", " package, you can install from source with the following commands: ", "The ", " package contains a launch file for starting up the backend necessary for grasp demonstration collection and object model generation, as well as a frontend that launches rviz with the relevant panels and topics shown: "], "package_tt": ["rail_pick_and_place_tools", "rail_pick_and_place", "rail_pick_and_place_tools"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch rail_pick_and_place_tools model_generation_backend.launch", "roslaunch rail_pick_and_place_tools model_generation_frontend.launch"]},
{"url": "https://wiki.ros.org/turtlebot_arm_moveit_config", "package": "turtlebot_arm_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the turtlebot_arm with the MoveIt! Motion Planning Framework"], "package_details": ["The package contains some tweaks and addition to the automatically generated one. Refer to ", " if you want to generate the ", "! configuration by yourself. "]},
{"url": "https://wiki.ros.org/wge100_camera", "package": "wge100_camera", "package_summary": ["A ROS node and assorted tools to provide access to the WGE100\n    camera used in the forearms and the stereo cameras of the PR2\n    robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", " ", "\n", " ", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "The Willow Garage 100 Mbps Ethernet (WGE100) camera is a 752x480 Ethernet camera developed for the PR2 robot. The PR2's narrow stereo camera is a monochrome WGE100, while its wide stereo camera and forearm cameras are in color. This package contains the ", ", a ROS driver for a monocular WGE100 camera, the ", " node, which allows two cameras in a stereo pair to be configured from one centralized location, and a suite of ", " to manage the camera. ", "Except for the ", " and ", " tools, which can be used at any time, the WGE100 tools are not designed for concurrent access to the camera. ", "The timestamps returned by the ", " are with respect to the end of the exposure. The timestamps can be produced in one of two ways: ", "When working with a WGE100 camera, the user needs to identify the camera she wishes to work with.  Cameras are identified using URLs, which can refer either to the camera's serial number or to its descriptive name (set using ", "). If there is only one camera present, a URL can indicate that whatever camera is found should be used.  ", "If a URL matches more than one camera, none of them will be selected, and an error will be reported. This situation cannot happen with a ", " URL as camera serial numbers are unique. ", "When an IP address is specified, WGE100 camera tools will configure the camera to use that address before they try to work with it. The IP address that is specified using @ will get reset each time a new tool is used. To set a camera's IP address permanently, use the ", " tool. ", "In some cases, a single camera may be visible on multiple interfaces, or cameras with the same name may be visible on different network interfaces. In this case, an interface name can be included in the camera URL to force a particular interface to be used for communication. An interface name is introduced with the ", " sign. For example, on the PR2, only the ", " interface is searched to avoid potential conflicts with identically named cameras on the wan0 interface: ", " ", "The ", " tool uses a broadcast packet to find cameras on the network. It can be run on a single network interface: ", "The IP address that is reported by the ", " tool is the currently configured address for the camera. This may be different from the IP address stored in the camera's flash, and to which the camera defaults when it is reset. This IP may or may not be valid for the interface on which the camera is located, and it is quite possible that you will not be able to communicate with the camera at this particular IP address. ", "Sometimes a camera can be seen from multiple interfaces. The ", " tool only reports the first interface on which a response is seen. The camera can nevertheless be configured to run from an interface other than the one on which it was reported. ", "The camera name and IP address that are stored in the camera's flash can be accessed using the ", " tool. With a single camera URL argument, set_name reports the current settings. ", "The camera intrinsics that are stored in the camera's flash can be accessed using the ", " tool. With a single camera URL argument, set_name reports the current settings. ", "In general, calibration of the camera and uploading of the parameters should be done through the ", " package.  These programs will perform the calibration, and make the service call to flash the intrinsics back onto the camera. ", "The camera can be reset using the ", " command, which takes a single camera_url argument. ", "Note: The ", " tool currently has the same effect as ", ". In future firmware versions ", " will always cause the camera FPGA to reconfigure itself, whereas ", " may do a softer reset that resets all components without reconfiguring the FPGA. ", "For information on contents of the WGE100 flash memory, you may consult ", ". "], "package_tt": ["wge100_camera_node", "first_packet_offset", "name://wide_stereo_l", "serial://2701025", "any://", "@", "name://my_camera@192.168.1.2", "#", "lan0", "name://wide_stereo_l#lan0", "any://", "serial://15#eth2", "name://left_forearm@10.68.0.210", "wge100_camera_node", "wge100_camera_node", "<~trig_timestamp_topic>", "wge100_camera_node", "camera/image_raw", "camera/camera_info", "camera_alternate/image_raw", "camera_alternate/camera_info", "/diagnostics", "~self_test", "camera/set_camera_info", "~board_config", "wge100_camera_node", "~camera_url", "str", "~frame_id", "str", "~register_set", "int", "~packet_debug", "bool", "camera_info", "width", "height", "~width", "int", "~height", "int", "~imager_rate", "double", "~horizontal_binning", "int", "~vertical_binning", "int", "~horizontal_offset", "int", "~vertical_offset", "int", "~mirror_x", "bool", "~mirror_y", "bool", "~rotate_180", "bool", "~ext_trig", "bool", "~rising_edge_trig", "bool", "~trig_timestamp_topic", "str", "~trig_rate", "double", "~first_packet_offset", "double", "~brightness", "int", "~black_level", "int", "~max_exposure", "double", "~auto_exposure", "bool", "~exposure", "double", "~auto_gain", "bool", "~gain", "int", "~companding", "bool", "~auto_exposure_alternate", "bool", "~exposure_alternate", "double", "~auto_gain_alternate", "bool", "~gain_alternate", "int", "~companding_alternate", "bool", "wge100_multi_configurator", "wge100_camera_node", "wge100_camera_node", "wge100_camera_node", "~camera_nodes", "str", "~<any\u00a0wge100_camera_node\u00a0parameter\u00a0except\u00a0camera_url>", "same"], "package_code": ["name://camera_name[@camera_ip][#local_interface]\n", "serial://serial_number[@camera_ip][#local_interface]\n", "any://[@camera_ip][#local_interface]", "$ rosrun wge100_camera discover eth1\n", "Found camera serial://13 name://test MAC: 00:24:cd:00:00:83 iface: eth2:avahi current IP: 169.254.8.124, PCB rev: C HDL rev: 400 FW rev: 118", "$ rosrun wge100_camera discover\n", "Found camera serial://13 name://test MAC: 00:24:cd:00:00:83 iface: eth2:avahi current IP: 169.254.8.124, PCB rev: C HDL rev: 400 FW rev: 118", "$ rosrun wge100_camera set_name serial://15@169.254.8.200\n", "Previous camera name was: test.\n", "Previous camera IP: 169.254.8.124.", "$ rosrun wge100_camera set_name serial://15@169.254.8.200 new_name 169.254.8.200\n", "Previous camera name was: test\n", "Previous camera IP: 169.254.8.124\n", "Success! Restarting camera, should take about 10 seconds to come back up after this.\n", "$ rosrun wge100_camera set_name serial://15\n", "Previous camera name was: new_name\n", "Previous camera IP: 169.254.8.200", "$ rosrun wge100_camera set_calibration name://wide_stereo_l\n", "Unable to create ARP entry (are you root?), continuing anyway\n", "Reading old calibration...\n", "[image]\n", "...", "$ rosrun wge100_camera set_calibration serial://15@169.254.8.200 intrinsics.ini", "$ rosrun wge100_camera reset_cam any://"]},
{"url": "https://wiki.ros.org/realsense_camera", "package": "realsense_camera", "package_summary": ["RealSense Camera package allowing access to Intel 3D cameras and advanced modules"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package provides ROS node(s) for using the Intel\u00ae ", "\u2122 R200, F200 and SR300 cameras. ", "This package requires the ", " package as the underlying camera drivers for all Intel\u00ae ", "\u2122 cameras. ", " installing the realsense-camera package, follow the ", ". ", "This will also install the required ros-<*distro*>-librealsense library on your system. ", "If a user needs to debug this package or contribute changes/bug fixes to the package, only then should the package need to be built from source. Please closely follow the directions provided on the ", " page. ", "To ensure you camera has the most current, supported firmware, please review the ", ". If the camera requires a firmware upgrade, please refer to the ", " page. ", ": Currently there is no native Linux tool for FW updates; all updates require a system with Microsoft Windows. ", "Please ", " concerning this package to the realsense_camera ", " Issues. ", "See the ", " for a complete list. "], "package_tt": ["color/camera_info", "color/image_raw", "depth/camera_info", "depth/image_raw", "uint16", "depth/points", "ir/camera_info", "ir/image_raw", "uint16", "ir/camera_info", "ir/image_raw", "uint16", "fisheye/camera_info", "ir/image_raw", "uint16", "imu/data_raw", "get_settings", "set_power", "true", "false", "false", "force_power", "true", "false", "false", "is_powered", "get_imu_info", "mode", "string", "preset", "serial_no", "string", "blank", "usb_port_id", "string", "blank", "camera_type", "string", "blank", "enable_ir", "bool", "enable_depth", "bool", "depth_width", "int", "depth_height", "int", "depth_fps", "int", "enable_color", "bool", "color_width", "int", "color_height", "int", "color_fps", "int", "enable_fisheye", "bool", "fisheye_width", "int", "fisheye_height", "int", "fisheye_fps", "int", "enable_imu", "bool", "enable_pointcloud", "bool", "enable_tf", "bool", "enable_tf_dynamic\u00a0('''Added\u00a0in\u00a01.7.0''')", "bool", "base_frame_id", "string", "depth_frame_id", "string", "depth_optical_frame_id", "string", "color_frame_id", "string", "color_optical_frame_id", "string", "ir_frame_id", "string", "ir_optical_frame_id", "string", "ir2_frame_id", "string", "ir2_optical_frame_id", "string", "fisheye_frame_id", "string", "fisheye_optical_frame_id", "string", "imu_frame_id", "string", "imu_optical_frame_id", "string", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_exposure", "int", "~r200_lr_gain", "int", "~r200_lr_exposure", "int", "~color_enable_auto_white_balance", "int", "~color_enable_auto_exposure", "int", "~r200_lr_auto_exposure_enabled", "int", "~r200_auto_exposure_top_edge", "int", "~r200_auto_exposure_bottom_edge", "int", "~r200_auto_exposure_left_edge", "int", "~r200_auto_exposure_right_edge", "int", "~r200_emitter_enabled", "int", "~r200_dc_preset", "int", "~r200_dc_estimate_median_decrement", "int", "~r200_dc_estimate_median_increment", "int", "~r200_dc_median_threshold", "int", "~r200_dc_score_minimum_threshold", "int", "~r200_dc_score_maximum_threshold", "int", "~r200_dc_texture_count_threshold", "int", "~r200_dc_texture_difference_threshold", "int", "~r200_dc_second_peak_threshold", "int", "~r200_dc_neighbor_threshold", "int", "~r200_dc_lr_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_exposure", "int", "~color_enable_auto_white_balance", "int", "~color_enable_auto_exposure", "int", "~f200_laser_power", "int", "~f200_accuracy", "int", "~f200_motion_range", "int", "~f200_filter_option", "int", "~f200_confidence_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_enable_auto_white_balance", "int", "~color_exposure", "int", "~color_enable_auto_exposure", "int", "~f200_laser_power", "int", "~f200_accuracy", "int", "~f200_motion_range", "int", "~f200_filter_option", "int", "~f200_confidence_threshold", "int", "~sr300_auto_range_enable_motion_versus_range", "int", "~sr300_auto_range_enable_laser", "int", "~sr300_auto_range_min_motion_versus_range", "int", "~sr300_auto_range_max_motion_versus_range", "int", "~sr300_auto_range_start_motion_versus_range", "int", "~sr300_auto_range_min_laser", "int", "~sr300_auto_range_max_laser", "int", "~sr300_auto_range_start_laser", "int", "~sr300_auto_range_upper_threshold", "int", "~sr300_auto_range_lower_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_exposure", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~r200_lr_gain", "int", "~r200_lr_exposure", "int", "~color_enable_auto_exposure", "int", "~color_enable_auto_white_balance", "int", "~r200_lr_auto_exposure_enabled", "int", "~r200_emitter_enabled", "int", "~r200_depth_clamp_min", "int", "~r200_depth_clamp_max", "int", "~fisheye_exposure", "int", "~fisheye_gain", "int", "~fisheye_enable_auto_exposure", "int", "~fisheye_auto_exposure_mode", "int", "~fisheye_auto_exposure_antiflicker_rate", "int", "~fisheye_auto_exposure_pixel_sample_rate", "int", "~fisheye_auto_exposure_skip_frames", "int", "~frames_queue_size", "int", "~hardware_logger_enabled", "int", "~r200_dc_preset", "int", "~r200_dc_estimate_median_decrement", "int", "~r200_dc_estimate_median_increment", "int", "~r200_dc_median_threshold", "int", "~r200_dc_score_minimum_threshold", "int", "~r200_dc_score_maximum_threshold", "int", "~r200_dc_texture_count_threshold", "int", "~r200_dc_texture_difference_threshold", "int", "~r200_dc_second_peak_threshold", "int", "~r200_dc_neighbor_threshold", "int", "~r200_dc_lr_threshold", "int", "camera_link", "camera_rgb_frame", "camera_rgb_frame", "camera_rgb_optical_frame", "camera_link", "camera_depth_frame", "camera_depth_frame", "camera_depth_optical_frame", "camera_link", "camera_ir_frame", "camera_ir_frame", "camera_ir_optical_frame", "camera_link", "camera_ir2_frame", "camera_ir2_frame", "camera_ir2_optical_frame", "camera_link", "camera_fisheye_frame", "camera_fisheye_frame", "camera_fisheye_optical_frame", "camera_link", "camera_imu_frame", "camera_imu_frame", "camera_imu_optical_frame"], "package_code": ["sudo apt-get install 'ros-*-realsense-camera'", "$ roslaunch realsense_camera r200_nodelet_default.launch", "$ roslaunch realsense_camera f200_nodelet_default.launch", "$ roslaunch realsense_camera sr300_nodelet_default.launch", "$ roslaunch realsense_camera zr300_nodelet_default.launch", "/camera/depth_registered/hw_registered/image_rect_raw\n", "/camera/depth_registered/hw_registered/image_rect\n", "/camera/depth_registered/image\n", "/camera/depth/disparity\n", "/camera/depth_registered/disparity"]},
{"url": "https://wiki.ros.org/turtlebot_arm_block_manipulation", "package": "turtlebot_arm_block_manipulation", "package_summary": ["turtlebot_arm_block_manipulation contains a demo allowing the TurtleBot arm\n    to manipulate small blocks on a level surface using interactive markers."], "package_details": ["\n", "\n", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This ", " will walk you through running this demo on your own TurtleBot. ", " ", " ", "This package requires almost all the others on ", " stack. In particular, ", " from the ", " package and ", " and ", " from ", " have to be running. See the ", " launch file for more details. ", "Additionally, it requires an external kinect to be running and calibrated to the robot. Refer to ", " package to learn how to calibrate your camera. "], "package_tt": ["arm.launch", "planning_context.launch", "move_group.launch", "block_manipulation_moveit.launch", "demo/block_manipulation_moveit.launch", "demo/block_manipulation_demo.launch", "launch/block_manipulation.launch", "/turtlebot_blocks", "/pick_and_place", "~bump_size", "double", "/camera/depth_registered/points", "/turtlebot_blocks", "block_output", "pointcloud\u00a0frame", "arm_link\u00a0(from\u00a0goal)"], "package_code": ["#goal definition\n", "string frame\n", "float32 table_height\n", "float32 block_size\n", "---\n", "#result definition\n", "geometry_msgs/PoseArray blocks\n", "---\n", "#feedback", "#goal definition\n", "string frame\n", "float32 block_size\n", "---\n", "#result definition\n", "geometry_msgs/Pose pickup_pose\n", "geometry_msgs/Pose place_pose\n", "---\n", "#feedback", "#goal definition\n", "string frame\n", "float32 z_up\n", "float32 gripper_open\n", "float32 gripper_closed\n", "geometry_msgs/Pose pickup_pose\n", "geometry_msgs/Pose place_pose\n", "string topic\n", "---\n", "#result definition\n", "---\n", "#feedback"]},
{"url": "https://wiki.ros.org/leg_detector", "package": "leg_detector", "package_summary": ["Leg Detector using a machine learning approach to find leg-like patterns of laser scanner readings."], "package_details": ["\n", "\n", "\n", "This leg detector package takes ", "s as input and uses a machine-learning-trained classifier to detect groups of laser readings as possible legs. Sadly, the training dataset has been lost to Willow Garage history (it wasn't even available before they closed). The code is in the repository for retraining, but is unsupported at this time.  ", "This node will publish ", "s for the individual legs, and it can also attempt to pair the legs together and publish their average as an estimate of where the center of one person is as a ", ". The node will also optionally publish visualization Marker messages to indicate where detections happened.  ", "In the seeded mode, the algorithm will use another source of PositionMeasurement messages to guide the algorithm to possible locations for people. Historically, this has been used with a face detection algorithm that alerts the leg_detector that there is probably a pair of legs underneath. This mode is enabled using the ", " parameter.  "], "package_tt": ["use_seeds", "scan", "people_tracker_filter", "leg_tracker_measurements", "people_tracker_measurements", "visualization_marker", "use_seeds", "boolean", "connection_threshold", "double", "min_points_per_group", "int", "leg_reliability_limit", "double", "publish_legs", "boolean", "publish_people", "boolean", "publish_leg_markers", "boolean", "publish_people_markers", "boolean", "no_observation_timeout", "double", "max_second_leg_age", "double", "max_track_jump", "double", "max_meas_jump", "double", "leg_pair_separation", "double", "fixed_frame", "string", "kalman_p", "double", "kalman_q", "double", "kalman_r", "double"]},
{"url": "https://wiki.ros.org/uos_diffdrive_teleop", "package": "uos_diffdrive_teleop", "package_summary": ["uos_diffdrive_teleop"]},
{"url": "https://wiki.ros.org/sr_kinematics", "package": "sr_kinematics", "package_summary": ["\n    A specific shadowhand package derived from arm_kinematics, for computing both forward and backward kinematics for the fingers except thumb.\n    Solution is analytic. Developed as an alternative to arm_kinematics that cannot solve coupled joints.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "sr_kinematics currently contains a specific analytical inverse kinematics for the ", " hand. Currently, only the 4 fingers have an IK solution, the thumb will come later. The solution takes care of the coupled joint J1/J2 (assuming it is 1:1) and accepts 3D requests (instead of 6D). There is an approximation in this solution. ", "The node proposes the same services and parameters as the ", " ", "NOTE that ", " parameter is used to detect singularities for J4 joint. "]},
{"url": "https://wiki.ros.org/turtlebot_panorama", "package": "turtlebot_panorama", "package_summary": ["\n\n     This app utilises pano_ros for taking snapshots and stitching them together to create panorama pictures.\n\n  ", "To be documented. "], "package_details": [" ", "\n", "\n", "\n", "To learn how to use this package, take a look to the ", " "], "package_tt": ["pano_app/take_pano", "pano_app/stop_pano", "pano_app/odom", "pano_server/stitch", "pano_app/log", "pano_app/panorama", "pano_app/cmd_vel", "pano_server/snap", "pano_server/stop", "pano_app/take_pano", "~default_mode", "String", "~default_pano_angle", "double", "~default_snap_interval", "String", "~default_rotation_velocity", "double", "~camera_name", "String", "~bag_location", "String"]},
{"url": "https://wiki.ros.org/turtlesim_dash_tutorial", "package": "turtlesim_dash_tutorial", "package_summary": ["The turtlesim_dash_tutorial package"], "package_details": ["\n", " ", " ", "\n", " ", "\n", "\n", " ", "This package is designed to provide a quick and dirty tutorial on how to quickly create a Web UI for a ROS environment with ", ". As backbone for this tutorial, we'll use ROS's ", ". ", "The default launch file included in this package, ", " brings up a ", " environment and starts ", "'s ", " node. As mentioned in the documentation for ", ", the node is designed to control the simulated turtlebot so that it traces out a polygon of a specified radius with the desired number of edges. ", "The launch file also starts a ", ". On navigating to that URL, you should see a web page like so: ", "Here is an example of the page as the turtlebot is executing a ", ": ", "Creates a ", " server on the port 8080; navigate to ", " in order to view it. "], "package_tt": ["tutorial.launch", "turtlesim", "turtle_actionlib", "shape_server", "turtle_actionlib", "Trace\u00a0Shape", "shape_server", "actionlib", "ShapeGoal", "turtle_actionlib", "sudo\u00a0apt\u00a0install\u00a0ros-melodic-turtle-actionlib", "pip\u00a0install\u00a0-r\u00a0requirements.txt", "\u00a0roslaunch\u00a0turtlesim_dash_tutorial\u00a0tutorial.launch\u00a0", "dash", "/turtle_shape", "/turtle1/pose"]},
{"url": "https://wiki.ros.org/linux_networking", "package": "linux_networking", "package_summary": ["\n    ", "\n      Tools to work with linux networking. \n    "], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/ridgeback_navigation", "package": "ridgeback_navigation", "package_summary": ["Launch files and code for autonomous navigation of the Ridgeback"], "package_details": ["\n", "The ridgeback_navigation package contains configuration and launch files for running ", " on ", ". "]},
{"url": "https://wiki.ros.org/sr_movements", "package": "sr_movements", "package_summary": ["\n\n    Contains a node which can be used to take the hand through a series of movements (perfect for tuning\n    controllers for example).\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "It also receives an input topic and calculates the MSE for each cycle of the bitmap plot. The MSE is output to ROS_INFO and published in the topic ", ". ", "For example, using this png file ", " will send targets between the specified ", " and ", " values on a (very) rough sinusoid. The black dot on each row represents the percentage between ", " and ", ". The top of the graph is 100% (=max), the bottom is 0% (=min). ", "Publishes ", " with the targets values. ", "Publishes ", " with the calculated MSE values. ", "Subscribe to ", " to receive the data to calculate MSE. "], "package_code": ["rosrun sr_movements sr_movements /sr_movements/targets:=/sh_ffj3_mixed_position_velocity_controller/command /sr_movements/inputs:=/sh_ffj3_mixed_position_velocity_controller/state _image_path:=\"`rospack find sr_movements`/movements/test.png\" _min:=.1 _max:=1.4 _publish_rate:=100 _repetition:=5 _nb_step:=1000 _msg_type:=\"sr\""]},
{"url": "https://wiki.ros.org/turtlebot_concert", "package": "turtlebot_concert", "package_summary": ["A solution for multi TurtleBot teloperation and navigation which can be used in a lab.", "\n", " ", " ", "how to start the turtlebot concert ", "how to start the turtlebot concert ", "how to teleoperate turtlebot in concert ", " "]},
{"url": "https://wiki.ros.org/tf", "package": "tf", "package_summary": ["tf is a package that lets the user keep track of multiple coordinate\nframes over time. tf maintains the relationship between coordinate\nframes in a tree structure buffered in time, and lets the user\ntransform points, vectors, etc between any two coordinate frames at\nany desired point in time.\n\n    ", ": Since ROS Hydro, tf has been \"deprecated\" in favor of ", ". tf2 is an iteration on tf providing generally the same feature set more efficiently. As well as adding a few new features.", "\n    As tf2 is a major change the tf API has been maintained in its current form. Since tf2 has a superset of the tf features with a subset of the dependencies the tf implementation has been removed and replaced with calls to tf2 under the hood. This will mean that all users will be compatible with tf2. It is recommended for new work to use tf2 directly as it has a cleaner interface. However tf will continue to be supported for through at least J Turtle.\n    "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", " ", "\n", " ", " ", "\n", " ", " ", " is designed both as a command-line tool for manual use, as well as for use within ", " files for setting static transforms. For example: ", " ", "\n", " is a graphical debugging tool that creates a PDF graph of your current transform tree. ", "\n", " tf comes with a plugin for ", " that automatically runs whenever you run ", ". This plugin will analyze your current tf configuration and attempt to find common problems. To run, just invoke ", " normally: ", "\n", " ", "\n", " ", "\n", " ", "You want to ", " what tf can do instead of just reading about it? Check out the ", ". ", "A robotic system typically has many 3D ", " that change over ", ", such as a world frame, base frame, gripper frame, head frame, etc. tf keeps track of all these frames over time, and allows you to ask questions like: ", "tf can operate in a ", ". This means all the information about the coordinate frames of a robot is available to all ROS components on any computer in the system.  There is ", " of transform information. ", "For more information on the design see ", " ", "There is a paper on tf presented at TePRA 2013 ", " ", "We created a set of ", " that walk you through using tf, step by step. You can get started on the ", " tutorial. For a complete list of all tf and tf-related tutorials check out the ", " page. ", "Once you are finished with the basic tutorials, you can move on to learn about tf and time. The tf and time tutorial ", " ", " teaches the basic principles of tf and time. The advanced tutorial about tf and time ", " ", " teaches the principles of time traveling with tf. ", "Although tf is mainly a code library meant to be used within ROS ", ", it comes with a large set of command-line tools that assist in the debugging and creation of tf coordinate frames. These tools include: ", "You may also wish to use the ", " node, which is a utility node for remapping coordinate transforms. ", "Therefore an helpful shortcut to add in your ", " is: ", "NOTE: See also ", " that allows dynamic introspection of the frames. "], "package_tt": ["tfwtf", "tf_monitor", "tf_monitor\u00a0<source_frame>\u00a0<target_target>", "/base_footprint", "/odom", "tf_echo\u00a0<source_frame>\u00a0<target_frame>", "source_frame", "target_frame", "/map", "/odom", "static_transform_publisher\u00a0x\u00a0y\u00a0z\u00a0yaw\u00a0pitch\u00a0roll\u00a0frame_id\u00a0child_frame_id\u00a0period_in_ms", "static_transform_publisher\u00a0x\u00a0y\u00a0z\u00a0qx\u00a0qy\u00a0qz\u00a0qw\u00a0frame_id\u00a0child_frame_id\u00a0\u00a0period_in_ms", "static_transform_publisher", "view_frames", ".bashrc", "roswtf", "roswtf", "roswtf", "/tf_old", "/tf", "/tf:=/tf_old", "tf_remap", "~mappings", "/tf_old", "/tf", "/tf", "~mappings", "[\u00a0{str:\u00a0str}\u00a0]", "change_notifier", "/tf", "/tf_changes", "/tf", "/tf_changes", "~polling_frequency", "float", "~translational_update_distance", "float", "~angular_update_distance", "float"], "package_code": ["$ rosrun tf tf_monitor\n", "RESULTS: for all Frames\n", "\n", "Frames:\n", "Frame: /base_footprint published by /robot_pose_ekf Average Delay: 0.0469324 Max Delay: 0.0501503\n", "Frame: /base_laser_link published by /robot_state_publisher Average Delay: 0.00891066 Max Delay: 0.009591\n", "Frame: /base_link published by /robot_state_publisher Average Delay: 0.00891147 Max Delay: 0.009592\n", "0.00891431 Max Delay: 0.009595\n", "\n", "... editing for the sake of brevity ...\n", "\n", "Broadcasters:\n", "Node: /realtime_loop 94.7371 Hz, Average Delay: 0.000599916 Max Delay: 0.001337\n", "Node: /robot_pose_ekf 30.8259 Hz, Average Delay: 0.0469324 Max Delay: 0.0501503\n", "Node: /robot_state_publisher 25.8099 Hz, Average Delay: 0.0089224 Max Delay: 0.00960276", "$ rosrun tf tf_monitor /base_footprint /odom\n", "RESULTS: for /base_footprint to /odom\n", "Chain currently is: /base_footprint -> /odom\n", "Net delay     avg = 0.00371811: max = 0.012472\n", "\n", "Frames:\n", "Frame: /base_footprint published by /robot_pose_ekf Average Delay: 0.0465218 Max Delay: 0.051754\n", "Frame: /odom published by /realtime_loop Average Delay: 0.00062444 Max Delay: 0.001553\n", "\n", "Broadcasters:\n", "Node: /realtime_loop 95.3222 Hz, Average Delay: 0.00062444 Max Delay: 0.001553\n", "Node: /robot_pose_ekf 30.9654 Hz, Average Delay: 0.0465218 Max Delay: 0.051754\n", "Node: /robot_state_publisher 25.9839 Hz, Average Delay: 0.00903061 Max Delay: 0.00939562", "$ rosrun tf tf_echo /map /odom\n", "At time 1263248513.809\n", "- Translation: [2.398, 6.783, 0.000]\n", "- Rotation: in Quaternion [0.000, 0.000, -0.707, 0.707]\n", "in RPY [0.000, -0.000, -1.570]", "\n", "\n", "\n", "$ rosrun tf view_frames", "$ rosrun tf view_frames\n", "$ evince frames.pdf", "alias tf='cd /var/tmp && rosrun tf view_frames && evince frames.pdf &'", "$ roswtf"]},
{"url": "https://wiki.ros.org/xbot_bringup", "package": "xbot_bringup", "package_summary": ["The xbot_bringup package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n"], "package_code": ["roslaunch xbot_bringup xbot.launch", "roslaunch xbot_bringup rplidar.launch", "roslaunch xbot_bringup realsense.launch", "roslaunch xbot_bringup xbot-u.launch"]},
{"url": "https://wiki.ros.org/xbot_msgs", "package": "xbot_msgs", "package_summary": ["\n      Xbot message and service types: custom messages and services for Xbot packages.\n    "]},
{"url": "https://wiki.ros.org/stereo_msgs", "package": "stereo_msgs", "package_summary": ["stereo_msgs contains messages specific to stereo processing, such as disparity images."], "package_details": ["\n", ": this package is now part of ", ".  In previous releases, it was part of ", ". ", "\n"]},
{"url": "https://wiki.ros.org/topic_proxy", "package": "topic_proxy", "package_summary": ["topic_proxy implements a ROS service server and client to pull single messages from one master and optionally republish them locally."], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n "]},
{"url": "https://wiki.ros.org/rtabmap_ros", "package": "rtabmap_ros", "package_summary": ["RTAB-Map's ros-pkg. RTAB-Map is a RGB-D SLAM approach with real-time constraints."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", ": It is recommend to use directly ", " or ", " published topics from ", " node instead of using this node. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", ": this node will use a lot of CPU ressources if the raw point clouds are fed to it directly. A ", " can be used to downsample the raw point cloud (e.g. like 5 cm voxel) or ", " nodelet can be used to generate a downsampled cloud from a depth image (e.g. decimating the depth image by 4 before creating a cloud). That filtered point cloud would be fed to ", ".  ", "\n", "\n", "\n", " ", "\n", "\n", "This package is a ROS wrapper of ", " (Real-Time Appearance-Based Mapping), a RGB-D SLAM approach based on a global loop closure detector with real-time constraints. This package can be used to generate a 3D point clouds of the environment and/or to create a 2D occupancy grid map for navigation. The ", " and ", " show some examples of mapping with RTAB-Map. ", "For this demo, you will need the ROS bag ", " (295 MB, ", ", ", "). ", "Launch: ", " ", "For this demo, you will need the ROS bag ", " (295 MB, ", ", ", "). ", "Launch: ", " ", "Detailed results are shown on the ", " page on RTAB-Map's wiki. ", "For the first launch, you can do \"Edit->Delete memory\" to make sure that you start from a clean memory. You may need to do this after starting the first bag with \"--pause\" so that rtabmap node is initialized to avoid a \"service /reset cannot be called\" error. ", "Launch: ", " ", "Find-Object's ros-pkg ", " should be installed. ", "ROS Bag: ", " (416 MB) ", "Launch: ", " ", "There is no bag recorded for this demo but how to reproduce this setup is described on the page ", " of the RTAB-Map's wiki. ", "Visit the tutorial ", " for detailed information. It is also shown how to create 2D occupancy grid map for navigation. ", "Launch : ", " ", "There is no bag recorded for this demo but how to reproduce this setup is described in the tutorial ", ". ", "Launch: ", " ", "For ", " and information about the loop closure detection approach used in RTAB-Map, visit ", ". ", "All ", " topics use ", ". ", "\n", "This is the main node of this package. It is a wrapper of the RTAB-Map Core library. This is where the graph of the map is incrementally built and optimized when a loop closure is detected. The online output of the node is the local graph with the latest added data to the map. The default location of the RTAB-Map database is \"~/.ros/rtabmap.db\" and the workspace is also set to \"~/.ros\". To get a 3D point cloud or a 2D occupancy grid of the environment, subscribe to ", ", ", " or ", " topics. ", "This node starts the visualization interface of RTAB-Map. It is a wrapper of the RTAB-Map GUI library. It has the same purpose as ", " but with specific options for RTAB-Map. ", "Common odometry stuff for ", ", ", " and ", " nodes. These nodes wrap the various odometry approaches of RTAB-Map. When a transformation cannot be computed, a null transformation is sent to notify the receiver that odometry is not updated or lost. ", "See also ", " for common odometry stuff used by this node. ", "\n", "See also ", " for common odometry stuff used by this node. ", "\n", "See also ", " for common odometry stuff used by this node. ", "\n", "A node for image acquisition from an USB camera (OpenCV is used). A special option for this node is that it can be configured to read images from a directory or a video file. Parameters can be changed with the ", " GUI from ROS. For dynamic parameters, see ", " ", "This node subscribes to ", " output topic ", " and assembles the 3D map incrementally, then publishes the same maps than ", ". See all ", " related topics and parameters of ", " node. ", "This node is for ", " as it is preferred to use graph optimization already inside ", " node (which is the default). See related parameters in ", ": ", "This node subscribes to ", " output topic ", " and optimize the graph, then republishes the optimized ", ". ", "This rviz plugin subscribes to /mapData (", ") topic. A 3D map cloud will be created incrementally in RVIZ. When the graph is changed, all point clouds added in RVIZ will be transformed to new poses. It has the same properties as ", " display but with these new ones: ", "This rviz plugin subscribes to /mapGraph (", ") topic. It will show the RTAB-Map's graph with different colors depending on the links' type. It has the same properties as ", " display. ", "This rviz plugin subscribes to /info (", ") topic. Information about loop closures detected are shown in the \"Status\". "], "package_tt": ["video_or_images_path", "cloud_map", "grid_map", "proj_map", "\"--delete_db_on_start\"", "\"--delete_db_on_start\"", "\"-d\"", "\"--udebug\"", "\"--uinfo\"", "\"--params\"", "odom", "subscribe_depth", "subscribe_stereo", "odom_frame_id", "rgb/image", "subscribe_depth", "subscribe_stereo", "left/image_rect", "rgb/camera_info", "subscribe_stereo", "left/camera_info", "depth/image", "subscribe_depth", "scan", "subscribe_scan", "scan_cloud", "subscribe_scan_cloud", "left/image_rect", "subscribe_stereo", "left/camera_info", "subscribe_stereo", "right/image_rect", "subscribe_stereo", "right/camera_info", "subscribe_stereo", "goal", "RGBD/LocalRadius", "set_goal", "rgbd_image", "subscribe_rgbd", "true", "info", "mapData", "mapGraph", "grid_map", "map_", "grid_", "proj_map", "map_", "grid_", "proj_", "cloud_map", "map_", "cloud_", "scan_map", "map_", "scan_", "labels", "global_path", "local_path", "goal_reached", "goal_out", "move_base_simple/goal", "octomap_full", "octomap_binary", "octomap_occupied_space", "octomap_obstacles", "octomap_ground", "octomap_empty_space", "octomap_grid", "get_map", "get_map_data", "publish_map", "list_labels", "update_parameters", "reset", "pause", "resume", "trigger_new_map", "backup", "database_path", "~/.ros/rtabmap.db.back", "set_mode_localization", "set_mode_mapping", "set_label", "set_goal", "octomap_full", "octomap_binary", "~subscribe_depth", "bool", "\"true\"", "~subscribe_scan", "bool", "\"false\"", "~subscribe_scan_cloud", "bool", "\"false\"", "~subscribe_stereo", "bool", "\"false\"", "~subscribe_rgbd", "bool", "\"false\"", "rgbd_image", "~frame_id", "string", "\"base_link\"", "~map_frame_id", "string", "\"map\"", "~odom_frame_id", "string", "\"\"", "odom", "~queue_size", "int", "~publish_tf", "bool", "\"true\"", "~tf_delay", "double", "~tf_prefix", "string", "\"\"", "~wait_for_transform", "bool", "\"true\"", "wait_for_transform_duration", "~wait_for_transform_duration", "double", "wait_for_transform", "~config_path", "string", "\"\"", "~database_path", "string", "\"~/.ros/rtabmap.db\"", "~gen_scan", "bool", "\"false\"", "subscribe_scan", "subscribe_scan_cloud", "~gen_scan_max_depth", "double", "~approx_sync", "bool", "\"false\"", "~rgbd_cameras", "int", "subscribe_rgbd", "true", "rgbd_image0", "rgbd_image1", "~use_action_for_goal", "bool", "\"false\"", "goal_out", "move_base_simple/goal", "~map_filter_radius", "double", "map_filter_angle", "~map_filter_angle", "double", "map_filter_radius", "~map_cleanup", "bool", "\"true\"", "cloud_map", "grid_map", "proj_map", "~latch", "bool", "\"true\"", "~cloud_decimation", "int", "cloud_map", "~cloud_max_depth", "double", "cloud_map", "~cloud_voxel_size", "double", "cloud_map", "~cloud_floor_culling_height", "double", "cloud_map", "~cloud_output_voxelized", "bool", "\"false\"", "cloud_map", "~cloud_frustum_culling", "bool", "\"false\"", "cloud_map", "~cloud_noise_filtering_radius", "double", "cloud_noise_filtering_min_neighbors", "cloud_noise_filtering_radius", "cloud_map", "~cloud_noise_filtering_min_neighbors", "double", "cloud_noise_filtering_min_neighbors", "cloud_noise_filtering_radius", "cloud_map", "~scan_voxel_size", "double", "scan_map", "~scan_output_voxelized", "bool", "\"false\"", "scan_map", "~grid_cell_size", "double", "grid_map", "proj_map", "~grid_size", "double", "grid_map", "proj_map", "~grid_eroded", "bool", "\"false\"", "grid_map", "proj_map", "~grid_unknown_space_filled", "bool", "\"false\"", "grid_map", "~proj_max_ground_angle", "double", "proj_map", "~proj_min_cluster_size", "int", "grid_cell_size", "proj_map", "~proj_max_height", "double", "proj_map", "base_link", "<the\u00a0frame\u00a0attached\u00a0to\u00a0sensors\u00a0of\u00a0incoming\u00a0data>", "tf", "odom", "base_link", "map", "odom", "-d\u00a0\"config.ini\"", "\"/.ros/rtabmapGUI.ini\"", "odom", "subscribe_depth", "subscribe_stereo", "odom_frame_id", "rgb/image", "subscribe_depth", "subscribe_stereo", "left/image_rect", "rgb/camera_info", "subscribe_stereo", "left/camera_info", "depth/image", "subscribe_depth", "scan", "subscribe_scan", "scan_cloud", "subscribe_scan_cloud", "left/image_rect", "subscribe_stereo", "left/camera_info", "subscribe_stereo", "right/image_rect", "subscribe_stereo", "right/camera_info", "subscribe_stereo", "odom_info", "subscribe_odom_info", "info", "mapData", "rgbd_image", "subscribe_rgbd", "true", "~subscribe_depth", "bool", "\"false\"", "~subscribe_scan", "bool", "\"false\"", "~subscribe_scan_cloud", "bool", "\"false\"", "~subscribe_stereo", "bool", "\"false\"", "~subscribe_odom_info", "bool", "\"false\"", "~subscribe_rgbd", "bool", "\"false\"", "rgbd_image", "~frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"\"", "odom", "~tf_prefix", "string", "\"\"", "~wait_for_transform", "bool", "\"false\"", "~queue_size", "int", "~rgbd_cameras", "int", "subscribe_rgbd", "true", "rgbd_image0", "rgbd_image1", "base_link", "<the\u00a0frame\u00a0attached\u00a0to\u00a0sensors\u00a0of\u00a0incoming\u00a0data>", "tf", "odom", "base_link", "map", "odom", "\"--params\"", "odom", "odom_info", "Odom/FillInfoData", "true", "odom_last_frame", "odom_local_map", "Odom/Strategy=0", "reset_odom", "reset_odom_to_pose", "\"x\u00a0y\u00a0z\u00a0roll\u00a0pitch\u00a0yaw\"", "pause_odom", "resume_odom", "~frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~publish_tf", "bool", "\"true\"", "~tf_prefix", "bool", "\"\"", "~wait_for_transform", "bool", "\"false\"", "~initial_pose", "string", "\"\"", "\"x\u00a0y\u00a0z\u00a0roll\u00a0pitch\u00a0yaw\"", "~queue_size", "int", "~publish_null_when_lost", "bool", "~ground_truth_frame_id", "string", "\"\"", "~ground_truth_base_frame_id", "string", "\"\"", "ground_truth_frame_id", "~guess_frame_id", "string", "\"\"", "tf", "guess_frame_id", "odom_combined", "odom_frame_id", "odom", "frame_id", "base_footprint", "odom", "odom_combined", "tf", "/odom\u00a0->\u00a0/odom_combined\u00a0->\u00a0/base_link", "~guess_min_translation", "float", "0.0", "guess_frame_id", "~guess_min_rotation", "float", "0.0", "guess_frame_id", "~config_path", "string", "\"\"", "base_link", "<the\u00a0frame\u00a0attached\u00a0to\u00a0sensors\u00a0of\u00a0incoming\u00a0data>", "tf", "odom", "base_link", "rgb/image", "rgb/camera_info", "depth/image", "rgbd_image", "subscribe_rgbd", "true", "~approx_sync", "bool", "\"true\"", "~rgbd_cameras", "int", "subscribe_rgbd", "true", "rgbd_image0", "rgbd_image1", "~subscribe_rgbd", "bool", "\"false\"", "rgbd_image", "left/image_rect", "left/camera_info", "right/image_rect", "right/camera_info", "rgbd_image", "subscribe_rgbd", "true", "~approx_sync", "bool", "\"false\"", "~subscribe_rgbd", "bool", "\"false\"", "rgbd_image", "scan", "scan", "scan_cloud", "scan_cloud", "scan", "scan_cloud", "~scan_cloud_max_points", "int", "0", "0", "~scan_downsampling_step", "int", "1", "<=1", "~scan_voxel_size", "float", "0.0", "0.0", "~scan_normal_k", "int", "0", "Icp/Point2Plane", "0", "~scan_normal_radius", "float", "0.0", "Icp/Point2Plane", "0.0", "image", "stop_camera", "start_camera", "~frame_id", "string", "\"camera\"", "cloud_map", "proj_map", "\"mapData\"", "mapData", "~reset", "\"mapData\"", "\"mapData\"", "mapData_optimized", "poses", "RGBD/OptimizeStrategy", "RGBD/OptimizeIterations", "0", "RGBD/OptimizeMaxError", "0", "publish_tf", "false", "mapData", "[mapData]_optimized", "[mapData]Graph_optimized", "~map_frame_id", "string", "\"map\"", "~odom_frame_id", "string", "\"odom\"", "~strategy", "int", "~slam_2d", "bool", "\"false\"", "~robust", "bool", "\"true\"", "strategy", "~global_optimization", "bool", "\"true\"", "~iterations", "int", "~epsilon", "double", "epsilon", "~ignore_variance", "bool", "\"false\"", "~optimize_from_last_node", "bool", "\"false\"", "~publish_tf", "bool", "\"true\"", "~tf_delay", "double", "subscribe_rgbd", "rtabmap", "rgb/image", "depth/image", "rgb/camera_info", "rgbd_image", "rgbd_image/compressed", "~queue_size", "int", "~approx_sync", "bool", "\"True\"", "~compressed_rate", "double", "rgbd_image/compressed", "subscribe_rgbd", "rtabmap", "left/image_rect", "right/image_rect", "left/camera_info", "right/camera_info", "rgbd_image", "rgbd_image/compressed", "~queue_size", "int", "~approx_sync", "bool", "\"False\"", "~compressed_rate", "double", "rgbd_image/compressed", "rgbd_image", "[rgbd_image]_relay", "~queue_size", "int", "~compress", "bool", "\"False\"", "~uncompress", "bool", "\"False\"", "odom_in", "rgb/image_in", "depth/image_in", "rgb/camera_info_in", "odom_out", "rgb/image_out", "depth/image_out", "rgb/camera_info_out", "~queue_size", "int", "rgb/image_in", "depth/image_in", "rgb/camera_info_in", "rgb/image_out", "depth/image_out", "rgb/camera_info_out", "~queue_size", "int", "~rate", "double", "~approx_sync", "bool", "\"True\"", "~decimation", "double", "camera_info_out", "left/image_rect", "left/camera_info", "right/image_rect", "right/camera_info", "[left/image_rect]_throttle", "[left/camera_info]_throttle", "[right/image_rect]_throttle", "[right/camera_info]_throttle", "~queue_size", "int", "~rate", "double", "~approx_sync", "bool", "\"false\"", "~decimation", "double", "rgb/image", "depth/image", "rgb/camera_info", "left/image", "left/camera_info", "right/image", "right/camera_info", "cloud", "~queue_size", "int", "~approx_sync", "bool", "\"true\"", "\"false\"", "~decimation", "int", "~voxel_size", "double", "0.0", "~min_depth", "double", "~max_depth", "double", "0.0", "~noise_filter_radius", "double", "0.0", "~noise_filter_min_neighbors", "int", "depth/image", "depth/camera_info", "disparity/image", "disparity/camera_info", "cloud", "~queue_size", "int", "~approx_sync", "bool", "\"true\"", "~decimation", "int", "~voxel_size", "double", "0.0", "~min_depth", "double", "~max_depth", "double", "0.0", "~noise_filter_radius", "double", "0.0", "~noise_filter_min_neighbors", "int", "disparity", "depth", "depth_raw", "fixed_frame_id", "camera_info", "cloud", "image", "image_raw", "~queue_size", "int", "~fixed_frame_id", "string", "approx", "true", "~approx", "bool", "\"true\"", "~wait_for_transform", "double", "~decimation", "int", "~fill_holes_size", "int", "~fill_holes_error", "double", "~fill_iterations", "int", "obstacles_detection", "cloud", "ground", "obstacles", "~frame_id", "string", "\"base_link\"", "~queue_size", "int", "~normal_estimation_radius", "double", "~ground_normal_angle", "double", "~min_cluster_size", "int", "~max_obstacles_height", "double", "base_link", "<the\u00a0frame\u00a0attached\u00a0to\u00a0sensors\u00a0of\u00a0incoming\u00a0data>", "tf"], "package_code": ["$ roslaunch rtabmap_ros demo_robot_mapping.launch\n", "$ rosbag play --clock demo_mapping.bag", "$ roslaunch rtabmap_ros demo_robot_mapping.launch localization:=true\n", "$ rosbag play --clock demo_mapping.bag", "$ roslaunch rtabmap_ros demo_robot_mapping.launch rviz:=true rtabmapviz:=false\n", "$ rosbag play --clock demo_mapping.bag", "$ roslaunch rtabmap_ros demo_multi-session_mapping.launch\n", "$ rosbag play --clock --pause map1.bag\n", "$ (...)\n", "$ rosbag play --clock map2.bag\n", "$ (...)\n", "$ rosbag play --clock map3.bag\n", "$ (...)\n", "$ rosbag play --clock map4.bag\n", "$ (...)\n", "$ rosbag play --clock map5.bag", "$ roslaunch rtabmap_ros demo_find_object.launch\n", "$ rosbag play --clock demo_find_object.bag", "$ roslaunch rtabmap_ros demo_stereo_outdoor.launch\n", "$ rosbag play --clock stereo_outdoorA.bag\n", "[...]\n", "$ rosbag play --clock stereo_outdoorB.bag", "$ roslaunch rtabmap_ros demo_appearance_mapping.launch", "$ rostopic echo /rtabmap/info/loopClosureId\n", "6\n", "---\n", "0\n", "---\n", "7\n", "---", "$ roslaunch rtabmap_ros demo_appearance_mapping.launch localization:=true", "<launch>\n", "<node name=\"rtabmap\" pkg=\"rtabmap_ros\" type=\"rtabmap\">\n", "   <param name=\"Optimizer/Iterations\" type=\"int\" value=\"50\"/>\n", "</node>\n", "</launch>", "$ rosrun rtabmap_ros rtabmap --params", "<launch>\n", "<node name=\"rtabmap\" pkg=\"rtabmap_ros\" type=\"rtabmap\" args=\"\">\n", "   <!-- LOCALIZATION MODE -->\n", "   <param name=\"Mem/IncrementalMemory\" type=\"string\" value=\"false\"/>\n", "</node>\n", "</launch>", "$ rosrun rtabmap_ros rgbd_odometry --params\n", "or\n", "$ rosrun rtabmap_ros stereo_odometry --params\n", "or\n", "$ rosrun rtabmap_ros icp_odometry --params", "$rosrun rtabmap_ros rtabmap --params | grep Optimize"]},
{"url": "https://wiki.ros.org/turtlebot_follower", "package": "turtlebot_follower", "package_summary": ["Follower for the turtlebot. Follows humans and robots around by following the centroid of a box points in front of the turtlebot."], "package_details": ["\n", "\n", "Before running the follower, make sure your TurtleBot is setup: ", "To start the follower, open an SSH terminal on the TurtleBot laptop, and run the following command: ", "The follower should now be running. To initiate following, walk in front of the TurtleBot. Then, slowly walk away from the TurtleBot. The robot should move forward. Moving close to the TurtleBot will cause it to back away. Moving slowly to the left or right will cause the TurtleBot to turn. To stop the robot from following, walk quickly away from the robot. ", "To get more details about running TurtleBot follower, please take a look to the ", " "], "package_code": ["roslaunch turtlebot_follower follower.launch"]},
{"url": "https://wiki.ros.org/blort", "package": "blort", "package_summary": ["\n    BLORT - The Blocks World Robotic Vision Toolbox ", "\n    Ported and refactored version of the library.\n  "], "package_details": [" ", " ", "\n", "\n"]},
{"url": "https://wiki.ros.org/kurt3d", "package": "kurt3d", "package_summary": ["\n\n     kurt3d\n\n  "], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/rosatomic", "package": "rosatomic", "package_summary": ["rosatomic provides the C++11-style atomic operations by pulling symbols from the proposed Boost.Atomic\n     package into the ros namespace.  Once C++11-style atomics (std::atomic) are available from compilers, rosatomic will\n     conditionally use those instead."]},
{"url": "https://wiki.ros.org/naoqi_bridge_msgs", "package": "naoqi_bridge_msgs", "package_summary": ["The naoqi_bridge_msgs package provides custom messages for running Aldebaran's robot such as NAO and Pepper. See the packages nao_robot and pepper_robot for details."]},
{"url": "https://wiki.ros.org/kobuki_gazebo", "package": "kobuki_gazebo", "package_summary": ["Kobuki simulation for Gazebo"], "package_details": [" ", "\n", "\n", "Refer to the Kobuki's ", " tutorial. "]},
{"url": "https://wiki.ros.org/turtlebot_arm_ikfast_plugin", "package": "turtlebot_arm_ikfast_plugin", "package_summary": ["The turtlebot_arm_ikfast_plugin package"]},
{"url": "https://wiki.ros.org/tf2", "package": "tf2", "package_summary": ["tf2 is the second generation of the transform library, which lets\n    the user keep track of multiple coordinate frames over time. tf2\n    maintains the relationship between coordinate frames in a tree\n    structure buffered in time, and lets the user transform points,\n    vectors, etc between any two coordinate frames at any desired\n    point in time."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " is the core of a group of packages which form the 2nd generation of ", ".  There are three types of packages. ", "\n", " implements templated datatype support. This allows the core packages to have minimal dependencies and there be packages which add support for converting to and from different datatypes as well as transforming those data types. Please see ", " overview, and ", " for how to use tf2 with different datatypes. ", " does have an internal datatypes which are based on ", "'s LinearMath library. However it's recommended to use a fully supported math datatype which best supports your application. ", " conversion methods also support converting between and transforming between multiple different datatypes too. ", "\n", "\n", "\n", " In previous versions there was a concept of a ", " which would be prepended to the frame name using a ", " separator. A leading slash used to indicate that it had already been prefixed. For backwards compatibility tf2 will strip any leading ", " character. ", " ", " ", "\n", "\n", " provides basic geometry data types, such as ", ", ", ", ", ", ", ". These data types support linear algebra operations between each other. ", "\n", "\n", "\n", "\n", " ", "You want to ", " what tf can do instead of just reading about it? Check out the ", ". ", "A robotic system typically has many 3D ", " that change over ", ", such as a world frame, base frame, gripper frame, head frame, etc. tf2 keeps track of all these frames over time, and allows you to ask questions like: ", "tf2 can operate in a ", ". This means all the information about the coordinate frames of a robot is available to all ROS components on any computer in the system.  Tf2 can operate with a central server that contains all transform information, or you can have every component in your distributed system build its own transform information database. ", "For more information on the design see ", " ", "There is a paper on tf presented at TePRA 2013 ", " ", "We created a set of ", " that walk you through using tf2, step by step. You can get started on the ", " tutorial. For a complete list of all tf2 and tf2-related tutorials check out the ", " page. ", "Once you are finished with the basic tutorials, you can move on to learn about tf2 and time. The tf2 and time tutorial ", " ", " teaches the basic principles of tf2 and time. The advanced tutorial about tf2 and time ", " ", " teaches the principles of time traveling with tf2. ", "If you are looking for an easy tool to manually tweak tf transforms, such as for quick calibration-by-eye tuning, try ", " ", "The ", " described the high level design of the tf2 library. ", "At it's core ", " relies on the ", " which can be conveniently correlated to ROS messages which have a ", ". ", "Coordinate frames in ROS are identified by a string ", " in the format lower case underscore separated. This string has to be unique in the system. All data produced can simply identify it's ", " to state where it is in the world. ", "The concept of ", " ", " is not scoped in the same way as ", ". In particular, namespacing a specific subpart of a computation graph does not change the physical layout which the ", " tree represents. Because of this ", "s do not follow namespace remapping rules. It is common to support a ", " to allow changing ", "s used in algorithms. ", "For use cases with multiple robots it is generally recommended to use multiple masters and forward specific tf information between the robots. There are several different methods of implementing bridges between masters. For more information please see the ", ". ", "These packages provide the primary interface for developers using ", ". ", "For more information about migrating from ", " see ", " "], "package_tt": ["tf2", "tf2", "tf2", "bullet", "tf2", "tf2", "frame_id", "frame_id", "tf_prefix", "tf_prefix", "/", "/", "tf", "frame_ids", "tf", "frame_id", "frame_id", "tf2", "BufferListener", "BufferBroadcaster", "BufferServer", "BufferClient", "BufferListener", "BufferBroadcaster", "BufferClient"]},
{"url": "https://wiki.ros.org/xbot", "package": "xbot", "package_summary": ["Software for xbot, Droid Robot's mobile research base."], "package_details": ["\n", "\n", "Introduction: ", " ", "Tutorial: ", " "]},
{"url": "https://wiki.ros.org/ar_track_alvar", "package": "ar_track_alvar", "package_summary": ["This package is a ROS wrapper for Alvar, an open source AR tag tracking library."], "package_tt": ["visualization_marker", "ar_pose_marker", "Camera\u00a0frame\u00a0(from\u00a0Camera\u00a0info\u00a0topic\u00a0param)", "AR\u00a0tag\u00a0frame", "visualization_marker", "ar_pose_marker", "Camera\u00a0frame\u00a0(from\u00a0Camera\u00a0info\u00a0topic\u00a0param)", "AR\u00a0tag\u00a0frame", "marker_size", "max_new_marker_error", "max_track_error", "camera_image", "camera_info", "output_frame", "./bundles", "marker_size", "max_new_marker_error", "max_track_error", "camera_image", "camera_info", "output_frame", "bundle_files", "(e.g.)\u00a0/kinect_head/rgb/camera_info", "(any\u00a0topic\u00a0in\u00a0an\u00a0image\u00a0format)", "visualization_marker", "ar_pose_marker", "Camera\u00a0frame\u00a0(from\u00a0Camera\u00a0info\u00a0topic\u00a0param)", "AR\u00a0tag\u00a0frame", "visualization_marker", "ar_pose_marker", "Camera\u00a0frame\u00a0(from\u00a0Camera\u00a0info\u00a0topic\u00a0param)", "AR\u00a0tag\u00a0frame"], "package_code": ["$ git clone https://github.com/sniekum/ar_track_alvar.git\n", "$ git checkout f093668", "$ sudo apt-get install ros-fuerte-ar-track-alvar", "\n", "\n", "\n", "$ sudo apt-get install ros-indigo-ar-track-alvar", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/asmach", "package": "asmach", "package_summary": ["\n    SMACH, which stands for 'state machine', is a task-level\n    architecture for rapidly creating complex robot behavior. At its\n    core, SMACH is a ROS-independent Python library to build\n    hierarchical state machines.  SMACH is a new library that takes\n    advantage of very old concepts in order to quickly create robust\n    robot behavior with maintainable and modular code.\n  "]},
{"url": "https://wiki.ros.org/trac_ik_examples", "package": "trac_ik_examples", "package_summary": ["This package contains the source code for testing and comparing trac_ik"]},
{"url": "https://wiki.ros.org/sr_example", "package": "sr_example", "package_summary": ["\n\n    sr_example is an example of a real package interfaced with our robot. Please refer to the tutorial Creating a package to interact with our robots.\n\n  "], "package_details": ["\n", "Please refer to ", " for more information. "]},
{"url": "https://wiki.ros.org/turtlebot_core_apps", "package": "turtlebot_core_apps", "package_summary": ["\n\n    The core set of turtlebot 'app manager' apps are defined in this package.\n\n  "]},
{"url": "https://wiki.ros.org/hostapd_access_point", "package": "hostapd_access_point", "package_summary": ["\n    A ROS node that controls a hostapd-based access\n    point. It is mainly intended for use with a wireless \n    network adapter running in master mode. It implements \n    the dynamic_reconfigure interface defined\n    in the [[access_point_control]] package.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", ":  ", "\n", "A ROS node for starting and controlling a hostapd-based access point. This node works with wifi adapters that have ", "-compatible drivers which support master mode (see ", " for more information). ", "This is an example that shows how to set up an access point and control its parameters using the ", " interface. ", "The following launch file starts an AP node on the ", " interface and the ", ": ", "The desired configuration is selected: mode ", ", channel 44, WPA security with the chosen password, a TX power level of 8 dBm and a TX bitrate of 24Mbit/s. Next the ", " checkbox is checked at the AP is started: ", "This script is useful for setting up a ", "-based setup. mac80211_hwsim is a 802.11 radio simulator. The script takes two parameters: ", "If the mac80211_hwsim is not loaded or if the number of radios it has currently spawned is smaller than ", " then it is re-loaded with the proper radio count. The script prints to its output the name of the ", "-th interface. ", "For example (this is taken from a real setup), suppose that the system has a real wireless interface with name ", " and we need to spawn three virtual interfaces. Their names will be ", ", ", " and ", ".  ", "Using ", ": ", "The script can be used to launch nodes on the ", " with roslaunch. The following example, launches two nodes on the first and second mac80211_hwsim interfaces while ensuring that there are at least three total interfaces: "], "package_tt": ["ap_hostapd_node.py", "~interface", "string", "wlan0", "wlan1", "~ip", "string", "~netmask", "string", "~hostapd_path", "string", "hostapd", "~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string", "reconfigure_gui", "wlan0", "reconfigure_gui", "a", "enabled", "mac80211_hwsim", "radio\u00a0index", "total\u00a0number\u00a0of\u00a0radios", "total\u00a0number\u00a0of\u00a0radios", "radio\u00a0index", "wlan1", "wlan0", "wlan1", "wlan2", "find_hwsim_iface.py", "wlan0", "hwsim_nat_setup.sh", "network_traffic_control", "ap_hostapd_node.py"], "package_code": ["<launch>\n", "    <node name=\"ap_wlan0\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" value=\"wlan0\"/>\n", "        <param name=\"ip\" value=\"192.168.68.1\"/>\n", "        <param name=\"netmask\" value=\"255.255.255.0\"/>\n", "    </node>\n", "    <node name=\"reconfigure_node\" pkg=\"dynamic_reconfigure\" type=\"reconfigure_gui\"/>\n", "</launch>", "import dynamic_reconfigure.client\n", "\n", "ap = dynamic_reconfigure.client.Client(\"ap_wlan0\")\n", "\n", "freq = IEEE80211_Channels.get_freq(44, IEEE80211_Channels.BAND_5000_MHz)\n", "config = ap.update_configuration({\"enabled\": True, \"mode\": 'a', \"freq\": freq, \"encryption_mode\": \"wpa\", \"encryption_pass\": \"sample_password\", \"txpower_auto\": False, \"txpower\": 8, \"bitrate\": 24*10**6})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])\n", "\n", "freq = IEEE80211_Channels.get_freq(1, IEEE80211_Channels.BAND_2400_MHz)\n", "config = ap.update_configuration({\"freq\": freq})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 1 3`\n", "wlan0\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 2 3`\n", "wlan1\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 3 3`\n", "wlan1", "<launch>\n", "    <node name=\"ap1\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 1 3\"/>\n", "    </node>\n", "\n", "    <node name=\"ap2\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 2 3\"/>\n", "    </node>\n", "</launch>", "# rosrun hostapd_access_point hwsim_nat_setup.sh wlan0 192.168.68.1 192.168.69.1 wlan1 192.168.69.2 192.168.68.2\n", "\n", "# ifconfig wlan0\n", "wlan0     Link encap:Ethernet  HWaddr 02:00:00:00:00:00  \n", "          inet addr:192.168.68.1  Bcast:192.168.68.255  Mask:255.255.255.0\n", "\n", "# ifconfig wlan1\n", "wlan1     Link encap:Ethernet  HWaddr 02:00:00:00:01:00  \n", "          inet addr:192.168.69.2  Bcast:192.168.69.255  Mask:255.255.255.0"]},
{"url": "https://wiki.ros.org/willow_maps", "package": "willow_maps", "package_summary": ["Holds maps of Willow Garage that can be used for a number of different applications."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/pr2_navigation_global", "package": "pr2_navigation_global", "package_summary": ["This package holds XML files for running the"], "package_details": ["\n", "\n", "\n", "\n", "This package contains configuration files for the ", " and ", " nodes meant to be run in an application that requires global navigation with a pre-specified static map. This package also includes launch files that bring up ", " and ", " with global navigation specific configurations. "], "package_tt": ["rviz/rviz_move_base.launch", "nav_view/nav_view_move_base.launch", "move_base.xml", "amcl_node.xml", "config/base_local_planner_params.yaml", "config/global_costmap_params.yaml", "move_base.xml", "config/local_costmap_params.yaml", "move_base.xml"]},
{"url": "https://wiki.ros.org/jog_controller", "package": "jog_controller", "package_summary": ["The jog_controller package"]},
{"url": "https://wiki.ros.org/pcl_msgs", "package": "pcl_msgs", "package_summary": ["Package containing PCL (Point Cloud Library)-related ROS messages."]},
{"url": "https://wiki.ros.org/tensorflow_ros_cpp", "package": "tensorflow_ros_cpp", "package_summary": ["Catkin-friendly C++ bindings for the tensorflow package."], "package_details": [" ", "\n", " are available for each of the options. ", "\n", "\n", " ", "See the usage example at ", " . ", "A comprehensive list of compatible options for various OSes and ROS distros is available ", ". ", "Ubuntu systems starting with 16.04 (Xenial) are using the new C++11 ABI for all system libraries. Until ", "  gets resolved (if ever!), the pip-distributed Tensorflow is built  againts an older C++ ABI, which is incompatible with the C++11 ABI. This  means linking to the Tensorflow library will fail on such systems and  there's no way around it. ", "An example of this approach can be found at ", ". "], "package_tt": ["<run_depend>python-tensorflow-pip</run_depend>"], "package_code": ["find_package(catkin REQUIRED COMPONENTS\n", "  ... your other packages ...\n", "  tensorflow_ros_cpp\n", ")", "rosdep install ... --skip-keys=tensorflow_catkin --skip-keys=python-tensorflow-pip"]},
{"url": "https://wiki.ros.org/laser_scan_sparsifier", "package": "laser_scan_sparsifier", "package_summary": ["The laser_scan_sparsifier takes in a LaserScan message and sparsifies it."], "package_details": ["\n", "\n", "\n", "\n", " ", "The ", " package is used to downsample ", " messages. ", "Two drivers are available: ", " and ", ". Their parameters and topics are identical. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["laser_scan_sparsifier_nodelet", "laser_scan_sparsifier_node", "laser_scan_sparsifier", "scan", "scan_sparse", "~step", "int"]},
{"url": "https://wiki.ros.org/wheeled_robin_rviz_launchers", "package": "wheeled_robin_rviz_launchers", "package_summary": ["Launchers for visualizing WheeledRobin"], "package_details": ["\n", "\n", "\n", "\n", " ", "This package provides several launch files for ", " to visualize ", ". ", "First launch the robot either in real or faked mode and start the Kinect drivers (see Getting Started section in ", "). "], "package_code": ["roslaunch wheeled_robin_rviz_launchers view_robot.launch"]},
{"url": "https://wiki.ros.org/ntpd_driver", "package": "ntpd_driver", "package_summary": ["ntpd_driver sends TimeReference message time to ntpd server"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Just add to ", ": ", "Add this to ", ": "], "package_tt": ["/etc/ntp.conf", "/etc/chrony/chrony.conf", "~time_ref", "~shm_unit", "int"], "package_code": ["### GPS SHM driver (unit 2)\n", "server 127.127.28.2 minpoll 4 maxpoll 4\n", "fudge 127.127.28.2 time1 0.5 stratum 12 refid ROS", "### SHM driver (unit 2)\n", "refclock SHM 2 delay 0.5 refid ROS"]},
{"url": "https://wiki.ros.org/waypoint_generator", "package": "waypoint_generator", "package_summary": ["Generates waypoint yaml file"]},
{"url": "https://wiki.ros.org/turtlebot3_follower", "package": "turtlebot3_follower", "package_summary": ["The follower demo was implemented using a 360 Laser Distance Sensor LDS-01. The classification algorithm is used based on previous fitting with samples of person and obstacles positions to take actions. It follows someone in front of the robot within a 50 centimeter range and 140 degrees."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["scan_filtered", "cmd_vel"]},
{"url": "https://wiki.ros.org/toposens_description", "package": "toposens_description", "package_summary": ["3D models of the sensor for visualization."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/schunk_libm5api", "package": "schunk_libm5api", "package_summary": ["This package wraps the libm5api to use it as a ros dependency. Original sources from http://www.schunk-modular-robotics.com/fileadmin/user_upload/software/schunk_libm5api_source.zip."]},
{"url": "https://wiki.ros.org/ridgeback_control", "package": "ridgeback_control", "package_summary": ["Controllers for Ridgeback"], "package_details": ["\n", "'s mobility is controlled by mecanum_drive_controller. "]},
{"url": "https://wiki.ros.org/jsk_gui_msgs", "package": "jsk_gui_msgs", "package_summary": ["jsk_gui_msgs"]},
{"url": "https://wiki.ros.org/turtlebot3_autorace_detect", "package": "turtlebot3_autorace_detect", "package_summary": ["AutoRace ROS packages for feature detection with TurtleBot3 Auto"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output_sub1/compressed", "detect/image_output_sub2/compressed", "detect/image_output", "detect/image_output_sub1", "detect/image_output_sub2", "detect/yellow_line_reliability", "detect/white_line_reliability", "detect/image_input/compressed", "detect/image_input", "detect/level_crossing_order", "control/level_crossing_finished", "detect/image_output/compressed", "detect/image_output_sub1/compressed", "detect/image_output", "detect/image_output_sub1", "detect/level_crossing_stamped", "control/level_crossing_start", "control/max_vel", "detect/parking_lot_order", "detect/scan", "control/parking_finished", "detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output", "detect/parking_lot_stamped", "control/parking_start", "control/max_vel", "detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output", "detect/traffic_sign", "detect/image_input/compressed", "detect/image_input", "control/traffic_light_finished", "detect/image_output/compressed", "detect/image_output", "detect/image_output_sub1/compressed", "detect/image_output_sub2/compressed", "detect/image_output_sub3/compressed", "detect/image_output_sub1", "detect/image_output_sub2", "detect/image_output_sub3", "detect/traffic_light_stamped", "control/traffic_light_start", "control/max_vel", "detect/tunnel_order", "move_base/result", "odom", "detect/tunnel_stamped", "move_base_simple/goal", "control/cmd_vel", "control/max_vel"], "package_code": ["#------------------ parameter for HSL detection of withe lane ------------------#\n", "gen.add(\"hue_white_l\",         int_t,   0,   \"hue_white_l\",         0,   0, 179)\n", "gen.add(\"hue_white_h\",         int_t,   0,   \"hue_white_h\",         179, 0, 179)\n", "gen.add(\"saturation_white_l\",  int_t,   0,   \"saturation_white_l\",  0,   0, 255)\n", "gen.add(\"saturation_white_h\",  int_t,   0,   \"saturation_white_h\",  255, 0, 255)\n", "gen.add(\"lightness_white_l\",   int_t,   0,   \"lightness_white_l\",   0,   0, 255)\n", "gen.add(\"lightness_white_h\",   int_t,   0,   \"lightness_white_h\",   255, 0, 255)\n", "\n", " ------------------ parameter for HSL detection of yellow lane -----------------#\n", "gen.add(\"hue_yellow_l\",        int_t,   0,   \"hue_yellow_l\",        0,   0, 179)\n", "gen.add(\"hue_yellow_h\",        int_t,   0,   \"hue_yellow_h\",        179, 0, 179)\n", "gen.add(\"saturation_yellow_l\", int_t,   0,   \"saturation_yellow_l\", 0,   0, 255)\n", "gen.add(\"saturation_yellow_h\", int_t,   0,   \"saturation_yellow_h\", 255, 0, 255)\n", "gen.add(\"lightness_yellow_l\",  int_t,   0,   \"lightness_yellow_l\",  0,   0, 255)\n", "gen.add(\"lightness_yellow_h\",  int_t,   0,   \"lightness_yellow_h\",  255, 0, 255)", "#------------------ parameter for HSL detection of red color ------------------#\n", "gen.add(\"hue_red_l\",           int_t,   0,   \"hue_red_l\",           0,   0, 179)\n", "gen.add(\"hue_red_h\",           int_t,   0,   \"hue_red_h\",           179, 0, 179)\n", "gen.add(\"saturation_red_l\",    int_t,   0,   \"saturation_red_l\",    0,   0, 255)\n", "gen.add(\"saturation_red_h\",    int_t,   0,   \"saturation_red_h\",    255, 0, 255)\n", "gen.add(\"lightness_red_l\",     int_t,   0,   \"lightness_red_l\",     0,   0, 255)\n", "gen.add(\"lightness_red_h\",     int_t,   0,   \"lightness_red_h\",     255, 0, 255)", "#------------- parameter for HSL detection of traffic red light ---------------#\n", "gen.add(\"hue_red_l\",           int_t,   0,   \"hue_red_l\",           0,   0, 179)\n", "gen.add(\"hue_red_h\",           int_t,   0,   \"hue_red_h\",           179, 0, 179)\n", "gen.add(\"saturation_red_l\",    int_t,   0,   \"saturation_red_l\",    0,   0, 255)\n", "gen.add(\"saturation_red_h\",    int_t,   0,   \"saturation_red_h\",    255, 0, 255)\n", "gen.add(\"lightness_red_l\",     int_t,   0,   \"lightness_red_l\",     0,   0, 255)\n", "gen.add(\"lightness_red_h\",     int_t,   0,   \"lightness_red_h\",     255, 0, 255)\n", "\n", "#------------ parameter for HSL detection of traffic yellow light -------------#\n", "gen.add(\"hue_yellow_l\",        int_t,   0,   \"hue_yellow_l\",        0,   0, 179)\n", "gen.add(\"hue_yellow_h\",        int_t,   0,   \"hue_yellow_h\",        179, 0, 179)\n", "gen.add(\"saturation_yellow_l\", int_t,   0,   \"saturation_yellow_l\", 0,   0, 255)\n", "gen.add(\"saturation_yellow_h\", int_t,   0,   \"saturation_yellow_h\", 255, 0, 255)\n", "gen.add(\"lightness_yellow_l\",  int_t,   0,   \"lightness_yellow_l\",  0,   0, 255)\n", "gen.add(\"lightness_yellow_h\",  int_t,   0,   \"lightness_yellow_h\",  255, 0, 255)\n", "\n", "#------------ parameter for HSL detection of traffic green light --------------#\n", "gen.add(\"hue_green_l\",         int_t,   0,   \"hue_green_l\",         0,   0, 179)\n", "gen.add(\"hue_green_h\",         int_t,   0,   \"hue_green_h\",         179, 0, 179)\n", "gen.add(\"saturation_green_l\",  int_t,   0,   \"saturation_green_l\",  0,   0, 255)\n", "gen.add(\"saturation_green_h\",  int_t,   0,   \"saturation_green_h\",  255, 0, 255)\n", "gen.add(\"lightness_green_l\",   int_t,   0,   \"lightness_green_l\",   0,   0, 255)\n", "gen.add(\"lightness_green_h\",   int_t,   0,   \"lightness_green_h\",   255, 0, 255)"]},
{"url": "https://wiki.ros.org/pheeno_ros", "package": "pheeno_ros", "package_summary": ["The pheeno_ros package contains necessary files for run and control an individual Pheeno unit with ROS."], "package_details": ["\n", "Documentation for our package can be found ", ". We will also be adding documentation to this ROS page in the coming weeks. "]},
{"url": "https://wiki.ros.org/rtctree", "package": "rtctree", "package_summary": ["API for interacting with running RT-Components and managing RTM-based systems using OpenRTM-aist."]},
{"url": "https://wiki.ros.org/octomap_msgs", "package": "octomap_msgs", "package_summary": ["This package provides messages and serializations / conversion for the ", "."], "package_details": [" ", "\n", " "]},
{"url": "https://wiki.ros.org/graph_rviz_plugin", "package": "graph_rviz_plugin", "package_summary": ["An RViz plugin to draw graphs from topics values"], "package_details": ["Documentation is here: ", " "]},
{"url": "https://wiki.ros.org/vigir_pluginlib_msgs", "package": "vigir_pluginlib_msgs", "package_summary": ["The vigir_pluginlib_msgs package"], "package_details": ["\n", "The ", " package provides basic message definition needed for inter-process communication via ROS. See ", ". "]},
{"url": "https://wiki.ros.org/pr2_2dnav", "package": "pr2_2dnav", "package_summary": ["This application allows the PR2 robot to navigate autonomously with a pre-specified static map."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "As with all PR2 applications, you must ", ". ", "This application assumes that a map is provided. Please see documentation on the ", " for information on providing a map over ROS. ", "Tuck the arms of the PR2 using the ", ". ", "The ", " application can be run with the following command: ", "The ", " stack that is the heart of the pr2_2dnav application can be commanded via ", ", ", ", or through code. "], "package_code": ["roslaunch pr2_2dnav pr2_2dnav.launch", "roslaunch pr2_navigation_global rviz_move_base.launch", "roslaunch pr2_navigation_global nav_view_move_base.launch"]},
{"url": "https://wiki.ros.org/costmap_2d", "package": "costmap_2d", "package_summary": ["This package provides an implementation of a 2D costmap that takes in sensor\n        data from the world, builds a 2D or 3D occupancy grid of the data (depending\n        on whether a voxel based implementation is used), and inflates costs in a\n        2D costmap based on the occupancy grid and a user specified inflation radius.\n        This package also provides support for map_server based initialization of a\n        costmap, rolling window based costmaps, and parameter based subscription to\n        and configuration of sensor topics."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "The ", " package provides a configurable structure that maintains information about where the robot should navigate in the form of an occupancy grid. The costmap uses sensor data and information from the static map to store and update information about obstacles in the world through the ", " object. The ", " object provides a purely two dimensional interface to its users, meaning that queries about obstacles can only be made in columns. For example, a table and a shoe in the same position in the XY plane, but with different Z positions would result in the corresponding cell in the ", " object's costmap having an identical cost value. This is designed to help planning in planar spaces. ", "As of the Hydro release, the underlying methods used to write data to the costmap is fully configurable. Each bit of functionality exists in a layer. For instance, the static map is one layer, and the obstacles are another layer. By default, the obstacle layer maintains information three dimensionally (see ", "). Maintaining 3D obstacle data allows the layer to deal with marking and clearing more intelligently. ", "The main interface is ", " which maintains much of the ROS related functionality. It contains a ", " which is used to keep track of each of the layers. Each layer is instantiated in the ", " using ", " and is added to the ", ". The layers themselves may be compiled individually, allowing arbitrary changes to the costmap to be made through the C++ interface. The ", " class implements the basic data structure for storing and accessing the two dimensional costmap. ", "While each cell in the costmap can have one of 255 different cost values (see the ", " section), the underlying structure that it uses is capable of representing only three. Specifically, each cell in this structure can be either free, occupied, or unknown. Each status has a special cost value assigned to it upon projection into the costmap. Columns that have a certain number of occupied cells (see ", " parameter) are assigned a ", " cost, columns that have a certain number of unknown cells (see ", " parameter) are assigned a ", " cost, and other columns are assigned a ", " cost. ", "The costmap performs map update cycles at the rate specified by the ", " parameter. Each cycle, sensor data comes in, marking and clearing operations are perfomed in the underlying occupancy structure of the costmap, and this structure is projected into the costmap where the appropriate cost values are assigned as described ", ". After this, each obstacle inflation is performed on each cell with a ", " cost. This consists of propagating cost values outwards from each occupied cell out to a user-specified inflation radius. The details of this inflation process are outlined ", ". ", "In order to insert data from sensor sources into the costmap, the ", " object makes extensive use of ", ". Specifically, it assumes that all transforms between the coordinate frames specified by the ", " parameter, the ", " parameter, and sensor sources are connected and up-to-date. The ", " parameter sets the maximum amount of latency allowed between these transforms. If the ", " tree is not updated at this expected rate, the ", " stops the robot. ", "There are two main ways to initialize a ", " object. The first is to seed it with a user-generated static map (see the ", " package for documentation on building a map). In this case, the costmap is initialized to match the width, height, and obstacle information provided by the static map. This configuration is normally used in conjunction with a localization system, like ", ", that allows the robot to register obstacles in the map frame and update its costmap from sensor data as it drives through its environment. ", "The second way to initialize a ", " object is to give it a width and height and to set the ", " parameter to be true.  The ", " parameter keeps the robot in the center of the costmap as it moves throughout the world, dropping obstacle information from the map as the robot moves too far from a given area. This type of configuration is most often used in an odometric coordinate frame where the robot only cares about obstacles within a local area. "], "package_tt": ["costmap_2d", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::LayeredCostmap", "Costmap2DROS", "LayeredCostmap", "costmap_2d::Costmap2D", "costmap_2d::LETHAL_OBSTACLE", "costmap_2d::NO_INFORMATION", "costmap_2d::FREE_SPACE", "costmap_2d::LETHAL_OBSTACLE", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2D", "costmap_2d::Costmap2DROS", "~<name>/obstacles", "~<name>/inflated_obstacles", "~<name>/unknown_space", "~<name>/voxel_grid", "<point_cloud_topic>", "\"PointCloud\"", "observation_sources", "<point_cloud2_topic>", "\"PointCloud2\"", "observation_sources", "<laser_scan_topic>", "\"LaserScan\"", "observation_sources", "\"map\"", "costmap_2d::Costmap2DROS", "~<name>/global_frame", "string", "\"/map\"", "~<name>/robot_base_frame", "string", "\"base_link\"", "~<name>/transform_tolerance", "double", "global_frame", "robot_base_frame", "transform_tolerance", "ros::Time::now()", "~<name>/update_frequency", "double", "~<name>/publish_frequency", "double", "~<name>/max_obstacle_height", "double", "~<name>/obstacle_range", "double", "~<name>/raytrace_range", "double", "~<name>/cost_scaling_factor", "double", "exp(-1.0\u00a0*\u00a0cost_scaling_factor\u00a0*\u00a0(distance_from_obstacle\u00a0-\u00a0inscribed_radius))\u00a0*\u00a0(costmap_2d::INSCRIBED_INFLATED_OBSTACLE\u00a0-\u00a01)", "~<name>/inflation_radius", "double", "~<name>/footprint", "list", "~<name>/robot_radius", "double", "~<name>/observation_sources", "string", "\"\"", "<source_name>", "source_name", "observation_sources", "~<name>/<source_name>/topic", "string", "source_name", "~<name>/<source_name>/sensor_frame", "string", "\"\"", "sensor_msgs/LaserScan", "sensor_msgs/PointCloud", "sensor_msgs/PointCloud2", "~<name>/<source_name>/observation_persistence", "double", "~<name>/<source_name>/expected_update_rate", "double", "~<name>/<source_name>/data_type", "string", "\"PointCloud\"", "\"PointCloud\"", "\"PointCloud2\"", "\"LaserScan\"", "~<name>/<source_name>/clearing", "bool", "false", "~<name>/<source_name>/marking", "bool", "true", "~<name>/<source_name>/max_obstacle_height", "double", "max_obstacle_height", "max_obstacle_height", "~<name>/<source_name>/min_obstacle_height", "double", "~<name>/<source_name>/obstacle_range", "double", "~<name>/<source_name>/raytrace_range", "double", "~<name>/static_map", "bool", "true", "rolling_window", "~<name>/rolling_window", "bool", "false", "static_map", "~<name>/unknown_cost_value", "int", "~<name>/publish_voxel_map", "bool", "false", "~<name>/lethal_cost_threshold", "int", "~<name>/map_topic", "string", "~<name>/width", "int", "~<name>/height", "int", "~<name>/resolution", "double", "~<name>/origin_x", "double", "~<name>/origin_y", "double", "~<name>/map_type", "string", "\"voxel\"", "\"voxel\"", "\"costmap\"", "map_type", "\"voxel\"", "~<name>/origin_z", "double", "~<name>/z_resolution", "double", "~<name>/z_voxels", "int", "~<name>/unknown_threshold", "int", "~<name>/mark_threshold", "int", "~<name>/track_unknown_space", "bool", "false", "(value\u00a0of\u00a0global_frame\u00a0parameter)", "(value\u00a0of\u00a0robot_base_frame\u00a0parameter)", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2DPublisher", "raw_obstacles", "inflated_obstacles", "unknown_space", "Costmap2DPublisher", "costmap_2d::Costmap2D", "costmap_2d::Costmap2D", "costmap_2d::Costmap2DROS", "cosmtap_2d::Costmap2D", "costmap_2d::VoxelCostmap2D", "Costmap2D", "costmap_2d::VoxelCostmap2D", "costmap_2d::VoxelCostmap2D", "costmap_2d::Costmap2DROS", "costmap_2d::VoxelCostmap2D", "costmap_2d::ObservationBuffer", "costmap_2d::ObservationBuffer", "costmap_2d::Costmap2DROS", "costmap_2d::ObservationBuffer", "costmap_2d::Costmap2DROS", "costmap_2d::Costmap2D", "costmap_2d::Costmap2DROS", "rosrun", "roslaunch", "costmap_2d", "costmap", "move_base", "~<name>/footprint", "~<name>/costmap", "~<name>/costmap_updates", "~<name>/voxel_grid", "costmap_2d", "plugins", "static_layer", "obstacle_layer", "inflation_layer", "plugins", "~<name>/plugins", "sequence", "~<name>/global_frame", "string", "\"/map\"", "~<name>/robot_base_frame", "string", "\"base_link\"", "~<name>/transform_tolerance", "double", "global_frame", "robot_base_frame", "transform_tolerance", "ros::Time::now()", "~<name>/update_frequency", "double", "~<name>/publish_frequency", "double", "~<name>/rolling_window", "bool", "false", "static_map", "~<name>/always_send_full_costmap", "bool", "false", "~<name>/width", "int", "~<name>/height", "int", "~<name>/resolution", "double", "~<name>/origin_x", "double", "~<name>/origin_y", "double", "(value\u00a0of\u00a0global_frame\u00a0parameter)", "(value\u00a0of\u00a0robot_base_frame\u00a0parameter)", "costmap_2d::Costmap2DROS", "ObstacleCostmapPlugin"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/naoqi_tools", "package": "naoqi_tools", "package_summary": ["Set of tools provided by Aldebaran to convert Aldebaran files (URDF, blender...)"]},
{"url": "https://wiki.ros.org/base_local_planner", "package": "base_local_planner", "package_summary": ["This package provides implementations of the Trajectory Rollout and Dynamic Window approaches to local robot navigation on a plane. Given a plan to follow and a costmap, the controller produces velocity commands to send to a mobile base. This package supports both holonomic and non-holonomic robots, any robot footprint that can be represented as a convex polygon or circle, and exposes its configuration as ROS parameters that can be set in a launch file. This package's ROS wrapper adheres to the BaseLocalPlanner interface specified in the ", " package."], "package_details": ["\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 2.5) ", " (", ", default: [-0.3, -0.1, 0.1, 0.3]) ", "\n", " (", ", default: 0.05) ", "\n", " (", ", default: 1.0) ", "\n", " (", ", default: ", ") ", "\n", " (", ", default: 0.05) ", "\n", " (", ", default: ", ") ", "\n", "\n", "The ", " package provides a controller that drives a mobile base in the plane.  This controller serves to connect the path planner to the robot.  Using a map, the planner creates a kinematic trajectory for the robot to get from a start to a goal location. Along the way, the planner creates, at least locally around the robot, a value function, represented as a grid map.  This value function encodes the costs of traversing through the grid cells.  The controller's job is to use this value function to determine dx,dy,dtheta velocities to send to the robot. ", "The groovy release of ROS includes a new implementation of the ", " package. The implementation attempts to be more modular, to allow easier creation of custom local planners while reusing a lot of code. The code base of base_local_planner has been extended with several new headers and classes. ", "The interfaces and classes below capture the generic local planning principles allowing many instantiations. It should be possible to create custom local planners using the ", " as template and just adding own cost functions or trajectory generators. ", "This interface describes a Generator which may generate a finite or infinte number of trajectories, returning a new one on each invocation of ", ".  ", "The ", " class can generate trajectories described in the overview, using either the trajectory rollout or the DWA principle. ", "This interface contains most importantly ", ", which takes a trajectory and returns a score. A negative score means the trajectory is invalid. For positive value, the semantics are that a trajectory with a lower score is preferrable to one with a higher score with respect to this cost function. ", "The ", " package ships with some cost functions used on the PR2, described below. ", "This is a simple implementation of a trajectory search, taking a ", " and a list of ", ". It will invoke ", " until the generator stops generating trajectories. For each, trajectory, it will loop over the list of cost functions, adding up their positive values or aborting the scoring if one cost function returns a negative value. ", "The ", " is a Controller that can be used as soon as the robot is close enough to the goal. The Controller will then just perform a full stop and a rotation on the spot towards the goal orientation, regardless of whether the robot position after the full stop leads the robot outside the goal position tolerance. ", "The ", " object is a ", " for a ", " object that exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "There are a large number of ROS ", " that can be set to customize the behavior of the ", " wrapper. These parameters are grouped into several categories: robot configuration, goal tolerance, forward simulation, trajectory scoring, oscillation prevention, and global plan. ", "The following parameters are only used if ", " is set to true: ", "The ", " provides implementations of the DWA and Trajectory Rollout algorithms described earlier. In order to use the ", " with ROS, please use the ", ". It is not recommended to use the ", " on its own. ", "The C++ API is stable. However, it is recommended that you use the ", " instead of using the ", " on its own. "], "package_tt": ["base_local_planner", "dwa_local_planner", "nextTrajectory()", "SimpleTrajectoryGenerator", "scoreTrajectory(Trajectory\u00a0&traj)", "base_local_planner", "TrajectorySampleGenerator", "TrajectoryCostFunction", "nextTrajectory()", "base_local_planner::TrajectoryPlannerROS", "base_local_planner::TrajectoryPlanner", "nav_core::BaseLocalPlanner", "base_local_planner::TrajectoryPlannerROS", "~<name>/global_plan", "~<name>/local_plan", "~<name>/cost_cloud", "publish_cost_grid_pc", "odom", "robot_base_frame", "TrajectoryPlannerROS\u00a0object", "robot_base_frame", "base_local_planner::TrajectoryPlannerROS", "~<name>/acc_lim_x", "double", "~<name>/acc_lim_y", "double", "~<name>/acc_lim_theta", "double", "~<name>/max_vel_x", "double", "~<name>/min_vel_x", "double", "~<name>/max_vel_theta", "double", "~<name>/min_vel_theta", "double", "~<name>/min_in_place_vel_theta", "double", "~<name>/backup_vel", "double", "~<name>/escape_vel", "double", "~<name>/holonomic_robot", "bool", "holonomic_robot", "~<name>/y_vels", "list", "~<name>/yaw_goal_tolerance", "double", "~<name>/xy_goal_tolerance", "double", "~<name>/latch_xy_goal_tolerance", "bool", "~<name>/sim_time", "double", "~<name>/sim_granularity", "double", "~<name>/angular_sim_granularity", "double", "~<name>/vx_samples", "integer", "~<name>/vtheta_samples", "integer", "~<name>/controller_frequency", "double", "~<name>/meter_scoring", "bool", "false", "gdist_scale", "pdist_scale", "goal_distance", "path_distance", "~<name>/pdist_scale", "double", "~<name>/gdist_scale", "double", "~<name>/occdist_scale", "double", "~<name>/heading_lookahead", "double", "~<name>/heading_scoring", "bool", "false", "~<name>/heading_scoring_timestep", "double", "~<name>/dwa", "bool", "true", "~<name>/publish_cost_grid_pc", "bool", "false", "sensor_msgs/PointCloud2", "~<name>/cost_cloud", "~<name>/global_frame_id", "string", "odom", "cost_cloud", "~<name>/oscillation_reset_dist", "double", "~<name>/prune_plan", "bool", "true", "base_local_planner::TrajectoryPlanner", "base_local_planner::TrajectoryPlanner", "base_local_planner::TrajectoryPlanner", "base_local_planner::TrajectoryPlanner"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "cost = \n", "  pdist_scale * (distance to path from the endpoint of the trajectory in map cells or meters depending on the meter_scoring parameter) \n", "  + gdist_scale * (distance to local goal from the endpoint of the trajectory in map cells or meters depending on the meter_scoring parameter) \n", "  + occdist_scale * (maximum obstacle cost along the trajectory in obstacle cost (0-254))"]},
{"url": "https://wiki.ros.org/kdl_parser_py", "package": "kdl_parser_py", "package_summary": ["The Kinematics and Dynamics Library (KDL) defines a tree structure\n   to represent the kinematic and dynamic parameters of a robot\n   mechanism. ", " provides Python tools to construct a KDL\n   tree from an XML robot representation in URDF."], "package_tt": ["kdl_parser_py", "kdl_parser_py", "kdl_parser_py", "kdl_parser_py", "kdl_parser_py"]},
{"url": "https://wiki.ros.org/rosmon", "package": "rosmon", "package_summary": ["Node launcher and monitor for ROS. rosmon is a replacement\n\t\tfor the roslaunch tool, focused on performance, remote\n\t\tmonitoring, and usability."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "rosmon is a drop-in replacement for the venerable ", " tool. It offers some interesting features both for monitoring and debugging: ", "The ", " specification is complex and a bit vague, so you can expect some differences. Bug reports are welcome! Known differences include: ", "For additional information and rosmon extensions not supported by roslaunch see ", ". ", "rosmon can also be controlled remotely using an ", " plugin, which uses rosmon's ROS interface. The context menu offers starting and stopping control. Additionally collected statistics (CPU and memory usage) are displayed. "], "package_tt": ["<machine>", "~state", "~start_stop"], "package_code": ["sudo apt install ros-${ROS_DISTRO}-rosmon\n", "\n", "source /opt/ros/${ROS_DISTRO}/setup.bash # Needed to use the 'mon launch' shortcut", "mon launch <package> <launch file> [arguments]", "mon launch <path to launch file> [arguments]", "Usage:\n", "  rosmon [actions] [options] some_package test.launch [arg1:=value1 ...]\n", "  rosmon [actions] [options] path/to/test.launch [arg1:=value1 ...]\n", "\n", "Actions (default is to launch the launch file):\n", "  --benchmark    Exit after loading the launch file\n", "  --list-args    List launch file arguments\n", "\n", "Options:\n", "  --disable-ui   Disable fancy terminal UI\n", "  --help         This help screen\n", "  --log=FILE     Write log file to FILE\n", "  --name=NAME    Use NAME as ROS node name. By default, an anonymous\n", "                 name is chosen.\n", "\n", "rosmon also obeys some environment variables:\n", "  ROSMON_COLOR_MODE   Can be set to 'truecolor', '256colors', 'ansi'\n", "                      to force a specific color mode\n", "                      If unset, rosmon tries to detect the best\n", "                      available color mode."]},
{"url": "https://wiki.ros.org/adhoc_communication", "package": "adhoc_communication", "package_summary": ["The adhoc_communication package allows to exchange data over an ad-hoc network setup by robots running the corresponding node. The package allows you to exchange data over serveral roscores by wrapping transmitting the data to the destination and publishing the data on a predefined topic at the destination host. Routing is accomplished using the hostname of the robots."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", ":      srv ", ":        sendQuaternion.srv ", ":", " ", "\n", ": ad_hoc_communication.cpp ", "\n", "\n", ": ad_hoc_communication.cpp ", ": publishPacket ", "  ", "The node ", " allows you to exchange data over an ad-hoc network protocol via dynamic source routing. The package allows you to exchange data over serveral roscores. The node will send the data to the destination robot and publish the message on the destination on a given topic. The routing is done with the hostname of the robots. ", "One-to-Many communication. Every robot has its own multicast group, which will be created when the ", " node is starting. The name of the group will be \"", "\" plus the hostname. If a robots hostname is \"", "\", its multicast group is called \"", "\". All other robots can join a group with the service ", ". All members of a group can send data within this group. ", "You may obtain the paper from ", " or search in  ", ". ", "It's ", " that the node always runs with root rights because the protocol is implement using raw sockets requiring root. ", "\n", "\nMark node to automatically run as root by setting the SUID bit:", "\n ", " ", "\n  ", "\n ", "To send custom messages you just need to serialize a message to a string and then send it with the service ", ". To serialize any type of ROS message you can use this function: ", "Include the service in ", " ", "Function: ", " ", "Service name is ", ". ", " ", "Adapt the function ", " that the new payload type will be published. To deserialize the message, the function from Step 4 is used. ", " "], "package_code": ["@InProceedings{Andre2014,\n", "  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},\n", "  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},\n", "  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},\n", "  Year                     = {2014},\n", "  Month                    = dec,\n", "}", "template <class t>\n", "std::string getSerializedMessage(t message)\n", "{\n", "    /* Description:\n", "     * returns a serialized ROS message as string to send it over network.\n", "     */\n", "    uint32_t serial_size = ros::serialization::serializationLength(message);\n", "    boost::shared_array<uint8_t> buffer(new uint8_t[serial_size]);\n", "    ros::serialization::OStream streamOut(buffer.get(), serial_size);\n", "    ros::serialization::serialize(streamOut, message);\n", "\n", "    std::string serialized_map = \"\";\n", "    serialized_map.append((const char*) buffer.get(), serial_size);\n", "\n", "    return serialized_map;\n", "}", "template <class t>\n", "void desializeObject(unsigned char* serialized_message, uint32_t length, t * obj)\n", "{\n", "    /* Description:\n", "     * de-serialize a ROS message from a buffer.\n", "     */\n", "\n", "    try\n", "    {\n", "        ros::serialization::IStream stream(serialized_message, length);\n", "        ros::serialization::deserialize(stream, *obj);\n", "    } catch (ros::serialization::StreamOverrunException e)\n", "    {\n", "        ROS_ERROR(\"IN desializeObject: NODE THROWS EXCEPTION: %s \", e.what());\n", "        ROS_ERROR(\"PARAMETERS: length=[%u] object type=[%s]\", length, typeid (*obj).name());\n", "    }\n", "}", "string topic\n", "geometry_msgs/Quaternion Quaternion\n", "string destinationHost\n", "---\n", "uint8 successfullySend", "#include \"mapExchange/sendQuaternion.h\""]},
{"url": "https://wiki.ros.org/tuw_multi_robot_router", "package": "tuw_multi_robot_router", "package_summary": ["This package contains a MultiRobotRouter using Prioritized Planning in Combination with a collision resolution algorithm to find a routing tabel for a large number of robots."], "package_details": ["\n", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", " (", ") ", "  (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "  (", ") ", " (", ") ", "  (", ") ", "\n", " (", " default: \"\") ", "\n", " (", " default: \"true\") ", " (", " default: \"true\") ", " (", " default: \"true\") ", " (", " default: \"10.0\") ", " (", " default: \"10.0\") ", " (", " default: \"false\") ", " (", " default: \"Avoidance\") ", " (", " default: \"use_voronoi_goal\") ", " (", " default: \"standard_router\") ", " (", " default: \"1\") ", "\n", "Use GitHub to ", ". [", "]", "\n ", "The Multi Robot Mode is the default mode. The planner listens to ", " see how many robots are online and available for planning. A list of goals can be send to ", "  ", "Since the results generated for these scenarios are interdependent, the given routes have to be executed in a synchronized fashion. Therefore, the Router publishes a tuw_multi_robot_msgs/Route containing preconditions, when a robot is allowed to enter a segment. Additionally a unsynchronized version via nav_msgs/Path is published for every robot. "], "package_tt": ["/robot_info", "goal", "path_endpoint_optimization", "robot_name", "/robot_info", "tuw_multi_robot_msgs/RobotInfo", "/robot_info.\u00a0", "map", "nav_msgs/OccupancyGrid", "segments", "tuw_multi_robot_msgs/Graph", "tuw_multi_robot_msgs/Vertex", "goals", "tuw_multi_robot_msgs/RobotGoalArray", "/goal", "geometry_msgs", "/PoseStamped", "planner_status", "tuw_multi_robot_msgs/PlannerStatus", "[robot_name]/path", "nav_msgs/Path", "[robot_name]\u00a0", "/robot_info", "[robot_name]/route", "tuw_multi_robot_msgs/Route", "robot_name", "string", "voronoi_graph", "bool", "priority_rescheduling", "bool", "speed_rescheduling", "bool", "router_time_limit_s", "float", "topic_timeout_s", "float", "path_endpoint_optimization", "bool", "collision_resolver", "enum", "goal_mode", "enum", "router_type", "enum", "nr_threads", "int"]},
{"url": "https://wiki.ros.org/rb1_base_description", "package": "rb1_base_description", "package_summary": ["The rb1_base_description package"]},
{"url": "https://wiki.ros.org/octomap_server", "package": "octomap_server", "package_summary": ["octomap_server loads a 3D map (as Octree-based OctoMap) and distributes it to other nodes in a compact binary format. It also allows to incrementally build 3D OctoMaps, and provides map saving in the node octomap_saver."], "package_details": ["\n", "\n", "\n", " and ", " offer a dynamic_reconfigure interface to change the displayed map resolution on the fly (since version 0.3.8). Note that this will not change the resolution of the underlying ", ", but only of the published marker / collision topics (e.g. for visualization). ", "\n", "\n", "General information about OctoMap is available at ", " and in the publication ", " by A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard (Autonomous Robots Journal, 2013). ", "Please cite our paper if you use OctoMap in your research. ", "Use the alufr-ros-pkg ", " to report bugs or request features. For questions (and FAQ), check ", ". "], "package_tt": ["cloud_in", "octomap_binary", "octomap_full", "occupied_cells_vis_array", "octomap_point_cloud_centers", "octomap_collision_object", "collision_map_out", "map\u00a0(up\u00a0to\u00a0fuerte)\u00a0/\u00a0projected_map\u00a0(since\u00a0fuerte)", "projected_map", "octomap_binary", "~clear_bbx", "~reset", "~frame_id", "string", "~resolution", "float", "~base_frame_id", "string", "~height_map", "bool", "~color/[r/g/b/a]", "float", "~sensor_model/max_range", "float", "~sensor_model/[hit|miss]", "float", "~sensor_model/[min|max]", "float", "~latch", "bool", "~filter_ground", "bool", "~ground_filter/distance", "float", "~ground_filter/angle", "float", "~ground_filter/plane_distance", "float", "~pointcloud_[min|max]_z", "float", "~occupancy_[min|max]_z", "float", "sensor\u00a0data\u00a0frame", "/map\u00a0(static\u00a0world\u00a0frame,\u00a0changeable\u00a0with\u00a0parameter\u00a0frame_id)"], "package_code": ["@ARTICLE{hornung13auro,\n", "  author = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill\n", "  Stachniss and Wolfram Burgard},\n", "  title = {{OctoMap}: An Efficient Probabilistic {3D} Mapping Framework Based\n", "  on Octrees},\n", "  journal = {Autonomous Robots},\n", "  year = 2013,\n", "  url = {http://octomap.github.com},\n", "  doi = {10.1007/s10514-012-9321-0},\n", "  note = {Software available at \\url{http://octomap.github.com}}\n", "}"]},
{"url": "https://wiki.ros.org/force_sensor_handler", "package": "force_sensor_handler", "package_summary": ["The force_sensor_handler package"]},
{"url": "https://wiki.ros.org/ur5_moveit_config", "package": "ur5_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the ur5 with the MoveIt Motion Planning Framework"], "package_details": ["\n", "\n", "\n", "This package is part of the ", " program. It is the ", "! configuration for the UR5 arm, generated automatically by the ", " Setup Assistant. ", "Install the package from package management, and run the MoveIt! planning demo: ", "This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR5, see the ", " package. ", "See also the relevant sections in the ", " on Github. "], "package_tt": ["moveit_simple_controller_manager"], "package_code": ["$ sudo apt-get install ros-$ROS_DISTRO-ur5-moveit-config\n", "\n", "$ roslaunch ur5_moveit_config demo.launch"]},
{"url": "https://wiki.ros.org/euscollada", "package": "euscollada", "package_summary": ["euscollada"], "package_details": ["\n", "\n", " and ", " ", "Documentation is available ", ". ", "Use trac to report ", " or ", ". ", " "]},
{"url": "https://wiki.ros.org/stage", "package": "stage", "package_summary": ["Mobile robot simulator http://rtv.github.com/Stage"], "package_details": ["\n", "For detailed documentation on the Stage .world file format, consult the ", " , ", " or  ", ". "], "package_tt": ["stageros", ".world", "world", "stage", "robot_<i>/", "robot_0/cmd_vel", "cmd_vel", "robot_<i>/", "robot_0/cmd_vel", "odom", "base_scan", "base_pose_ground_truth", "odom", "base_pose_ground_truth", "base_pose_ground_truth", "~base_watchdog_timeout", "cmd_vel", "base_link", "base_laser", "base_footprint", "base_link", "odom", "base_footprint"], "package_code": ["stageros [-g runs headless] <world> [standard ROS args]"]},
{"url": "https://wiki.ros.org/std_srvs", "package": "std_srvs", "package_summary": ["Common service definitions."], "package_details": ["\n", " contains two service types called ", " and ", ", which are common service patterns for sending a signal to a ROS node. For the ", " service, no actual data is exchanged between the service and the client. The ", " service adds the possibility to check if triggering was successful or not.  ", "For common message definitions, please see the ", " package. "], "package_tt": ["std_srvs", "Empty", "Trigger", "Empty", "Trigger"]},
{"url": "https://wiki.ros.org/win_pymercurial", "package": "win_pymercurial", "package_summary": ["\n\nBuild script for python (only) mercurial module.\n\n  "]},
{"url": "https://wiki.ros.org/canopen_motor_node", "package": "canopen_motor_node", "package_summary": ["canopen_chain_node specialization for handling of canopen_402 motor devices. It facilitates interface abstraction with ros_control."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The objects used in the conversion functions and the drive modes should be mapped to PDOs for best performance.", " ", "\n", "\n", " ", "The canopen_motor_node package provides a ", " interface to [canopen_402]] compliant motors. It is based on ", " and inherits all its interfaces, so this site just focuses on the additional interfaces. ", "The node includes a ", " instance that can be used to spawn ", " compliant controllers. ", "Depending on the motor device different interfaces are support. ", "For each joint a ", " is registered with the position, velocity and effort of the specific drive. The actual value is determined by the conversion functions. ", "The output from the controller is limited by ", " and not passed directly to the motor. ", "The limits can be read from URDF or the ", ": ", ". ", "The driver features ", " based conversion functions. ", "In addition to the predefined ", " and ", ", the following functions are available: ", "Further two constants are defined for convenience: ", " and ", ". ", "The conversion functions from ROS the device units can read the commands from the respective ", ",", " and ", " variables. ", "The conversion functions from device to ROS supports an extended notion with obj prefixes: E.g. ", " will read the actual position and ", " will read  the gear ration nominator. ", "The basic configuration is described in ", ". ", "For the canopen_motor_node to work each node is given a ", " parameter that defaults to the CANopen node name and is used as joint name in the ", " interfaces. ", "For each motor node a ", " can be specified which is used to load a motor plugin with ", ", it defaults to the ", " implementation. ", "All settings contained in the 'motor_layer' parameter will be passed to the motor layer instance. ", "In summary the following parameters are supported in ", " section and per node: ", "The canopen_motor_node exposes the ROS interfaces of ", ". ", "In addition the interfaces of ", " are available after initialization. ", "However, the controller_manager is stopped when shutdown service ist called. ", "The ", " will read its limits from the URDF and from the ParameterServer. The latter takes precedence but does not support soft limits. ", "The current implementation does not expose a C++ API, but it is planned for the future: ", " "], "package_tt": ["hardware_interface::JointStateHandle", "hardware_interface::PositionJointInterface", "hardware_interface::VelocityJointInterface", "hardware_interface::EffortJointInterface", "pi", "nan", "pos", "vel", "eff", "obj6064", "obj6091sub1", "joint", "motor_allocator", "defaults", "init"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/asr_ftc_local_planner", "package": "asr_ftc_local_planner", "package_summary": ["A local planner which based on the \"follow the carrot\" algorithm. Drives accurate along the global plan"], "package_details": [" ", "\n", "\n", " ", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", " ", "\n", "\n", "\n", " ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", " ", " ", "This package provides an implementation of the \"", "\" algorithm to local robot navigation on a flat plane. Given a global plan to follow and a costmap, the local planner produces velocity commands to send to a mobile base. The parameters for this planner are also dynamically reconfigurable. This package implements the asr_nav_core interface for a local planner. For this to work the standard ", " and ", " must be adapted (look at kapitel 3.1 Needed Packages). ", "In this pictures you can see the function graph of the slow down factor. The first one depicts braking without a slow down factor -> the robot rotates a long time with minimal rotation velocity. With the slow down factor in the second picture the robot rotates not as long with a minimal rotation velocity. ", "You can also look at this ", " with a point by point description on how to setup the navigation to use the ftc_local_planner. ", "Manually adapt the two packages ", " and ", ": ", "You can use the launch files in ", ": "], "package_tt": ["~<name>/local_plan", "~max_x_vel", "double", "~max_rotation_vel", "double", "~min_rotation_vel", "double", "~acceleration_x", "double", "~acceleration_z", "double", "~position_accuracy", "double", "~rotation_accuracy", "double", "~slow_down_factor", "double", "~sim_time", "double", "~local_planner_frequence", "int", "~join_obstacle", "bool"], "package_code": ["tc_->setGlobalCostmap(planner_costmap_ros_);", "void setGlobalCostmap(costmap_2d::Costmap2DROS* global_costmap_ros){\n", "     global_costmap_ros_ = global_costmap_ros;\n", "}", "costmap_2d::Costmap2DROS* global_costmap_ros_;", "<node name=\"move_base\" pkg=\"asr_move_base\" type=\"move_base\" respawn=\"false\" output=\"screen\">\n", "\n", "<param name=\"controller_frequency\" value=\"5.0\"/> <param   name=\"planner_frequency\" value=\"10\"/> <param name=\"base_local_planner\" value=\"ftc_local_planner/FTCPlanner\" />\n", "\n", "... yaml files ....\n", "\n", "</node>", "global_costmap/obstacle_layer:\n", "    enabled: true", "join_obstacle: true", "roslaunch asr_mild_navigation simulation_manual_rearranged.launch", "roslaunch asr_mild_navigation navigation.launch"]},
{"url": "https://wiki.ros.org/sr_hardware_interface", "package": "sr_hardware_interface", "package_summary": ["\n\n    This package contains the actuator used in the hand model.\n\n  "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/pr2_dashboard_aggregator", "package": "pr2_dashboard_aggregator", "package_summary": ["A simple script that aggregates all of the topics that a \"pr2_dashboard\" app might be interested in."], "package_details": ["\n", "\n"], "package_tt": ["pr2_dashboard_aggregator", "pr2.launch", "pr2_dashboard_aggregator", "power_board/state", "power_state", "ddwrt/accesspoint", "pr2_etherCAT/motors_halted", "dashboard_agg"]},
{"url": "https://wiki.ros.org/summit_x_control", "package": "summit_x_control", "package_summary": ["This package contains the launch files that load the required controller interfaces for simulation in Gazebo."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/message_runtime", "package": "message_runtime", "package_summary": ["Package modeling the run-time dependencies for language bindings of messages."]},
{"url": "https://wiki.ros.org/turtlebot_android", "package": "turtlebot_android", "package_summary": ["\n    This stack contains android applications for turtlebot.\n  "], "package_details": ["\n", "Thanks to the great job of Kazuto Murase, we have the the old Android ROS apps updated and improved. See ", " for more details. On this stack we add some extra apps specific for ", ". If you just want to use them, install the ", " (Groovy) or ", " (Hydro) and connect to the turtlebot. It will download the follower for you from the app list. ", "But if you want to make your own apps, or try to compile the apps by yourself, proceed with the ", ". "]},
{"url": "https://wiki.ros.org/win_python_build_tools", "package": "win_python_build_tools", "package_summary": ["Collects all the ros python build tools packages together in \n    one installer.", "\n", "Currently bundles in a single msi installer: ", "\n", "The rosinstall installation is based around a 32 bit version of python (x86). This must be the case even for win64 as many python modules do not yet have 64 bit versions. This is not a big issue, so don't worry. ", " If upgrading from win_ros for fuerte, first uninstall vcstools, rosinstall and rospkg. ", ": ", " ", " ", " ", " ", " ", " ", " ", " - select '", "' ", "/", " ", " ", "Finally, add ", " and ", " to your ", " variable if not already present. ", ": ", " - catkin-pkg, rospkg, vcstools, wstool, win_ros ", "\n", " ", "You shouldn't need to use these directly as they are support modules only. ", " ", "Options are identical to that for ", ". An example one liner: ", "An example of repeated use: ", " Note that we don't make use of ", " anymore. ", " ", "The win_ros module provides a few convenience scripts, currently ", ", ", " and ", ". They are mostly just simple wrappers around cmake and catkin functionality tailored for windows. If you want to know more in detail about the build process, the ", " are fairly self explanatory. "], "package_tt": ["Run\u00a0git\u00a0and\u00a0unix\u00a0tools\u00a0from\u00a0windows\u00a0command\u00a0prompt", "C:\\Python27\\", "C:\\Python27\\Scripts", "PATH", "rosws", "winros_init_workspace", "winros_init_build", "winros_make"], "package_code": ["> wstool init src https://raw.github.com/ros-windows/win_ros/groovy-devel/msvc_unstable.rosinstall", "> mkdir src\n", "> cd src\n", "> wstool init .\n", "> wstool set catkin --git https://github.com/yujinrobot/catkin.git\n", "> wstool set genmsg --git git://github.com/ros/genmsg.git\n", "> wstool set gencpp --git git://github.com/ros/gencpp.git\n", "> wstool set genpy --git git://github.com/ros/genpy.git\n", "> wstool update catkin\n", "> wstool update genmsg\n", "> wstool update gencpp\n", "> wstool update genpy"]},
{"url": "https://wiki.ros.org/xbot_driver", "package": "xbot_driver", "package_summary": ["C++ driver library for xbot:\n    Pure C++ driver library for xbot. This is for those who do not wish to use ROS on their systems."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rtabmap", "package": "rtabmap", "package_summary": ["RTAB-Map's standalone library. RTAB-Map is a RGB-D SLAM approach with real-time constraints."], "package_details": ["\n", "\n", "Visit ", " to know how to use RTAB-Map under ROS. The ", " package is only for convenient release of the RTAB-Map libraries and standalone application. Visit ", " to know how to use the standalone application and ", " that come with this package: ", "If you use ", " in academic context, please cite the appropriate publication from ", " "], "package_code": ["$ rtabmap"]},
{"url": "https://wiki.ros.org/scan_to_cloud_converter", "package": "scan_to_cloud_converter", "package_summary": ["Converts LaserScan to PointCloud messages."], "package_details": ["\n", "\n", "\n", "\n", " ", "The ", " converts ", " to  ", " messages. ", "The ouput cloud message has the ", " attribute set to ", ". Ranges in the scan message which are outside ", " are represented by ", " values in the output cloud. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "], "package_tt": ["is_dense", "false", "(min_range,\u00a0max\u00a0range)", "nan", "scan_to_cloud_converter", "scan", "cloud"]},
{"url": "https://wiki.ros.org/wpi_jaco_wrapper", "package": "wpi_jaco_wrapper", "package_summary": ["ROS Wrapper for the JACO Arm Developed at WPI"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains nodes to interface ROS with the JACO API.  It includes publishing angular and Cartesian commands to the arm, generating and following trajectories from input such as ", "!, rotational representation conversions between ROS and the JACO API, and forward kinematics. ", "The ", " package uses a configuration file to set most of the parameters for its nodes.  This allows for support of different types of arms, such as the Jaco, Jaco2, or the Mico.  The configuration files are located within the ", " directory, which includes a ", " file, ", " file, and ", " file that define default parameter values for the Jaco, Jaco2, and Mico arms respectively.  The parameters include: ", "The ", " provides three different options for trajectory execution, each of which has its own action server and its own set of advantages and disadvantages.  The specifics of each trajectory follower, how they compare to eachother, and situations where each one may be applicable are detailed below. ", "The ", " action server provides the simplest trajectory execution method.  This method sends each point to the JACO arm using the Kinova API, which will then execute the trajectory using its PID controller to move the arm from point to point.  This is the most accurate and precise trajectory follower for point-to-point motion, but for complex trajectories with many points, the point-to-point motion causes the arm to stop at each point resulting in a jerky, uneven overally motion.  As such, this trajectory follower is recommended only for simple trajectories that are comprised of a small number of points spaced far apart, such as pre-defined trajectories for basic motions. ", "The ", " action server works similarly to the point-to-point trajectory follower provided by ", ", with the addition of the Kinova API's trajectory smoothing.  This is accomplished through first converting the trajectory points from joint position points to Cartesian end effector points.  The Kinova API then smooths the trajectory of the end effector.  This has the disadvantage of requiring the full trajectory to avoid the singularity protection zones defined internally, so this trajectory follower should only be used for trajectories generated from planners that are aware of these protection zones, or for pre-defined trajectories. ", "The ", " action server provides an alternative to the previous two methods (which rely on trajectory execution through the Kinova API) by using its own trajectory controller and trajectory follower based on velocity control.  The trajectory points are used to generate a linear interpolated trajectory with smoothed corners using the ", " package.  The trajectory is then followed using a velocity controller, defined in the ", " file, that sends its control inputs as joint velocity commands through the Kinova API.  This controller is the recommended trajectory follower for execution of complex trajectories with many points, such as those generated by ", "!'s motion planners, as it uses joint control and is therefore not subject to the singularity constraints of the smoothed point-to-point trajectory follower. ", "This package is designed to work with the 2- or 3-fingered gripper included with the JACO, JACO2, and MICO.  With it's default behavior, the wrapper node will publish joint states for the fingers, and includes gripper control action servers.  If you are using an alternative end-effector for your arm, setting the kinova_gripper argument in the ", " file will disable the finger joint state publishing and the gripper action servers.  ", "This package has been updated to work with the new JACO2.  There is one important difference to note when using this package with the JACO2 instead of the JACO or the MICO.  For the JACO and MICO, the joint state names are published as ", ".  The JACO2 publishes joint state names under a different set of names for compatibility with a new arm urdf.  The joint names, in order from the base to the end-effector, are: [", ", ", ", ", ", ", ", ", ", ", "] ", "See the metapackage, ", ", for any other limitations of using this package with the JACO2. ", "To install the ", " package, you can install from source with the following commands: ", "The ", " package contains the launch file ", " which will launch all of the nodes required to send trajectories and manipulation commands to the JACO arm.  Note that the launch file will remap some of the topic names for the trajectory execution actions (this is done for easier ", "! integration), but these can be changed if desired by editing the launch file.  This can be launched with the following command: "], "package_tt": ["wpi_jaco_wrapper", "jaco_arm/arm_controller/trajectory/goal", "jaco_arm/smooth_arm_controller/trajectory/goal", "jaco_arm/joint_velocity_controller/trajectory/goal", "jaco_arm/fingers_controller/gripper/goal", "jaco_arm/fingers_controller_radian/gripper/goal", "jaco_arm/home_arm/goal", "jaco_arm/arm_controller/trajectory/result", "jaco_arm/smooth_arm_controller/trajectory/result", "jaco_arm/joint_velocity_controller/trajectory/result", "jaco_arm/fingers_controller/gripper/result", "jaco_arm/fingers_controller_radian/gripper/result", "jaco_arm/home_arm/result", "jaco_arm/angular_cmd", "jaco_arm/cartesian_cmd", "jaco_arm/joint_states", "jaco_arm/angular_cmd", "jaco_arm/cartesian_cmd", "jaco_arm/arm_homed", "jaco_arm/get_angular_position", "jaco_arm/get_cartesian_position", "jaco_arm/software_estop", "jaco_arm/erase_trajectories", "jaco_arm/kinematics/fk", "jaco_conversions/quaternion_to_euler", "jaco_arm/erase_trajectories", "wpi_jaco/arm_name", "string", "wpi_jaco/finger_scale", "float", "wpi_jaco/finger_error_threshold", "float", "wpi_jaco/gripper_open", "float", "wpi_jaco/gripper_closed", "float", "wpi_jaco/max_curvature", "double", "wpi_jaco/max_speed_finger", "float", "wpi_jaco/num_fingers", "int", "home_arm_on_init", "bool", "kinova_gripper", "bool", "jaco_arm/manipulation/gripper/goal", "jaco_arm/manipulation/lift/goal", "jaco_arm/manipulation/gripper/result", "jaco_arm/manipulation/pickup/result", "jaco_arm/joint_states", "jaco_arm/angular_cmd", "jaco_arm/cartesian_cmd", "jaco_arm/get_cartesian_position", "wpi_jaco/arm_name", "string", "wpi_jaco/gripper_open", "float", "wpi_jaco/gripper_closed", "float", "wpi_jaco/num_fingers", "int", "kinova_gripper", "bool", "jaco_conversions/euler_to_quaternion", "jaco_conversions/quaternion_to_euler", "wpi_jaco/arm_name", "string", "jaco_arm/kinematics/fk", "wpi_jaco/arm_name", "string", "wpi_jaco_wrapper", "config", "jaco.yaml", "jaco2.yaml", "mico.yaml", "jaco_arm_trajectory_node", "jaco_arm/arm_controller", "jaco_arm/smooth_arm_controller", "jaco_arm/arm_controller", "jaco_arm/joint_velocity_controller", "jaco_arm_trajectory_node.cpp", "arm.launch", "[arm_name]_joint_[joint_number]", "jaco_shoulder_pan_joint", "jaco_shoulder_lift_joint", "jaco_elbow_joint", "jaco_wrist_1_joint", "jaco_wrist_2_joint", "jaco_wrist_3_joint", "wpi_jaco", "wpi_jaco_wrapper", "arm.launch"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch wpi_jaco_wrapper arm.launch"]},
{"url": "https://wiki.ros.org/theora_image_transport", "package": "theora_image_transport", "package_summary": ["Theora_image_transport provides a plugin to image_transport for\n    transparently sending an image stream encoded with the Theora codec."], "package_details": ["\n", " is a plugin package for ", ". It enables any node using ", " classes to publish and subscribe to image topics compressed over the wire using the Theora video codec. ", " only works with 8-bit color or grayscale images. ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "See ", " for general instruction on using ", ". "], "package_tt": ["theora_image_transport", "image_transport", "theora_image_transport", "image_transport", "<base\u00a0topic>/theora", "<base\u00a0topic>/theora/optimize_for", "int", "Quality", "~theora/target_bitrate", "~theora/quality", "Bitrate", "Quality", "<base\u00a0topic>/theora/target_bitrate", "int", "optimize_for", "Bitrate", "<base\u00a0topic>/theora/quality", "int", "optimize_for", "Quality", "<base\u00a0topic>/theora/keyframe_frequency", "int", "<base\u00a0topic>/theora", "~theora/post_processing_level", "int", "ogg_saver", "<image>/theora", "image", "stream"], "package_code": ["$ rosrun theora_image_transport ogg_saver image:=<base_topic> [output_file.ogv]"]},
{"url": "https://wiki.ros.org/rostime", "package": "rostime", "package_summary": ["Time and Duration implementations for C++ libraries, including roscpp."], "package_details": [" ", "\n", "Please see ", ". "]},
{"url": "https://wiki.ros.org/sr_robot_msgs", "package": "sr_robot_msgs", "package_summary": ["\n\n     sr_robot_msgs contains some messages used in the shadow_robot stack.\n\n  "], "package_details": ["\n", "This package contains messages specific to our packages. They are defined in a separate package to minimize the dependencies between packages. If you develop a node to interact with ours, most of the time, you only need to depend on this package (and not on ", "). "]},
{"url": "https://wiki.ros.org/naoqi_pose", "package": "naoqi_pose", "package_summary": ["\n          This package contains nodes for managing Nao's poses.\n    "], "package_details": ["\n", "\n"], "package_tt": ["body_pose", "joint_trajectory", "~xap", "string", "~poses", "list", "joint_angles_action/goal", "joint_trajectory/goal", "joint_stiffness_trajectory/goal", "body_pose_naoqi/goal", "joint_angles", "joint_stiffness", "body_stiffness/disable", "body_stiffness/enable", "rest", "wakeup", "~poll_rate", "float", "~init_stiffness"]},
{"url": "https://wiki.ros.org/kurt_bringup", "package": "kurt_bringup", "package_summary": ["\n\n     kurt_bringup\n\n  "]},
{"url": "https://wiki.ros.org/clear_costmap_recovery", "package": "clear_costmap_recovery", "package_summary": ["This package provides a recovery behavior for the navigation stack that attempts to clear space by reverting the costmaps used by the navigation stack to the static map outside of a given area."], "package_details": ["\n", "\n", "\n", "\n", " (", ", default: 3.0) ", "\n", "The ", " is a simple recovery behavior that clears out space in the navigation stack's ", " by reverting to the static map outside of a given radius away from the robot. It adheres to the ", " interface found in the ", " package and can be used as a recovery behavior ", " for the ", " node. ", "The ", " object exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "The C++ ", " class adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". "], "package_tt": ["clear_costmap_recovery::ClearCostmapRecovery", "nav_core::RecoveryBehavior", "clear_costmap_recovery::ClearCostmapRecovery", "nav_core::RecoveryBehavior", "clear_costmap_recovery::ClearCostmapRecovery", "~<name>/reset_distance", "double", "clear_costmap_recovery::ClearCostmapRecovery", "nav_core::RecoveryBehavior"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/qb_chain", "package": "qb_chain", "package_summary": ["This package contains the ROS interface to control multiple qbrobotics\u00ae devices simultaneously."]},
{"url": "https://wiki.ros.org/rosmaster", "package": "rosmaster", "package_summary": ["ROS ", " implementation."], "package_details": ["\n", "\n", "The ", " package implements the ROS ", ". Most programs will not need to interact with this package directly. The ", " is run automatically whenever ", " is run and all communication with the Master happens over XMLRPC APIs. ", "The XMLRPC API of the ROS Master is documented on the ", " page.  This API is for advanced users only and backwards compatibility is not guaranteed. "], "package_tt": ["rosmaster", "rosmaster"]},
{"url": "https://wiki.ros.org/rotors_gazebo", "package": "rotors_gazebo", "package_summary": ["The rotors_gazebo package"]},
{"url": "https://wiki.ros.org/ros_realtime", "package": "ros_realtime", "package_summary": ["The ros_realtime package"], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/rigid_body_handler", "package": "rigid_body_handler", "package_summary": ["The rigid_body_handler package"], "package_details": ["\n", "\n", "\n"], "package_code": ["pose_handl = simGetObjectAssociatedWithScript(sim_handle_self)\n", "simExtSetFloatCustomDataFromHeader(pose_handl, sim_ext_ros_bridge_obj_pose_data_main, 0.0)", "twist_handl = simGetObjectAssociatedWithScript(sim_handle_self)\n", "simExtSetIntCustomDataFromHeader(twist_handl, sim_ext_ros_bridge_set_obj_twist_data_main, 0)"]},
{"url": "https://wiki.ros.org/nao_gazebo_plugin", "package": "nao_gazebo_plugin", "package_summary": ["The nao_gazebo_plugin package"], "package_details": ["See the doc is on the github ", " "]},
{"url": "https://wiki.ros.org/ivcon", "package": "ivcon", "package_summary": ["Mesh Conversion Utility Used to generate '.iv' files from '.stl' files. This package has not been changed since 2001 and appears to be very stable. We plan on keeping this package in this revision for mesh conversions. This package is only available as a single source file for download. There are no local modifications to this package."], "package_details": ["\n", "\n", "This is a thirdparty package with ", ". "], "package_code": ["rosrun ivcon ivcon `rospack find gazebo_worlds`/meshes/000.580.67.obj 000.580.67.stlb"]},
{"url": "https://wiki.ros.org/eus_assimp", "package": "eus_assimp", "package_summary": ["eus_assimp"]},
{"url": "https://wiki.ros.org/visp_bridge", "package": "visp_bridge", "package_summary": ["Converts between ROS structures and ViSP structures."], "package_details": ["\n", " is a small interface between ViSP library and ROS. For instance it converts between the different data types used by each library. ", "To date, the supported functionnality sums up to: ", "\n", " is part of ", " stack.  ", "For usage, see the ", ". "], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-visp-bridge", "sudo apt-get install ros-$ROS_DISTRO-vision-visp"]},
{"url": "https://wiki.ros.org/widowx_arm_controller", "package": "widowx_arm_controller", "package_summary": ["The widowx_arm_controller package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/trac_ik_lib", "package": "trac_ik_lib", "package_summary": ["TRAC-IK is a faster, significantly more reliable drop-in replacement for\n    KDL's pseudoinverse Jacobian solver.\n\n    The TRAC-IK library has a very similar API to KDL's IK solver calls,\n    except that the user passes a maximum time instead of a maximum number of\n    search iterations.  Additionally, TRAC-IK allows for error tolerances to\n    be set independently for each Cartesian dimension (x,y,z,roll,pitch.yaw)."]},
{"url": "https://wiki.ros.org/schunk_description", "package": "schunk_description", "package_summary": ["This package contains the description (mechanical, kinematic, visual,\n  etc.) of different schunk components. The files in this package are parsed and used by\n  a variety of other components. Most users will not interact directly\n  with this package."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Further information ", " ", "Further information ", " ", "Further information ", " ", "Further information ", " ", "Further information ", " "]},
{"url": "https://wiki.ros.org/sr_self_test", "package": "sr_self_test", "package_summary": ["\n\n     sr_self_test\n\n  "]},
{"url": "https://wiki.ros.org/rosbag_migration_rule", "package": "rosbag_migration_rule", "package_summary": ["This empty package allows to export rosbag migration rule files without depending on rosbag."]},
{"url": "https://wiki.ros.org/pr2_ft_moveit_config", "package": "pr2_ft_moveit_config", "package_summary": ["Configuration and launch files for using the PR2 robot with force-torque sensors with the MoveIt Motion Planning Framework"], "package_details": ["\n", " ", "Configuration and launch files for using the PR2 robot with force-torque sensors with the ", " Motion Planning Framework "]},
{"url": "https://wiki.ros.org/sr_cyberglove_config", "package": "sr_cyberglove_config", "package_summary": ["\n\n    sr_cyberglove_config contains configuration files for the cyberglove (calibration, mapping) for the Shadow Robot hand\n\n  "]},
{"url": "https://wiki.ros.org/arbotix_msgs", "package": "arbotix_msgs", "package_summary": ["Messages and Services definitions for the ArbotiX."]},
{"url": "https://wiki.ros.org/vigir_step_control", "package": "vigir_step_control", "package_summary": ["The vigir_step_control package"], "package_details": ["\n", "\n", "\n", " ", "\n", " If you would like to see the system running with a real robot, then you can get in touch with it using the THORMANG3 in simulation. The full install instruction can be found ", ". ", "\n", " ", "\n", "\n", "\n", "The ", " provides a step queue management system and a state machine to keep track of current step plan execution. It is able to feed the low-level motion layer with the proper number of steps required for seamless execution while continuously merging incoming step plans provided by the ", ". This allows even for continuous walking using our ", " stack. This package provides following features: ", "For detailed information about the system please take a look at the ", ". ", "The ", " packages can be downloaded from Git", "Hub: ", "In order to run this example. you will need to install the ", " stack as well. An install instruction can be found ", ". ", "In the ", " you have first to select a footstep planner parameter set. Afterwards the direction commands become available which allows to generate simple pattern of footsteps. As soon a footstep plan has been generated the ", " button becomes active as well. When you click on this button the previously generated footsteps will be executed virtually by the ", " which fakes an footstep execution. During the fake execution, you will be able to follow the fake execution in the ", " by the progress bar. ", "The THORMANG3 provides a nice real world example how to migrate the software into an exisiting setup ", ". ", "During the Humanoids@Robo", "Cup Demo 2016 at Leipzig, the step controller was used. ", "If you would like to try it out in simulation by yourself, then just follow the instructions ", ". "], "package_tt": ["StepControllerTestPlugin"], "package_code": ["roscore\n", "roslaunch vigir_footstep_planning footstep_planner_test.launch\n", "roslaunch vigir_step_control step_controller_test.launch\n", "roslaunch vigir_footstep_planning step_interface_rqt.launch"]},
{"url": "https://wiki.ros.org/pr2_2dnav_slam", "package": "pr2_2dnav_slam", "package_summary": ["This application allows the PR2 to navigate autonomously while also building a map of its environment as it drives along."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "As with all PR2 applications, you must ", ". ", "Tuck the arms of the PR2 using the ", ". ", "The ", " stack that is the heart of the pr2_2dnav_slam application can be commanded via ", ", ", ", or through code. "], "package_code": ["roslaunch pr2_2dnav_slam pr2_2dnav.launch", "roslaunch pr2_navigation_slam rviz_move_base_slam.launch", "roslaunch pr2_navigation_slam nav_view_move_base_slam.launch"]},
{"url": "https://wiki.ros.org/pr2_2dnav_local", "package": "pr2_2dnav_local", "package_summary": ["This application allows the PR2 to navigate autonomously in an odometric frame."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "As with all PR2 applications, you must ", ". ", "Tuck the arms of the PR2 using the ", ". ", "The ", " stack that is the heart of the pr2_2dnav_local application can be commanded via ", ", ", ", or through code. "], "package_code": ["roslaunch pr2_2dnav_local pr2_2dnav.launch", "roslaunch pr2_navigation_local rviz_move_base_local.launch", "roslaunch pr2_navigation_local nav_view_move_base_local.launch"]},
{"url": "https://wiki.ros.org/ueye_cam", "package": "ueye_cam", "package_summary": ["A ROS nodelet and node that wraps the driver API for UEye cameras\n    by IDS Imaging Development Systems GMBH."], "package_details": [" git clone ", " --branch fuerte ", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "This package provides a ROS interface for the ", ". This ROS interface exposes many of the features of the underlying ", ", and is compatible with ", ", ", ", and ", ". ", "This package has been tested with the ", ", on ", ", operating with ", " cameras. ", "(side-note: it is technically possible to ", "; see video caption for outline of instructions) ", "This implementation makes use of certain C++11 features (such as std::thread, std::to_string, etc), although the CMakeLists.txt is configured for GCC >= 4.6 (and hence uses the ", " flag). ", "The IDS camera API allows users to have fine-grain control over the camera on-board processor's clock rate, which determines the range of values for frame rates, exposures, and other camera settings. This can be adjusted at runtime alongside other parameters, via ", ". It is however not recommended to operate the camera at a fast clock rate for extended periods of time, as the onboard processor may get excessively hot. Thus, ideally one should adjust the clock rate to match a target frame rate and exposure setting. ", "You may choose to use the underlying IDS camera API to perform bayer decoding and publish images as 'rgb8' or 'mono8', or alternatively choose to publish images as 'bayer_rggb8' and rely on the standard ROS ", " package for decoding. Currently, this ROS interface does not expose fine-grain control over the bayer decoding engine from the underlying IDS camera API. ", "A common mistake is to interpret the 'image_width' and 'image_height' ROS parameters as the width and height of the resulting ROS image. Unfortunately, these names were chosen to be consistent with official camera interfaces provided by IDS, and they refer to the width and height of the camera sensor's Area of Interest (AOI). Therefore, values for 'image_width' and 'image_height' that are smaller than your camera's maximum values will result in ", " (a.k.a. reduced AOI). ", "1. Install the IDS Software Suite 4.xx for Linux from ", " ", "2. create catkin workspace ", ". ", "4. Run ", " under ", ". ", "Returns raw Bayer-encoded (RGGB encoding) images from the UEye camera, and uses ", " to convert to RGB images. Also publishes on /camera/image_raw. ", "Same as rgb8.launch, but spawns the nodelet (manager) in gdb on a separate screen. ", " ", "The ueye_cam wrapper fully supports ", ". You can refer to ", " for info on calibrating your own UEye cameras. ", "All calibration files are stored by default under: ", " ", "We have connected multiple cameras in hardware to an Arduino-compatible device (a ", "), which allows any camera to act as master and any number of other cameras to act as slaves, and achieve synchronization seamlessly with unified hardware add-on required. Please see ", " for further documentation and instructions. A video demonstration of UEye camera synchronization can be seen ", ". ", "Historically speaking, ueye_cam was based on an earlier ROS package for interfacing with ", " cameras. Given that the initial work on ueye_cam was done prior to the release of other similar ROS wrappers like ", " and ", ", the original intention was to keep this code internal so as to avoid contention. Nevertheless, this code has since been released as result of a number of recent requests, with the sole hope that it may benefit the ROS community. Please check out the other packages to see which one will best suite your needs. "], "package_tt": ["<camera_name>/<camera_topic>", "<camera_name>/camera_info", "<~camera_name>/<~camera_topic>", "<~camera_name>/set_camera_info", "~camera_name", "string", "~camera_topic", "string", "~camera_id", "int", "~camera_parameters_file", "string", "~camera_intrinsics_file", "string", "~image_width", "int", "~image_height", "int", "~image_left", "int", "~image_top", "int", "~color_mode", "str", "~subsampling", "int", "~binning", "int", "~sensor_scaling", "double", "~auto_gain", "bool", "~master_gain", "int", "~red_gain", "int", "~green_gain", "int", "~blue_gain", "int", "~gain_boost", "bool", "~auto_exposure", "bool", "~exposure", "double", "~auto_white_balance", "bool", "~white_balance_red_offset", "int", "~white_balance_blue_offset", "int", "~flash_delay", "int", "~flash_duration", "int", "~ext_trigger_mode", "bool", "~auto_frame_rate", "bool", "~frame_rate", "double", "~pixel_clock", "int"]},
{"url": "https://wiki.ros.org/node_manager_fkie", "package": "node_manager_fkie", "package_summary": ["Graphical interface, written in PySide, to manage the running and \n     configured ROS nodes on different hosts. For discovering \n     the running ROS master master_discovery node will be used."], "package_details": [" ", " ", "\n", " ", "\n", "\n", "\n", "\n", "This package offers a graphical user interface (GUI) to manage ROS nodes, topics, services, parameters, and launch files in a ROS network. Combined with other tools of the ", " it is possible to operate a network with multiple masters. ", "Although the node is written in Python we need to run ", " to generate message and service types: ", "The services of ", " and ", " are detected automatically by whose names. ", "1. Error while launch a node on remote host: ", " ", "2. The ", " crashes on load a launch file with error: ", " "], "package_tt": ["ROS\u00a0Network", "Start", "ROS\u00a0Network", "Start", "roscore", "master_discovery", "static\u00a0hosts", "Refresh", "host\u00a0description\u00a0panel", "ROS_MASTER_URI", "node_manager_fkie/images", "/robot_icon", "screen", "rqt_console", "rqt_graph", "/use_sim_time", "True", "Nodes", "master_discovery", "launch", "shutdown", "SIGKILL", "screen", "Topics", "Publisher", "Subscriber", "Services", "Parameter", "get\u00a0parameter", "Launch\u00a0Dock", "root", "ROS_PACKAGE_PATH", "*.launch", "Delete", "Launch\u00a0Editor", "Description\u00a0Dock", "Node\u00a0Manager", "capability_group", "capability_group", "capabilities", "group\u00a0name", "group\u00a0type", "image", "description", "image", "node_manager_fkie", "description", "node_manager_fkie", "\\n", "namespace", "robots", "host\u00a0name", "robot\u00a0type", "displayed\u00a0name", "image", "description", "Node\u00a0Manager", "list_nodes", "default_cfg", "Cfgs", "Capability\u00a0View", "rosmake", "changes", "linkstats", "XML\u00a0Editor", "SCREEN", "rxconsole", "rxgraph", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "SIGKILL", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "SIGKILL", "SCREEN", "SCREEN's", "Nodes", "Nodes", "Nodes", "ROS\u00a0Network", "Start", "ROS\u00a0Network", "Start", ":", "roscore", "Refresh", "host\u00a0description\u00a0panel", "ROS_MASTER_URI", "node_manager_fkie/images", "screen", "rxconsole", "rxgraph", "Nodes", "master_discovery", "master_discovery", "/empty_world_server", "launch", "shutdown", "SIGKILL", "screen", "Topics", "Publisher", "Subscriber", "Services", "Parameter", "get\u00a0parameter", "Launch\u00a0Dock", "root", "ROS_PACKAGE_PATH", "*.launch", "Launch\u00a0Editor", "Description\u00a0Dock", "Node\u00a0Manager", "capability_group", "capability_group", "capabilities", "group\u00a0name", "group\u00a0type", "image", "description", "image", "node_manager_fkie", "description", "node_manager_fkie", "\\n", "namespace", "robots", "host\u00a0name", "robot\u00a0type", "displayed\u00a0name", "image", "description", "Node\u00a0Manager", "list_nodes", "default_cfg", "Cfgs", "Capability\u00a0View", "rosmake", "changes", "linkstats", "XML\u00a0Editor", "SCREEN", "rxconsole", "rxgraph", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "SIGKILL", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "rosout", "node_manager", "master_discovery", "master_sync", "default_cfg", "SIGKILL", "SCREEN", "SCREEN's", "Nodes", "Nodes", "Nodes", "catkin_make", "changes", "linkstats", "Node\u00a0Manager"], "package_code": ["  <node name=\"node_manager\" pkg=\"node_manager_fkie\" type=\"nm\" >\n", "    <param name=\"capability_group\" value=\"Management\"/>\n", "  </node>", "  <node name=\"node_manager\" pkg=\"node_manager_fkie\" type=\"nm\" >\n", "    <param name=\"capability_group\" value=\"Management\"/>\n", "    <param name=\"1.capability_group\" value=\"Node Manager\"/>\n", "  </node>", "   <rosparam param=\"capabilities\">\n", "      [\n", "        [\"Management\",\n", "         \"core\",\n", "         \"images/crystal_clear_app_network2.png\",\n", "         \"The ``management`` group provides nodes needed to detect and synchronize\n", "          other robots in the ROS network. These are:\\n\\n- Node Manager\\n- Master\n", "          Discovery\\n- Master Synchronization\"\n", "        ]\n", "      ]\n", "\n", "    </rosparam>", "  <rosparam param=\"robots\">\n", "    [\n", "      [\"tiderko\",\n", "       \"Workstation\",\n", "       \"tiderko\",\n", "       \"images/veryicon_devcom_workstation.png\",\n", "       \"Workstation\\n\\n|ws|\\n\\n.. |ws| image::\n", "        images/veryicon_devcom_workstation.png\\n\"\n", "      ]\n", "    ]\n", "  </rosparam>", "rosmake master_discovery_fkie default_cfg_fkie", "rosrun node_manager_fkie nm", "  <node name=\"node_manager\" pkg=\"node_manager_fkie\" type=\"nm\" >\n", "    <param name=\"capability_group\" value=\"Management\"/>\n", "  </node>", "  <node name=\"node_manager\" pkg=\"node_manager_fkie\" type=\"nm\" >\n", "    <param name=\"capability_group\" value=\"Management\"/>\n", "    <param name=\"1.capability_group\" value=\"Node Manager\"/>\n", "  </node>", "   <rosparam param=\"capabilities\">\n", "      [\n", "        [\"Management\",\n", "         \"core\",\n", "         \"images/crystal_clear_app_network2.png\",\n", "         \"The ``management`` group provides nodes needed to detect and synchronize\n", "          other robots in the ROS network. These are:\\n\\n- Node Manager\\n- Master\n", "          Discovery\\n- Master Synchronization\"\n", "        ]\n", "      ]\n", "\n", "    </rosparam>", "  <rosparam param=\"robots\">\n", "    [\n", "      [\"tiderko\",\n", "       \"Workstation\",\n", "       \"tiderko\",\n", "       \"images/veryicon_devcom_workstation.png\",\n", "       \"Workstation\\n\\n|ws|\\n\\n.. |ws| image::\n", "        images/veryicon_devcom_workstation.png\\n\"\n", "      ]\n", "    ]\n", "  </rosparam>", "rosmake master_discovery_fkie default_cfg_fkie", "rosrun node_manager_fkie nm", "catkin_make", "rosrun node_manager_fkie node_manager", "node_manager", "#[ -z \"$PS1\" ] && return", "sudo update-alternatives --config x-terminal-emulator'''"]},
{"url": "https://wiki.ros.org/ros_emacs_utils", "package": "ros_emacs_utils", "package_summary": ["A metapackage of Emacs utils for ROS.\n    Only there for simplifying the release process."]},
{"url": "https://wiki.ros.org/interactive_marker_twist_server", "package": "interactive_marker_twist_server", "package_summary": ["Interactive control for generic Twist-based robots using interactive markers"], "package_details": ["\n", "\n", "\n", "The purpose of this package is to provide a basic generic marker server for teleoperation of twist-based robots, particularly simple differential drive bases. Examples of such platforms include ", ", ", ", and ", ". ", "Package is ", ". Please see the feature tracker for planned enhancements. "], "package_tt": ["~cmd_vel", "~link_name", "str", "base_link", "base_footprint", "~robot_name", "str", "~marker_size_scale", "double", "cmd_vel", "~link_name", "str", "base_link", "base_footprint", "~robot_name", "str", "~marker_size_scale", "double"]},
{"url": "https://wiki.ros.org/roslz4", "package": "roslz4", "package_summary": ["A Python and C++ implementation of the LZ4 streaming format.  Large data\n    streams are split into blocks which are compressed using the very fast LZ4\n    compression algorithm."]},
{"url": "https://wiki.ros.org/navfn", "package": "navfn", "package_summary": ["navfn provides a fast interpolated navigation function that can be used to create plans for\n        a mobile base. The planner assumes a circular robot and operates on a costmap to find a\n        minimum cost plan from a start point to an end point in a grid. The navigation function is\n        computed with Dijkstra's algorithm, but support for an A* heuristic may also be added in the\n        near future. navfn also provides a ROS wrapper for the navfn planner that adheres to the\n        nav_core::BaseGlobalPlanner interface specified in ", "."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". ", "\n", "\n", "\n", "\n", "This package provides an implementation of a fast, interpolated navigation function used to create plans for a mobile base through the ", " class. It also provides a ", " for this class via the ", " object that adheres to the ", " interface specified in the ", " package. The ", " object is also used as a global planner plugin for the ", " node. ", "The ", " object is a ", " for a ", " object that exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "The ", " object provides an implementation of the navigation function described above. Feel free to use it, but beware that we make no guarantees about the stability of its public API. "], "package_tt": ["navfn::NavFn", "navfn::NavfnROS", "nav_core::BaseGlobalPlanner", "navfn::NavfnROS", "navfn::NavfnROS", "navfn::NavFn", "nav_core::BaseGlobalPlanner", "navfn::NavfnROS", "~<name>/plan", "navfn", "~<name>/allow_unknown", "bool", "true", "~<name>/planner_window_x", "double", "~<name>/planner_window_y", "double", "~<name>/default_tolerance", "double", "default_tolerance", "~<name>/visualize_potential", "bool", "false", "navfn::NavfnROS", "nav_core::BaseGlobalPlanner", "navfn::NavFn", "navfn::NavFn"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/timestamp_tools", "package": "timestamp_tools", "package_summary": ["This package is currently for internal use only. Its API may change\n    without warning in the future.  This package is deprecated."], "package_details": ["\n"], "package_tt": ["timestamp_tools", "TriggerMatcher", "timestamp_tools", "TriggerMatcher", "timestamp_tools", "TriggerMatcher"]},
{"url": "https://wiki.ros.org/turtlebot_rviz_launchers", "package": "turtlebot_rviz_launchers", "package_summary": ["Launchers for visualizing TurtleBot"]},
{"url": "https://wiki.ros.org/pr2_navigation_slam", "package": "pr2_navigation_slam", "package_summary": ["This package holds launch files for running the"], "package_details": ["\n", "\n", "\n", "\n", "This package contains configuration files for the ", " and ", " nodes meant to be run in an application that requires SLAM-based global navigation. This package also includes launch files that bring up ", " and ", " with global navigation specific configuration options. "], "package_tt": ["rviz/rviz_move_base_slam.launch", "nav_view/nav_view_move_base_slam.launch", "move_base.xml", "slam_gmapping.xml", "config/base_local_planner_params.yaml", "config/global_costmap_params.yaml", "move_base.xml", "config/local_costmap_params.yaml", "move_base.xml", "config/move_base_params.yaml"]},
{"url": "https://wiki.ros.org/rtt_nav_msgs", "package": "rtt_nav_msgs", "package_summary": ["Provides an rtt typekit for ROS nav_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/nav_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/summit_x_robot_control", "package": "summit_x_robot_control", "package_summary": ["Control the robot joints in all kinematic configurations, publishes odom topic and, \n\t  if configured, also tf odom to base_link. Usually takes as input joystick commands \n\t  and generates as outputs references for the gazebo controllers defined in summit_xl_control."], "package_details": ["\n", "Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "]},
{"url": "https://wiki.ros.org/summit_x_gazebo", "package": "summit_x_gazebo", "package_summary": ["Launch files and world files to start the models in gazebo"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/minas", "package": "minas", "package_summary": ["Meta package for minas for PANASONIC MINAS EtherCAT Motor Driver Control System"], "package_details": ["\n", "\n", "\n", "\n", " package wiki page shows how to run robots virtually. ", "\n", " ", "The minas pacakges contains basic control tools for MINAS-A5B EtherCAT communication driver for indusdtrial robots Tra1 and  its simulator with the ", "! Motion Planning Framework. ", "On your ", " machine where ", " ", " is installed: "], "package_tt": ["Ubuntu", "ROS", "minas", "minas", "tra1"], "package_code": ["$ sudo apt-get install ros-indigo-minas"]},
{"url": "https://wiki.ros.org/multi_level_map_utils", "package": "multi_level_map_utils", "package_summary": ["multi_level_map_utils"]},
{"url": "https://wiki.ros.org/sbpl", "package": "sbpl", "package_summary": ["Search-based planning library (SBPL)."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "The API documentation for this package can be found ", ". ", "A good resource for technical information on the planners in the SBPL package is Maxim Likhachev's presentation (", ",", ") at the ROS Cotesys School at TUM, Germany in November 2010. "]},
{"url": "https://wiki.ros.org/teleop_keyboard_omni3", "package": "teleop_keyboard_omni3", "package_summary": ["Generic keyboard teleop for 3 wheeled omnidirectional robots."], "package_details": ["\n", "\n", "\n", " ", "Motion Analysis of 3 wheeled omnidirectional robot: ", " "], "package_code": ["cd ~/catkin_ws/src\n", "git clone https://github.com/YugAjmera/teleop_keyboard_omni3\n", "cd ~/catkin_ws\n", "catkin_make\n", "source ~/catkin_ws/devel/setup.bash\n", "source ~/.bashrc", "rosrun teleop_keyboard_omni3 teleop_keyboard_omni3.py", "Reading from the keyboard !\n", "---------------------------\n", "Moving around:\n", "   u    i    o\n", "   j    k    l\n", "   m    ,    .\n", "\n", "For Holonomic mode (strafing), hold down the shift key:\n", "---------------------------\n", "   U    I    O\n", "   J    K    L\n", "   M    <    >\n", "\n", "\n", "anything else : stop\n", "\n", "q/z : increase/decrease max speeds by 10%\n", "\n", "CTRL-C to quit"]},
{"url": "https://wiki.ros.org/libfreenect", "package": "libfreenect", "package_summary": ["Open source libraries that will enable the Kinect to be used with Windows, Linux, and Mac."], "package_details": ["\n", " is a library for accessing the Microsoft Kinect USB camera. This package downloads revision ", " from the ", ". ", "\n", "The tarball is currently hosted ", ". ", "Bugs should be reported on the relevant github issues page: ", " ", "If you would like to submit a patch for the ROS wrapper, please open an issue here: ", " "]},
{"url": "https://wiki.ros.org/telegram_ros", "package": "telegram_ros", "package_summary": ["The telegram_ros package"]},
{"url": "https://wiki.ros.org/pr2_description", "package": "pr2_description", "package_summary": ["This package contains the description (mechanical, kinematic, visual,\n  etc.) of the PR2 robot.  The files in this package are parsed and used by\n  a variety of other components.  Most users will not interact directly\n  with this package."], "package_details": ["\n", "\n", "\n", "\n", " ", "This package contains the description of the PR2 robot.  It supercedes the older ", " package which was written for the alpha hardware. ", "Some notable changes from ", ": ", "To see the PR2 URDF graphically, you can", " ", "A snapshot (r46956) is attached ", " for reference. ", "In general, PR2 URDF contains a tree structured set of links and joints, with ", " as the root link of the tree. "], "package_tt": ["urdf/", "robots/", "urdf/", "gazebo/", "meshes/", ".stl", ".dae", "frame_id", "base_laser", "base_laser_link", "frame_id", "{narrow,wide}_stereo_{l,r}_stereo_camera_optical_frame", "plug_holder", "base_footprint"], "package_code": ["rosrun xacro xacro.py `rospack find pr2_description`/robots/pr2.urdf.xacro > pr2.urdf\n", "rosrun urdf urdf_to_graphiz pr2.urdf\n", "evince pr2.pdf", "export KINECT1=true", "export KINECT2=true"]},
{"url": "https://wiki.ros.org/usv_gazebo_plugins", "package": "usv_gazebo_plugins", "package_summary": ["Gazebo plugins for simulating Unmanned Surface Vehicles\n    Originaly copied from https://github.com/bsb808/usv_gazebo_plugins"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The included ", " file sets all of the parameters for the plugin, intended as a example for customization. "], "package_tt": ["waterLevel", "double", "waterDensity", "double", "xDotU", "double", "xDotV", "double", "nDotR", "double", "xU", "double", "xUU", "double", "yV", "double", "yVV", "double", "zW", "double", "kP", "double", "mQ", "double", "nR", "double", "nRR", "double", "maxCmd", "double", "maxForceFwd", "double", "maxForceRev", "double", "boatArea", "double", "boatWidth", "double", "boatLength", "double", "thrustOffsetZ", "double", "metacentricLength", "double", "metcentricWidth", "double", "urdf/usv_gazebo_dynamics_plugin.xacro"]},
{"url": "https://wiki.ros.org/libnabo", "package": "libnabo", "package_summary": ["\n\n     Fetches libnabo through git submodule and makes it available to ROS\n\n  "]},
{"url": "https://wiki.ros.org/kvh_geo_fog_3d_driver", "package": "kvh_geo_fog_3d_driver", "package_summary": ["A ROS driver for the KVH Geo Fog 3D INS family of systems."], "package_details": ["\n", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", " latitude/longitude is measured in degrees (see message definition). This is different than the KVH messages, which report latitude/longitude in radians. ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", " ", " ", " ", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "Link: ", " ", "Link: ", " ", "Developer Note: Notice that at the end we must run kvhDriver.", "(packet_id, bool)`. The driver has been implemented so that you must explicitly state when you have read its data. If you wish to keep track of when new data appears, the driver must be used this way. In any case, the driver will always store the most recent packet of a specific type that it receives and will set the update status to true. ", "1. Add packet information to each set/map currently in ", ". ", "2. Add packet-specific decoding function to ", " function in ", " ", "3. Add packet to initialization mapping in the ", " function of ", " ", "4. Add to the ", " that you are sending upon creation of the driver. "], "package_tt": ["~<node_name>/kvh_system_state", "~<node_name>/kvh_satellites", "~<node_name>/kvh_detailed_satellites", "~<node_name>/kvh_local_magnetics", "~<node_name>/kvh_utm_position", "~<node_name>/kvh_ecef_pos", "~<node_name>/kvh_north_seeking_status", "~<node_name>/kvh_odometer_state", "~<node_name>/kvh_raw_sensors", "~<node_name>/kvh_raw_gnss", "~<node_name>/imu/data_raw_frd", "~<node_name>/imu/data_raw_flu", "~<node_name>/imu/data_ned", "~<node_name>/imu/data_enu", "~<node_name>/imu/rpy_ned", "~<node_name>/imu/rpy_ned_deg", "~<node_name>/imu/rpy_enu", "~<node_name>/imu/rpy_enu_deg", "~<node_name>/gps/fix", "~<node_name>/gps/raw_fix", "~<node_name>/gps/mag", "~<node_name>/gps/utm_ned", "~<node_name>/gps/utm_enu", "~<node_name>/odom/wheel_encoder", "~<node_name>imu/raw_sensor_frd", "~<node_name>/odom/raw_sensor_flu", "~<node_name>/port", "~<node_name>/baud", "~<node_name>/debug", "~<node_name>/filterVehicleType", "~<node_name>/atmosphericAltitudeEnabled", "~<node_name>/velocityHeadingEnabled", "~<node_name>/reversingDetectionEnabled", "~<node_name>/motionAnalysisEnabled", "~<node_name>/odomPulseToMeters", "~<node_name>/port", "$\u00a0sudo\u00a0chmod\u00a0a+rw\u00a0<port>\u00a0\u00a0#\u00a0E.g.,\u00a0port\u00a0may\u00a0be\u00a0/dev/ttyUSB0", "$\u00a0git\u00a0clone\u00a0<url>\u00a0", "$\u00a0cd\u00a0kvh_geo_fog_3d\u00a0", "$\u00a0catkin\u00a0build\u00a0kvh_geo_fog_3d\u00a0", "$\u00a0source\u00a0.../devel/setup.bash\u00a0#\u00a0May\u00a0be\u00a0required\u00a0after\u00a0building", "$\u00a0rosmsg\u00a0list\u00a0|\u00a0grep\u00a0kvh\u00a0", "$\u00a0roslaunch\u00a0kvh_geo_fog_3d_driver\u00a0kvh_geo_fog_3d_node.launch\u00a0port:=<port>\u00a0baud:=<baud>\u00a0#\u00a0E.g.,\u00a0port=\"/dev/ttyUSB0\"\u00a0baud=\"921600\"", "\u00a0$\u00a0roslaunch\u00a0kvh_geo_fog_3d_driver\u00a0determine_baud.launch\u00a0starting_baud:=<baud_rate>\u00a0", "src/kvh_driver/kvh_global_vars.cpp", "src/kvh_driver/decode_packets.cpp", "src/kvh_driver/packet_storage.cpp", "KvhPacketRequest"]},
{"url": "https://wiki.ros.org/rosjava_messages", "package": "rosjava_messages", "package_summary": ["Message generation for rosjava."], "package_details": ["\n", "Please see ", " for details about how this package generates code and artifacts for the officially released message package set. "]},
{"url": "https://wiki.ros.org/rotors_description", "package": "rotors_description", "package_summary": ["The rotors_description package provides URDF models of the AscTec multicopters."]},
{"url": "https://wiki.ros.org/tuw_multi_robot_local_behavior_controller", "package": "tuw_multi_robot_local_behavior_controller", "package_summary": ["This package presents a node, which converts synchronized robot routes to path segments published sequentially to maintain synchronization"], "package_details": ["\n", "\n", "  (", ") ", " (", ") ", "\n", " (", ") ", " (", ") ", "\n", " (", " default: \"[robot_0]\") ", " (", " default: \"\") ", " (", " default: \"[]\") ", " (", " default: \"0.3\") ", " (", " default: \"path\") ", " (", " default: \"route\") ", "\n", "Use GitHub to ", ". [", "]", "\n  "], "package_tt": ["[robot_name]/route", "tuw_multi_robot_msgs/Route", "robot_info", "tuw_multi_robot_msgs/RobotInfo", "[robot_name]/path", "nav_msgs/Path", "robot_info", "tuw_multi_robot::RobotInfo", "~robot_names", "string[]", "~robot_names_str", "string", "~robot_radius", "float[]", "~robot_default_radius", "float", "~path_topic", "string", "~route_topic", "string"]},
{"url": "https://wiki.ros.org/visp", "package": "visp", "package_summary": ["ViSP standing for Visual Servoing Platform is a modular cross platform library that allows prototyping and developing applications using visual tracking and visual servoing technics at the heart of the researches done by Inria Lagadic team. ViSP is able to compute control laws that can be applied to robotic systems. It provides a set of visual features that can be tracked using real time image processing or computer vision algorithms. ViSP provides also simulation capabilities. ViSP can be useful in robotics, computer vision, augmented reality and computer animation."], "package_details": ["\n", "\n", "\n", "This package provides packaging of the ViSP library for ROS. For information about the ViSP library, please see the ViSP main page at ", ". ", "The next video shows what can be done with ", " package that uses ", " package. ", "The next video shows what can be done with ", " package that uses also ", " package. ", "This other video shows how using ", " package that depends on ", " it may possible to control a Pioneer P3-DX mobile robot using visual servoing. ", "ViSP is a library that is maintained by Inria Lagadic research team ", ". "], "package_code": ["\n", "\n", "  $ sudo apt-get install ros-$ROS_DISTRO-visp"]},
{"url": "https://wiki.ros.org/ethercat_manager", "package": "ethercat_manager", "package_summary": ["ROS-Industrial support stack for facilitating communication with\nEtherCAT networks. The code is mainly copied from https://github.com/ros-industrial/robotiq/blob/jade-devel/robotiq_ethercat/src/ethercat_manager.cpp"]},
{"url": "https://wiki.ros.org/access_point_control", "package": "access_point_control", "package_summary": ["\n    Defines an API for access point control based on \n    dynamic_reconfigure. Other packages must\n    implement the API for various access-point models: \n    for example: hostapd_access_point for hostapd-based control or\n    linksys_access_point for Linksys router web interface.\n  "], "package_details": ["\n", "\n", "The following dynamic_reconfigure API must be implemented by packages specific to access point model such as ", ", ", ", ", ". "], "package_tt": ["~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string"]},
{"url": "https://wiki.ros.org/hironx_moveit_config", "package": "hironx_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the HiroNX with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/xbot_navi", "package": "xbot_navi", "package_summary": ["The xbot_navi package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "The package has many functions such as mapping, positioning, navigation, path planning, and integrated services demo including navigation, face recognition, and voice conversations. The package relies on the xbot-u robot platform and other packages such as ", ", ", " and ", ". See the ", ", ", ", ", " and ", " package for more details to configure the mapping and navigation parameters. ", "To make a map from xbot-u robot with ", " package: ", "Or you can choose to use google open source ", " to make a map: ", "Navigate via ", " and ", ": ", "Or use ", " to navigate: "], "package_tt": ["param/kp.json", "\u00a0and\u00a0param/greet.json"], "package_code": ["roslaunch xbot_navi build_map.launch", "roslaunch xbot_navi rviz_build_map.launch", "roslaunch xbot_navi build_map_carto.launch", "roslaunch xbot_navi demo.launch", "roslaunch xbot_navi navi_carto.launch", "roslaunch xbot_navi demo.launch"]},
{"url": "https://wiki.ros.org/uos_gazebo_worlds", "package": "uos_gazebo_worlds", "package_summary": ["Gazebo world and model files for UOS."]},
{"url": "https://wiki.ros.org/wge100_driver", "package": "wge100_driver", "package_summary": ["This stack contains the ROS driver and firmware for the WGE100 camera used on the PR2 robot."], "package_details": [" ", "\n", "\n", "\n", "  ", "ROS driver and firmware for the WGE100 Ethernet camera. See ", " for usage and tutorials. ", "Prior to Fuerte, these packages resided in ", ". ", "A ", ". WGE100 cameras are not available separately. "]},
{"url": "https://wiki.ros.org/rtshell", "package": "rtshell", "package_summary": ["Shell commands for managing RT-Middleware running on OpenRTM-aist."]},
{"url": "https://wiki.ros.org/minas_control", "package": "minas_control", "package_summary": ["This package contains ros_control based robot controller for PANASONIC MINAS EtherCAT Motor Driver Control System"]},
{"url": "https://wiki.ros.org/pr2_props_app", "package": "pr2_props_app", "package_summary": ["\n    Application files for running PR2 props\n  "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rospy", "package": "rospy", "package_summary": ["rospy is a pure Python client library for ROS. The rospy client\n    API enables Python programmers to quickly interface with ROS ", ", ", ", and ", ". The\n    design of rospy favors implementation speed (i.e. developer\n    time) over runtime performance so that algorithms can be quickly\n    prototyped and tested within ROS. It is also ideal for\n    non-critical-path code, such as configuration and initialization\n    code. Many of the ROS tools are written in rospy to take\n    advantage of the type introspection capabilities.\n\n    Many of the ROS tools, such\n    as ", "\n    and ", ", are\n    built on top of rospy."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Please refer to the ", " package and to the ", " page. ", "Please see the ", " for an introduction to the rospy API and its usage. ", "For a more detailed reference, please consult the ", ". ", "Bug reports and feature requests can be filled and views in the ", ". "]},
{"url": "https://wiki.ros.org/moveit_visual_tools", "package": "moveit_visual_tools", "package_summary": ["Helper functions for displaying and debugging MoveIt! data in Rviz via published markers"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/katana_msgs", "package": "katana_msgs", "package_summary": ["This package contains messages specific to the Neuronics Katana arm."]},
{"url": "https://wiki.ros.org/staubli_rx160_moveit_config", "package": "staubli_rx160_moveit_config", "package_summary": ["\n      MoveIt package for the Staubli RX160.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the Staubli RX160 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " metapackage page. "]},
{"url": "https://wiki.ros.org/turtlebot_create", "package": "turtlebot_create", "package_summary": ["Catkin metapackage for the turtlebot_create stack"], "package_details": ["\n", "Please refer main ", " page "]},
{"url": "https://wiki.ros.org/nextage_gazebo", "package": "nextage_gazebo", "package_summary": ["Gazebo simulation for NEXTAGE Open"]},
{"url": "https://wiki.ros.org/svenzva_utils", "package": "svenzva_utils", "package_summary": ["Svenzva Arm utilities that streamline arm-code interaction"]},
{"url": "https://wiki.ros.org/kvh_geo_fog_3d_rviz", "package": "kvh_geo_fog_3d_rviz", "package_summary": ["The KVH GEO FOG 3D rviz plugin package"], "package_details": ["Utilizes the ", " message published by the ", ". "], "package_tt": ["/diagnostics"]},
{"url": "https://wiki.ros.org/mongodb_store", "package": "mongodb_store", "package_summary": ["A package to support MongoDB-based storage and analysis for data from a ROS system, eg. saved messages, configurations etc"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " Use GitHub to ", ". [", "]", "\n ", "This package contains nodes and libraries for storing and retrieving ROS-related data in a ", " database using C++ and Python. It is intended to support data persistence and inspection, including in running systems (i.e. introspection). The main functions are the storage and retrieval of single message (this is the ", "); the rosbag-like logging of topics to the db (via ", ") and their playback (mongodb_play); and the storage and recreation of parameters. ", "First set the host and port you want the datacentre to run on. We do this via ", " so that other nodes know where to find the server. ", "If these are not set the server uses a generated port number and ", " then sets the above parameters to its chosen values. ", "This runs the ", " server and also provides some utility functions around this. By default, the mongod database will be stored in ", ". This can be overridden by setting the private parameter ~database_path for the node. If it is the first time that the database is used, be sure to first create the database path (e.g. ", "). ", "To create \"", " record\"-like logging of topics to the ", " use ", ". This has been updated to store logged data in a format that can be easily recreated into ROS messages for replay. ", "The ", " node reads logged messages from the store and replays them on their original topics. This provides a similar function to \"", " play\". Currently this node always creates its own ", " in order to play back the messages at the time they were originally recorded. ", "will play back messages previously from the ", " ", " and ", " topics which were previously stored in the default database (", "). ", " and ", " respect latched topics. ", "1. ", ".  These should be \"working defaults\" - so all essential parameters at least have a default value. For example, if a robot application requires some calibration data then default values should be provided. Default parameters can be shared among sites and stored inside a shared ROS package. When the config manager is started, all .yaml files stored in a 'defaults' folder will be examined. Any new default parameters will automatically be inserted into the \"defaults\" collection within the configs database. The defaults folder should be supplied as a private parameter: ", " either set to a system path or in the form ", ". ", "2. ", ". These parameters override the same named  global default parameters, allowing site-specific parameter setting. They are stored within the database inside the \"local\" collection. ", "At start up, the config manager places all parameters onto the ros parameter server to allow interoperability with existing software. Parameters can also be queried using the ", ", or by directly connection to and querying the mongo database server. ", "Likewise, local parameter overrides can be set using the ", " service or by directly editing the \"local\" collection in the configs database. ", "The message store node provides services to allow clients to add, update and remove ROS messages in the mongo store via the ", " object in both Python and C++. This is best demonstrated by examples. With the mongodb server running, run the message store: ", "If the constructor argument to the message store node ", " is set to true, replication of the message store parts of the store is done manually to allow different content to appear on different hosts. A list of hosts and ports where replications should be made can be set via the ", " ros parameter: ", "If ", " is set (regardless of ", "), queries are performed on the main first, and if nothing found, the replicants are tried. ", "You can test if this works by adding some things to the message store, deleting them from the master using ", " (not the message store as the deletes are replicated), then running queries. ", "The ", " action and the corresponding action server: ", "(which is included in ", ") ", "allows you to bulk copy or move entries from message store collections to the mongod instances defined under ", ". The client accepts a list of collection names and uses the ", " field of the message store entries to replicate or move all entries that were inserted before a particular time. If no time is provided then the default is 24 hours ago. There is an example client that does this for a list of collections specified on the command line. This *moves* entries inserted 24 hours ago or earlier. ", "***NOTE THAT this all makes ", " operations a bit uncertain, so please do not use this type of replication on collections you plan to use update on.*** "], "package_tt": ["rosparam", "localhost", "mongod", "/opt/ros/mongodb_store", "mkdir\u00a0\u00a0-p\u00a0/opt/strands/mongodb_store", "mongodb_store", "mongodb_play", "/map", "/tf", "/scan", "roslog", "mongodb_log", "mongodb_play", "~defaults_path", "pkg://ros_package_name/inside/package", "/config_manager/get_param\u00a0service", "/config_manager/set_param", "MessageStoreProxy", "replicate_on_write", "mongodb_store_extras", "mongodb_store_extras", "replicate_on_write", "MoveEntries", "datacentre.launch", "mongodb_store_extras", "meta[\"inserted_at\"]", "update"], "package_code": ["HOSTNAME=yourhost roslaunch mongodb_store mongodb_store.launch db_path:=/path/to/db db_port:=62345", "rosparam set mongodb_port 62345\n", "rosparam set mongodb_host bob", "rosrun mongodb_store mongodb_server.py", "Usage: mongodb_play.py [options] [TOPICs...]\n", "\n", "Options:\n", "  -h, --help           show this help message and exit\n", "  --mongodb-name=NAME  Name of DB in which to store values", "rosrun mongodb_store mongodb_play.py  /map /tf /scan", "rosrun mongodb_store config_manager.py _defaults_path:=pkg://my_package/defaults", "rosparam list", "rosparam get /my/parameter", "rosservice call /config_manager/get_param \"param_name: '/my/parameter'\"", "rosservice call /config_manager/set_param \"param: '{\\\"path\\\":\\\"/chris\\\",\\\"value\\\":43}'\"", "rosservice call /config_manager/save_param name_of_the_parameter_to_be_saved", "rosrun mongodb_store message_store_node.py", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "mongodb_store_extras: [[\"localhost\", 62344], [\"localhost\", 62333]]", "rosrun mongodb_store mongodb_server.py _master:=false _database_path:=/opt/strands/strands_mongodb_62344 _host:=localhost _port:=62344\n", "rosrun mongodb_store mongodb_server.py _master:=false _database_path:=/opt/strands/strands_mongodb_62333 _host:=localhost _port:=62333", "rosrun mongodb_store replicator_node.py", "rosrun mongodb_store replicator_client.py message_store robblog scheduling_problems"]},
{"url": "https://wiki.ros.org/nao_robot", "package": "nao_robot", "package_summary": ["The nao_robot metapackage contains some useful nodes to integrate the Nao humanoid robot into ROS.\n    Check out the ", " for more functionality.\n    The ", " contains some more general packages for humanoid/biped robots."], "package_details": ["\n", "\n", "See ", " for installation instructions and the packages in this stack for more documentation, in particular ", " to start the nodes for Nao. ", "For issues and questions, please use ", " or the ", " ", "Use the ", " to report bugs or request features.  "]},
{"url": "https://wiki.ros.org/roslaunch", "package": "roslaunch", "package_summary": ["roslaunch is a tool for easily launching multiple ROS ", " locally and remotely\n    via SSH, as well as setting parameters on the ", ". It includes options to automatically respawn processes\n    that have already died. roslaunch takes in one or more XML\n    configuration files (with the ", " extension) that\n    specify the parameters to set and nodes to launch, as well as the\n    machines that they should be run on."], "package_details": ["\n", " uses XML files that describe the nodes that should be run, parameters that should be set, and other attributes of launching a collection of ROS ", ". For a specification of this XML format, please see: ", " was designed to fit the ROS architecture of complexity via composition. Understanding ", "'s architecture will give you better insight in how to construct your ", " files and better debug remote vs. local launches. ", "\n", " is a specialization of the ", " tool for bringing up the \"core\" ROS system.  A roslaunch will automatically start roscore if it detects that it is not already running (unless the --wait argument is supplied).  For more information, please see the ", " documentation. Note: due to a ", ", roslaunch should not be used to guarantee a singleton instance of roscore. ", "\n", "\n", "\n", "\n", " these *.launch file tests can also be initiated using console tool called ", " OR ", ". ", "\n", " ", "\n", "\n", "The ", " ", " contains the ", " tools, which reads the ", ". It also contains a variety of other support tools to help you use these files.  ", "Many ROS packages come with \"launch files\", which you can run with: ", "To find out more about the main ", " tool and other command-line tools, please consult: ", "The launch file syntax itself is ", ", and every effort will be made to provide backwards compatibility with new features. ", "The code API of ", " is ", " and should not be used directly. In order to support the new features that are being planned, it may be necessary to make major, incompatible changes to the programmatic API. ", "There are many new features being planned for ", ". These include new features within the launch file syntax, GUI tools for interacting with launch files more effectively, network API, better coordination between separate launch files, and more. ", "Ref. ", " ", "The ", " CMake macro can be used to check launch files for common errors such as missing arguments, dependencies, packages, or nodes. ", "The following is how you would check all ", " files in a package's \"", "\" directory: ", "NOTE: ", " takes only one directory at a time. ", "The check runs during ", ". So something like following is cleaner. ", "Since you need to find ", " in ", " as above, you better explicitly add a dependency in your ", " as following: ", "Pass an optional argument \"", "\" to ", " as the following example, if your package defines dependency for the tests (e.g. ", "). This avoids issues that happen during tests such as ", ". ", "A few graphical tools are available to support ", " functionalities of ROS. "], "package_tt": [".launch", ".launch", ".launch", ".launch", ".launch", ".launch", ".launch", ".launch", ".launch", ".launch", "roslaunch", "roslaunch", "roslaunch", "roslaunch", "roslaunch", "roslaunch", ".launch", "roslaunch", "roslaunch", "roslaunch", "roslaunch_add_file_check", "*.launch", "launch", "roslaunch_add_file_check", "roslaunch", "find_package", "package.xml", "USE_TEST_DEPENDENCIES", "roslaunch_add_file_check", "test_depend", "launch"], "package_code": ["$ roslaunch package_name file.launch", "find_package(catkin REQUIRED COMPONENTS roslaunch)\n", "roslaunch_add_file_check(launch)", "if (CATKIN_ENABLE_TESTING)\n", "  find_package(roslaunch REQUIRED)\n", "  roslaunch_add_file_check(launch)\n", "endif()", "<build_depend>roslaunch</build_depend>", "find_package(catkin REQUIRED COMPONENTS roslaunch)\n", "roslaunch_add_file_check(launch USE_TEST_DEPENDENCIES)"]},
{"url": "https://wiki.ros.org/rotors_joy_interface", "package": "rotors_joy_interface", "package_summary": ["The rotors_joy_interface package to control MAVs with a joystick"]},
{"url": "https://wiki.ros.org/fingertip_pressure", "package": "fingertip_pressure", "package_summary": ["This package provides access to the PR2 fingertip pressure sensors. This information includes:"], "package_details": ["\n", "\n", ": All nodes assume that ", " is either ", " or ", ". ", "\n", " ", "\n", "\n", " is a standalone demo of the package's capabilities. ", "It runs all the package's nodes, and rviz (to view the visualization markers). This should demonstrate all the packages capabilities. ", "Each pr2 gripper is equipped with two pressure-sensitive fingertips. Each pressure comprises 22 pressure sensing elements: one on the back, 6 around the edges and a 3x5 array on the front. ", " provides nodes to facilitate the visualization and interpretation of the fingertip pressure sensor data. ", "Example of ", " GUI: ", "Example: ", "and in a separate shell: "], "package_tt": ["fingertip_pressure", "<gripper_motor_name>", "r_gripper_motor", "l_gripper_motor", "/pressure/<gripper_motor_name>_info", "board", "<board>_info", "view_fingertip_pressure", "/pressure/<gripper_motor_name>", "/pressure/<gripper_motor_name>_info", "\"/visualization_marker\"", "sphere_viz", "/pressure/<gripper_motor_name>", "/pressure/<gripper_motor_name>_info", "\"/visualization_marker\"", "/pressure/<gripper_motor_name>", "launch/fingertip_demo.launch"], "package_code": ["$ roslaunch launch/fingertip_demo.launch", "$ roscd pr2_gazebo\n", "$ roslaunch pr2_empty.launch"]},
{"url": "https://wiki.ros.org/rtsprofile", "package": "rtsprofile", "package_summary": ["Library to read, manipulate and write RT system profiles using the RTSProfile XML schema."]},
{"url": "https://wiki.ros.org/rosserial_client", "package": "rosserial_client", "package_summary": ["Generalized client side source for rosserial."], "package_details": [" contains the generic client-side ", " implementation. It is designed for microcontrollers and it can run on any processor for which you have an ANSI C++ compiler and a serial port connection to a computer running ROS.  ", " The serialization and deserialization code generated by the ", " module assumes that the client is a little-endian machine. If you have a bi-endian target such as ARM or MIPS, be sure that it has been placed in little-endian mode in order to use it with rosserial. ", "For details on using rosserial_client with the Arduino, please see ", ". For other platforms, please see the ", ". "], "package_tt": ["make_libraries"]},
{"url": "https://wiki.ros.org/uos_rotunit_teleop", "package": "uos_rotunit_teleop", "package_summary": ["sends command to handle the rotunit speed and to start the snapshotter"]},
{"url": "https://wiki.ros.org/ur_driver", "package": "ur_driver", "package_summary": ["Driver for the UR5/10 arm based on the Polyscope control scheme."], "package_details": ["\n"], "package_tt": ["30002", "50001", "ping", "joint_states", "~max_velocity", "double", "~prefix", "str", "JointState", "~prevent_programming", "boolean", "~robot_description", "str", "30002", "30003", "50001", "ping", "io_states", "joint_states", "wrench", "~max_velocity", "double", "~min_payload", "double", "SetPayload", "~max_payload", "double", "SetPayload", "~prefix", "str", "JointState", "~prevent_programming", "boolean", "~robot_description", "str"]},
{"url": "https://wiki.ros.org/sr_edc_ethercat_drivers", "package": "sr_edc_ethercat_drivers", "package_summary": ["\n\n    A package implementing a ROS interface for the etherCAT Shadow Robot Dextrous Hand.\n\n  "], "package_details": ["\n", "\n", "This package contains the driver for the etherCAT Hand. It uses the ", " which is running the main loop at 1kHz for sending and receiving packets to/from the etherCAT. We also load the ", " which will be used to load the controllers on demand. ", "The driver sends different demands to the etherCAT hand and receives and formats correctly the incoming packets. The incoming data is stored in a vector of actuators (defined in the ", " package). Those actuators are then passed to the controllers for the 1kHz control loop. The controllers are publishing the relevant data (position / effort / velocity) at 100Hz on the ", " topic, and the hardware diagnostics on the ", " topic at 1Hz. ", "The protocol used to interpret or build the etherCAT packets can be found in ", ".  ", "Please refer to the ", " to learn how to use the driver. ", "You can look at the current status of the robot using the ", ": "], "package_code": ["$ rosrun robot_monitor robot_monitor"]},
{"url": "https://wiki.ros.org/rsv_balance_description", "package": "rsv_balance_description", "package_summary": ["RoboSavvy's balancing platform URDF description and meshes."], "package_details": ["'s self-balance platform URDF model and meshes. ", "\n", " ", " ", "The platform macro is provided by the file: ", " and can be included in your URDF model as such: ", "As an example you can look at ", ", which puts on top a rod and a dummy weight of 5kg. "], "package_code": ["<robot name=\"you_awesome_robot\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n", "  <xacro:include filename=\"$(find rsv_balance_description)/urdf/balance.urdf.xacro\" />\n", "  <xacro:balance/> \n", "\n", "  ..\n", "  .. <your_awesome_robot_here>\n", "  ..\n", "\n", "</robot>"]},
{"url": "https://wiki.ros.org/simple_grasping", "package": "simple_grasping", "package_summary": ["Basic grasping applications and demos."]},
{"url": "https://wiki.ros.org/dataspeed_ulc", "package": "dataspeed_ulc", "package_summary": ["CAN interface to the Universal Lat/Lon Controller (ULC) firmware"]},
{"url": "https://wiki.ros.org/tf2_sensor_msgs", "package": "tf2_sensor_msgs", "package_summary": ["Small lib to transform sensor_msgs with tf. Most notably, PointCloud2"], "package_details": ["\n", "\n", "\n", " "]},
{"url": "https://wiki.ros.org/win_bzip2", "package": "win_bzip2", "package_summary": []},
{"url": "https://wiki.ros.org/turtlebot_arm_bringup", "package": "turtlebot_arm_bringup", "package_summary": ["turtlebot_arm_bringup provides launch files for starting the drivers for the TurtleBot arm."], "package_details": ["\n", " ", " ", "\n", " "], "package_tt": ["\u00a0launch/arm.launch\u00a0", "\u00a0launch/fake-arm.launch\u00a0", "\u00a0launch/simple_arm_server.launch\u00a0", "\u00a0launch/constraint_aware_simple_arm_server.launch\u00a0", "\u00a0config/arm.yaml\u00a0", "\u00a0config/planning_environment.yaml\u00a0"]},
{"url": "https://wiki.ros.org/tango_ros_streamer", "package": "tango_ros_streamer", "package_summary": ["This package wraps Tango Ros Streamer application"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "Note that all image topics are published via ", ". Therefore, for each image topic, a compressed version of the image is available together with its compression parameters. ", "Also note that the service ", " seems to not work properly on Tango Tablet Development Kit. "], "package_tt": ["android/imu", "tango/camera/color_1/camera_info", "tango/camera/color_1/image_raw", "tango/camera/color_1/image_rect", "tango/camera/fisheye_1/camera_info", "tango/camera/fisheye_1/image_raw", "tango/camera/fisheye_1/image_rect", "tango/laser_scan", "tango/point_cloud", "tango/reconstruction/mesh_marker", "tango/reconstruction/occupancy_grid", "tango/static_occupancy_grid", "tango/load_occupancy_grid", "tango/status", "tango/transform/area_description_T_start_of_service", "tango/transform/start_of_service_T_device", "tango/connect", "tango/get_map_name", "tango/get_map_uuids", "tango/load_occupancy_grid", "tango/occupancy_grid_directory", "/tango/static_occupancy_grid", "/tango/localization_map_uuid", "tango/save_map", "/tango/create_new_map", "tango/occupancy_grid_directory", "/tango/localization_map_uuid", "tango/set_parameters", "tango/area_description_frame_id", "string", "tango/create_new_map", "bool", "tango/localization_mode", "tango/enable_3dr_mesh", "bool", "enable_color_camera", "enable_depth", "tango/enable_3dr_occupancy_grid", "bool", "enable_color_camera", "enable_depth", "tango/enable_color_camera", "bool", "tango/enable_depth", "bool", "tango/laser_scan_max_height", "double", "tango/laser_scan_min_height", "double", "tango/localization_map_uuid", "string", "tango/localization_mode", "tango/localization_mode", "int", "tango/occupancy_grid_directory", "string", "tango/publish_pose_on_tf", "bool", "tango/reconstruction/floorplan_max_error", "double", "tango/reconstruction/max_voxel_weight", "int", "tango/reconstruction/min_num_vertices", "int", "tango/reconstruction/occupancy_grid_threshold", "int", "tango/reconstruction/resolution_3d", "double", "tango/reconstruction/update_method", "int", "tango/reconstruction/use_space_clearing", "bool", "tango/start_of_service_frame_id", "string", "tango/use_tf_static", "bool", "tango/android_api_level", "int", "area_description", "start_of_service", "start_of_service", "device", "device", "camera_depth", "camera_depth", "laser", "device", "camera_fisheye", "device", "camera_color", "device", "imu", "tango/connect"]},
{"url": "https://wiki.ros.org/surface_perception", "package": "surface_perception", "package_summary": ["Simple library for segmentation of tabletop and shelf surfaces"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " ", " is a simple tabletop/shelf perception pipeline. ", " is the main API. ", "It takes in a point cloud, where the positive \"z\" direction points up. ", "It also assumes that the point cloud has been cropped down to a tabletop/shelf scene. ", "\n", " visualizes the result: ", "\n", "If ", " is not provided, the point cloud will be processed in ", ". "], "package_tt": ["surface_perception", "target_point_cloud_frame", "base_link", "crop_min_x", "float", "crop_min_y", "float", "crop_min_z", "float", "crop_max_x", "float", "crop_max_y", "float", "crop_max_z", "float", "horizontal_tolerance_degrees", "float", "margin_above_surface", "float", "cluster_distance", "float", "min_cluster_size", "integer", "max_cluster_size", "integer", "min_surface_size", "integer", "min_surface_exploration_iteration", "integer"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "rosrun surface_perception demo target_point_cloud_frame cloud_in:=input_point_cloud_topic", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/ros_ethernet_rmp", "package": "ros_ethernet_rmp", "package_summary": ["ROS Wrapper for the Segway RMP Ethernet Python Driver"], "package_details": ["\n", "\n", "\n", "\n", " broadcasts the robot frame ('/base_footprint') with respect to the odometry frame (", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package is used to bridge ROS and a Segway RMP. It will convert ", " topic messages to the RMPCommand format and then publish the feedback from the RMP. There is also a joint state publisher to read in the feedback and publish the changing joint states as necessary. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ", 'rmp_pose_updater.py' and ", " nodes. 'battery_monitor_rmp.launch' from 'battery_monitor_rmp' will also be launched if the argument, include_batt_monitor, is true. It is defaulted to true. To launch these nodes, ", " the battery monitor the following command can be used: ", "To launch these nodes ", " the battery monitor, the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["ros_ethernet_rmp", "cmd_vel", "ethernet_rmp.py", "cmd_vel", "rmp_command", "rmp_feedback", "~update_delay_sec", "~log_data", "~current_rmp_ip_addr", "~current_rmp_port_num", "~is_omni", "~my_velocity_limit_mps", "~my_accel_limit_mps2", "~my_decel_limit_mps2", "~my_dtz_rate_mps2", "~my_coastdown_accel_mps2", "~my_yaw_rate_limit_rps", "~my_yaw_accel_limit_rps2", "~my_tire_diameter_m", "~my_wheel_base_length_m", "~my_wheel_track_width_m", "~my_gear_ratio", "~my_config_bitmap", "~my_ip_address", "~my_port_num", "~my_subnet_mask", "~my_gateway", "~my_user_defined_feedback_bitmap_1", "~my_user_defined_feedback_bitmap_2", "~my_user_defined_feedback_bitmap_3", "~my_user_defined_feedback_bitmap_4", "rmp_pose_updater.py", "rmp_feedback", "odom", "~publish_tf", "rmp_pose_updater", "/odom", "rmp_joint_state.py", "rmp_feedback", "rmp_joint_states", "~has_two_wheels", "~link_left_front", "~link_right_front", "~link_left_rear", "~link_right_rear", "ros_ethernet_rmp", "ros_ethernet_rmp", "ros_ethernet_rmp.launch", "ethernet_rmp.py", "rmp_joint_states.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-ros-ethernet-rmp", "roslaunch ros_ethernet_rmp ros_ethernet_rmp.launch ", "roslaunch ros_etehrnet_rmp ros_ethernet_rmp.launch include_batt_monitor:=false"]},
{"url": "https://wiki.ros.org/catkinize_this", "package": "catkinize_this", "package_summary": ["Scripts for helping catkinize packages"]},
{"url": "https://wiki.ros.org/multi_interface_roam", "package": "multi_interface_roam", "package_summary": ["\n    ", "\n    This package allows automatic configuration and switching between \n    multiple network interfaces. It can be used in combination with a VPN\n    tunnel to achieve seamless wifi roaming, and near-instantaneous\n    transitioning between multiple available network interfaces.\n  ", "\n    Currently only wifi interfaces are supported.\n  "]},
{"url": "https://wiki.ros.org/turtlebot3_applications", "package": "turtlebot3_applications", "package_summary": ["ROS packages for the turtlebot3 applications (meta package)"], "package_details": [" ", "\n", " ", " is a new generation mobile robot that is modular, compact and customizable. Let\u2019s explore ROS and create exciting applications for education, research and product development. The goal of ", " is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and ", " can be customized in various ways. ", " is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. ", "\n", "\n", "\n", "\n"], "package_tt": ["TurtleBot3", "TurtleBot3", "TurtleBot3"]},
{"url": "https://wiki.ros.org/ndt_fuser", "package": "ndt_fuser", "package_summary": ["\n\n     ndt_fuser\n\n  "], "package_details": ["\n", "\n", "\n", "A tutorial describing how to set-up an NDT fuser node and use it with your robot is available - ", ". "], "package_tt": ["~/points", "~/laser_scan", "~/odometry", "/tf", "/ndt_map", "~/save_map"]},
{"url": "https://wiki.ros.org/swri_profiler", "package": "swri_profiler", "package_summary": ["swri_profiler provides basic tools for real-time selective\n    profiling of ROS C++ nodes."], "package_details": [". "]},
{"url": "https://wiki.ros.org/abb_driver", "package": "abb_driver", "package_summary": ["\n     ROS-Industrial nodes for interfacing with ABB robot controllers.\n   ", "\n     This package is part of the ROS-Industrial program and contains nodes \n     for interfacing with ABB industrial robot controllers.\n   "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "RobotWare OS version 5.13 or later is required due to the use of certain socket options. Earlier versions may work, but will require modifications to the RAPID code. ", "\n", "\n", "\n", "This package is part of the ", " program.  ", "While it is possible to use this driver with YuMi, for now this is not recommended. ", "There are many packages that target YuMi specifically, one of which is ", ". As of now, users of an IRB 14000 are suggested to consider using that package. ", "The package is usable as-is, but is not feature complete. However, no significant development is planned, as development focus has shifted to ", " and ", ". ", "Use the links on the ", " page for access to the tutorials. These explain how to install and set up the RAPID programs on the controller, as well as how to use them in conjunction with the ROS nodes in this package. "], "package_tt": ["623-1", "672-1", "616-1", "feedback_states", "joint_states", "robot_ip_address", "str", "~port", "integer", "robot_description", "str", "controller_joint_names", "[str,\u00a0str,\u00a0str,\u00a0..]", "robot_description", "controller_joint_names", "joint_states", "joint_path_command", "joint_path_command", "stop_motion", "robot_ip_address", "str", "~port", "integer", "robot_description", "str", "controller_joint_names", "[str,\u00a0str,\u00a0str,\u00a0..]", "robot_description", "controller_joint_names"]},
{"url": "https://wiki.ros.org/sbpl_recovery", "package": "sbpl_recovery", "package_summary": ["A recovery behavior that uses the sbpl lattice planner and the pose\n    follower to try to plan in full 3D to get the robot out of really tricky\n    situations."]},
{"url": "https://wiki.ros.org/irb_6640_moveit_config", "package": "irb_6640_moveit_config", "package_summary": [" This package has been deprecated in Hydro, and will be removed in Indigo. Please use the abb_irb6640_moveit_config package as a replacement.", "An automatically generated package with all the configuration and launch\n     files for using the irb_6640 with the MoveIt Motion Planning Framework\n     (deprecated)."], "package_details": ["\n", "This package is part of the ", " program. "]},
{"url": "https://wiki.ros.org/uav_random_direction", "package": "uav_random_direction", "package_summary": ["A package that performs random direction coverage with an unmanned aerial vehicle (UAV)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["single_target=true", "uav_random_direction", "id", "integer", "output", "string", "screen", "screen", "log", "param", "uav_random_direction.yaml", "uav_random_direction", "uav_random_direction", "single_target", "true", "uav_coverage/goal", "uav_coverage/result", "target_found", "single_target", "true", "area/get_area", "obstacle_detection/get_clear_sector", "~loop_rate", "real", "~queue_size", "integer", "~single_target", "boolean", "~margin", "real", "/rng_seed", "integer"], "package_code": ["roslaunch uav_random_direction uav_random_direction.launch"]},
{"url": "https://wiki.ros.org/radar_omnipresense", "package": "radar_omnipresense", "package_summary": ["This is the radar driver package developed for the omnipresense radar module."], "package_details": ["\n", "\n", "\n", "\n", " ", "Please see the individual packages within this stack for documentation. OPS241/OPS242 radar sensors can be purchased from ", ".  The full API documentation is available at ", ". ", "radar_omnipresense , a ROS module for the ", " radar sensor ", "The radar_omipresense driver is built automatically by the ROS build farm.  Subsequently, the standard way of installing drivers works for the radar omnipresense driver.  Namely, apt install ros-", "-radar-omnipresense.  So, for example, if you are running with ROS \"melodic\" and are not logged in as root, you could issue the command; ", "You can also download the driver as source code and build it yourself.  All external dependencies have been removed, so a beginner should be able to accomplish it without too many complications. The instructions on the wiki are very thorough on walking a developer through the steps.  A good place to start is ", " ", "For application support, please contact ", " . "], "package_code": ["sudo apt install ros-melodic-radar-omnipresense"]},
{"url": "https://wiki.ros.org/sick_tim", "package": "sick_tim", "package_summary": ["A ROS driver for the SICK TiM and the SICK MRS 1000 laser scanners.", " "], "package_details": ["\n", "\n", "\n", " TIM310-1030000S01 ", " 1056791 ", " ", " ", "\n", " TIM310-1030000 ", " 1052627 ", " ", ". ", "\n", " TIM310-1130000M01 ", " 1062563 ", " none ", "\n", " TIM551-2050001 ", " 1060445 ", " ", " ", "\n", " MRS1104C-111011 ", " 1081208 ", " ", " ", " 4 x 12.5 Hz ", " 0.25\u00b0 ", " Horizontal: 275\u00b0; Vertical 7.5\u00b0 (Over 4 measurement layer) ", " 0.2m to 64m ", " \u00b1 60 mm ", " \u2264 30 mm ", " LAN, TCP ", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "This is the standard edition of the TIM310. It does ", " support ranging (only detection). There was a firmware bug in versions prior to V2.50 that allowed ranging output, and this node works with those firmware versions. All newer firmware versions ", ". ", "See the ", " file in the package directory. ", "To reduce data rates, some scanners (e.g., the TiM 571) don't send RSSI data by default. It must first be enabled in the configuration software by downloading ", ", connecting to the sensor using USB or Ethernet, logging in (UID: Authorized Client, PWD: client), and clicking the checkbox shown below: ", "Now you can visualize the ", " topic using ", ". Enjoy! ", " "], "package_tt": ["scan", "datagram", "publish_datagram", "~min_ang", "double", "~max_ang", "double", "~intensity", "bool", "~skip", "int", "~frame_id", "str", "~time_offset", "double", "~auto_reboot", "bool", "~hostname", "string", "hostname", "~port", "string", "hostname", "~publish_datagram", "bool", "/datagram", "~subscribe_datagram", "bool", "true", "/datagram", "publish_datagram", "udev/README", "/scan", "publish_datagram", "<!--\u00a0...\u00a0-->", "<param\u00a0name=\"publish_datagram\"\u00a0type=\"bool\"\u00a0value=\"true\"\u00a0/>"], "package_code": ["roslaunch sick_tim sick_tim551_2050001.launch"]},
{"url": "https://wiki.ros.org/usb_cam", "package": "usb_cam", "package_summary": ["A ROS Driver for V4L USB Cameras"], "package_details": ["\n", "\n", "\n", " - supports image capture from usb cameras using OpenCV "], "package_tt": ["usb_cam_node", "~<camera_name>/image_raw", "~video_device", "string", "\"/dev/video0\"", "~image_width", "integer", "640", "~image_height", "integer", "480", "~pixel_format", "string", "\"mjpeg\"", "~io_method", "string", "\"mmap\"", "~camera_frame_id", "string", "\"head_camera\"", "~framerate", "integer", "30", "~contrast", "integer", "32", "~brightness", "integer", "32", "~saturation", "integer", "32", "~sharpness", "integer", "22", "~autofocus", "boolean", "false", "~focus", "integer", "51", "~camera_info_url", "string", "~camera_name", "string", "head_camera"]},
{"url": "https://wiki.ros.org/velodyne_height_map", "package": "velodyne_height_map", "package_summary": ["\n\n    Obstacle detection for 3D point clouds using a height map algorithm.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Start the height map nodelet in a separate process. ", " ", "This launch file runs the height map nodelet in the same process with the Velodyne device driver and a ", " nodelet which publishes the points transformed into the \"/odom\" frame. ", " "], "package_tt": ["velodyne_points", "velodyne_obstacles", "velodyne_clear", "cell_size", "double", "full_clouds", "bool", "true", "grid_dimensions", "int", "height_threshold", "double"], "package_code": ["$ rosrun nodelet nodelet standalone velodyne_height_map/HeightMapNodelet", "<launch>\n", "\n", "  <!-- start nodelet manager and driver nodelets -->\n", "  <include file=\"$(find velodyne_driver)/launch/nodelet_manager.launch\">\n", "    <arg name=\"pcap\"\n", "           value=\"$(find velodyne_pointcloud)/tests/class.pcap\"/>\n", "  </include>\n", "\n", "  <!-- start transform nodelet using test calibration file -->\n", "  <include file=\"$(find velodyne_pointcloud)/launch/transform_nodelet.launch\">\n", "    <arg name=\"calibration\"\n", "         value=\"$(find velodyne_pointcloud)/tests/angles.config\"/>\n", "  </include>\n", "\n", "  <!-- start heightmap nodelet -->\n", "  <include file=\"$(find velodyne_height_map)/launch/heightmap_nodelet.launch\"/>\n", "\n", "</launch>", "$ rosrun velodyne_height_map heightmap_node", "$ rosrun velodyne_height_map heightmap_node _grid_dimensions:=100 _cell_size:=0.1", "$ rosrun velodyne_height_map heightmap_node _height_threshold:=0.05"]},
{"url": "https://wiki.ros.org/nav2d_operator", "package": "nav2d_operator", "package_summary": ["The operator is a lightweight, purely reactive obstacle-avoidance\n    module for mobile robots moving in a planar environment. The operator node\n    works by evaluating a set of predefined motion primitives based on a local\n    costmap and a desired direction. The best evaluated motion command will be\n    send to the mobile base."], "package_details": ["\n", "\n", "\n", "See the ", " for an example how to setup the Operator in Stage and use a Joystick to simulate commands from a higher level node. "], "package_tt": ["operator", "scan", "tf", "cmd", "Velocity", "Turn", "Mode", "cmd_vel", "~desired", "~route", "~local_map/costmap", "~max_free_space", "double", "~safety_decay", "double", "~max_velocity", "double", "~safety_weight", "int", "~distance_weight", "int", "~conformance_weight", "int", "~continue_weight", "int", "~publish_route", "bool", "desired", "route"]},
{"url": "https://wiki.ros.org/pr2_controller_interface", "package": "pr2_controller_interface", "package_summary": ["This package specifies the interface to a realtime controller. A\n   controller that implements this interface can be executed by the\n    ", " in the real time control loop. The package basically\n  contains the C++ controller base class that all controllers need to\n  inherit from."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "To implement a real time controller, your controller needs to inherit from the ", " base class. The base class contains  ", "The ", " method is executed in ", ". ", "The ", " method returns if the initialization was successful or not. If the initialization fails, the controller will get unloaded by ", ". Make sure to always use ", " to inform the user why your controller failed to initialize. A controller can only be initialized once. If you want to re-initialize a controller, you first need to unload it, and then load it again.  ", "The ", " method is executed in ", ". ", "The ", " method initializes the controller right before the first time update is called. The ", " is allowed to re-start a controller at a later time, without having to unload/load the controller. ", "The ", " method is executed in ", ". ", "The ", " method is executed in ", ". ", "The ", " method does not return anything, it is not allowed to fail.  ", "The ", " method is executed in ", ". ", "The ", " method takes three arguments: "], "package_tt": ["pr2_controller_interface::Controller", "init", "init", "init", "pr2_mechanism_model::RobotState", "ros::NodeHandle", "init", "ROS_ERROR(\"explanation\");", "starting", "starting", "update", "update", "stopping", "stopping", "stopping", "getController", "getController", "getController", "pr2_controller_interface:BEFORE_ME", "pr2_controller_interface::AFTER_ME", "getController"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/industrial_moveit", "package": "industrial_moveit", "package_summary": ["ROS Industrial MoveIt packages."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It currently contains packages that are meant for use with the ", " packages. ", "See the ", " page for an overview of the available tutorials. "]},
{"url": "https://wiki.ros.org/asr_intermediate_object_generator", "package": "asr_intermediate_object_generator", "package_summary": ["The intermediate object generator generates intermediate objects for a domain composed from scenes. \n    It is used to restrain the amount of objects searched during the direct search phase by selecting appropriate objects to search."], "package_details": [" ", "\n", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", ": The path were the intermediate_object_weights xml file should be created. The XXX works analog here, too. ", "\n", " ", "The intermediate object generator generates intermediate object for a domain composed from scenes. It is used to restrain the amount of object searched during the direct search (", ") phase by selecting appropriate objects to search. ", "This package needs a database of objects and their absolute positions during the time (can be set in the ", "). On basis of this information it will be determined which objects have a heigher chance to be found in a 3D-object-search. There will be two files saved. ", "In one a subset of the current objects will be saved, to limit the search objects while the direct search of the ", ". ", "In the second the calculated weight for each object will be saved. This can be used in the ", " to prefer some objects about the others. ", "The ", " will launch this package automatically if the generated files for the current database were not generated yet. There is an option in asr_world_model to activate this function. ", "!", ": The path were the intermediate_objects xml file should be created. If there is an XXX in the name, the XXX will be replaced with the current database name. So the name has not to be changed manually after a database change. ", "!", " : 0 or 1, 0 is additive and 1 is multiplicative ", " : weight for the presence in scene criteria ", " : weight for the position variance criteria ", " : weight for the average distance between object criterias!  ", " : gain threshold for the object filtering !", " : name of the domain "]},
{"url": "https://wiki.ros.org/md49_base_controller", "package": "md49_base_controller", "package_summary": ["The md49_base_controller package"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", "\n"], "package_tt": ["/cmd_vel", "/md49_data", "/md49_encoders", "~serialport/name", "std::string", "~serialport/bps", "int", "~md49/mode", "int", "~md49/acceleration", "int", "~md49/regulator", "boolean", "~md49/timeout", "boolean", "~md49/speed_l", "int", "~md49/speed_r", "int"]},
{"url": "https://wiki.ros.org/octomap_ros", "package": "octomap_ros", "package_summary": ["octomap_ros provides conversion functions between ROS and OctoMap's native types.\n    This enables a convenvient use of the octomap package in ROS."], "package_details": ["\n", "\n", " ", "See ", " for documentation. ", " helps you to convert between various ROS / PCL and OctoMap data types.  ", "Messages, services and conversions of them (without ROS-dependencies) are available in ", ". Since fuerte, this package is a unary stack and released separately. "]},
{"url": "https://wiki.ros.org/trac_ik", "package": "trac_ik", "package_summary": ["The ROS packages in this repository were created to provide an improved\n    alternative Inverse Kinematics solver to the popular inverse Jacobian\n    methods in KDL.  TRAC-IK handles joint-limited chains better than KDL\n    without increasing solve time."], "package_details": ["\n", "\n", "\n", "Sources -- including a ", "! compatible IK plugin -- can be found at: ", ". ", "TRAC-IK has a very similar API to KDL's IK solver calls, except that the user passes a maximum time instead of a maximum number of search iterations.  Additionally, TRAC-IK allows for error tolerances to be set independently for each Cartesian dimension (x, y, z, roll, pitch & yaw). ", "Detailed usage instructions can be found at ", " (or more specifically, ", "). ", "KDL's joint-limited pseudoinverse Jacobian implementation is the solver used by various ROS packages and ", "! for generic manipulation chains. In our research with Atlas humanoids in the DARPA Robotics Challenge and with NASA's Robonaut 2 and Valkyrie humanoids, TRACLabs researchers experienced a high amount of solve errors when using KDL's inverse kinematics functions on robotic arms.  We tracked the issues down to the fact that theoretically-sound Newton methods fail in the face of joint limits.  As such, we have created TRAC-IK that concurrently runs two different IK methods: ", "Details can be found here in our Humanoids 2015 paper ", ". ", "Image (from ", "): A few high-level results are shown in the attached (low-res) figure. ", " ", "Use ", " to ", ". ", ". "]},
{"url": "https://wiki.ros.org/social_navigation_layers", "package": "social_navigation_layers", "package_summary": ["Plugin-based layers for the navigation stack that \n  implement various social navigation contraints, like proxemic distance."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "There are currently two social navigation layers. However, they both share functionality in that they both subscribe to where people are and alter the costmaps with a Gaussian distribution around those people. Both classes derive from the general SocialLayer class. ", "They can be used in ", " with the following types: ", "The proxemic layer adds gaussian costs all around the detected person, with the parameters specified above. If the person is stationary, the gaussian is perfectly round. However, if the person is moving, then the costs will be increased in the direction of their motion. How far in front of the person the costs are increased is proportional to the ", " parameter.  "], "package_tt": ["social_navigation_layers::ProxemicLayer", "social_navigation_layers::PassingLayer", "/people", "enabled", "bool", "cutoff", "double", "amplitude", "double", "covariance", "double", "factor", "double", "keep_time", "double", "factor"]},
{"url": "https://wiki.ros.org/webui", "package": "webui", "package_summary": ["A web interface to install and launch applications for the PR2."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Ergo, the easiest way to install the webui from the binary is to ", " the webui directory.  ", "... where <robot name> would usually be of the form prX and <robot type> would usually be pr2. ", "Add the following line to /etc/apache2/sites-available/default just above <", "> near the end of the file: "], "package_tt": ["ros-RELEASE-web-interface", "python-clearsilver", "apache2-mpm-prefork", "libapache2-mod-python", "ruby1.8-dev", "chown", "/etc/ros/env", "ROBOT", "ROBOT_NAME", "ROS_ROOT", "ROS_MASTER_URI", "ROS_PACKAGE_PATH"], "package_code": ["roscd webui\n", "make -f setup.make\n", "sudo ./install.py <robot name> <robot type> www-data", "sudo ./install_root", "Include /etc/ros/ros_webui_apache.cfg", "sudo cp varwww/index.html /var/www/index.html", "sudo apache2ctl restart", "    gPump.publish(\"/hoge\",\"std_msgs/String\",[\"hoga\"]);", "    gPump.service_call2(\"/service/knowrob\",\n", "                       {'str': command},\n", "                       function(res){\n", "                         document.getElementById('displaybox') , res.str);\n", "                       }\n", "                       );", "<div class=\"nav_element\" objtype=PercentTextWidget topic=\"/power_state\" num=\"a\" div=\"b\"/></div>", "var PercentTextWidget = Class.create({\n", "  initialize: function(domobj) {\n", "    this.pump = null;\n", "    this.domobj = domobj;\n", "    this.topics = [domobj.getAttribute(\"topic\")];\n", "    this.numerator = domobj.getAttribute(\"num\");\n", "    this.denominator = domobj.getAttribute(\"den\");\n", "  }, \n", "\n", "  init: function() {\n", "  }, \n", "\n", "  receive: function(topic, msg) {\n", "    if(msg[this.numerator] != null) {\n", "      var percent = parseFloat(msg[this.numerator]) / parseFloat(msg[this.denominator]);\n", "      this.domobj.innerHTML = (100. * percent).toFixed(2) + \"%\";\n", "    }\n", "  } \n", "});\n", "\n", "gRosClasses[\"PercentTextWidget\"] = function(dom){\n", "  return new PercentTextWidget(dom);\n", "}"]},
{"url": "https://wiki.ros.org/pr2_navigation_local", "package": "pr2_navigation_local", "package_summary": ["This package holds xml files for running the"], "package_details": ["\n", "\n", "\n", "\n", "This package contains configuration files for the ", " node meant to be run in an application that requires navigation in an odometric frame. This package also includes launch files that bring up ", " and ", " with local navigation specific configurations. "], "package_tt": ["rviz/rviz_move_base_local.launch", "nav_view/nav_view_move_base_local.launch", "move_base_local.xml", "config/global_costmap_params.yaml", "move_base_local.xml", "config/base_local_planner_params.yaml", "config/local_costmap_params.yaml", "move_base_local.xml", "config/move_base_params.yaml"]},
{"url": "https://wiki.ros.org/pr2_navigation_teleop", "package": "pr2_navigation_teleop", "package_summary": ["This package holds a special teleop configuration for the PR2 robot that\n     should be used when running applications that use autonomous navigation."], "package_details": ["\n", "\n", "This package provides an XML file for running ", " in a configuration that allows it to run in parallel with the ", " stack on the PR2 robot. "], "package_tt": ["teleop.xml"]},
{"url": "https://wiki.ros.org/ieee80211_channels", "package": "ieee80211_channels", "package_summary": ["\n    This package provides mapping from frequencies to\n    IEEE802.11 channels and vice-versa.\n  "], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/tuw_marker_slam", "package": "tuw_marker_slam", "package_summary": ["The tuw_marker_slam package provides a framework for feature based SLAM implementations in ROS.\n      Meanwhile a variant of EKF-SLAM is implemented."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Start SLAM framework in EKF-SLAM mode with a predefined measurement noise model using the simulation environment Stage (", "): ", "Start SLAM framework in EKF-SLAM mode with a predefined measurement noise model using the simulation environment Gazebo (", ") and the tuw_aruco marker detection "], "package_tt": ["cmd", "marker", "xt", "mt", "mode", "int", "xzplane", "boolean", "false", "frame_id_map", "string", "\"map\"", "frame_id_odom", "string", "\"odom\"", "frame_id_base", "string", "\"base_link\"", "beta_1/18", "double", "base", "odom", "<frame\u00a0in\u00a0which\u00a0measurements\u00a0are\u00a0taken>", "base", "map", "odom"], "package_code": ["rosrun tuw_marker_slam tuw_marker_slam_node", "roslaunch tuw_marker_slam slam.launch", "roslaunch tuw_marker_slam slam_demo_stage.launch", "roslaunch tuw_marker_slam slam_demo_gazebo.launch"]},
{"url": "https://wiki.ros.org/shape_tools", "package": "shape_tools", "package_summary": ["Tools for operating on shape messages."]},
{"url": "https://wiki.ros.org/staubli_resources", "package": "staubli_resources", "package_summary": ["\n      Shared configuration data, 3D models and launch files for Staubli\n      manipulators.\n    ", "\n      This package contains configuration data, 3D models and launch files\n      that are shared between different Staubli robot support packages\n      within the ROS-Industrial program.\n\n      This package also contains common urdf / xacro resources used by\n      other Staubli related packages.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " metapackage page. "]},
{"url": "https://wiki.ros.org/xaxxon_openlidar", "package": "xaxxon_openlidar", "package_summary": ["ROS Drivers for the Xaxxon OpenLIDAR Sensor"], "package_details": ["\n", "is an open hardware rotational laser scanner, using the Garmin LIDAR-LiteV3 sensor. Full specs and complete documentation can be found at ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Full specs and complete documentation can be found at ", " "], "package_tt": ["/scan", "/odom", "dropscan_turnrate", "minimum_range", "maximum_range", "rpm", "masks", "dropscan_turnrate", "/odom", "park_offset", "forward_offset", "read_frequency"]},
{"url": "https://wiki.ros.org/stdr_simulator", "package": "stdr_simulator", "package_summary": ["A simple, flexible and scalable 2D multi-robot simulator."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", " ", " ", "STDR Simulator implements a distributed, server-client based architecture. Each node can run in a different machine and communicate using ros interfaces. STDR Simulator, also provides a ", " developed in QT, for visualization purposes and more. The ", ", is not necessary for the simulator to run and its functionalities can be performed using command-line tools provided with the package. ", "The ", " available packages are: ", "An overview of the ", " architecture is depicted in the following diagram: "]},
{"url": "https://wiki.ros.org/rwt_plot", "package": "rwt_plot", "package_summary": ["rwt_plot"], "package_details": ["Example of ", " with ", ". ", " "], "package_tt": ["rwt_plot"]},
{"url": "https://wiki.ros.org/moveit_object_handling", "package": "moveit_object_handling", "package_summary": ["Package which helps generate the MoveIt! moveit_msgs/CollisionObject\n    messages for existing objects in the scene, described by object_msgs/Object.\n    Also provides helper classes for MoveIt! in relation to objects."]},
{"url": "https://wiki.ros.org/viso2_ros", "package": "viso2_ros", "package_summary": ["\n    This is the ROS wrapper for libviso2, library for visual odometry (see package libviso2).\n  "], "package_details": ["\n", "\n", ": The coordinate frame of the camera is expected to be the ", " frame, which means ", " is pointing right, ", " downwards and ", " from the camera into the scene. The origin is where the camera's principle axis hits the image plane (as given in ", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains two nodes that talk to ", " (which is included in the ", " package): ", " and ", ". Both estimate camera motion based on incoming rectified images from calibrated cameras. To estimate the scale of the motion, the mono odometer uses the ground plane and therefore needs information about the camera's z-coordinate and its pitch. The stereo odometer needs no additional parameters and works - if provided with images of good quality - out of the box. ", "The video below shows an online 3D reconstruction of a 3D scene shot by a Micro AUV using dense stereo point clouds coming from ", " concatenated in ", " using the stereo odometer of this package. ", "In the repository, you can find a sample launch file, which uses a public bagfile available here: ", ". ", "Please read ", " for an explanation of odometry frame ids. ", "Visual odometry algorithms generally calculate ", ". To be able to calculate ", " based on ", ", the transformation from the camera frame to the robot frame has to be known. ", "Therefore this implementation needs to know the tf ", " \u2192 ", " to be able to publish ", " \u2192 ", ". ", "The name of the camera frame is taken from the incoming images, so be sure your camera driver publishes it correctly. If your camera driver does not set frame ids, you can use the fallback parameter ", " (see below). ", "To learn how to publish the required tf ", " \u2192 ", ", please refer to the ", ". ", "If the required tf is not available, the odometer assumes it as the identity matrix which means the robot frame and the camera frame are identical. ", "In general, monocular odometry and SLAM systems cannot estimate motion or position on a metric scale. All estimates are relative to some unknown scaling factor. libviso2 overcomes this by assuming a fixed transformation from the ground plane to the camera (parameters ", " and ", "). To introduce these values, in each iteration the ground plane has to be estimated. That is why features on the ground as well as features above the ground are mandatory for the mono odometer to work. ", "Please use the stack's issue tracker at Github to submit bug reports and feature requests regarding the ROS wrapper of libviso2: ", ". "], "package_tt": ["mono_odometer", "stereo_odometer", "world", "odom", "base_link", "camera", "base_link", "camera", "odom", "base_link", "sensor_frame_id", "x", "y", "z", "base_link", "camera", "camera_height", "camera_pitch", "camera_height", "camera_pitch", "~pose", "~odometry", "~info", "~odom_frame_id", "string", "/odom", "~base_link_frame_id", "string", "/base_link", "~publish_tf", "bool", "~sensor_frame_id", "string", "~max_features", "int", "~bucket_width", "double", "~bucket_height", "double", "~nms_n", "int", "~nms_tau", "int", "~match_binsize", "int", "~match_radius", "int", "~match_disp_tolerance", "int", "~outlier_disp_tolerance", "int", "~outlier_flow_tolerance", "int", "~multi_stage", "int", "~half_resolution", "int", "~refinement", "int", "~base_link_frame_id", "<frame_id\u00a0attached\u00a0to\u00a0image\u00a0messages>", "base_link", "~odom_frame_id", "~base_link_frame_id", "odom", "base_link", "image", "camera_info", "image_transport::CameraSubscriber", "~camera_height", "double", "~camera_pitch", "double", "~ransac_iters", "int", "~inlier_threshold", "double", "~motion_threshold", "double", "<stereo>/left/<image>", "<stereo>/right/<image>", "<stereo>/left/camera_info", "<stereo>/right/camera_info", "~point_cloud", "~queue_size", "int", "~approximate_sync", "bool", "~ransac_iters", "int", "~inlier_threshold", "double", "~reweighting", "bool", "~ref_frame_change_method", "int", "~ref_frame_motion_threshold", "double", "~ref_frame_inlier_threshold", "int"]},
{"url": "https://wiki.ros.org/uwb_hardware_driver", "package": "uwb_hardware_driver", "package_summary": ["The uwb_hardware_driver package"]},
{"url": "https://wiki.ros.org/segbot_navigation", "package": "segbot_navigation", "package_summary": ["Contains launch files for running the ROS navigation stack on the segbot\n    using the eband_local_planner approach, as well as launch files for amcl\n    and gmapping."]},
{"url": "https://wiki.ros.org/goal_passer", "package": "goal_passer", "package_summary": ["A global planner plugin for move_base that simply passes the target pose on\n    as a global plan. Useful for debugging local planners."]},
{"url": "https://wiki.ros.org/rwt_config_generator", "package": "rwt_config_generator", "package_summary": ["The rwt_config_generator package"]},
{"url": "https://wiki.ros.org/katana_moveit_ikfast_plugin", "package": "katana_moveit_ikfast_plugin", "package_summary": ["The katana_moveit_ikfast_plugin package"]},
{"url": "https://wiki.ros.org/hironx_calibration", "package": "hironx_calibration", "package_summary": ["Launch and configuration files for calibrating hironx using the generic ", " package.\n\n   THIS FILE IS AUTOMATICALLY GENERATED BY:", "\n   "]},
{"url": "https://wiki.ros.org/rosh_geometry", "package": "rosh_geometry", "package_summary": ["\n\n     ROSH plugin for the geometry stack, including tf.\n\n  "], "package_details": ["\n", "\n", " "], "package_tt": ["transforms", "Point", "Quaternion", "PointStamped", "PoseStamped", "QuaternionStamped", "Vector3Stamped", "transforms.transform_name('target_transform')", "transform_name", "target_transform"]},
{"url": "https://wiki.ros.org/tuw_marker_pose_estimation", "package": "tuw_marker_pose_estimation", "package_summary": ["This node does pose estimation for detected fiducials (marker_msgs/FiducialDetection.msg)"]},
{"url": "https://wiki.ros.org/warehouse_ros_mongo", "package": "warehouse_ros_mongo", "package_summary": ["Implementation of warehouse_ros for MongoDB"], "package_details": [" "]},
{"url": "https://wiki.ros.org/summit_xl_robot_control", "package": "summit_xl_robot_control", "package_summary": ["Control the robot joints in all kinematic configurations, publishes odom topic and, \n\t  if configured, also tf odom to base_link. Usually takes as input joystick commands \n\t  and generates as outputs references for the gazebo controllers defined in summit_xl_control."], "package_details": ["\n", "Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "]},
{"url": "https://wiki.ros.org/rc_pick_client", "package": "rc_pick_client", "package_summary": ["The ros client for roboception grasp generation modules"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", "See ", " and ", " for more details. ", "The components provide out-of-the-box perception solutions for robotic pick-and-place applications. ", " targets the detection of flat surfaces of unknown objects for picking with a suction gripper. ", " detects rectangular surfaces and determines their position, orientation and size for grasping. The interface of both components is very similar. Therefore both components are described together in this chapter. ", "For detail description of the modules check the following link: ", " ", "The following parameters are available for the ", " and ", " modules: ", "For the ", " module, two additional parameters are available: ", "The ", " node offers an additional service: ", "For the ", " module: ", "For the ", " module: "], "package_tt": ["host", "device", "02912345", ":02912345", "load_carrier_crop_distance", "load_carrier_model_tolerance", "cluster_max_curvature", "clustering_max_surface_rmse", "clustering_discontinuity_factor", "cluster_max_dimension", "clustering_patch_size", "start", "stop", "set_region_of_interest", "get_region_of_interests", "delete_regions_of_interest", "set_load_carrier", "get_load_carriers", "delete_load_carriers", "detect_load_carrier", "compute_grasps", "detect_items"], "package_code": ["$ rosrun rc_pick_client rc_itempick_client_node _host:=<sensor_ip>", "rosrun rc_pick_client rc_itempick_client_node _device:=:<serial_number>", "$ rosrun rc_pick_client rc_boxpick_client_node _host:=<sensor_ip>", "rosrun rc_pick_client rc_boxpick_client_node _device:=:<serial_number>"]},
{"url": "https://wiki.ros.org/nav2d", "package": "nav2d", "package_summary": ["Meta-Package containing modules for 2D-Navigation"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "This stack is developed using the catkin tool-chain. An older version is available that uses ROS Fuerte and rosbuild tool-chain, but has not been updated after the move to Hydro. To build the ", " package is required, which is included in ros-navigation. ", "To check if all packages are working correctly, you can run the launch files located in the ", " package. This will use a joystick to semi-autonomous control a simulated robot in Stage. A more in-detail description can be found in the ", ". To start the tests you need to have the following packages additionally installed: ", "If you have a Question concerning any of the nav2d-packages, please post your question at ", " and add the tag \"nav2d\". "], "package_code": ["    apt-get install ros-<release-name>-nav2d", "    ros-<release-name>-nav2d_operator\n", "    ros-<release-name>-nav2d_navigator\n", "    ros-<release-name>-nav2d_exploration\n", "    ros-<release-name>-nav2d_karto\n", "    ros-<release-name>-nav2d_remote\n", "    ros-<release-name>-nav2d_msgs\n", "    ros-<release-name>-nav2d_tutorials", "    source /opt/ros/<release-name>/setup.bash\n", "    cd catkin_ws/src\n", "    git clone https://github.com/skasperski/navigation_2d\n", "    cd ..\n", "    catkin_make -DCMAKE_BUILD_TYPE=Release\n", "    source catkin_ws/devel/setup.bash", "roslaunch nav2d_tutorials tutorial1.launch"]},
{"url": "https://wiki.ros.org/joint_trajectory_action_tools", "package": "joint_trajectory_action_tools", "package_summary": ["joint_trajectory_action_tools"]},
{"url": "https://wiki.ros.org/sbpl_lattice_planner", "package": "sbpl_lattice_planner", "package_summary": ["The sbpl_lattice_planner is a global planner plugin for move_base and wraps\n    the SBPL search-based planning library."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "sbpl_lattice_planner is a ROS wrapper for the ", " lattice environment and  adheres to the nav_core::", " interface specified in ", ".  The lattice planner can therefore be used as the global planner for ", ". The planner will generate a path from the robot's current position to a desired goal pose. Paths are generated by combining a series of \"motion primitives\" which are short, kinematically feasible motions. Planning is therefore done in x, y, and theta dimensions, resulting in smooth paths that take robot orientation into account, which is especially important if the robot is not assumed to be circular or has nonholonomic constraints. Plans can be found using the ARA* planner or AD* planner. ", "Please refer to the ", " documentation for pre-made motion primitives for the PR2 (and other robots) as well as instructions on how to generate your own custom motions. "], "package_tt": ["~/SBPLLatticePlanner/plan", "~/SBPLLatticePlanner/sbpl_lattice_planner_stats", "~/SBPLLatticePlanner/planner_type", "string", "~/SBPLLatticePlanner/allocated_time", "double", "~/SBPLLatticePlanner/initial_epsilon", "double", "~/SBPLLatticePlanner/environment_type", "string", "~/SBPLLatticePlanner/forward_search", "bool", "~/SBPLLatticePlanner/primitive_filename", "string", "~/SBPLLatticePlanner/force_scratch_limit", "int", "~/SBPLLatticePlanner/nominalvel_mpersecs", "double", "~/SBPLLatticePlanner/timetoturn45degsinplace_secs", "double", "~/SBPLLatticePlanner/lethal_obstacle", "unsigned\u00a0char"], "package_code": ["roslaunch sbpl_lattice_planner  move_base_sbpl_fake_localization_2.5cm.launch"]},
{"url": "https://wiki.ros.org/agile_grasp", "package": "agile_grasp", "package_summary": ["The agile_grasp ROS package. AGILE stands for Antipodal Grasp Identification and LEarning. The package \n  finds antipodal grasps in point clouds."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", "\n", "\n", ": If you want to adjust the grasp parameters, you can do this from the launch file. For the available parameters, see ", ". ", "\n", " ", " ", " ", "\n", " ", " When no handles or not enough antipodal grasps are found, please increase the ", " parameter. Another option is to modify the workspace limits in ", " (this requires recompiling the code). ", " ", "\n", "\n", "\n", " ", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", "This package localizes antipodal grasps in 3D point clouds. ", " stands for ", "ntipodal ", "rasp ", "dentification and ", "arning. The reference for this package is: ", ". ", "The package already comes with pre-trained machine learning classifiers and can be used (almost) out-of-the-box, in particular with an ", " range sensor. ", "For a complete ", " on a Baxter robot, check out our ", " package. ", "Two example ROS launch files, ", " and ", ", are provided that illustrate  how to use the ", " ROS node to localize grasps in a point cloud obtained from one or two range sensors. ", "The most important parameters to increase the number of grasps found are ", " and ", ". A higher sample number means that a larger subset of points in the point cloud will be considered. A smaller workspace means that less samples are required to find grasps. ", "Localize grasps in a point cloud stored in a ", " file: ", "This localizes grasps in the point cloud file ", " using the SVM stored in the file ", ". The last three parameters are optional. ", " sets the number of samples, ", " sets the number of CPU threads used, and ", " sets the minimum number of grasps required to have a cluster of grasps. ", "To train the SVM to predict grasps, first create a directory that contains the ", " files used for training. ", "If you like this package and use it in your own work, please cite our ", ": ", "Andreas ten Pas and Robert Platt. ", " International Symposium on Robotics Research (ISRR), Italy, September 2015. "], "package_tt": ["$\u00a0sudo\u00a0apt-get\u00a0install\u00a0liblapack-dev", "$\u00a0cd\u00a0location_of_workspace/src", "$\u00a0git\u00a0clone\u00a0https://github.com/atenpas/agile_grasp.git", "$\u00a0cd\u00a0..", "$\u00a0catkin_make", "$\u00a0git\u00a0clone\u00a0https://github.com/atenpas/agile_grasp.git\u00a0-b\u00a0hydro", "$\u00a0roslaunch\u00a0agile_grasp\u00a0single_camera_grasps.launch", "$\u00a0roscore", "$\u00a0roslaunch\u00a0openni2_launch\u00a0openni2.launch", "$\u00a0roslaunch\u00a0agile_grasp\u00a0single_camera_grasps.launch", "$\u00a0rosrun\u00a0rviz\u00a0rviz", "$\u00a0rosrun\u00a0agile_grasp\u00a0test_svm\u00a0/home/userABC/data/input.pcd\u00a0/home/userABC/ros_ws/src/agile_grasp/svm_032015_20_20_same", "$\u00a0rosrun\u00a0agile_grasp\u00a0test_svm\u00a0pcd_filename\u00a0svm_filename\u00a0[num_samples]\u00a0[num_threads]\u00a0[min_handle_inliers]", "$\u00a0rosrun\u00a0agile_grasp\u00a0train_svm\u00a0num_files\u00a0pcd_directory/obj\u00a0svm_filename\u00a0[plots_hands]\u00a0[num_samples]\u00a0[num_threads]", "$\u00a0rosrun\u00a0agile_grasp\u00a0train_svm\u00a0num_files\u00a0pcd_directory\u00a0svm_filename\u00a0[plots_hands]\u00a0[num_samples]\u00a0[num_threads]"], "package_code": ["file1\n", "file2\n", "...", "file1\n", "file2\n", "..."]},
{"url": "https://wiki.ros.org/range_sensor_layer", "package": "range_sensor_layer", "package_summary": ["Navigation Layer for Range sensors like sonar and IR"], "package_details": ["\n", "\n", "\n", "\n", " ", "The range_sensor_layer is a plugin for the LayeredCostmap in ", ", that uses the ", " message. It is intended for use with sonar and infrared data. "], "package_tt": ["\"topics\"", "ns", "string", "topics", "Array\u00a0of\u00a0strings", "no_readings_timeout", "double", "clear_threshold", "double", "mark_threshold", "double", "clear_on_max_reading", "bool"], "package_code": ["      - {name: sonar,   type: \"range_sensor_layer::RangeSensorLayer\"}"]},
{"url": "https://wiki.ros.org/rotors_simulator", "package": "rotors_simulator", "package_summary": ["RotorS is a MAV gazebo simulator."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "RotorS is a MAV gazebo simulator. It provides some multi-rotor helicopter models such as the ", " Hummingbird, Pelican, and Firefly, but the simulator is not limited for the use with these multicopters. "]},
{"url": "https://wiki.ros.org/tuw_multi_robot_demo", "package": "tuw_multi_robot_demo", "package_summary": ["Contains launch and config files to run a sample demo."], "package_details": ["\n", "\n", "\n", "\n", "\n", " default: \"cave\" ", " default: \"true\" ", " default: \"true\" ", " default: \"true\" ", " default: \"true\" ", " default: \"true\" ", " default: \"true\" ", " default: \"default\" (2 robots) ", " default: \"false\" ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "To control the robots one can use a custom controller (e.g. the DWA from move_base) in combination with the local behavior controller which takes care of synchronization with other robots and provides an ordinary nav_msgs/Path message. For tests with a large number of robots the ", " is provided which directly uses synchronous tuw_multi_robot_msgs/Route messages and controls all robots simultaneously. This is advantageous for performance reasons. "], "package_tt": ["multi_segment_controller_node", "room", "use_rviz", "use_stage", "use_map_server", "use_planner", "use_controller", "use_graph_generator", "cfg", "use_path_synchronizer"]},
{"url": "https://wiki.ros.org/arbotix_firmware", "package": "arbotix_firmware", "package_summary": ["Firmware source code for ArbotiX ROS bindings."], "package_details": ["\n", "\n", "\n", "\n", "You can then copy the files found in the ", " folder of this package into your sketchbook. You should then be able to open the ", " sketch, compile and upload.  "]},
{"url": "https://wiki.ros.org/webrtc_ros", "package": "webrtc_ros", "package_summary": ["A collection of ROS utilities for using WebRTC with ROS"], "package_details": ["\n", "\n", "\n", "\n", "A ROS wrapper that allows for streaming of ROS video topics over  ", ". ", "webrtc_ros_server_node operates similar to ", ". It provides a way of streaming ROS topics to a web browser. By default it provides a webpage at the root path of the web server that allows you to browse all video topics and stream any of them. A small Javascript library is also served to simplify the usage. See the topic stream web page source for a simple example of usage. ", "A simple protocol that uses JSON over WebSockets is used as the WebRTC signaling channel. "], "package_tt": ["~port", "string", "~image_transport", "string"]},
{"url": "https://wiki.ros.org/rtt_actionlib_msgs", "package": "rtt_actionlib_msgs", "package_summary": ["Provides an rtt typekit for ROS actionlib_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/actionlib_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/rosserial_server", "package": "rosserial_server", "package_summary": ["A more performance- and stability-oriented server alternative implemented\n    in C++ to rosserial_python."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains a C++ implementation of the host-side rosserial connection. It automatically handles setup, publishing, and subscribing for a connected rosserial-enabled device. It uses a python node in the rosserial_python package as an aid for handling subcriptions. ", "These nodes use the ", "/ShapeShifter meta message in order to republish messages from clients without having to know about them at compile time. The only caveat to this approach is that the servers do not have the full textual definition of messages (as it is not stored in clients or part of the rosserial protocol). There is a provided Python shim which the servers may optionally use to acquire this information. Example launch files for serial and socket usage are provided in the package. ", "The ", " parameter to the server allows it to enforce that the client(s) must publish and subscribe to a certain set of topics. This is important because a serial connection provides no guarantee of delivery, and the rosserial protocol doesn't inherently contain any such checks. ", "Use of the ", " parameter is completely optional, but may be of value to users needing to deploy ROS-connected microcontrollers into environments where the occasional failed initialization is not acceptable. ", "At this time, ", " is experimental. It is missing key features of the ", "-provided node, including parameters, logging, and services. If you require these features, please stick to the standard Python server for now. "], "package_tt": ["~port", "str", "~baud", "int", "~require", "obj", "~port", "int", "~require", "~require"], "package_code": ["roslaunch rosserial_server serial.launch port:=/dev/ttyUSB0", "roslaunch rosserial_server socket.launch", "rosrun rosserial_server serial_node _port:=/dev/ttyUSB0", "<launch>\n", "  <node pkg=\"rosserial_server\" type=\"serial_node\" name=\"rosserial_server\">\n", "    <rosparam>\n", "      port: /dev/arduino\n", "      require:\n", "        publishers: [ status ]\n", "        subscribers: [ cmd, lights ]\n", "    </rosparam>\n", "  </node>\n", "  <node pkg=\"rosserial_python\" type=\"message_info_service.py\"\n", "        name=\"rosserial_message_info\" />\n", "</launch>"]},
{"url": "https://wiki.ros.org/nav_pcontroller", "package": "nav_pcontroller", "package_summary": ["Simple P-Controller for a holonomic robot base"]},
{"url": "https://wiki.ros.org/trac_ik_kinematics_plugin", "package": "trac_ik_kinematics_plugin", "package_summary": ["A MoveIt! Kinematics plugin using TRAC-IK"]},
{"url": "https://wiki.ros.org/trajectory_msgs", "package": "trajectory_msgs", "package_summary": ["This package defines messages for defining robot trajectories. These messages are\n    also the building blocks of most of the\n    ", " actions."], "package_details": ["\n", ": this package is now part of ", ".  In previous releases, it was part of ", ". ", "\n"]},
{"url": "https://wiki.ros.org/wheeled_robin_apps", "package": "wheeled_robin_apps", "package_summary": ["The wheeled_robin_apps is a group of applications to run on the WheeledRobin Robot."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "Please refer main ", " page. "]},
{"url": "https://wiki.ros.org/ackermann_msgs", "package": "ackermann_msgs", "package_summary": ["ROS messages for robots using Ackermann steering."], "package_details": ["\n", "\n", " ", "This package provides ROS messages for vehicles using front-wheel Ackermann steering. It was defined by the", ". "]},
{"url": "https://wiki.ros.org/people", "package": "people", "package_summary": ["The people stack holds algorithms for perceiving people from a number of sensors."]},
{"url": "https://wiki.ros.org/rail_maps", "package": "rail_maps", "package_summary": ["Maps generated by the RAIL group at WPI.", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "\n", "To install from source, execute the following:  ", "\n", "To install the Ubuntu package, execute the following:  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " stack contains a set of maps in ", " format that have been generated by the ", " research group at ", ". Maps can be used in the real world or in simulated worlds provided in the ", " package. ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["rail_maps", "*.pgm", "0.05", "0.05", "0.05", "0.05", "0.05", "0.05", "rail_maps", "rail_maps"], "package_code": ["\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-rail-maps", "\n", "\n", "\n", "\n", "sudo apt-get install ros-groovy-rail-maps"]},
{"url": "https://wiki.ros.org/nao_path_follower", "package": "nao_path_follower", "package_summary": ["\n\t", "\n  Enables a Nao humanoid to either walk to a target location (with localization feedback),\n  or follow a planned 2D path closely. Sends nao_msgs to the nao_walker node in nao_driver.\n  "], "package_details": ["\n", "\n"], "package_tt": ["foot_contact", "True", "cmd_pose", "use_vel_ctrl", "False", "cmd_vel", "use_vel_ctrl", "True", "nao_path_follower/target_pose", "walk_path/goal", "walk_target/goal", "base_frame_id", "string", "controller_frequency", "float", "target_distance_threshold", "float", "target_angle_threshold", "float", "waypoint_distance_threshold", "float", "waypoint_angle_threshold", "float", "max_vel_x", "float", "max_vel_y", "float", "max_vel_yaw", "float", "step_freq", "float", "use_vel_ctrl", "boolean", "True", "False", "use_foot_contact_protection", "boolean", "True", "path_next_target_distance", "float", "path_max_start_distance", "float", "threshold_damp_xy", "float", "threshold_damp_yaw", "float"]},
{"url": "https://wiki.ros.org/wheeled_robin_simulator", "package": "wheeled_robin_simulator", "package_summary": ["The wheeled_robin_simulator stack provides packages for simulating a WheeledRobin robot."], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n  ", "Please refer main ", " page. ", "\n"]},
{"url": "https://wiki.ros.org/sr_common_drivers", "package": "sr_common_drivers", "package_summary": ["sr_common_drivers metapackage"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/rosh", "package": "rosh", "package_summary": ["rosh is a Python-based scripting and runtime environment for ROS.  Through rosh and its various plugins, you can interact with ROS APIs in an introspectable and unified approach."], "package_details": [" ", "\n", " is a Python-based shell and runtime environment for ROS.  It leverages the IPython shell environment to provide tab-completion introspection across various ROS APIs, like topics, services, parameters, and nodes.  It is similar to using tools like ", " and ", ", but with Pythonic semantics and the convenience of a Python interpreter.  You can also develop ROS nodes using rosh, which we call \"roshlets\". ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Please see the ", ". ", "See ", " ", "See ", " ", "In order customize your default ", " shell, you can write a ", ". ", "See ", ". "], "package_tt": ["rosh", "show(cameras.camera)", "rosh_robot", "rosh_robot"], "package_code": ["rosrun rosh rosh"]},
{"url": "https://wiki.ros.org/spin_hokuyo", "package": "spin_hokuyo", "package_summary": ["This package enables a 2D Hokuyo laser, connected to a Dynamixel servo motor, to produce a 3D point cloud that can\n    be visualized in rviz and used to make an octomap."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "Light Detection and Ranging, or LiDAR, depends on data from one or more laser range finders.  While some laser range finders are now available that create 3D scans, such as the Velodyne Puck, there are still gaps in the data, and 2D laser range finders provide even less data.  By connecting a 2D sensor to a servo, the amount of data acquired can be significantly increased and improve the robot's perception of its environment.  This package includes the code to operate such a setup and generates a point cloud that then be visualized in rviz or used to create an ", ". ", "The hardware used for developing this package were based on the setup detailed in this ", " from Glendale Community College. ", "While this code is specifically designed to operate with the Hokuyo laser and Dynamixel servo, any laser range finder and servo that provide identical or similar data could be used with the proper modification of the code.  The part files for the gimbal and mount used in this project are currently unavailable, but the original gimbal used in the capstone report can be found ", ". "], "package_tt": ["tilt_controller/state", "tilt_controller/command", "time/start_time", "time/end_time", "~maximum", "integer", "~minimum", "integer", "~pause", "float", "tilt_controller/state", "perform_sweep", "tilt_controller/command", "time/start_time", "time/end_time", "~maximum", "integer", "~minimum", "integer", "~pause", "float", "tilt_controller/State", "servo", "laser", "scan", "hokuyo_filtered", "hokuyo_filtered", "hokuyo_points", "time/start_time", "time/end_time", "assembled_cloud", "assemble_scans2", "~assembled_cloud_mode", "string", "~scan_time", "double"], "package_code": ["sudo apt-get install ros-indigo-spin-hokuyo", "roslaunch spin_hokuyo basic_motors.launch", "roslaunch spin_hokuyo tilting_lidar_continuous.launch"]},
{"url": "https://wiki.ros.org/tf2_msgs", "package": "tf2_msgs", "package_summary": ["tf2_msgs"], "package_details": ["\n", "This is the package grouping the Transform and Error messages used by ", " and ", ". "]},
{"url": "https://wiki.ros.org/rtt_rosgraph_msgs", "package": "rtt_rosgraph_msgs", "package_summary": ["Provides an rtt typekit for ROS rosgraph_msgs messages.\n\n    It allows you to use ROS messages transparently in\n\tRTT components and applications.\n\n\tThis package was automatically generated by the\n\tcreate_rtt_msgs generator and should not be manually\n\tmodified.\n\n\tSee the http://ros.org/wiki/rosgraph_msgs documentation\n\tfor the documentation of the ROS messages in this\n\ttypekit."]},
{"url": "https://wiki.ros.org/laptop_battery_monitor", "package": "laptop_battery_monitor", "package_summary": ["Simple script to check battery status"]},
{"url": "https://wiki.ros.org/rtmros_hironx", "package": "rtmros_hironx", "package_summary": ["The rtmros_hironx package is an operating interface via ROS and OpenRTM, for Hiro and ", " dual-armed robots from Kawada Industries Inc.\n  ", "\n  NOTE for Hiro users: Utilizing this opensource controller for Hiro requires installation both on Controller Box (QNX-based) and Vision PC (Ubuntu Linux), and the steps for it are not shared publicly in order to avoid any possible inconvenience that can easily be caused by slight mis-operation during installation. Please contact ", " for an advice."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Root of the frame tree is ", " (instead of ", " ", ") due to the fact that originally this robot wasn't made to work on ", ". ", "ROS news related to ", " twin-arm robot: ", "Full-fledged user document incl. writing codes is found ", ". ", "For ", "! related feature, HiroNXO does no customization. So follow general ", ".  ", "! has \"allow re-plan\" feature. ", " might be of your interest. "], "package_tt": ["QNX", "Ubuntu", "Hiro/NEXTAGE\u00a0OPEN", "ROS", "WAIST", "base_link", "ROS", "Hiro", "MoveIt!\u00a0way"], "package_code": [" Can moveit plan a path and then change it during execution because a new obstacle\n", " appeared in the path? There are `move_group.plan()` and `move_group.go()` for static\n", " scenes. Do I need other commands for dynamic scenes? ", " At the moment I am working on the low level API, the joint trajectory action\n", " interface to control the robot. Is it true that the joint trajectory controller \n", " directly control the joints (joint motors) of the robot? Because I thought that \n", " the robot can only be accessed via CORBA and ROS does not know anything about CORBA.", " Another question is, if the hrpsys simulator can also simulate the correct physical\n", " behavior when we control the joints directly (with Joint Trajectory Aciton). \n", " Let\u2019s say my controller parameters are chosen wrong.. Will the robot arm overshoot? "]},
{"url": "https://wiki.ros.org/sr_gui_bootloader", "package": "sr_gui_bootloader", "package_summary": ["\n\n    A GUI plugin for bootloading the motors on the shadow etherCAT hand.\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/ohm_tsd_slam", "package": "ohm_tsd_slam", "package_summary": ["The ohm_tsd_slam package provides a 2D SLAM approach for laser scanners."], "package_details": [" RANSAC-aided registration  ", " Multi-robot SLAM  ", "\n", "\n", "\n", " ", "Welcome to the ohm_tsd_slam ROS wiki page. Ohm_tsd_slam is the SLAM approach of the ", " Rescue ", " from the Technische Hochschule Nuremberg, Germany. ", "The release includes a SLAM package using 2D LIDAR data only as input. Its localization module uses ICP-based registration. The mapping uses a grid map, which cells contain Truncated Signed Distances (tsd), similar to the well known ", " approach. This representation performs dynamic mapping, wherefore temporary objects are removed over time. ", "The repository comes with an example launchfile, slam.launch. Its parameters are set to fit the typical ", " rescue scenario deploying a Hokuyo UTM30LX LIDAR or a sensor with similar parameters. ", "This video shows a demo of the package. It uses public available recorded Lidar data, acquired from the University of Freiburg (", "). ", "The ohm_tsd_slam package is based on our CPU version of the well known ", " approach,  and is available at ", ". ", "The multi-robot SLAM has been subject of a paper itself and can be downloaded at ", ". ", "If you like to install obviously externally it is recommended to use the master branch and follow the installation instructions provided in the ", " repository of ", ". ", "Finally, you can use the slam.launch launchfile to run the SLAM. If you play a bagfile that publishes sensor_msgs::", " on the \"/scan\" topic you will receive a map on topic \"/map\" and the robot's pose on \"/pose\" "], "package_tt": ["1.", "2.", "map", "pose", "map_size", "integer", "cell_size", "double", "x_offset", "double", "y_offset", "double", "yaw_offset", "double", "min_range", "double", "max_range", "double", "low_reflectivity_range", "double", "occ_grid_time_interval", "double", "loop_rate", "double", "pose_topic", "string", "tf_base_frame", "string", "tf_child_frame", "string", "truncation_radius", "double", "map_topic", "string", "get_map_topic", "string", "footprint_width", "double", "footprint_height", "double", "footprint_x_offset", "double", "registration_mode", "int", "dist_filter_max", "double", "dist_filter_min", "double", "icp_iterations", "int", "reg_trs_max", "double", "reg_sin_rot_max", "double", "node_control_topic", "double", "ransac_trials", "int", "ransac_eps_tresh", "double", "ransac_ctrlset_size", "int", "ransac_phi_max", "double"], "package_code": ["S. May, P. Koch, R. Koch, C. Merkl, C. Pfitzner and A. Nuechter.\n", "A Generalized 2D and 3D Multi-Sensor Data Integration Approach based on Signed Distance Functions for Multi-Modal Robotic Mapping.\n", "In Proceedings of the VMV 2014: Vision, Modeling & Visualization, Darmstadt, Germany, 2014.", "P. Koch, S. May, M. Schmidpeter, M. K\u00fchn, J. Martin, C. Pfitzner, C. Merkl, M. Fees, R. Koch and A. N\u00fcchter.\n", "Multi-Robot Localization and Mapping based on Signed Distance Functions.\n", "In Proceedings of the IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC '15), Vila Real, Portugal, April 2015.", "$ #In your catkin workspace\n", "$ cd src\n", "$ git clone https://github.com/autonohm/ohm_tsd_slam\n", "$ cd ohm_tsd_slam\n", "$ git checkout indigo-devel\n", "$ cd ../..", "$ wstool update -t src/ohm_tsd_slam", "$ sudo rosdep init\n", "$ rosdep update", "$ source devel/setup.bash #for example\n", "$ rosdep install ohm_tsd_slam", "$ catkin_make --only-pkg-with-deps ohm_tsd_slam", "$ roslaunch ohm_tsd_slam slam.launch"]},
{"url": "https://wiki.ros.org/segbot_simulator", "package": "segbot_simulator", "package_summary": ["segbot_simulator"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/rtt_visualization_msgs", "package": "rtt_visualization_msgs", "package_summary": ["Provides an rtt typekit for ROS visualization_msgs messages.\n\n    It allows you to use ROS messages transparently in\n    RTT components and applications.\n\n    This package was automatically generated by the\n    create_rtt_msgs generator and should not be manually\n    modified.\n\n    See the http://ros.org/wiki/visualization_msgs documentation\n    for the documentation of the ROS messages in this\n    typekit."]},
{"url": "https://wiki.ros.org/multi_level_map_server", "package": "multi_level_map_server", "package_summary": ["multi_level_map_server"]},
{"url": "https://wiki.ros.org/uav_optimal_coverage", "package": "uav_optimal_coverage", "package_summary": ["A package that performs optimal coverage with a swarm of unmanned aerial vehicles (UAVs). The UAVs optimally divide the area to be covered among each other."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["single_target=true", "uav_optimal_coverage", "id", "integer", "output", "string", "screen", "screen", "log", "param", "uav_optimal_coverage.yaml", "uav_optimal_coverage", "uav_optimal_coverage", "single_target", "true", "uav_coverage/goal", "uav_coverage/result", "target_found", "single_target", "true", "coverage_path/waypoint", "~loop_rate", "real", "~queue_size", "integer", "~single_target", "boolean"], "package_code": ["roslaunch uav_optimal_coverage uav_optimal_coverage.launch"]},
{"url": "https://wiki.ros.org/moveit_controller_multidof", "package": "moveit_controller_multidof", "package_summary": ["A moveit_controller_manager implementation which supports execution\n    of a MultiDOF-trajectory with a virtual joint.\n    Transforms the moveit_msgs::RobotTrajectory into a path navigation action\n    and/or a control_msgs/FollowJointTrajectoryAction\n    to control (1) the virtual joint with the path navigation action (read from\n    moveit_msgs/RobotTrajectory.multi_dof_joint_trajectory), and (2) the\n    joints with a control_msgs/FollowJointTrajectoryAction."]},
{"url": "https://wiki.ros.org/pr2_arm_move_ik", "package": "pr2_arm_move_ik", "package_summary": ["Move the pr2 arm using inverse kinematics"], "package_details": [" ", "\n"], "package_tt": ["pr2_arm_ik_action", "<~arm>_arm_ik/goal", "<~arm>_arm_ik/result", "<~arm>_arm_controller/<~joint_trajectory_action>", "~arm", "string", "~joint_trajectory_action", "string", "~free_angle", "int", "~search_discretization", "double", "~ik_timeout", "double"], "package_code": ["<launch>\n", "  <!-- ik action -->\n", "  <node pkg=\"pr2_arm_move_ik\" type=\"arm_ik\" name=\"r_arm_ik\" output=\"screen\">\n", "    <param name=\"joint_trajectory_action\" value=\"/r_arm_controller/joint_trajectory_generator\" />\n", "    <param name=\"arm\" value=\"r\" />\n", "    <param name=\"free_angle\" value=\"2\" />\n", "    <param name=\"search_discretization\" value=\"0.01\" />\n", "    <param name=\"ik_timeout\" value=\"5.0\" />\n", "  </node>\n", "\n", "  <!-- Trajectory generator -->\n", "  <node pkg=\"joint_trajectory_generator\" type=\"joint_trajectory_generator\" output=\"screen\"\n", "        name=\"joint_trajectory_generator\" ns=\"r_arm_controller\" >\n", "    <param name=\"max_acc\" value=\"2.0\" />\n", "    <param name=\"max_vel\" value=\"2.5\" />\n", "  </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/rosserial_mbed", "package": "rosserial_mbed", "package_summary": ["rosserial for mbed platforms."], "package_details": [" ", "This package contains Mbed-specific extensions required to run ", " on an ", ". It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors into your ROS project using an ", ". The Tutorials of this package will walk you through a setting up your Mbed environment, creating a few example programs and explain where to purchase the additional hardware. "]},
{"url": "https://wiki.ros.org/slam_gmapping", "package": "slam_gmapping", "package_summary": ["slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities."], "package_details": ["\n", "\n", "  ", "\n", "See the ", " package for more details on mapping options. ", "Also, see the ", " "]},
{"url": "https://wiki.ros.org/typelib", "package": "typelib", "package_summary": ["\n      This library offers an introspection mechanism for C/C++ value-types. I.e.\n      it offers a way to represent types, and to manipulate in-memory values\n      that are instances of those types.\n\n      A Ruby binding is included, which gives a fast and transparent\n      modification of C/C++ in-memory types from Ruby, and an associated\n      interface to call C functions from shared libraries.\n  "]},
{"url": "https://wiki.ros.org/urdf2inventor", "package": "urdf2inventor", "package_summary": ["A conversion from URDF 2 Inventor including a simple viewer."]},
{"url": "https://wiki.ros.org/navigation", "package": "navigation", "package_summary": ["A 2D navigation stack that takes in information from odometry, sensor\n        streams, and a goal pose and outputs safe velocity commands that are sent\n        to a mobile base."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Available Translations: ", " ", "The Navigation Stack is fairly simple on a conceptual level. It takes in information from odometry and sensor streams and outputs velocity commands to send to a mobile base. Use of the Navigation Stack on an arbitrary robot, however, is a bit more complicated. As a pre-requisite for navigation stack use, the robot must be running ROS, have a ", " transform tree in place, and publish sensor data using the correct ROS ", ". Also, the Navigation Stack needs to be configured for the shape and dynamics of a robot to perform at a high level. To help with this process, this manual is meant to serve as a guide to typical Navigation Stack set-up and configuration.  ", "The following documentation assumes familiarity with the Robot Operating System. Documentation on ROS can be found here: ", " "], "package_tt": ["sensor_msgs/LaserScan", "sensor_msgs/PointCloud"]},
{"url": "https://wiki.ros.org/mrpt_msgs", "package": "mrpt_msgs", "package_summary": ["ROS messages for MRPT classes and objects"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/industrial_core", "package": "industrial_core", "package_summary": ["ROS-Industrial core stack contains packages and libraries for supporing industrial systems"], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It currently contains core packages that provide nodes and libraries for communication with industrial robot controllers.  It also includes utilities and tools that are useful for industrial robotics and automation applications. ", "See the ", " page for an overview of the available tutorials. "]},
{"url": "https://wiki.ros.org/rosgraph", "package": "rosgraph", "package_summary": ["rosgraph contains the rosgraph command-line tool, which prints\n    information about the ROS Computation Graph. It also provides an\n    internal library that can be used by graphical tools."], "package_details": ["\n", "\n", " is a console version of ", ". It periodically displays information about your current graph in a text format. To use it, simply type: ", "\n", " ", "\n", "For a graphical version of ", ", please see ", ". ", "The ", " package contains the ", " module, which implements a Python library for interacting with the low-level ROS Master API. ", "For other Python libraries for interacting with the ROS graph, see ", ", ", ", ", ", and ", ". ", "There are no plans to update the ", " tool at this time.  The Python API may expand as necessary to provide access to other ROS graph primitives, though those are currently covered by the ", ", ", ", and ", " libraries as well. "], "package_tt": ["rxgraph", "rxgraph", "rosgraph", "rosgraph", "rosgraph", "rosgraph.masterapi", "rosgraph"], "package_code": ["$ rosgraph"]},
{"url": "https://wiki.ros.org/urdf_transform", "package": "urdf_transform", "package_summary": ["Provides a collection of functions which\n      can be applied on a URDF traversed by urdf_traverser"]},
{"url": "https://wiki.ros.org/nao_bringup", "package": "nao_bringup", "package_summary": ["Launch files and scripts needed to bring ROS interfaces for Nao up into a\n      running state."], "package_details": ["\n", "\n", "\n", "Before starting, please make sure you meet all the required dependencies especially the packages ", ", ", " and ", ".  ", "You can either install the official releases via your package manager or directly clone the necessary ros packages from github. ", "Alternatively you can make use of the python SDK, which has to be installed and correctly setup in your PYTHONPATH environment variable. For more information on that, please refer to ", ". "], "package_code": ["$ roslaunch nao_bringup nao_full.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip>", "$ roslaunch nao_bringup nao_full_py.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip> "]},
{"url": "https://wiki.ros.org/rosserial_tivac", "package": "rosserial_tivac", "package_summary": ["rosserial for TivaC Launchpad evaluation boards."], "package_details": ["\n", " ", " ", " ", "\n", "\n", " will communicate either through UART0 or USB0: ", "\n", "See also ", ". ", "This package contains all necessary extensions on ", " to bring two Tiva C Launchpad boards from ", " to ROS. ", "All boards can use both debug USB and device USB to communicate with rosserial. ", "Due to changes in USB library of TivaWare. ", " ", "This package contains the prepares the required libraries for Energia's IDE and also prepares a build configuration for ", " packages based on ", " GNU compiler toolchain and TI's TivaWare libraries. ", "The ", " page of this package will walk you through the steps for setting up your environment, and demonstrate how to develop applications, both for Energia and catkin. ", "The SystemTick interrupt service must be available for ", " to use, so it can keep the execution time. ", "After going through the ", " you should have understood that each project requires a ", " which calls the function ", " to prepare the build files. "], "package_tt": ["catkin", "arm-none-eabi", "rosserial_tivac", "rosserial_tivac", "CMakeLists.txt", "generate_tivac_firmware", "TIVA_WARE_PATH", "TIVA_FLASH_EXECUTABLE", "TARGET_IS_TM4C123_RB1"], "package_code": ["generate_tivac_firmware(\n", "  USB\n", "  STARTUP custom_startup.c\n", "  SRCS buttons.cpp buttons.c\n", "  INCS .\n", "  BOARD tm4c123gxl\n", ")"]},
{"url": "https://wiki.ros.org/industrial_robot_simulator", "package": "industrial_robot_simulator", "package_summary": ["The industrial robot simulator is a stand in for industrial robot driver node(s).  It adheres to the driver specification for industrial robot controllers."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package simulates an industrial robot controller that adheres to the ", " driver specification.  Currently the simulator only supports the minimum ", ".  The purpose of this node is to provide a simulated robot controller for development.  This simulator publishes standard topics that can be fed into ", " to create a realistic visualization of an actual robot cell.  Note that the simulation is at the ROS API level, the node does not accept Simple Message TCP/UDP connections. "], "package_tt": ["joint_path_command", "joint_states", "feedback_states", "controller_joint_names", "str[]", "initial_joint_state", "double[]", "motion_update_rate", "double", "pub_rate", "double"], "package_code": ["roslaunch industrial_robot_simulator robot_interface_simulator.launch "]},
{"url": "https://wiki.ros.org/wheeled_robin_viz", "package": "wheeled_robin_viz", "package_summary": ["Catkin meta-package for wheeled_robin_viz"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "Please refer main ", " page. "]},
{"url": "https://wiki.ros.org/dataspeed_ulc_can", "package": "dataspeed_ulc_can", "package_summary": ["Package to translate ROS messages to and from CAN messages to interact with the Universal Lat/Lon Controller (ULC) firmware"]},
{"url": "https://wiki.ros.org/blort_ros", "package": "blort_ros", "package_summary": ["\n\n    BLORT - The Blocks World Robotic Vision Toolbox ", "\n    ROS interface classes and nodes for the BLORT library.\n\n  "], "package_details": [" ", " ", " ", " ", "\n", " ", "\n", "\n", "\n", "\n", " ", "More information:  [", "] or you can also visit the ", ". "], "package_code": ["sudo apt-get install ros-hydro-perception-blort", "sudo apt-get install ros-hydro-pal-vision-segmentation"]},
{"url": "https://wiki.ros.org/ur10_moveit_config", "package": "ur10_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the ur10 with the MoveIt Motion Planning Framework"], "package_details": ["\n", "\n", "\n", "This package is part of the ", " program. It is the ", "! configuration for the UR10 arm, generated automatically by the ", " Setup Assistant. ", "Install the package from package management, and run the MoveIt! planning demo: ", "This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR10, see the ", " package. ", "See also the relevant sections in the ", " on Github. "], "package_tt": ["moveit_simple_controller_manager"], "package_code": ["$ sudo apt-get install ros-$ROS_DISTRO-ur10-moveit-config\n", "\n", "$ roslaunch ur10_moveit_config demo.launch"]},
{"url": "https://wiki.ros.org/toposens_markers", "package": "toposens_markers", "package_summary": ["Rviz integration for TS sensor data."], "package_details": ["\n", "\n", "\n"], "package_tt": ["ts_scans", "ts_markers", "~frame_id", "std_msgs/String", "~lifetime", "double", "~scale", "double"]},
{"url": "https://wiki.ros.org/visp_auto_tracker", "package": "visp_auto_tracker", "package_summary": ["Online automated pattern-based object tracker relying on visual servoing.\n\n    visp_auto_tracker wraps model-based trackers provided by ViSP visual\n    servoing library into a ROS package. The tracked object should have a\n    QRcode of Flash code pattern. Based on the pattern, the object is\n    automaticaly detected. The detection allows then to initialise the\n    model-based trackers. When lost of tracking achieves a new detection\n    is performed that will be used to re-initialize the tracker.\n\n    This computer vision algorithm computes the pose (i.e. position and\n    orientation) of an object in an image. It is fast enough to allow\n    object online tracking using a camera."], "package_details": ["\n", "\n", "\n", "\n", " ", " ", "\n", " is part of ", " stack.  ", "\n", "\n", "\n", "\n", " centralises most of its parameters inside a configuration file following the ", " default format. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "This package wraps an automated pattern barcode based tracker using ", " library. The tracker estimates the pattern position and orientation with respect to the camera. It requires the pattern 3d model and a configuration file. ", "The package is composed of one node called ", ".  This node tries to track the object as fast as possible. The viewer coming with ", " package can be used to monitor the tracking result. ", "Currently the ", " package requires calibration information from a camera_info topic. To this end ", " package can be used. ", "This is an example of a valid QR-code pattern that can be downloaded ", ". ", "This is an example of a valid flash-code pattern that can be downloaded ", ". ", "You can run ", " on a pre-recorded bag file that comes with the package, or on a live video from a camera. ", "To run ", " on a pre-recorded image sequence, just run: ", "The pattern used in this example can be downloaded ", ". ", "You have a ready-to-use roslaunch file in ", ". This works with a firewire (1394) camera. If you have an usb camera (like a webcam) you can use ", " launch file. ", "When set (", ") this parameter activates the tracking lost detection and recovery using ", ", ", " and ", " point coordinates. ", "When you track a model, you probably want a visual feedback. You can get one by connecting rviz to the outputed ", " topic. ", " does not have a dedicated viewer. It can use the viewer provided with ", " package, specifically ", " node. ", "Without connecting another node, you can also open a debug graphical output directly from the ", " node by setting the ", " parameter. ", "The following figure shows the debug output (left) next to the external ", "/viewer (right) in the case of the hybrid model-based tracker with QR-code initialisation: ", "Use GitHub to ", ". "], "package_tt": ["visp_auto_tracker", "launch/tracklive_firewire.launch", "launch/tracklive_usb.launch", "detector-type=\u00a0zbar", "detector-type=\u00a0dmtx", "tracker-type=\u00a01", "flashcode-coordinates", "inner-coordinates", "outer-coordinates", "/object_position", "visp_tracker/visp_tracker_viewer", "visp_auto_tracker", "debug_display", "image_raw", "camera_info", "object_position", "object_position_covariance", "status", "moving_edge_sites", "klt_points_positions", "model_path", "string", "model_name", "string", "debug_display", "boolean"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-visp-auto-tracker", "sudo apt-get install ros-$ROS_DISTRO-vision-visp", "roslaunch launch/tutorial.launch", "roslaunch launch/tracklive_firewire.launch", "#set the detector type: \"zbar\" to detect QR code, \"dmtx\" to detect flashcode\n", "detector-type= zbar\n", "#enable recovery mode when the tracker fails\n", "ad-hoc-recovery= 1\n", "\n", "#point 1\n", "flashcode-coordinates= -0.024\n", "flashcode-coordinates= -0.024\n", "flashcode-coordinates= 0.000\n", "#point 2\n", "flashcode-coordinates= 0.024\n", "flashcode-coordinates= -0.024\n", "flashcode-coordinates= 0.000\n", "#point 3\n", "flashcode-coordinates= 0.024\n", "flashcode-coordinates= 0.024\n", "flashcode-coordinates= 0.000\n", "#point 4\n", "flashcode-coordinates= -0.024\n", "flashcode-coordinates= 0.024\n", "flashcode-coordinates= 0.000\n", "\n", "#point 1\n", "inner-coordinates= -0.038\n", "inner-coordinates= -0.038\n", "inner-coordinates= 0.000\n", "#point 2\n", "inner-coordinates= 0.038\n", "inner-coordinates= -0.038\n", "inner-coordinates= 0.000\n", "#point 3\n", "inner-coordinates= 0.038\n", "inner-coordinates= 0.038\n", "inner-coordinates= 0.000\n", "#point 4\n", "inner-coordinates= -0.038\n", "inner-coordinates= 0.038\n", "inner-coordinates= 0.000\n", "\n", "#point 1\n", "outer-coordinates= -0.0765\n", "outer-coordinates= -0.0765\n", "outer-coordinates= 0.000\n", "#point 2\n", "outer-coordinates= 0.0765\n", "outer-coordinates= -0.0765\n", "outer-coordinates= 0.000\n", "#point 3\n", "outer-coordinates= 0.0765\n", "outer-coordinates= 0.0765\n", "outer-coordinates= 0.000\n", "#point 4\n", "outer-coordinates= -0.0765\n", "outer-coordinates= 0.0765\n", "outer-coordinates= 0.000"]},
{"url": "https://wiki.ros.org/maggie_motor_controller_msgs", "package": "maggie_motor_controller_msgs", "package_summary": ["motor_controller messages and services"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"maggie_motor_controller_msgs\" in rosdoc: /home/rosbot/docs/api/maggie_motor_controller_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/stdr_robot", "package": "stdr_robot", "package_summary": ["Provides robot, sensor implementation, using nodelets for stdr_server to load them."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", " (", ") ", "\n", " (", ") ", " (", ") ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package implements a simulated robot, all simulated sensors and its simulated motion controller. Till now the following sensors are implemented: ", "The robot class is available using the ", " interface, named ", ". To load a new robot a ", " has to be running. New robots/nodelets can be loaded only from ", ", using either ", " or command-line tools described below. ", "A parser for YAML and XML files is also provided, to load or save robots, sensors etc. More details on how to use YAML and XML files with stdr_simulator ", ".  ", "A robot provides tf transforms for the pose of itself and its sensors. All transforms are relative to ", " frame. For more details about map tf frames see ", ". An example with one spawned robot follows (using ", "): ", "The ", " for each sensor is defined on loading a robot from GUI or when using a YAML/XML file to describe a sensor. Each sensor ", " has to have a unique name per robot. To avoid naming collisions with other robots it is also (automatically) prefixed with robot's name. Example: ", ". ", "Each robot provides a tf transform with its current pose. The ", " is automatically assigned and has the format ", ". Example: ", ". ", "All topic names are prefixed with robot name. Example ", ". ", "All services are prefixed with the name ", ". This is the name of the nodelet manager and should ", " change. ", "With the ", " command-line tool you can add, delete and move a robot directly from the terminal. The following sections describe the available commands. ", "For tutorials see ", ". "], "package_tt": ["stdr_robot", "nodelet", "stdr_robot/Robot", "map_static", "rqt_tf_tree", "frame_id", "frame_id", "robot0_laser_1", "frame_id", "robot<ID>", "robot2", "robot1/cmd_vel", "cmd_vel", "<laser_sensor_frame_id>", "robot0/laser_back", "<sonar_sensor_frame_id>", "robot0/sonar_2", "robot_manager", "load_nodelet", "unload_nodelet", "robot_handler", "add\u00a0<description.yaml>\u00a0<x>\u00a0<y>\u00a0<theta>", "robot_handler", "delete\u00a0<robot_name>", "replace\u00a0<robot_name>\u00a0<new_x>\u00a0<new_y>\u00a0<new_theta>", "robot_handler"], "package_code": ["$ rosrun stdr_robot robot_handler add resources/robots/khepera2.yaml 1.2 2 1.57", "$ rosrun stdr_robot robot_handler delete /robot2", "$ rosrun stdr_robot robot_handler replace /robot1 1.2 3 3.14"]},
{"url": "https://wiki.ros.org/sdf_tracker", "package": "sdf_tracker", "package_summary": ["\n\n     sdf_tracker\n\n  "], "package_details": ["\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "This package provides an implementation of the truncated Signed Distance Function tracking algorithm, proposed ", ".  ", "The initial starting point of the camera is at the center of the specified volume, looking along the z-axis. To change the initial camera pose, relative to the volume set the ", " parameter of the SDF_Parameter class and pass this to the constructor when initializing your SDFTracker, e.g.,  ", "In the interactive mode, pressing ", " or ", " sets a flag to notify the node that it's time to shut down. Terminating the program with ctrl-C works, but will not output triangles.  "], "package_code": ["export ROS_PACKAGE_PATH=/your_path/oru-ros-pkg/:$ROS_PACKAGE_PATH", "roscd sdf_tracker\n", "rosmake", "roslaunch openni_launch openni.launch &\n", "rosrun sdf_tracker sdf_tracker_node _param1:=val1 _param2:=val2 ...etc", "rosrun sdf_tracker sdf_tracker_node _c_name:=\"camera2\" _depth_registered:=\"true\" _OutputTriangles:=\"true\" _CellSize:=0.02 _GridSizeX:=300", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/socketcan_interface", "package": "socketcan_interface", "package_summary": ["Generic CAN interface description with helpers for filtering and driver implementation. Further a socketcan implementation based on boost::asio is included."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This packages provides a generic CAN interface class and a ", "-based driver implementation. ", "The listeners are based on ", " ", " (since melodic) and use RAII-pointers. ", "The SocketCAN driver interface is based on ", " and provides concurrent access to SocketCAN interfaces. It is the default CAN implementation used throughout ros_canopen and requires Linux kerner 2.6.25 or newer. ", "The SocketCAN driver is exposed as \"can::SocketCANInterface\" with base class can::DriverInterface via ", ". In addition the plugin library is announced to ", ". ", "Further options are availabe, please consult ", ". For automatic set-up, the network can be configured in ", ", e.g.: "], "package_code": ["sudo modprobe peak_usb # kernel driver, since 3.11", "sudo modprobe peak_pci # kernel driver", "sudo modprobe pcan # PEAK vendor driver", "sudo modprobe esd_usb2 # kernel driver", "sudo ip link set can0 up type can bitrate 500000 # adjust bitrate as needed", "allow-hotplug can0\n", "iface can0 can static\n", "    bitrate 500000\n", "#    up ip link set $IFACE txqueuelen 20 # uncomment if more than 4 nodes are used", "rosrun socketcan_interface socketcan_dump can0", "ip -details -statistics link show can0", "sudo apt-get install can-utils"]},
{"url": "https://wiki.ros.org/nextage_moveit_config", "package": "nextage_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the NextageOpen with the MoveIt Motion Planning Framework."]},
{"url": "https://wiki.ros.org/rviz_fps_plugin", "package": "rviz_fps_plugin", "package_summary": ["The rviz_fps_plugin package contains an additional ViewController and a Tool Plugin to navigate RViz like an FPS-Shooter.\n\n    To enable the tool press 'q' and enable the 'FPSMotion' ViewController. Use the 'wasd' keys for walking.\n    By pressing 'f' one can switch between walk or fly mode. By pressing 'r' you can reset the view controller."], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n "]},
{"url": "https://wiki.ros.org/nextage_calibration", "package": "nextage_calibration", "package_summary": ["This package provides .launch files and other tools for\n  calibrating the head-mount cameras to the NEXTAGE Open robot.\n  As of version 0.7.15/March 2017, only Kinect/Xtion is capable (i.e. Ueye\n  cameras, the ones the robot comes with on this head by default, are not yet\n  handled)."], "package_details": ["Some info on ", " about this package is available. "]},
{"url": "https://wiki.ros.org/roshlaunch", "package": "roshlaunch", "package_summary": ["roshlaunch is a temporary package for redesigning roslaunch to have better programmatic APIs for libraries like rosh."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/svenzva_drivers", "package": "svenzva_drivers", "package_summary": ["The svenza_drivers package"], "package_details": ["\n", " ", "\n", " ", "\n"], "package_tt": ["/joint_states", "tf", "moveit", "/revel/motor_state", "/svenzva_joint_action/", "/revel/follow_joint_trajectory", "/revel/gripper_action/", "/home_arm_service", "/revel/SetTorqueEnable", "/revel/gripper/insert_finger", "~data_frequency", "int", "~mode", "str", "user_defined", "svenzva_bringup.launch", "user_defined", "velocity", "gravity", "gravity", "/joint_states", "tf", "moveit", "/revel/model_efforts"]},
{"url": "https://wiki.ros.org/ros_tutorials", "package": "ros_tutorials", "package_summary": ["ros_tutorials contains packages that demonstrate various features of ROS,\n    as well as support packages which help demonstrate those features."], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/moveit_ikfast", "package": "moveit_ikfast", "package_summary": ["Generates a IKFast kinematics plugin for MoveIt using OpenRave generated cpp files."], "package_details": ["/!\\", ":From ROS ", " onward, this package is renamed as ", ". "]},
{"url": "https://wiki.ros.org/rail_pick_and_place_msgs", "package": "rail_pick_and_place_msgs", "package_summary": ["Messages and Services for RAIL Pick and Place"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"rail_pick_and_place_msgs\" in rosdoc: /home/rosbot/docs/api/rail_pick_and_place_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/wge100_camera_firmware", "package": "wge100_camera_firmware", "package_summary": ["Source for the WGE100 Ethernet camera: Verilog source for the\n    FPGA, Forth source for the camera firmware.  Intended for camera\n    developers.  Note that a built binary from this package is checked\n    in under wge100_camera/firmware_images/"], "package_details": ["\n", "\n", "The Willow Garage 100 Mbps Ethernet (WGE100) camera is a 752x480 Ethernet camera developed for the PR2 robot.  This package contains the source code for the camera hardware and firmware.  If you want to develop or change the camera firmware, everything you need is in this package.  If you only want to use the WGE100 cameras, see package ", ". ", "The Verilog source for the camera firmware is under ", ", with the main Makefile in ", ".  You will need Xilinx ISE Webpack 11.1 or 11.3 to build the FPGA .bit file. ", "The Forth source code for the ", " CPU is under ", ", see ", " for build details.  You do not need the Xilinx tools to update the camera firmware. "], "package_tt": ["src/hardware", "src/hardware/synth/Makefile", "src/firmware", "readme.txt"]},
{"url": "https://wiki.ros.org/perception_blort", "package": "perception_blort", "package_summary": ["perception_blort"], "package_details": ["\n", " Currently, BLORT makes use of GLSL (OpenGL Shading Language) and requires GPU in order to run the tracker node. ", " ", "\n", "  "]},
{"url": "https://wiki.ros.org/rail_face_detector", "package": "rail_face_detector", "package_summary": ["This package provides face detection."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This detector uses ", " to perform face detection. It publishes faces found in images from a subscribed image topic. The face detector itself can be found here: ", ". ", "This package contains a single ROS node - ", " - which serves as an interface between a ROS system and the trained face recognition network. ", "Type: ", " ", "Type: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " "], "package_tt": ["top_left_x", "top_left_y", "bot_right_x", "bot_right_y", "nose_x", "nose_y", "left_eye_x", "left_eye_y", "right_eye_x", "right_eye_y", "left_mouth_x", "left_mouth_y", "right_mouth_x", "right_mouth_y", "face_detector_node", "string", "\"/kinect/qhd/image_color_rect\"", "bool", "false", "bool", "true", "bool", "false"]},
{"url": "https://wiki.ros.org/rail_object_detection", "package": "rail_object_detection", "package_summary": ["Object Detection methods used in the RAIL Lab"]},
{"url": "https://wiki.ros.org/vigir_pluginlib", "package": "vigir_pluginlib", "package_summary": ["The vigir_pluginlib package"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", "\n", "\n", ": Ensure all above steps have been done right. Another very weird issue may arise if you try to load plugins from a package A which have been depended from another package B which exports plugins too. NEVER DO THAT!!! As the library from A may be linked into B, while loading library B the ", " may invoke all PLUGINLIB_EXPORT_CLASS macros from A too while being under the namespace of package B. This confuses the class_loaders as all plugins from A seems now to be part of package B. ", "\n", "Use GitHub to ", ". [", "]", "\n ", "The ", " is based on the exisiting ", " system. It extends the basic plugin system by a convenient plugin management tool which enables to gather specific plugins based on their provided functionality from a heterogeneous plugin database. ", "Hereby the basic infrastructure remains identically to the original ", " system as the ", " is built on top. Using the ", " allows analogously to load classes from a runtime library (i.e. shared object, dynamically linked library) without the application having any prior awareness of the library or the header file containing the class definition (for details see the ", " documentation). ", "The ", " uses the C++ RTTI mechanism to determine the functionality of each instantiated plugin based on implemented parent classes. This information helps the plugin manager to resolve any kind of plugin request done by the application during runtime and allows to manage a heterogeneous plugin database. For clarification, heterogeneous denotes indeed that you can load plugins of different type in one single manager and therefore have convenient centralized access to all your plugins no matter which interface they actually implement. If you need a plugin implementing a specific interface, then the plugin manager tries best effort to deliver them. Polymorphic plugins are indeed allowed, thus a single plugin may implement the interfaces of multiple interface plugins and still will be retrieved correctly. ", "As an example use case for such kind of plugin system, please take a look at the ", " stack. ", "The ", " class provides the low level basic functionality needed by the plugin manager. Therefore each new interface plugin must be derived from this class. ", "See ", ". ", "See ", ". ", "Please take also a look at the ", ". ", "A Plugin Aggregator is a collector for a set of plugins implementing a specified interface and simplifies handling of such sets. It obtains automatically all plugins from the plugin manager and provides the option to update parameters of those plugins. The plain ", " class is ready for use, but may be extended as demonstrated ", " to perform accumulative operations using the plugins. ", "The ", " comes with a ", " widget providing full access to all running plugin manager instance. The widget allows to  monitor the current state of all plugins and even to add and remove plugins during runtime. In ", " this widget is located in the ", " menu. Alternatively you can launch the standalone version: ", "The ", " uses ", " under the hood where many magic is happening. This can cause many unforeseen issues. "], "package_tt": ["vigir_pluginlib::Plugin", "name", "string", "type_class_package", "string", "type_class", "string", "base_class_package", "string", "base_class", "string", "plugins->vigir_pluginlib", "MultiLibraryClassLoader"], "package_code": ["roslaunch vigir_pluginlib_manager plugin_mananger_rqt.launch", "[PluginManager] Plugin (thor_mang_step_plan_msg_plugin) of type_class 'thor_mang_footstep_planning::ThorMangStepPlanMsgPlugin' failed to load for some reason. Error: MultiLibraryClassLoader: Could not create object of class type thor_mang_footstep_planning::ThorMangStepPlanMsgPlugin as no factory exists for it. Make sure that the library exists and was explicitly loaded through MultiLibraryClassLoader::loadLibrary()"]},
{"url": "https://wiki.ros.org/asr_fake_object_recognition", "package": "asr_fake_object_recognition", "package_summary": ["This package provides a 'perception algorithm'-independent simulation of 6-D object localization for 3D object search by a mobile robot: Based on the poses of the searched objects with respect to the current viewing frustum(s) of the robot, the detectability of the objects is estimated."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package offers two sets of parameters you can adjust, the static ones which you can set by adjusting the params.yaml file located in the param-directory of the package, and the dynamic ones which you can either set by adjusting the launch-file or during runtime by using ", ". "], "package_code": ["<Objects>\n", "    <Object type=\"Cup\" id=\"011021054100\" mesh=\"package://asr_object_database/rsc/databases/segmentable_objects/Cup/object.dae\" angles=\"quaternion\">-1.2902,0.729374,0.755761,0.721985,-0.665815,-0.13442,0.131754 </Object>\n", "    <Object type=\"CoffeeBox\" id=\"0\" mesh=\"package://asr_object_database/rsc/databases/textured_objects/CoffeeBox/CoffeeBox.dae\" angles=\"euler\">1.5,-0.5,1.5,90,0,0 </Object>\n", "</Objects>", "roslaunch fake_object_recognition fake_object_recognition.launch"]},
{"url": "https://wiki.ros.org/mqtt_bridge", "package": "mqtt_bridge", "package_summary": ["The mqtt_bridge package"], "package_details": ["\n", " provides a functionality to bridge between ROS and MQTT in bidirectional. ", " uses ROS message as its protocol. Messages from ROS are serialized by json (or messagepack) for MQTT, and messages from MQTT are deserialized for ROS topic. So MQTT messages should be ROS message compatible. (We use ", " for message conversion.) ", "\n", "\n"], "package_tt": ["mqtt_bridge", "mqtt_bridge", "rosbridge_library.internal.message_conversion", "mqtt_bridge_node"]},
{"url": "https://wiki.ros.org/map_merger", "package": "map_merger", "package_summary": ["Map merger is a package to merge several maps on the fly to one global map, if possible"], "package_details": ["\n", "  ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "The map_merger node uses the ", " to distribute local maps, i.e., maps created by each robot, to other robots which attempt to merge other robots' local maps into their own to create a global map. The following picture shows a global map created by merging local maps of two robots.  ", "Changes in local maps are detected by the map_merger node which then automatically distributes the changes in the network using the ", ". Upon reception of map updates by other robots, the map_merger node integrates the update using an existing transformation. If no transformation is available, the remote map update is stored for later processing. Upon availability of a transformation, the remote map is merged into a robot's own map. The map_merger node regularly publishes the global map on a distinct topic (see below) to which other nodes are required to subscribe to in order to receive the global map. ", "You may obtain the paper from ", " or search in  ", ". "], "package_tt": ["map", "odom", "control", "map_other", "position_other_robots", "adhoc_communication/new_robot", "global_map", "all_positions", "map_merger/logOutput", "map_merger/transformPoint", "adhoc_communication/get_neighbors", "adhoc_communication/send_control", "adhoc_communication/send_map_update", "adhoc_communication/send_point", "adhoc_communication/send_position", "adhoc_communication/send_map", "~has_local_map", "bool", "exchange_position", "bool", "max_size_map_part", "int", "seconds_pub_timer", "int", "seconds_send_timer", "int", "seconds_recompute_transform", "int", "max_rotation_robots", "double", "local_map_topic", "string", "local_map_metadata_topic", "string", "local_map_frame_id", "string", "map_topic_over_network", "string", "position_local_robot_topic", "string", "position_other_robots_topic", "string", "control_topic", "string", "robot_prefix", "string", "log_path", "string"], "package_code": ["@InProceedings{Andre2014,\n", "  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},\n", "  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},\n", "  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},\n", "  Year                     = {2014},\n", "  Month                    = dec,\n", "}"]},
{"url": "https://wiki.ros.org/rail_manipulation_msgs", "package": "rail_manipulation_msgs", "package_summary": ["Common Manipulation Messages and Services Used in RAIL Manipulation Packages"]},
{"url": "https://wiki.ros.org/rosjava_build_tools", "package": "rosjava_build_tools", "package_summary": ["Simple tools and catkin modules for rosjava development."], "package_tt": ["package.xml", "CMakeLists.txt"], "package_code": ["> sudo apt-get install ros-hydro-rosjava-build-tools ros-hydro-rosjava-bootstrap", "cmake_minimum_required(VERSION 2.8.3)\n", "project(rosjava_core)\n", "find_package(catkin REQUIRED rosjava_build_tools)\n", "# replace argument with another gradle target of your choice\n", "catkin_rosjava_setup(publishMavenJavaPublicationToMavenRepository)\n", "catkin_package()", "cmake_minimum_required(VERSION 2.8.3)\n", "project(android_extras)\n", "find_package(catkin REQUIRED rosjava_build_tools)\n", "catkin_android_setup(assembleRelease uploadArchives)\n", "catkin_package()", "> cd build\n", "> make clean-gradle"]},
{"url": "https://wiki.ros.org/myahrs_driver", "package": "myahrs_driver", "package_summary": ["myahrs_driver is a driver package for the WITHROBOT's myAHRS+. The myAHRS+ is a low cost high performance AHRS(Attitude Heading Reference System) with USB/UART/I2C interface. The myAHRS+ board contains a 3-axis 16-bit gyroscope, a 3-axis 16-bit accelerometer and a 3-axis 13-bit magnetometer. The driver should also work with USB port."], "package_details": ["\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "This is a driver package for the WITHROBOT's ", " from ", " and ", " . The myAHRS+ is a low cost high performance AHRS(Attitude Heading Reference System) with USB/UART/I2C interface. The myAHRS+ board contains a 3-axis 16-bit gyroscope, a 3-axis 16-bit accelerometer and a 3-axis 13-bit magnetometer. The driver should also work with USB port. ", "The myAHRS+ board used NED type. The myahrs_driver contained in this package converts to the frame conventions of ROS (use the east north up (ENU) convention and right hand rule) before publishing the msgs. The driver use the coordinate frame below. Please see ", " for more information. ", "The myAHRS+ protocol can be found ", ". The Forum for myAHRS+ user can be found ", ". "], "package_tt": ["imu/data_raw", "imu/data", "imu/mag", "imu/temperature", "~port", "string", "~baud_rate", "int", "~frame_id", "string", "~parent_frame_id_", "string", "~linear_acceleration_stddev", "double", "~angular_velocity_stddev", "double", "~magnetic_field_stddev", "double", "~orientation_stddev", "double"], "package_code": ["sudo apt-get install ros-indigo-myahrs-driver", "cd ~/catkin_ws/src\n", "git clone https://github.com/robotpilot/myahrs_driver.git\n", "cd ~/catkin_ws && catkin_make", "rosrun myahrs_driver myahrs_driver _port:=/dev/ttyACM0", "roslaunch myahrs_driver myahrs_driver.launch"]},
{"url": "https://wiki.ros.org/ur_kin_py", "package": "ur_kin_py", "package_summary": ["Python wrappers for ur_kinematics"], "package_details": ["\n"], "package_code": ["from ur_kin_py.kin import Kinematics\n", "kin = Kinematics('ur5') # or ur10\n", "print kin.forward([0.1]*6)"]},
{"url": "https://wiki.ros.org/rail_segmentation", "package": "rail_segmentation", "package_summary": ["Segmentation Functionality from the RAIL Lab"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package provides tabletop segmentation functionality given a point cloud.  It also allows for segmentation within a robot's coordinate frame, so that objects stored on a robot's platform can be segmented. ", "To install the ", " package, you can install from source with the following commands: ", "Segmentation zones can be defined in yaml config files, an example of which can be found in the config directory.  The ", " file defines a segmentation zone that will segment objects on horizontal surfaces anywhere above the level of the floor. ", "Each resulting segmented object is represented by a ", " ", " message, with the following data calculated and filled in: ", "The ", " package can be launched by running the rail_segmentation node: "], "package_tt": ["rail_segmentation", "point_cloud_topic", "~/segmented_objects", "point_cloud_topic", "~point_cloud_topic", "rail_segmentation", "<~/point_cloud_topic\u00a0parameter>", "~/segmented_objects", "~/segmented_table", "~/markers", "~/table_marker", "~/debug_pc", "~/debug_img", "~/segment", "~/segment_objects", "~/segment_objects_from_point_cloud", "point_cloud_topic", "~/clear", "~/remove_object", "~/calculate_features", "~/debug", "bool", "~/point_cloud_topic", "string", "~/zones_config", "string", "~/min_cluster_size", "int", "~/max_cluster_size", "int", "~/cluster_tolerance", "double", "~/use_color", "bool", "~/crop_first", "bool", "~/label_markers", "bool", "~/markers", "~/segmented_objects", "rail_segmentation", "zones.yaml", "rail_segmentation"], "package_code": ["\n", "\n", "\n", "\n", "\n", "rosrun rail_segmentation rail_segmentation"]},
{"url": "https://wiki.ros.org/uav_local_coverage", "package": "uav_local_coverage", "package_summary": ["A package that performs local coverage with an unmanned aerial vehicle (UAV)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["single_target=true", "uav_local_coverage", "id", "integer", "output", "string", "screen", "screen", "log", "param", "uav_local_coverage.yaml", "uav_local_coverage", "uav_local_coverage", "single_target", "true", "uav_local_coverage/goal", "uav_local_coverage/result", "target_found", "single_target", "true", "~loop_rate", "real", "~queue_size", "integer", "~single_target", "boolean", "~fov_hor", "real", "~fov_ver", "real", "~local_steps", "integer"], "package_code": ["roslaunch uav_local_coverage uav_local_coverage.launch"]},
{"url": "https://wiki.ros.org/carrot_planner", "package": "carrot_planner", "package_summary": ["This planner attempts to find a legal place to put a carrot for the robot to follow. It does this by moving back along the vector between the robot and the goal point."], "package_details": ["\n", " ", "\n", "\n", "\n", " (", ", default: Resolution of the associated costmap) ", "\n", "The ", " is a simple global planner that adheres to the ", " interface found in the ", " package and can be used as a global planner ", " for the ", " node. The planner takes a goal point from an external user, checks if the user-specified goal is in an obstacle, and if it is, it walks back along the vector between the user-specified goal and the robot until a goal point that is not in an obstacle is found. It then passes this goal point on as a plan to a local planner or controller. In this way, the carrot planner allows the robot to get as close to a user-specified goal point as possible. ", "The ", " object exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "The C++ ", " class adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". "], "package_tt": ["carrot_planner::CarrotPlanner", "nav_core::BaseGlobalPlanner", "carrot_planner::CarrotPlanner", "nav_core::BaseGlobalPlanner", "carrot_planner::CarrotPlanner", "~<name>/step_size", "double", "~<name>/min_dist_from_robot", "double", "carrot_planner::CarrotPlanner", "nav_core::BaseGlobalPlanner"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/shadow_robot_ethercat", "package": "shadow_robot_ethercat", "package_summary": ["\n    This stack contains the drivers and the controllers for Shadow Robot's EtherCAT Hand.\n  "], "package_details": ["Our documentation can now be found on ", ". "]},
{"url": "https://wiki.ros.org/rwt_ros", "package": "rwt_ros", "package_summary": ["The rwt_ros package"]},
{"url": "https://wiki.ros.org/spur_description", "package": "spur_description", "package_summary": ["A package for storing 3D model of SPUR omni-directional mobile manipulator robot made at Tamagawa University."]},
{"url": "https://wiki.ros.org/pr2_props", "package": "pr2_props", "package_summary": ["pr2_props is a package designed to be the first step towards replacing your real (or imaginary) friends with a robot. Robot gives you mad props yo."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "The goal of pr2_props, aside from just generally being awesome and making you feel good, is to demonstrate the PR2's ability to do dynamic human interaction. It has been designed to use low-latency real-time controller packages like ", " and ", " so that PR2 is capable of quickly and sensitively responding to a human slapping the robot's hand. ", "Currently ", " supports 3 main behaviors: ", "If you have not previously built the real-time controller libraries associated with the ", " package dependency it is important you build pr2_props prior to launching the robot. ", "In the above commands the values inside () are optional. The robot is naturally right-handed if no hand is specified. ", " and ", " have the same effect.  "], "package_tt": ["explode", "explosion"], "package_code": ["sudo apt-get install ros-<version>-pr2-props-stack ", "svn co https://mediabox.grasp.upenn.edu/svn/penn-ros-pkgs/pr2_props_stack/trunk/pr2_props ~/ros/pr2_props", "rosmake pr2_props", "roslaunch pr2_props pr2_props.launch", "for continuous repeating of different props:\n", "rosrun  pr2_props run_all_props.sh \n", "or individually one-by-one:\n", "rosrun pr2_props high_five (left/right/double)\n", "rosrun pr2_props low_five (left/right)\n", "rosrun pr2_props pound (left/right/double) (explode/explosion)\n", "rosrun pr2_props repeat_high_five\n", "rosrun pr2_props hug"]},
{"url": "https://wiki.ros.org/ur_gazebo", "package": "ur_gazebo", "package_summary": ["Gazebo wrapper for the Universal UR5/10 robot arms."], "package_details": ["\n", "\n", " ", "\n", " ", "This package is part of the ", " program. ", "See also the sections ", " and ", " in the ", " on Github. "], "package_tt": ["moveit_simple_controller_manager"], "package_code": ["$ sudo apt-get install \\\n", "  ros-$ROS_DISTRO-ur-gazebo \\\n", "  ros-$ROS_DISTRO-ur5-moveit-config \\\n", "  ros-$ROS_DISTRO-ur-kinematics", "$ roslaunch ur_gazebo ur5.launch", "$ roslaunch ur5_moveit_config ur5_moveit_planning_execution.launch sim:=true", "$ roslaunch ur5_moveit_config moveit_rviz.launch config:=true"]},
{"url": "https://wiki.ros.org/turtlebot3_automatic_parking_vision", "package": "turtlebot3_automatic_parking_vision", "package_summary": ["Package for TurtleBot3 automatic_parking which uses ar code. This example needs a printed ar code and a TurtleBot3."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["ar_pose_marker", "cmd_vel"]},
{"url": "https://wiki.ros.org/industrial_extrinsic_cal", "package": "industrial_extrinsic_cal", "package_summary": ["The industrial_extrinsic_cal package", ": This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status ", "."], "package_details": ["\n", "\n", "\n", "\n", "The ", " package provides a generic tool for calibrating sensors to a known reference frame.  It is relevant to anyone using a system in which the relative position(extrinsics) of multiple pieces of equipment must be determined. Common equipment examples include positioning systems(i.e. robots, cartesian gantries), measurement/sensor systems (i.e. camera(s), laser scanner/trackers, radio) and fixturing(accurately produced parts for referencing objects of interest). ", "The industrial extrinsic calibration package depends on the google ", ".  The steps below walk through a minimal installation of Ceres on Ubuntu 14.04 as required for this package, more detailed instructions or different Ubuntu versions can be found ", ". ", " These instructions download and install dependencies from your home directory.  Once installed, these tarballs and directories can be deleted. ", "Detailed design info can be found in this ", " presented at ROSCon 2014. "], "package_tt": ["industrial_extrinsic_cal", "ceres", "industrial_extrinisc_cal"], "package_code": ["cd\n", "wget https://github.com/gflags/gflags/archive/v2.1.2.zip\n", "unzip v2.1.2.zip && rm v2.1.2.zip\n", "cd gflags-2.1.2 && mkdir build && cd build\n", "cmake .. -DBUILD_SHARED_LIBS=ON\n", "make\n", "sudo make install", "cd\n", "wget https://github.com/google/glog/archive/v0.3.4.zip\n", "unzip v0.3.4.zip && rm v0.3.4.zip\n", "cd glog-0.3.4/\n", "./configure --with-gflags=/usr/local/\n", "make\n", "sudo make install", "cd\n", "wget https://github.com/ceres-solver/ceres-solver/archive/1.11.0.zip\n", "unzip 1.11.0.zip && rm 1.11.0.zip\n", "cd ceres-solver-1.11.0\n", "mkdir build && cd build\n", "cmake ..\n", "make\n", "sudo make install"]},
{"url": "https://wiki.ros.org/turtlebot3_autorace_control", "package": "turtlebot3_autorace_control", "package_summary": ["TurtleBot3 AutoRace ROS package that controls TurtleBot3 Auto"], "package_details": [" ", "\n", "\n", "\n", "\n"], "package_tt": ["control/lane", "control/max_vel", "cmd_vel", "odom", "control/parking_start", "control/cmd_vel", "control/parking_finished"]},
{"url": "https://wiki.ros.org/explore_lite", "package": "explore_lite", "package_summary": ["Lightweight frontier-based exploration."], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " ", "\n", " uses ", " for navigation. You need to run properly configured ", " node. ", " ", " subscribes to a ", " and ", " messages to construct a map where it looks for frontiers. You can either use costmap published by ", " (ie. ", ") or you can use map constructed by mapping algorithm (SLAM). ", "\n", "\n", "\n", "\n", "This package provides greedy frontier-based exploration. When node is running, robot will greedily explore its environment until no frontiers could be found. Movement commands will be send to ", ". ", "Unlike similar packages, ", " does not create its own costmap, which makes it easier to configure and more efficient (lighter on resources). Node simply subscribes to ", " messages. Commands for robot movement are send to ", " node. ", "Depending on your environment you may achieve better results with either SLAM map or costmap published by ", ". Advantage of ", " costmap is the inflation which helps to deal with some very small unexplorable frontiers. When you are using a raw map produced by SLAM you should set the ", " parameter to some reasonable number to deal with the small frontiers. For details on both setups check the ", " and ", " launch files. ", "Before starting experimenting with ", " you need to have working ", " for navigation. You should be able to navigate with ", " manually through ", ". Please refer to ", " for setting up ", " and the rest of the navigation stack with your robot. ", "You should be also able to to navigate with ", " though unknown space in the map. If you set the goal to unknown place in the map, planning and navigating should work. With most planners this should work by default, refer to ", " if you need to setup this for ", " planner (but should be enabled by default). Navigation through unknown space is required for ", ". ", "If you want to use costmap provided by ", " you need to enable unknown space tracking by setting ", ". ", "If you have ", " configured correctly, you can start experimenting with ", ". Provided ", " should work out-of-the box in most cases, but as always you might need to adjust topic names and frame names according to your setup. ", "This package was developed as part of my bachelor thesis at ", " in Prague. ", "This project was initially based on ", " package by Charles DuHadway. Most of the node has been rewritten since then. The current frontier search algorithm is based on ", " by Paul Bovbel. "], "package_tt": ["explore_lite", "explore_lite", "explore_lite", "<move_base>/global_costmap/costmap", "move_base", "move_base", "min_frontier_size", "explore.launch", "explore_costmap.launch", "explore_lite", "explore_lite", "track_unknown_space:\u00a0true", "explore_lite", "explore.launch", "move_base", "explore_lite", "costmap", "track_unknown_space:\u00a0true", "costmap_updates", "~frontiers", "~robot_base_frame", "string", "base_link", "~costmap_topic", "string", "costmap", "~costmap_updates_topic", "string", "costmap_updates", "~visualize", "bool", "false", "~planner_frequency", "double", "1.0", "~progress_timeout", "double", "30.0", "progress_timeout", "~potential_scale", "double", "1e-3", "~orientation_scale", "double", "0", "~gain_scale", "double", "1.0", "~transform_tolerance", "double", "0.3", "~min_frontier_size", "double", "0.5", "global_frame", "robot_base_frame", "map", "base_link", "robot_base_frame", "global_frame", "global_frame", "costmap_topic"], "package_code": ["@masterthesis{H\u00f6rner2016,\n", "  author = {Ji\u0159\u00ed H\u00f6rner},\n", "  title = {Map-merging for multi-robot system},\n", "  address = {Prague},\n", "  year = {2016},\n", "  school = {Charles University in Prague, Faculty of Mathematics and Physics},\n", "  type = {Bachelor's thesis},\n", "  URL = {https://is.cuni.cz/webapps/zzp/detail/174125/},\n", "}"]},
{"url": "https://wiki.ros.org/automotive_autonomy_msgs", "package": "automotive_autonomy_msgs", "package_summary": ["Messages for vehicle automation"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/sr_ronex_test", "package": "sr_ronex_test", "package_summary": ["contains software tests that require RoNeX hardware."]},
{"url": "https://wiki.ros.org/utexas_gdc", "package": "utexas_gdc", "package_summary": ["Simulation environment for the Gates Dell Complex of the\n    University of Texas At Austin"]},
{"url": "https://wiki.ros.org/dwa_local_planner", "package": "dwa_local_planner", "package_summary": ["This package provides an implementation of the Dynamic Window Approach to\n        local robot navigation on a plane. Given a global plan to follow and a\n        costmap, the local planner produces velocity commands to send to a mobile\n        base. This package supports any robot who's footprint can be represented as\n        a convex polygon or cicrle, and exposes its configuration as ROS parameters\n        that can be set in a launch file. The parameters for this planner are also\n        dynamically reconfigurable. This package's ROS wrapper adheres to the\n        BaseLocalPlanner interface specified in the ", " package."], "package_details": [" ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 2.5) ", "\n", " (", ", default: 0.05) ", "\n", " (", ", default: 1.7) ", "\n", " (", ", default: 32.0) ", "\n", " (", ", default: 0.05) ", "\n", " (", ", default: ", ") ", "\n", "\n", "\n", "\n", " ", "The ", " package provides a controller that drives a mobile base in the plane.  This controller serves to connect the path planner to the robot.  Using a map, the planner creates a kinematic trajectory for the robot to get from a start to a goal location. Along the way, the planner creates, at least locally around the robot, a value function, represented as a grid map.  This value function encodes the costs of traversing through the grid cells.  The controller's job is to use this value function to determine dx,dy,dtheta velocities to send to the robot. ", "The ", " object is a ", " for a ", " object that exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "There are a large number of ROS ", " that can be set to customize the behavior of the ", " wrapper. These parameters are grouped into several categories: robot configuration, goal tolerance, forward simulation, trajectory scoring, oscillation prevention, and global plan. Most of these parameters can also be changed using ", " to facilitate tuning the local planner in a running system. ", "For C++ level API documentation on the ", " class, please see the following page: ", " ", "The ", " provides implementations of the DWA and Trajectory Rollout algorithms described earlier. In order to use the ", " with ROS, please use the ", ". It is not recommended to use the ", " on its own. ", "For C++ level API documentation on the ", ", please see the following page: ", " "], "package_tt": ["dwa_local_planner", "dwa_local_planner::DWAPlannerROS", "dwa_local_planner::DWAPlanner", "nav_core::BaseLocalPlanner", "dwa_local_planner::DWAPlannerROS", "~<name>/global_plan", "~<name>/local_plan", "odom", "robot_base_frame", "TrajectoryPlannerROS\u00a0object", "robot_base_frame", "dwa_local_planner::DWAPlannerROS", "~<name>/acc_lim_x", "double", "~<name>/acc_lim_y", "double", "~<name>/acc_lim_th", "double", "~<name>/max_trans_vel", "double", "~<name>/min_trans_vel", "double", "~<name>/max_vel_x", "double", "~<name>/min_vel_x", "double", "~<name>/max_vel_y", "double", "~<name>/min_vel_y", "double", "~<name>/max_rot_vel", "double", "~<name>/min_rot_vel", "double", "~<name>/yaw_goal_tolerance", "double", "~<name>/xy_goal_tolerance", "double", "~<name>/latch_xy_goal_tolerance", "bool", "~<name>/sim_time", "double", "~<name>/sim_granularity", "double", "~<name>/vx_samples", "integer", "~<name>/vy_samples", "integer", "~<name>/vth_samples", "integer", "~<name>/controller_frequency", "double", "~<name>/path_distance_bias", "double", "~<name>/goal_distance_bias", "double", "~<name>/occdist_scale", "double", "~<name>/forward_point_distance", "double", "~<name>/stop_time_buffer", "double", "~<name>/scaling_speed", "double", "~<name>/max_scaling_factor", "double", "~<name>/publish_cost_grid", "bool", "~<name>/oscillation_reset_dist", "double", "~<name>/prune_plan", "bool", "true", "base_local_planner::TrajectoryPlannerROS", "dwa_local_planner::DWAPlanner", "dwa_local_planner::DWAPlanner", "dwa_local_planner::DWAPlanner", "dwa_local_planner::TrajectoryPlanner", "dwa_local_planner::DWAPlanner\u00a0class"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "cost =\n", "  path_distance_bias * (distance to path from the endpoint of the trajectory in meters)\n", "  + goal_distance_bias * (distance to local goal from the endpoint of the trajectory in meters)\n", "  + occdist_scale * (maximum obstacle cost along the trajectory in obstacle cost (0-254))"]},
{"url": "https://wiki.ros.org/pose_base_controller", "package": "pose_base_controller", "package_summary": ["A node that provides the move_base action server interface, but instead of\n    planning simply drives towards the target pose using a control-based\n    approach."]},
{"url": "https://wiki.ros.org/tuw_object_msgs", "package": "tuw_object_msgs", "package_summary": ["The tuw_object_msgs package. This pkg provides a set of messages used to detect, map and track objects of different types."], "package_details": ["\n", "\n", "The ", " message is used to define the location and the quality of a detection. ", "The msg also hold a shape field to define the real appearance of the object useful for debugging and visualization.  ", "\n", "Same a ", " with header information ", "\n", "Same a ", " but with information about the pose uncertainty as covariance ", "\n", "Same a ", "  with header information ", "\n", "The ", " message represents the result of a detector with the detector settings such as field of view, or noise model. ", "\n", "The ", " message represents a map of objects and a result of filter (SLAM). It can also be used to publish a Feature map for a feature based self-localization.  "]},
{"url": "https://wiki.ros.org/rosconsole", "package": "rosconsole", "package_summary": ["ROS console output library."], "package_details": [" ", " is a C++ package that supports console output and logging in ", ". It provides a macro-based interface which allows both ", "- and stream-style output. It also wraps ", ", which supports hierarchical loggers, verbosity levels and configuration-files. ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", " the default format (if the environment variable is not set) for Python is now the same as for C++. If you want to keep the previous format for backward compatibility you can set the following: ", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", "rosconsole also provides assertions, in ", ": ", "rosconsole will load a config file from ", " when it initializes. ", "rosconsole also lets you define your own configuration file that will be used by log4cxx, defined by the ROSCONSOLE_CONFIG_FILE environment variable. Anything defined in this config file will ", " the default config file. ", "ROS output is set to ", " and higher by default. ", "For more detailed information on the config file, and log4cxx in general, please see the ", ". ", "If you want to include a custom configuration into a specific launch file, you can do so using the ", " of roslaunch. ", "Rosconsole uses the \"ros\" logger as its root-level logger. All unnamed logging statements will be output to the \"ros.<package_name>\" logger. The named variations will output to \"ros.<package_name>.<name>\". There are a couple of defines that expose this: ", "rosconsole provides a way to remove logging at compile time, though this should rarely be necessary. This is accomplished through the ", " define. Statements of a severity level lower than ", " will be compiled out. The options are: ", "If you want to change the logger levels via a configuration file, please see the ", " section. ", "To change the logger levels from C++, use ", ". Example: ", "If you change one of the ", "'s verbosity levels after any logging statements using that logger, you ", " call ", ". If you do not, logging statements that have already been hit once (and therefore initialized) may continue to print when they should not, and vice-versa. ", "For examples of this behavior, please see the ", " file. ", "rosconsole allows you to specify how you'd like its output to show up in the console output through the ", " environment variable.  The default is equivalent to: ", "By invoking ", " in C++ the logging subsystem is shut down and therefore no more logging occurs. ", "When ", " of a ROS application is fully buffered, for example in case when it is connected to a pipe, users may not see the output of the application until the buffer fills up. The user can force line buffering for ROS loggers that print to the console by setting the environment variable ", " to ", ". ", "Default value is ", ". When set to ", " the flush is not triggered on every line and the default buffering scheme of ", " is used. "], "package_tt": ["rosconsole", "printf", "printf", "ROS_DEBUG(...)", "ROS_DEBUG_STREAM(args)", "ROS_DEBUG_NAMED(name,\u00a0...)", "ROS_DEBUG_STREAM_NAMED(name,\u00a0args)", "ROS_DEBUG_COND(cond,\u00a0...)", "ROS_DEBUG_STREAM_COND(cond,\u00a0args)", "ROS_DEBUG_COND_NAMED(cond,\u00a0name,\u00a0...)", "ROS_DEBUG_STREAM_COND_NAMED(cond,\u00a0name,\u00a0args)", "ROS_DEBUG_ONCE(...)", "ROS_DEBUG_STREAM_ONCE(args)", "ROS_DEBUG_ONCE_NAMED(name,\u00a0...)", "ROS_DEBUG_STREAM_ONCE_NAMED(name,\u00a0args)", "ROS_DEBUG_THROTTLE(period,\u00a0...)", "ROS_DEBUG_STREAM_THROTTLE(period,\u00a0args)", "ROS_DEBUG_THROTTLE_NAMED(period,\u00a0name,\u00a0...)", "ROS_DEBUG_STREAM_THROTTLE_NAMED(period,\u00a0name,\u00a0args)", "ROS_DEBUG_DELAYED_THROTTLE(period,\u00a0...)", "ROS_DEBUG_STREAM_DELAYED_THROTTLE(period,\u00a0args)", "ROS_DEBUG_DELAYED_THROTTLE_NAMED(period,\u00a0name,\u00a0...)", "ROS_DEBUG_STREAM_DELAYED_THROTTLE_NAMED(period,\u00a0name,\u00a0args)", "ROS_DEBUG_FILTER(filter,\u00a0...)", "ROS_DEBUG_STREAM_FILTER(filter,\u00a0args)", "ROS_DEBUG_FILTER_NAMED(filter,\u00a0name,\u00a0...)", "ROS_DEBUG_STREAM_FILTER_NAMED(filter,\u00a0name,\u00a0args)", "ros/assert.h", "ROS_ASSERT(cond)", "ROS_ASSERT_MSG(cond,\u00a0...)", "ROS_BREAK()", "$ROS_ROOT/config/rosconsole.config", "ROSCONSOLE_ROOT_LOGGER_NAME", "ROSCONSOLE_DEFAULT_NAME", "ROSCONSOLE_MIN_SEVERITY", "ROSCONSOLE_MIN_SEVERITY", "ROSCONSOLE_SEVERITY_DEBUG", "ROSCONSOLE_SEVERITY_INFO", "ROSCONSOLE_SEVERITY_WARN", "ROSCONSOLE_SEVERITY_ERROR", "ROSCONSOLE_SEVERITY_FATAL", "ROSCONSOLE_SEVERITY_NONE", "ros::console::set_logger_level()", "Logger", "ros::console::notifyLoggerLevelsChanged()", "examples/example.cpp", "ROSCONSOLE_FORMAT", "ros_console", "ros::console::shutdown();", "stdout", "ROSCONSOLE_STDOUT_LINE_BUFFERED", "1", "0", "0", "stdout"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# Set the default ros output to warning and higher\n", "log4j.logger.ros=WARN\n", "# Override my package to output everything\n", "log4j.logger.ros.my_package_name=DEBUG", "<launch>\n", "  <env name=\"ROSCONSOLE_CONFIG_FILE\"\n", "       value=\"$(find mypackage)/custom_rosconsole.conf\"/>\n", "  <node pkg=\"mypackage\" type=\"mynode\" name=\"mynode\" output=\"screen\"/>\n", "</launch>", "\n", "#include <ros/console.h>\n", "if( ros::console::set_logger_level(ROSCONSOLE_DEFAULT_NAME, ros::console::levels::Debug) ) {\n", "   ros::console::notifyLoggerLevelsChanged();\n", "}", "export ROSCONSOLE_FORMAT='[${severity}] [${time}]: ${message}'", "export ROSCONSOLE_FORMAT='[${severity}] [WallTime: ${time}]: ${message}'", "log4j.threshold=OFF", "export ROSCONSOLE_STDOUT_LINE_BUFFERED=1"]},
{"url": "https://wiki.ros.org/rosjava_bootstrap", "package": "rosjava_bootstrap", "package_summary": ["Bootstrap utilities for rosjava builds."], "package_details": ["\n", "Please see ", ". "]},
{"url": "https://wiki.ros.org/moveit_msgs", "package": "moveit_msgs", "package_summary": ["Messages, services and actions used by MoveIt"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/webrtc", "package": "webrtc", "package_summary": ["WebRTC Native API"], "package_details": ["\n", "\n", "\n", "A package that exports the ", " libraries for use by other packages. ", "The ", " package does not export any include directories, libraries, or compiler options directly. This is because there are a substantial number of options and libraries that may cause issues with other libraries. Instead ", " exports a number of CMake variables that can be used. See ", " for example usage. "], "package_tt": ["webrtc", "webrtc"]},
{"url": "https://wiki.ros.org/turtlebot_arm_description", "package": "turtlebot_arm_description", "package_summary": ["turtlebot_arm_description contains URDF files and meshes for the TurtleBot arm."]},
{"url": "https://wiki.ros.org/stage_ros", "package": "stage_ros", "package_summary": ["This package provides ROS specific hooks for stage"], "package_details": ["\n", "\n", "\n", "\n", " ", " ", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", " (default: 0.2) ", " (default: true) ", "\n", " \u2192 ", " ", " \u2192 ", " ", " \u2192 ", " ", " \u2192 ", " ", "\n", "The ", " node wraps the Stage 2-D multi-robot simulator, via libstage.  Stage simulates a world as defined in a ", " file.  This file tells stage everything about the world, from obstacles (usually represented via a bitmap to be used as a kind of background), to robots and other objects. ", "The .world file syntax is documented in the  ", ". stageros only exposes models created by a subset of the .world file syntax, specifically ", ", ", " and ", " models.  For examples, see the ", " directory in the ", " and ", " packages. ", "If there is only one position model defined in the world file, all of these topics appear at the top namespace. However, if more than 1 position models exist, these topics are pushed down into their own namespaces, by prefixing the topics with ", " , e.g., ", " etc. ", "If there is only one position model defined in the world file, all of these topics appear at the top namespace. However, if more than 1 position models exist, these topics are pushed down into their own namespaces, by prefixing the topics with ", " , e.g., ", " etc. ", "The ", " topic gives simulated odometry, which is affected by settings in the .world file, which can change its origin and noise model (the transforms mentioned below use the same data); see the ", " for details on changing this behavior.  The  ", " topic always provides a perfect, globally referenced pose for the robot in the simulation, independent of .world file settings.  The ", " data is intended for testing purposes; it should not be used in robot control loops (because it's unrealistic). ", "Stage supports the use of \"controllers,\" which are chunks of code that control simulated robots from inside the simulator, instead of being on the other end of a ROS connection.  There are some situations in which it can be advantageous to use Stage controllers. For a discussion of when and how to use Stage controllers, see ", ". "], "package_tt": ["stageros", ".world", "world", "stage", "stage_ros", "robot_<i>/", "robot_0/cmd_vel", "cmd_vel", "robot_<i>/", "robot_0/cmd_vel", "odom", "base_scan", "base_pose_ground_truth", "image", "depth", "camera_info", "odom", "base_pose_ground_truth", "base_pose_ground_truth", "~base_watchdog_timeout", "cmd_vel", "~is_depth_canonical", "base_link", "base_laser", "base_footprint", "base_link", "odom", "base_footprint", "base_link", "camera"], "package_code": ["rosrun stage_ros stageros [-g runs headless] <world> [standard ROS args]"]},
{"url": "https://wiki.ros.org/pr2_precise_trajectory", "package": "pr2_precise_trajectory", "package_summary": ["This does some precise trajectory stuff, I'm not really sure though. :D"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/topic_tools", "package": "topic_tools", "package_summary": ["Tools for directing, throttling, selecting, and otherwise messing with\n    ROS topics at a meta level. None of the programs in this package actually\n    know about the topics whose streams they are altering; instead, these\n    tools deal with messages as generic binary blobs. This means they can be\n    applied to any ROS topic."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/aruco_mapping", "package": "aruco_mapping", "package_summary": ["This package allows user to create a map of Aruco markers in 2D or 3D space \n    and estimate full 6 DOF pose of the camera."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", " ", "Using ", " to estimate full 6 DOF position only by means of single calibrated camera is well known approach that has been utilized for quite a long time now. This package leverages basic ", " functionality and provides tools to create a map of detected markers in 2D/3D space. It is designed for ", "scenario", "and can be used for various navigation tasks for UAVs, UGVs, etc. ", "In order to achieve successfull mapping, everytime when a new marker is detected, previous marker needs to be visible in the actual image to allow computing new marker's position. (See ", " for better understanding). Keep this principle in mind when placing markers in your environment and do not overdo their mutual distances. ", "In order to to calibrate your camera and get results in INI format, we stongly suggest  ", " package. ", "Here is an example of launch file to run ", ", ", " driver and ", ": ", "In case you use other camera driver, remap ", " to your topic name. Do not forget to adopt ", ", ", " and other params to your setup. If everything is set and ready, launch the aruco_mapping by following command: ", "If you are experiencing problems with basic aruco detector caused by lighting conditions (strong reflections, poor lighting, bad focus) try to include our ", " into your processing pipeline in order to improve the raw image. "], "package_tt": ["image_raw", "aruco_markers", "aruco_poses", "calibration_file", "std_msgs/String", "num_of_markers", "std_msgs/UInt8", "marker_size", "std_msgs/Double64", "space_type", "std_msgs/String", "roi_allowed", "std_msgs/Bool", "roi_x", "std_msgs/UInt8", "roi_y", "std_msgs/UInt8", "roi_w", "std_msgs/UInt8", "roi_h", "std_msgs/UInt8", "world", "camera_pose"], "package_code": ["# Prosilica camera intrinsics\n", "\n", "[image]\n", "\n", "width\n", "2448\n", "\n", "height\n", "2050\n", "\n", "[prosilica]\n", "\n", "camera matrix\n", "4827.93789 0.00000 1223.50000\n", "0.00000 4835.62362 1024.50000\n", "0.00000 0.00000 1.00000\n", "\n", "distortion\n", "-0.41527 0.31874 -0.00197 0.00071 0.00000\n", "\n", "rectification\n", "1.00000 0.00000 0.00000\n", "0.00000 1.00000 0.00000\n", "0.00000 0.00000 1.00000\n", "\n", "projection\n", "4827.93789 0.00000 1223.50000 0.00000\n", "0.00000 4835.62362 1024.50000 0.00000\n", "0.00000 0.00000 1.00000 0.00000", "<launch>\n", "\n", "  <!-- RVIZ -->\n", "  <node name=\"rviz\" pkg=\"rviz\" type=\"rviz\" args=\"-d $(find aruco_mapping)/launch/aruco_config.rviz\" />\n", "\n", "   <!--   usb_cam node -->\n", "  <node name=\"usb_cam\" pkg=\"usb_cam\" type=\"usb_cam_node\" output=\"screen\">\n", "    <param name=\"video_device\" value=\"/dev/video0\" />\n", "    <param name=\"image_width\" value=\"640\" />\n", "    <param name=\"image_height\" value=\"480\" />\n", "    <param name=\"pixel_format\" value=\"mjpeg\" />\n", "    <param name=\"camera_frame_id\" value=\"usb_cam\" />\n", "    <param name=\"io_method\" value=\"mmap\"/>\n", "  </node>\n", "\n", "  <!-- ArUco mapping -->\n", "  <node pkg=\"aruco_mapping\" type=\"aruco_mapping\" name=\"aruco_mapping\" output=\"screen\">\n", "    <remap from=\"/image_raw\" to=\"/usb_cam/image_raw\"/>\n", "\n", "    <param name=\"calibration_file\" type=\"string\" value=\"$(find aruco_mapping)/data/F100.ini\"/>\n", "    <param name=\"num_of_markers\" type=\"int\" value=\"20\" />\n", "    <param name=\"marker_size\" type=\"double\" value=\"0.135\"/>\n", "    <param name=\"space_type\" type=\"string\" value=\"plane\" />\n", "    <param name=\"roi_allowed\" type=\"bool\" value=\"false\" />\n", "  </node>\n", "</launch>", "roslaunch aruco_mapping aruco_mapping.launch"]},
{"url": "https://wiki.ros.org/stereo_image_proc", "package": "stereo_image_proc", "package_summary": ["Stereo and single image rectification and disparity processing."], "package_tt": ["stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "stereo", "left", "right", "stereo/left", "stereo/right", "stereo/disparity", "stereo/points2", "left", "right", "left/*", "right/*", "stereo_image_proc", "image_raw", "camera_info", "left/image_raw", "left/camera_info", "right/image_raw", "right/camera_info", "left/image_mono", "left/image_rect", "left/image_color", "left/image_rect_color", "right/image_mono", "right/image_rect", "right/image_color", "right/image_rect_color", "disparity", "points2", "points", "points2", "~prefilter_size", "int", "~prefilter_cap", "int", "~correlation_window_size", "int", "~min_disparity", "int", "min_disparity", "min_disparity", "~disparity_range", "int", "min_disparity", "~uniqueness_ratio", "double", "uniqueness_ratio\u00a0>\u00a0(best_match\u00a0-\u00a0next_match)\u00a0/\u00a0next_match", "~texture_threshold", "int", "~speckle_size", "int", "~speckle_range", "int", "~approximate_sync", "bool", "~queue_size", "int", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "stereo", "left", "right", "stereo/left", "stereo/right", "stereo/disparity", "stereo/points2", "left", "right", "left/*", "right/*", "stereo_image_proc", "image_raw", "camera_info", "left/image_raw", "left/camera_info", "right/image_raw", "right/camera_info", "left/image_mono", "left/image_rect", "left/image_color", "left/image_rect_color", "right/image_mono", "right/image_rect", "right/image_color", "right/image_rect_color", "disparity", "points2", "points", "points2", "~prefilter_size", "int", "~prefilter_cap", "int", "~correlation_window_size", "int", "~min_disparity", "int", "min_disparity", "min_disparity", "~disparity_range", "int", "min_disparity", "~uniqueness_ratio", "double", "uniqueness_ratio\u00a0>\u00a0(best_match\u00a0-\u00a0next_match)\u00a0/\u00a0next_match", "~texture_threshold", "int", "~speckle_size", "int", "~speckle_range", "int", "~approximate_sync", "bool", "~queue_size", "int", "stereo_image_proc", "stereo_image_proc", "left/image_rect", "left/camera_info", "right/image_rect", "right/camera_info", "disparity", "~approximate_sync", "bool", "~queue_size", "int", "~prefilter_size", "int", "~prefilter_cap", "int", "~correlation_window_size", "int", "~min_disparity", "int", "min_disparity", "min_disparity", "~disparity_range", "int", "min_disparity", "~uniqueness_ratio", "double", "uniqueness_ratio\u00a0>\u00a0(best_match\u00a0-\u00a0next_match)\u00a0/\u00a0next_match", "~texture_threshold", "int", "~speckle_size", "int", "~speckle_range", "int", "~approximate_sync", "bool", "~queue_size", "int", "left/image_rect_color", "left/camera_info", "right/camera_info", "disparity", "points2", "~approximate_sync", "bool", "~queue_size", "int", "left/image_rect_color", "left/camera_info", "right/camera_info", "disparity", "points", "~approximate_sync", "bool", "~queue_size", "int", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "stereo", "left", "right", "stereo/left", "stereo/right", "stereo/disparity", "stereo/points2", "left", "right", "left/*", "right/*", "stereo_image_proc", "image_raw", "camera_info", "left/image_raw", "left/camera_info", "right/image_raw", "right/camera_info", "left/image_mono", "left/image_rect", "left/image_color", "left/image_rect_color", "right/image_mono", "right/image_rect", "right/image_color", "right/image_rect_color", "disparity", "points2", "points", "points2", "~prefilter_size", "int", "~prefilter_cap", "int", "~correlation_window_size", "int", "~min_disparity", "int", "min_disparity", "min_disparity", "~disparity_range", "int", "min_disparity", "~uniqueness_ratio", "double", "uniqueness_ratio\u00a0>\u00a0(best_match\u00a0-\u00a0next_match)\u00a0/\u00a0next_match", "~texture_threshold", "int", "~speckle_size", "int", "~speckle_range", "int", "~approximate_sync", "bool", "~queue_size", "int", "stereo_image_proc", "stereo_image_proc", "left/image_rect", "left/camera_info", "right/image_rect", "right/camera_info", "disparity", "~approximate_sync", "bool", "~queue_size", "int", "~prefilter_size", "int", "~prefilter_cap", "int", "~correlation_window_size", "int", "~min_disparity", "int", "min_disparity", "min_disparity", "~disparity_range", "int", "min_disparity", "~uniqueness_ratio", "double", "uniqueness_ratio\u00a0>\u00a0(best_match\u00a0-\u00a0next_match)\u00a0/\u00a0next_match", "~texture_threshold", "int", "~speckle_size", "int", "~speckle_range", "int", "~approximate_sync", "bool", "~queue_size", "int", "left/image_rect_color", "left/camera_info", "right/camera_info", "disparity", "points2", "~approximate_sync", "bool", "~queue_size", "int", "left/image_rect_color", "left/camera_info", "right/camera_info", "disparity", "points", "~approximate_sync", "bool", "~queue_size", "int", "image_proc", "stereo_image_proc", "stereo_image_proc", "stereo_image_proc", "manager", "string", "/my_manager", "respawn", "bool", "left", "string", "right", "string", "stereo_image_proc"], "package_code": ["/stereo/left/image_raw\n", "/stereo/left/camera_info\n", "/stereo/right/image_raw\n", "/stereo/right/camera_info", "$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc", "$ rosrun image_view image_view image:=/stereo/left/image_rect_color", "$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color", "/stereo/left/image_raw\n", "/stereo/left/camera_info\n", "/stereo/right/image_raw\n", "/stereo/right/camera_info", "$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc", "$ rosrun image_view image_view image:=/stereo/left/image_rect_color", "$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color", "/stereo/left/image_raw\n", "/stereo/left/camera_info\n", "/stereo/right/image_raw\n", "/stereo/right/camera_info", "$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc", "$ rosrun image_view image_view image:=/stereo/left/image_rect_color", "$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color"]},
{"url": "https://wiki.ros.org/polar_scan_matcher", "package": "polar_scan_matcher", "package_summary": ["\n    A wrapper around Polar Scan Matcher by Albert Diosi and Lindsay Kleeman, used for laser scan registration.\n    "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " package is a wrapper around Polar Scan Matcher [1], courtesy of: ", "Albert Diosi and Lindsay Kleeman ", "\n ", "Intelligent Robotics Research Centre (IRRC) ", "\n ", "Monash University ", "\n ", " ", "\n ", "The package allows to scan match between consecutive ", " messages, and publish the estimated position of the laser as a ", " or a ", " transform. ", "An estimation for theta can optionally be provided to improve accuracy, in the form of a ", ". This message would typically be published by an IMU or other angular rate sensor. ", "Alternatively, an estimation for x, y, and theta can optionally be provided to improve accuracy, in the form of a ", " transform. This transform would typically be published by an odometry system. This has not yet been tested. ", "You can run the ", " on a pre-recorded bag file that comes with the package. First, make sure you have the ", " stack downloaded and installed by following the instructions ", ". ", "Please use our ", " to ", " or ", ". "], "package_tt": ["psm_node", "scan", "imu", "odometry_type", "imu", "pose2D", "~world_frame", "string", "\"world\"", "~base_frame", "string", "\"base_link\"", "~publish_tf", "bool", "true", "~publish_pose", "bool", "true", "~odometry_type", "string", "none", "none", "imu", "imu", "tf", "world", "base", "~min_valid_points", "int", "200", "~search_window", "int", "40", "~max_error", "double", "0.20", "~max_iterations", "int", "20", "~stop_condition", "double", "0.01", "base_link", "laser", "use_odometry", "world", "base_link", "publish_tf"], "package_code": ["\n", "\n"]},
{"url": "https://wiki.ros.org/vision_visp", "package": "vision_visp", "package_summary": ["Virtual package providing ViSP related packages.", "These packages depend on ", " package that corresponds to the ", " last stable release packaged for ROS. "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Get ", " stack: ", "Use GitHub to ", ". "], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-vision-visp", "mkdir -p ~/catkin_ws/src\n", "cd ~/catkin_ws/src\n", "catkin_init_workspace\n", "cd ~/catkin_ws\n", "catkin_make", "cd ~/catkin_ws/src", "git clone https://github.com/lagadic/vision_visp.git", "cd vision_visp\n", "git checkout $ROS_DISTRO", "cd ~/catkin_ws\n", "sudo rosdep init\n", "rosdep update\n", "rosdep install --from-paths src --ignore-src --rosdistro $ROS_DISTRO", "cd ~/catkin_ws\n", "catkin_make -j4 -DCMAKE_BUILD_TYPE=Release", "cd ~/catkin_ws\n", "catkin_make -j4 -DCMAKE_BUILD_TYPE=Release --pkg visp_tracker", "roslaunch visp_tracker tutorial.launch\n", "roslaunch visp_auto_tracker tutorial.launch"]},
{"url": "https://wiki.ros.org/thingmagic_usbpro", "package": "thingmagic_usbpro", "package_summary": ["ROS driver package for the thingmagic USB pro RFID reader.  The driver creates a node named /rfid_detector_node and \npublish all detected tags on the topic /RFID_detections as custom RFID_Detection messages.  The RFID_Detection messages have 4\nfields: \n  epc:  A string containing the RFID tag identifier detected\n  antenna:  8-bit integer containing the antenna number of the detection\n  read_count:  8-bit integer containing the number of detections during the collection period\n  rssi:  8-bit integer containing the RSSI value of the detection \n\nUses the python wrapper for ThingMagic's Mercury API located here: https://github.com/gotthardp/python-mercuryapi"]},
{"url": "https://wiki.ros.org/rc_tagdetect_client", "package": "rc_tagdetect_client", "package_summary": ["The ros client for roboception tag detection modules"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", "See ", " and ", " for more details. ", "This node provides ROS service calls and parameters for the ", " module. ", "For detail description of the ", " module check the ", ". "], "package_tt": ["host", "device", "02912345", ":02912345", "use_cached_images", "forget_after_n_detections", "max_corner_distance", "quality", "detect_inverted_tags", "publish_visualization", "detect", "start_continuous_detection", "stop_continuous_detection"], "package_code": ["rosrun rc_tagdetect_client rc_april_node _host:=<sensor_ip>\n", "rosrun rc_tagdetect_client rc_qr_node _host:=<sensor_ip>", "rosrun rc_tagdetect_client rc_april_node _device:=:<serial_number>\n", "rosrun rc_tagdetect_client rc_qr_node _device:=:<serial_number>"]},
{"url": "https://wiki.ros.org/roscpp_tutorials", "package": "roscpp_tutorials", "package_summary": ["This package attempts to show the features of ROS step-by-step,\n    including using messages, servers, parameters, etc."], "package_details": ["\n", " contains a number of tutorial applications for programming with roscpp.  ", "You can browse these tutorials by ", "-ing to the ", " package, i.e. "], "package_tt": ["roscd", "roscpp_tutorials", "NodeHandle", "NodeHandle"], "package_code": ["roscd roscpp_tutorials"]},
{"url": "https://wiki.ros.org/rosh_robot_plugins", "package": "rosh_robot_plugins", "package_summary": ["ROSH related packages. This is a temporary stack that is expected to go away after the Diamondback release. For C Turtle and Diamondback it provides a convenient way to install rosh until it is properly stabilized."], "package_details": ["\n", " is a Python-based shell and runtime environment for ROS.  It leverages the IPython shell environment to provide tab-completion introspection across various ROS APIs, like topics, services, parameters, and nodes.  It is similar to using tools like ", " and ", ", but with Pythonic semantics and the convenience of a Python interpreter.  You can also develop ROS nodes using rosh, which we call \"roshlets\". ", "\n", "\n", " ", "To get started, please see the ", " documentation. ", "rosh_robot_plugins houses stacks related to the \"robot\" variant, which was introduced in ", ". The robot variant focuses on on-robot capabilities, such as ", " and ", " libraries. "]},
{"url": "https://wiki.ros.org/dataspeed_ulc_msgs", "package": "dataspeed_ulc_msgs", "package_summary": ["ROS messages for interacting with the Universal Lat/Lon Controller (ULC)"]},
{"url": "https://wiki.ros.org/stereo_slam", "package": "stereo_slam", "package_summary": ["Stereo Slam"], "package_details": [" ", "stereo_slam is a ROS node to execute Simultaneous Localization And Mapping (SLAM) using only one stereo camera. The algorithm was designed and tested for underwater robotics. This node is based on the ", " library for graph optimization and uses the power of ", " to find loop closures between graph nodes. It uses a keyframe to multi-keyframe loop closing mechanism, based on keypoint clustering, to improve the SLAM corrections on feature-poor environments. ", "See the documentation on ", ". "]},
{"url": "https://wiki.ros.org/turtlebot_interactive_markers", "package": "turtlebot_interactive_markers", "package_summary": ["Interactive control for the TurtleBot using RViz and interactive markers"], "package_details": [" ", "\n", "\n", "\n", "\n", "This ", " will walk you through using interactive markers to control the ", ".  "], "package_tt": ["/turtlebot_node/cmd_vel", "~link_name", "string", "~linear_scale", "double", "~angular_scale", "double"]},
{"url": "https://wiki.ros.org/topics_rviz_plugin", "package": "topics_rviz_plugin", "package_summary": ["Display topics values in a RViz plugin"], "package_details": ["Documentation is here: ", " "]},
{"url": "https://wiki.ros.org/nextage_ros_bridge", "package": "nextage_ros_bridge", "package_summary": ["A main ROS interface for developers and users of ", " dual-armed robot from Kawada Robotics Inc. Developers can build their own application that takes control over Nextage via this package. Interface for both ROS and ", " is provided."], "package_details": ["\n", " is a python class that functions as a programming interface for the robot users. As seen in the api document, it extends ", " class so that all the public methods are inherited from there on.  ", " ", "The reason ", " was created separately from ", " is because of the ", " design unique to ", " robot. "], "package_tt": ["NextageClient", "HIRONX", "DIO"]},
{"url": "https://wiki.ros.org/explorer", "package": "explorer", "package_summary": ["The explorer package utilizes frontier based exploration for multi-robot systems. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration reducing exploration time."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " utilizes frontier based exploration to discover environments autonomously operating a distributed multi-robot system. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration which result in improvement of efficiency in terms of exploration time. ", "The ", " comprises multiple functionalities to perform frontier based exploration. Frontier detection is utilized on local and global costmaps to further select navigation goals in the environment to proceed with exploration. The assignment of robots to goals is accomplished according to coordinated and uncoordinated exploration strategies being applied for the distributed multi-robot system. ", "Auctioning thereby ensures negotiation among available goals to coordinate efficiently, distributing robots among the environment by minimizing the overall travel path. Additionally to frontier detection and selection, the ", " is concerned with navigation to goal points by incorporating a simple action client utilizing ", ". ", "You may obtain the paper from ", " or search in  ", ". "], "package_tt": ["~<name>/map_merger/global_map", "~<name>/base_scan", "~<name>/frontiers", "~<name>/visited_frontiers", "~<name>/negotiation_list", "~<name>/auction", "~<name>/all_positions", "~<name>/visitedfrontierPoints", "~<name>/goalPoint", "~<name>/frontierPoints", "~<name>/cluster_grid_~", "~<name>/adhoc_communication/send_frontier", "~<name>/adhoc_communication/send_auction", "~<name>/frontier_selection", "int", "~<name>/local_costmap/width", "int", "~<name>/number_unreachable_for_cluster", "int"], "package_code": ["@InProceedings{Andre2014,\n", "  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},\n", "  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},\n", "  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},\n", "  Year                     = {2014},\n", "  Month                    = dec,\n", "}"]},
{"url": "https://wiki.ros.org/nav2d_remote", "package": "nav2d_remote", "package_summary": ["This package is used to manually control a robot that uses the operator and\n    navigator node from navigation_2d. Currently there is one node to control one\n    robot with a joystick and one to control multiple robots in simulation.\n    It can send commands directly to the operator or start and stop navigator actions."]},
{"url": "https://wiki.ros.org/advanced_navigation_driver", "package": "advanced_navigation_driver", "package_summary": ["The Advanced Navigation driver package for ROS"], "package_details": [" ", "This example has been developed and tested using Ubuntu Linux v16.04 LTS and ROS Lunar. Installation instructions for ROS can be found here: ", ". ", "If you require any assistance using this code, please email ", " . "]},
{"url": "https://wiki.ros.org/reemc_description", "package": "reemc_description", "package_summary": ["This package contains the description (mechanical, kinematic, visual,\n      etc.) of the REEM-C robot.  The files in this package are parsed and used by\n      a variety of other components.  Most users will not interact directly\n      with this package."]},
{"url": "https://wiki.ros.org/slam_karto", "package": "slam_karto", "package_summary": ["This package pulls in the Karto mapping library, and provides a ROS\n     wrapper for using it."], "package_details": [" ", "\n", "\n", "\n", "\n", "Part of the documentation is available in the previously maintained ", ". ", "Use github to ", ". "], "package_tt": ["slam_karto", "tf", "scan", "map_metadata", "map", "visualization_marker_array", "dynamic_map", "~odom_frame", "string", "\"odom\"", "~map_frame", "string", "\"map\"", "~base_frame", "string", "\"base_link\"", "~throttle_scans", "int", "~map_update_interval", "float", "~resolution", "float", "~delta", "float", "~transform_publish_period", "float", "0", "~use_scan_matching", "bool", "~use_scan_barycenter", "bool", "~minimum_travel_distance", "double", "~minimum_travel_heading", "double", "~scan_buffer_size", "int", "~scan_buffer_maximum_scan_distance", "double", "~link_match_minimum_response_fine", "double", "~link_scan_maximum_distance", "double", "~loop_search_maximum_distance", "double", "~do_loop_closing", "bool", "~loop_match_minimum_chain_size", "int", "~loop_match_maximum_variance_coarse", "double", "~loop_match_minimum_response_coarse", "double", "~loop_match_minimum_response_fine", "double", "~correlation_search_space_dimension", "double", "~correlation_search_space_resolution", "double", "~correlation_search_space_smear_deviation", "double", "~loop_search_space_dimension", "double", "~loop_search_space_resolution", "double", "~loop_search_space_smear_deviation", "double", "~distance_variance_penalty", "double", "~angle_variance_penalty", "double", "~fine_search_angle_offset", "double", "~coarse_search_angle_offset", "double", "~coarse_angle_resolution", "double", "~minimum_angle_penalty", "double", "~minimum_distance_penalty", "double", "~use_response_expansion", "bool", "<the\u00a0frame_id\u00a0of\u00a0the\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"]},
{"url": "https://wiki.ros.org/ethercat_hardware", "package": "ethercat_hardware", "package_summary": ["Package for creating a hardware interface to the robot using the EtherCAT motor controller/driver"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", " ", " will respond with: ", "\n", "The ", " package's primary purpose is to provide a library for communicating with motor controller boards.  However, the package does provide the ", " command-line tool for configuring these boards.  In practice, this tool is used during robot assembly, and should not be needed after initial bring-up of the robot.  ", " ", "When running motorconf, you must specify the interface used to communicate with the EtherCAT devices.  Without any additional arguments, ", " will enumerate all of the EtherCAT devices it can find. ", "In order to program an unconfigured device, or re-program a device, you must specify a name, motor type, and board type for this motor.  If the name given (using the ", " option) matches one of the names in the actuators configuration file (", ", by default), then the motor type and board type will be selected automatically.  The motor type can be specified explicitly with the ", " option, and the board type can be specified with the ", " option.  A list of valid actuator names and motor types can be found with the ", " option.  In addition to the name, motor, and board types, ", " needs to know which device in the EtherCAT chain to program.  The device number is specified with the ", " option.  Finally, the ", " option tells ", " to actually program the board.  The following example programs device #2 to be the ", ": ", "actuators.conf is an XML file that specifies the motor parameters and common motor names to be programmed into the motor controller boards.  The file consists of a single <configuration> section.  The <configuration> section contains two subsections: <motors> and <actuators>. ", "The <motors> subsection contains a series of <motor> definitions.  Each motor requires a ", " attribute.  The <motor> also requires child elements <params> and <encoder>.  The <params> element contains the following attributes: ", "The <encoder> element contains the following attributes: ", "The <actuators> subsection contains a series of <actuator> definitions.  An <actuator> has the following attributes: ", "For example, the following <actuator> definition states that the ", " should be configured with the motor parameters specified in the previous example: "], "package_tt": ["ethercat_hardware", "diagnostics", "accelerometer", "pressure", "motors_halted", "ethercat_hardware", "motorconf", "motorconf", "motorconf", "-n", "actuators.conf", "-m", "-b", "-h", "motorconf", "-d", "-p", "motorconf", "br_caster_r_wheel_motor", "motorconf"], "package_code": ["Usage: ./motorconf [options]\n", " -i, --interface <i>    Use the network interface <i>\n", " -a, --actuators <file> Get the actuator definitions from file (default: actuators.conf)\n", " -d, --device <d>       Select the device to program\n", " -b, --board <b>        Set the expected board type (wg005, wg006, wg021)\n", " -p, --program          Program a motor control board\n", " -n, --name <n>         Set the name of the motor control board to <n>\n", " -m, --motor <m>        Set the configuration for motor <m>\n", " -h, --help             Print this message and exit", "# ./motorconf -i ecat0\n", "\n", "[DEBUG] 1263333387.377268000: Device #00: WG014 (0x67d616)\n", "[DEBUG] 1263333387.419128000: Device #01: WG014 (0x67d616)\n", "[DEBUG] 1263333387.462366000: Device #02: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1399\n", "[DEBUG] 1263333387.463359000:             Serial #: 01399\n", "[DEBUG] 1263333387.465986000:             Name: br_caster_r_wheel_motor\n", "[DEBUG] 1263333387.509329000: Device #03: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1414\n", "[DEBUG] 1263333387.510322000:             Serial #: 01414\n", "[DEBUG] 1263333387.512832000:             Name: br_caster_l_wheel_motor\n", " .\n", " . \n", " .\n", "[DEBUG] 1263333388.293608000: Device #20: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1695\n", "[DEBUG] 1263333388.294604000:             Serial #: 01695\n", "[DEBUG] 1263333388.297113000:             Name: laser_tilt_mount_motor", "./motorconf -i ecat0 -n br_caster_r_wheel_motor -d 2 -p", "[ INFO] 1263334127.577301000: Programming device 2, to be named: br_caster_r_wheel_motor", "  <!-- Elbow, shoulder, spine -->\n", "  <!-- http://pr.willowgarage.com/wiki/HardwareComponents/Motors?action=AttachFile&do=get&target=maxonRE40.pdf -->\n", "  <motor name=\"148877\">\n", "    <params make=\"Maxon\"\n", "            model=\"148877\"\n", "            max_current=\"3.12\"\n", "            speed_constant=\"158\"\n", "            resistance=\"1.16\"\n", "            motor_torque_constant=\"0.0603\" />\n", "    <encoder pulses_per_revolution=\"1200\" reduction=\"-1\"/>\n", "  </motor>", "  <actuator name=\"l_elbow_flex_motor\" motor=\"148877\" board=\"wg005\"/>"]},
{"url": "https://wiki.ros.org/move_slow_and_clear", "package": "move_slow_and_clear", "package_summary": ["move_slow_and_clear"], "package_details": [" ", "\n", "\n", "\n", "\n", " (", ", default: 0.5) ", "\n", "The ", " is a simple recovery behavior that clears information in the ", " and then limits the speed of the robot. Note, this recovery behavior is not truly safe, the robot may hit things, it'll just happen at a user-specified speed. Also, this recovery behavior is only compatible with local planners that allow maximum speeds to be set via ", " such as the ", ". ", "The ", " object exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "The C++ ", " class adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". "], "package_tt": ["move_slow_and_clear::MoveSlowAndClear", "move_slow_and_clear::MoveSlowAndClear", "nav_core::RecoveryBehavior", "~<name>/clearing_distance", "double", "~<name>/limited_trans_speed", "double", "~<name>/limited_rot_speed", "double", "~<name>/limited_distance", "double", "~<name>/planner_namespace", "string", "max_trans_vel", "max_rot_vel", "move_slow_and_clear::MoveSlowAndClear", "nav_core::RecoveryBehavior"]},
{"url": "https://wiki.ros.org/v4r_ellipses", "package": "v4r_ellipses", "package_summary": ["The v4r_ellipses package contains a computer vision library which is able to detect ellipses within images.  \n    The package is able to estimate the pose of the circle related to the ellipse the circle diameter as well as the camera parameter are known.\n    A dynamic reconfigure interface allows the user to tune the parameter of the system to ones needs.\n    But be aware that the pose of a projected circle within a image (ellipse) has two solutions and only one is published as TF.\n    A costom message (v4r_msgs) publishes all the data as well as the pose ambiguity."], "package_details": ["\n", "\n", " ", "Chen2004) Chen, Q.; Wu, H. & Wada, T. Pajdla, T. & Matas, J. (Eds.) Camera Calibration with Two Arbitrary Coplanar Circles Computer Vision - ECCV 2004, Springer Berlin Heidelberg, 2004, 3023, 521-532,  ", " "], "package_code": ["rosrun v4r_ellipses v4r_ellipses_node image:=/camera/image_raw camera_info:=/camera/camera_info", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/libsick_ldmrs", "package": "libsick_ldmrs", "package_summary": ["A library for communication with the SICK LD-MRS series of laser scanners."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "This package contains a library for communicating with the SICK LD-MRS line of laser scanners. For a ROS wrapper, see ", ". "]},
{"url": "https://wiki.ros.org/pr2_moveit_plugins", "package": "pr2_moveit_plugins", "package_summary": ["PR2 specific plugins for MoveIt"]},
{"url": "https://wiki.ros.org/jsk_common_msgs", "package": "jsk_common_msgs", "package_summary": ["Metapackage that contains commonly used messages for jsk-ros-pkg"]},
{"url": "https://wiki.ros.org/svenzva_simulation", "package": "svenzva_simulation", "package_summary": ["Files relating to running 3D simulations of Svenzva manipulators"], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "This package contains relevant files for running Svenzva robots in 3D simulations. Currently supported simulations are through Gazebo, ", "!, or both Gazebo and Moveit!.  ", "For control of robot arms in simulation we use ", " plugins for Gazebo.  ", "This provides software level controllers for each joint which likely will not translate 1-1 on the real robot.  ", "Tips on tuning PID parameters for ", " can be found on Gazebo's ", " plugin page (located ", ") under the section \"Tuning PID Parameters\". ", "The tutorial for 3D simulations using Gazebo and/or ", " can be found at ", " "], "package_tt": ["ros_control", "ros_control", "ros_control", "ros_control", "/revel/effort_joint_trajectory_controller/follow_joint_trajectory/goal", "/revel/effort_joint_trajectory_controller/gains/joint_1/parameter_descriptions", "/revel/effort_joint_trajectory_controller/gains/joint_2/parameter_descriptions", "/revel/effort_joint_trajectory_controller/gains/joint_3/parameter_descriptions", "/revel/effort_joint_trajectory_controller/gains/joint_4/parameter_descriptions", "/revel/effort_joint_trajectory_controller/gains/joint_5/parameter_descriptions", "/revel/effort_joint_trajectory_controller/gains/joint_6/parameter_descriptions", "/revel/effort_joint_trajectory_controller/follow_joint_trajectory/feedback", "/revel/effort_joint_trajectory_controller/follow_joint_trajectory/result", "/svenzva_controllers/joint_1/command", "/svenzva_controllers/joint_1/pid/parameter_descriptions", "/svenzva_controllers/joint_2/command", "/svenzva_controllers/joint_2/pid/parameter_descriptions", "/svenzva_controllers/joint_3/command", "/svenzva_controllers/joint_3/pid/parameter_descriptions", "/svenzva_controllers/joint_4/command", "/svenzva_controllers/joint_4/pid/parameter_descriptions", "/svenzva_controllers/joint_5/command", "/svenzva_controllers/joint_5/pid/parameter_descriptions", "/svenzva_controllers/joint_6/command", "/svenzva_controllers/joint_6/pid/parameter_descriptions", "/svenzva_controllers/joint_1/state", "/svenzva_controllers/joint_2/state", "/svenzva_controllers/joint_3/state", "/svenzva_controllers/joint_4/state", "/svenzva_controllers/joint_5/state", "/svenzva_controllers/joint_6/state"]},
{"url": "https://wiki.ros.org/phidgets_ir", "package": "phidgets_ir", "package_summary": ["\n\n     Driver for the Phidgets IR.\n\n  "], "package_details": ["\n", " ", "\n", " ", "The ", " package contains a  ROS driver for the ", " device. The driver does not publish any data in ROS, but can be used as an example or adapted. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "]},
{"url": "https://wiki.ros.org/rc_visard", "package": "rc_visard", "package_summary": ["Roboception rc_visard support meta package"], "package_details": ["\n", " is a meta package of the ROS interface for the ", " ", " 3D sensor. ", " ", " ", " contains the packages ", " and ", ". ", "\n", "The ", " is the world\u2019s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. ", "The ", " package contains xacro and urdf files for the two baseline versions of the ", " (", ", ", "). ", "The ", " is the official ROS driver for the ", " which provides ROS parameters (configuration), ROS services (control of ", "s dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF). ", "Purchase one of the rc_visard variants available right now and continue with the ", ": "]},
{"url": "https://wiki.ros.org/sr_gazebo_plugins", "package": "sr_gazebo_plugins", "package_summary": ["\n    Gazebo Plugins for various Shadow Robot-specific sensors and actuators on the robot.\n  "]},
{"url": "https://wiki.ros.org/rsv_balance_desktop", "package": "rsv_balance_desktop", "package_summary": ["Visualization and HMI packages for RoboSavvy's balancing platform"], "package_details": ["\n", " "], "package_code": ["  roslaunch rsv_balance_viz view_model.launch", "  roslaunch rsv_balance_viz view_robot.launch"]},
{"url": "https://wiki.ros.org/world_canvas_server", "package": "world_canvas_server", "package_summary": ["Storage manager and server for WCF semantic maps."], "package_details": ["\n", "\n", "\n"], "package_tt": ["get_annotations", "get_annotations_data", "pub_annotations_data", "delete_annotations", "save_annotations_data", "list_worlds", "set_keyword", "set_relationship", "reset_database", "yaml_import", "yaml_export", "list_maps", "publish_map", "delete_map", "rename_map", "save_map", "dynamic_map", "~start_map_manager", "~last_map_id", "~last_map_id", "~auto_save_map"]},
{"url": "https://wiki.ros.org/summit_x_common", "package": "summit_x_common", "package_summary": ["The summit_x_common package"], "package_details": ["\n", " ", "\n", "\n", "This package contains the different controllers and launch files for the ", ", shared for real robot and simulation.  "]},
{"url": "https://wiki.ros.org/svenzva_ros", "package": "svenzva_ros", "package_summary": ["The svenzva_ros meta-package"], "package_details": ["\n", "\n", "\n", "Source code is available on ", " which also contains instructions for installation and compilation. ", "General tutorials, guides and discussions on implementation can be found on the svenzva_ros ", ". "]},
{"url": "https://wiki.ros.org/tf_remapper_cpp", "package": "tf_remapper_cpp", "package_summary": ["More efficient version of tf/tf_remap able to handle TFs at kHz with tens of subscribers."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package is an alternative to official ROS node ", " with the following advantages: "], "package_tt": ["/tf_static", "new", "/tf_old", "/tf", "/tf", "/tf_old", "/map", "/ugv1/map", "/ugv2/map", "/global_map", "tf", "tf_remapper_cpp", "libtf_remapper_cpp.so", "mappings", "array\u00a0of\u00a0dicts", "[{\"old\":\u00a0\"b\",\u00a0\"new\":\u00a0\"d\"}]", "old", "new", "rosrun", "rosparam\u00a0set\u00a0/tf_remapper/mappings\u00a0'[{\"old\":\u00a0\"b\",\u00a0\"new\":\u00a0\"d\"}]'", "static_tf", "bool", "new_tf_topic_name", "new_tf_topic_name", "tf_static", "/tf_static", "static_tf", "True", "False", "old_tf_topic_name", "string", "'/tf_old'", "new_tf_topic_name", "string", "'/tf'", "is_bidirectional", "bool", "False", "True", "/tf_old", "old_tf_topic_name", "tf2_ros/TFMessage", "/tf", "new_tf_topic_name", "is_bidirectional\u00a0==\u00a0True", "tf2_ros/TFMessage", "/tf_old", "/tf", "new_tf_topic_name", "tf2_ros/TFMessage", "/tf_old", "old_tf_topic_name", "is_bidirectional\u00a0==\u00a0True", "tf2_ros/TFMessage", "/tf"], "package_code": ["<launch>\n", "    <group>\n", "        <remap from=\"tf\" to=\"tf_old\" />\n", "        <!-- The tf(1) static_transform_publisher does not use /tf_static, but periodically publises to /tf -->\n", "        <node name=\"broadcaster_ab\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"1 2 3 4 5 6 a b 10\"/>\n", "        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->\n", "    </group>\n", "\n", "    <node name=\"remapper\" pkg=\"tf_remapper_cpp\" type=\"tf_remap\">\n", "        <rosparam param=\"mappings\">[{old: b, new: c}]</rosparam>\n", "    </node>\n", "\n", "    <!-- This node will see transform a->c -->\n", "    <node name=\"my_node\" pkg=\"my_pkg\" type=\"node_type\" />\n", "</launch>", "<launch>\n", "    <group>\n", "        <remap from=\"tf_static\" to=\"tf_static_old\" />\n", "        <!-- The tf2 static_transform_publisher uses /tf_static -->\n", "        <node name=\"broadcaster_ab\" pkg=\"tf2_ros\" type=\"static_transform_publisher\" args=\"1 2 3 4 5 6 a b\"/>\n", "        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->\n", "    </group>\n", "\n", "    <node name=\"remapper\" pkg=\"tf_remapper_cpp\" type=\"tf_remap\">\n", "        <rosparam param=\"mappings\">[{old: b, new: c}]</rosparam>\n", "        <!--<param name=\"static_tf\" value=\"true\" />  - this is not needed, autodetection works in this case -->\n", "    </node>\n", "\n", "    <!-- This node will see static transform a->c -->\n", "    <node name=\"my_node\" pkg=\"my_pkg\" type=\"node_type\" />\n", "</launch>", "<launch>\n", "    <group>\n", "        <remap from=\"tf\" to=\"tf_old\" />\n", "        <!-- The tf(1) static_transform_publisher does not use /tf_static, but periodically publises to /tf -->\n", "        <node name=\"broadcaster_ab\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"1 2 3 4 5 6 a b 10\"/>\n", "        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->\n", "            \n", "        <!-- This node will see transforms a->b and d->e -->\n", "        <node name=\"my_node2\" pkg=\"my_pkg\" type=\"node_type\" />\n", "    </group>\n", "\n", "    <node name=\"remapper\" pkg=\"tf_remapper_cpp\" type=\"tf_remap\">\n", "        <rosparam param=\"mappings\">[{old: b, new: c}, {old: e, new: f}]</rosparam>\n", "        <param name=\"is_bidirectional\" value=\"true\" />\n", "    </node>\n", "\n", "    <!-- This node will see transforms a->c and d->f -->\n", "    <node name=\"my_node\" pkg=\"my_pkg\" type=\"node_type\" />\n", "        \n", "    <node name=\"broadcaster_df\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"1 2 3 4 5 6 d f 10\"/>\n", "</launch>"]},
{"url": "https://wiki.ros.org/rotunit_snapshotter", "package": "rotunit_snapshotter", "package_summary": ["This modul can be used to assemble a point cloud from a rotating laserscanner."], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/toposens", "package": "toposens", "package_summary": ["ROS support for Toposens 3D Ultrasound sensors."], "package_details": ["\n", " ", "\n", " ", "\n", "\n", "\n", "ROS packages for ", " ", "These packages support the ", " ultrasonic sensor by Toposens. ", "Use the ROS Answers forum for questions and tag with ", ": ", "Use the issue tracker in the ", " repository to report bugs or submit feature requests: "], "package_tt": ["toposens"]},
{"url": "https://wiki.ros.org/rtt_geometry", "package": "rtt_geometry", "package_summary": ["This metapackage contains tools for integrating the Orocos Kinematics and\n    Dynamics Library (KDL) with the Orocos Toolchain and Real-Time Toolkit\n    (RTT)."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "  "], "package_code": ["sudo aptitude install ros-electric-rtt-geometry", "git clone http://git.mech.kuleuven.be/robotics/rtt_geometry.git\n", "rosmake rtt_geometry"]},
{"url": "https://wiki.ros.org/rosparam", "package": "rosparam", "package_summary": ["rosparam contains the rosparam command-line tool for getting and\n    setting ROS Parameters on the ", " using YAML-encoded files. It also contains an\n    experimental library for using YAML with the Parameter\n    Server. This library is intended for internal use only.\n\n    rosparam can be invoked within a ", " file."], "package_details": ["\n", " uses a 1-to-1 correspondence between ", " types and YAML types. For example: ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " is a stable command-line tool within the ROS core toolchain. No major feature development is currently scheduled for this tool. ", "\n", "YAML is a lightweight markup language that supports all parameter types. For more on YAML, see ", ". For tips on entering YAML in at the command-line, please see the ", " guide. ", "YAML dictionaries can occur as the argument to the ", " and ", " commands of ", ".  Dictionaries in this context are interpreted differently from namespace dictionaries that are set as the value of a parameter (e.g. from a C++ or Python node). Instead of ", " a parameter namespace, dictionaries ", " are unpacked into individual parameters to be set on the Parameter Server. Thus, ", " dictionaries can be thought of as ", " new values to a parameter namespace. ", "The ", " tag enables the use of the ", " tool for loading and dumping parameters encoded in YAML files.  The ", " tag can be put inside of a ", " tag, in which case the parameter is treated like a ", ". ", "The ", " tool enables command-line setting and getting of parameters as well as loading and dumping ", " state to a file. The currently supported commands are: ", "Command-line arguments to rosparam obey the ", " environment variable (see ", "). Parameter names that are not globally specified are resolved with respect to ", ". ", "NOTE: ", " and ", " are essentially the same command, as are ", " and ", ", with the only difference being whether or not a file is used. "], "package_tt": ["rosparam", "load", "set", "rosparam", "rosparam", "rosparam", "pi", "rosparam", "rosparam", "ROS_NAMESPACE", "ROS_NAMESPACE", "get", "dump", "set", "load", "list", "list\u00a0<namespace>", "get\u00a0<parameter-name>", "-p", "-v", "set\u00a0<parameter-name>\u00a0[parameter-value]", "parameter-value", "--textfile", "--binfile", "-v", "-t\u00a0<text_file>,\u00a0--textfile\u00a0<text_file>", "-b\u00a0<binary_file>,\u00a0--binfile\u00a0<binary_file>", "delete\u00a0<parameter-name>", "-v", "dump\u00a0<file>", "dump\u00a0<file>\u00a0<namespace>", "-v", "load\u00a0<yaml-file>\u00a0[namespace]", "[namespace]", "/", "-v", "rosparam"], "package_code": ["string: 'foo'\n", "integer: 1234\n", "float: 1234.5\n", "boolean: true\n", "list: [1.0, mixed list]\n", "dictionary: {a: b, c: d}", "angle1: rad(2*pi)\n", "angle2: deg(180)", "angle1: !degrees 181.0\n", "angle2: !radians 3.14169", "rosparam set    set parameter\n", "rosparam get    get parameter\n", "rosparam load   load parameters from file\n", "rosparam dump   dump parameters to file\n", "rosparam delete delete parameter\n", "rosparam list   list parameter names", "$ rosparam list", "$ rosparam list /namespace", "$ rosparam get parameter_name", "$ rosparam set parameter_name value", "$ rosparam set /foo \"['1', 1, 1.0]\"", "$ rosparam set /gains \"p: 1.0\n", "i: 1.0\n", "d: 1.0\"", "$ rosparam delete parameter_name ", "$ rosparam dump dump.yaml", "$ rosparam dump dump.yaml /namespace", "$ rosparam dump -v gains.yaml /gains\n", "dumping namespace [/gains] to file [gains.yaml]\n", "/gains/i=1.0\n", "/gains/p=1.0\n", "/gains/d=1.0", "$ rosparam load dump.yaml"]},
{"url": "https://wiki.ros.org/tf2_kdl", "package": "tf2_kdl", "package_summary": ["KDL binding for tf2"], "package_details": ["\n", "\n", "\n", " ", "Please see the ", " for use. "]},
{"url": "https://wiki.ros.org/ur_description", "package": "ur_description", "package_summary": ["URDF description for Universal UR5/10 robot arms"], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "To view and manipulate the arm models in ", ", install the package from package management and launch the following: ", "You should see an rviz window showing the UR5 in a lying-down position, and a separate window where the joint values may be manually specified. Note that this is not a simulation, just a visualization of the arm model. To simulate UR5 or UR10, see ", ". "], "package_code": ["roslaunch ur_description ur5_upload.launch\n", "roslaunch ur_description test.launch"]},
{"url": "https://wiki.ros.org/multi_level_map_msgs", "package": "multi_level_map_msgs", "package_summary": ["multi_level_map_msgs"]},
{"url": "https://wiki.ros.org/wheeled_robin_driver", "package": "wheeled_robin_driver", "package_summary": ["Driver for WheeledRobin"], "package_details": ["\n", " ", "This is a generic driver for ", ". Port of pyrobot.py by Damon Kohler and ", " by OSRF. For ROS bindings, please see ", ". "]},
{"url": "https://wiki.ros.org/universal_teleop", "package": "universal_teleop", "package_summary": ["Allows keyboard/joystick control of any robot by means of geometry_msgs::Twist messages"], "package_details": ["\n", "\n", "\n"], "package_tt": ["joy", "keyboard/key_up", "keyboard/key_down", "robot/cmd_vel", "events", "controls"]},
{"url": "https://wiki.ros.org/rqt_ez_publisher", "package": "rqt_ez_publisher", "package_summary": ["The rqt_ez_publisher package"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "2. run as plugin of ", " ", "Plugins -> Topics -> Easy Message Publisher ", "Input topic name -> You got GUI ", "A. Click \"config (gear) icon\" -> set repeat interval [ms] "], "package_code": ["$ sudo apt-get install ros-indigo-rqt-ez-publisher", "$ sudo apt-get install ros-hydro-rqt-ez-publisher", "$ rosrun rqt_ez_publisher rqt_ez_publisher", "$ rqt", "qt_gui_main() found no plugin matching \"rqt_ez_publisher\"", "$ rm ~/.config/ros.org/rqt_gui.ini"]},
{"url": "https://wiki.ros.org/qb_device_srvs", "package": "qb_device_srvs", "package_summary": ["This package contains the device-independent custom ROS services for qbrobotics\u00ae devices."], "package_details": ["\n", "Each ", " device-independent custom ROS service is documented directly in its ", " specification and it is designed to fit the Communication Handler requirements (cf. ", "). We recommend not to use these services for other purposes outside the ", " ecosystem. "], "package_tt": [".srv"]},
{"url": "https://wiki.ros.org/rsv_balance_gazebo", "package": "rsv_balance_gazebo", "package_summary": ["Gazebo's specific packages for RoboSavvy's balance platform."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", " ", "This package provides all the necessary URDF model extensions, worlds and launch files for successfully simulating ", "'s self-balance platform. ", "On ", " package we have available 3 worlds: "], "package_tt": ["rsv_balance_gazebo", "empty.world", "ramp.world", "terrain.world", "/cmd_vel", "/tilt_equilibrium", "/odom", "/state", "/joint_states", "/tf", "/set_mode", "/set_input", "/reset_odom", "/reset_override", "robotNamespace", "str", "commandTopic", "str", "publishOdomTF", "bool", "baseFrameId", "str", "odomFrameId", "str", "odomSource", "str", "odomTopic", "str", "publishWheelJointState", "bool", "startMode", "str", "publishState", "bool", "publishStateRate", "int", "updateRate", "int"], "package_code": [" roslaunch rsv_balance_gazebo simulation_empty.launch", " roslaunch rsv_balance_gazebo simulation_ramp.launch", " roslaunch rsv_balance_gazebo simulation_terrain.launch", "roslaunch rsv_balance_gazebo view.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/applanix_msgs", "package": "applanix_msgs", "package_summary": ["\n    ROS messages which represent the serialized wire messages and groups of Applanix devices.\n  "]},
{"url": "https://wiki.ros.org/pr2_teleop", "package": "pr2_teleop", "package_summary": ["The pr2_teleop package"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Note: before moving the robot base, you may want to ", ". ", "As with all applications, you must first ", ". ", "Before use, the PS3 controller must be \"paired\" with the robot. If your controller is not already paired, you can pair it by pressing the center button, shown in the image.  If you need to pair a new PS3 controller to the PR2 (i.e. not the controller that came with it), see ", ". ", "Note: The ", ", ", ", ", ", and ", " buttons are all labeled on the controller.  ", "Now you should be able to control the robot base with keyboard commands in the shell where you ran the above ", " command.   "], "package_code": ["roslaunch pr2_teleop teleop_joystick.launch", "roslaunch pr2_teleop teleop_keyboard.launch"]},
{"url": "https://wiki.ros.org/bwi_guidance_concert", "package": "bwi_guidance_concert", "package_summary": ["Wraps a Human-Robot Interaction Experiment conducted at the\n    University of Texas At Austin to use the Robotics in Concert Framework. The\n    results from this experiment were reported in the following symposium\n    paper: Piyush Khandelwal and Peter Stone. Multi-robot Human Guidance using\n    Topological Graphs. In AAAI Spring 2014 Symposium on Qualitative\n    Representations for Robots (AAAI-SSS), March 2014."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package wraps this experiment to use the ", " framework. ", "This package currently wraps preliminary work on this project, where a central positioner node teleports each robot to a desired location using Gazebo's ", " service. Additionally, each robot subscribes to an image stream which is displayed on its simulated robot screen (ex. '/robot1/image'), and these images are also published by the positioner. ", "Apart from the positioner node, an experiment controller node decides which exact problem the user is facing, and a server node keeps track of which user is interfacing with the system. A user controls a human avatar inside the simulator using a web based GUI that talks to the rest of the system using ", ". ", "Once you get to the ", " page, follow the instructions to run through the experiment! "], "package_tt": ["bwi_guidance_concert", "set_model_state", "/var/www", "index.html"], "package_code": ["sudo apt-get install apache2", "- git: {local-name: segbot_rocon, uri: 'https://github.com/utexas-bwi/segbot_rocon.git', version: master}\n", "- git: {local-name: bwi_guidance, uri: 'https://github.com/utexas-bwi/bwi_guidance.git', version: master}\n", "- git: {local-name: rl_pursuit, uri: 'https://github.com/utexas-bwi/rl_pursuit.git', version: master}\n", "- git: {local-name: rosbridge_suite, uri: 'https://github.com/piyushk/rosbridge_suite.git', version: patch-1}", "sudo ln -sf `rospack find bwi_guidance`/www /var/www/exp1", "roscd bwi_guidance_solver/data/exp2/cache\n", "wget http://cs.utexas.edu/~piyushk/share/vi.tar.gz\n", "tar xvzf vi.tar.gz\n", "rm vi.tar.gz", "roslaunch bwi_guidance_solver server.launch --screen", "rocon_launch bwi_guidance_concert guidance.concert --screen", "http://localhost/exp1/index.html", "http://robot-devil.csres.utexas.edu/exp1/index.html?host=robot-devil.csres.utexas.edu", "http://robot-devil.csres.utexas.edu/exp1/index.html?host=robot-devil.csres.utexas.edu&concert=true", "http://robot-devil.csres.utexas.edu/exp1/link.html"]},
{"url": "https://wiki.ros.org/fake_localization", "package": "fake_localization", "package_summary": ["A ROS node that simply forwards odometry information."], "package_details": ["\n", "\n", "The ", " package provides a single node, ", ", which substitutes for a localization system, providing a subset of the ROS API used by ", ". This node is most frequently used during simulation as a method to provide perfect localization in a computationally inexpensive manner. ", "Specifically, ", " converts odometry data into pose, particle cloud, and transform data of the form published by ", ". "], "package_tt": ["fake_localization", "fake_localization", "fake_localization", "fake_localization", "base_pose_ground_truth", "initialpose", "amcl_pose", "particlecloud", "~odom_frame_id", "string", "\"odom\"", "~delta_x", "double", "fake_localization", "~delta_y", "double", "fake_localization", "~delta_yaw", "double", "fake_localization", "~global_frame_id", "string", "global_frame_id", "odom_frame_id", "~base_frame_id", "string", "/map", "<value\u00a0of\u00a0odom_frame_id\u00a0parameter>"]},
{"url": "https://wiki.ros.org/tuw_msgs", "package": "tuw_msgs", "package_summary": ["The tuw_msgs meta package"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/rwt_image_view", "package": "rwt_image_view", "package_summary": ["The rwt_image_view package"]},
{"url": "https://wiki.ros.org/multimaster_fkie", "package": "multimaster_fkie", "package_summary": ["The metapackage to combine the nodes required to establish and manage a multimaster network. \n    This requires no or minimal configuration. The changes are automatically detected and synchronized."], "package_details": [" ", " - Technical Report by Sergi Hernandez Juan and Fernando Herrero Cotarelo ", "\n", " "]},
{"url": "https://wiki.ros.org/rosparam_handler", "package": "rosparam_handler", "package_summary": ["An easy wrapper for using parameters in ROS."]},
{"url": "https://wiki.ros.org/ddwrt_access_point", "package": "ddwrt_access_point", "package_summary": ["\n    A ROS node that controls a Linksys WRT610Nv2 access point with\n    a dd-wrt firmware. Other access points models/dd-wrt versions\n    may be compatible as long as the web interface is identical.\n  "], "package_details": ["\n", "Provides a node for controlling a Linksys WRT610Nv2 (or compatible) access point with the ", " firmware. It has been tested with the firwmare version ", ". Other dd-wrt firmware versions and access point models may be compatible with this node provided the web interface is the same. ", "See ", " and ", " for more details. "]},
{"url": "https://wiki.ros.org/sr_communications", "package": "sr_communications", "package_summary": ["communications for the Social Robots robots"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/libsensors_monitor", "package": "libsensors_monitor", "package_summary": ["A ROS node for using libsensors to provide diagnostics information about the sensors on a computer system."], "package_details": ["\n", "\n", "\n"], "package_tt": ["/diagnostics", "~ignore_sensors", "string[]"]},
{"url": "https://wiki.ros.org/rail_mesh_icp", "package": "rail_mesh_icp", "package_summary": ["Enables matching a mesh model file (e.g. STL) to a point cloud using ROS."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", "The intended use for ", " is to allow RGBD sensing platforms using ROS to match a mesh model (e.g. an STL file) to point clouds. This is useful in cases where an accurate estimate of the model's 6-DoF pose in the point cloud is needed (e.g. grasping/manipulation). ", "To install the ", " package, you can install from source with the following commands: ", "can read the file format and convert it to a point cloud. In Ubuntu, [Mesh Lab](", ") allows  you to import many mesh model formats (e.g. STL, PLY, DAE) and convert them to PLY via the ", " and  ", " options. ", "[INPUT_MESH_MODEL].ply [OUTPUT_POINT_CLOUD].pcd", "-h`. "], "package_tt": ["rail_mesh_icp", "template_matcher_node", "icp_matcher_node", "<~/pcl_topic\u00a0parameter>", "~/template_points", "~/target_points", "~/matched_template_points", "~/match_template", "~/debug", "bool", "~/matched_template_points", "~/visualize", "bool", "~/template_frame", "~/pcl_topic", "string", "~/pre_processed_cloud", "~/pre_processed_cloud", "bool", "target_cloud", "~/match_template", "~/pcl_topic", "~/template_file", "string", "cad_models", "~/matching_frame", "string", "~/initial_estimate_string", "string", "~/matching_frame", "latch_initial", "~/latch_initial", "bool", "~/initial_estimate_string", "initial_estimate", "~/match_template", "~/template_offset_string", "string", "~/template_frame", "string", "~/visualize", "icp_matcher_node", "/icp_match_clouds", "/icp_matcher_node/iterations", "int", "/icp_matcher_node/max_distance", "float", "/icp_matcher_node/trans_epsilon", "float", "/icp_matcher_node/fit_epsilon", "float", "mesh_sampler_node", "-h", "rail_mesh_icp", ".ply", "Import\u00a0Mesh", "Export\u00a0Mesh", ".\u00a0Optional\u00a0arguments,\u00a0like\u00a0sampling\u00a0density,\u00a0are\u00a0detailed\u00a0using\u00a0", ".pcd", "cad_models", "corner.pcd", "cad_models", "template_match_demo.launch", "roslaunch\u00a0fetchit_challenge\u00a0main.launch", "roslaunch\u00a0fetch_navigation\u00a0build_map.launch", "rosrun\u00a0teleop_twist_keyboard\u00a0teleop_twist_keyboard.py", "/head_camera/depth_registered/points", "roslaunch\u00a0rail_mesh_icp\u00a0template_match_demo.launch", "template_matcher_node", "corner", "icp_matcher_node", "initial_estimate", "template_matcher_node", "initial_estimate", "initial_estimate", "template_match_demo.launch", "static_transform_publisher", "rosservice\u00a0call\u00a0/template_matcher_demo_node/match_template", "template_pose", "template\u00a0pose", "template_offset", "debug", "target_points", "template_points", "matched_template_points", "template_match_demo.launch", "initial_estimate", "template_offset", "provide_processed_cloud", "latch_initial_estimate", "template_filename", "initial_estimate", "~match_template"], "package_code": ["\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rospy_tutorials", "package": "rospy_tutorials", "package_summary": ["This package attempts to show the features of ROS python API step-by-step,\n    including using messages, servers, parameters, etc. These tutorials are compatible with the nodes in roscpp_tutorial."], "package_details": ["\n", "rospy_tutorials is a series of tutorials for using the ", " client API. You can browse these tutorials by ", "-ing to the ", " package, i.e. "], "package_tt": ["roscd", "rospy_tutorials", "Makefile"], "package_code": ["roscd rospy_tutorials"]},
{"url": "https://wiki.ros.org/xbot_face", "package": "xbot_face", "package_summary": ["The xbot_face package"], "package_details": ["\n", "\n", " ", "\n", " ", "\n"], "package_tt": ["face_recog", "/xbot/camera/image", "/xbot/face_result", "camera_image_publisher", "/xbot/camera/image", "/xbot/camera/image"]},
{"url": "https://wiki.ros.org/rtt_ros_comm", "package": "rtt_ros_comm", "package_summary": ["The rtt_ros_comm package"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "  "], "package_code": ["sudo aptitude install ros-electric-rtt-ros-comm", "git clone http://git.mech.kuleuven.be/robotics/rtt_ros_comm.git\n", "rosmake rtt_ros_comm"]},
{"url": "https://wiki.ros.org/tedusar_cartesian_controller", "package": "tedusar_cartesian_controller", "package_summary": ["A controller for ros_control enabling moving an arm's tool frame in a cartesian coordinate frame."]},
{"url": "https://wiki.ros.org/laser_joint_processor", "package": "laser_joint_processor", "package_summary": ["Computes joint angles associated with a specific set of detected checkerboard corners.\n     This package is experimental and unstable.\n     Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rtt_ros_integration", "package": "rtt_ros_integration", "package_summary": ["This stack contains all software necessary to build systems using both Orocos and ROS infrastructures"], "package_code": ["rosrun rtt_ros_integration create_rtt_msgs MyPkg", "  <depend package=\"rtt_MyPkg\"/>", "#include <MyPkg/typekit/MsgName.h>", "import(\"OrocosPkg\")", "var ConnPolicy cp;\n", "cp.transport = 3; // ROS == 3\n", "cp.name_id = \"/topic_name\"; // ros topic", "stream(\"YourComponentName.YourRTTPortName\", cp ) ", "<simple name=\"Import\" type=\"string\"><value>rtt_ros_integration</value></simple>\n", "<struct name=\"ROSConMsg\" type=\"ConnPolicy\">\n", "  <simple name=\"transport\" type=\"short\"><value>3</value></simple><!-- 3 means ROS --/>\n", "  <simple name=\"name_id\" type=\"string\"><value>topic_name</value></simple>\n", "</struct>", "<struct name=\"Ports\" type=\"PropertyBag\">\n", "  <simple name=\"YourRTTPortName\" type=\"string\"><value> RosConMsg </value></simple>\n", "</struct>", "rosrun rtt_ros_integration create_rtt_msgs MyPkg", "  <depend package=\"rtt_MyPkg\"/>", "#include <MyPkg/typekit/MsgName.h>", "import(\"OrocosPkg\")", "var ConnPolicy cp;\n", "cp.transport = 3; // ROS == 3\n", "cp.name_id = \"/topic_name\"; // ros topic", "stream(\"YourComponentName.YourRTTPortName\", cp ) ", "<simple name=\"Import\" type=\"string\"><value>rtt_ros_integration</value></simple>\n", "<struct name=\"ROSConMsg\" type=\"ConnPolicy\">\n", "  <simple name=\"transport\" type=\"short\"><value>3</value></simple><!-- 3 means ROS --/>\n", "  <simple name=\"name_id\" type=\"string\"><value>topic_name</value></simple>\n", "</struct>", "<struct name=\"Ports\" type=\"PropertyBag\">\n", "  <simple name=\"YourRTTPortName\" type=\"string\"><value> RosConMsg </value></simple>\n", "</struct>", "sudo aptitude install ros-electric-rtt-ros-integration", "git clone http://git.mech.kuleuven.be/robotics/rtt_ros_integration.git\n", "rosmake rtt_ros_integration", "rosrun rtt_rosnode rtt-upgrade-2.5 <package_dir>", "rosrun rtt_rosnode create_rtt_msgs MyPkg", "  <depend package=\"rtt_MyPkg\"/>", "#include <MyPkg/typekit/MsgName.h>", "rosrun ocl orocreate-pkg my_component_pkg component\n", "cd my_component_pkg\n", "rosmake", "rosrun ocl deployer-gnulinux [-s scriptname.ops]", "import(\"rtt_rosnode\") // makes this process a ROS node\n", "import(\"my_component_pkg\")\n", "loadComponent(\"YourComponentName\",\"My_component_pkg\")\n", "// See DeploymentComponent Manual for creating a component using 'loadComponent'", "stream(\"YourComponentName.YourRTTPortName\", ros.topic(\"/topic_name\")) ", "rosrun ocl deployer-gnulinux -s xmlfile.xml", "<simple name=\"Import\" type=\"string\"><value>rtt_rosnode</value></simple>\n", "<simple name=\"Import\" type=\"string\"><value>my_component_pkg</value></simple>\n", "<struct name=\"ROSConMsg\" type=\"ConnPolicy\">\n", "  <simple name=\"transport\" type=\"short\"><value>3</value></simple><!-- 3 means ROS --/>\n", "  <simple name=\"name_id\" type=\"string\"><value>topic_name</value></simple>\n", "</struct>", "<struct name=\"Ports\" type=\"PropertyBag\">\n", "  <simple name=\"YourRTTPortName\" type=\"string\"><value> RosConMsg </value></simple>\n", "</struct>", "sudo apt-get install ros-fuerte-rtt-ros-integration", "git clone http://git.mech.kuleuven.be/robotics/rtt_ros_integration.git -b fuerte\n", "rosmake rtt_ros_integration", "rosrun rtt_rosnode create_rtt_msgs MyPkg", "  <depend package=\"rtt_MyPkg\"/>", "#include <MyPkg/typekit/MsgName.h>", "rosrun ocl orocreate-pkg my_component_pkg component\n", "cd my_component_pkg\n", "rosmake", "rosrun ocl deployer-gnulinux [-s scriptname.ops]", "import(\"rtt_rosnode\") // makes this process a ROS node\n", "import(\"my_component_pkg\")\n", "loadComponent(\"YourComponentName\",\"My_component_pkg\")\n", "// See DeploymentComponent Manual for creating a component using 'loadComponent'", "stream(\"YourComponentName.YourRTTPortName\", ros.topic(\"/topic_name\")) ", "rosrun ocl deployer-gnulinux -s xmlfile.xml", "<simple name=\"Import\" type=\"string\"><value>rtt_rosnode</value></simple>\n", "<simple name=\"Import\" type=\"string\"><value>my_component_pkg</value></simple>\n", "<struct name=\"ROSConMsg\" type=\"ConnPolicy\">\n", "  <simple name=\"transport\" type=\"short\"><value>3</value></simple><!-- 3 means ROS --/>\n", "  <simple name=\"name_id\" type=\"string\"><value>topic_name</value></simple>\n", "</struct>", "<struct name=\"Ports\" type=\"PropertyBag\">\n", "  <simple name=\"YourRTTPortName\" type=\"string\"><value> RosConMsg </value></simple>\n", "</struct>"]},
{"url": "https://wiki.ros.org/speech_recognition_msgs", "package": "speech_recognition_msgs", "package_summary": ["speech_recognition_msgs"]},
{"url": "https://wiki.ros.org/toposens_sync", "package": "toposens_sync", "package_summary": ["Operational sync of multiple TS sensors."], "package_details": ["\n", "\n", "\n", "This package enables simultaneous use of multiple TS3 devices in a sensor system. It administers the lifecycle and ultrasonic emission characteristics of each sensor to coordinate incoming datastreams. Is is designed as a thin layer handling multiple ", "::Sensor instances that individually encapsulate all the device communication and logic flow. "], "package_tt": ["ts_scans", "~ports", "XmlRpc::XmlRpcValue", "~frame_ids", "XmlRpc::XmlRpcValue"]},
{"url": "https://wiki.ros.org/turtlebot_calibration", "package": "turtlebot_calibration", "package_summary": ["turtlebot_calibration"], "package_details": ["\n", "\n", "\n", "To use this package please follow the ", " "]},
{"url": "https://wiki.ros.org/asr_grid_creator", "package": "asr_grid_creator", "package_summary": ["This package can generate a grid for the current map. Each grid_point\n    defines a position where the robot has to move to. The grid can be used\n    later on in the asr_direct_search_manager as a basis to generate poses to\n    search the map. At each grid_point the robot will search around him. All\n    gird_points together should cover the map."], "package_details": [" ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " (MarkerArray): Visualisation of the grid ", "\n", "\n", " ", "The path to a file where the generated grid should be saved ", "\n", " ", "the width of the grid ", " the hieght of the grid !", ": the shape of each ", " It can be Hex or Quad !", ": if the generated positions should make a ", " or not ", ": start postition of the robot (for sorting the postitions) ", "\n", "\n", "roslaunch asr_robot_model_services RobotModelServiceSim.launch ", "!", ": the size of each cell or rather the half of the distance between two neighbors of ", " ", ": horizontal translation offset applied to the grid ", ": vertical translation offset applied to the grid ", ": rotation offset applied to the grid ", "The (", ") defines the ranges in which the generation took place. The best one will be saved at the end. The best grid is the one with the most ", ". ", "asr_robot_model_services: ", ", GetDistance ", "The generation of the grid is part of the ", ". "]},
{"url": "https://wiki.ros.org/toposens_msgs", "package": "toposens_msgs", "package_summary": ["ROS message definitions for TS sensors."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/khi_robot_control", "package": "khi_robot_control", "package_summary": ["ROS KHI robot controller package based on ros_control"]},
{"url": "https://wiki.ros.org/phantomx_reactor_arm", "package": "phantomx_reactor_arm", "package_summary": ["The phantomx_reactor_arm package"], "package_details": ["\n", " ", "\n", "\n", "\n", "This package contains the different controllers and description files for ", " "]},
{"url": "https://wiki.ros.org/pi_trees", "package": "pi_trees", "package_summary": ["Behavior Trees for ROS"], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "A Python implementation for using Behavior Trees and ROS for task management.  Please see the ", " or the book \"", "\". "], "package_code": ["$ sudo apt-get install graphviz-dev libgraphviz-dev python-pygraph python-pygraphviz gv\n", "$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/pirobot/pi_trees.git\n", "$ cd ..\n", "$ catkin_make"]},
{"url": "https://wiki.ros.org/rcll_ros", "package": "rcll_ros", "package_summary": ["ROS packages related to RoboCup Logistics League (metapackage)"], "package_details": ["This is a meta package covering the ROS packages related to the ", " and the ", ". ", "\n", "This metapackage pulls the ", " and ", " packages. ", "\n", "You might also want to have a look at the simulation integration package ", ". "]},
{"url": "https://wiki.ros.org/ros_opcua_impl_freeopcua", "package": "ros_opcua_impl_freeopcua", "package_summary": ["The ros_opcua_impl_freeopcua package implements bindings for freeopcua - Open Source C++ OPC-UA Server and Client Library."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", " ", "This package provides communication interface between ROS and ", " communication standard using ", " written in C++. This package currently implements an OPC UA Client with basic functionality. For more details see the node description. ", "Check the ", " page. "], "package_tt": ["connect", "disconnects", "list_node", "call_method", "read", "write", "subscribe", "unsubscribe"], "package_code": ["roslaunch ros_opcua_impl_freeopcua clinet.launch"]},
{"url": "https://wiki.ros.org/moveit_full", "package": "moveit_full", "package_summary": ["All MoveIt components and plugins"]},
{"url": "https://wiki.ros.org/unique_id", "package": "unique_id", "package_summary": ["ROS Python and C++ interfaces for universally unique identifiers."], "package_details": ["\n", "This package provides Python and C++ interfaces for ", ", as described in ", ". "]},
{"url": "https://wiki.ros.org/abb_moveit_plugins", "package": "abb_moveit_plugins", "package_summary": ["\n    ABB-specific plugins for MoveIt\n  "], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/object_recognition_tabletop", "package": "object_recognition_tabletop", "package_summary": ["A port of the old tabletop object recognition"]},
{"url": "https://wiki.ros.org/segbot_gui", "package": "segbot_gui", "package_summary": ["Displays a simple GUI to the user. The GUI is capable of displaying a simple\n    message or image to the user, and ask a question. The message and question\n    plugins are also written in this package."]},
{"url": "https://wiki.ros.org/fawkes_msgs", "package": "fawkes_msgs", "package_summary": ["Messages used by Fawkes to interact with ROS."], "package_details": ["\n", "\n", "\n", "This package contains the message types specific to the integration with the ", ". It is used in several of the ", ". ", "It is used, for example, for the ", " for ROS. "]},
{"url": "https://wiki.ros.org/vrpn_client_ros", "package": "vrpn_client_ros", "package_summary": ["ROS client nodes for the ", " library, compatible with VICON, OptiTrack, and other ", "."], "package_details": ["\n", "\n", "To debug connection issues, try to use ", "'s CLI tools, such as ", ", to verify that a connection to the Tracker object of interest can be established. If you cannot get this to work, note that debugging networking or VRPN issues is outside the scope of this ROS interface package, and see ", " for further guidance. ", "Please check the ", " for common problems, or open an ", " if still unsolved. See sample configuration launch file ", ". "], "package_tt": ["vrpn", "vrpn_print_devices\u00a0<tracker_name>@<vrpn_server>", "<tracker\u00a0name>/pose", "<tracker\u00a0name>/twist", "<tracker\u00a0name>/accel", "~update_frequency", "double", "~refresh_tracker_frequency", "double", "~trackers", "~trackers", "list", "~refresh_tracker_frequency", "~frame_id", "string", "~use_server_time", "bool", "~broadcast_tf", "bool", "/tf"]},
{"url": "https://wiki.ros.org/turtlebot_arm_moveit_demos", "package": "turtlebot_arm_moveit_demos", "package_summary": ["The turtlebot_arm_moveit_demos package contains scripts to start playing with a turtlebot arm and MoveIt."]},
{"url": "https://wiki.ros.org/socketcan_bridge", "package": "socketcan_bridge", "package_summary": ["Conversion nodes for messages from SocketCAN to a ROS Topic and vice versa."], "package_details": ["\n", "\n", "\n", "\n", "\n", "The packages provides functionality to expose CAN frames from ", " to a ROS Topic. Internally it uses the ", " from the ", " package, as such it is capable of dealing with both normal and extended CAN frames. For more information and hardware related information see ", ". ", "The functionality is offered in the form of three nodes: ", ", ", " and ", ". To receive frames from and sent frames to the same CAN device, the ", " needs to be used to prevent every sent message from being echoed to the receiving topic. "], "package_tt": ["socketcan_bridge_node", "socketcan_to_topic_node", "topic_to_socketcan_node", "socketcan_bridge_node", "sent_messages", "received_messages", "~can_device", "string", "received_messages", "~can_device", "string", "sent_messages", "~can_device", "string", "ros::Time::now()"]},
{"url": "https://wiki.ros.org/roslibjs_experimental", "package": "roslibjs_experimental", "package_summary": ["The roslibjs_experimental package"]},
{"url": "https://wiki.ros.org/mjpegcanvas", "package": "mjpegcanvas", "package_summary": ["The mjpegcanvas package"]},
{"url": "https://wiki.ros.org/sr_edc_controller_configuration", "package": "sr_edc_controller_configuration", "package_summary": ["\n\n    contains the different launch files for Shadow Robot hand controllers. The actual configuration files are stored in the sr_config stack.\n\n  "], "package_details": ["\n", "\n", "\n", "See ", " for more details on the actual implementation of the controllers. ", "The Parameters are saved in the different ", " file:  ", "The package also contains one launch file per controller type. You can change which controller is started by default by editing ", ". ", "Just make sure you only have one type of controllers started (otherwise one of them is going to be ignored by the controller manager). ", "The controller manager is started by the ", " file (which is called from ", "/sr_edc.launch file). "]},
{"url": "https://wiki.ros.org/vigir_footstep_planning", "package": "vigir_footstep_planning", "package_summary": ["The vigir_footstep_planning package is a stack for the whole footstep planning system. It contains the top-level launch files and may be used to include all dependencies."], "package_details": ["\n", " ", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", " ", "\n", " ", " Before the direction commands become activated you have to select a parameter set from the parameter selection section. ", "\n", " The terrain generator does only consider all point cloud data around the current robot pose to reduce computational cost. Therefore you should place a ", " (hotkey \"p\") in RViz in a feasible region of the input pointcloud (see below) to obtain a world model. ", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The ", " stack provides an integrated full 3D footstep planner. It was originally based on the search-based ", " (using A* from SBPL) and has been intensively extended/rewritten to enable the generation of feasible footstep placements based on perceived 3D data. It can cope with sloped terrain and uses overhanging steps to improve planning performance. The footstep planning system is designed to be easily deployable and adaptable to any humanoid bipedal robot. It can be either used as a 3D planner out of the box, as a research tool in bipedal search-based planning or for benchmarking walking controllers in difficult terrain. ", "For improvement mission performance in real world scenarios, the footstep planner implements a comprehensive set of coactive footstep planning services. In this way, it enables human-in-the-loop planning to combine human intelligence and capable footstep placement algorithms to generate quickly a safe sequence of footstep placements through challenging terrain (examples see under ", "). ", "This allows for adaptive code execution even during runtime which is superior to classic parameter-based systems. Although plugins can provide new code for the pipeline, already existing code is kept untouched which simplifies code maintenance and improves code stability. In order to achieve this kind of versatile code management, the ", " has been developed. ", "See under ", ". ", "The ", " stack consists of multiple repositories located at Git", "Hub: ", "All generated step plan are published on ", ". ", "You can just place a start pose (", " (hotkey \"p\")) and goal pose (", " (hotkey \"g\")) to trigger planning. You should be able to follow the planning process and receive a result at the end. ", "The planning system is also capable to provide manual step generation. For this purpose the ", " widget can be launched by: ", "Using this widget allows to lay down patterns of step placements manually. Each parameter can be set individually in this widget. It also includes an interface for the ", " which manages step execution on the robot. ", "For a quick demonstration of the 3D planning capabilities the ", " package can be used here. In order to use that package clone and compile from ", "Create the ", " subfolder in the ", " package. Download and extract the example pointcloud files from ", " into this recently created directory. Afterwards you are able to launch the terrain generator test environment (while the footstep planning system is already running in the background): ", "As already mentioned above, you need to set the fake robot pose by placing a ", " (hotkey \"p\"). If you place it like illustrated in the image below, then you should get a nice world model of the pitch ramp scenario. ", " ", "Please wait a few seconds until the world model is reasonable dense. Now you can request footstep plans over the pitch ramp by placing a ", " (hotkey \"g\"). After a few seconds you should see results similar to that demonstrated on the picture below: ", " ", "You can also use your own pointcloud data as the ", " can accumulate data from any arbitrary source. Just launch the standalone ", ": ", "Now you can just publish your pointcloud data as incremental updates at ", " in a common frame (e.g. ", "). ", "If you wish to just generate the terrain model from a single pointcloud, the data must be published on ", ". ", "The ", " stack is accompanied by the ", " package which enables seamless integration to the low-level motion layer. In particular, this includes step queue management and step queue spooling. Using this package should simplify integration to other robot platforms while providing high-level functionality such as continuous walking (by continuous updating the step queue). ", "The ", " stack takes heavy use of the ", " package due to heavy use of plugins (see ", "). In this step-by-step tutorial we do not discuss details about the ", " as we refer to the ", " documentation for details. We recommend to read through the basics of the ", " to understand how the footstep planning system can be customized easily. ", "Please take note of the ", " which provides seamless low-level hardware integration and step queue management in order to simplify even more the migration process while providing a capable step queue management system that allows even for continuous walking. ", "During the Humanoids@Robo", "Cup Demo 2016 at Leipzig, the footstep planner was used as well. ", "If you would like to try it out in simulation by yourself, then just follow the install instruction of the basic THORMANG software ", " which provides a fully working robot using Gazebo simulation. ", "When Gazebo has started up, first unpause the simulator. Afterwards, you can bring the robot in ", " mode by using the ", ". You have to proceed following states with the robot: ", "From this point, you can work with the ", ". After selecting a parameter set you can command simple step patterns and directly execute them afterwards. As long you do not push the limits too hard, the robot will execute the steps safely in simulation. ", "As explained ", " you can use RViz to generate step plans. After a step plan has been generated you can hit the ", " button in the ", " which will then execute the recently generated plan. "], "package_tt": ["pcl", "vigir_terrain_classifier", "/vigir/terrain_classifier/point_cloud_update", "/world", "/vigir/terrain_classifier/set_point_cloud", "walk", "stand_prep", "stand", "walk"], "package_code": ["@INPROCEEDINGS{2016:Humanoids-Stumpf,\n", "  author = {Stumpf, Alexander and Kohlbrecher, Stefan and Conner, David C and von Stryk, Oskar},\n", "  title = {Open source integrated 3D footstep planning framework for humanoid robots},\n", "  booktitle = {Humanoid Robots (Humanoids), 2016 IEEE-RAS 16th International Conference on},\n", "  pages = {938--945},\n", "  year = {2016},\n", "  organization = {IEEE}\n", "}", "@INPROCEEDINGS{2014:Humanoids-Stumpf,\n", "  author = {Supervised Footstep Planning for Humanoid Robots in Rough Terrain Tasks using a Black Box Walking Controller},\n", "  title = {Supervised Footstep Planning for Humanoid Robots in Rough Terrain Tasks using a Black Box Walking Controller},\n", "  year = {2014},\n", "  pages = {287-294},\n", "  month = {Nov 18-20},\n", "  address = {Madrid, Spain},\n", "  booktitle = {Proc. IEEE-RAS Intl. Conf. Humanoid Robots},\n", "}", "@ARTICLE{2016:FRAI-Kohlbrecher-etal,\n", "  author = {Kohlbrecher, Stefan and Stumpf, Alexander and Romay, Alberto and Schillinger, Philipp and von Stryk, Oskar and C. Conner, David},\n", "  title = {A comprehensive software framework for complex locomotion and manipulation tasks applicable to different types of humanoid robots},\n", "  journal = {Frontiers in Robotics and AI},\n", "  year = {2016},\n", "  pages = {online},\n", "  doi = {10.3389/frobt.2016.00031},\n", "  url = {http://journal.frontiersin.org/article/10.3389/frobt.2016.00031},\n", "}", "roslaunch vigir_footstep_planning footstep_planner_test.launch", "roslaunch vigir_footstep_planning rviz_footstep_planning.launch", "roslaunch vigir_footstep_planning step_interface_rqt.launch", "https://github.com/team-vigir/vigir_terrain_classifier.git", "roslaunch vigir_terrain_classifier terrain_classifier_test.launch", "roslaunch vigir_terrain_classifier terrain_classifier.launch", "thor install footstep_planning ui", "thor make", "roscore\n", "thor sim\n", "roslaunch thor_mang_footstep_planner thor_mang_footstep_planner.launch\n", "thor ui supervisor\n", "thor ui step_interface_rqt", "thor ui rviz_thor_mang_default.launch"]},
{"url": "https://wiki.ros.org/roswtf", "package": "roswtf", "package_summary": ["roswtf is a tool for diagnosing issues with a running ROS system. Think of it as a FAQ implemented in code."], "package_details": ["\n", " will examine your ROS setup, such as your ", ", and look for configuration issues. If you have a ROS system online, it will look at it and check for any potential issues. ", "\n", "\n", ": ", " performs those checks based on the directory you run it from. For example, if you run it in the ", " stack, it will perform it's filesystem checks based on files in the ", " stack and its dependencies.  ", "\n", "\n", " accepts the following command-line options: ", "\n", " looks for many, many things, and the list is always growing. There are two categories of what it looks for: file-system issues and online/graph issues. ", "\n", " produces a report containing both warnings and errors based on the checks it performed. In general, warnings are something that seems odd, but may be just fine. Errors are known problems that you should probably address if you are experiencing problems. ", "\n", "\n", " will continue to evolve to try and diagnose more complex problems that may arise in large ROS systems. There are currently plans to do checks for multi-machine setups, as well as expand the range of its checks via the plugin API.  Recommendations for checks that can be performed are always welcome. ", "Other than the general checks, ", " has two usages. ", "Or you can also run ", " on a ", " file: ", "For file-system issues, ", " looks at your environment variables, package configurations, stack configurations, and more. It can also take in a ", " file and attempt to find any potential configuration issues in it, such as packages that haven't been built properly. ", "For online issues, ", " examines the state of your current graph and tries to find any potential issues. These issues might be unresponsive nodes, missing connections between nodes, or potential machine-configuration issues with ", ". ", "Please see ", ". "], "package_tt": ["roswtf", "roswtf", "roswtf", "navigation", "roswtf", "roswtf", "--all", "roswtf", "ROS_PACKAGE_PATH", "--no-plugins", "roswtf", "--offline", "roswtf", "roswtf", "roswtf", "roswtf", "roswtf"], "package_code": ["$ roswtf", "$ roswtf yourfile.launch"]},
{"url": "https://wiki.ros.org/rplidar_ros", "package": "rplidar_ros", "package_summary": ["The rplidar ros package, support rplidar A2/A1 and A3/S1"]},
{"url": "https://wiki.ros.org/kobuki_desktop", "package": "kobuki_desktop", "package_summary": ["Visualisation and simulation tools for Kobuki"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/transform_graph", "package": "transform_graph", "package_summary": ["Library for computing transformations in arbitrary graph structures."], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " is a library for computing transformations between coordinate frames in an arbitrary graph structure. ", "\n", " maintains the graph of transformations and is the primary interface to transform_graph: ", " ", "The library's generated documentation explains how to use ", " in detail. ", "Below are a few quick examples illustrating how it can be used. ", "Add frames to the graph using ", ": ", "Get points in different frames using ", ". ", "In this example, we want to know what a point 10 cm in front of the robot's wrist is, expressed in the base frame: "], "package_tt": ["transform_graph", "transform_graph", "transform_graph", "transform_graph", "transform_graph", "transform_graph", "transform_graph::Graph", "transform_graph::Graph::Add", "transform_graph::Graph::DescribePosition"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/osg_interactive_markers", "package": "osg_interactive_markers", "package_summary": ["This package is basically an OpenSceneGraph (OSG) adaptation of the Interactive Markers client writen for rviz/Ogre."], "package_details": ["\n", "\n", " ", "\n", " does not currently offer all the potential of Interactive Markers. However, the most frequent use cases should be supported. ", "This package is basically an ", " (OSG) adaptation of the ", " client writen for rviz/Ogre. Most of the code has been taken from the rviz sources, and adapted to use OSG data types and facilities when possible. It allows the creation of Interactive Markers in ", " applications. ", "Let's have a look to the ", " example, inside the ", " package: ", "The example above creates an ", " application that listens for Interactive Markers in the ", " topic. By running the above example and the ", " tutorial in different terminals you should see something like the following: ", "Let's have a look to the code required for setting the Interactive Markers client. First you need to create a ", " instance and set the fixed frame where you expect the markers to be referenced to. After that, ", " is the main class you have to instantiate, giving as input the topic where to listen to Interactive Markers, a node in your OSG scene that will hold the geometry, and a TF client:  "], "package_tt": ["osg_interactive_markers_demo.cpp", "osg_interactive_markers", "basic_controls/update", "osg_interactive_markers"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ rosrun osg_interactive_markers osg_interactive_markers_demo", "$ rosrun interactive_marker_tutorials basic_controls", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/contact_handler", "package": "contact_handler", "package_summary": ["The contact_handler package. It reports the dynamic-engine-reported contacts between\n      all scene objects on a topic called \"contacts\".\n\n      This package uses gazebo_msgs/ContactsState message type to report body contacts.\n      This is because ROS doesn't have any standardized contact reporting messages.\n      However, to have gazebo_msgs, you don't need to install whole Gazebo, you just need to\n      install the single package ros-indigo-gazebo-msgs."]},
{"url": "https://wiki.ros.org/network_detector", "package": "network_detector", "package_summary": ["\n\n     A ROS node that watches a given network interface and publishes\n     whether it is both UP and RUNNING (indicating that a cable is\n     plugged into it and communication is happening, for instance) or\n     not.\n\n  "]},
{"url": "https://wiki.ros.org/win_dateutil", "package": "win_dateutil", "package_summary": ["Scripts to help download, patch and compile python dateutil."]},
{"url": "https://wiki.ros.org/uos_tools", "package": "uos_tools", "package_summary": ["Various helper utilities not associated with a particular stack"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/homer_robot_face", "package": "homer_robot_face", "package_summary": ["An application to display a talking head on your robot for human robot interaction."]},
{"url": "https://wiki.ros.org/mvsim", "package": "mvsim", "package_summary": ["Node for the \"multivehicle simulator\" framework."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", " (default: 0.2) ", "\n", " \u2192 ", " ", " \u2192 ", " ", " \u2192 ", " ", "The ", " node wraps Multi-Vehicle Simulator library (libmvsim). It loads a ", " file and exposes vehicles, sensors and wheel forces via ROS.  ", "If there is only one vehicle defined in the world file, all of these topics appear at the top namespace. However, if more than one vehicle exist, topics are placed into their own namespaces like ", " , e.g., ", " etc. ", "If there is only one vehicle defined in the world file, all of these topics appear at the top namespace. However, if more than one vehicle exist, topics are placed into their own namespaces like ", " , e.g., ", " etc. ", "The ", " topic gives simulated odometry, while ", " always provides a perfect, globally referenced pose. "], "package_tt": ["mvsim_node", "world", "veh<i>/", "veh0/cmd_vel", "cmd_vel", "veh<i>/", "veh0/odom", "odom", "base_pose_ground_truth", "<LASER_SENSOR_NAME>", "odom", "base_pose_ground_truth", "~base_watchdog_timeout", "cmd_vel", "base_link", "base_<LASER_SENSOR_NAME>", "base_footprint", "base_link", "odom", "base_footprint"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-mvsim", "    roslaunch mvsim mvsim_demo_2robots.launch"]},
{"url": "https://wiki.ros.org/khi_rs080n_moveit_config", "package": "khi_rs080n_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the khi_rs080n with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/kuka_rsi_simulator", "package": "kuka_rsi_simulator", "package_summary": ["Python node that implements a minimal RSI interface simulator."], "package_details": ["\n", "\n", "This package is part of the ", " program. ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/maggie_teleop", "package": "maggie_teleop", "package_summary": ["teleoperation"], "package_details": ["\n", "\n", "This package provides an launch file for running ", " in a configuration that allows it to run in parallel with the ", " stack on the ", ". "], "package_tt": ["teleop_joy.launch", "teleop_keyboard.launch"]},
{"url": "https://wiki.ros.org/ros_ethercat_model", "package": "ros_ethercat_model", "package_summary": ["The mechanism model"]},
{"url": "https://wiki.ros.org/vrmagic_ros_bridge_server", "package": "vrmagic_ros_bridge_server", "package_summary": ["This Package contains a ROS-brige for the VRMagic Smartcameras. There is a\n\tROS-node (vrmagic_ros_bridge_server), which is the Server for the ROS-brige,\n  \tand firmware for the VRMagic Smartcam. On the Smartcam the User have to implement a firmware and have\t\n\tto use the Class VrMagicHandler_camhost for communication with the vrmagic_ros_bridge_server.\n\tEach Image which is transmitted to the vrmagic_ros_bridge_server by using the Class VrMagicHandler_camhost\n  \twill be published as Image via ROS. Multiple Images are also possible."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", " the following explanations are extracted from demo_app. ", "\n", "\n", " The demo application is written for a D3-Multisensor smart cam from VRMagic. ", " ", "This package contains a ROS bridge for the VRMagic smart cameras. It includes a ROS server node named ", ", and a firmware interface for VRMagic smart cams. The firmware interface is implemented as C++ class (", ") and needs to be included in the user's application. Smart cam images are transmitted to the ", " via this interface. The camhost server provides a ROS multi-channel publisher for the multi-sensor devices. ", "The node receives from the VRMagic smart cam an image via the ", " class. Each image must have an ID representing a specific channel. An individual publisher is instanciated for each ID. The node verifies for incoming images whether a publisher is already instanciated. New publishers are created during runtime with the following convention for the topic name: <base_topic> + ID, (e.g. base_topic:\"topicname\", ID:1 -> \"topicname1\"). ", "Or use a launch file and roslaunch with the parameters described in ", " ", "To use the ROS bridge you have to be familiar with the VRMagic camera user guide, which you can find on the ", ". ", "To use the ROS bridge in your applications, the folder ", " ", "in ", " has to be copied in your application's source folder. You have to add all ", " files in ", " to your ", ". ", "In the first step a ", " - object must be instanciated. For that the header file from the class needs to be included. ", "A connection to the ROS server can be established by calling the ", " method. This method blocks until a connection to the ROS server can be established. ", "With the method ", " an image is transmitted to the ROS server. Create and fill an instance of ", " with information about the image format. Image data is passed via the pointer variable ", ". ", "After filling the ", "-object, it must be transmitted to the ROS bridge with the method ", ", see the following code: ", "The example application is located in the folder ", ". ", "To build the demo application, copy the whole ", " folder to the location where the VRMagic SDK is installed (host PC or virtual machine).  ", "Type ", "To execute the demo application, copy the binary in ", " named ", " to your VRMagic smart cam. Now execute the demo application on the VRMagic smart cam: "], "package_tt": ["vrmagic_ros_bridge_server", "VrMagicHandler_camhost", "vrmagic_ros_bridge_server", "VrMagicHandler_camhost", "VrMagicHandler_camhost", "firmware/src/", ".cpp", "VrMagicHandler_camhost", "Makefile", "VrMagicHandler_camhost", "connect()", "writeImage(ohm::ImageType&\u00a0image)", "ohm::ImageType", "image_ptr", "unsigned\u00a0int\u00a0channels", "unsigned\u00a0int\u00a0channels", "ohm::ImageType.id", "ohm::ImageType.dataSize", "ohm::ImageType.dataType", "ohm::ImageType.compressionType", "ohm::ImageType.width", "ohm::ImageType.height", "ohm::ImageType.channels", "ohm::ImageType.bytePerPixel", "ohm::ImageType.data", "ImageType", "ohm::ImageType", "writeImage(ohm::ImageType&\u00a0image)", "VrMagicHandler_camhost", "Makefile", "VrMagicHandler_camhost/", "firmware/src/demp_app", "firmware", "firmware/src/demo_app", "ros_bridge_demo_app", "<your_base_topicname>1"], "package_code": [" $ cd \"Path_to_catkin_ws\"/src/\"\n", " $ git clone https://github.com/ohm-ros-pkg/vrmagic_drivers.git", " $ rosrun vrmagic_ros_bridge_server vrmagic_ros_bridge_server_node _pub_name:=<topicname> _ip_smartcam:=<ip> _port_smartcam:=<port>", " $ rosrun vrmagic_ros_bridge_server vrmagic_ros_bridge_server_node _pub_name:=vrmagic_image_ _ip_smartcam:=192.168.3.100 _port_smartcam:=1234", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " $ cd firmware/\n", " $ make", " $ cd where_you_copied_the_binary/\n", " $ ./ros_bridge_demo_app", " $ rosrun image_view image_view image:=/<your_base_topicname>1", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/shadow_robot", "package": "shadow_robot", "package_summary": ["\n\n  This stack regroups the different ros interfaces developped for Shadow Robot's\n  Hardware. It provides an interface to both simulated and real hardware.\n\n  "], "package_details": ["Our documentation can be found on ", ". "]},
{"url": "https://wiki.ros.org/maggie_create_map", "package": "maggie_create_map", "package_summary": ["create map for Social Robot Maggie."], "package_details": ["\n", "\n", "\n"], "package_code": [" $ roslaunch maggie_create_map maggie_mapping.launch robot:=maggie", " $ roslaunch maggie_create_map save_map.launch robot:=maggie"]},
{"url": "https://wiki.ros.org/default_cfg_fkie", "package": "default_cfg_fkie", "package_summary": ["The configuration node loads a given launch configuration and offers services to \n     list or start the contained nodes. It provides additional description \n     extracted from launch file. This is used by node_manager_fkie."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " node offers a list of nodes, which can be started by calling a service with name of the node. Thus the needed nodes can be launched on demand without knowing the details of the configuration to run those. To configure the list with nodes a ROS launch file is used. ", "While loading a launch file by the ", " some addtional parameters are parsed to obtain a description of robots, nodes and capabilities configured by the launch file. This description is used in ", " to show additional information for nodes. The ", " shows the usage of additional description. ", "You can run the node without parameter and use the ", " service to load a launch configuration. "], "package_tt": ["default_cfg", "default_cfg", "~load", "~list_nodes", "~run", "~description", "~list_nodes", "~run", "~description", "~reload", "~package", "String", "''", "~launch_file", "String", "''", "~argv", "list", "[str]"], "package_code": ["rosmake default_cfg_fkie", "catkin_make", "rosrun default_cfg_fkie default_cfg _package:=@PACKAGE_NAME@ _launch_file:=@FILE_NAME@"]},
{"url": "https://wiki.ros.org/nao_teleop", "package": "nao_teleop", "package_summary": ["\n\n     Teleoperation (gamepad or joystick) for the Nao humanoid\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "Then start ", " either on your local machine or on the Nao (nao_walker and nao_controller are required by this node). By default, gamepad teleoperation starts paused. Just hit the \"toggle control button\" (#8 by default or #9 on PS3 controller) and start walking Nao around by setting the velocities for the OmniWalk engine with the two sticks on the gamepad (see below). ", "You can teleoperate Nao using any joystick or gamepad configured in ROS with omnidirectional velocities, very similar to ", ". The following commands are currently implemented (tested on a Logitech Cordless Rumblepad II, where the button numbering should be increased by one as it starts with \"1\"): "], "package_tt": ["joy", "cmd_vel", "motion_command_btn", "head_angles", "speech", "~axis_*", "int", "axis_", "axis_x", "~btn_*", "int", "btn_", "~max_vx", "double", "~max_vy", "double", "~max_vw", "double"], "package_code": ["roslaunch nao_teleop teleop_joy.launch"]},
{"url": "https://wiki.ros.org/ros_control_boilerplate", "package": "ros_control_boilerplate", "package_summary": ["Simple simulation interface and template for setting up a hardware interface for ros_control"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/sr_gui_controller_tuner", "package": "sr_gui_controller_tuner", "package_summary": ["\n\n     sr_gui_controller_tuner is a rosgui plugin for tuning the sr_mechanism_controllers\n\n  "], "package_details": [" ", " "]},
{"url": "https://wiki.ros.org/asmach_tutorials", "package": "asmach_tutorials", "package_summary": ["\n    This package containes numerous examples of how to use SMACH. See the examples directory.\n  "]},
{"url": "https://wiki.ros.org/odva_ethernetip", "package": "odva_ethernetip", "package_summary": ["Library implementing ODVA EtherNet/IP (Industrial Protocol)."]},
{"url": "https://wiki.ros.org/turtlebot3_autorace_core", "package": "turtlebot3_autorace_core", "package_summary": ["TurtleBot3 AutoRace ROS package that TurtleBot3 Auto's core"], "package_details": [" ", "\n", "\n", "\n", "\n"], "package_tt": ["detect/traffic_sign", "core/returned_mode", "core/decided_mode", "detect/parking_lot_stamped", "detect/level_crossing_stamped", "detect/tunnel_stamped", "detect/traffic_light_order", "detect/parking_lot_order", "detect/level_crossing_order", "detect/tunnel_order", "core/returned_mode"]},
{"url": "https://wiki.ros.org/rosh_desktop_plugins", "package": "rosh_desktop_plugins", "package_summary": ["\n\n    ROSH plugins related to the desktop variant. \n\n  "], "package_details": ["\n", "\n", "Please see the ", " documentation to get started. ", "rosh_desktop_plugins is an ", " development stack for using  ", ". As rosh has APIs that reach across many ROS libraries, such as ", ", ", ", and ROS itself, this stack is being used to unify the development.  This stack is expected to disappear as ", " and its related plugins mature. ", "rosh_robot_plugins houses stacks related to the \"desktop\" variant, which was introduced in ", ". The desktop plugins mainly focus on ", "-based capabilities. "]},
{"url": "https://wiki.ros.org/dense_laser_assembler", "package": "dense_laser_assembler", "package_summary": ["Stores streaming data from a laser sensor in a\n    dense representation. This allows the user to do 'image-like'\n    processing on the data, and can also be used for very fast approx\n    neighborhood searches.  This package is still experimental and unstable.\n    Expect its APIs to change."], "package_details": ["\n", "\n", " ", "\n ", "- ", " - A single range/intensity reading from a laser scanner. Takes approx 17 \u03c5s to acquire ", "\n ", "- ", " - Data collected during a single revolution of a laser scanner. Takes approx 25 ms to acquire, and consists of 100's of rays ", "\n ", "- ", " - Data collected during monotonic motion of the tilting_stage on the PR2. Usually takes 2-10 seconds to acquire, and consists of 100's of scans ", "\n ", " ", " ", "\n", " ", "A 'typical' Laser", "Scan message will also be published, providing config information for each scan. This includes info like min-angle, max-angle, angle-increment, time-increment, etc. Currently, we assume that the config information is consistent across all scans in a dense laser scan. ", "It is likely that the Dense", "Point", "Cloud could end up using ", " as the underlying data structure. "]},
{"url": "https://wiki.ros.org/straf_recovery", "package": "straf_recovery", "package_summary": ["The straf_recovery package"], "package_details": ["\n", "\n", " ", "The ", " is a simple recovery behavior that attempts to move away from the nearest obstacle in the navigation stack's ", ". It is designed only for omnidirectional robots. It adheres to the ", " interface found in the ", " package and can be used as a recovery behavior ", " for the ", " node. "], "package_tt": ["straf_recovery::StrafRecovery", "nav_core::RecoveryBehavior", "move_base_simple/goal", "~/obstacle_direction", "~/cycles", "timeout", "double", "minimum_translate_distance", "double", "maximum_translate_distance", "double", "straf_vel", "double", "xy_goal_tolerance", "double", "frequency", "double"]},
{"url": "https://wiki.ros.org/interactive_marker_proxy", "package": "interactive_marker_proxy", "package_summary": ["A Proxy Server for Interactive Markers"], "package_details": ["\n"], "package_tt": ["~topic_ns", "~topic_ns/tunneled/update", "~topic_ns/tunneled/get_init", "~target_frame", "string", "~topic_ns", "string", "~update_rate", "float"]},
{"url": "https://wiki.ros.org/naoqi_dashboard", "package": "naoqi_dashboard", "package_summary": ["naoqi_dashboard is a GUI for monitoring the state of an ALdebaran robot.\n    It is a port of pr2_dashboard and shows status information like\n    battery status, joint temperatures, and joint stiffness, as well\n    as integrating ROS tools like rqt_console and rqt_robot_monitor."]},
{"url": "https://wiki.ros.org/people_velocity_tracker", "package": "people_velocity_tracker", "package_summary": ["Track the output of the leg_detector to indicate the velocity of person."], "package_details": ["\n", "\n", "\n"], "package_tt": ["people_tracker_measurements", "/people", "/visualization_marker", "timeout", "double", "/people"]},
{"url": "https://wiki.ros.org/rospeex_audiomonitor", "package": "rospeex_audiomonitor", "package_summary": ["This package provides a stable waveform monitor of rospeex's (recommended).\n    This package requires an external library: qtmobility-dev."]},
{"url": "https://wiki.ros.org/sentis_tof_m100", "package": "sentis_tof_m100", "package_summary": ["The Sentis ToF M100 ROS package"], "package_details": ["\n", "\n", ". ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " Make sure your network is correctly configured. We recommend you to follow the API instructions to check whether the camera and your network are working without any problem. ", " Network parameters cannot be changed at runtime. ", " Following camera parameters and filtering methods can be accessed in runtime using the rqt_reconfigure. ", "There is a new package (", ") that uses the new ", " developed by Bluetechnix for interacting with their sensors. ", "The ", "' works with ROS versions groovy and hydro. You can use catkin workspaces or the previous rosbuild to configure, compile and get ready ROS. ", "ROS tutorial: ", " ", "Be sure your libboost library version is >= 1.49. Previous versions as 1.46 generate error while compiling sentis_tof_m100_ros_pkg. ", "Clone from repository: ", " to the src/ folder in your catkin workspace. Now compile it with: "], "package_code": ["sentis_tof_m100_ros_pkg", "apt-get install ros-hydro-pcl-ros ros-hydro-pcl-conversions ros-hydro-perception-pcl", "cd catkin_ws\n", "source devel/setup.bash ## initialize search path to include local workspace\n", "cd src/\n", "git clone https://github.com/voxel-dot-at/sentis_tof_m100_pkg.git\n", "cd ..\n", "catkin_make", "roslaunch sentis_tof_m100 start.launch", "cd catkin_ws\n", "source devel/setup.bash\n", "roscore &", "rosrun sentis_tof_m100 sentis_tof_m100_node #[options]", "Using help for sentis_tof_m100_ros_pkg\n", " You can set the configuration values for the camera. If any option is missing the value of the parameter server or the default value will be used:\n", "\n", " Usage:\n", " rosrun sentis_tof_m100 sentis_tof_m100_node <options>\n", "-tcp_ip *TCP IP Addresss*\n", "        Ip address for the control connection\n", "        (string, i.e: 192.168.0.10)\n", "-tcp_port *Port for tcp*\n", "        Defines the port used for the control connection\n", "        (unsigned short, i.e: 10001)\n", "-udp_ip *UDP IP Addresss*\n", "        Multicast ip address for the data connection\n", "        (string, i.e: 224.0.0.1)\n", "-udp_port *Port for udp*\n", "        Defines the port used for the data connection\n", "        (unsigned short, i.e: 10001)\n", "-it *Integration_Time*\n", "        Integration time(in usec) for the sensor\n", "        (min: 50 | max: 7000 | default: 1500)\n", "-mf  *Modulation_Frequency*\n", "        Sets the modulation frequency(Hz) of the sensor\n", "        (min: 5000 | max: 30000 | default: 20000)\n", "-fr *Frame_Rate*\n", "        Sets the frame rate of the camera\n", "        (min: 1 | max: 45 | default: 40)\n", "-mef *MedianFilter*\n", "        Sets on or off the Median Filter.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-avf *AverageFilter*\n", "        Sets on or off the Average Filter.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-gaf *GaussFilter*\n", "        Sets on or off the Gauss Filter.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-sla *SlidingAverage*\n", "        Sets on or off the Sliding Average.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-wic *WigglingCompensation*\n", "        Sets on or off the Wiggling Compensation.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-fppnc *FPPNCompensation*\n", "        Sets on or off the FPPN Compensation.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-mfs *ModFreqScaling*\n", "        Sets on or off the ModFreq Scaling.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-smm *Scalingmm*\n", "        Sets on or off the Scaling to [mm].\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-aos *AdditiveOffset*\n", "        Sets on or off the Additive Offset.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-tmc *TemperatureCompensation*\n", "        Sets on or off the Temperature Compensation.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-sdcg *ScalingDistCalibGradient*\n", "        Sets on or off the Scaling via register DistCalibGradient.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-sdco *ScalingDistCalibOffset*\n", "        Sets on or off the Scaling via register DistCalibOffset.\n", "        (OFF: 0 | ON: any other integer value |  ON if not set )\n", "-mefite *FilterMedian_Config*\n", "        Sets the n\u00ba of iteration for the Media filter.\n", "        (min: 1 | max: 255 | default: 1)\n", "-avfpix *FilterAverage_Config_Pixels*\n", "        Sets pixel matrix for the Average filter.\n", "        (3x3: 0 | 5x5: 1 | Default: 3x3 )\n", "-avfite *FilterAverage_Config_Iters*\n", "        Sets the n\u00ba of iteration for the Average filter.\n", "        (min: 1 | max: 255 | default: 1)\n", "-gafpix *FilterGauss_Config_Pixels*\n", "        Sets pixel matrix for the Gauss filter.\n", "        (3x3: 0 | 5x5: 1 | Default: 3x3 )\n", "-gafite *FilterGauss_Config_Iters*\n", "        Sets the n\u00ba of iteration for the Gauss filter.\n", "        (min: 1 | max: 255 | default: 1)\n", "-slacw *FilterSLAF_config*\n", "        Sets the SLAF filter windows size.\n", "        (min: 1 | max: 255 | default: 1)\n", "-af *Amplitude_Filter_On*\n", "        Whether to apply amplitude filter or not. Image pixels with amplitude values less than the threshold will be filtered out\n", "        (ON: if set | OFF: default)\n", "-at *Amplitude_Threshold*\n", "        What should be the amplitude filter threshold. Image pixels with smaller amplitude values will be filtered out. Amplitude Filter Status should be true to use this filter\n", "        (min: 0 | max: 2500 | default: 0)\n", "\n", " Example:\n", "rosrun sentis_tof_m100 sentis_tof_m100_node -tcp_ip 192.168.0.10 -tcp_port 10001 -it 1500 -mf 20000 -fr 20", "rosrun rviz rviz", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/motoman", "package": "motoman", "package_summary": ["ROS-Industrial support for Yaskawa Motoman manipulators (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It currently contains packages that provide nodes for communication with Motoman industrial robot controllers (DX100, FS100, DX200, and YRC1000), URDF models for various robot arms and associated ", " configuration packages. ", "Please see the ", " page for more information. ", "See the ", " metapackage for additional packages, such as robot support packages and ", " configuration packages. ", "The packages in the main repository have been released into ROS Indigo on Ubuntu, making installation through ", " or synaptic possible. Other Linux distributions will have to build from source. ", "This installs all the dependencies as well. The controller must be installed/configured to work with ROS-Industrial as well.  The relevant software can be found in the ", " package.  Installation instructions for the controller can be found in this ", ". ", "See the ", " page for an overview of the available tutorials. ", "See the ", " page for details on alarms and errors when using the MotoROS driver. "], "package_tt": ["apt-get"], "package_code": ["sudo apt-get install ros-indigo-motoman"]},
{"url": "https://wiki.ros.org/kuka_kr210_support", "package": "kuka_kr210_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR 210 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 210 manipulators. This currently includes the L150 only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      found in the online ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      ", ": this package currently uses non-valid inertia parameters.\n    "]},
{"url": "https://wiki.ros.org/schunk_svh_driver", "package": "schunk_svh_driver", "package_summary": ["SVH Driver wrapper to enable control of the Schunk five finger hand"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " The urdf of the node makes use of the ", " tag which is currently only resolved by the robot joint state publisher. in order to generate TFs for the visualization and to get the angles of the coupled joints the node is used in conjunction with a joint state publisher and a robot state publisher. If you include the node without these nodes the TF tree will not be complete as the joints that use mimic are not working. See the URDF section for details on joints, their naming and relation. ", "\n", " ", "\n", ": The SVH uses relative encoders that need a hard stop to reset. Especially the finger spread however also contains springs that will lead to a slightly different pose than commanded in real execution. So please beware when you develop poses without the hardware in the loop. ", "\n", "\n", " ", " ", " ", " ", " ", " ", " ", " ", " ", "\n", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", "This package provides a way of controlling the ", ". It provides the driver for the low level interface and enables an easy control of the hand via ROS ", ". ", "To use this package you will need a ", ".  It communicates via RS485 protocol. Brainbox USB to Serial converter have proven to work well with the hand and are usually delivered in combination with the hand. ", "this will copy the udev rules to ", " and restart your udev service. ", "If you have the fzi_icl_core or fzi_icl_comm package in your workspace you'll have to build it with ", ", as those packages are plain cmake packages. See the ", " for details. ", "which will copy the udev rules into ", " and restart your udev service. ", "\n", "When using the launch file ", " all parameters are read from yaml files residing in the folder ", ". If you want to give custom parameters just edit the file ", " if you are using the source installation. In case of an installation from deb you should first copy the file under ", " to a folder with user write acces, make your changes and then use it by adding the argument ", " when launching the node.  ", "If you want to go back to the original values (and have edited the file, residing in etc) you can simply delete the file and copy the ", " to the name ", " and start again. If no ", " file is present the values of the default file will be used. If both files are missing or the node use used without the launch file hardcoded default values that are safe will be used. ", "In any case ", " as it sets up many variables, the parameter sets and some additional packages that are needed for correct operation and visualization. ", "You can change the device used by adding the argument ", " to the launch calls, change it via dynamic reconfigure and then do a reconnect or change it permanently by replacing the argument in the launch file. ", "By using the ", " argument the launchfile will start a joint state publisher for easy input. If you do not activate this as input you have to provide the target positions by another node or console input. The package folder comes with a file called \"quick_commands\" which gives you some examples how to controll the hand via rostopic. ", "By default the node will await input from another node. To use the svh_controller with your project ", " like this: ", "The node will automatically show the input sliders if started with the standalone argument. If you additionally provide the ", " argument as true an rqt gui will be opened when launching the node: ", "The ", " gui opens always to its default configuration (which is usually the last one). The SVH comes with the plugin ", " which enables easy reset control of the hand. Additionally you can use dynamic_reconfigure to change some of the values and the RVIZ plugin to visualize the robot model of the SVH. A configuration file for rviz is provided with the package at \"urdf/svh.rviz\". Your configuration should look something like this to access all GUI functionalities: ", "as with the real hardware you can choose to use the simulation (which is not really a simulation but just a visualisation) with convenient sliders or with the command line/ your own packages by using the ", " argument: ", "As a test to see if the hardware is properly working the very simple test node ", " is provided. Make sure the hand can move freely and run the test with: ", "In case you do not use the autostart feature of the controller you will have to connect and start the controller manually.  You should do this by using the ", " plugin provided with the package. When the hardware is ready press the connect button. Afterwards you can either reset all or individual fingers by pressing reset. The fingers will be disabled after start but are automatically enabled once a target position is set. ", "If the troubleshooting did not answer your questions you can ask the community via ", " or contact the support offered by FZI on behalf of Schunk at svh-support AT fzi DOT de "], "package_tt": ["/etc/udev/rules.d", "/etc/udev/rules.d", "connect", "serial_device", "reset_channel", "enable_channel", "channel_targets", "channel_feedback", "channel_currents", "parameter_descriptions", "parameter_descriptions", "parameter_updates", "~autostart", "bool", "~serial_device", "string", "~disable_flags", "vector\u00a0of\u00a0bool", "~reset_timeout", "int", "~finger_reset_speed", "double", "/robot_description", "urdf\u00a0model", "~logging_config", "string", "~use_internal_logging", "bool", "~CHANNEL_NAME/position_controller", "vector\u00a0of\u00a0floats", "~CHANNEL_NAME/current_controller", "vector\u00a0of\u00a0floats", "~CHANNEL_NAME/home_settings", "vector\u00a0of\u00a0floats", "~VERSIONS_PARAMETER", "array", "svh_controller", "toggle_run", "speed", "loop", "channel_targets", "svh_controller.launch", "controller_config:=path_to_your/logging.xml", "serial_device", "standalone", "mimic", "gui", "rqt", "SVH_Reset", "standalone", "svh_sin_test", "SVH_Reset", "rqt", "rqt\u00a0--clear-config"], "package_code": ["apt-get install ros-indigo-schunk-svh-driver", "apt-get install ros-jade-schunk-svh-driver", "apt-get install ros-hydro-schunk-svh-driver", "apt-get install ros-indigo-schunk-svh-driver", "apt-get install ros-kinetic-schunk-svh-driver", "rosrun schunk_svh_driver create_udev_rules", "   catkin_make_isolated\n", "   source devel_isolated/setup.bash", "   rosrun schunk_svh_driver create_udev_rules", "ls /dev", "roslaunch schunk_svh_driver svh_controller.launch standalone:=true", "roslaunch schunk_svh_driver svh_controller.launch standalone:=true autostart:=false", "  <include file=\"$(find schunk_svh_driver)/launch/svh_controller.launch\">\n", "        <arg name=\"standalone\" value=\"False\" />\n", "        <arg name=\"gui\" value=\"False\" />\n", "  </include>", "<include file=\"$(find schunk_svh_driver)/launch/svh_node.launch\">\n", "            <arg name=\"serial_device\" value=\"$(arg serial_device)\"/>\n", "            <arg name=\"autostart\" value=\"$(arg autostart)\" />\n", "</include>", "roslaunch schunk_svh_driver svh_controller.launch standalone:=true gui:=true", "roslaunch schunk_svh_driver svh_controller.launch simulation:=true gui:=true", "roslaunch schunk_svh_driver svh_controller.launch simulation:=true standalone:=true gui:=true", "roslaunch schunk_svh_driver svh_sin_test.launch", "rostopic pub -1 /svh_sin_test/toggle_run std_msgs/Empty \"{}\"", "<2014-09-29 14:40:56.004> DriverSVH(Warning) SVHFingerManager::setAllTargetPositions: Could not set target position vector: At least one channel is out of bounds!", "<2014-09-30 11:24:20.086> DriverSVH(Info) SVHFingerManager::connect: Successfully established connection to SCHUNK five finger hand.\n", "<2014-09-30 11:24:20.086> DriverSVH(Info) SVHFingerManager::connect: Send packages = 28, received packages = 28", "<2014-09-30 13:23:54.741> DriverSVH(Error) SVHSerialInterface::connect: Could not open serial device: /dev/ttyUSB0\n", "[ INFO] [1412076234.741596785]: SVH Driver Ready, you will need to connect and reset the fingers before you can use the hand."]},
{"url": "https://wiki.ros.org/nodelet_core", "package": "nodelet_core", "package_summary": ["Nodelet Core Metapackage"], "package_details": ["\n", ": the nodelet packages are now part of nodelet_core.  In previous releases, they were part of ", ". ", "For documentation on using nodelets, please see the ", " package.  For nodelet libraries similar in function to the ", " package, see ", ". "]},
{"url": "https://wiki.ros.org/abb_irb5400_support", "package": "abb_irb5400_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 5400 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 5400 manipulators. This currently includes the base model.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the ABB data sheets.  All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/kobuki_ftdi", "package": "kobuki_ftdi", "package_summary": ["Utilities for flashing and enabling Kobuki's USB connection.\n\t    This package contains tools for flashing the Kobuki's FTDI chip (usually done at the factory).\n\t    The special firmware for the FTDI chip (USB to serial converter) enables it to appear as\n\t    /dev/kobuki on the user's PC."], "package_details": ["\n", "\n"], "package_tt": ["kobuki", "/dev/kobuki"], "package_code": ["> rosrun kobuki_ftdi create_udev_rules", "> make udev"]},
{"url": "https://wiki.ros.org/rosbag", "package": "rosbag", "package_summary": ["This is a set of tools for recording from and playing back to ROS\n    topics.  It is intended to be high performance and avoids\n    deserialization and reserialization of the messages."], "package_details": ["\n", "\n", "The ", " package provides a command-line tool for working with ", " as well as code APIs for reading/writing bags in ", " and ", ". ", "The rosbag command-line tool and code APIs are ", ".  Every effort will be made to maintain backwards compatibility. ", "The main new feature being planned for ", " is the addition of a ROS API for interacting with the playing and recording nodes via service calls. "], "package_tt": ["rosbag", "rosbag", "rosbag", "rosbag", "rosbag"]},
{"url": "https://wiki.ros.org/viso2", "package": "viso2", "package_summary": ["\n    A ROS-Wrapper for libviso2, a library for visual odometry, \n    maintained by the Systems, Robotics and Vision group of the \n    University of the Balearic Islands, Spain. http://srv.uib.es "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/nav_core", "package": "nav_core", "package_summary": ["This package provides common interfaces for navigation specific robot actions. Currently, this package provides the BaseGlobalPlanner, BaseLocalPlanner, and RecoveryBehavior interfaces, which can be used to build actions that can easily swap their planner, local controller, or recovery behavior for new versions adhering to the same interface."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains key interfaces for the navigation stack. All planners and recovery behaviors that wish to be used as ", " in the ", " node must adhere to these interfaces. ", "The ", " provides an interface for global planners used in navigation. All global planners written as plugins for the ", " node must adhere to this interface. Current global planners using the ", " interface are: ", "Documentation on the C++ API for the ", " can be found here: ", ". ", "The ", " provides an interface for local planners used in navigation. All local planners written as plugins for the ", " node must adhere to this interface. Current local planners using the ", " interface are: ", "Documentation on the C++ API for the ", " can be found here: ", ". ", "The ", " provides an interface for recovery behaviors used in  navigation. All recovery behaviors written as plugins for the ", " node must adhere to this interface. Current recovery behaviors using the ", " interface are: ", "Documentation on the C++ API for the ", " can be found here: ", " "], "package_tt": ["nav_core", "nav_core::BaseGlobalPlanner", "nav_core::BaseGlobalPlanner", "nav_core::BaseGlobalPlanner", "nav_core::BaseLocalPlanner", "nav_core::BaseLocalPlanner", "nav_core::BaseLocalPlanner", "nav_core::RecoveryBehavior", "nav_core::RecoveryBehavior", "nav_core::RecoveryBehavior"]},
{"url": "https://wiki.ros.org/reemc_bringup", "package": "reemc_bringup", "package_summary": ["Launch files and scripts needed to bring up the ROS nodes of a REEM-C robot."]},
{"url": "https://wiki.ros.org/tuw_multi_robot", "package": "tuw_multi_robot", "package_summary": ["This repository includes ros packages to plan routes for multiple robots on a search graph. It creates a search graph out of a pixel map and tries to find a path for multiple robots using an extended approach for prioritized planning. The inputs are the tuw_multi_robot_msgs/RobotInfo messages which include the robots pose, the map and the desired goal poses. The output are multiple synchronized routes given to the individual robots."], "package_details": ["\n", " ", "\n", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "The following figure represents the current state and planed developments on the tuw_multi_robot framework.  The green boxes show already existing modules while the red boxes are not yet implmented/released.  The framework is designed to cover all tools needed for an automated delivery system with autonomous vehicles. The current implementation of the system allows one to set goals for multiple vehicles using RViz or by a configuration file. In the future we also want a order management integrated which is capable to assign vehicles for specific deliveries and to generate goals needed by the multi robot route planner. The system provides a simple local motion controller for all robots, which allows a high number (> 100) of vehicles to be controlled in real time using stage. Furthermore, the design allows the usage of existing individual controllers running on each vehicle such as DWA implemented in move_base. "]},
{"url": "https://wiki.ros.org/pr2_common_actions", "package": "pr2_common_actions", "package_summary": ["Various actions which help in moving the arms of the PR2\n    or getting data from its tilting laser."], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/rtt_tf", "package": "rtt_tf", "package_summary": ["This package contains the components of the rtt_tf package"]},
{"url": "https://wiki.ros.org/ur_modern_driver", "package": "ur_modern_driver", "package_summary": [" This package has been deprecated. Users of CB3 and e-Series controllers should migrate to ur_robot_driver.", "The new driver for Universal Robots UR3, UR5 and UR10 robots with CB2 and CB3 controllers."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package is part of the ", " program. It currently contains nodes that support communication with Universal Robots' industrial robot controllers. ", "The following instructions assume that a ", " has been created at $HOME/catkin_ws and that the source space is at $HOME/catkin_ws/src. Update paths appropriately if they are different on the build machine. "], "package_tt": ["v3.x", "v5.x", "<=\u00a01.8.x", "ur_modern_driver", "v1.8.x"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/vrep_ros_plugin", "package": "vrep_ros_plugin", "package_summary": ["The vrep_ros_plugin package"], "package_details": ["\n", " contains all the objects in the scene to which we have added a custom data. The handlers are derived classes that redefines the functions of the ", " in order to handle the object. ", " ", "Vrep_ros_plugin contains the main code of the bridge. We wrote Vrep_ros_plugin starting from a template called v_repExtPluginSkeleton, available in the V-REP folder \"/programming\" with the porpoise to create your own plugin. You can find more information about the plugins in V-REP ", ". "]},
{"url": "https://wiki.ros.org/universal_robots", "package": "universal_robots", "package_summary": ["ROS-Industrial support for Universal Robots manipulators (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It currently contains packages that provide nodes for communication with Universal's industrial robot controllers, URDF models for various robot arms and the associated ", " packages. ", "On supported Linux distributions (Ubuntu, up to 16.04 (Xenial), ", " and ", "): ", "The following instructions assume that a ", " has been created at $HOME/catkin_ws and that the source space is at $HOME/catkin_ws/src. Update paths appropriately if they are different on the build machine. ", "Refer to the ", " for more information on building catkin workspaces. ", "See the ", " page for an overview of the available tutorials. "], "package_tt": ["ur_driver", "v1.8.16941", "v1.8.x", "universal_robot", "i386", "amd64"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-universal-robots", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/sr_utilities", "package": "sr_utilities", "package_summary": ["\n\n     sr_utilities contains different useful header libraries (math libraries, etc...).\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "Please note that the robot_state_publisher should soon implement this feature (with a cleaner implementation), as stated by Wim in the ", ". ", "The node subscribes to the two topics to merge: ", " and ", ". These are hard coded for the time being. ", "Publishes the merged joint state messages to ", ". "]},
{"url": "https://wiki.ros.org/rosserial_windows", "package": "rosserial_windows", "package_summary": ["rosserial for Windows platforms."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package contains Windows-specific extensions required to run ", " on an Windows. It will generate a package of headers and a few cpp files that you will need to add to your Visual Studios project in order to communicate with a ROS system, usually over a TCP socket. ", "Please see the ", " for examples of using rosserial_windows ", "Visual Studio 2013 defaults to indenting using tabs. The ROS guidelines are for 2 spaces. To keep things consistent, all of the examples are with 2 spaces. You're welcome to use your editor however you like, but please do not submit code with tabs. See the following page from MSDN for how to set up your Visual Studios environment correctly: ", " "], "package_code": ["error C1010: unexpected end of file while looking for precompiled header. Did you forget to add '#include \"stdafx.h\"' to your source?"]},
{"url": "https://wiki.ros.org/rc_cloud_accumulator", "package": "rc_cloud_accumulator", "package_summary": ["A viewer for the SLAM component of roboception based on ROS and PCL"], "package_details": ["\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "The rc_cloud_accumulator ROS node subscribes to the following topics of the ", " ", "After starting the ", ", execute ", "The ", " provides the following services "], "package_tt": ["/stereo/points2", "/pose", "/trajectory", "True", "rosrun\u00a0rc_cloud_accumulator\u00a0rc_cloud_accumulator", "rosrun\u00a0rc_cloud_accumulator\u00a0rc_cloud_accumulator\u00a0_voxel_grid_size_display:=0.01", "/rc_cloud_accumulator/toggle_pause", "/rc_cloud_accumulator/save_cloud", "voxel_grid_size_display", "voxel_grid_size_save", "minimum_distance", "maximum_distance", "output_filename", "start_paused", "keep_high_resolution"]},
{"url": "https://wiki.ros.org/rosparam_shortcuts", "package": "rosparam_shortcuts", "package_summary": ["Quickly load variables from rosparam with good command line error checking."], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/rosh_robot", "package": "rosh_robot", "package_summary": ["\n\n     ROSH meta-plugin for the ROS 'robot' variant.\n\n  "], "package_details": ["rosh_robot is a meta-plugin that makes it easy to automatically load all desktop-related ", " plugins.  See the ", " documentation on how to automatically load rosh_robot when you start rosh. ", "Please see the ", " documentation to find out more about rosh. "]},
{"url": "https://wiki.ros.org/teraranger", "package": "teraranger", "package_summary": ["This package provides ros nodes for single sensors from Terabee"], "package_details": ["\n", " ", " is the long range Time-of-Flight distance sensor of the ", " product family. ", "It provides calibrated distance readings in millimetres and has a range up to 60m, whilst remaining lightweight and small! Instead of laser, ", " Evo uses LED technology. ", "React faster and detect obstacles with greater assurance, ", " ", " is perfect for high-speed collision avoidance and object detection solution! ", "With its 10cm to 3m range, 100Hz fixed update rate and greater accuracy(+/-2cm), the ", " ", ", is optimized for close-range distance measurement. ", " ", " Monitor heat variations, detect movement and capture the unseen! In a compact and affordable design, ideal for OEM integration in Smart City, Smart building, Robotics and Industrial applications. ", "For more information about ", " ", ": ", " ", " is a lightweight, high-performance multi-pixel sensor based on infrared Time-of-Flight (ToF) technology. ", "For more information about ", " ", ": ", " ", " is a lightweight, high-performance distance measurement sensor based on infrared Time-of-Flight (ToF) technology. ", " ", "\n", "\n", "\n", "\n", " ", "Github: *", " ", "This package works with ", " ", ", ", " ", ", ", " ", ", ", " ", " ,  ", " ", ", ", " ", ", ", " ", " and ", " ", ". You can find more information below. ", "For more information about ", " ", ": ", "*", " ", "*", " ", "*", " ", "*", " ", "For more information about ", " ", ": ", "*", " ", "*", " ", "*", " ", "*", " ", "*", " ", "*", " ", "For more information about ", " ", ": ", "*", " ", "*", " ", "For more information about ", " ", ": ", "*", " ", "*", " "], "package_tt": ["/teraranger_evo", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "_sensor_type", "str,\u00a0default:\u00a0\"Evo_60m\"", "/teraranger_evo_mini/range", "/teraranger_evo_mini/ranges", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "Pixel_mode", "int", "Range_mode", "int", "/teraranger_evo_thermal/raw_temp_array", "/teraranger_evo_thermal/rgb_image", "/teraranger_evo_thermal/ptat", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "_baudrate", "int,\u00a0default:\u00a0\"115200\"", "thermal_image_flip_h", "bool", "thermal_image_flip_v", "bool", "thermal_image_interpolate", "bool", "manual_min_scaling", "double_t", "manual_max_scaling", "double_t", "Map", "int_t", "/teraranger_evo_64px/point_cloud", "/teraranger_evo_64px/depth_image", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "_baudrate", "int,\u00a0default:\u00a0\"115200\"", "depth_image_invert", "bool", "depth_image_interpolate", "bool", "min_distance_mm", "int", "max_distance_mm", "int", "Mode", "int", "/teraranger_one", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\"", "/teraranger_duo", "_portname", "str,\u00a0default:\u00a0\"/dev/ttyACM0\""], "package_code": ["rosrun teraranger name_of_the_sensor"]},
{"url": "https://wiki.ros.org/network_monitor_udp", "package": "network_monitor_udp", "package_summary": ["\n    Facilities to monitor a network connection by sending UDP packets from\n    a client to a server, which bounces them back to the client. The client\n    collects statistics on latency and loss. The server is a C standalone utility\n    or a ROS node. The client can be a ROS node, a standalone utility or a python class.\n  "], "package_details": ["\n", "\n", " records packets receive times and sorts them into latency bins based on their travel time. These latency bins can be periodically retrieved and information such as packet loss, average latency and bandwidth can be therefrom determined. ", "\n", " is a node that implements an action server which receives link testing goals. It instantiates and collects statistics from multiple ", "s. Each source (i.e. link test) is independent of all others and can be parametrized differently in terms of bandwidth, latency bin thresholds, update (i.e. stats collection) interval and so on. It sends periodical feedback to the action client. ", " also implements logic for adaptive bandwidth tests: link tests that strive to saturate a link in terms of bandwidth while maintaining latency and loss within specified thresholds. ", "\n", "\n", "\n", "\n", " can also be used stand-alone, independent of ROS with ", " as in the example below: ", "\n", "\n", "The basic link measurements are implemented by the class ", " (defined in ", ") and the ", " node. ", " sends UDP packets at a specified rate to ", " which timestamps them and echoes them back either via UDP or via ROS topic message. ", "Multiple stream support is built in so multiple ", "s on the same ROS node can ping packets off the same ", ". ", "For a ROS independent setup, ", " can be used instead of ", ". The former is not a ROS node, but rather a standalone UDP server. By default, ", " does not use ROS messages for the return path and no ROS dependency is created on the class. ", "Typically there would be one ", " node running on every machine in a test setup as each ", " supports any number of tests with destination sinks on different machines. ", "The ", " implements the action client for link tests, as well as logging and test control logic via three classes: ", "More usage examples with more complex configurations can be found in the ", " package. "], "package_tt": ["MonitorSource", "udpmonclient.py", "udpmonsink", "MonitorSource", "udpmonsink", "MonitorSource", "MonitorSource", "udpmonsink", "udpmonserv", "udpmoncli", "MonitorSource", "udpmonsourcenode", "MonitorSource", "udpmonsourcenode", "udpmonsourcenode.py", "sourcenode", "linktest.py", "UdpmonsourceHandle", "udpmonsourcenode.py", "udpmonsourcenode", "UdpmonsourceHandle", "Linktest", "LinkTest", "UdpmonsourceHandle", "MetricLog", "MetricLog", "duration", "float", "0.0", "0.0", "update_interval", "float", "0.15", "bw", "float", "5000000.0", "bw_type", "char", "'c'", "'c'", "'a'", "latency_threshold", "float", "0.01", "pktloss_threshold", "float", "0.5", "tos", "byte", "0x00", "pktsize", "int", "1500", "ros_returnpath", "boolean", "False", "roundtrip", "boolean", "False", "max_return_time", "float", "rostopic_prefix", "string", "\"\"", "udpmonsink", "udpsink_feedback", "udpmonsink", "sink_ip", "string", "\"\"", "udpmonsink", "sink_port", "int", "0", "udpmonsink", "latency_bins", "float[]", "[.005,\u00a0.01,\u00a0.025,\u00a0.05,\u00a0.075,\u00a0.1]", "latency", "float", "loss", "float", "bandwidth", "float", "latency_histogram", "float", "udpmonsink", "udpsink_feedback", "udpmoncli.py", "udpmonserv"], "package_code": ["# rosrun network_monitor_udp udpmonserv 12345\n", "\n", "# rosrun network_monitor_udp udpmoncli.py 127.0.0.1 12345 10 1500\n", "  0.501: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %\n", "  1.001: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %\n", "  1.501: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %\n", "  2.001: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %\n", "  2.501: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %\n", "  3.000: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %", "<launch>\n", "<node name=\"sink\" pkg=\"network_monitor_udp\" type=\"udpmonsink\" args=\"12345\" output=\"screen\"/>\n", "<node name=\"source\" pkg=\"network_monitor_udp\" type=\"udpmonsourcenode.py\" output=\"screen\"/>\n", "<node name=\"test_node\" pkg=\"network_monitor_udp\" type=\"sample_bwtest.py\" required=\"true\" output=\"screen\"/>\n", "</launch> ", "import roslib; roslib.load_manifest('network_monitor_udp')\n", "import rospy\n", "\n", "from network_monitor_udp.linktest import UdpmonsourceHandle\n", "from network_monitor_udp.linktest import LinkTest\n", "from network_monitor_udp.msg import LinktestGoal\n", "\n", "if __name__ == '__main__':\n", "    rospy.init_node('test_node')\n", "        \n", "    source = UdpmonsourceHandle() \n", "    source.cancel_all_tests()\n", "\n", "    try:\n", "        print \"Link capacity: %.2fMbit/s\"%(source.get_link_capacity(sink_ip=\"127.0.0.1\", sink_port=12345)/1e6)\n", "    finally:\n", "        source.cancel_all_tests()", "# roslaunch launch_nodes.launch\n", "\n", "[...]\n", "\n", "core service [/rosout] found\n", "process[sink-1]: started with pid [20043]\n", "process[source-2]: started with pid [20044]\n", "process[test_node-3]: started with pid [20055]\n", "Link capacity: 68.71Mbit/s"]},
{"url": "https://wiki.ros.org/steer_drive_ros", "package": "steer_drive_ros", "package_summary": ["Steer driving meta package for ROS."], "package_details": ["An example of using the packages can be seen in ", ". "]},
{"url": "https://wiki.ros.org/moveit_sim_controller", "package": "moveit_sim_controller", "package_summary": ["A simulation interface for a hardware interface for ros_control, and loads default joint values from SRDF"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/wire_core", "package": "wire_core", "package_summary": ["The wire meta package is implements a framework that \n     generates and maintains one consistent world state estimate based \n     on object detections. It solves the data association problem by \n     maintaining multiple hypotheses and facilitates tracking of various\n     object attributes. The state estimators used for estimation and the\n     probabilistic models used for association can be configured."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The wire_core package it is the core of the ", " stack. It takes detections and fuses them to a world state estimate. Technical details can be found here: ", "J. Elfring, S. van den Dries, M.J.G. van de Molengraft, M. Steinbuch, Semantic world modeling using probabilistic multiple hypothesis anchoring, Robotics and Autonomous Systems, Volume 61, Issue 2, February 2013, Pages 95-105, (", ") ", "An extended list of tutorials can be found ", ". ", "The package listens to ", " generated by perceptual algortihms. It fuses the evidence using object class specific models. It includes multiple hypothesis-based data association and can be configured easily. See the ", " for more information about the configuration of this package. ", "First install the stack by following the steps mentioned ", ". Then, launch: "], "package_tt": ["/world_evidence", "/world_state", "world_model_frame", "string", "output_frame", "string", "evidence_topics", "string[]"], "package_code": ["$ roslaunch wire_core start.launch", "***** 1352890681.479009 ***** \n", "   Number of hypotheses        = 1 \n", "   Max probability             = 1 \n", "   Tree height                  = 0 \n", "Num MAP objects:      0 \n", "Last update:          0 seconds \n", "Max update:           0 seconds \n", "Evidence buffer size: 0 \n", "***** 1352890682.228999 ***** \n", "   Number of hypotheses        = 1 \n", "   Max probability             = 1 \n", "   Tree height                  = 0 \n", "Num MAP objects:      0 \n", "Last update:          0 seconds \n", "Max update:           0 seconds \n", "Evidence buffer size: 0 ", "$ roslaunch wire_tutorials rviz_wire_fuerte.launch", "$ roslaunch wire_tutorials rviz_wire_electric.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rtt_common_msgs", "package": "rtt_common_msgs", "package_summary": ["The rtt_common_msgs package"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "  "], "package_code": ["sudo aptitude install ros-electric-rtt-common-msgs", "git clone http://git.mech.kuleuven.be/robotics/rtt_common_msgs.git\n", "rosmake rtt_common_msgs"]},
{"url": "https://wiki.ros.org/stdr_launchers", "package": "stdr_launchers", "package_summary": ["Launch files, to easily bringup server, robots, guis"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " package provides ROS launchers for the basic ", " functionalities. Specifically the launchers available are: ", "Initializes a bare ", ". ", "Initializes an ", " and automatically loads the ", " map (found in the ", " package). ", "Initializes an ", " and automatically loads the ", " map (found in the ", " package. Also an instance of ", " is executed. ", "Initializes an ", " and automatically loads the ", " map (see ", "). Also an instance of ", " is executed. Finally a robot of type ", " (see ", ") is spawned in the map. ", "Wrapper launcher for the ", ", modified so that the essential information about ", " are visible.  "]},
{"url": "https://wiki.ros.org/sr_gui_movement_recorder", "package": "sr_gui_movement_recorder", "package_summary": ["\n    This is a rosgui plugin for recording and replaying movements.\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/schunk_ezn64", "package": "schunk_ezn64", "package_summary": ["Xacro model and usb driver for basic communication with Schunk EZN64 gripper"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "This package is part of ", " stack. It allows user to control Schunk EZN64 gripper over USB using standard ROS services and provides Xacro model for easier integration with various robots. ", "Git clone ", " to your \"", "folder and ", " as usual. ", "This package depends on ", " library which should be part of ROS installation. To check availibility type: ", "These services are ROS user interface to Schunk EZN64 gripper. Except \"set_position\" all of them use ", " requests, so you don't need to specify any values, just \"rosservice call\" as in the example below. ", "To test the driver start by calling the ", " service (", "  request): ", "To get actual gripper position, call ", " service (", "  request): ", "Gripper should respond with actual position value in ", " format: ", "To move the gripper to target position, call ", " service (", " request): ", "where \"", "\" is within a range of <0 - 12> mm. The current driver supports", ", which means that \"goal_velocity\" and \"goal_acceleration\" are permanently set to default values. ", "To reference gripper, call ", " service (", "  request). Referencing may also help in cases you are not able to move the gripper although everything else looks okay: "], "package_tt": ["joint_states", "schunk_ezn64/reference", "schunk_ezn64/get_error", "schunk_ezn64/acknowledge_error", "schunk_ezn64/get_position", "schunk_ezn64/set_position", "schunk_ezn64/stop", "vendor_id", "std_msgs/UInt16", "product_id", "std_msgs/UInt16", "gripper_id", "std_msgs/UInt8", "robot_end_link", "schunk_ezn64_base_link", "schunk_ezn64_base_link", "schunk_ezn64_finger_1_link", "schunk_ezn64_base_link", "schunk_ezn64_finger_2_link", "schunk_ezn64_base_link", "schunk_ezn64_finger_3_link"], "package_code": ["$ sudo apt-get install libusb-1.0-0", "SUBSYSTEM==\"usb\"\n", "ATTR{idVendor}==\"7358\"\n", "ATTR{idProduct}==\"371\"\n", "ACTION==\"add\"\n", "MODE:=\"0666\"", "$ roslaunch schunk_ezn64 ezn64_usb_control.launch", "$ rostopic echo /joint_states", "header:\n", "  seq: 34\n", "  stamp:\n", "    secs: 1443076490\n", "    nsecs: 513091024\n", "  frame_id: ''\n", "name: ['ezn64_finger_1_joint', 'ezn64_finger_2_joint', 'ezn64_finger_3_joint']\n", "position: [0.011971454620361328, 0.011971454620361328, 0.011971454620361328]\n", "velocity: []\n", "effort: []\n", "---\n", "header:\n", "  seq: 35\n", "  stamp:\n", "    secs: 1443076490\n", "    nsecs: 612699408\n", "  frame_id: ''\n", "name: ['ezn64_finger_1_joint', 'ezn64_finger_2_joint', 'ezn64_finger_3_joint']\n", "position: [0.01197367763519287, 0.01197367763519287, 0.01197367763519287]\n", "velocity: []\n", "effort: []", "$ rosservice list", "schunk_ezn64/reference\n", "schunk_ezn64/get_error\n", "schunk_ezn64/acknowledge_error\n", "schunk_ezn64/get_position\n", "schunk_ezn64/set_position\n", "schunk_ezn64/stop", "$ rosservice call /schunk_ezn64/get_error", "error_code: 0", "$ rosservice call /schunk_ezn64/get_position", "actual_position: 11.9702377319", "$ rosservice call /schunk_ezn64/set_position value", "goal_accepted: True", "$ rosservice call schunk_ezn64/reference", "$ roslaunch schunk_ezn64 ezn64_visualize_standalone.launch"]},
{"url": "https://wiki.ros.org/ridgeback_robot", "package": "ridgeback_robot", "package_summary": ["Metapackage of software to install on Ridgeback."], "package_details": ["\n", "Metapackage capturing software to be installed on ", ". "]},
{"url": "https://wiki.ros.org/rail_grasp_collection", "package": "rail_grasp_collection", "package_summary": ["Grasp Collection for Constructing a Grasping and Recognition Database"], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package contains nodes to collect demonstration grasps for detected point cloud objects.  These demonstrations can then be used to build object models for recognition and manipulation using the ", " package.  Demonstrations are stored in a grasp database, handled by ", ". ", "To install the ", " package, you can install from source with the following commands: ", "The ", " package contains launch files for launching either the rail_grasp_collection node or the rail_grasp_retriever node individually, and for launching both nodes together.  These can be launched with the following commands, respectively: ", "Grasp collection can also be run and executed with an rviz plugin found in ", ". "], "package_tt": ["rail_grasp_collection", "rail_grasp_collection/grasp_and_store", "rail_grasp_collection/grasp_and_store", "gripper_action_server\u00a0param", "lift_action_server\u00a0param", "verify_grasp_action_server\u00a0param", "segmented_objects_topic\u00a0param", "rail_grasp_collection/debug", "debug", "bool", "robot_fixed_frame_id", "string", "eef_frame_id", "string", "segmented_objects_topic", "string", "gripper_action_server", "string", "lift_action_server", "string", "verify_grasp_action_server", "string", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "rail_grasp_retriever/retrieve_grasp", "rail_grasp_retriever/retrieve_grasp", "rail_grasp_retriever/point_cloud", "rail_grasp_retriever/pose", "/graspdb/host", "string", "/graspdb/port", "int", "/graspdb/user", "string", "/graspdb/password", "string", "/graspdb/db", "string", "rail_pick_and_place", "rail_grasp_collection"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch rail_grasp_collection rail_grasp_collection.launch", "roslaunch rail_grasp_collection rail_grasp_retriever.launch", "roslaunch rail_grasp_collection rail_grasp_collection_and_retriever.launch"]},
{"url": "https://wiki.ros.org/pr2_mannequin_mode", "package": "pr2_mannequin_mode", "package_summary": ["The pr2_mannequin_mode package"], "package_details": ["\n", "\n", "As with all applications, you must first ", ". "], "package_code": ["roslaunch pr2_mannequin_mode pr2_mannequin_mode.launch"]},
{"url": "https://wiki.ros.org/rospeex_msgs", "package": "rospeex_msgs", "package_summary": ["This package defines messages used in rospeex."]},
{"url": "https://wiki.ros.org/rqt_robot_plugins", "package": "rqt_robot_plugins", "package_summary": ["Metapackage of rqt plugins that are particularly used with robots\n   during its operation.", "\n   ", "\n   To run any rqt plugins, just type in a single command \"rqt\", then select any plugins you want from the GUI that launches afterwards.", "\n   ", "\n   rqt consists of three following metapackages:", "\n    "], "package_details": ["\n", "\n", "See ", ".  ", "Other than that, there's extra policy for this ", ": "], "package_tt": ["metapackage", "There's\u00a0"]},
{"url": "https://wiki.ros.org/velodyne_gazebo_plugins", "package": "velodyne_gazebo_plugins", "package_summary": ["Gazebo plugin to provide simulated data from Velodyne laser scanners."], "package_details": ["Documentation at ", " "]},
{"url": "https://wiki.ros.org/qb_chain_description", "package": "qb_chain_description", "package_summary": ["This package contains the ROS description for complex chains of qbrobotics\u00ae devices."], "package_details": ["This package contains the description resources for ", " device chains. It includes the ", "/", " model of the chained systems exploiting single module descriptions, and extends them with additional parts when required. "]},
{"url": "https://wiki.ros.org/rcll_ros_msgs", "package": "rcll_ros_msgs", "package_summary": ["Message definitions for RCLL refbox communication"], "package_details": ["\n", "\n", "\n", "This package contains messages and services providing the interface to interact with the ", " of the ", " which is also used in the ", ". ", "In addition to this msgs package, you will also need the ", " (see its documentation there for a description of the actual topics). But you may, for example, choose to keep the calling code on a different machine than the peer. The messages have a close relation to the respective protobuf message types of the referee box. We suggest also consulting the ", ".  "]},
{"url": "https://wiki.ros.org/abb_irb2400_moveit_config", "package": "abb_irb2400_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 2400.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 2400 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "This package is part of the ", " program. "]},
{"url": "https://wiki.ros.org/rb1_base_pad", "package": "rb1_base_pad", "package_summary": ["The rb1_base_pad package"], "package_details": ["This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux (", ") so that the final command to the robot can be set by different components (move_base, etc.) "]},
{"url": "https://wiki.ros.org/rosfmt", "package": "rosfmt", "package_summary": ["fmt is an open-source formatting library for C++.\n\t\tIt can be used as a safe and fast alternative to (s)printf and IOStreams."]},
{"url": "https://wiki.ros.org/nav2d_msgs", "package": "nav2d_msgs", "package_summary": ["Messages used for 2D-Navigation."]},
{"url": "https://wiki.ros.org/maggie_skills_msgs", "package": "maggie_skills_msgs", "package_summary": ["maggie_skills_msgs metapackage"], "package_details": ["\n", "\n", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"basic_states_skill_msgs\" in rosdoc: /home/rosbot/docs/api/basic_states_skill_msgs/manifest.yaml ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"batteries_skill_msgs\" in rosdoc: /home/rosbot/docs/api/batteries_skill_msgs/manifest.yaml ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"touch_skill_msgs\" in rosdoc: /home/rosbot/docs/api/touch_skill_msgs/manifest.yaml ", "This package defines ", "-specific message and service types for the skills. Most users will not use these types directly, but rather through Maggie-specific visualizations and utilities. "]},
{"url": "https://wiki.ros.org/uos_rotunit_snapshotter", "package": "uos_rotunit_snapshotter", "package_summary": ["This modul assemble a point cloud for a given rotational angle from a rotating laserscanner."]},
{"url": "https://wiki.ros.org/rc_common_msgs", "package": "rc_common_msgs", "package_summary": ["Common msg and srv definitions used by Roboception's ROS packages"]},
{"url": "https://wiki.ros.org/kuka_kr10_support", "package": "kuka_kr10_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR 10 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 10 manipulators. This currently includes the R1100 sixx only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      in the ", " version ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/coverage_path", "package": "coverage_path", "package_summary": ["A package that generates an optimal path to cover a given area with a cyber physical system (CPS)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The communication between CPSs is based on the ", ". ", "The following packages of the ", " are required: ", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["coverage_path", "id", "integer", "output", "string", "screen", "screen", "log", "param", "coverage_path.yaml", "coverage_path", "coverage_path", "area/assigned", "divide_area=true", "area/map", "divide_area=false", "coverage_path/path", "visualize", "coverage_path/waypoint", "visualize", "coverage_path/mst", "visualize", "coverage_path/path", "coverage_path/waypoint", "area/get_area", "~loop_rate", "real", "~queue_size", "integer", "~resolution", "real", "~visualize", "boolean", "~divide_area", "boolean", "~vertical", "boolean", "~turning_points", "boolean"], "package_code": ["roslaunch coverage_path coverage_path.launch"]},
{"url": "https://wiki.ros.org/slime_ros", "package": "slime_ros", "package_summary": ["Extensions for slime to assist in working with ROS packages"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This is an extension of ", " (a \"contrib\") that helps you to deal with ASDF systems in ROS packages. It also adds a REPL shortcut ", " to the slime REPL. ", "Then call the initialization script that generates ", " in your home directory for configuring your SBCL. ", "And then add the following to your ", ": ", "The most up-to-date version of ", " code can be found ", ". Installation instructions are in the README file. ", "What you'll need to do will be something like the following: ", "If you've set up your emacs init file correctly you should be able to start the REPL by typing ", ". Now, by pressing ", " (coma) in an empty REPL prompt, you can select the shortcut ", ". Press enter and select a ROS package and an ASDF system inside this ROS package. Slime will set the variable ", " and perform a load operation on the selected system. ", "The package contains one customization variable, ", ". It allows the user to select ido mode completion or similar completion mechanisms. To change its value, use ", ". "], "package_tt": ["ros-load-system", ".sbclrc", "slime_ros", "M-x\u00a0slime", ",", "ros-load-system", "ros-load:*current-ros-package*", "slime-ros-completion-function", "M-x\u00a0customize-group\u00a0slime-ros"], "package_code": ["$ sudo apt-get install ros-DISTRO-slime-ros", "$ rosrun slime_ros slime_ros_init", "(require 'slime-config \"/opt/ros/DISTRO/share/slime_ros/slime-config.el\")", "$ cd YOUR_CATKIN_WS/src\n", "$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git\n", "$ wstool update ros_emacs_utils\n", "$ cd ..\n", "$ catkin_make\n", "$ catkin_make install\n", "$ emacs -nw ~/.emacs.d/init.el # edit your emacs configuration file"]},
{"url": "https://wiki.ros.org/kurt_base", "package": "kurt_base", "package_summary": ["\n\n     This package contains a driver for KURT mobile robot bases and for their laser rotation units.\n\n  "], "package_details": ["\n", "\n"], "package_tt": ["rot_vel", "cmd_vel", "joint_states", "odom", "imu", "range", "~wheel_perimeter", "float", "~axis_length", "float", "~turning_adaptation", "float", "~ticks_per_turn_of_wheel", "int", "~use_rotunit", "bool", "~x_stddev", "float", "~rotation_stddev", "float", "~cov_xy", "float", "~cov_xrotation", "float", "~cov_yrotation", "float", "~feedforward_turn", "float", "~speedtable", "~ki", "float", "~speedtable", "~kp", "float", "~speedtable", "~publish_tf", "bool", "odom", "base_link", "tf_prefix", "string", "~rotunit_speed", "int", "~speedtable", "string"]},
{"url": "https://wiki.ros.org/rwt_utils_3rdparty", "package": "rwt_utils_3rdparty", "package_summary": ["The rwt_utils_3rdparty package"]},
{"url": "https://wiki.ros.org/view_controller_msgs", "package": "view_controller_msgs", "package_summary": ["Messages for (camera) view controllers"], "package_details": ["\n", "\n", "\n", "This package provides the messages necessary for controlling the behaviour of the RViz view controller plugin provided by the ", " package. ", "This package has been released into Hydro and Indigo. Installation through ", " is easiest in most cases (note that installation of ", " should install this package as a dependency automatically): ", "See the ", ", ", " and ", " Python scripts installed in the packages directory for examples of how to use the messages provided by this package. "], "package_tt": ["apt-get", "CameraTest", "ControlsTest", "SquareTest"], "package_code": ["sudo apt-get install ros-hydro-view-controller-msgs", "sudo apt-get install ros-indigo-view-controller-msgs"]},
{"url": "https://wiki.ros.org/nao_dcm_bringup", "package": "nao_dcm_bringup", "package_summary": ["Bring-up the nao_dcm driver to connect to Aldebaran's Nao robot (v4)."], "package_details": ["\n", "\n", "\n", "\n", "\n"], "package_code": ["sudo apt-get install ros-indigo-nao-robot ros-indigo-nao-meshes ros-indigo-nao-control", "catkin_make", "roslaunch nao_dcm_bringup nao_dcm_H25_bringup_remote.launch robot_ip:=<ROBOT_IP>", "roslaunch nao_moveit_config moveit_planner.launch", "roslaunch nao_dcm_bringup nao_dcm_H25_bringup_position.launch robot_ip:=<ROBOT_IP>", "rostopic pub /nao_dcm/LWristYaw_position_controller/command std_msgs/Float64 \"data: 0\""]},
{"url": "https://wiki.ros.org/khi_robot", "package": "khi_robot", "package_summary": ["Meta package for khi_robot"]},
{"url": "https://wiki.ros.org/kuka_rsi_hw_interface", "package": "kuka_rsi_hw_interface", "package_summary": ["A ROS-Control hardware interface for use with KUKA RSI"], "package_details": ["\n", "\n", "\n", "\n", "This package is part of the ", " program. ", "See the ", " page. ", "This package can be used with both KR C2 (", ") and KR C4 (", ") controllers. ", "See the ", " page for a listing of common errors and possible solutions. "]},
{"url": "https://wiki.ros.org/kuka_resources", "package": "kuka_resources", "package_summary": ["\n      Shared resources for KUKA manipulators within ROS-Industrial.\n    ", "\n      This package contains common urdf / xacro resources used by KUKA robot\n      support packages within the ROS-Industrial program.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program. ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/rqt_nav_view", "package": "rqt_nav_view", "package_summary": ["rqt_nav_view provides a gui for viewing navigation maps and paths."]},
{"url": "https://wiki.ros.org/viodom", "package": "viodom", "package_summary": ["Visual odometry package, currently supporting stereo camera + IMU"], "package_details": ["\n", "\n", "\n", "\n", " ", "This package contains one single node: ", ", which estimates robot motion based on incoming raw images and IMU mesaurements from the ", ". To correctly estimate the motion, the node first needs to wait for a few seconds to initialize an IMU filter. ", "The transforms tree (following ", ") is as follows: ", "Visual odometry algorithms generally calculate", " To be able to calculate ", " based on ", ",  the transformation from the camera frame to the robot frame has to be  known. Therefore this implementation needs to know the tf ", " \u2192 ", " to be able to publish ", " \u2192 ", ". The node currently uses default values from the sensor setup on the AscTec Neo Research platform. ", "If you use viodom in an academic context, please cite the following publication: ", " "], "package_tt": ["viodom_node", "odom", "base_link", "camera", "base_link", "camera", "odom", "base_link"], "package_code": ["@INPROCEEDINGS{7502653,\n", "  author={F. J. Perez-Grau and F. R. Fabresse and F. Caballero and A. Viguria and A. Ollero},\n", "  booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)},\n", "  title={Long-term aerial robot localization based on visual odometry and radio-based ranging},\n", "  year={2016},\n", "  pages={608-614},\n", "  doi={10.1109/ICUAS.2016.7502653},\n", "  month={June},}"]},
{"url": "https://wiki.ros.org/pattern_manager", "package": "pattern_manager", "package_summary": ["A ROS package for defining, configuring, and working with patterns in robotics applications. This allows a robotics application developer to easily define a pattern, or group of patterns, for batch processing of structured parts, e.g. palletizing operations."], "package_details": ["\n", "\n", " ", " ", "A list of tutorials for getting started with pattern_manager can be found on the tutorials page ", ". These tutorials cover interaction with the pattern_manager node via ROS service calls using CLI.  ", "An RQt-plugin has also been created as a GUI for pattern_manager. It can be found  ", ". ", "Currently, ", " only exists as source files on ", ", although an official release is planned for sometime in the future. "], "package_code": ["    root [tf0]                      # <transform-name> [<transform-number>]\n", "    \u251c\u2500\u2500 grp1 [tf1]                  # transform as pattern group/container\n", "    \u2502   \u251c\u2500\u2500 lin1 [tf2]              # ex. linear pattern of transforms\n", "    \u2502   \u2502   \u251c\u2500\u2500 lin1_1 [tf3]           \n", "    \u2502   \u2502   \u251c\u2500\u2500 lin1_2 [tf4]\n", "    \u2502   \u2502   \u251c\u2500\u2500 lin1_3 [tf5]\n", "    \u2502   \u2502   \u2514\u2500\u2500 ...\n", "    \u2502   \u2514\u2500\u2500 lin2 [tf11]\n", "    \u2502       \u251c\u2500\u2500 lin2_1 [tf12]           \n", "    \u2502       \u251c\u2500\u2500 lin2_2 [tf13]\n", "    \u2502       \u2514\u2500\u2500 lin2_3 [tf14]\n", "    \u251c\u2500\u2500 grp2 [tf6]\n", "    \u2502   \u251c\u2500\u2500 grp3 [tf7]\n", "    \u2502   \u2502   \u251c\u2500\u2500 rect1 [tf8]         # ex. rectangular pattern of transforms\n", "    \u2502   \u2502   \u2502   \u251c\u2500\u2500 rect1_1 [tf9]\n", "    \u2502   \u2502   \u2502   \u251c\u2500\u2500 rect1_2 [tf10]\n", "    \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n", "    \u2502   \u2502   \u2514\u2500\u2500 ...\n", "    \u2502   \u2514\u2500\u2500 ...\n", "    \u2514\u2500\u2500 ..."]},
{"url": "https://wiki.ros.org/maggie_motor_drivers", "package": "maggie_motor_drivers", "package_summary": ["motor drivers for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/ros_ethercat_hardware", "package": "ros_ethercat_hardware", "package_summary": ["Package for creating a hardware interface to the robot using the EtherCAT motor controller/driver"]},
{"url": "https://wiki.ros.org/pr2_plugs_common", "package": "pr2_plugs_common", "package_summary": ["\n\n     pr2_plugs_common contains common utilies for plugging in the PR2 robot. \n\n  "]},
{"url": "https://wiki.ros.org/maggie_bringup", "package": "maggie_bringup", "package_summary": ["maggie_bringup launchers"], "package_details": [" is a package that collects together the scripts, ", " files, and dependencies that are required to bring the social robot ", " into a running state. ", "\n", "\n", "\n", "\n", "\n", "\n", "For running all the system is necessary the file ", ". This launch file contains all nodes to run the complete ", " robot. ", "For running the basic of the robot is necessary the file ", ". This launch file contains all nodes to run the complete ", " robot. "], "package_tt": ["maggie_bringup", "maggie_start.launch", "maggie_start_basic.launch", "maggie_start_basic.launch"], "package_code": [" $ roslaunch maggie_bringup maggie_start.launch", " $ roslaunch maggie_bringup maggie_start_basic.launch", " $ ls -la /etc/udev/rules.d | grep maggie", " $ rosrun maggie_bringup install.sh"]},
{"url": "https://wiki.ros.org/mingw_cross", "package": "mingw_cross", "package_summary": ["\n\n     Installer script for the mingw cross environment. This will install to /opt/mingw\n     and immediately begin cross-compiling gcc, boost and qt. Other libraries can be added by\n     simply cd'ing to /opt/mingw and running make for the desired target.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "You can of course install the mingw cross environment directly yourself following the instructions at the ", ". Alternatively: ", "Installation location can be moved if the ", " environment variable is set before running ", ". ", "See the ", " for usage patterns. "], "package_tt": ["MINGW_INSTALL_PREFIX", "make\u00a0install"], "package_code": ["> roscd mingw_cross\n", "> make install       # downloads, installs into ~/mingw \n", "                     # compiles gcc, apr, apr-util, log4cxx, boost, qt\n", "                     # adds mingw_cross binary path to PATH in ~/.bashrc\n", "> make uninstall     # remove ~/mingw and delete modifications in ~/.bashrc", "cd ~/mingw\n", "make wxwidgets"]},
{"url": "https://wiki.ros.org/ros_ethercat_loop", "package": "ros_ethercat_loop", "package_summary": ["Main loop to run EtherCAT robot hardware."]},
{"url": "https://wiki.ros.org/industrial_trajectory_filters", "package": "industrial_trajectory_filters", "package_summary": ["\n     ROS Industrial libraries/plugins for filtering trajectories.\n   ", "\n     This package is part of the ROS Industrial program and contains libraries\n     and moveit plugins for filtering robot trajectories.\n   "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "For more detailed examples see the ", " page. "], "package_tt": ["sample_duration", "float", "n_points", "float"], "package_code": ["  service_type: FilterJointTrajectoryWithConstraints\n", "  filter_chain:\n", "# Uniformly sample motion (creates smooth motion on controller)\n", "  -\n", "    name: uniform_sample_filter\n", "    type: IndustrialUniformSampleFilterJointTrajectoryWithConstraints\n", "    params: {sample_duration: 0.010}\n", "# Limit the number of points sent to the controller\n", "  -\n", "    name: n_point_filter\n", "    type: IndustrialNPointFilterJointTrajectoryWithConstraints\n", "    params: {n_points: 10}", "<arg name=\"planning_adapters\" value=\"   my_filter_package/MyFilter\n", "    default_planner_request_adapters/AddTimeParameterization\n", "    default_planner_request_adapters/FixWorkspaceBounds\n", "    default_planner_request_adapters/FixStartStateBounds\n", "    default_planner_request_adapters/FixStartStateCollision\n", "    default_planner_request_adapters/FixStartStatePathConstraints\" />", "<param name=\"my_filter_parameter\" value=\"40\" />"]},
{"url": "https://wiki.ros.org/urdf_traverser", "package": "urdf_traverser", "package_summary": ["Urdf traverser (C++) which provides functions to traverse\n      the URDF and convenience functions to access the URDF model."]},
{"url": "https://wiki.ros.org/industrial_robot_client", "package": "industrial_robot_client", "package_summary": ["industrial robot client contains generic clients for connecting \n     to industrial robot controllers with servers that adhere to the\n     simple message protocol."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The ", " package provides a standardized interface for controlling industrial robots, based on the ROS-Industrial ", ".  This package includes a C++ reference implementation of the specification, using the ", " protocol to communicate with a compatible server running on a standalone industrial robot controller. ", "Primarily, this package provides the industrial_robot_client library.  The intent is for robot-specific implementations to reuse code from this library using standard C++ derived-class mechanisms, to avoid much of the copy/paste duplication in current industrial-robot driver implementations.  ", " ", "This package also provides generic nodes exposing the base industrial_robot_client functionality.  If a robot does not require any specific client-side code, then it may be sufficient to run these standard nodes.  ", " describes this usage in more detail. ", "A ROS-Industrial REP describing the Simple Message protocol is currently being reviewed. See ", ". ", "Rather than make a new copy of the entire ROS client codebase, it is recommended that the integrator use a derived-class approach to only re-implement the minimal functionality required.  Wherever possible, the new code should call the base class reference-implementation functions to avoid code duplication and maintain consistent operations.  It may be helpful to review the library's ", " to determine which functionality may need replacing.  Simple joint reordering and renaming can be handled through existing capabilities, as described ", ". "], "package_tt": ["industrial_robot_client"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/kobuki_msgs", "package": "kobuki_msgs", "package_summary": ["\n      Kobuki message and service types: custom messages and services for Kobuki packages.\n    "], "package_details": [" ", "\n", "\n"], "package_tt": ["<kobuki\u00a0AT\u00a0yujinrobot\u00a0DOT\u00a0com>"], "package_code": ["$ sudo apt-get install ros-groovy-kobuki-msgs", "$ sudo apt-get install ros-hydro-kobuki-msgs"]},
{"url": "https://wiki.ros.org/pr2_arm_kinematics", "package": "pr2_arm_kinematics", "package_summary": ["This package provides a kinematics implementation for the PR2 robot. It can be used to compute forward and inverse kinematics."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The pr2_arm_kinematics package is a PR2 specific package that provides IK solutions for the PR2 robot arms. The recommended interface is through ROS. The node provides multiple interfaces (listed in the ROS API below) and can be used to compute the closest IK solution to an initial guess. More information on using this package can be found in the API documentation. Example code for using this package can be found in the ", ". ", "pr2_arm_kinematics provides services for IK computation. It can be configured using ROS parameters. The ROS API is explained in greater detail below. To get a collision free version of this node, check out the ", ". ", "Tutorials for this package can be found in the ", ". "], "package_tt": ["node_namespace/get_ik", "node_namespace/get_fk", "node_namespace/get_ik_solver_info", "node_namespace/get_fk_solver_info", "~free_angle", "int", "~search_discretization", "double", "~root_name", "string", "~tip_name", "string"]},
{"url": "https://wiki.ros.org/rr_openrover_basic", "package": "rr_openrover_basic", "package_summary": ["The rr_openrover_basic package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_basic/fan_speed", "/rr_openrover_basic/odom_encoder", "/rr_openrover_basic/raw_fast_rate_data", "/rr_openrover_basic/raw_med_rate_data", "/rr_openrover_basic/raw_slow_rate_data", "/rr_openrover_basic/battery_status_a", "/rr_openrover_basic/battery_status_b", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["sudo apt-get install ros-kinetic-rr-openrover-basic", "roslaunch rr_openrover_basic example.launch", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_basic openrover_basic_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_basic\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"openrover_basic_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover InOrbit Diagnostics -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/nao_description", "package": "nao_description", "package_summary": ["Description of the Nao robot model that can be used with robot_state_publisher to display the robot's state of joint angles."], "package_details": [" ", "\n", " ", " ", "Nao's URDF description contains all joints and links according to the ", " for V3 and V4 Naos. In accordance with ", " and ", " the root link is ", ", directly connected to ", ". The camera frames are ", " and ", ". ", " publishes the ", " transform and a ", " frame, projected between the feet on the ground. The defined links for the end effectors are ", " for the arms and ", " for the feet. "]},
{"url": "https://wiki.ros.org/utilmm", "package": "utilmm", "package_summary": ["\n    This library is a collection of useful C++ classes\n  "]},
{"url": "https://wiki.ros.org/nao_apps", "package": "nao_apps", "package_summary": ["Applications for NAO using the NAOqi API"], "package_details": ["\n", "\n"], "package_tt": ["nao_alife/disabled", "nao_alife/interactive", "nao_alife/safeguard", "nao_alife/solitary", "nao_behaviors", "run_behavior", "get_installed_behaviors", "diagnostics", "nao_footsteps", "footstep", "footstep_srv", "clip_footstep_srv", "~init_stiffness", "float", "nao_leds", "blink", "colors", "blink_duration", "blink_rate_mean", "blink_rate_sd", "bg_color", "fade_rgb", "led_name", "color", "fade_duration", "speech_action/goal", "/speech_vocabulary_action/goal", "speech", "word_recognized", "reconfigure", "start_recognition", "stop_recognition", "~voice", "string", "~language", "string", "~volume", "float", "~vocabulary", "list\u00a0of\u00a0strings", "~enable_audio_expression", "boolean", "~enable_visual_expression", "boolean", "~word_spotting", "boolean", "tactile_touch", "bumper", "foot_contact", "nao_walker", "speech", "cmd_vel", "cmd_pose", "cmd_step", "read_foot_gait_config_srv", "cmd_vel_srv", "cmd_step_srv", "cmd_pose_srv", "stop_walk_srv", "needs_start_walk_pose_srv", "enable_arms_walking_srv", "~step_frequency", "double", "~use_walk_pose", "boolean", "~enable_foot_contact_protection", "boolean", "~use_foot_gait_config", "boolean", "~foot_gait_config", "ALValue/Tupel", "~init_stiffness", "float"]},
{"url": "https://wiki.ros.org/khi_duaro_gazebo", "package": "khi_duaro_gazebo", "package_summary": ["The khi_duaro_gazebo package"]},
{"url": "https://wiki.ros.org/mpc_local_planner", "package": "mpc_local_planner", "package_summary": ["The mpc_local_planner package implements a plugin\n    to the base_local_planner of the 2D navigation stack.\n    It provides a generic and versatile model predictive control implementation\n    with minimum-time and quadratic-form receding-horizon configurations."]},
{"url": "https://wiki.ros.org/motoman_sia5d_moveit_config", "package": "motoman_sia5d_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the motoman_sia5d with the MoveIt Motion Planning Framework"], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/maggie_rfid", "package": "maggie_rfid", "package_summary": ["rfid node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["rfid_write", "rfid_write", "~num_device", "int"], "package_code": [" $ roslaunch maggie_rfid rfid_head.launch robot:=maggie", " $ roslaunch maggie_rfid rfid_base.launch robot:=maggie", " $ rostopic echo /maggie/rfid_write"]},
{"url": "https://wiki.ros.org/khi_duaro_ikfast_plugin", "package": "khi_duaro_ikfast_plugin", "package_summary": ["The khi_duaro_ikfast_plugin package"]},
{"url": "https://wiki.ros.org/naoqi_driver_py", "package": "naoqi_driver_py", "package_summary": ["\n      Python implementation of the driver package for the Naoqi robot, providing access to walking commands,\n      joint angles, and sensor data (odometry, IMU, ...). The\n      most-current version is compatible with the Nao API version 1.12 or newer,\n      connecting to a real or simulated Nao by wrapping Aldebaran Robotics'\n      NaoQI API in Python. This requires the \"lib\" directory of the Aldebaran\n      Python SDK to be in your PYTHONPATH environment variable.\n\n      Note that cameras drivers are provided in a separate package (naoqi_sensors_py).\n    "], "package_details": ["\n", "\n"], "package_tt": ["odom", "imu", "joint_states", "joint_stiffness", "~sensor_rate", "float", "~base_frame_id", "string", "~odom_frame_id", "string", "~use_joint_sensors", "boolean", "base_link", "odom", "/move_base_simple/goal", "/rosout"]},
{"url": "https://wiki.ros.org/urdf_viewer", "package": "urdf_viewer", "package_summary": ["A urdf viewer which converts the URDF to inventor first\n      and then displays it in SoQtExaminerViewer"]},
{"url": "https://wiki.ros.org/velo2cam_calibration", "package": "velo2cam_calibration", "package_summary": ["The velo2cam_calibration package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", ": In order to test the algorithm with a proper ground truth, a simulator environment in Gazebo is provided ", " ", "\n", " ", ": Other size may be used for convenience. If so, please configure nodes parameters accordingly. ", "\n", "Package developed at ", ", Universidad Carlos III de Madrid. ", "cloud1 (velo2cam_calibration::", ") ", "cloud2 (velo2cam_calibration::", ") ", "\n", "[1] Guindel, C., Beltr\u00e1n, J., Mart\u00edn, D. and Garc\u00eda, F. (2017). Automatic Extrinsic Calibration for Lidar-Stereo Vehicle Sensor Setups. ", ". ", "Pre-print available ", " "], "package_code": ["roslaunch velo2cam_calibration laser_pattern.launch", "roslaunch velo2cam_calibration stereo_pattern.launch", "roslaunch velo2cam_calibration velo2cam_calibration.launch"]},
{"url": "https://wiki.ros.org/soem", "package": "soem", "package_summary": ["ROS wrapper for the Simple Open EtherCAT Master SOEM.\n    This is an updated version of the original SOEM wrapper released into ROS now including\n    the upstream Repo as a git subtree."], "package_details": ["See ", " in the repository for further information. "]},
{"url": "https://wiki.ros.org/tuw_multi_robot_goal_generator", "package": "tuw_multi_robot_goal_generator", "package_summary": ["The tuw_multi_robot_goal_generator package"], "package_details": ["\n", "\n", "\n", "  (", ") ", "\n", " (", " default: \"/tmp/goals.txt\") ", " (", " default: \"false\") ", "\n", "\n", "  (", ") ", "\n", " (", " default: \"/tmp/goals.txt\") ", " (", " default: \"1.0\") ", " (", " default: \"false\") ", " (", " default: \"true\") ", "\n", "\n", "  (", ") ", "\n", "  (", ") ", "  (", ") ", "\n", " (", " default: \"-\") ", " (", " default: \"-1\") ", " (", " default: \"map\") ", " (", " default: \"robot_\") ", " (", " default: \"0.5\") ", " (", " default: \"2.0\") ", " (", " default: \"0.2\") ", " (", " default: \"1000\") ", "\n", "Use GitHub to ", ". [", "]", "\n  "], "package_tt": ["goals", "tuw_multi_robot_msgs/RobotGoalsArray", "~run_once", "string", "~file_name", "bool", "goals", "tuw_multi_robot_msgs/RobotGoalsArray", "~file_name", "string", "~loop_rate", "double", "~run_once", "bool", "~time_now", "time_now", "map", "nav_msgs/OccupancyGrid", "goals", "tuw_multi_robot_msgs/RobotGoalsArray", "valid_goal_locations", "nav_msgs/OccupancyGrid", "~nr_of_robots", "int", "~nr_of_available_robots", "int", "~frame_id", "string", "~robot_name_prefix", "string", "~distance_boundary", "double", "~distance_between_robots", "double", "~distance_to_map_border", "double", "~max_resample", "int"]},
{"url": "https://wiki.ros.org/pr2_mechanism_msgs", "package": "pr2_mechanism_msgs", "package_summary": ["This package defines services that are used to communicate with\n     the realtime control loop. It also defines messages\n     that represent the state of the realtime controllers, the joints\n     and the actuators."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/oculus_rviz_plugins", "package": "oculus_rviz_plugins", "package_summary": ["RViz plugins for the Oculus Rift."], "package_details": ["\n", " ", "In RViz, add an OculusDisplay. This will create an additional window with a stereo rendering of the contents of the main RViz rendering area. Check \"Render to Oculus\" to render in full screen mode on your Oculus headset. Like with any Oculus application, it must be set up as secondary screen for this to work. "]},
{"url": "https://wiki.ros.org/raspimouse_sim", "package": "raspimouse_sim", "package_summary": ["ROS package suite for Raspberry Pi Mouse Simulator"], "package_details": ["\n", " ", "\n", " ", "\n", "\n"]},
{"url": "https://wiki.ros.org/rotors_gazebo_plugins", "package": "rotors_gazebo_plugins", "package_summary": ["The rotors_gazebo_plugins package"]},
{"url": "https://wiki.ros.org/rail_face_detection", "package": "rail_face_detection", "package_summary": ["Face Detection methods used in the RAIL Lab"]},
{"url": "https://wiki.ros.org/master_discovery_fkie", "package": "master_discovery_fkie", "package_summary": ["Discover the running ROS Masters in local network. The \n     discovering is done by sending an echo heartbeat messages to a defined \n     multicast group.\n     The alternative is to use a zeroconf/avahi daemon to register the ROS \n     master as service and discover other ROS masters.", "\n"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", " ", " ", "This package contains discovery nodes to detect a ROS master in a multi robot system. There are currently two nodes 'master_discovery' and 'zeroconf' which uses different discovery strategies. 'zeroconf' node uses an avahi implementation of zeroconf technique. The 'master_discovery' node sends periodically a multicast message to notify about an available ROS master.  Furthermore the ROS master will be monitored for changes. On changes other discovery nodes are notified using a timestamp. This feature is used e.g. by ", " to syncronize the ROS masters. Moreover an XML-RPC server created by a discovery node helps to avoid a lot of requests on remote ROS master for a synchronization. ", "To use ", " for discovering you need to run: "], "package_tt": ["zeroconf", "python-avahi", "avahi-daemon", "~changes", "~linkstats", "zeroconf", "~list_masters", "~name", "String", "hostname", "~rpc_port", "int", "11611", "~rosmaster_hz", "int", "1", "Hz", "~heartbeat_hz", "int", "2", "Hz", "master_discovery", "~mcast_group", "String", "master_discovery", "~mcast_port", "int", "11511", "master_discovery", "~static_hosts", "list", "[]", "master_discovery", "~changes", "~linkstats", "zeroconf", "~list_masters", "~refresh", "~name", "String", "hostname", "~rpc_port", "int", "11611", "~rosmaster_hz", "int", "1", "Hz", "~heartbeat_hz", "int", "2", "Hz", "master_discovery", "~mcast_group", "String", "master_discovery", "~mcast_port", "int", "11511", "master_discovery", "~interface", "str", "master_discovery", "~robot_hosts\u00a0(since\u00a0v0.4.0)", "list", "[]", "static_host", "master_discovery", "~static_hosts\u00a0(until\u00a0v0.4.0)", "list", "[]", "master_discovery", "~remove_after", "float", "300.0", "~active_request_after", "float", "60.0", "master_discovery", "~send_mcast", "bool", "True", "master_discovery", "~listen_mcast\u00a0(since\u00a0v0.7.0)", "bool", "True", "master_discovery", "masterContacts()", "empty", "[str,\u00a0str,\u00a0str,\u00a0str,\u00a0str]", "masterInfo()", "empty", "(float,\u00a0float,\u00a0str,\u00a0str,", "[\u00a0[str,[str]\u00a0]\u00a0],", "[\u00a0[str,[str]\u00a0]\u00a0],", "[\u00a0[str,[str]\u00a0]\u00a0],", "[\u00a0[str,str]\u00a0],", "[\u00a0[str,str,str,int,str]\u00a0],", "[\u00a0[str,str,str,str,str]\u00a0])", "publishers", "subscribers", "services", "nodes", "topicTypes", "serviceProvider"], "package_code": ["rosmake master_discovery_fkie", "catkin_make", "rosrun master_discovery_fkie master_discovery", "rosrun master_discovery_fkie zeroconf", "[stamp, stamp of local changes, masteruri, name, publishers, subscribers, services, topicTypes, nodes, serviceProvider]", "[ [topic1, [topic1Publisher1...topic1PublisherN]] ... ]", "[ [topic1, [topic1Subscriber1...topic1SubscriberN]] ... ]", "[ [service1, [service1Provider1...service1ProviderN]] ... ]", "[ [topicName1, topicType1], ... ]", "[ [nodename, XML-RPC URI, origin ROS_MASTER_URI, pid, {str(local) or str(remote)} ], ... ]", "[ [service, XML-RPC URI, origin ROS_MASTER_URI, type, {str(local) or str(remote)} ], ... ]"]},
{"url": "https://wiki.ros.org/simple_message", "package": "simple_message", "package_summary": ["simple_message defines a simple messaging connection and protocol for communicating \n\twith an industrial robot controller.  Additional handler and manager classes are \n\tincluded for handling connection limited systems.  This package is part of the ROS-Industrial \n\tprogram."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The Simple Message (SimpleMessage) protocol defines the message structure between the ROS driver layer and the robot controller itself.  The protocol meets the following requirements: ", "See ", " for documentation on officially assigned message identifiers to be used for the ", " field. ", "The message protocol allows for an arbitrary data payload for message and communications types.  However, the client/server model requires that both understand the data payload associated with the different message and communications types.  The typed message class enforces the data payload structure.  The typed message base class provides methods for creating topic, reply, and request messages.  If used in both the client and server, the developer need not understand the structure of the data payload.  Unfortunately, a typical robot controller cannot use C++ classes, and thus the developer must understand the message protocol and payload data structure in order to parse it on the robot controller side.  The documentation on message specific structures can be found in the source header files.  For convenience the message structure is also shown here for common message types.  For a more detailed example of a typed message structure and how it is used see the following ", ". ", "The point data serves as a waypoint along a trajectory and is meant to mirror the ", " message. ", "This point differs from the ROS trajectory point in the following ways: ", "The simple message utilizes a abstract connection (SmplMsgConnection) interface to send messages to the industrial robot controller.  The interface makes two assumptions: ", "The Message Manager and Handler (MessageManager and MessageHandler) classes can be used to manage a connection that allows for multiple message types to be handled.  The message manager contains a list of message handlers and executed the appropriate handler when a message is received.  These classes are particularly useful on robot controllers which may have a limited number of connections available to them. ", "A Lua Wireshark dissector plugin for the simple message protocol is available from ", " at GitHub. See the readme for information on how to install it. "], "package_tt": ["MSG_TYPE"], "package_code": ["rosbuild_add_executable(my_exe my_exe.cpp)\n", "target_link_libraries(my_exe simple_message)\n", "OR\n", "target_link_libraries(my_exe simple_message_bswap)"]},
{"url": "https://wiki.ros.org/pr2_computer_monitor", "package": "pr2_computer_monitor", "package_summary": ["Monitors the computer's processor and hard drives of the PR2 and publishes data to diagnostics."], "package_details": ["\n", "\n", "\n", "\n", " uses command line tools to monitor the CPU. These commands are called in timer threads every 10 seconds or so to keep load down. ", "\n", "\n", "\n", " uses command line tools to monitor the HD. ", " will only check the disk usage if the home directory argument is set from the command line. ", "\n", "\n", "\n", " uses ntpdate to check the offset in clocks, using the NTP protocol. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Each computer has two times: the time ", " thinks it is, and the system time. When they disagree, ", " slowly slews the system time until they match again. When you do ", " you compare host's chrony time with the local system time. Doing ", " allows you to verify that the chrony time and the system time match. ", "The ", " script uses the command: ", "With proper system dependencies, ", " can work on almost any linux system. Use ", " to install required packages from the operating system: ", "It's a good idea to verify the installation of ", ". To contact ", " (which measures hard drive temperature), pr2_computer_monitor opens a socket to the ", " daemon. ", "First, verify that the ", " daemon is running. ", "If ", " isn't up and running, start it by typing: ", "Now, check if you have ", " installed correctly. If you choose not to use ipmitool to monitor CPU temperature and fan speed, disable it with ", " parameter to False.  ", "If this command returns with an error (below), then you will need to disable the ipmitool checks using the ", " parameter. ", "The ", " command needs to work properly without a password. If the above command asks for a \"sudo\" password, you'll need to edit the sudoers file: ", "Add the following line to use ", " without typing your password: ", "If your computers uses NFS, then you should enable the ", " parameter for CPU monitor. The NFS status messages will have no data if not enabled. ", "CPU monitor will warn if the CPU cores start throttling below 2240 MHz. This is appropriate for the PR2, but if your computer is different, disable the ", " parameter. "], "package_tt": ["cpu_monitor.py", "/diagnostics", "~check_core_temps", "boolean", "~check_impi_tool", "boolean", "~enforce_clock_speed", "boolean", "~load1_threshold", "float", "~load5_threshold", "float", "~check_nfs", "boolean", "~num_cores", "int", "cpumonitor.py", "sudo\u00a0ipmitool\u00a0sdr", "cat\u00a0/proc/cpuinfo\u00a0|\u00a0grep\u00a0MHz", "uptime", "free\u00a0-m", "mpstat\u00a0-P\u00a0ALL\u00a01\u00a01", "find\u00a0/sys/devices\u00a0-name\u00a0temp1_input", "hd_monitor.py", "/diagnostics", "~no_hd_temp_warn", "boolean", "hd_monitor.py", "df\u00a0-P\u00a0--block-size=1G\u00a0HOME_DIR", "hd_monitor.py", "ntp_monitor.py", "ntpdate", "/diagnostics", "ntp_monitor.py", "chrony", "chrony", "ntpdate\u00a0-q\u00a0<server>", "ntpdate\u00a0-q\u00a0<hostname>", "/diagnostics", "gpu_status", "nvidia_temp.py", "network_detector", "/network/connected", "~interface_name", "string", "pr2_computer_monitor", "hddtemp", "hddtemp", "hddtemp", "hddtemp", "hddtemp", "ipmitool", "~check_ipmi_tool", "~check_ipmi_tool", "ipmitool", "ipmitool", "~check_nfs", "~enforce_clock_speed"], "package_code": ["Usage: cpu_monitor.py [--diag-hostname=cX]\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  --diag-hostname=DIAG_HOSTNAME\n", "                        Computer name in diagnostics output (ex: 'c1')", "roslaunch pr2_computer_monitor cpu_monitor.launch", "Usage: hd_monitor.py [--diag-hostname=cX]\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  --diag-hostname=DIAG_HOSTNAME\n", "                        Computer name in diagnostics output (ex: 'c1')", "roslaunch pr2_computer_monitor hd_monitor.launch", "$ netcat localhost 7634\n", "|/dev/sda|Hitachi HDT725032VLA360|43|C|", "Usage: ntp_monitor ntp-hostname []\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  --offset-tolerance=OFFSET-TOL\n", "                        Offset from NTP host\n", "  --self_offset-tolerance=SELF_OFFSET-TOL\n", "                        Offset from self\n", "  --diag-hostname=DIAG_HOSTNAME\n", "                        Computer name in diagnostics output (ex: 'c1')", "roslaunch pr2_computer_monitor ntp_monitor.launch", "ntpdate -q <server>\n", "ntpdate -q <hostname>", "Usage: nvidia_temp.py", "sudo nvidia-smi -a", "  <node pkg=\"pr2_computer_monitor\" type=\"network_detector\" name=\"network_detector\" output=\"screen\">\n", "    <param name=\"interface_name\" value=\"wan0\"/>\n", "  </node>", "$ rosdep install pr2_computer_monitor", "$ netcat localhost 7634", "|/dev/sda|Hitachi HDT725032VLA360|41|C|", "sudo hddtemp -d /dev/sda", "sudo ipmitool sdr", "$ sudo ipmitool sdr\n", "Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0: No such file or directory\n", "Get Device ID command failed\n", "Unable to open SDR for reading", "sudo visudo", "sudo ipmitool sdr ALL NOPASSWD"]},
{"url": "https://wiki.ros.org/kuka_kr6_support", "package": "kuka_kr6_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR 6 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 6 manipulators. This currently includes the R700 sixx and\n      the R900 sixx.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      in the ", " version ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/pr2_camera_synchronizer", "package": "pr2_camera_synchronizer", "package_summary": ["\n    The PR2 is equipped with a texture projector that can be used to\n    project a texture onto featureless surfaces, allowing their\n    three-dimensional structure to be determined using stereoscopy. The\n    projector operates in a pulsed mode, producing brief (2ms) pulses of\n    light. Cameras that want to see the texture must expose during the\n    projector pulse; other cameras should be expose while the projector is\n    off.\n    ", "\n      This package contains the pr2_projector_synchronizer node. Based on its dynamically reconfigurable parameters, this node controls the projector pulsing, and sets up triggering of the WGE100 cameras.\n    "], "package_details": ["\n", " ", "\n", " ", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "This section gives an overview of the PR2's camera systems. Some readers may want to skip directly to ", " for a more practical discussion of how to use the robot's cameras, or to the ", " for a detailed description of the pr2_camera_synchronizer parameters. ", "This section shows how to use the ", " to set these parameters, they can be set just as easily using any other ", " mechanism as demonstrated in ", ". ", "Frame rates and projector modes should be set using ", " on the pr2_camera_synchronizer_node. For example:", "The synchronizer will make a best-effort attempt at using the rates and modes you requested, but may have to ", ". In that case, the GUI and parameter will reflect the rates and modes that were actually set. ", "Many WGE100 settings not managed by the synchronizer can be set directly with the cameras by using ", ". A detailed list of which parameters can be set in this way without conflicting with the synchronizer can be found ", ". ", "For the forearm cameras, the camera node (", " or ", ") should be configured directly. For the stereo pairs, the wge100_multi_configurator node (", " or ", ") should be configured; this node controls both cameras of a stereo pair, and will dispatch configuration changes to both underlying camera nodes. ", "For the wide stereo camera:", "For the narrow stereo camera:", "For the right forearm camera:", "For the left forearm camera:", "Please refer to the ", " documentation for details on what these parameters mean. ", "The following parameters can be set: ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ". ", "Please refer to the ", " documentation for details on what these parameters mean. ", "Note 1: the ", " stored in the camera is only valid for the region of interest parameters that were used when it was created. The ", " will refuse to use ", " with the wrong width and height, but will not detect changes in the other parameters. ", "Images from the wide stereo camera and forearm cameras are published in the ", ", ", " and ", " namespaces, whether they are textured or not. ", "To facilitate using the narrow stereo camera in ", " mode, textured images from the narrow stereo camera are always published in the ", " namespace, and untextured images are always published in the ", " namespace. ", "Due to unresolved firmware bugs, it may happen that a WGE100 camera will become unresponsive. The unresponsiveness of the camera can be verified by running:", "The easiest way to reset all the WGE100 cameras while ROS is running on the PR2 is to use the  ", " option to true in the ", " options. This will raise the camera's trigger signal for a few seconds, telling the camera to reset itself. The reset will take about 5-10 seconds.", "Alternatively, a single camera can be reset when ROS is not running by using the ", " utility in ", ". For example:", "In a running PR2, many cameras may be simultaneously in use by different users. Whether the projector should be on at any given time is a combination of the operating modes requested by the user of each camera. The settings of a user's camera depend on whether the projector is on or off. To avoid spurious changes in the settings of one user's camera when another user's camera is reconfigured, the pr2_camera_synchronizer is organized so that there is a master ", " setting, and a ", " setting for each camera.  ", "Users request the ", " that their camera should be in, and the synchronizer decides on the projector state based on the current ", ". For a given ", ", the pr2_camera_synchronizer ensures that the settings of one camera do not depend on the ", " of the other cameras. In a typical use of the synchronizer, the ", " is set once and for all by a high-level decision, and users can adjust ", " at will. ", "The recommended operating mode is ", ". ", " can be used if longer exposures are needed or if the projector is deemed too unpleasant. ", " will most likely not be used in practice. ", "In many cases, the camera frame rate must be some suitable divisor of the ", ". When a user sets the frame rate for a camera, the synchronizer will round that rate to the nearest suitable rate, and report the rounded value back to the user via the ", " mechanism.  ", "The ", " is not affected by the camera settings. When it is set, it is simply rounded to the nearest divisor of 1 kHz. Again the rounded value is reported back via the ", " mechanism. ", "To avoid having texture in images taken by the Prosilica camera, the ", " option can be turned on. In this case, an exposure signal from the Prosilica camera directly inhibits firing of the projector. When the projector is inhibited the WGE100 cameras will continue to be triggered as if the projector was active, so some frames that should be textured may be partially textured or not textured at all. ", "On the other hand, the Prosilica camera projector inhibition will not work between robots. Therefore, Prosilica images from one robot may see texture projected by the other, even if ", " is true. "], "package_tt": ["reconfigure_gui", "forearm_camera_l", "forearm_camera_r", "wide_stereo_both", "narrow_stereo_both", "brightness", "black_level", "auto_exposure", "exposure", "auto_gain", "gain", "companding", "auto_gain_alternate", "gain_alternate", "companding", "width", "height", "horizontal_binning", "vertical_binning", "horizontal_offset", "vertical_offset", "mirror_x", "mirror_y", "rotate_180", "camera_info", "wge100_camera_node", "camera_info", "camera_reset", "camera_synchronizer_node", "reconfigure_cam", "wge100_camera", "projector_mode", "_trig_mode", "_trig_mode", "projector_mode", "projector_mode", "trig_mode", "projector_mode", "_trig_mode", "narrow_stereo_textured", "narrow_stereo_textured", "narrow_stereo", "projector_rate", "projector_rate", "~projector_rate", "double", "~projector_pulse_length", "double", "~projector_pulse_shift", "double", "~projector_mode", "int", "~prosilica_projector_inhibit", "bool", "~stereo_rate", "double", "~wide_stereo_trig_mode", "int", "~narrow_stereo_trig_mode", "int", "~forearm_r_rate", "double", "~forearm_r_trig_mode", "int", "~forearm_l_rate", "double", "~forearm_l_trig_mode", "int", "~projector_tweak", "double", "~camera_reset", "bool"], "package_code": ["$ rosrun dynamic_reconfigure reconfigure_gui /camera_synchronizer_node", "$ rosrun dynamic_reconfigure reconfigure_gui /wide_stereo_both", "$ rosrun dynamic_reconfigure reconfigure_gui /narrow_stereo_both", "$ rosrun dynamic_reconfigure reconfigure_gui /forearm_camera_r", "$ rosrun dynamic_reconfigure reconfigure_gui /forearm_camera_l", "$ rosrun wge100_camera discover lan0\n", "Found camera serial://1800023 name://forearm_l MAC: 00:24:cd:00:00:f0 iface: lan0 current IP: 10.68.0.42, PCB rev: C HDL rev: 504 FW rev: 202\n", "Found camera serial://3001038 name://wide_stereo_r MAC: 00:24:cd:00:01:01 iface: lan0 current IP: 10.68.0.46, PCB rev: C HDL rev: 504 FW rev: 202\n", "Found camera serial://3001039 name://wide_stereo_l MAC: 00:24:cd:00:00:fc iface: lan0 current IP: 10.68.0.45, PCB rev: C HDL rev: 504 FW rev: 202\n", "Found camera serial://2701021 name://narrow_stereo_r MAC: 00:24:cd:00:01:02 iface: lan0 current IP: 10.68.0.44, PCB rev: C HDL rev: 504 FW rev: 202\n", "Found camera serial://1800031 name://forearm_r MAC: 00:24:cd:00:00:ea iface: lan0 current IP: 10.68.0.41, PCB rev: C HDL rev: 504 FW rev: 202\n", "Found camera serial://2701031 name://narrow_stereo_l MAC: 00:24:cd:00:01:03 iface: lan0 current IP: 10.68.0.43, PCB rev: C HDL rev: 504 FW rev: 202", "$ rosrun dynamic_reconfigure dynparam /camera_synchronizer_node camera_reset true", "$ rosrun wge100_camera reconfigure_cam name://wide_stereo_l"]},
{"url": "https://wiki.ros.org/imu_monitor", "package": "imu_monitor", "package_summary": ["This package contains a single node that monitors the drift of the IMU\ngyroscopes. The results are published to the '/diagnostics' topic and\nare aggregated in the PR2 dashboard."], "package_details": [" ", "\n", "\n"], "package_tt": ["imu_monitor.py", "torso_lift_imu/data", "base_odometry/odometer", "/diagnostics"]},
{"url": "https://wiki.ros.org/maggie_ir_drivers", "package": "maggie_ir_drivers", "package_summary": ["ir drivers for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/voronoi_planner", "package": "voronoi_planner", "package_summary": ["A path planner library, that searches a path from robot position to given goal on generalized Voronoi diagram (GVD) which is made up of regions around obstacles on costmap."], "package_details": ["\n", " ", " uses ", " package to make generalized Voronoi diagrams (GVD) which is made up of regions around obstacles on costmap.  ", "\n", "\n", " (", ", default: true) ", "\n", " may be useful. ", "The ", " object exposes its functionality as a ", ". It operates withing a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Planner was tested using ", ", ", " and ", ". ", "To use ", " you need to change ", " of ", " in such a way: ", "Other parameters changed were global_costmap/width and global_costmap/height (in move_base.launch from ", "): ", "Path generated is published in ~<name>/plan topic. Voronoi grid map is published (if publish_voronoi_grid parameter is true) in ~<name>/voronoi_grid. You should configure RViz to view it. "], "package_tt": ["voronoi_planner", "voronoi_planner::VoronoiPlanner", "nav_core::BaseGlobalPlanner", "~<name>/publish_voronoi_grid", "bool", "~<name>/smooth_path", "bool", "~<name>/weight_data", "double", "~<name>/weight_smooth", "double", "voronoi_planner", "base_global_planner"], "package_code": ["    <arg name=\"base_global_planner\" default=\"voronoi_planner/VoronoiPlanner\"/>", "    <param name=\"global_costmap/width\" value=\"35.0\" if=\"$(arg no_static_map)\"/>\n", "    <param name=\"global_costmap/height\" value=\"35.0\" if=\"$(arg no_static_map)\"/>"]},
{"url": "https://wiki.ros.org/segbot_logical_translator", "package": "segbot_logical_translator", "package_summary": ["High-level navigation application for the segbot allowing the segbot to\n    approach and gothrough doors. The application can also be used to determine\n    the segbot's logical location, as well as sense when a door in front of the\n    robot is open or not."]},
{"url": "https://wiki.ros.org/kurt_driver", "package": "kurt_driver", "package_summary": ["kurt_driver"], "package_details": [" ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/iot_bridge", "package": "iot_bridge", "package_summary": ["The iot_bridge provides a bi-directional bridge between ROS and the OpenHAB Home Automation system. This allows a ROS robot to connect to a vast variety of IoT devices such as motion detectors, Z-Wave devices, lighting, door locks, etc."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "When iot_bridge receives a name/value pair from the ROS ", " topic, it publishes those to OpenHAB  and OpenHAB sends that command to the device specified.  The value must be valid for that device.  See ", " for a summary of valid values. ", "A ROS program wants to turn on a ceiling light.  It publishes the following to the ", " topic: ", "When the iot_bridge receives a name/value pair from the ROS ", " topic, it publishes those to OpenHAB and OpenHAB updates the status for the item specified (e.g. indicate that a switch is now ON). ", "A ROS program running Facial Detection detects that Sarah is present.  It publishes the following to the ", " topic: ", "The IoT bridge receives updates from OpenHAB and publishes those as name/value pairs to the ", " ROS topic. ", "For example:  A motion detector is triggered in OpenHAB.  The openhab bridge will publish the following to the ", " topic in ROS ", "A ROS program publishes the following to the ", " topic: ", "Use GitHub to ", " "], "package_tt": ["roslaunch\u00a0iot_bridge\u00a0iot.launch"], "package_code": ["        cd catkin_ws/src\n", "        git clone address-from-above\n", "        cd ..\n", "        catkin_make", "Group ROS (All)\n", "String ROS_Status \"ROS [%s]\"\n", "Switch Light_GF_Corridor_Ceiling  \"Ceiling\"  (GF_Corridor, Lights, ROS)\n", "Switch Light_GF_Bathroom (GF_Bathroom, Lights, ROS)", "       rostopic echo /iot_updates", "    cd catkin_ws/src/iot_bridge/scripts\n", "    ./iot_test  item_name item_value", "           Text item=ROS_Status label=\"ROS [%s]\""]},
{"url": "https://wiki.ros.org/master_sync_fkie", "package": "master_sync_fkie", "package_summary": ["Synchronize the local ROS master to the remote masters \n     discovered by master_discovery_fkie node. The registration\n     of topics and services is only perform by local ROS master.", "\n"], "package_details": ["\n", " in the current state the ", " will be not synchronized. ", "\n", "\n", "\n", "\n", "This package contains a node to synchronize the local ROS master to remote ROS masters discovered by ", " node. For synchronization the ", " will be used. Thereby the regitration of topics/services are performed only on the local ROS master. To obtain a complete synchronization of two ROS master one master_sync node in each \"ROS system\" have to be started. ", "The syncronization will be performed on each time the remote ROS master is changed. The change detection is done by the ", " node. To avoid multiple calls over unreliable connections e.g. ", ", needed for a synchronization, the XML-RPC server of the ", " node is used to get the current state of the remote ROS master. ", "Run the ", " node first. "], "package_tt": ["~changes", "~get_sync_info", "~changes", "~get_sync_info", "~interface_url", "str", "pkg://master_sync_fkie///sync_interface.sync", "ignore_", "sync_", "~resync_on_reconnect", "bool", "True", "~resync_on_reconnect_timeout", "float", "0", "~do_not_sync", "list", "[]", "~ignore_hosts", "array", "[]", "~sync_hosts", "array", "[]", "~ignore_hosts", "~ignore_nodes", "array", "[/rosout,\u00a0\"/*master_sync*\u00a0node\",\u00a0\"remote\u00a0/*master_discovery*\u00a0node\",\u00a0\"/*node_manager\",\u00a0/*zeroconf]", "~sync_nodes", "array", "[]", "~ignore_nodes", "~ignore_topics", "~ignore_services", "~ignore_topics", "array", "['/rosout',\u00a0'/rosout_agg']", "~ignore_nodes", "~ignore_publishers", "array", "[]", "~ignore_subscribers", "array", "[]", "~sync_topics", "array", "[]", "~ignore_nodes", "~ignore_topics", "~ignore_services", "array", "['/*get_loggers',\u00a0'/*set_logger_level']", "~ignore_nodes", "~sync_services", "array", "[]", "~ignore_nodes", "~ignore_services", "~sync_topics_on_demand", "boolean", "sync_nodes", "sync_topics", "sync_*", "~ignore_type", "array", "['bond/Status']", "~sync_remote_nodes", "boolean"], "package_code": ["rosrun master_sync_fkie master_sync"]},
{"url": "https://wiki.ros.org/reemc_controller_configuration", "package": "reemc_controller_configuration", "package_summary": ["Launch files and scripts needed to configure\n    the controllers of the REEM-C robot."]},
{"url": "https://wiki.ros.org/nav2d_navigator", "package": "nav2d_navigator", "package_summary": ["This package provides a node for higher level navigation of a mobile\n    robot in a planar environment. It needs a map and the robot's position\n    within this map to create a plan for navigation. When used together with\n    a SLAM module it can also be used to perform autonomous exploration of\n    the robot's workspace."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " is a ROS node that implements a path planner for navigation and is supposed to be used in conjunction with the 'operator' node. Beside this, the whole functionality is provided by the ", " class, which is exported by this package and can be used from within other nodes as well. ", "Interaction with the Navigator is implemented using the ", " interface. This allows other nodes (e.g. some high level mission control) to start actions like goal navigation or exploration, monitor the progress and eventually cancel an action in progress. The following four actions are available: ", "See the ", " for an example how to setup the Navigator in Stage with a given map of the environment. "], "package_tt": ["navigator", "navigator", "operator", "scan", "tf", "cmd", "~plan", "~markers", "robot_id", "int", "map_frame", "string", "robot_frame", "string", "map_service", "string", "~robot_radius", "double", "~map_inflation_radius", "double", "~navigation_goal_distance", "double", "~navigation_goal_angle", "double", "~navigation_homing_distance", "double", "~exploration_strategy", "string", "~exploration_goal_distance", "double", "~min_replanning_period", "double", "~max_replanning_period", "double", "goal", "StartMapping", "StartExploration"]},
{"url": "https://wiki.ros.org/pose_follower", "package": "pose_follower", "package_summary": ["A implementation of a local planner that attempts to follow a plan as closely as possible."]},
{"url": "https://wiki.ros.org/naoqi_bridge", "package": "naoqi_bridge", "package_summary": ["Meta package to interface ROS with Aldebaran's NAOqi."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "This package is the meta-package for packages that create a bridge with Aldebaran's ", " (versions 1.14 and 2.1). "]},
{"url": "https://wiki.ros.org/irb_2400_moveit_config", "package": "irb_2400_moveit_config", "package_summary": ["irb_2400_moveit_config"], "package_details": ["\n", "This package is part of the ", " program. "]},
{"url": "https://wiki.ros.org/qb_move_hardware_interface", "package": "qb_move_hardware_interface", "package_summary": ["This package contains the hardware interface for qbrobotics\u00ae qbmove device."], "package_details": ["\n", "\n", "This package is barely usable alone since it provides only the hardware interface for the ", " device. "], "package_tt": ["~command_with_position_and_preset", "boolean", "true", "false", "~encoder_resolutions", "int", "0", "8", "~preset_ticks_limit", "int", "encoder_resolutions", "preset_ticks_limit"]},
{"url": "https://wiki.ros.org/motoman_bmda3_support", "package": "motoman_bmda3_support", "package_summary": ["\n      ROS Industrial support for the Motoman bmda3 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman bmda3 manipulators.\n    ", "\n   ", "\n  ", "\n      Joint limits and maximum joint velocities are based on the information \n      found in the online \n      http://www.motoman.com/datasheets/bmda3.pdf\n      All urdfs are based on the default motion and joint velocity limits, \n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/maggie_eyelids", "package": "maggie_eyelids", "package_summary": ["eyelids node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["move_abs_pos", "move_str_pos", "~port", "string", "~side", "string"], "package_code": [" $ roslaunch maggie_eyelids eyelids.launch robot:=maggie", " $ rosservice call /maggie/move_str_pos eyelids_msgs/MoveStrPos \"open\""]},
{"url": "https://wiki.ros.org/rovio", "package": "rovio", "package_summary": ["The rovio stack contains packages to control and query a WowWee Rovio."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "To install the ", " stack, you can choose to either install from source, or from the Ubuntu package: ", "Each control package contains a ", " file which should be edited with the appropriate ROS parameters (e.g. hostname, username, and password to login to your Rovio). These launch files launch the necessary nodes for reading sensor information and control of the Rovio. Additional information on each launch file is given in their respective package wiki pages. ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["rovio", ".wav", "rovio", ".launch"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-rovio"]},
{"url": "https://wiki.ros.org/mpc_local_planner_examples", "package": "mpc_local_planner_examples", "package_summary": ["The mpc_local_planner_examples package"]},
{"url": "https://wiki.ros.org/pr2_ethercat_drivers", "package": "pr2_ethercat_drivers", "package_summary": ["This stack contains drivers for the ethercat system and the peripherals\n    that connect to it: motor control boards, fingertip sensors, texture\n    projector, hand accelerometer."], "package_details": ["\n", "\n", "The ", " stack provides support for the realtime ethernet variant that is used for communication on the PR2 robot.  These drivers are brought up as part of the realtime loop from ", ". ", "Report new issues on ", " "], "package_tt": ["pr2_ethercat_drivers"]},
{"url": "https://wiki.ros.org/industrial_msgs", "package": "industrial_msgs", "package_summary": ["The industrial message package containes industrial specific messages \n\tdefinitions. This package is part of the ROS-Industrial program."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package is part of the ", " program. It contains message definitions used by other packages in the ", " metapackage. "]},
{"url": "https://wiki.ros.org/pheeno_ros_description", "package": "pheeno_ros_description", "package_summary": ["The pheeno_ros_description package"], "package_details": ["\n", "Documentation for our package can be found ", ". We will also be adding documentation to this ROS page in the coming weeks. "]},
{"url": "https://wiki.ros.org/nav2d_localizer", "package": "nav2d_localizer", "package_summary": ["Wrapper around Particle Filter implementation.\n    The SelfLocalizer can be used as library or as a ros-node."]},
{"url": "https://wiki.ros.org/pr2_navigation_apps", "package": "pr2_navigation_apps", "package_summary": ["The pr2_navigation_apps package"], "package_details": ["\n", "\n", "  ", "This stack holds a number of navigation specific applications for the PR2. These applications can be run on the PR2 hardware, or in ", ". The current set of applications in this stack consists of: "]},
{"url": "https://wiki.ros.org/visual_pose_estimation", "package": "visual_pose_estimation", "package_summary": ["\n\n     visual_pose_estimation\n\n  "]},
{"url": "https://wiki.ros.org/agvs_robot_control", "package": "agvs_robot_control", "package_summary": ["The agvs_robot_control package. Robot controller that interacts with Gazebo motor controllers."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/motoman_msgs", "package": "motoman_msgs", "package_summary": ["Messages for the multi-group interface of motoman_driver."]},
{"url": "https://wiki.ros.org/lex_node", "package": "lex_node", "package_summary": ["Package providing a ROS node for interacting with Amazon Lex"], "package_details": ["\n", ": Amazon Lex is a service for building conversational interfaces into any application using voice and text. Amazon Lex provides the advanced deep learning functionality of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (\u201cchatbots\u201d). ", "\n", "\n", "The ROS ", " node enables a robot to comprehend natural language commands by voice or textual input and respond through a set of actions, which an Amazon Lex Bot maps to ROS messages. Out of the box this node provides a ROS interface to communicate with a specified Amazon Lex bot (configured via lex_config.yaml) and requires configuration of AWS credentials. The Amazon Lex bot needs to be defined with responses and slots for customer prompts. A set of default slots and mappings are demonstrated in the ", " and include actions as \u201cCreate <location_name>,\u201d \u201cGo to <location_name>\u201d and \u201cStop.\u201d Additional guides on configuring bots with are available at ", ". ", "The ROS ", "  wraps the ", " in a ROS service API. ", "The source code is released under an ", ". "], "package_tt": ["lex_node", "lex_node"]},
{"url": "https://wiki.ros.org/nao_moveit_config", "package": "nao_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the NAO robot with the MoveIt Motion Planning Framework"], "package_details": ["\n", "Please, find the documentation on the github page ", ". "]},
{"url": "https://wiki.ros.org/ugv_random_walk", "package": "ugv_random_walk", "package_summary": ["A package performs random walk coverage with an unmanned ground vehicle (UGV)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["single_target=true", "ugv_random_walk", "id", "integer", "output", "string", "screen", "screen", "log", "param", "ugv_random_walk.yaml", "ugv_random_walk", "ugv_random_walk", "single_target", "true", "ugv_coverage/goal", "ugv_coverage/result", "target_found", "single_target", "true", "obstacle_detection/get_clear_sector", "area/closest_bound", "~loop_rate", "real", "~queue_size", "integer", "~single_target", "boolean", "~step_size_max", "real", "/rng_seed", "integer"], "package_code": ["roslaunch ugv_random_walk ugv_random_walk.launch"]},
{"url": "https://wiki.ros.org/korg_nanokontrol", "package": "korg_nanokontrol", "package_summary": ["ROS driver to use the Korg NanoKontrol MIDI device as a joystick."], "package_details": ["\n", "\n", " ", "Where ", " is the MIDI ID of your input device. On my system, the ", " is usually device 3. "], "package_tt": ["<id>"]},
{"url": "https://wiki.ros.org/arbotix", "package": "arbotix", "package_summary": ["ArbotiX Drivers"], "package_details": ["\n", " ", "\n", " ", " check out the latest code from our repository: ", "\n", "Please see the individual packages within this stack for documentation. ArbotiX RoboControllers can be purchased from ", " ", "Bug reports, feature requests and patches are welcome. Please post new issues on our ", " site. "], "package_code": ["git clone https://github.com/vanadiumlabs/arbotix_ros.git"]},
{"url": "https://wiki.ros.org/pioneer_teleop", "package": "pioneer_teleop", "package_summary": ["The pioneer_teleop package provides teleoperation using keyboard, sockets or command line for the Adept MobileRobots Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, AmigoBot, PeopleBot, PatrolBot, PowerBot, Seekur and Seekur Jr.)."], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The package is compatible with any robot using ROS ecosystem, but is originally implemented for Adept ", " Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, ", ", ", ", ", ", ", ", Seekur and Seekur Jr.). ", "In case you have a different robot, please read ", " section ", "You need first to get and install ", " package ", "The expected commands are \"", "\", \"", "\", \"", "\" or \"", "\" ", "The expected commands (", " argument) are \"", "\", \"", "\", \"", "\" or \"", "\" ", "The velocity commands are published in ", " topic (see the next section). ", "You modify the .launch scripts to remove the pionner_bringup call, or you execute directly the python scripts located in ", " folder. ", "By default, the scripts publish velocity commands to ", " topic. ", "In case your velocity commands topic has a different name, or you are not using Pionner-compatible robots, you will have to remap your velocity topic to ", " or change the topic name in the python scripts which are located in ", " folder "], "package_code": ["cd ~/catkin_ws/src\n", "git clone https://github.com/amineHorseman/pioneer_teleop.git\n", "rosdep install pioneer_teleop", "cd ~/catkin_ws/src/pioneer_teleop/nodes\n", "sudo chmod +x *.py", "roslaunch pioneer_teleop keyboard_teleop.launch", "roslaunch pioneer_teleop discrete_keyboard_teleop.launch", "roslaunch pionner_teleop socket_teleop.launch", "roslaunch pionner_teleop socket_teleop.launch _port:=12345 _speed:=0.3 _move_time:=2.0", "roslaunch pionner_teleop socket_commandline.launch _direction:=forward", "roslaunch pionner_teleop socket_teleop.launch _direction:=backward _speed:=0.3 _move_time:=2.0"]},
{"url": "https://wiki.ros.org/jsk_smart_gui", "package": "jsk_smart_gui", "package_summary": ["\n\n     jsk_smart_gui for tablets\n\n  "], "package_details": ["Documentation is available ", ". "]},
{"url": "https://wiki.ros.org/mrpt_bridge", "package": "mrpt_bridge", "package_summary": ["C++ library to convert between ROS messages and MRPT classes"], "package_details": ["\n", "\n"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/nav2d_karto", "package": "nav2d_karto", "package_summary": ["Graph-based Simultaneous Localization and Mapping module.\n    Includes OpenKarto GraphSLAM library by \"SRI International\"."]},
{"url": "https://wiki.ros.org/arbotix_python", "package": "arbotix_python", "package_summary": ["Bindings and low-level controllers for ArbotiX-powered robots."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "The arbotix_python package provides a basic ROS interface to an ", " over a USB serial connection, or XBEE wireless radios.  ", "The ", " package also offers several controllers which add higher-level interfaces to common hardware. These include:  ", "The ControllerGUI is a test/teleop node that allows you to control a mobile base and/or your Dynamixel servos. The ControllerGUI publishes geometry_msgs/Twist commands to the ", " topic, and commands to individual servos. It will automatically determine the names and limits of your servos from your YAML specification file. Launching the ControllerGUI is as easy as:  ", "Moving the red dot up drives the robot forward, moving left/right turns in place, etc. The slider bars move servos, but must be checked to be enabled. When not enabled, they will be updated with the values of the last joint_states message, so that when enabled they will not ", " to a position, but just torque-on in place. In the above image, only head_pan and head_tilt are enabled. ", "Working with Dynamixel servos often requires some setup of the servos themselves. This is made easy with the ArbotiX terminal tool. The terminal works like a typical Linux terminal, you can type ", " to query which servos are attached, ", " will ", " the servo with ID 1 to an ID of 2, etc: ", "The terminal has several other commands. Typing ", " will list all commands: "], "package_tt": ["<servo>/command", "/joint_states", "<servo>/relax", "~port", "str", "~baud", "int", "~rate", "int", "~read_rate", "float", "~write_rate", "float", "~sync_read", "boolean", "~sync_write", "boolean", "~dynamixels/<servo>/id", "str", "~dynamixels/<servo>/neutral", "int", "~dynamixels/<servo>/range", "float", "~dynamixels/<servo>/ticks", "int", "~dynamixels/<servo>/min_angle", "float", "~dynamixels/<servo>/max_angle", "float", "~dynamixels/<servo>/max_speed", "float", "~dynamixels/<servo>/invert", "boolean", "~dynamixels/<servo>/readable", "boolean", "arbotix_python", "control_msgs/FollowJointTrajectoryAction", "ls", "mv\u00a01\u00a02", "move", "help"], "package_code": ["port: /dev/ttyUSB1\n", "rate: 15\n", "dynamixels: {\n", "    head_pan_joint: {id: 1, invert: true},\n", "    head_tilt_joint: {id: 2, max_angle: 100, min_angle: -100}\n", "}\n", "controllers: {\n", "  head_controller: {type: follow_controller, joints: [head_pan_joint, head_tilt_joint], action_name: head_controller/follow_joint_trajectory },\n", "  base_controller: {type: diff_controller, base_width: 0.140, ticks_meter: 26145 }\n", "}", "<launch>\n", "  <node name=\"arbotix\" pkg=\"arbotix_python\" type=\"driver.py\" output=\"screen\">\n", "    <rosparam file=\"$(find your_package)/default.yaml\" command=\"load\" />\n", "  </node>\n", "</launch>", "rosrun arbotix_python controllerGUI.py", "$ rosrun arbotix_python terminal.py \n", "ArbotiX Terminal --- Version 0.1\n", "Copyright 2011 Vanadium Labs LLC\n", ">>  ls\n", "   1 .... .... .... .... .... .... .... .... \n", ".... .... .... .... .... .... .... .... .... \n", ">>  mv 1 2\n", "OK\n", ">>  ls\n", "....    2 .... .... .... .... .... .... .... \n", ".... .... .... .... .... .... .... .... ....", ">>  help\n", "ArbotiX Terminal V0.1\n", "\n", "valid commands:\n", " ls - list the servos found on the bus. \n", " mv id id2 - rename any servo with ID=id, to id2\n", " baud b - set baud rate of bus to b\n", " get param id - get a parameter value from a servo\n", " set param id val - set parameter on servo ID=id to val\n", "\n", "valid parameters\n", " pos - current position of a servo, 0-1023\n", " baud - baud rate\n", " temp - current temperature, degrees C, READ ONLY"]},
{"url": "https://wiki.ros.org/qb_chain_control", "package": "qb_chain_control", "package_summary": ["This package contains the ROS node to control multiple qbrobotics\u00ae devices simultaneously."]},
{"url": "https://wiki.ros.org/ps4eye", "package": "ps4eye", "package_summary": ["The ps4eye package"], "package_details": ["see ", " for documentation "]},
{"url": "https://wiki.ros.org/agvs_pad", "package": "agvs_pad", "package_summary": ["The agvs_pad package.Component to control the robot by using a ps3 pad."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ainstein_radar_rviz_plugins", "package": "ainstein_radar_rviz_plugins", "package_summary": ["Radar message type plugins for RViz."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/motoman_driver", "package": "motoman_driver", "package_summary": ["ROS-Industrial nodes for interfacing with Yaskawa Motoman robot controllers."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", ": this is required for the ", ". ", "\n ", "The MotoROS application and source is available for public download.  However, ordering this part number will ensure your controller is updated with correct system software, the MotoROS driver is installed, and all internal parameters are properly configured. ", "\n", ": This is ", ", but will allow you to modify the MotoROS driver which runs on the robot controller. The MotoPlus SDK is ", " required to be able to develop ROS applications, it is only needed if the MotoROS application is to be changed. ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The software will work on all ", ", ", ", ", ", ", " and ", " robot controllers.  However, for DX100 controllers, a specific software option must be explicitly ordered from Motoman in order to enable ROS-Industrial integration (see the ", " section below). ", "For more detailed information, please contact one of the support resources listed on ", " or ", ". ", "The latest MotoROS binary (", " or higher) requires the following controller firmware (or a newer version): ", "Please note that the MotoROS application is now compatible with the Human Collaborative HC series robots. Please review the ", " document to understand the functionality and limitations. ", "The Motoman driver communicates with ROS through the ", " interface, with a few additional Motoman-specific message types.  Trajectories are streamed to the controller using a message format that captures all the ROS ", " data: joint positions, velocities, accelerations, and path timing.  The controller buffers these points and interpolates between them to send commands to the controller at the required timing.  More detail on the internal operations and required ", " commands is documented ", ". ", "See the ", " page for details on installing and using the MotoROS software. ", "See the ", " page for details on alarms and errors when using the MotoROS driver. "], "package_tt": ["v1.5.0", "FS3.30.00-00", "DS3.32.00-14", "-14", "DN2.21.00-00", "YAS1.11.00-00", "YAS2.80.00-00", "YBS2.31.00-00", "180014-1", "167536", "169272-3", "158302", "169272-1", "147961", "169272-2", "166386", "169272-4", "183387", "169272-5", "206078", "simple_message"]},
{"url": "https://wiki.ros.org/mdm_library", "package": "mdm_library", "package_summary": ["This is the core package of the Markov Decision Making Library."]},
{"url": "https://wiki.ros.org/qb_move", "package": "qb_move", "package_summary": ["This package contains the ROS interface for qbrobotics\u00ae qbmove device."]},
{"url": "https://wiki.ros.org/maggie_navigation", "package": "maggie_navigation", "package_summary": ["maggie_navigation metapackage"], "package_details": ["\n", "\n", "\n", "The ", " stack provides configuration files for running the ", " stack on ", " robot in a number of common configurations. For example, the package holds files that configure the ", " node to operate in an odometric frame, and configure the sensors for autonomous navigation. These configuration files are intended for use as building blocks for applications that wish to use autonomous navigation as a component. "]},
{"url": "https://wiki.ros.org/rovio_av", "package": "rovio_av", "package_summary": ["The rovio_av package contains nodes to control and query the audio/video devices on a WowWee Rovio. Video streaming is provided via the gscam package."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains nodes and launch files that can be used to stream video and play sounds on the Rovio. Additionally, included in the ", " package is a selection of ", " files that have been converted to 8000 Hz 16 bit PCM (the native format for the Rovio). These files are conversions from Willow Garage's ", ". These sounds can then be sent to the Rovio via a service call and played on its internal speakers. ", "To install the ", " stack, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file which should be edited with the hostname, username and password to login to your Rovio. Additionally, the username, password, and host should be changed in the ", " variable in order to stream video using ", ". This file launches an instance of the ", " and ", " nodes. To launch these nodes, the following command can be used: ", "With the above nodes running, you can test video streaming with the ", " package using the following command: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["rovio_av", "rovio_av", ".wav", "rovio_audio", ".wav", ".wav", "wav", "wav_play", "/rovio_shared/host", "/rovio_shared/user", "/rovio_shared/pass", "rovio", "rovio_av", "rovio_av.launch", "GSCAM_CONFIG", "rovio_audio", "gscam"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-rovio", "roslaunch rovio_av rovio_av.launch", "rosrun image_view image_view image:=/gscam/image_raw", "rosservice call /wav_play /path/to/rovio/rovio_av/wav/G22.wav"]},
{"url": "https://wiki.ros.org/segbot_bringup", "package": "segbot_bringup", "package_summary": ["Contains launch files and runtime scripts necessary for running\n    segbots in simulation and in the real world.", " ", "Contents", " ", "\n", "The segbot robot is a configurable platform, and can support many different sensor configurations. The segbot_bringup package contains launch files for all common sensor configurations. Each configuration brings up all the low level interfaces of the segbot robot (mobile base + sensor drivers). A secondary goal of this package is to abstract potions of each configuration easily so that configuration can be used within the Gazebo simulator. ", "More formally, a launch file in this package should launch the following: ", "ROS node for the segway base driver, found in the ", " package. For ease of use, a launch file called ", " can be found in this package which wraps the driver with required parameters.  ", "Kinect - The launch files for the Kinect driver can be found in the ", " package, which are called by launch files in segbot_bringup. ", "Hokuyo - Launch file for the Hokuyo from ", " are launched in this package. ", "Sensor Filters (common with simulation) - Data from each sensor is filtered using a number of filters, more details about which can be found in the ", " package. ", " (common with simulation) - publishes all fixed joints of the robot on the ", " tree. ", " (common with simulation) - publish all non-fixed joints to default values (wheels and the castor joint). Since the segbot robot does not have any true actuated joints, publishing default values for these joints is sufficient for now. ", "\n", "Each configuration has an auxiliary files that captures all redundancy between real world and simulation, allowing the auxiliary file to be called from a launch script responsible for launching the robot inside simulation. For a robot configuration called ", " the real robot launch file is called ", " and the auxiliary file is called ", ". ", "In addition, each auxiliary file must expose ", " and ", " as arguments, which are required to launch multiple robots and choose the complexity of the simulation, respectively. To see how these parameters are used, take a look at one of the existing robot launch files in this package, as well as ", " in the ", " package.  ", "\n", "The main launch files that run on the real robot are stored in the ", " directory as ", " and include the auxiliary launch configuration directly. These files need to call ROS nodes corresponding to the drivers for the segway base and sensors directly. ", "The auxiliary files are stored in the ", " directory.  ", "A convenience wrapper around ", " (The segway driver) called ", " can be found in the ", " directory. "], "package_tt": ["launch/segway_base.launch", "<config_name>", "tf_prefix", "use_full_gazebo_model", "segbot_mobile_base.launch", "segway_base.launch"]},
{"url": "https://wiki.ros.org/pepper_description", "package": "pepper_description", "package_summary": ["The pepper_description package"]},
{"url": "https://wiki.ros.org/rcll_fawkes_sim", "package": "rcll_fawkes_sim", "package_summary": ["RCLL simulation access through Fawkes"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides topics and services specific for the ROS integration with the ", " of the ", " (RCLL) that is also used for the ", ". The simulation environment is based on ", " and ", ". Detailed information about the simulation is available on the ", ". ", "For general setup instructions to setup ROS and Fawkes on your system please have a look at our wiki for ", ", or ", ". ", "Then it is time to ", ". First, run without the ROS integration and with the default agent that comes with the simulation. ", "This opens a separate terminal with several tabs. Please see the ", " in the simulation that gives an overview of the tabs and what to do to start the game. Once you set the game to the exploration phase the robots should start moving. If you are at this point, excellent! ", "This will run the simulation without the original agent (no \"-a\" flag) and with the appropriate ROS nodes for a single robot (the robot should still appear in the refbox shell as before and ", " should show many topics, also in the robot1 namespace. ", "At this point you are ready to go! Have a look at the ", " and make the robot do as you wish. ", "If you run into trouble, please join the ", " to ask questions. ", "This node provides an action to execute skills through the ", ", more specifically through its Fawkes implementation ", ". The current version of Fawkes provides the ", " which serves the same purpose (and provides exactly the same ROS message API), please see its documentation on how to execute skills. "], "package_tt": ["rostopic\u00a0list", "rcll_sim/explore_zone_info", "rcll_sim/mps_marker_array", "rcll_sim/mps_light_state", "rcll_sim/amcl_pose", "rcll_sim/navgraph_generate", "rcll_sim/amcl_pose", "rcll/send_beacon", "skiller/goal", "skiller/result", "skiller/feedback", "skiller_status"], "package_code": ["cd fawkes-robotino/bin\n", "./gazsim.bash -x start -r -a -t -n1", "cd fawkes-robotino/bin\n", "./gazsim.bash -x start -n 1 -r -t \\\n", "  --ros-launch-main rcll_fawkes_sim:rcll_fawkes_sim_all_1robot.launch", "rosrun actionlib axclient.py /robot1/skiller fawkes_msgs/ExecSkillAction", "skillstring='ppgoto{place=\"C-CS1-O\"}'"]},
{"url": "https://wiki.ros.org/realsense2_camera", "package": "realsense2_camera", "package_summary": ["RealSense Camera package allowing access to Intel T265 Tracking module and SR300 and D400 3D cameras"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package provides ROS node(s) for using the Intel\u00ae ", "\u2122 SR300 and D400 cameras. ", "Installation instructions can be found ", " ", "The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS ", " packages. Please ", " concerning this package to the realsense_camera ", " Issues. ", "For updated details on this library see the ", ". "]},
{"url": "https://wiki.ros.org/dbc", "package": "dbc", "package_summary": ["DBC file interface.  Read a DBC file, unpack CAN messages and convert to engineering units, pack values into CAN messages for publishing."]},
{"url": "https://wiki.ros.org/pr2_tuck_arms_action", "package": "pr2_tuck_arms_action", "package_summary": ["The pr2_tuck_arms_action package"], "package_details": [" ", "\n", "\n", "See ", " "], "package_tt": ["pr2_tuck_arm_action", "tuck_arms/goal", "tuck_arms/result", "r_arm_controller/<~joint_trajectory_action>\u00a0and\u00a0l_arm_controller/<~joint_trajectory_action>", "~r_joint_trajectory_action", "string", "~l_joint_trajectory_action", "string", "~move_duration", "float", "\u00a0rosrun\u00a0pr2_tuck_arms_action\u00a0tuck_arms.py\u00a0-lt\u00a0"]},
{"url": "https://wiki.ros.org/reemc_robot", "package": "reemc_robot", "package_summary": ["Description and launch files for the REEM-C robot"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/uvc_camera", "package": "uvc_camera", "package_summary": ["A collection of node(let)s that stream images from USB cameras (UVC)\n     and provide CameraInfo messages to consumers. Includes a\n     two-camera node that provides rough synchronization\n     for stereo vision.\n\n     Currently uses the base driver from Morgan Quigley's uvc_cam package."], "package_details": ["\n", " Please use another driver, such as ", " (", "). ", "\n", " ", "\n", "\n", " ", "\n", "\n", "\n", "This package provides drivers for USB Video Class (UVC) cameras. This standard covers almost all consumer webcams.  The source is on github ", " ", "It works with the ROS ", " like other streaming ", ". Its ", " supports binocular streams, publishing synchronized image pairs from two cameras. ", "The drivers are implemented as nodes and as ", ". "], "package_tt": ["image_raw", "camera_info", "camera/image_raw", "video_mode", "set_camera_info", "~camera_info_url", "string", "~device", "string", "~fps", "int", "~width", "int", "~height", "int", "~frame_id", "string", "left/image_raw", "right/image_raw", "left/camera_info", "left/image_raw", "video_mode", "right/camera_info", "right/image_raw", "left/set_camera_info", "right/set_camera_info", "~left/camera_info_url", "string", "~right/camera_info_url", "string", "~left/device", "string", "~right/device", "string", "~fps", "int", "~skip_frames", "int", "~left/rotate", "bool", "true", "~right/rotate", "bool", "true", "~width", "int", "~height", "int", "~frame_id", "string"]},
{"url": "https://wiki.ros.org/joint_trajectory_generator", "package": "joint_trajectory_generator", "package_summary": ["joint_trajectory_generator action takes in a trajectory specified\n    by a number of joint positions, and it generates a new smooth trajectory\n    through these joint positions."], "package_details": [" ", "\n"], "package_tt": ["joint_trajectory_generator", "joint_trajectory_generator/goal", "joint_trajectory_generator/result", "joint_trajectory_action", "~max_acc", "float64", "~/max_vel", "float64", "robot_description", "string"]},
{"url": "https://wiki.ros.org/app_manager", "package": "app_manager", "package_summary": ["app_manager"], "package_details": ["\n", "See ", " in the Building Manager project. "]},
{"url": "https://wiki.ros.org/urdf_parser_plugin", "package": "urdf_parser_plugin", "package_summary": ["This package contains a C++ base class for URDF parsers."]},
{"url": "https://wiki.ros.org/naoqi_sensors_py", "package": "naoqi_sensors_py", "package_summary": ["ROS driver for miscellaneous sensors on NAO.\n    Python bindings for camera, sonar and octomap\n    C++: bindings for camera only (requires NAOqi to build)"], "package_details": ["\n", "\n"], "package_tt": ["camera", "image_raw", "camera_info", "~audio_raw", "~use_ros_time", "boolean", "~frequency", "integer", "sonar", "~memory_key", "string", "Device/SubDeviceList/US/Left/Sensor/Value", "Device/SubDeviceList/US/Right/Sensor/Value", "~frame_id", "string", "LSonar_frame", "RSonar_frame", "~sonar_rate", "float"]},
{"url": "https://wiki.ros.org/roomba_stage", "package": "roomba_stage", "package_summary": ["The roomba_stage package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/prosilica_camera", "package": "prosilica_camera", "package_summary": ["A ROS driver node for AVT/Prosilica Gigabit Ethernet (GigE) cameras."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "This package contains a ROS driver node for ", ". It is built on top of the ", ". ", "The ROS API of this package is stable. The driver node has been tested extensively with the ", " model, which was used in the Willow Garage ", ". The node should work with any AVT/Prosilica GigE camera, and we welcome reports of use with other cameras. ", "This page and the ", " cover expected use of this package. Features of interest to advanced users only are documented ", ". ", "For basic vision processing of camera images, see the ", ". ", "Sets the camera to a fixed IP address. The camera must be visible to ", ", and must be the only camera listed. The camera must be unopened (i.e. ", " should not be running). This tool is normally used once to configure a new camera (see the ", "). "], "package_tt": ["camera/image_raw", "camera/camera_info", "camera/image_raw", "camera/camera_info", "response_namespace", "request_image", "<response_namespace>/image_raw", "<response_namespace>/camera_info", "set_camera_info", "request_image", "~ip_address", "~guid", "~ip_address", "string", "~guid", "string", "~trigger_mode", "str", "~auto_exposure", "bool", "~exposure", "~exposure", "double", "~auto_gain", "bool", "~gain", "~gain", "int", "~auto_whitebalance", "bool", "~whitebalance_red", "~whitebalance_blue", "~whitebalance_red", "int", "~whitebalance_blue", "int", "~frame_id", "str", "~x_offset", "int", "~y_offset", "int", "~width", "int", "~height", "int", "~trigger_mode", "str", "~auto_exposure", "bool", "~exposure", "~exposure", "double", "~auto_gain", "bool", "~gain", "~gain", "int", "~auto_whitebalance", "bool", "~whitebalance_red", "~whitebalance_blue", "~whitebalance_red", "int", "~whitebalance_blue", "int", "~binning_x", "int", "~binning_y", "int", "~x_offset", "int", "~y_offset", "int", "~width", "int", "~height", "int", "~frame_id", "str", "~trig_timestamp_topic", "str", "~trig_rate", "double", "prosilica_node"], "package_code": ["$ set_ip <IP address>"]},
{"url": "https://wiki.ros.org/rospeex", "package": "rospeex", "package_summary": ["Meta package for rospeex packages."]},
{"url": "https://wiki.ros.org/pr2_gazebo_plugins", "package": "pr2_gazebo_plugins", "package_summary": ["Gazebo Plugins for various PR2-specific sensors and actuators on the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " plugin provides ROS topic and service interfaces similar to those provided by the ", " on PR2. ", "\n", "\n", "\n", " plugin provides ROS topics and services similar to those provided by ", " on physical PR2. ", "\n", "\n", "\n", "\n", "\n", "\n", " plugin provides similar ROS interface as ", " on the physical PR2 robot.  This plugin is written in a way that ", " works transparently with either this simulated plugin or the ", " hardware.  For more information on using ", " or ", " with this plugin, please see ", ". ", "\n", "\n", "This package contains dynamic plugins for ", " and ", " integration with simulated hardware. ", "Please see ", " for additional supported hardware components in simulation. ", "This stack will be updated with new features as the PR2 hardware itself is updated. Future versions will also incorporate ", " options to match ORS driver functionality. "], "package_tt": ["GazeboRosControllerManager", "GazeboRosProsilica", "GazeboRosPowerMonitor", "<robotParam>", "<robotNamespace>", "GazeboRosProsilica", "<robotNamespace>", "<imageTopicName>", "<cameraInfoTopicName>", "<pollServiceName>", "<frameName>", "<CxPrime>", "<Cx>", "<Cy>", "<focal_length>", "<distortion_k1>", "<distortion_k2>", "<distortion_k3>", "<distortion_t1>", "<distortion_t2>", "<hackBaseline>", "GazeboRosPowerNode", "<robotNamespace>", "<powerStateTopic>", "<powerStateRate>", "<fullChargeCapacity>", "<chargeRate>", "<dischargeVoltage>", "<dischargeRate>", "<chargeVoltage>", "plugged_in", "<powerStateTopic>", "<imageTopicName>", "<cameraInfoTopicName>", "request_image", "GazeboRosControllerManager"], "package_code": ["    <!-- GazeboMechanismControl -->\n", "    <controller:gazebo_ros_controller_manager name=\"gazebo_ros_controller_manager\" plugin=\"libgazebo_ros_controller_manager.so\">\n", "      <alwaysOn>true</alwaysOn>\n", "      <updateRate>1000.0</updateRate>\n", "      <robotParam>robot_description</robotParam>\n", "      <robotNamespace>/</robotNamespace>\n", "    </controller:gazebo_ros_controller_manager>", "  <body:empty name=\"camera_body_name\">\n", "    <sensor:camera name=\"high_def_sensor\">\n", "      <imageFormat>R8G8B8</imageFormat>\n", "      <imageSize>2448 2050</imageSize>\n", "      <hfov>45</hfov>\n", "      <nearClip>0.1</nearClip>\n", "      <farClip>100</farClip>\n", "      <updateRate>20.0</updateRate>\n", "      <controller:gazebo_ros_prosilica name=\"high_def_controller\" plugin=\"libgazebo_ros_prosilica.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>20.0</updateRate>\n", "        <imageTopicName>/prosilica/image_raw</imageTopicName>\n", "        <cameraInfoTopicName>/prosilica/camera_info</cameraInfoTopicName>\n", "        <pollServiceName>/prosilica/request_image</pollServiceName>\n", "        <frameName>high_def_frame</frameName>\n", "        <CxPrime>1224.5</CxPrime>\n", "        <Cx>1224.5</Cx>\n", "        <Cy>1025.5</Cy>\n", "        <focal_length>2955</focal_length> <!-- image_width / (2*tan(hfov_radian /2)) -->\n", "        <distortion_k1>0.00000001</distortion_k1>\n", "        <distortion_k2>0.00000001</distortion_k2>\n", "        <distortion_k3>0.00000001</distortion_k3>\n", "        <distortion_t1>0.00000001</distortion_t1>\n", "        <distortion_t2>0.00000001</distortion_t2>\n", "        <interface:camera name=\"high_def_iface\"/>\n", "      </controller:gazebo_ros_prosilica>\n", "    </sensor:camera>\n", "  </body:empty>", "    <controller:gazebo_ros_power_monitor name=\"gazebo_ros_power_monitor_controller\" plugin=\"libgazebo_ros_power_monitor.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>1.0</updateRate>\n", "        <timeout>5</timeout>\n", "        <interface:audio name=\"power_monitor_dummy_interface\" />\n", "        <powerStateTopic>power_state</powerStateTopic>\n", "        <powerStateRate>10.0</powerStateRate>\n", "        <fullChargeCapacity>87.78</fullChargeCapacity>\n", "        <dischargeRate>-474</dischargeRate>\n", "        <chargeRate>525</chargeRate>\n", "        <dischargeVoltage>15.52</dischargeVoltage>\n", "        <chargeVoltage>16.41</chargeVoltage>\n", "    </controller:gazebo_ros_power_monitor>"]},
{"url": "https://wiki.ros.org/ocean_battery_driver", "package": "ocean_battery_driver", "package_summary": ["This is an interface to the Ocean Server Technology Intelligent Battery and Power System."], "package_details": ["\n", "\n", "\n", " controls an array of battery controllers.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data.  ", "\n", " (", ") ", "\n", " (", ", default: if no value specified on command-line, 4) ", "The ", " node will report the status of the batteries to diagnostics. It will warn on the diagnostics if a battery does not update within a timeout. "], "package_tt": ["ocean_server", "ocean_server", "/diagnostics", "/battery/server2", "/battery/server", "~number_of_ports", "int", "~debug_level", "int", "~port<ID>", "string", "\"/dev/ttyUSB<ID>\"", "~lag_timeout", "int", "60", "~stale_timeout", "int", "120"]},
{"url": "https://wiki.ros.org/velodyne_simulator", "package": "velodyne_simulator", "package_summary": ["Metapackage allowing easy installation of Velodyne simulation components."], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/slime_wrapper", "package": "slime_wrapper", "package_summary": ["ROS wrapper for slime"], "package_details": ["This is a ROS wrapper around ", ", more precisely, the ", " branch of it, see ", ". "], "package_tt": ["choose-swank-loading-method"]},
{"url": "https://wiki.ros.org/rwt_moveit", "package": "rwt_moveit", "package_summary": ["This package provides a web user interface of ", " on top of visualizer in ", "."]},
{"url": "https://wiki.ros.org/video_player", "package": "video_player", "package_summary": ["Video_player package to play/stream a video with \"gscam\"."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " "], "package_tt": ["mode", "string", "gscam_config", "string"], "package_code": ["sudo apt-get install ros-hydro-gscam", "cd ~/catkin_ws/src", "wstool init\n", "wstool set gscam --git https://github.com/ros-drivers/gscam.git\n", "wstool update", "sudo apt-get install gstreamer-0.10 libgstreamer0.10-0 libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev gstreamer0.10-ffmpeg gstreamer0.10-gconf gstreamer0.10-tools gstreamer0.10-x", "cd ..\n", "catkin_make", "roscore\n", "roslaunch video_player video_player.launch\n", "rosrun video_player test_client ~/catkin_ws/src/tools_robin/video_player/data/Video1"]},
{"url": "https://wiki.ros.org/unique_identifier", "package": "unique_identifier", "package_summary": ["ROS messages and interfaces for universally unique identifiers.\n\n    Not needed for wet packages, use only to resolve dry stack\n    dependencies."], "package_details": ["\n", "\n", "\n", " ", "This stack defines a ROS message for a ", ", as described in ", ". ", "This stack was originally released for Fuerte (without the ", " C++ API).  ", "For Groovy, the C++ ", " API was added. ", "For Hydro, the packages were converted to build using ", ". The ", " stack became an empty meta-stack, depending on ", " and ", " for backwards compatibility with rosbuild stacks. Catkin packages should depend on those packages directly, not depending on ", ". ", "The interface is now ", ". "], "package_tt": ["unique_identifier", "uuid_msgs", "unique_id", "unique_identifier"]},
{"url": "https://wiki.ros.org/ucl_drone", "package": "ucl_drone", "package_summary": ["The ucl_drone package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "1. Install the ", " package. To do this, follow intructions at ", " "], "package_code": ["# cd into ros root dir\n", "roscd\n", "\n", "# clone repository\n", "git clone git:https://github.com/Felicien93/ucl_drone.git\n", "\n", "# compile in the root of ucl_drone package\n", "catkin_make", "#Connect your computer to the drone's network\n", "\n", "#Use telnet to access the drone network informations\n", "telnet 192.168.1.1\n", "\n", "#Display relevant informations\n", "ifconfig ath0\n", "\n", "#Note the drone's MAC address. You will need it later. It is written in the \"HWaddr\" field. MAC address example: 90:03:B7:2A:DF:11\n", "\n", "#Set up your network card\n", "sudo ifconfig eth0 192.168.1.253\n", "\n", "#Type the IP address of your router in your internet navigator\n", "192.168.1.254\n", "\n", "#Connect on the page using the password and ID of the router\n", "\n", "#Go in Network>Interfaces>Edit>LAN and define 192.168.1.254 in the ipv4address field.\n", "\n", "#Go in Network>wifi and click add. Use the controller with \"BGN\" in his description.\n", "\n", "#In \"general setup\" configure the essid fiel on \"drone\" and hide essid.\n", "\n", "#Go back in Network>wifi and click \"enable\" next to the \"drone\" network\n", "\n", "#Click on \"edit\". Go in Mac filter, chose \"allow listed only\" and add the MAC addresses of the drones you connected.\n", "\n", "#In your files (not in navigator) go in src>ucl_drone>drone_preparation>Appareillage and add one file per drone. The file name should be the drone's network name (example: ardrone2_00217) and it should contain the IP address you want it to have (example: 192.168.1.5)", "# Connect to the drones. Go in src>ucl_drone>drone_preparation>Appareillage\n", "bash autoconfarparrot\n", "\n", "# run the program\n", "roslaunch ucl_drone two_simples_new.launch"]},
{"url": "https://wiki.ros.org/ardrone_autonomy", "package": "ardrone_autonomy", "package_summary": ["ardrone_autonomy is a ROS driver for Parrot AR-Drone 1.0 and 2.0 quadrocopters. This driver is based on official AR-Drone SDK version 2.0.1."], "package_details": [" ", "Documentation is hosted ", ". "]},
{"url": "https://wiki.ros.org/rosemacs", "package": "rosemacs", "package_summary": ["ROS tools for those who live in Emacs."], "package_details": [" ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ")", "\n ", " (", ")", "\n ", " (", ")", "\n ", " (", ")", "\n ", " (", ")", "\n ", " (", ") ", " (", ") ", "\n", " (", ") ", " ", "\n", "\n", " maintains information about current ROS topics.  The topic list is used for tab completion, both in the shell and emacs commands, of topics in the appropriate places.   ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", " (", ") ", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", " (", ") ", "\n", "\n", "\n", " is an Emacs extension that allows you to write snippets, which are templates for recurring patterns in source code.  Rosemacs (trunk) provides a few ros-specific ones in the ", " directory.  E.g., if you enable snippets support and set up your path as per the above instructions, if you open up a new file ", " in the ", " package and type ", " followed by ", ", it will: ", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", "This is an emacs extension for dealing with ros.  Simplifies navigating the package system, tracking topics and nodes, and running various commands (", ", ", ", ", ") directly from emacs. ", "Setting up ", " defines a set of ROS-related emacs commands.  These can be either called using the full command names given below (using ", ") or using a keyboard shortcut, if you've set a prefix for the ros-keymap.  For example, given the setup below, ", " will find a package or file using rospack.  Type ", " to see if there's a shortcut for a given command.  Type ", " to see the entire list of keyboard shortcuts.  In this document, we'll list the keyboard shortcut with each command, which has to be preceded with whatever prefix you're using (in our case ", "). ", "If you are a Lisp developer you'll probably need the ", " package. It installs ", " automatically as a dependency. ", "The most up-to-date version of rosemacs code can be found ", ". Installation instructions can be found in the README file. ", "What you'll need to do will be something like the following: ", "IMPORTANT: Make sure the standard ROS variables are always set in the emacs process environment.  For example, if you use bash, follow the standard ROS installation instructions about sourcing ", " in your ", ", and launch emacs from a bash shell. ", "Update your ", ", e.g.: ", "For troubleshooting consult the ", " file. ", "Put the following in your ", " (e.g. ", "): ", "The ", " buffer contains a timestamped list of noteworthy events in the ros system.  Useful for answering the question \"did something unexpectedly die?\" when your system is behaving strangely.  Currently, it keeps track of nodes starting and stopping.   ", "By default, ROS tab completion does not work if you use shell-mode in emacs.  ", " fixes this and adds completion of current nodes and topics.   ", "You can add the following expression to the customization ", ": ", "Invoking rosemacs makes files with extension ", ", ", " and ", " open in Emacs's gdb-script-mode for syntax highlighting.  You can override this behavior by updating the ", " variable after calling ", ". ", "Emacs 23 and later includes ", " which, given a RELAX NG schema, validates xml documents online as you edit them and provides intelligent completion.  Rosemacs includes schemas for roslaunch and manifest.xml files.  This is now automatically setup (with Emacs 23 and later). ", "For more information on programming ROS packages in Lisp see the ", " package wiki. ", "There are various customizable options.  You can set these using emacs's customization system (in the ", " customization group), or by just doing ", " in your .emacs. "], "package_tt": ["roscore", "rosrun", "roslaunch", "rosemacs", "M-x\u00a0command-name", "C-x\u00a0C-r\u00a0C-f", "C-h\u00a0f\u00a0command-name", "C-x\u00a0C-r\u00a0C-h", "C-x\u00a0C-r", "rosemacs", "setup.bash", ".bashrc", "~/.emacs", "find-ros-file", "C-f", "view-ros-file", "f", "find-ros-message", "C-m", "view-ros-message", "m", "find-ros-service", "C-s", "view-ros-service", "s", "{find|view}-ros-{file|message|service}", "ros-load-package-locations", "r", "rosemacs", "ros-rgrep-package", "g", "ros-find-dired", "find", "rosemacs", "display-ros-topic-info", "C-t", "*ros-topics*", "add-hz-update", "h", "rosemacs", "*ros-topics*", "remove-hz-update", "H", "echo-ros-topic", "t", "rosemacs/display-nodes", "C-n", "ros-launch", "C-l", "k", "r", "q", "ros-run", "C-r", "ros-launch", "ros-core", "C-c", "*ros-core*", "*ros-events*", "rosemacs/display-event-buffer", "C-e", "rosemacs", "snippets/", "bar.h", "foo", "wgh", "[TAB]", "foo", "FOO_BAR_H", "foo", "mode-line-format", ".msg", ".srv", ".action", "auto-mode-alist", "invoke-rosemacs", "rosemacs", "(setq\u00a0variable\u00a0value)", "ros-completion-function", "ros-completion-function", "ido-completing-read", "ros-topic-update-interval", "ros-node-update-interval"], "package_code": ["$ sudo apt-get install ros-DISTRO-rosemacs", "$ sudo apt-get install rosemacs-el", "$ cd YOUR_CATKIN_WS/src\n", "$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git\n", "$ wstool update ros_emacs_utils\n", "$ cd ..\n", "$ catkin_make\n", "$ catkin_make install", "$ emacs -nw ~/.emacs.d/init.el", "(add-to-list 'load-path \"/opt/ros/DISTRO/share/emacs/site-lisp\")\n", ";; or whatever your install space is + \"/share/emacs/site-lisp\"\n", "(require 'rosemacs-config)", ";; Load the library and start it up\n", "(require 'rosemacs)\n", "(invoke-rosemacs)\n", "\n", ";; Optional but highly recommended: add a prefix for quick access\n", ";; to the rosemacs commands\n", "(global-set-key \"\\C-x\\C-r\" ros-keymap)", "(:eval (ros-current-pkg-modeline-entry))", "(require 'yaml-mode)\n", "(add-to-list 'auto-mode-alist '(\"\\\\.yml$\" . yaml-mode))\n", "(add-to-list 'auto-mode-alist '(\"\\\\.yaml$\" . yaml-mode))"]},
{"url": "https://wiki.ros.org/lanelet2", "package": "lanelet2", "package_summary": ["Meta-package for lanelet2"], "package_details": ["\n", " is a C++ library for handling map data in the context of automated driving. It is designed to utilize high-definition map data in order to efficiently handle the challenges posed to a vehicle in complex traffic scenarios. Flexibility and extensibility are some of the core principles to handle the upcoming challenges of future maps. ", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", " ", "Lanelet2 is the successor of the old ", " that was developed in 2013. ", "\n", "For more information, please refer to our ", ". ", "If you are using Lanelet2 for scientific research, we would be pleased if you would cite our ", ": "], "package_code": ["@inproceedings{poggenhans2018lanelet2,\n", "  title     = {Lanelet2: A High-Definition Map Framework for the Future of Automated Driving},\n", "  author    = {Poggenhans, Fabian and Pauls, Jan-Hendrik and Janosovits, Johannes and Orf, Stefan and Naumann, Maximilian and Kuhnt, Florian and Mayr, Matthias},\n", "  booktitle = {Proc.\\ IEEE Intell.\\ Trans.\\ Syst.\\ Conf.},\n", "  year      = {2018},\n", "  address   = {Hawaii, USA},\n", "  owner     = {poggenhans},\n", "  month     = {November},\n", "  Url={http://www.mrt.kit.edu/z/publ/download/2018/Poggenhans2018Lanelet2.pdf}\n", "}"]},
{"url": "https://wiki.ros.org/nao_vision", "package": "nao_vision", "package_summary": ["Package for the Nao robot, providing access to NAOqi vision proxies"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " package allows easy control and access of the NAO's vision via ROS. These packages have been tested with ", ". ", "To install the ", " stack, simply run the following commands in your shell: ", "The ", " package contains a ", " file which should be edited with the hostname and port of your NAO. Additionally, if your local ", " does not include the path to your NAOqi /lib folder, an optional parameter can be set in the launch file. Parameters are also included to configure the resolution and the camera (bottom or top) that will be streamed. These are set to the default values in the given launch file. This file launches an instance of the ", " node. To launch this node, the following commands can be used: ", "With the above node running, you can test video streaming with the ", " package using the following command: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments. "], "package_tt": ["nao_vision", "nao_vision", "nao_camera", "nao_vision", "/naoqi/host", "/naoqi/port", "/naoqi/path", "null", "PYTHONPATH", "~resolution", "kQVGA", "kQQVGA", "kQVGA", "kVGA", "~camera", "nao_rail", "nao_vision", "nao_vision.launch", "PYTHONPATH", "nao_vision"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch nao_vision nao_vision.launch", "rosrun image_view image_view image:=/nao_camera"]},
{"url": "https://wiki.ros.org/rovio_shared", "package": "rovio_shared", "package_summary": ["The rovio_shared package contains standard messages and services as well as a library that can be used to communicate with a WowWee Rovio."], "package_details": ["\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"rovio_shared\" in rosdoc: /home/rosbot/docs/api/rovio_shared/manifest.yaml ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " package contains a library that is used to communicate with the Rovio. This package and library are intended to be used with the packages provided in the ", " stack; however, it is possible to compile and use the library in your own packages as well. ", "To install the ", " stack, you can choose to either install from source, or from the Ubuntu package: ", "While the ", " library was constructed primarily for use within the ", " stack's packages, it is possible to utilize its functionality in any ROS node. ", "The example below has the Rovio drive forwards until the user issues a ", " command. Other information on the ", " library can be found in the  ", ". ", "Create a ", " object by supplying it with the username and password to your Rovio. This object with use ", " to communicate to the Rovio's HTTP server. ", "Here we construct and send an HTTP command based on the ", ". In this example we will tell to Rovio to drive forwards at speed 5. This function will return a pointer to a 'rovio_response' struct containing the response from the Rovio. Even if this information is not need it is important to always free this struct once you are finished to prevent a memory leak. ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["rovio_shared", "rovio", "rovio_http", "rovio", "ctrl-c", "rovio_http", "rovio_http", "libcurl"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-rovio", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/kuka", "package": "kuka", "package_summary": ["ROS-Industrial support for KUKA manipulators (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This repository is part of the ", " program. ", "See the ", " metapackage for additional packages, such as ", " configuration packages and ", " plugins. ", "For questions related to the KUKA support or ROS Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "]},
{"url": "https://wiki.ros.org/qb_hand", "package": "qb_hand", "package_summary": ["This package contains the ROS interface for qbrobotics\u00ae qbhand device."]},
{"url": "https://wiki.ros.org/dbw_pacifica_can", "package": "dbw_pacifica_can", "package_summary": ["Drive-by-wire interface to the Chrysler Pacifica DBW kit"]},
{"url": "https://wiki.ros.org/tuw_multi_robot_msgs", "package": "tuw_multi_robot_msgs", "package_summary": ["The tuw_multi_robot_msgs package contains messages for sending graph, route and sync data over topics."], "package_details": ["\n", " ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "This package provides messages to the ", " package to send graphs over topics.  "], "package_tt": ["tuw_multi_robot"]},
{"url": "https://wiki.ros.org/kobuki_description", "package": "kobuki_description", "package_summary": ["Description of the Kobuki model.\n      Provides the model description of Kobuki for simulation and visualisation. The files in this \n      package are parsed and used by a variety of other components. Most users will not interact directly\n      with this package.\n      \n      WARNING: This package is disabled because it cannot be catkinized by now, as xacro dependency is not\n      catkin still. In the interim we use a unary pre-catkin stack named kobuki_description."], "package_details": [" ", "\n", "\n"], "package_tt": ["kobuki.urdf.xacro", "<kobuki/>", "kobuki_standalone.urdf.xacro", "launch/view_model.launch"], "package_code": ["> roslaunch kobuki_description view_model.launch"]},
{"url": "https://wiki.ros.org/blink1", "package": "blink1", "package_summary": ["This package provides a node that manipulates Blink(1) RGB LED using a service. Accompanies the node an API that facilitates the use of the service."], "package_details": ["\n", "\n", "\n", " ", "This node provides a ROS service that manipulates ", ". Accompanies the node an API that facilitates the use of the service. ", "Create a catkin workspace. For instructions on how to create the workspace go ", ". Download and compile the package: ", "To permanently change the permissions of the device and run the node in the user mode, please refer to the ", ". "], "package_code": ["sudo apt-get install libusb-dev", "catkin_ws/src\n", "git clone git@bitbucket.org:castacks/blink1_node.git\n", "cd ..\n", "catkin_make", "catkin_ws/src\n", "git clone  https://bitbucket.org/castacks/blink1_node.git\n", "cd ..\n", "catkin_make", "source devel/setup.bash\n", "roslaunch blink1 blink1.launch", "source devel/setup.bash\n", "rosrun blink1 blink1_example"]},
{"url": "https://wiki.ros.org/arni_rqt_overview_plugin", "package": "arni_rqt_overview_plugin", "package_summary": ["The ARNI rqt_gui overview plugin."]},
{"url": "https://wiki.ros.org/kobuki_testsuite", "package": "kobuki_testsuite", "package_summary": ["Kobuki test suite: this package provides tools to thoroughly test Kobuki's hardware."], "package_details": [" "]},
{"url": "https://wiki.ros.org/rbcar_common", "package": "rbcar_common", "package_summary": ["The rbcar_common package. It contains RBCAR common packages"], "package_details": ["\n", " ", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", ", shared for real robot and simulation.  "]},
{"url": "https://wiki.ros.org/pid", "package": "pid", "package_summary": ["Launch a PID control node."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "You can install the pid package from binaries or build from source. If you install from binaries, the example files discussed below will be in /opt/ros/<release>/share/pid ", "If you're seeing high CPU usage, it's probably due to rqt_plot. You can comment it in the launch files. The PID controller itself (no graphics) typically runs at <10% CPU usage. "], "package_code": ["$ sudo apt-get install ros-indigo-pid", "$ cd catkin_ws/src\n", "$ git clone https://bitbucket.org/AndyZe/pid.git\n", "$ cd ..\n", "$ catkin_make", "$ roslaunch pid servo_sim.launch", "$ rosrun pid autotune", "    <node name=\"left_wheel_pid\" pkg=\"pid\" type=\"controller\" >\n", "      <param name=\"Kp\" value=\"5.0\" />\n", "      <param name=\"Ki\" value=\"0.0\" />\n", "      <param name=\"Kd\" value=\"0.1\" />\n", "      <param name=\"upper_limit\" value=\"10\" />\n", "      <param name=\"lower_limit\" value=\"-10\" />\n", "      <param name=\"windup_limit\" value=\"10\" />\n", "      <param name=\"max_loop_frequency\" value=\"100.0\" />\n", "      <param name=\"min_loop_frequency\" value=\"100.0\" />\n", "    </node>", "rosrun rqt_reconfigure rqt_reconfigure", "    <node name=\"controller\" pkg=\"pid\" type=\"controller\" ns=\"left_wheel\" output=\"screen\" >\n", "      <param name=\"node_name\" value=\"left_wheel_pid\" />\n", "      <param name=\"Kp\" value=\"5.0\" />\n", "      <param name=\"Ki\" value=\"0.0\" />\n", "      <param name=\"Kd\" value=\"0.1\" />\n", "      <param name=\"upper_limit\" value=\"10\" />\n", "      <param name=\"lower_limit\" value=\"-10\" />\n", "      <param name=\"windup_limit\" value=\"10\" />\n", "      <param name=\"max_loop_frequency\" value=\"100.0\" />\n", "      <param name=\"min_loop_frequency\" value=\"100.0\" />\n", "      <remap from=\"setpoint\" to=\"/setpoint\" />\n", "     </node>\n", "\n", "    <node name=\"servo_sim_node\" pkg=\"pid\" type=\"plant_sim\" ns=\"left_wheel\" output=\"screen\" >\n", "      <param name=\"plant_order\" value=\"2\" />\n", "    </node>\n", "\n", "    <node name=\"controller\" pkg=\"pid\" type=\"controller\" ns=\"right_wheel\" output=\"screen\" >\n", "      <param name=\"node_name\" value=\"right_wheel_pid\" />\n", "      <param name=\"Kp\" value=\"-4.0\" />\n", "      <param name=\"Ki\" value=\"-0.0\" />\n", "      <param name=\"Kd\" value=\"-0.3\" />\n", "      <param name=\"upper_limit\" value=\"10\" />\n", "      <param name=\"lower_limit\" value=\"-10\" />\n", "      <param name=\"windup_limit\" value=\"10\" />\n", "      <param name=\"max_loop_frequency\" value=\"100.0\" />\n", "      <param name=\"min_loop_frequency\" value=\"100.0\" />\n", "      <remap from=\"setpoint\" to=\"/setpoint\" />\n", "     </node>\n", "\n", "    <node name=\"servo_sim_node\" pkg=\"pid\" type=\"plant_sim\" ns=\"right_wheel\" output=\"screen\" >\n", "      <param name=\"plant_order\" value=\"2\" />\n", "      <param name=\"reverse_acting\" value=\"true\" />\n", "    </node>", "    <param name=\"use_sim_time\" value=\"true\" />\n", "\n", "        <node name=\"sim_time\" pkg=\"pid\" type=\"sim_time\" output=\"screen\" >\n", "      <param name=\"sim_speedup\" value=\"4\" />\n", "    </node>"]},
{"url": "https://wiki.ros.org/pr2_simulator", "package": "pr2_simulator", "package_summary": ["The pr2_simulator package"], "package_details": [" ", "\n ", "\n", "\n", "\n", "\n", "  ", "\n", "The PR2 simulator is implemented using ", " stack. It is a three-dimensional, rigid-body model of the PR2 robot with most of the hardware-ROS interfaces found on the actual PR2 robot. You can see the ", " package for documentation on the supported interfaces. "]},
{"url": "https://wiki.ros.org/aruco", "package": "aruco", "package_summary": ["The ARUCO Library has been developed by the Ava group of the Univeristy of Cordoba(Spain).\n    It provides real-time marker based 3D pose estimation using AR markers."]},
{"url": "https://wiki.ros.org/kuka_kr16_support", "package": "kuka_kr16_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR16 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 16 manipulators. This currently includes the KR 16-2 only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      found in the online datasheet ", ". All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      ", ": this package currently uses non-valid inertia parameters.\n    "]},
{"url": "https://wiki.ros.org/movie_publisher", "package": "movie_publisher", "package_summary": ["Node for using a video file as video topic source."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The node can run with either of two backends - ", " and ", ". ", " is strongly recommended, as it uses ", ", which is quite versatile and efficient. Is you do not set the ", " param, autodetection is run. ", "It is a Bash script with ROS node-like API - you pass it parameters via ", " on commandline or via ROS param server. ", "Call this script from commandline setting the node-private parameters, and pass any other ", " arguments - these will be relayed to ", " as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ", "). ", "It is a Bash script with ROS node-like API - you pass it parameters via ", " on commandline or via ROS param server. ", "Call this script from commandline setting the node-private parameters, and pass any other ", " arguments - these will be relayed to movie_publisher.launch as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ", "). ", "Goes through ", " and for all messages with a ", " field sets their publication time to the time stored in their ", " plus ", ". If ", " are set, only works on messages on the listed topics. Reading timestamps from ", " is also supported. ", "It is a Python script with ROS node-like API - you pass it parameters via ", " on commandline. "], "package_tt": ["movie_publisher_node", "sensor_msgs/Image", "movie_publisher.launch", "immediate", "movie_to_bag", "add_movie_to_bag", "fix_bag_timestamps", "merge.py", "moviepy", "opencv", "moviepy", "ffmpeg", "backend", "movie\u00a0(sensor_msgs/Image)", "movie_file\u00a0(string,\u00a0required)", "fps\u00a0(float,\u00a0optional)", "start\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "end", "duration", "end\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "start", "duration", "duration\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "start", "end", "loop\u00a0(bool,\u00a0default\u00a0False)", "immediate", "immediate\u00a0(bool,\u00a0default\u00a0False)", "fake_time_start", "loop", "playback_rate\u00a0(float,\u00a0optional)", "fake_time_start\u00a0(float,\u00a0default\u00a00.0)", "immediate", "frame_id\u00a0(string,\u00a0default\u00a0\"\")", "spin_after_end\u00a0(bool,\u00a0default\u00a0False)", "verbose\u00a0(bool,\u00a0default\u00a0False)", "wait_after_publisher_created\u00a0(float,\u00a0default\u00a01.0)", "publisher_queue_size\u00a0(int,\u00a0default\u00a01000\u00a0in\u00a0immediate\u00a0mode,\u00a010\u00a0otherwise)", "queue_size", "backend\u00a0(string,\u00a0default\u00a0\"moviepy\")", "moviepy", "opencv", "moviepy", "opencv", "ffmpeg\u00a0(string,\u00a0default\u00a0\"\")", "transport\u00a0(string,\u00a0default\u00a0'raw')", "image_transport/republish", "republished_topic_basename\u00a0(string,\u00a0default\u00a0movie_$(arg\u00a0transport))", "$(arg\u00a0republished_topic_basename)/$(arg\u00a0transport)", "$(arg\u00a0republished_topic_basename)", "raw", "movie_publisher_node", "movie", "_param:=value", "movie\u00a0(string)", "bag\u00a0(string)", "topic\u00a0(string)", "overwrite_bag\u00a0(bool,\u00a0default\u00a0false)", "bag", "bag", "tmp_bag\u00a0(string,\u00a0default\u00a0/tmp/movie.bag)", "transport\u00a0(string,\u00a0default\u00a0compressed)", "raw", "compressed", "theora", "arg:=value", "movie_publisher.launch", "movie_file", "_param:=value", "movie\u00a0(string)", "bag_in\u00a0(string)", "bag_out\u00a0(string,\u00a0default:\u00a0output.bag)", "topic\u00a0(string)", "movie_delay\u00a0(int,\u00a0default\u00a00)", "overwrite_out_bag\u00a0(bool,\u00a0default\u00a0false)", "bag_out", "bag_out", "bag_tmp\u00a0(string,\u00a0default\u00a0/tmp/movie_add_to.bag)", "transport\u00a0(string,\u00a0default\u00a0compressed)", "raw", "compressed", "theora", "arg:=value", "movie_file", "in_bag", "header", "header.stamp", "delay", "topics", "/tf", "_param:=value", "in_bag\u00a0(string)", "out_bag\u00a0(string)", "topics\u00a0(string,\u00a0default:\u00a0'')", "delay\u00a0(int,\u00a0default\u00a00)", "header", "overwrite_existing\u00a0(bool,\u00a0default\u00a0false)", "out_bag", "out_bag"], "package_code": ["sudo pip install moviepy", "rosdep install python-moviepy-pip", "rosrun movie_publisher movie_to_bag _movie:=movie.mp4 _bag:=movie.bag _topic:=\"/movie\" start:=5 fake_time_start:=1548323340.24", "rosrun movie_publisher add_movie_to_bag _movie:=movie.mp4 _bag_in:=movie_in.bag _bag_out:=movie_out.bag _topic:=\"/movie\" start:=5 movie_delay:=-1"]},
{"url": "https://wiki.ros.org/urdfdom_headers", "package": "urdfdom_headers", "package_summary": ["C++ Headers for URDF"], "package_details": ["This is now an upstream package, and can be found here: ", " "]},
{"url": "https://wiki.ros.org/velodyne_utils", "package": "velodyne_utils", "package_summary": ["\n\n    ROS tools and utilities for Velodyne 3D LIDARs.\n\n  "], "package_details": ["\n", "\n", "In Hydro it is ", ", but still provided. Catkin stacks should never use it, but rosbuild stacks depending on ", " should still work. ", "In Indigo, all references must be changed to use ", " directly. ", "See ", ", the only package. "], "package_tt": ["velodyne_utils"]},
{"url": "https://wiki.ros.org/multimaster_msgs_fkie", "package": "multimaster_msgs_fkie", "package_summary": ["The messages required by multimaster packages."], "package_details": ["\n", "\n", "\n", "\n", "The ", " describes a discovered ROS Master by ", " and ", ". It offers also additional information about corresponding ", " node and timestamps of last detected changes of the ROS Master. The ", " service returns the list with current discovered ROS Masters. The changes of each ROS Master are annonced by ", ". ", "The ", " and ", " messages offers additional information about the link quality to discovered ROS Master machines. ", "The ", " service uses ", " respectively ", " messages to return the all currently synchronized ", " and ", ". ", "The services ", " and ", " returns the nodes and their description. The ", " service can then be used to launch one of these nodes. See ", " for additional information. "], "package_tt": ["name", "uri", "topics", "services"]},
{"url": "https://wiki.ros.org/pepperl_fuchs_r2000", "package": "pepperl_fuchs_r2000", "package_summary": ["The Pepperl+Fuchs R2000 laser range finder driver package"], "package_details": ["\n", " ", "\n", " (from the official datasheet with permission from Pepperl+Fuchs) ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The driver is based upon the widespread boost asio library (", ") ", "The driver comes as a library, which contains the actual driver, and has additionally a ROS-Node interface to the Robot Operating System (", "), which can be used optionally. ", "Official Website: ", " ", "Datasheet OMD10M-R2000 (en): ", " ", "Datasheet OMD30M-R2000 (en): ", " ", "The ROS package ", " consists of the driver library and a node named ", ", which is linked to the library. This is the actual driver node. The ", " is only needed if you want to display the sensors data using the ", " method mentioned below. ", "Copy the driver in your ROS workspace and compile it. Set the IP-Address of the scanner in ", " and run the following command: ", "This starts ", " (", ") and the driver and you should see the measuring output of the scanner. ", "There exists a file ", " in the ", " directory. Replace ", " with it to compile the driver without ROS: ", "This builds a SHARED library which can be used in your program.  To build a static library remove the ", " in the ", " command in the ", ". ", "The driver is commented in doxygen style.  You can create a latex and html documentation in the ", " directory  by entering the following command in the ", " directory: "], "package_tt": ["pepperl_fuchs_r2000", "r2000_node", "dummy_slam_broadcaster", "scan", "scan_frequency", "frame_id", "scanner_ip", "scan_frequency", "samples_per_scan", "pepperl_fuchs_r2000/launch/gui_example.launch", "RViz", "CMakeLists.txt.NO_ROS_LIB_ONLY", "pepperl_fuchs_r2000", "CMakeLists.txt", "SHARED", "add_library", "CMakeLists.txt", "pepperl_fuchs_r2000/doxygen", "pepperl_fuchs_r2000"], "package_code": ["    roslaunch pepperl_fuchs_r2000 gui_example.launch", "    $ cd pepperl_fuchs_r2000\n", "    $ mv CMakeLists.txt.NO_ROS_LIB_ONLY CMakeLists.txt\n", "    $ mkdir build\n", "    $ cd build\n", "    $ cmake ..\n", "    $ make", "    #include <pepperl_fuchs_r2000/r2000_driver.h>\n", "\n", "    int main(int argc, char **argv)\n", "    {\n", "      bool success;\n", "\n", "      pepperl_fuchs::R2000Driver driver;\n", "      success = driver.connect(\"192.168.0.100\"); // Replace IP\n", "      success = driver.setScanFrequency(35);     // Set scanner frequency in the range [10;50]\n", "      success = driver.setSamplesPerScan(3600);  // Set samples per scan in the range [72,25200] (valid values are listed in manual)\n", "\n", "      auto params = driver.getParameters();      // Get all parameter values as std::map<string, string>\n", "      for( auto key_value : params )\n", "      { Do something with the parameter values }\n", "\n", "      success = driver.startCapturingUDP();      // Notice: startCapturingTCP() also exists\n", "\n", "      while(true)\n", "      {\n", "          pepperl_fuchs::ScanData  scandata = driver.getFullScan(); // Do something with:\n", "          scandata.headers;                                         // headers,\n", "          scandata.distance_data;                                   // distances and\n", "          scandata.amplitude_data;                                  // amplitudes\n", "      }\n", "\n", "      driver.stopCapturing();\n", "      driver.disconnect();\n", "    }", "    $ doxygen doxygen.conf"]},
{"url": "https://wiki.ros.org/nodelet", "package": "nodelet", "package_summary": ["The nodelet package is designed to provide a way to run multiple\n    algorithms in the same process with zero copy transport between\n    algorithms.\n\n    This package provides both the nodelet base class needed for\n    implementing a nodelet, as well as the NodeletLoader class used\n    for instantiating nodelets."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Nodelets are designed to provide a way to run multiple algorithms on a single machine, in a single process, without incurring copy costs when passing messages intraprocess. roscpp has optimizations to do zero copy pointer passing between publish and subscribe calls within the same node.  To do this nodelets allow dynamic loading of classes into the same node, however they provide simple separate namespaces such that the nodelet acts like a seperate node, despite being in the same process.  This has been extended further in that it is dynamically loadable at runtime using ", ". ", "For command line and launch file examples see this tutorial ", " ", "These are nodelet aware wrappers around ", " macros.  They include verbosity levels DEBUG, INFO, WARN, ERROR, and FATAL.  These macros will only compile inside nodelet methods. ", "If you want the no-copy pub/sub to work you must publish your messages as ", "s.  See ", " for more details. ", "Following commands are helpful to list all nodelets available on your system found in ", ". Note that it's NOT the list of currently running nodelet nor nodelet managers. ", "Or list the nodelet xml files for ", " by: "], "package_tt": ["shared_ptr", "ROS_PACKAGE_PATH"], "package_code": ["nodelet usage:\n", "nodelet load pkg/Type manager - Launch a nodelet of type pkg/Type on manager manager\n", "nodelet standalone pkg/Type   - Launch a nodelet of type pkg/Type in a standalone node\n", "nodelet unload name manager   - Unload a nodelet a nodelet by name from manager\n", "nodelet manager               - Launch a nodelet manager node", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "rosrun nodelet declared_nodelets", "rospack plugins --attrib=plugin nodelet"]},
{"url": "https://wiki.ros.org/industrial_utils", "package": "industrial_utils", "package_summary": ["Industrial utils is a library package that captures common funcitonality for the ROS-Industrial distribution."], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The industrial utilities package provides a common package library for ", " functions.  The functions in this package apply across package boundaries.  Utility functions for single packages should not be included in this package. "]},
{"url": "https://wiki.ros.org/arbotix_sensors", "package": "arbotix_sensors", "package_summary": ["Extends the arbotix_node package with a number of more sophisticated ROS wrappers for common devices."], "package_details": ["\n", "\n", "\n", "The arbotix_sensors package contains several sensor modules that add additional layers of ROS interface onto the basic structure of ", ". "], "package_tt": ["/<name>", "/ir_range", "/arbotix/SetupAnalogIn", "~name", "str", "~pin", "int", "~rate", "int", "~type", "str"]},
{"url": "https://wiki.ros.org/adi_driver", "package": "adi_driver", "package_summary": ["The adi_driver package"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "Documentation for ", " is now ", ". "]},
{"url": "https://wiki.ros.org/ping360_sonar", "package": "ping360_sonar", "package_summary": ["A ROS package for Blue Robotics Ping360 Sonar"]},
{"url": "https://wiki.ros.org/pr2_image_snapshot_recorder", "package": "pr2_image_snapshot_recorder", "package_summary": ["\n\n     pr2_image_snapshot_recorder\n\n  "]},
{"url": "https://wiki.ros.org/leptrino_force_torque", "package": "leptrino_force_torque", "package_summary": ["The leptrino_force_torque package"], "package_details": ["ROS driver package for ", " force-torque sensor ", ", ", ", both of which seemingly only Japanese available as of Sep. 2016). "], "package_tt": ["Leptrino"]},
{"url": "https://wiki.ros.org/mir_description", "package": "mir_description", "package_summary": ["URDF description of the MiR100 robot"]},
{"url": "https://wiki.ros.org/rospeex_launch", "package": "rospeex_launch", "package_summary": ["This package launches rospeex's core nodes."]},
{"url": "https://wiki.ros.org/maggie_robot", "package": "maggie_robot", "package_summary": ["maggie_robot metapackage"], "package_details": ["\n", "\n", "\n", "\n", "The user's interface to the ", " stack is ", ", which provides launch files that can be used to bring up the robot. The other packages in this stack are used during the bringup process, and are not usually accessed directly by users. ", "Starting up the robot is not any different from launching a normal ROS program. Launch the ", " file. ", "Check out the ", " that guide you through all the steps for running the Maggie devices. ", "Go to ", ". ", "Report new issues on ", " "], "package_tt": ["maggie_robot", "maggie_start.launch"]},
{"url": "https://wiki.ros.org/rospeex_samples", "package": "rospeex_samples", "package_summary": ["This package provides some rospeex samples."]},
{"url": "https://wiki.ros.org/assisted_teleop", "package": "assisted_teleop", "package_summary": ["The assisted_teleop node subscribes to a desired trajectory topic\n    (geometry_msgs/Twist) and uses TrajectoryPlannerROS to find a valid\n    trajectory close to the desired trajectory before republishing. Useful for\n    filtering teleop commands while avoiding obstacles. This package also\n    contains LaserScanMaxRangeFilter, which is a LaserScan filter plugin that\n    takes max range values in a scan and turns them into valid values that are\n    slightly less than max range."]},
{"url": "https://wiki.ros.org/nav2d_exploration", "package": "nav2d_exploration", "package_summary": ["This package holds a collection of plugins for the RobotNavigator, that provide\n    different cooperative exploration strategies for a team of mobile robots."]},
{"url": "https://wiki.ros.org/robot_pose_ekf", "package": "robot_pose_ekf", "package_summary": ["The Robot Pose EKF package is used to estimate the 3D pose of a robot, based on (partial) pose measurements coming from different sources. It uses an extended Kalman filter with a 6D model (3D position and 3D orientation) to combine measurements from wheel odometry, IMU sensor and visual odometry. The basic idea is to offer loosely coupled integration with different sensors, where sensor signals are received as ROS messages."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "The ", " node does not require all three sensor sources to be available all the time. Each source gives a pose estimate and a covariance. The sources operate at different rates and with different latencies. A source can appear and disappear over time, and the node will automatically detect and use the available sensors.To add your own sensor inputs, check out ", " ", "All the sensor sources that send information to the filter node can have their own ", " reference frame, and each of these ", " reference frames can drift arbitrary over time. Therefore, the ", " sent by the different sensors cannot be compared to each other. The node uses the ", " of each sensor to update the extended Kalman filter. ", "As a robot moves around, the uncertainty on its pose in a world reference continues to grow larger and larger. Over time, the covariance would grow without bounds. Therefore it is not useful to publish the covariance on the pose itself, instead the sensor sources publish how the covariance changes over time, i.e. the covariance on the velocity. ", " ", "Imagine the robot pose filter was last updated at time t_0. The node will not update the robot pose filter until at least one measurement of ", " sensor arrived with a timestamp later than t_0. When e.g. a message was received on the ", " topic with timestamp t_1 > t_0, and on the ", " topic with timestamp t_2 > t_1 > t_0, the filter will now update to the latest time at which information about all sensors is available, in this case to time t_1. The odom pose at t_1 is directly given, and the imu pose at t_1 is obtained by linear interpolation of the imu pose between t_0 and t_2. The robot pose filter is updated with the relative poses of the odom and imu, between t_0 and t_1. ", "The above figure shows experimental results when the PR2 robot started from a given initial position (green dot), driven around, and returned to the initial position. A perfect odometry x-y plot should show an exact loop closure. The blue line shows the input from the wheel odometry, with the blue dot the estimated end position. The red line shows the output of the ", ", which combined information of wheel odometry and imu, with the red dot the estimated end position.  "], "package_tt": ["robot_pose_ekf", "odom", "imu_data", "vo", "robot_pose_ekf", "robot_pose_ekf/odom_combined", "odom_combined", "base_footprint", "odom", "imu_data", "robot_pose_ekf"], "package_code": [" <launch>\n", "  <node pkg=\"robot_pose_ekf\" type=\"robot_pose_ekf\" name=\"robot_pose_ekf\">\n", "    <param name=\"output_frame\" value=\"odom\"/>\n", "    <param name=\"freq\" value=\"30.0\"/>\n", "    <param name=\"sensor_timeout\" value=\"1.0\"/>\n", "    <param name=\"odom_used\" value=\"true\"/>\n", "    <param name=\"imu_used\" value=\"true\"/>\n", "    <param name=\"vo_used\" value=\"true\"/>\n", "    <param name=\"debug\" value=\"false\"/>\n", "    <param name=\"self_diagnose\" value=\"false\"/>\n", "  </node>\n", " </launch>", " $ rosdep install robot_pose_ekf\n", " $ roscd robot_pose_ekf\n", " $ rosmake", " $ roslaunch robot_pose_ekf.launch"]},
{"url": "https://wiki.ros.org/agvs", "package": "agvs", "package_summary": ["The agvs package. This package contains all the components to simulate the AGVS robot. An ackermann type robot intended for logistics transport."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", " simulation.  ", "1. ", " "]},
{"url": "https://wiki.ros.org/ros_additive_manufacturing", "package": "ros_additive_manufacturing", "package_summary": ["ROS-Industrial additive manufacturing tools (metapackage)"], "package_details": ["\n", "Documentation is here: ", " "]},
{"url": "https://wiki.ros.org/patrolling_sim", "package": "patrolling_sim", "package_summary": [" Multi-Robot Patrolling Stage/ROS Simulation Package.", " ", " ", "\n", "Multi-Robot Patrolling Package for ROS. ", "Composed of 7 running algorithms: ", " ", "\n", " ", "\n", "\n", "To run the package, please read ", " Tutorial. "], "package_details": ["\n", "\n"], "package_tt": ["monitor", "results", "Conscientious_Cognitive", "Conscientious_Reactive", "Cyclic", "GBS", "Heuristic_Conscientious_Reactive", "MSP", "SEBS"]},
{"url": "https://wiki.ros.org/lex_common_msgs", "package": "lex_common_msgs", "package_summary": ["Common messages for interacting with Amazon Lex using the lex_node package"]},
{"url": "https://wiki.ros.org/pr2_moveit_tutorials", "package": "pr2_moveit_tutorials", "package_summary": ["The pr2_moveit_tutorials package"]},
{"url": "https://wiki.ros.org/mir_driver", "package": "mir_driver", "package_summary": ["A reverse ROS bridge for the MiR100 robot"]},
{"url": "https://wiki.ros.org/pr2_apps", "package": "pr2_apps", "package_summary": ["Basic applications for the PR2 robot"], "package_details": [" ", "\n", "\n", "  ", "This stack comprises applications that can be run on the PR2.  In most cases, these applications can be run on PR2 hardware, or in ", ". ", "The latter example brings up the PR2 in an empty simulated world; for information on other worlds, including building your own, consult the ", ". "], "package_code": ["roslaunch /etc/ros/robot.launch", "roslaunch pr2_gazebo pr2_empty_world.launch "]},
{"url": "https://wiki.ros.org/rsv_balance_simulator", "package": "rsv_balance_simulator", "package_summary": ["Simulation packages for RoboSavvy's balancing platform."], "package_details": [" "]},
{"url": "https://wiki.ros.org/maggie_ir_controller", "package": "maggie_ir_controller", "package_summary": ["ir_controller node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " file contains all possible commands to use with a TV. To generate new commands for another TV consult the Users Manual. ", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["tv_action", "send_command"], "package_code": [" $ roslaunch maggie_ir_controller ir_controller.launch robot:=maggie", " $ rosservice call /maggie/send_command maggie_ir_controller_msgs/SetTvAction \"on\""]},
{"url": "https://wiki.ros.org/kobuki_core", "package": "kobuki_core", "package_summary": ["Non-ROS software for Kobuki, Yujin Robot's mobile research base."], "package_details": ["\n", "Driver documentation is provided by ", ". ", "For ros-related information about kobuki, visit either the ", " or the ", " pages. "]},
{"url": "https://wiki.ros.org/abb_irb6640_moveit_config", "package": "abb_irb6640_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 6640.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 6640 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "This package is part of the ", " program. "]},
{"url": "https://wiki.ros.org/abb_irb6600_support", "package": "abb_irb6600_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 6600 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 6600 manipulators. This currently includes the base model.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the ABB data sheets.  All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      The unqualified IRB 6400 model will be removed in ROS-Lunar, please\n      use the abb_irb6640_support as a replacement.\n    "]},
{"url": "https://wiki.ros.org/rail_object_detector", "package": "rail_object_detector", "package_summary": ["The rail_object_detector package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", ": recognize objects in the latest image from the camera stream ", ".  Takes no input, and outputs a list of detected, labeled objects and a corresponding image.  Only advertised if ", " is true. ", "\n", ": recognize objects in an image passed to the service.  Takes an image as input, and outputs a list of detected, labeled objects and a corresponding image. Only advertised if ", " is true. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package includes two object detectors which you may choose between, YOLOv2 and Deformable R-FCN (DRFCN). Detections from YOLOv2 are a bit faster, >10fps compared to ~4fps (on a Titan X), but less accurate than the detections from DRFCN. ", "The YOLOv2 detector uses ", " to perform object detection. It provides the ability to query for objects in an image through both services as well as from a topic. ", "The ", " detector is built on MXNet, and provides the ability to query for objects from a topic. ", "The nodes in this package publish a list of ", " within a given image, each of which has the following properties: ", "The DRFCN detector requires a CUDA and cuDNN capable GPU, so it is not installed by default. In order to use it, we recommend getting this code from Github and following the instructions in the ", ". The rest of this documentation covers instructions for a CPU-only install of this package that uses darknet. ", "This package contains a single ROS node - ", " - which serves as an interface between a ROS system and the trained object recognition network. ", "Type: ", " ", "Type: ", " ", "Type: ", " ", "Topic with object detections performed in the background by grabbing images at a specified interval. Only advertised if ", " is true. ", "Type: ", " ", "Default: ", " ", "Number of asynchronous threads that can be used to service each of the services. ", " implies the use of one thread per processor ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "Type: ", " ", "Default: ", " ", "A good set of weights, to complement the default trained labels can be obtained from ", ". ", "To build using CUDA, obtain the package from Github and follow the instructions in the ", ". This is necessary if you wish to use the Deformable R-FCN detector. ", "The underlying Darknet code has been copied as is. So the detector can be trained and retrained following instructions on the ", ". ", "The same is true for the Deformable R-FCN. Check the ", " for details. "], "package_tt": ["label", "probability", "centroid_x", "centroid_y", "left_bot_x", "left_bot_y", "right_top_x", "right_top_x", "darknet_node", "image_sub_topic_name", "use_scene_service", "use_image_service", "publish_detections_topic", "int", "0", "0", "bool", "true", "bool", "false", "bool", "false", "string", "\"/kinect/hd/image_color_rect\"", "float", "1.0", "float", "0.25", "string", "\"$(find\u00a0rail_object_detector)/libs/darknet/data/coco.names\"", "string", "\"$(find\u00a0rail_object_detector)/libs/darknet/cfg/yolo.cfg\"", "string", "\"$(find\u00a0rail_object_detector)/libs/darknet/yolo.weights\""]},
{"url": "https://wiki.ros.org/rwt_speech_recognition", "package": "rwt_speech_recognition", "package_summary": ["The rwt_speech_recognition package"]},
{"url": "https://wiki.ros.org/rospack", "package": "rospack", "package_summary": ["ROS Package Tool"], "package_details": ["\n", " is a command-line tool for retrieving information about ROS ", " available on the filesystem. It implements a wide variety of commands ranging from locating ROS packages in the filesystem, listing available packages, to calculating the dependency tree of packages. It is also used in the ROS ", " for calculating build information for packages. ", "For an equivalent tool for ", ", see ", ". ", "Prior to ROS ", ", ", " was included in the ", " stack.  Since Fuerte, it is a standalone tool. ", "Documentation is available ", ". "], "package_tt": ["rospack", "rospack"]},
{"url": "https://wiki.ros.org/visualization_msgs", "package": "visualization_msgs", "package_summary": ["visualization_msgs is a set of messages used by higher level packages, such as ", ", that deal in visualization-specific data.\n\n    The main messages in visualization_msgs is ", ".\n    The marker message is used to send visualization \"markers\" such as boxes, spheres, arrows, lines, etc. to a visualization environment such as ", ".\n    See the rviz tutorial ", " for more information."], "package_details": [": this package was moved from ", " to ", ".  ", "\n", "\n", " is the ", "top-level message for sending data from the interactive marker server ", "to the client (i.e. rviz).  The update message has an array of ", " messages which are ", "new or which need to be updated.  It also has an array of ", " messages for ", "sending only pose updates to existing interactive markers. ", "A useful overview of ", " types can be found at ", ". ", "An introduction to the InteractiveMarker messages is given in the interactive marker tutorial at ", ". ", "Each ", " message has an ", "array of ", "s ", "which describe its subcomponents.  Each ", " has an array ", "of ", "s which together describe the ", "shape of the control. ", "The ", " message also has ", "an array of ", "s which together ", "define a context menu which should appear when the appropriate action ", "happens in the client (like a right-click).  Although the entries are ", "sent in a flat array, each one contains an id and a parent_id to ", "specify a tree structure.  This is described in  ", ". "], "package_tt": ["visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker", "visualization_msgs/Marker"]},
{"url": "https://wiki.ros.org/abb_common", "package": "abb_common", "package_summary": ["\n\n     abb_common\n\n  "], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/asr_flock_of_birds_tracking", "package": "asr_flock_of_birds_tracking", "package_summary": ["This package controls a motorized robot head (a sensor setup equipped with a PTU) in order to ensure that the hand of a human user remains inside its field of view. The human hand is tracked with the help of an Ascension - Flock of Birds system. The purpose of this package is to enable continuous localization of objects during their manipulation through the tracked hand."], "package_details": [" ", "\n", "\n", " ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "First of all, the position of magnet tracker (p) is transformed into the PTU's coordinate frame. Azimuth (a_xy) and altitude (a_yz) are calculated with the arccos of dot-Product divided by euclidiean distance. The following equations shows this: ", " ", "To successfully run this tool the whole kinematic chain of the PbD -Dome has to be started (PTU and Flock of Birds) first and the correct topic- and framenames have to set in \"", "\". With keys \"R\" or \"L\" the PTU can look at the right or left tracker (autonomous tracking). In addition the PTU can be moved with the arrwokeys (direct PTU controlling). "], "package_code": ["roslaunch asr_flock_of_birds_tracking tracker.launch"]},
{"url": "https://wiki.ros.org/rviz", "package": "rviz", "package_summary": ["3D visualization tool for ROS."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", ".  [ ", " ] ", "rviz does not have a builtin capability to record movies.  You can, however, use an application like ", " (or ", ") to do so.  The ", " page has more information on recording and encoding. "], "package_code": ["rosrun rviz rviz --help"]},
{"url": "https://wiki.ros.org/joint_state_publisher_js", "package": "joint_state_publisher_js", "package_summary": ["rosjs package for publishing joint states"]},
{"url": "https://wiki.ros.org/ar_pose", "package": "ar_pose", "package_summary": ["\n    Augmented Reality Marker Pose Estimation using ARToolkit\n  "], "package_details": [" ", " ", "\n", " provides two nodes you can run. The program ", " provides a transform between the camera and a single AR Marker. The program ", " provides an array of transforms for multiple markers. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package is an ROS wrapper for ", ". ", "Currently the ", " package requires calibration information from a camera_info topic. If there is no camera_info topic the marker pose estimation will not start. ", "You can run ", " on a live video from a camera, or on a pre-recorded bag file that comes with the package. First, make sure you have ", " metapackage downloaded and installed and built. ", "This demo uses ", " to track the location of an ", " relative to the location of a fixed camera. The position of the camera in the world frame is published by ", " as a static transform. The tracking process is visualized in ", ". ", "This demo uses ", " to track the position of the camera relative to the location of an ", ". The position of the marker in the world frame is published by ", " as a static transform. The tracking process is visualized in ", ". ", "This demo uses ", " to track the location of multiple ", " relative to the location of a fixed camera. The position of the camera in the world frame is published by ", " as a static transform. The tracking process is visualized in ", ". ", "Two examples are provided that are configured and calibrated for use with a Logitech C600 webcam and the ", " driver. ", "A multi-marker configuration can be started as well. The Markers used in this example are found in ~/ros/stacks/ccny-ros-pkg/ccny_vision/data/4x4/4x4_ps.tar.gz The 4x4 patterns were created with ", " which was developed by David Johnson, Christopher Berthiaume and Bryan Witkowski. These patterns are distributed with this software under the GPL with permission. ", "Please use our ", " to ", " or ", ". "], "package_tt": ["ar_single", "ar_multi", "ar_single", "static_tf_publisher", "setup_single.sh", "ar_single", "static_tf_publisher", "setup_reverse.sh", "ar_multi", "static_tf_publisher", "setup_multi.sh"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/arni_core", "package": "arni_core", "package_summary": ["This package contains common ARNI functionality. Furthermore, generic launch files and integration tests."]},
{"url": "https://wiki.ros.org/qb_device_driver", "package": "qb_device_driver", "package_summary": ["This package contains a device-independent API wrapper for qbrobotics\u00ae devices."], "package_details": ["\n", "\n", "\n", "\n", "This is the only package among the ones in ", " which can be used as a stand-alone ROS node, called ", ". It wraps the ", " API, manages the shared resources and provides a multi-node from/to multi-device communication interface. ", "The ", " node manages the serial communication from the ROS ecosystem to the physical ", " devices connected to it through any serial ports, and vice versa. The need of such a mediator is demanded to the possibility to connect several devices together (i.e. in a chain) and access them through a single serial port. Each ROS node representing a device has to request services to the owner of the shared resources, i.e. the Communication Handler. ", "To start an instance of the Communication Handler node, be sure that the ", " is running and then simply execute the following command from a terminal (it ", " any configuration parameters): ", "To integrate the Communication Handler node in your application launch file you simply need to add the node to it (it ", " any configuration parameters). "], "package_tt": ["roscore", "deregister_device", "register_device", "register_device", "/communication_handler/activate_motors", "success", "true", "/communication_handler/deactivate_motors", "success", "true", "/communication_handler/deregister_device", "/communication_handler/get_info", "message", "/communication_handler/get_measurements", "success", "true", "currents", "positions", "/communication_handler/register_device", "success", "true", "/communication_handler/set_commands", "commands", "/communication_handler/sync_nodes", "success", "true"], "package_code": ["rosrun qb_device_driver qb_device_communication_handler", "<launch>\n", "  <node name=\"qb_device_communication_handler\" pkg=\"qb_device_driver\" type=\"qb_device_communication_handler\" respawn=\"true\" output=\"screen\"/>\n", "  ...\n", "</launch>"]},
{"url": "https://wiki.ros.org/ainstein_radar_msgs", "package": "ainstein_radar_msgs", "package_summary": ["ROS message definitions for Ainstein radars."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/sf30_node", "package": "sf30_node", "package_summary": ["The sf30_node package provides a driver for the sf30 laser range finder."], "package_details": ["\n", "\n", "\n", "\n", " ", "This is a ROS node for ", " ", "The node assume the following setup for the laser (I used the ", " terminal from the manufacture): ", "Create a catkin workspace. For instructions on how to create the workspace go ", ". Download and compile the package: ", "The message of type ", " will be published in topic /sf30/range at 50Hz. The intensities field on this message means data confidence. It is 1 if we can trust the given range. "], "package_code": ["   1: Active data port           USB distance in m\n", "   2: Resolution                 0.03 m\n", "   3: Serial port update rate    1000 / sec  (actual = 1665 / sec)\n", "   4: Serial port baud rate      115200\n", "   5: Analog port update rate    1 / sec  (actual = 1 / sec)\n", "   6: Analog maximum range       256 m\n", "   7: Alarm activation distance  17.50 m\n", "   8: Alarm latch                Off\n", "   9: USB port update rate       50 / sec  (actual = 50 / sec)", "0.57 m\n", "0.57 m\n", "0.59 m\n", "0.57 m\n", "0.59 m\n", "0.59 m\n", "0.55 m\n", "0.59 m\n", "0.57 m\n", "0.57 m\n", "0.57 m", "catkin_ws/src\n", "git clone git@bitbucket.org:castacks/sf30_node.git\n", "cd ..\n", "catkin_make", "source devel/setup.bash\n", "roslaunch sf30_node sf30.launch"]},
{"url": "https://wiki.ros.org/pacifica_dbw", "package": "pacifica_dbw", "package_summary": ["A ROS interface to the New Eagle Raptor drive-by-wire controller"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The raptor_dbw ", " is a collection of packages for interacting with the New Eagle Raptor DBW controllers. The primary goal of this stack is to facilitate ROS-based DBW kit development and provide a set of ROS-CAN interface tools. ", "The current development branch is ", " and targets ROS ", " and ", ". ", "For more on New Eagle Raptor controllers see: ", " "], "package_tt": ["master", "kinetic", "melodic"]},
{"url": "https://wiki.ros.org/qb_hand_control", "package": "qb_hand_control", "package_summary": ["This package contains the ROS control node for qbrobotics\u00ae qbhand device."], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the ROS control node and its structures to control the ", " device. It exploits the features provided by the base device-independent control library (cf. ", ") and the specific hardware interface (cf. ", "). ", "The two launch files start a ROS node for the ", " respectively to control it through a GUI and through predefined configurable waypoints (stored in the ", "). In both cases the controllers setup can be found in the ", "; it is recommended not to change the default settings though. ", "This launch file calls the template ", " with the default settings to bringup a full control node for the ", " based on GUI inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf. ", " to control several devices together). ", "This launch file calls the template ", " with the default settings to bringup a full control node for the ", " based on waypoint inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf. ", " to control several devices together). ", "This control library specifically designed for the ", " extends the ", " and exploits the ", ", therefore it provides all the ROS resources and requires all the specifications of this two base packages. "], "package_tt": ["config/qbhand_waypoints.yaml", "config/qbhand_controllers.yaml"]},
{"url": "https://wiki.ros.org/pr2_plugs_msgs", "package": "pr2_plugs_msgs", "package_summary": ["\n\n     pr2_plugs_msgs provides the msgs and action definitions required for plugging in.\n\n  "], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"pr2_plugs_msgs\" in rosdoc: /home/rosbot/docs/api/pr2_plugs_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/pr2_ethercat", "package": "pr2_ethercat", "package_summary": ["Main loop that runs the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", " is usually executed from a launch file, such as ", "/pr2.launch.  Common configuration: ", "\n", " is a utility that allows a regular user to run ", " with appropriate capabilities. See the section in ", " on \"Permissions.\" ", "\n", " is a simple command-line script that calls the ", " service. ", "(formerly ", " in Groovy and earlier) ", "Running ", " requires the following \"capabilities\": ", "Superuser has these capabilities, but they can also be granted to another executable by setting file system attributes on the executable file.  The ", " program is a setuid-root program which copies ", " to a part of the filesystem where attributes can be set (", "), and then grants the necessary capabilities to be able to run ", ". "], "package_tt": ["pr2_ethercat", "pr2_ethercat", "pr2_ethercat", "pr2_ethercat", "pr2_ethercat/reset_motors", "halt_motors", "pr2_ethercat/halt_motors", "reset_motors", "pr2_ethercat", "pr2-grant", "pr2_ethercat", "/var/tmp", "pr2_ethercaat", "pr2_ethercat", "pr2-grant", "pr2_ethercat", "pr2_ethercat", "reset_motors.py", "pr2_ethercat/reset_motors"], "package_code": ["Usage: ./pr2_ethercat [options]\n", "  Available options\n", "    -i, --interface <interface> Connect to EtherCAT devices on this interface\n", "    -x, --xml <file|param>      Load the robot description from this file or parameter name\n", "    -r, <param>                 Load the robot description from this parameter\n", "    -u, --allow_unprogrammed    Allow control loop to run with unprogrammed devices\n", "    -h, --help                  Print this message and exit", "<node name=\"realtime_loop\" machine=\"c1\" launch-prefix=\"pr2-grant\" pkg=\"pr2_ethercat\" type=\"pr2_ethercat\" args=\"-i ecat0 -x robot_description\"/>", "$ rosrun pr2_ethercat reset_motors.py"]},
{"url": "https://wiki.ros.org/motoman_sia20d_support", "package": "motoman_sia20d_support", "package_summary": [" This package will be removed in ROS Kinetic. The configuration data and\n      models included in this package can now be found in the motoman_sia_support\n      package in ROS Jade.", "ROS-Industrial support for the Motoman SIA20D (and variants).", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman SIA20D manipulators.\n    ", "\n      ", "\n    ", "\n      Joint limits and maximum joint velocities are based on the information \n      found in the online \n      http://www.motoman.com/datasheets/sia20d.pdf\n      All urdfs are based on the default motion and joint velocity limits, \n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/nav2d_tutorials", "package": "nav2d_tutorials", "package_summary": ["Contains a set of tutorials that run 2D-Navigation within Stage-Simulator."]},
{"url": "https://wiki.ros.org/innok_heros_driver", "package": "innok_heros_driver", "package_summary": ["Driver for the Innok Heros robot plattform", "\n", "\n", "Press the Power button on the Innok Heros. ", "\n", "Start the ROS driver with ", "Make sure that the ", " parameter in ", " is set to the correct address of your Heros (default host is 192.168.1.213). ", "\n", "\n"], "package_details": [" ", "ROS driver for the ", " robot plattform. "], "package_tt": ["host", "heros_base.launch", "cmd_vel", "odom", "host", "string", "odom", "base_link"], "package_code": ["roslaunch innok_heros_driver heros_base.launch"]},
{"url": "https://wiki.ros.org/odometry_publisher_tutorial", "package": "odometry_publisher_tutorial", "package_summary": ["The odometry_publisher_tutorial package"], "package_details": ["This package provides the code for the ", " tutorial. "]},
{"url": "https://wiki.ros.org/agvs_control", "package": "agvs_control", "package_summary": ["The agvs_control package. Config files used for Gazebo motor controllers."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/kobuki_bumper2pc", "package": "kobuki_bumper2pc", "package_summary": ["Bumper/cliff to pointcloud nodelet:\n    Publish bumpers and cliff sensors events as points in a pointcloud, so navistack can use them\n    for poor-man navigation. Implemented as a nodelet intended to run together with kobuki_node."], "package_tt": ["~bumper_events", "~cliff_events", "~pointcloud", "~pointcloud_radius", "double", "~bumper_events", "~cliff_events", "~pointcloud", "~pointcloud_radius", "double"]},
{"url": "https://wiki.ros.org/kobuki_controller_tutorial", "package": "kobuki_controller_tutorial", "package_summary": ["Code for the Kobuki controller tutorial."], "package_details": [" ", "\n", "This package holds the supporting code for the ", ". "]},
{"url": "https://wiki.ros.org/qb_device_description", "package": "qb_device_description", "package_summary": ["This package contains a device-independent description utilities for qbrobotics\u00ae devices."], "package_details": ["\n", " ", "\n", " ", "\n", "This package is barely usable alone since it provides only templates to create more structured launch files in the derived packages (cf. ", "). ", "The two launch file templates come in help when loading the description package of a device. It could seem unlikely to split the two files (and actually they are often called sequentially), but it guarantees in a ", " to be able to load every single robot description in each device namespace (which is required to setup their control nodes) and to load the whole robot model complete with ", ", ", " and ", " only once. "], "package_tt": ["robot_description", "model_name", "string", "qb_device", "qb_device.urdf.xacro.", "urdf/", "_description", "namespace", "string", "my_device", "my_device_joint_...", "my_device_link_...", "package_prefix", "string", "qb_device", "qb_device_description", "robot_description", "frequency", "int", "Hz", "package_prefix", "string", "qb_device", "qb_device_description", "rviz_config", "string", "qb_device", "qb_device.rviz.", "rviz/", "_description", "source_list_names", "string", "use_joint_state_gui", "bool", "use_rviz", "bool"]},
{"url": "https://wiki.ros.org/applanix_driver", "package": "applanix_driver", "package_summary": ["applanix_driver"], "package_details": [" ", "\n", "\n", "\n", " ", "\n", "\n", "  ", "The ", " stack provides a comprehensive ROS interface to ", ", which integrate GPS, IMU, and DMI data into a high accuracy position and orientation fix. ", "These packages have not (yet) been released for Indigo or newer versions, but can be build from source in your catkin workspace. Refer to the ", " for more information on building catkin workspaces. ", "If you're looking for the topic for a particular Applanix group, please consult the file ", ". ", "The ", " package provides a direct translation of the Applanix binary format into ROS messages and services. The remaining packages provide helper nodes which further convert those messages into familiar ROS messages (", ", ", ", ", ", etc), and offer some support for configuration via ROS parameters. ", "The applanix_msgs package contains a ROS ", " for each Applanix data group and command message, as well as ", ", which controls the naming of the resultant ROS topics and service. The applanix_generated_msgs package contains a script which creates a wrapper ", " for each command message, and also assembles a mega AllMsgs.msg file. This structure allows a natural service-oriented interface to configuring and commanding the Applanix hardware, while still allowing the user to subscribe to a single topic to receive a snapshot of the device's configuration at a given time. "], "package_tt": ["applanix_msgs/src/mapping.py", "mapping.py", "gpsmon"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-applanix-driver", "roslaunch applanix_launch example.launch"]},
{"url": "https://wiki.ros.org/schunk_canopen_driver", "package": "schunk_canopen_driver", "package_summary": ["The schunk_canopen_driver package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "If you have the fzi_icl_core or fzi_icl_can package in your workspace you'll have to build it with ", ", as those packages are plain cmake packages. See the ", " for details. ", "The simpler ", "-interface accepts series of waypoints which the robot will drive to with internal interpolation. It is not guaranteed (and might almost never happen), that all joints finish moving at the same time. If multiple waypoints are given, a new waypoint is started for all joints at the same time as soon as the last joint reached it's previous destination. Ramping up and down between waypoints is done by the robot internally depending on it's configuration. The ramping setup will be treated later on. ", "The ", "-interface provides a position controller in joint space which will interpolate between waypoints inside the controller (on the host PC). You can set joint velocities and time constraints for each waypoint which the controller will take care of. ", "This launchfile gives a ready-to-use action interface for ros_control. It loads controllers defined in ", " (This can be changed in the ros_control.launch file). Parameters: ", "If your robot arm does use custom canopen IDs, you can modify those in the ", " file. When modifying the canopen IDs you will also have to modify the node mapping in ", " which will perform the mapping between the canopen IDs and the URDF joint names. See the example config file for a syntax explanation. ", "When using the simple profile position mode Ramping up and down is controlled by the hardware. The velocity and acceleration can be configured in the ", "file. Also, targets can be commanded as a relative motion to the current position or as an absolute position relative to the home position (which is the default). Change the ", " parameter if you like to change this behavior. ", "Canceling a goal at high speeds seems to set the robot into a fault state. This comes from within the used position controller as it commands the robot to hold a position which is too far away to be reached within one control cycle. As a workaround prefer the ", " service "], "package_tt": ["follow_joint_trajectory/follow_joint_trajectory", "pos_based_pos_traj_controller/follow_joint_trajectory", "joint_states", "joint_currents", "close_brakes", "enable_nodes", "quick_stop_nodes", "home_reset_offset_by_id", "home_reset_offset_by_name", "home_reset_offset_all", "init_devices", "autostart", "bool", "can_device_name", "string", "frequency", "int", "traj_controller_name", "string", "use_ros_control", "bool"], "package_code": ["   rosrun fzi_icl_can install_pcan_module.sh", "   catkin_make_isolated\n", "   source devel_isolated/setup.bash\n", "   # If Peak driver was not installed before.\n", "   # Note: You will be asked for your sudo password during execution.\n", "   rosrun fzi_icl_can install_pcan_module.sh", "  sudo apt-get install ros-indigo-schunk-canopen-driver\n", "  # If Peak driver was not installed before.\n", "  # Note: You will be asked for your sudo password during execution.\n", "  rosrun fzi_icl_can install_pcan_module.sh"]},
{"url": "https://wiki.ros.org/nao_audio", "package": "nao_audio", "package_summary": ["Package for the Nao robot, providing access to NAOqi vision proxies"], "package_details": ["\n", "\n"], "package_tt": ["nao_audio/audio_source_localization", "nao_audio/master_volume", "nao_audio/play_file", "nao_audio/record"]},
{"url": "https://wiki.ros.org/kuka_lbr_iiwa_support", "package": "kuka_lbr_iiwa_support", "package_summary": ["\n      ROS-Industrial support for the KUKA LBR IIWA (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA LBR IIWA manipulators. This currently includes the base model.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the KUKA ", " online. \n      All urdf's / xacro's are based on the default motion and joint velocity \n      limits, unless noted otherwise (ie: no support for high speed joints, \n      extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/razor_imu_9dof", "package": "razor_imu_9dof", "package_summary": ["razor_imu_9dof is a package that provides a ROS driver\n     for the Sparkfun Razor IMU 9DOF. It also provides Arduino\n     firmware that runs on the Razor board, and which must be\n     installed on the Razor board for the system to work. A node\n     which displays the attitude (roll, pitch and yaw) of the Razor board \n     (or any IMU) is provided for testing."], "package_tt": ["\"sketchbook\"", "\"Arduino\"", "Razor_AHRS", "\"USER\u00a0SETUP\u00a0AREA\"", "\"HARDWARE\u00a0OPTIONS\"", "\"Tools\"", "\"Board\"", "\"Arduino\u00a0Pro\u00a0or\u00a0Pro\u00a0Mini\u00a0(3.3v,\u00a08mhz)\u00a0w/ATmega328\"", "\"Tools\"", "\"Serial\u00a0Port\"", "\"File\"", "\"Upload\u00a0to\u00a0I/O\u00a0Board\"", "\"Done\u00a0uploading\"", "\"Tools\"", "\"Serial\u00a0Monitor\"", "\"rostopic\u00a0list\"", "/imu", "\"rostopic\u00a0echo\u00a0/imu\"", "$(find\u00a0razor_imu_9dof)/src/Razor_AHRS/Razor_AHRS.ino", "\"USER\u00a0SETUP\u00a0AREA\"", "\"SENSOR\u00a0CALIBRATION\"", "#oc", "#oc", "#oc", "#oc", "Razor_AHRS.ino", "#oc", "#on", "#oc", "Razor_AHRS.ino", "$(find\u00a0razor_imu_9dof)/magnetometer_calibration/Processing/Magnetometer_calibration", "Magnetometer_calibration.pde", "SPACE", "\"USER\u00a0SETUP\u00a0AREA\"", "\"SENSOR\u00a0CALIBRATION\"", "magnetom.float", "$(find\u00a0razor_imu_9dof)/magnetometer_calibration/Matlab/magnetometer_calibration", "magnetometer_calibration.m", "$rosmake\u00a0razor_imu_9dof"], "package_code": ["sudo apt-get install python-visual", "$ cd catkin_ws/src\n", "$ git clone https://github.com/KristofRobot/razor_imu_9dof.git\n", "$ cd ..\n", "$ catkin_make", "$ sudo apt-get install ros-indigo-razor-imu-9dof", "$ roscd razor_imu_9dof\n", "$ cp -r src/Razor_AHRS ~/Arduino", "$ roscd razor_imu_9dof/config\n", "$ cp razor.yaml my_razor.yaml", "$ roslaunch razor_imu_9dof razor-pub-and-display.launch", "$ roslaunch razor_imu_9dof razor-pub.launch", "        #YPR=-155.73,-76.48,-129.51", "        accel x,y,z (min/max) = -5.00/-1.00  25.00/29.00  225.00/232.00", "gyro x,y,z (current/average) = -29.00/-27.98  102.00/100.51  -5.00/-5.85"]},
{"url": "https://wiki.ros.org/rb1_base_control", "package": "rb1_base_control", "package_summary": ["The rb1_base_control package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/segbot_firmware", "package": "segbot_firmware", "package_summary": ["Arduino firmware for BWI segbot sensor array."], "package_details": ["\n", "\n", "Select ", " followed by the desired firmware version. Then, click the ", " icon to compile the microcode and load it into the controller. ", "When the firmware is loaded, start ", " and run the ROS device driver: "], "package_tt": ["File\u00a0>\u00a0Sketchbook\u00a0>\u00a0Libraries", "->", "roscore"], "package_code": ["$ sudo apt-get install arduino\n", "$ mkdir ~/sketchbook \n", "$ cd ~/sketchbook\n", "$ ln -s $(rospack find segbot_firmware)/src/libraries .", "$ arduino", "$ rosrun segbot_sensors sensor_ranges_driver", "$ rostopic echo /sensor_ranges"]},
{"url": "https://wiki.ros.org/mir_robot", "package": "mir_robot", "package_summary": ["URDF description, Gazebo simulation, navigation, bringup launch files, message and action descriptions for the MiR100 robot."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/rb1_base_common", "package": "rb1_base_common", "package_summary": ["The rb1_base_common package. It contains rb1 base common packages used for robot control and for simulation"], "package_details": ["\n", " ", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", ", shared for real robot and simulation.  ", "This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux (", ") so that the final command to the robot can be set by different components (move_base, etc.) "]},
{"url": "https://wiki.ros.org/libccd", "package": "libccd", "package_summary": ["libccd is library for collision detection between two convex shapes."]},
{"url": "https://wiki.ros.org/tuw_multi_robot_ctrl", "package": "tuw_multi_robot_ctrl", "package_summary": ["A simple multi robot controller using Routes as input, which are used to execute the path synchronized."], "package_details": ["\n", "\n", "\n", "  (", ") ", " (", ") ", " (", ") ", "\n", "  (", ") ", "  (", ") ", "\n", " (", " default: \"[robot_0]\") ", " (", " default: \"\") ", " (", " default: \"[]\") ", " (", " default: \"0.3\") ", " (", " default: \"cmd_vel\") ", " (", " default: \"route\") ", " (", " default: \"ctrl\") ", " (", " default: \"0.8\") ", " (", " default: \"1.0\") ", " (", " default: \"0.2\") ", " (", " default: \"5.0\") ", " (", " default: \"1.0\") ", " (", " default: \"0.0\") ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "This package provides a simple multi robot controller to follow a route. It contains a node which controls all robots at once for performance reasons with a high number of robots (> 100). ", "This node receives route messages from the ", ". It provides control input for all robots to move on their routes in a synchronized fashion. "], "package_tt": ["tuw_multi_robot_router", "[robot_name]/path", "tuw_multi_robot_msgs/Route", "robot_info", "tuw_multi_robot_msgs/RobotInfo", "[robot_name]/ctrl", "std_msgs/string", "[robot_name]/cmdVel", "geometry_msgs/Twist", "robot_info", "tuw_multi_robot_msgs/RobotInfo", "~robot_names", "string[]", "~robot_names_str", "string", "~robot_radius", "float[]", "~robot_default_radius", "float", "~cmd_vel_topic", "string", "~route_topic", "string", "~topic_ctrl", "string", "~max_v", "float", "~max_w", "float", "~goal_radius", "float", "~Kp", "float", "~Kd", "float", "~Ki", "float"]},
{"url": "https://wiki.ros.org/navigation_layers", "package": "navigation_layers", "package_summary": ["Extra navigation layers."]},
{"url": "https://wiki.ros.org/pepper_sensors_py", "package": "pepper_sensors_py", "package_summary": ["The pepper_sensors package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Wraps the camera node from ", " ", "Starts two sonar nodes (from ", ") to get the data from the front and the back sonar "], "package_tt": ["~pepper/laser/shovel/scan", "~pepper/laser/ground_left/scan", "~pepper/laser/ground_right/scan", "~pepper/laser/srd_front/scan", "~pepper/laser/srd_left/scan", "~pepper/laser/srd_right/scan", "~pepper/laser/shovel/pointcloud", "~pepper/laser/ground_left/pointcloud", "~pepper/laser/ground_right/pointcloud", "~pepper/laser/srd_front/pointcloud", "~pepper/laser/srd_left/pointcloud", "~pepper/laser/srd_right/pointcloud", "pointcloud", "boolean", "laserscan", "boolean"]},
{"url": "https://wiki.ros.org/ainstein_radar_tools", "package": "ainstein_radar_tools", "package_summary": ["Tools for monitoring and validating radar data."], "package_details": ["\n", "\n", "\n"], "package_tt": ["radar_topic", "camera_topic", "~image_out", "~use_snr_alpha", "boolean", "<RADAR\u00a0FRAME>", "<CAMERA\u00a0FRAME>"]},
{"url": "https://wiki.ros.org/khi_robot_msgs", "package": "khi_robot_msgs", "package_summary": ["This package contains KHI ROS robot msgs"]},
{"url": "https://wiki.ros.org/segbot", "package": "segbot", "package_summary": ["ROS drivers for controlling Segway RMP 50 based robots at Learning Agents \n    Research Group (LARG), AI Laboratory, Department of Computer Science, \n    The University of Texas at Austin."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/ainstein_radar", "package": "ainstein_radar", "package_summary": ["ROS support for Ainstein radar sensors."], "package_details": ["\n", "\n", "Basic ROS support for ", " radars as well as simulation, visualization and processing tools and utilities for working with generic radar data. "]},
{"url": "https://wiki.ros.org/pr2_robot", "package": "pr2_robot", "package_summary": ["This stack collects PR2-specific components that are used in bringing up\n  a robot."], "package_details": ["\n", "\n", "\n", "\n", "The user's interface to the ", " stack is ", ", which provides launch files that can be used to bring up a robot.  The other packages in this stack are used during the bringup process, and are not usually accessed directly by users. ", "Check out the ", " that guide you through all the steps for running the PR2. ", "Go to ", ". ", "Report new issues on ", " "], "package_tt": ["pr2_robot"], "package_code": [" source /opt/ros/DISTRO/setup.bash\n", " roslaunch /etc/ros/DISTRO/robot.launch"]},
{"url": "https://wiki.ros.org/pr2_kinematics", "package": "pr2_kinematics", "package_summary": ["The pr2_kinematics package"], "package_details": ["\n", "\n", "\n", "  ", "To learn how to use the kinematics nodes for the PR2 through a ROS API, check out ", ". "]},
{"url": "https://wiki.ros.org/rotors_comm", "package": "rotors_comm", "package_summary": ["RotorS specific messages and services."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/kurt_description", "package": "kurt_description", "package_summary": ["\n\n     This package contains URDF descriptions of the KURT robots. The complete\n     robots are available in the directory \"robots/\". Each robot consists of\n     a base and a top (see those two directories). Usually, a top is made up\n     from several parts (see directory \"parts/\"), such as a laser scanner.\n\n  "]},
{"url": "https://wiki.ros.org/micros_swarm_framework", "package": "micros_swarm_framework", "package_summary": ["This is a programming framework to facilitate application development involving robot swarms. It makes coding for swarms much easier by providing an adequate swarm-level abstraction, as well as tools for swarm management, various communication mechanisms and so on. It also provides essential data structures, such as Neighbor, Swarm, and Virtual Stigmergy, to the user. Most importantly, it is completely compatible with ROS Indigo and presented in the form of a C++ library, which means that all resources in the ROS ecosystem are still available to the user. It is currently  extensible to Opensplice DDS."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "note: we could define ", " structure using the simple type, for example int, float, string. For the user-defined data-type, we need to use the Macro definition defined in the micros_swarm_framework to serialize in order to store and transport data of this type. We provided two Macro definition:BOOST_SERIALIZE, MEMBER: "], "package_code": ["mkdir -p catkin_ws/src\n", "cd catkin_ws/src\n", "catkin_init_workspace\n", "git clone https://github.com/xuefengchang/micros_swarm_framework.git\n", "cd ..\n", "catkin_make -j1\n", "source devel/setup.bash", "Swarm s = Swarm(1);  //create a swarm s with id 1", "Swarm s = Swarm(1);  //create a swarm s with id 1\n", "int id=s.id();", "Swarm s = Swarm(1);  //create a swarm s with id 1\n", "std::set<int> m=s.members();", "s.join();  //join in the swarm s", "s.leave();  //leave the swarm s", "bool checkID(unsigned int id)\n", "{\n", "    if(id%2==0)\n", "        return true;\n", "    return false;\n", "}\n", "\n", "/*\n", " *you might need to learn the bind and function in boost libarary.\n", " */\n", "boost::function<bool()> bf=boost::bind(&checkID, self_id);\n", "\n", "s.select(bf);  //the robot whose id is even join in the swarm s", "bool checkID(unsigned int id)\n", "{\n", "    if(id%2==0)\n", "        return true;\n", "    return false;\n", "}\n", "\n", "boost::function<bool()> bf=boost::bind(&checkID, self_id);\n", "\n", "s.unselect(bf);  //the robot whose id is even leave the swarm s", "void printID(unsigned int id)\n", "{\n", "    std::cout<<\"id=\"<<id<<std::endl;\n", "}\n", "\n", "boost::function<void()> f = boost::bind(&printID, self_id);\n", "\n", "s.execute(f);  //the robot in the swarm s print the id of themselves", "void printID(unsigned int id)\n", "{\n", "    std::cout<<\"id=\"<<id<<std::endl;\n", "}\n", "\n", "boost::function<void()> f = boost::bind(&printID, self_id);\n", "\n", "s.execute(f);  //the robot in the swarm s print the id of themselves", "Swarm s = Swarm(1);\n", "s.breakup();  //break up an existing swarm", "Swarm a = Swarm(1);\n", "Swarm b = Swarm(2);\n", "Swarm c = a.intersection(b, 3);  //intersect swarm a and swarm b, generating a new swarm c with id 3", "Swarm a = Swarm(1);\n", "Swarm b = Swarm(2);\n", "Swarm c = a.swarm_union(b, 3);  //union swarm a and swarm b, generating a new swarm c with id 3", "Swarm a = Swarm(1);\n", "Swarm b = Swarm(2);\n", "Swarm c = a.difference(b, 3);  //swarm a difference with swarm b, generating a new swarm c with id 3", "Swarm a = Swarm(1);\n", "Swarm b = a.negation(2);  //negate swarm a, generating a new swarm b with id 2", "Neighbors<NeighborBase> n;  //NeighborBase type", "Neighbors<int> n1;  //int\n", "Neighbors<float> n2;  //float\n", "Neighbors<string> n3;  //string\n", "Neighbors<Type> n4;  //user-defined type", "Neighbors<int> n;\n", "\n", "void testforeach(int a)\n", "{\n", "    std::cout<<\"testforeach.\"<<std::endl;\n", "}\n", "\n", "n.foreach(testforeach);\n", "\n", "//If using class member functions\n", "class TestForeach{\n", "    public:\n", "        void testforeach(int a)\n", "        {\n", "            std::cout<<\"testforeach.\"<<std::endl;\n", "        }\n", "}\n", "\n", "TestForeach tf;\n", "\n", "boost::function<void(int)> bf_testforeach=boost::bind(&TestForeach::testforeach, tf, _1);\n", "n.foreach(bf_testforeach);", "Neighbors<int> n;\n", "\n", "float testmap(int a)\n", "{\n", "    return a+3.14;\n", "}\n", "\n", "Neighbors<float> b = n.map(testmap);\n", "\n", "//If using class member functions\n", "class TestMap{\n", "    public:\n", "        float testmap(int a)\n", "        {\n", "            return a+3.14;\n", "        }\n", "}\n", "\n", "TestMap tm;\n", "\n", "boost::function<float(int)> bf_testmap=boost::bind(&TestMap::testmap, tm, _1);\n", "n.map(bf_testmap);", "Neighbors<int> n;\n", "\n", "float testreduce(int a, float& b)\n", "{\n", "    b=b+a*2;\n", "    return b;\n", "}\n", "\n", "float t2=0;\n", "\n", "t2 = n.reduce(testreduce, t2);\n", "\n", "//If using class member functions\n", "class TestReduce{\n", "    public:\n", "        float testreduce(int a, float &b)\n", "        {\n", "            b=b+a*2;\n", "            return b;\n", "        }\n", "}\n", "\n", "TestReduce tr;\n", "\n", "boost::function<float(int,float&)> bf_testreduce=boost::bind(&TestReduce::testreduce, tr, _1, _2);\n", "n.reduce(bf_testreduce);", "Neighbors<NeighborBase> n;\n", "\n", "bool testfilter(int a, NeighborBase b)\n", "{\n", "    if(b.getX()>=5)\n", "        return true;\n", "    return false;\n", "}\n", "\n", "Neighbors<NeighborBase> c = n.filter(testfilter);\n", "\n", "//If using class member functions\n", "class TestFilter{\n", "    public:\n", "        bool testfilter(int a, NeighborBase b)\n", "        {\n", "            if(b.getX()>=5)\n", "                return true;\n", "            return false;\n", "        }\n", "}\n", "\n", "TestFilter tf;\n", "\n", "boost::function<bool(int, NeighborBase)> bf_testfilter=boost::bind(&TestFilter::testfilter, tf, _1, _2);\n", "n.filter(bf_testfilter);", "Neighbors<float> n;\n", "Neighbors<float> c=n.kin(1);  //the memeber of the neighbors n which belong to the swarm with id 1 at the same time form a new neighbors c", "Neighbors<float> n;\n", "Neighbors<float> c=n.nonkin(1);  //the memeber of the neighbors n which don't belong to the swarm with id 1 form a new neighbors c", "VirtualStigmergy<float> v(1);  //data type is float\uff0cid is 1", "v.put(\"test\", 3.14);  //put <\"test\", 3.14> into the VirtualStigmergy v", "v.get(\"test\");  //query the value with the key \"test\" of the VirtualStigmergy v", "v.size();", "class TestVstigDataType{\n", "        private:\n", "            int a_;\n", "            float b_;\n", "            std::string c_;\n", "\n", "            BOOST_SERIALIZE\n", "            {\n", "                MEMBER a_;\n", "                MEMBER b_;\n", "                MEMBER c_;\n", "            }\n", "\n", "        public:\n", "            TestVstigDataType(){}\n", "            TestVstigDataType(int a, float b, std::string c)\n", "            {\n", "                a_=a;\n", "                b_=b;\n", "                c_=c;\n", "            }\n", "\n", "            void printTestVstigDataType()\n", "            {\n", "                std::cout<<\"a_ = \"<<a_<<std::endl;\n", "                std::cout<<\"b_ = \"<<b_<<std::endl;\n", "                std::cout<<\"c_ = \"<<c_<<std::endl;\n", "            }\n", "};", "roslaunch micros_swarm_stage swarm_in_stage.launch", "roslaunch micros_swarm_stage daemon_node.launch", "roslaunch micros_swarm_stage app1.launch", "roslaunch micros_swarm_stage swarm_in_stage.launch", "roslaunch micros_swarm_stage daemon_node.launch", "roslaunch micros_swarm_stage app2.launch", "roslaunch micros_swarm_stage swarm_in_stage2.launch", "roslaunch micros_swarm_stage daemon_node.launch", "roslaunch micros_swarm_stage app3.launch"]},
{"url": "https://wiki.ros.org/agvs_description", "package": "agvs_description", "package_summary": ["The agvs_description package. Robot description. Urdf and mesh files."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/khi_rs_ikfast_plugin", "package": "khi_rs_ikfast_plugin", "package_summary": ["The khi_rs_ikfast_plugin package"]},
{"url": "https://wiki.ros.org/moveit_full_pr2", "package": "moveit_full_pr2", "package_summary": ["All MoveIt components, plugins and PR2-specific plugins"]},
{"url": "https://wiki.ros.org/maggie_base", "package": "maggie_base", "package_summary": ["base node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["cmd_vel", "odom"], "package_code": [" $ roslaunch maggie_base base.launch robot:=maggie", " $ rostopic echo /maggie/odom"]},
{"url": "https://wiki.ros.org/pr2_teleop_general", "package": "pr2_teleop_general", "package_summary": ["pr2_teleop_general"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: ", ") ", "\n", " (", ", default: ", ") ", "Note: This package originated as ", " and wasn't released before ", ". ", "The base control is accessible by pushing the top left front button.  Base and torso controls are essentially the same as that described in ", ".  "], "package_tt": ["pr2_teleop_booth", "control_body", "Boolean", "true", "control_head", "Boolean", "true", "control_rarm", "Boolean", "true", "control_larm", "Boolean", "true", "control_prosilica", "Boolean", "true", "arm_controller_name", "string", "\"arm_controller\"", "arm_controller_name", "string", "\"arm_controller\"", "prosilica_namespace", "string", "\"prosilica_polled\""], "package_code": ["roslaunch pr2_teleop_general pr2_teleop_general_joystick.launch", "roslaunch pr2_teleop_general pr2_teleop_general_joystick_noik.launch", "roslaunch pr2_teleop_general pr2_teleop_general_joystick_bodyhead_only.launch ", "roslaunch pr2_teleop_general pr2_teleop_general_keyboard.launch", "roslaunch pr2_teleop_general pr2_teleop_general_keyboard_noik.launch", "roslaunch pr2_teleop_general pr2_teleop_general_keyboard_bodyhead_only.launch"]},
{"url": "https://wiki.ros.org/predicate_manager", "package": "predicate_manager", "package_summary": ["Predicate Manager is a ROS library to define and manage logical predicates and events."]},
{"url": "https://wiki.ros.org/pr2_app_manager", "package": "pr2_app_manager", "package_summary": ["Scripts and tools for running the application manager on the PR2."], "package_details": ["\n", "\n", "If you have the old version, you will be asked if you want to set up your SSH keys.  Answer \"Y\" for yes.  You should see a random ASCII art square.  Then type ", " to log back out of the \"applications\" user account. ", "If you have the new version, you will not be asked anything, you will just get a regular shell prompt.  Type ", " to log out of the \"applications\" account. ", "The QR codes for the PR2s are specified with a variety of attributes stored in YAML to help connect to them. They are generated using ", ". To create the QR codes, use the \"Text\" mode, type in the text (examples below) and click generate. When you are finished, you can right click and save or print the QR code image. To avoid the hassle of printing, many devices can read the QR code directly off of your PC screen. "], "package_tt": ["exit", "exit"], "package_code": ["sudo apt-get update\n", "sudo apt-get install ros-electric-pr2-apps ros-electric-wg-common ros-electric-multimaster-experimental ros-electric-pr2-props-stack", "sudo userdel applications\n", "sudo groupdel applications\n", "sudo rm -rf /u/applications\n", "sudo rm -rf /home/applications", "roscd pr2_app_manager/scripts/\n", "sudo ./install_applications.sh", "Enter the robot name (e.g. pri):", "sudo su applications", "robot claim\n", "robot start\n", "roslaunch pr2_app_manager pr2_app_manager.launch", "URL: http://pri1:11311/\n", "CURL: http://pri1/cgi-bin/control.py\n", "WIFI: priLAN", "WIFIPW: <then the wifi password>"]},
{"url": "https://wiki.ros.org/keyboard", "package": "keyboard", "package_summary": ["publishes keyboard key presses"], "package_details": ["\n", "\n", " "], "package_tt": ["keydown", "keyup", "~allow_repeat", "bool", "~repeat_delay", "int", "~repeat_interval", "int"]},
{"url": "https://wiki.ros.org/ros_comm", "package": "ros_comm", "package_summary": ["ROS communications-related packages, including core client libraries (roscpp, rospy) and graph introspection tools (rostopic, rosnode, rosservice, rosparam)."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". Please use 'ros_comm:' at the beginning of the title. [", "]", "\n ", "The ", " stack contains the ROS middleware/communications packages. These packages are collectively known as the ROS \"Graph\" layer. They provide implementations and tools for ", ", ", ", ", ", and ", ". This includes the supported ROS client libraries: ", ", ", ", and ", ". ", "C Turtle has an empty version of the ", " stack. This is provided so that stacks may update their dependencies for Diamondback but not break dependency compatibility with a C Turtle release. ", "ros_comm developers only: ", " "], "package_tt": ["ros_comm", "ros_comm"]},
{"url": "https://wiki.ros.org/rotate_recovery", "package": "rotate_recovery", "package_summary": ["This package provides a recovery behavior for the navigation stack that attempts to clear space by performing a 360 degree rotation of the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", " (", ", default: 0.017) ", "\n", " (", ", default: 0.05) ", "\n", "The ", " is a simple recovery behavior that attempts to clear out space in the navigation stack's ", " by rotating the robot 360 degrees if local obstacles allow. It adheres to the ", " interface found in the ", " package and can be used as a recovery behavior ", " for the ", " node. ", "The ", " object exposes its functionality as a ", ". It operates within a ROS namespace (assumed to be ", " from here on) specified on initialization. It adheres to the ", " interface found in the ", " package. ", "Example creation of a ", " object: ", "The ", " object assumes that the local planner used by the ", " node is the ", " documented in the ", " package and reads some of its parameters accordingly. It will work on its own, but this requires the user to specify additional parameters. ", "These parameters are already set when using the ", " local planner, they only need to be set explicitly for the ", " recovery behavior if a different local planne is used with the ", ". ", "The C++ ", " class adheres to the ", " interface found in the ", " package. For detailed documentation, please see ", ". "], "package_tt": ["rotate_recovery::RotateRecovery", "nav_core::RecoveryBehavior", "rotate_recovery::RotateRecovery", "nav_core::RecoveryBehavior", "rotate_recovery::RotateRecovery", "rotate_recovery::RotateRecovery", "base_local_planner::TrajectoryPlannerROS", "~<name>/sim_granularity", "double", "~<name>/frequency", "double", "base_local_planner::TrajectoryPlannerROS", "rotate_recovery::RotateRecovery", "~TrajectoryPlannerROS/yaw_goal_tolerance", "double", "~TrajectoryPlannerROS/acc_lim_th", "double", "~TrajectoryPlannerROS/max_rotational_vel", "double", "~TrajectoryPlannerROS/min_in_place_rotational_vel", "double", "rotate_recovery::RotateRecovery", "nav_core::RecoveryBehavior"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/velodyne_description", "package": "velodyne_description", "package_summary": ["URDF and meshes describing Velodyne laser scanners."], "package_details": ["Documentation at ", " "]},
{"url": "https://wiki.ros.org/rqt_robot_dashboard", "package": "rqt_robot_dashboard", "package_summary": ["rqt_robot_dashboard provides an infrastructure for building robot dashboard plugins in rqt."], "package_details": ["\n", "Check out the ", " for more information. "]},
{"url": "https://wiki.ros.org/nodelet_topic_tools", "package": "nodelet_topic_tools", "package_summary": ["This package contains common nodelet tools such as a mux, demux and throttle."], "package_details": ["\n", " represent a mux nodelet for topics: it takes N (<=8) input topics, and publishes all of them on one output topic. One implementation of ", " can be found in ", ". ", "\n", " represent a demux nodelet for topics: it takes 1 input topic, and publishes on N (<=8) output topics. One implementation of ", " can be found in ", ". ", "\n", " ", " can throttle a topic in a nodelet to a specified rate. Note that this tool is in the ", " namespace. ", "The ", " package contains a MUX (", ") and a DEMUX (", ") nodelet.  ", "The above accepts data from ", " and ", ", and republishes it on ", ". ", "To compile the ", " nodelet in your library, add something like: ", "(replace ", " with the message type of choice). ", "The above accepts data from ", ", and republishes it on ", " and ", ". ", "To compile the ", " nodelet in your library, add something like: ", "(replace ", " with the message type of choice). ", "To compile the ", " nodelet in your library, add something like: ", "(replace ", " with the message type of choice). "], "package_tt": ["nodelet_topic_tools", "NodeletMUX", "NodeletDEMUX", "NodeletMUX", "NodeletMUX", "/passthrough/output", "/normal_estimation/output", "/data_mux/output", "NodeletMUX", "sensor_msgs::PointCloud2", "NodeletDEMUX", "NodeletDEMUX", "/data_demux/input", "/data_demux/output1", "/data_demux/output2", "NodeletDEMUX", "sensor_msgs::PointCloud2", "NodeletThrottle", "nodelet_topic_tools", "NodeletThrottle", "sensor_msgs::Image"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/abb_irb2400_support", "package": "abb_irb2400_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 2400 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 2400 manipulators. This currently includes the base model.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the ABB data sheets.  All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      The unqualified IRB 2400 model will be removed in ROS-Lunar, please\n      use the IRB 2400-12/1.55 as a replacement.\n    "]},
{"url": "https://wiki.ros.org/kvh_geo_fog_3d", "package": "kvh_geo_fog_3d", "package_summary": ["Provides a driver node for KVH GEO FOG 3D INS sensors, messages, and rviz plugins."], "package_details": ["\n", " ", "ROS package for the ", " set of GNSS/INS sensors. "]},
{"url": "https://wiki.ros.org/rotors_evaluation", "package": "rotors_evaluation", "package_summary": ["The dataset evaluation package for the RotorS simulator."]},
{"url": "https://wiki.ros.org/industrial_deprecated", "package": "industrial_deprecated", "package_summary": ["The Industrial deprecated package contains nodes, launch files, etc... that are slated for \n  deprecation.  This package is the last place something will end up before being deleted.  \n  If you are missing a package/node and find it's contents here, then you should consider \n  a replacement."], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/s3000_laser", "package": "s3000_laser", "package_summary": ["The s3000_laser package"], "package_details": ["\n", "\n", " ", "\n", "\n"], "package_tt": ["s3000_laser/scan", "~port", "string", "~frame_id", "string", "~baud_rate", "int", "~serial_parity", "string", "~serial_datasize", "int", "~range_min", "float", "~range_max", "float"]},
{"url": "https://wiki.ros.org/roscpp", "package": "roscpp", "package_summary": ["roscpp is a C++ implementation of ROS. It provides\n    a ", " that enables C++ programmers to quickly interface with\n    ROS ", ",\n    ", ",\n    and ", ".\n\n    roscpp is the most widely used ROS client library and is designed to\n    be the high-performance library for ROS."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Please refer to the ", " package ", "For usage documentation and more in-depth treatment than the tutorials, please see the ", " ", "For a detailed API reference, please consult the ", " "]},
{"url": "https://wiki.ros.org/kobuki_keyop", "package": "kobuki_keyop", "package_summary": ["Keyboard teleoperation for Kobuki: relays commands from a keyboard to Kobuki."], "package_details": [" "]},
{"url": "https://wiki.ros.org/pepper_robot", "package": "pepper_robot", "package_summary": ["The pepper_robot package"]},
{"url": "https://wiki.ros.org/pr2_run_stop_auto_restart", "package": "pr2_run_stop_auto_restart", "package_summary": ["This package provides a node that monitors the state of the run stops of the pr2_robot. When the state of the\n   run stop changes from off to on, this node will automatically enable the power to the motors, and reset\n   the motors. This allows you to use the run stop as a 'pause' button. By using the run stop as a tool to\n   power up the robot, the run stop is also in reach of the user once the robot starts moving."], "package_details": ["\n", "\n"], "package_tt": ["run_stop_auto_restart", "power_board/state", "power_board/control", "pr2_etherCAT/reset_motors"]},
{"url": "https://wiki.ros.org/ros_ethercat", "package": "ros_ethercat", "package_summary": ["A pr2 agnostic replacement for robots using EtherCAT"]},
{"url": "https://wiki.ros.org/motoman_sia20d_moveit_config", "package": "motoman_sia20d_moveit_config", "package_summary": ["MoveIt package for the Motoman SIA20D.", "\n      An automatically generated package with all the configuration and launch files for using the Motoman SIA20D with the MoveIt Motion Planning Framework.\n    "], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/nao_interaction_launchers", "package": "nao_interaction_launchers", "package_summary": ["Launchers for bringing up the nodes of nao_interaction metapackage."]},
{"url": "https://wiki.ros.org/motoman_mh5_support", "package": "motoman_mh5_support", "package_summary": ["ROS-Industrial support for the Motoman MH5 (and variants).", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman MH5 manipulators.\n    ", "\n      ", "\n    ", "\n      Joint limits and maximum joint velocities are based on the information \n      found in the online \n      http://www.motoman.com/datasheets/mh5.pdf\n      All urdfs are based on the default motion and joint velocity limits, \n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/pr2_bringup", "package": "pr2_bringup", "package_summary": ["Launch files and scripts needed to bring a PR2 up into a running state."], "package_details": [" is a package that collects together the scripts, ", " files, and dependencies that are required to bring a PR2 robot into a running state. ", "\n", "\n", "\n", " ", " ", "\n", "The user's entry point for this package is the file ", ".  This launch file contains all nodes to run a complete PR2 system. However, you cannot use pr2.launch to start up the robot (see ", " for instructions), because pr2.launch requires another launch file to load the robot description and robot analyzer on the parameter server first. ", "To disable the ", " set the \"no-prosilica\" arg to \"true\" in \"/etc/ros/robot.launch\" when launching your PR2: ", "This manual will take you step by step through starting the PR2 robot, ", ". Note: If you have a PR2 that is running both ROS Groovy and ROS Hydro, this is then the start sequence: ", "When the PR2 starts up for the first time since a power down, it will move its arms, casters, head and later platform to find the reference position of each joint.  This is done by the calibration script ", ". When finished, the PR2 joint calibration script stores the joint reference positions locally in the motor controller board (MCB) of the corresponding joint.  So the next time you start the PR2, it will remember the reference positions and won't have to repeat the same calibration routine over and over again. "], "package_tt": ["pr2_bringup", "pr2.launch", "pr2_bringup/scripts/calibrate_pr2.py"], "package_code": ["<launch>\n", "  <arg name=\"no-prosilica\" value=\"true\" />\n", "  <include file=\"$(find pr2_bringup)/pr2.launch\" />\n", "\n", "  <!-- Other stuff -->\n", "</launch>", "robot groovy", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot hydro", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot start"]},
{"url": "https://wiki.ros.org/qb_device_utils", "package": "qb_device_utils", "package_summary": ["This package contains a device-independent utility functions for qbrobotics\u00ae devices."], "package_details": ["This package contains a device-independent utility functions for ", " devices. "]},
{"url": "https://wiki.ros.org/uav_simple_tracking", "package": "uav_simple_tracking", "package_summary": ["A package that tracks a target with an unmanned aerial vehicle (UAV)."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["uav_simple_tracking", "id", "integer", "output", "string", "screen", "screen", "log", "param", "uav_simple_tracking.yaml", "uav_simple_tracking", "uav_simple_tracking", "uav_tracking/goal", "target_update", "target_lost", "target_done", "~loop_rate", "real", "~queue_size", "integer"], "package_code": ["roslaunch uav_simple_tracking uav_simple_tracking.launch"]},
{"url": "https://wiki.ros.org/roslisp_repl", "package": "roslisp_repl", "package_summary": ["This package provides a script that launches Emacs with Slime (the\n    Superior Lisp Interaction Mode) ready for Lisp development and\n    roslisp."], "package_details": ["\n", "\n", "\n", " is distributed through the ROS release infrastructure. ", "\n", "\n", "This package provides you with a Lisp REPL configured to be used to program ROS packages as well as an integrated IDE for programming in Common Lisp with Emacs (see ", "). ", "The most up-to-date version of ", " code can be found ", ". Installation instructions are in the README file. ", "What you'll need to do will be something like the following: ", "To use the ", " just run the executable: ", "If you're on earlier versions of ROS, look through the ", " configuration file, ", " and copy-paste the relevant code into your Emacs config file. "], "package_tt": ["roslisp_repl", "roslisp_repl", "roslisp_repl", "roslisp_repl", "roslisp_repl", "roslisp_repl", "repl-config.el"], "package_code": ["$ sudo apt-get install ros-DISTRO-roslisp-repl", "$ cd YOUR_CATKIN_WS/src\n", "$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git\n", "$ wstool update ros_emacs_utils\n", "$ cd ..\n", "$ catkin_make\n", "$ catkin_make install\n", "$ emacs -nw ~/.emacs.d/init.el # edit your emacs configuration file", "$ roslisp_repl", "$ source ~/.bashrc\n", "$ rospack profile\n", "$ rosrun roslisp_repl roslisp_repl"]},
{"url": "https://wiki.ros.org/rb1_common", "package": "rb1_common", "package_summary": ["The rb1_common package. It contains rb1 mobile manipulator common packages"]},
{"url": "https://wiki.ros.org/planner_msgs", "package": "planner_msgs", "package_summary": ["The planner_msgs package. Messages and actions for planning the autonomous movement of the robot."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/qt_paramedit", "package": "qt_paramedit", "package_summary": ["A GUI application for viewing and editing ROS parameters."], "package_details": ["\n", "\n", " ", "Note: This package replaces groovy's ", " in hydro. "], "package_code": ["rosrun qt_paramedit qt_paramedit [parameter root] (default: /)"]},
{"url": "https://wiki.ros.org/rqt_pr2_dashboard", "package": "rqt_pr2_dashboard", "package_summary": ["rqt_pr2_dashboard is a GUI for debugging and controlling low-level state of the PR2.  It shows things like battery status and breaker states, as well as integrating tools like rqt_console and robot_monitor."], "package_details": ["\n", "A successor of ", " with enhancements based on ", " framework. ", "(see ", " for more installation details) "], "package_tt": ["rqt"], "package_code": ["$ sudo apt-get install ros-%YOUR_ROS_DISTRO%-rqt-pr2-dashboard\n", "$ sudo apt-get install ros-groovy-rqt-pr2-dashboard   (an example in Groovy)", "$ rosdep update\n", "$ rosdep install rqt_pr2_dashboard"]},
{"url": "https://wiki.ros.org/phantomx_reactor_arm_description", "package": "phantomx_reactor_arm_description", "package_summary": ["The phantomx_reactor_arm_description package"]},
{"url": "https://wiki.ros.org/pepper_control", "package": "pepper_control", "package_summary": ["Control for Pepper robot"], "package_details": ["Is used within ", " and ", " packages  "]},
{"url": "https://wiki.ros.org/nao_interaction", "package": "nao_interaction", "package_summary": ["Metapackage for the Nao robot, providing access to: - NAOqi audio proxies - NAOqi vision proxies"]},
{"url": "https://wiki.ros.org/mir_gazebo", "package": "mir_gazebo", "package_summary": ["Simulation specific launch and configuration files for the MiR100 robot."]},
{"url": "https://wiki.ros.org/kuka_experimental", "package": "kuka_experimental", "package_summary": ["Experimental packages for KUKA manipulators within ROS-Industrial.", ": This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status ", "."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This repository is part of the ", " program. It contains experimental packages that will be moved to the ", " repository once they've received sufficient testing and review. ", "Refer to the ", " for more information. ", "For the generic ROS-Industrial tutorials, please see the ROS-Industrial ", ". ", "For questions related to the KUKA support or ROS-Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/libphidget21", "package": "libphidget21", "package_summary": ["This package wraps the libphidget21 to use it as a ROS dependency"]},
{"url": "https://wiki.ros.org/pr2_controller_configuration_gazebo", "package": "pr2_controller_configuration_gazebo", "package_summary": ["A copy of the pr2_controller_configuration package, for use in \n    the PR2 simulator.  We maintain two copies to allow for controller\n    gains to be set differently between hardware and simulation."], "package_details": ["Please see ", " for details of all the configuration and launch scripts. "]},
{"url": "https://wiki.ros.org/mir_actions", "package": "mir_actions", "package_summary": ["Action definitions for the MiR100 robot"]},
{"url": "https://wiki.ros.org/dbw_pacifica_msgs", "package": "dbw_pacifica_msgs", "package_summary": ["Drive-by-wire messages for the Chrysler Pacifica"]},
{"url": "https://wiki.ros.org/kuka_kr120_support", "package": "kuka_kr120_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR 120 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 120 manipulators. This currently includes the R2500 PRO\n      (KR QUANTEC PRO) only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      found in the online\n      http://www.kuka-robotics.com/res/sps/e6c77545-9030-49b1-93f5-4d17c92173aa_Spez_KR_QUANTEC_pro_en.pdf.\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/marti_common_msgs", "package": "marti_common_msgs", "package_summary": ["marti_common_msgs"]},
{"url": "https://wiki.ros.org/map_merge_3d", "package": "map_merge_3d", "package_summary": ["Merging multiple 3D maps, represented as pointclouds,\n  without knowledge of initial positions of robots."], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " ", "\n", " finds robot maps automatically and new robots can be added to the system at any time. 3D maps are expected as ", ", other map messages are not supported. ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ROS node can merge maps from the arbitrary number of robots. It expects maps from individual robots as ROS topics and does not impose any particular messaging between robots. If your run multiple robots under the same ROS master then ", " may work for you out-of-the-box, this makes it easy to setup a simulation experiment. ", "In the multi-robot exploration scenario your robots probably run multiple ROS masters and you need to setup a communication link between robots. Common solution might be ", ". You need to provide maps from your robots on local topics (under the same master). Also if you want to distribute merged map and ", " transformations back to robots your communication must take care of it. ", "Recommended topics names for robot maps are ", ", ", " etc. However the names are configurable. All robots are expected to publish map under ", ", where topic name (", ") is configurable, but must be the same for all robots. For each robot ", " is of cause different, but it does not need to follow any pattern. Further, you can exclude some topics using ", " parameter, to avoid merging unrelated point clouds. ", "Estimating transforms between maps is cpu-intesive so you might want to tune ", " parameter to run the re-estimation less often. ", "Alongside ROS node ", " provides command-line tools to work with point cloud maps saved in ", " files. Both tools accept any of the ", ". ", "The tools use PCL command-line parsing module. PCL command-line parsing has some limits (PCL users won't be surprised): it supports only ", " format, ", " is not accepted. Unknown options are ignored. Options may be arbitrarily mixed with filenames. There are no short versions for parameters. ", "Tool for merging maps offline. Produces ", " with merged global map. This tool can merge arbitrary number of maps. ", "After one step of the estimation a visualisation window appears. You can freely navigate the point cloud, save a screenshot or camera parameters (press ", " to see all shortcuts). After the window is closed, estimation continues with the next phase and the next visualisation window appears. Details about estimation progress are printed to ", ". ", "This package was developed as part of my master thesis at ", " in Prague. "], "package_tt": ["map_merge_3d", "map_merge_3d", "/robot1/map", "/robot2/map", "<robot_namespace>/map", "map", "<robot_namespace>", "robot_namespace", "estimation_rate", "<robot_namespace>/map", "map", "~robot_map_topic", "string", "map", "~robot_namespace", "string", "<empty\u00a0string>", "robot_map_topic", "robot_namespace", "~merged_map_topic", "string", "map", "~world_frame", "string", "world", "~compositing_rate", "double", "0.3", "~discovery_rate", "double", "0.05", "~estimation_rate", "double", "0.01", "~publish_tf", "bool", "true", "~resolution", "double", "0.1", "~descriptor_radius", "double", "resolution\u00a0*\u00a08.0", "~outliers_min_neighbours", "int", "50", "~normal_radius", "double", "resolution\u00a0*\u00a06.0", "~keypoint_type", "string", "SIFT", "SIFT", "HARRIS", "~keypoint_threshold", "double", "5.0", "0.0", "~descriptor_type", "string", "PFH", "PFH", "PFHRGB", "FPFH", "RSD", "SHOT", "SC3D", "~estimation_method", "string", "MATCHING", "MATCHING", "SAC_IA", "~refine_transform", "bool", "true", "~inlier_threshold", "double", "resolution\u00a0*\u00a05.0", "~max_correspondence_distance", "double", "inlier_threshold\u00a0*\u00a02.0", "~max_iterations", "int", "500", "~matching_k", "int", "5", "~transform_epsilon", "double", "1e-2", "~confidence_threshold", "double", "0.0", "~output_resolution", "double", "0.05", "world", "mapX_frame", "world_frame", "frame_id", "mapX_frame", "map_merge_3d", "pcd", "--param\u00a0value", "--param=value", "output.pcd", "h", "stdout"], "package_code": ["rosrun map_merge_3d map_merge_tool [--param value] map1.pcd map2.pcd [map3.pcd...]", "rosrun map_merge_3d map_merge_tool --descriptor_type SHOT map1.pcd map2.pcd map3.pcd", "rosrun map_merge_3d registration_visualisation [--param value] map1.pcd map2.pcd"]},
{"url": "https://wiki.ros.org/um6", "package": "um6", "package_summary": ["The um6 package provides a C++ implementation of the CH Robotics serial protocol, and a\n    corresponding ROS node for publishing standard ROS orientation topics from a UM6."], "package_details": [" ", "\n", "\n", "\n", "\n", " A rosbuild branch is also available in the repository, for users working with rosbuild workspaces under Fuerte or Groovy. ", "\n", "\n", "The UM6 is available for purchase ", ". Alternatively, the UM6 is available as a standard supported accessory from Clearpath Robotics\u2014for example, for use with ", ". ", "For further information about this device and its configuration, please see its ", ". ", "Please see ", " for more information. ", "At ", ", we use a configuration which subscribes to the magnetometer as a raw data feed, and fuses it into the orientation as a process external to the device. This functionality is provided via the ", " package. "], "package_tt": ["imu/data", "imu/mag", "imu/rpy", "imu/temperature", "~port", "string", "~baud", "int", "~mag_updates", "bool", "~accel_updates", "bool", "~mag_ref/[x,y,z]", "float", "~accel_ref/[x,y,z]", "float", "~mag_bias/[x,y,z]", "float", "~accel_bias/[x,y,z]", "float", "~gyro_bias/[x,y,z]", "float"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-um6", "rosrun um6 um6_driver _port:=/dev/ttyUSB0"]},
{"url": "https://wiki.ros.org/kurt_gazebo", "package": "kurt_gazebo", "package_summary": ["\n\n     This package contains launch files for starting up Kurt in the Gazebo simulator.\n\n  "]},
{"url": "https://wiki.ros.org/uuid_msgs", "package": "uuid_msgs", "package_summary": ["ROS messages for universally unique identifiers."], "package_details": ["\n", "\n", "This package defines a ROS message for a ", ", as described in ", ". "]},
{"url": "https://wiki.ros.org/moveit_simple_grasps", "package": "moveit_simple_grasps", "package_summary": ["A basic grasp generator for simple objects such as blocks or cylinders for use with the MoveIt! pick and place pipeline. \n    Does not consider friction cones or other dynamics."], "package_details": ["Extensive documentation available on ", " "]},
{"url": "https://wiki.ros.org/navigation_experimental", "package": "navigation_experimental", "package_summary": ["A collection of navigation plugins and tools: Various recovery behaviors,\n    local and global planner plugins for move_base, a teleop filter for\n    obstacle avoidance, a simple control-based move_base replacement\n    etc."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/rosbash_params", "package": "rosbash_params", "package_summary": ["Tools for writing ros-node-like bash scripts"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "This Bash env-hook adds a \"node-like\" interface to your code written in Bash. The main thing it adds is ROS-like command-line parameter parsing (", "), so that you can easily call the Bash script from a launch file like "], "package_tt": ["_param:=value", "_param:=value", "_param:=value\u00a0positional_arg1\u00a0positional_arg2\u00a0_andrew:=martin", "positional_arg1", "positional_arg2", ":=", "rosbash_param\u00a0var\u00a0&quot;param&quot;\u00a0&quot;default&quot;", "true", "True", "yes", "on", "1", "True", "false", "false", "no", "off", "0", "False", "0", "0", "rospy", "roscore", "rosbash_node_name", "__name:=name", "\"$@\"", "rosbash_unused_params", "rosbash_param", "rosbash_unused_argv", "arg_string=\"${rosbash_unused_argv[@]}\"", "_rosbash_params", "rosbash_init_node", "result_var", "param", "default", "exit\u00a01", "return\u00a01", "ROS_BASH_PARAM_EXIT", "0", "1", "False", "True", "True", "False", "0", "1", "ROS_BASH_USE_PARAM_SERVER", "\"0\"", "ROS_BASH_USE_PARAM_VERBOSE", "\"0\"", "ROS_BASH_PARAM_EXIT", "\"0\"", "exit\u00a01", "return\u00a01"], "package_code": ["<node name=\"test\" pkg=\"pkg\" type=\"my_bash_script.sh\">\n", "    <param name=\"par\" value=\"test\" />\n", "</node>", "rosbash_init_node \"node_name\" \"$@\"  # parse the command line arguments\n", "\n", "rosbash_param mandatory_param \"param_name\"  # if default value is not specified, the param is mandatory\n", "rosbash_param optional_param \"param2_name\" \"default_value\" # optional param\n", "rosbash_param bool_param1 \"bool_name1\" # bool param without default\n", "rosbash_param bool_param2 \"bool_name2\" \"True\" # bool param with default\n", "rosbash_param bool_param3 \"bool_name3\" \"False\" # bool param with default\n", "\n", "echo \"mandatory_param = ${mandatory_param}\"  # access the parsed parameter value\n", "echo \"optional_param = ${optional_param}\"  # access the parsed parameter value\n", "echo \"bool_param1 = ${bool_param1}\"  # access the parsed parameter value\n", "echo \"bool_param2 = ${bool_param2}\"  # access the parsed parameter value\n", "echo \"bool_param3 = ${bool_param3}\"  # access the parsed parameter value\n", "\n", "echo \"rosbash_unused_argv = ${rosbash_unused_argv[@]}\"  # all CLI args not parsed as a parameter ", "$ ./test_rosbash _param_name:=1 _unparsed_param:=2 positional1 positional2 _bool_name1:=False\n", "mandatory_param = 1\n", "optional_param = default_value\n", "bool_param1 = False\n", "bool_param2 = True\n", "bool_param3 = False\n", "rosbash_unused_argv = _unparsed_param:=2 positional1 positional2", "$ ./test_rosbash positional1 positional2\n", "Required parameter 'param_name' was not set.", "$ ./test_rosbash  _param_name:=test _bool_name1:=1 _bool_name2:=0 _bool_name3:=on\n", "mandatory_param = test\n", "optional_param = default_value\n", "bool_param1 = 1  # without default value, we cannot safely convert all `1`s to `True`\n", "bool_param2 = False  # with default value either `True` or `False`, we can convert `1` to `True` and `0` to `False`\n", "bool_param3 = True  # `on` without quotes is always converted to `True`\n", "rosbash_unused_argv = ", "<launch>\n", "    <node name=\"test\" pkg=\"test_pkg\" type=\"test_rosbash\">\n", "        <param name=\"param_name\" value=\"test\" />\n", "        <param name=\"param2_name\" value=\"optional\" />\n", "        <param name=\"bool_name1\" value=\"off\" />\n", "    </node>\n", "</launch>", "ROS_BASH_PARAM_EXIT=0 rosbash_param var \"mandatory\" || echo \"Please, fill the mandatory param\""]},
{"url": "https://wiki.ros.org/voxel_grid", "package": "voxel_grid", "package_summary": ["voxel_grid provides an implementation of an efficient 3D voxel grid. The occupancy grid can support 3 different representations for the state of a cell: marked, free, or unknown. Due to the underlying implementation relying on bitwise and and or integer operations, the voxel grid only supports 16 different levels per voxel column. However, this limitation yields raytracing and cell marking performance in the grid comparable to standard 2D structures making it quite fast compared to most 3D structures."], "package_details": ["\n", "The ", " has no API that we're supporting officially. You should still feel free to use the code, just know that we're making no guarantees about the stability of the current API. "], "package_tt": ["voxel_grid"]},
{"url": "https://wiki.ros.org/v4r_uvc", "package": "v4r_uvc", "package_summary": ["The v4r_uvc package is a USB-Camera driver with a dynamic reconfigure interface optimized for logitech cameras."]},
{"url": "https://wiki.ros.org/rwt_robot_monitor", "package": "rwt_robot_monitor", "package_summary": ["The rwt_robot_monitor package"]},
{"url": "https://wiki.ros.org/nerian_sp1", "package": "nerian_sp1", "package_summary": ["Node for the SP1 Stereo Vision System by Nerian Vision Technologies"], "package_details": ["\n", "\n", "\n", " ", "\n", " (", ") ", "\n", " (", ", default: ", ") ", "\n", " ", "\n", " ", " ", "The ", " by Nerian Vision Technologies is a stand-alone processing system for performing stereo matching in real time. It is connected to two industrial USB cameras that provide input image data.  The SP1 correlates the images of both cameras and produces a disparity map, which is transmitted through gigabit ethernet. The disparity map describes a mapping of image points from the left camera image to corresponding image points in the right camera image. With this information it is possible to reconstruct the 3D location of the corresponding scene points. ", "The data delivered by the SP1 can be received using the available open source API. Using the API directly is recommended for high performance applications. Alternatively the ", " ROS node can be used for publishing the received data as ROS messages. ", "The behaviour of the node can be configured through various parameters. An example parameterization can be found in the included launch file ", ". The following parameters are supported: ", "The topics published by the nerian_sp1 node can be viewed with ", ". The disparity map can also be visualized with the ", " node. In this case color coding should be activated such that the disparity map can be displayed on a screen. In order to do so, please launch the image_view node as follows: "], "package_tt": ["nerian_sp1", "/nerian_sp1/point_cloud", "/nerian_sp1/disparity_map", "/nerian_sp1/left_image", "/nerian_sp1/right_image", "/nerian_sp1/stereo_camera_info", "nerian_sp1.launch", "~point_cloud_intensity_channel", "bool", "\"true\"", "~ros_coordinate_system", "bool", "\"true\"", "~color_code_disparity_map", "bool", "\"false\"", "~color_code_legend", "bool", "\"true\"", "~frame", "string", "\"world\"", "~remote_host", "string", "\"0.0.0.0\"", "~remote_port", "string", "\"7681\"", "~local_host", "string", "\"0.0.0.0\"", "~local_port", "string", "\"7681\"", "~use_tcp", "bool", "\"false\"", "~calibration_file", "string", "\"\"", "~delay_execution", "double", "0", "~max_depth", "double", "-1"], "package_code": ["sudo apt-get update\n", "sudo apt-get install ros-`rosversion -d`-nerian-sp1", "rosrun image_view image_view image:=/nerian_sp1/disparity_map", "rosrun image_view image_view image:=/nerian_sp1/left_image"]},
{"url": "https://wiki.ros.org/navigation_stage", "package": "navigation_stage", "package_summary": ["This package holds example launch files for running the ROS navigation stack in stage."], "package_details": ["\n", "\n", "This package holds example launch files for running the ", " stack in ", ". "], "package_tt": ["launch/move_base_amcl_10cm.launch", "launch/move_base_amcl_5cm.launch", "launch/move_base_amcl_2.5cm.launch", "launch/move_base_fake_localization_10cm.launch", "launch/move_base_fake_localization_5cm.launch", "launch/move_base_fake_localization_2.5cm.launch", "launch/move_base_multi_robot.launch", "launch/move_base_gmapping_5cm.launch"]},
{"url": "https://wiki.ros.org/khi_rs_gazebo", "package": "khi_rs_gazebo", "package_summary": ["The khi_rs_gazebo package"]},
{"url": "https://wiki.ros.org/khi_rs007n_moveit_config", "package": "khi_rs007n_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the khi_rs007n with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/global_planner", "package": "global_planner", "package_summary": ["A path planner library and node."], "package_details": ["\n", "\n", "\n", "\n", " ", " ", "Path follows the grid boundaries.  ", "\n", " ", " ", "Slightly different calculation for the potential. Note that the original potential calculation from ", " is a quadratic approximation. Of what, the maintainer of this package has no idea.  ", "\n", " ", " ", "Note that a lot less of the potential has been calculated (indicated by the colored areas). This is indeed faster than using Dijkstra's, but has the effect of not necessarily producing the same paths.  Another thing to note is that in this implementation of A*, the potentials are computed using 4-connected grid squares, while the path found by tracing the potential gradient from the goal back to the start uses the same grid in an 8-connected fashion.  Thus, the actual path found may not be fully optimal in an 8-connected sense.  (Also, no visited-state set is tracked while computing potentials, as in a more typical A* implementation, because such is unnecessary for 4-connected grids).  To see the differences between the behavior of Dijkstra's and the behavior of A*, consider the following example.  ", "\n", " ", "\n", " ", "\n", " ", "For reproducing paths just like ", " did.  ", " ", "\n", "\n", "\n", "This package provides an implementation of a fast, interpolated global planner for navigation. This class adheres to the ", " interface specified in the ", " package. It was built as a more flexible replacement to ", ", which in turn is based on ", ".  ", "The orientation of point i is calculated using the positions of ", " and `i + ", "orientation_window_size`. The window size can be altered to smoothen the orientation calculation. "], "package_tt": ["nav_core::BaseGlobalPlanner", "use_grid_path=True", "use_quadratic=False", "use_dijkstra=False", "old_navfn_behavior=True", "None=0", "Forward=1", "Interpolate=2", "ForwardThenInterpolate=3", "Backward=4", "Leftward=5", "Rightward=6", "i\u00a0-\u00a0orientation_window_size", "~<name>/plan", "~<name>/allow_unknown", "bool", "true", "~<name>/default_tolerance", "double", "default_tolerance", "~<name>/visualize_potential", "bool", "false", "~<name>/use_dijkstra", "bool", "true", "~<name>/use_quadratic", "bool", "true", "~<name>/use_grid_path", "bool", "false", "~<name>/old_navfn_behavior", "bool", "false", "~<name>/lethal_cost", "int", "~<name>/neutral_cost", "int", "~<name>/cost_factor", "double", "~<name>/publish_potential", "bool", "~<name>/orientation_mode", "int", "None=0", "Forward=1", "Interpolate=2", "ForwardThenInterpolate=3", "Backward=4", "Leftward=5", "Rightward=6", "~<name>/orientation_window_size", "int"]},
{"url": "https://wiki.ros.org/urdf_sim_tutorial", "package": "urdf_sim_tutorial", "package_summary": ["The urdf_sim_tutorial package"]},
{"url": "https://wiki.ros.org/netft_utils", "package": "netft_utils", "package_summary": ["C++ class and ROS node for ATI force/torque sensors connected to a Netbox. Includes gravity compensation and transformations."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "This package builds on the original ", " package by Derek King, written in 2008 but not updated since ROS groovy. ", "(You may have to do this every time you open a new terminal window, or add this line to your bashrc: ", ") Build the package ", "The IP address should be the IP address of your sensor. You should see a steady stream of ", " data. ", "The following code covers the gist of how to declare and use a netft object with C++. Do ", " to see it in action (you will have to adjust the IP address of the sensor in the source code, as it's hardcoded to 192.168.1.84. ", "If the program Seg Faults immediately, you may have specified an incorrect IP address for the sensor. Follow this ", " to see a list of IP addresses on your network and find the right one. ", "If the network latency increases significantly after launching the F/T sensor, it is probably pushing too much data. You can reduce its data transmission rate through the Netbox's web interface. Simply navigate to the sensor's IP in a browser, e.g.: ", " Reduce the data transmission rate downward via \"RDT Output Rate.\" "], "package_tt": ["$rosrun\u00a0netft_utils\u00a0netft_utils_cpp_test", "http://192.168.1.84"], "package_code": ["$ mkdir -p ~/Desktop/catkin_ws/src\n", "$ cd catkin_ws\n", "$ catkin_make", "$ cd src\n", "$ git clone https://github.com/UTNuclearRoboticsPublic/netft_utils.git\n", "$ cd ..", "$ source devel/setup.bash", "$ catkin_make", "$ roscore\n", "$ rosrun netft_utils netft_utils_sim\n", "$ rostopic echo /netft_data", "$ rosrun netft_utils netft_node 192.168.1.84\n", "$ rostopic echo /netft_data", "$ rosrun netft_utils netft_utils base_frame sensor_frame\n", "$ rostopic echo /raw_world  (raw data from the sensor, no bias applied, transformed to world frame)\n", "$ rostopic echo /transformed_tool   (if you biased the sensor, it has an effect here)\n", "$ rostopic echo /transformed_world  (if you biased the sensor, it has an effect here)", "$ rosservice call /bias true 20 10", "$ rosrun netft_utils netft_node 192.168.1.84\n", "$ rosrun netft_utils netft_utils base_frame ft_sensor_frame\n", "$ rostopic echo /transformed_world\n", "$ rosservice call /gravity_comp true 20 10", "  ros::init(argc, argv, \"netft_utils_cpp_test\");\n", "  ros::NodeHandle n;\n", "  ros::AsyncSpinner* spinner;\n", "  spinner = new ros::AsyncSpinner(3);\n", "  spinner->start();\n", "  double ftSleep; // controls the data acquisition rate\n", "\n", "  // Subscribe to the F/T topic\n", "  ros::Subscriber ftSub = n.subscribe(\"/netft/netft_data\", 1, netftCallback);\n", "\n", "  // Connect and bias the ft sensor\n", "  NetftUtilsLean* fti = new NetftUtilsLean(&n);\n", "  fti->setFTAddress(\"192.168.1.84\");\n", "  // Adjust the data acquisition rate and set the World and sensor frames, respectively\n", "  fti->initialize(1/ftSleep, \"base_link\", \"sensor_frame\");\n", "\n", "  // Set max and min force/torque readings\n", "  fti->setMax(80.0, 8.0, 60.0, 6.0);\n", "  std::future<bool> ftThread;\n", "  ftThread = std::async(std::launch::async, &NetftUtilsLean::run, fti);\n", "  fti->biasSensor(1);", "  geometry_msgs::WrenchStamped wrench;\n", "  fti->getToolData(wrench);", "  fti->getWorldData(wrench);"]},
{"url": "https://wiki.ros.org/maggie_labjack_drivers", "package": "maggie_labjack_drivers", "package_summary": ["labjack drivers for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/micros_mars_task_alloc", "package": "micros_mars_task_alloc", "package_summary": ["This is a ROS package used for the mult-task allocation in a robot team. It is based on Multi-Agent theory and is an abstraction of ALLIANCE model. A cooperative robot team is a multi-agent robot system in essence. In the team, each robot can be seen as an intelligent agent. We have developed a prototype system by python hitherto. The nodelet-based C++ version is being developed and will be released in short time periods."], "package_details": ["\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", " ", " ", "\n", " ", "The main APIs are shown below. The parameter names present the parameter function clearly. As mentioned above, each motivational behavior is responsible for activating a forwarder to forward the messges sent from the attached behavior set. So the '", "' class should have a parameter named 'forwarder_name' indicating that which forwarder it activates. The paramters of the topics in 'Forwarder' indicate which behavior set they attach. ", "The experimental videos can be downloaded and watched here. ", " "], "package_code": ["Inhibitor(inhibitor_name, topic_in, in_out_msg_type, topic_out, inhibiting_topic, inhibiting_msg_type)\n", "\n", "suppressor(suppressor_name, topic_in, in_out_msg_type, topic_out, suppressing_topic, suppressing_msg_type)\n", "\n", "Forwarder(forwarder_name, topic_1_in , msg_1_type, topic_1_out, topic_2_in, msg_2_type, topic_2_out)\n", "\n", "MotivationalBehavior(motivational_behavior_name, robot_ID, behavior_set_ID, forwarder_name)", "git clone https://github.com/daenny/collvoid.git", "git clone https://github.com/liminglong/multi_robot_stage.git", "git clone https://github.com/liminglong/micros_mars_task_alloc.git", " roslaunch multi_robot_stage multi_robot.launch", "cd /catkin_ws/src/micros_mars_task_alloc/scripts/basic_support", "python robot0.py", "python robot1.py", "python robot2.py", "roslaunch micros_mars_task_alloc robot3_control.launch"]},
{"url": "https://wiki.ros.org/maggie_devices", "package": "maggie_devices", "package_summary": ["maggie_devices metapackage"], "package_details": ["\n", "\n", "ROS packages for the devices of the robot ", ". "]},
{"url": "https://wiki.ros.org/qb_hand_description", "package": "qb_hand_description", "package_summary": ["This package contains the ROS description for qbrobotics\u00ae qbhand device."], "package_details": ["\n", "\n", "This package contains the description resources for the ", " device. It includes the ", "/", " model of the hand with its simplified meshes and its configuration setup. ", "This launch file calls the template ", " with the default settings to visualize a ", " in ", " (and nothing more). "], "package_code": ["roslaunch qb_hand_description qb_hand.launch"]},
{"url": "https://wiki.ros.org/twist_recovery", "package": "twist_recovery", "package_summary": ["A recovery behavior that performs a particular used-defined twist."]},
{"url": "https://wiki.ros.org/gmapping", "package": "gmapping", "package_summary": ["This package contains a ROS wrapper for OpenSlam's Gmapping. \n  The gmapping package provides laser-based SLAM (Simultaneous Localization and Mapping), \n  as a ROS node called slam_gmapping. Using slam_gmapping, you can create a 2-D occupancy\n  grid map (like a building floorplan) from laser and pose data collected by a mobile robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "This is mostly a third party package; the underlying GMapping library is ", ".  Look there for details on many of the parameters listed below. ", "To use ", ", you need a mobile robot that provides odometry data and is equipped with a horizontally-mounted, fixed, laser range-finder.  The ", " node will attempt to transform each incoming scan into the ", " (odometry) ", " frame.  See the \"", "\" for more on required transforms. ", "To make a map from a robot with a laser publishing scans on the ", " topic: "], "package_tt": ["slam_gmapping", "slam_gmapping", "odom", "base_scan", "slam_gmapping", "tf", "scan", "map_metadata", "map", "~entropy", "dynamic_map", "~inverted_laser", "string", "\"false\"", "~throttle_scans", "int", "~base_frame", "string", "\"base_link\"", "~map_frame", "string", "\"map\"", "~odom_frame", "string", "\"odom\"", "~map_update_interval", "float", "~maxUrange", "float", "~sigma", "float", "~kernelSize", "int", "~lstep", "float", "~astep", "float", "~iterations", "int", "~lsigma", "float", "~ogain", "float", "~lskip", "int", "~minimumScore", "float", "~srr", "float", "~srt", "float", "~str", "float", "~stt", "float", "~linearUpdate", "float", "~angularUpdate", "float", "~temporalUpdate", "float", "~resampleThreshold", "float", "~particles", "int", "~xmin", "float", "~ymin", "float", "~xmax", "float", "~ymax", "float", "~delta", "float", "~llsamplerange", "float", "~llsamplestep", "float", "~lasamplerange", "float", "~lasamplestep", "float", "~transform_publish_period", "float", "0", "~occ_thresh", "float", "~maxRange", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["rosrun gmapping slam_gmapping scan:=base_scan"]},
{"url": "https://wiki.ros.org/visualization_rwt", "package": "visualization_rwt", "package_summary": ["visualization packages using rwt"]},
{"url": "https://wiki.ros.org/ar_track_alvar_msgs", "package": "ar_track_alvar_msgs", "package_summary": ["This package is a ROS wrapper for Alvar, an open source AR tag tracking library."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/pepper_moveit_config", "package": "pepper_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the Pepper robot with the MoveIt Motion Planning Framework"], "package_details": ["\n", "Please, find the documentation on the github page ", ". "]},
{"url": "https://wiki.ros.org/abb_irb2400_moveit_plugins", "package": "abb_irb2400_moveit_plugins", "package_summary": ["\n      MoveIt plugins for the ABB 2400 (and variants).\n    ", "\n      This package contains plugins for use with MoveIt and ABB 2400 manipulators.\n      Plugins included support the 2400. See the ABB 2400 support package for\n      information on used joint angle and velocity limits.\n    ", "\n      Before using any of the plugins included in this package, be sure to\n      check they are correct for the particular robot model and configuration\n      you intend to use them with.\n    "], "package_details": ["\n", "This package is part of the ", " program. "]},
{"url": "https://wiki.ros.org/v4r_artoolkitplus", "package": "v4r_artoolkitplus", "package_summary": ["The v4r_artoolkitplus package is a wrapper around the ARToolKitPlus software library for ROS.\n  The ARToolKitPlus is a extended version of ARToolKit's library with a class-based API but with no VRML and camera library.\n  It is also optimized to work with a set of precoded marker, so no marker training is needed.\n  The ARToolKitPlus library was published under GPL2, thanks for that work goes to all people listed in a ./3rdParty/ARToolKitPlus/THANKS.\n  More details about ARToolKitPlus package can be found under http://studierstube.org/handheld_ar/artoolkitplus.php"], "package_details": ["\n", "\n", " ", "This package uses the ARToolKitPlus to detect visual tags encoded with an id. Details to the tag detection can be found at ", " ", "There are a large number of ROS ", " that can be set to customize the behavior of the ", " wrapper. Most of these parameters can also be changed using ", " but some of them must be set at start-up. "], "package_tt": ["ARToolKitPlus"], "package_code": ["sub{\n", "  0.name= image\n", "  0.type= sensor_msgs/Image\n", "  0.desc= Image stream from the camera driver see parameter ''distorted_input''\n", "  1.name= camera_info\n", "  1.type= sensor_msgs/CameraInfo\n", "  1.desc= Camera metadata\n", "}\n", "pub{\n", "  0.name= ~<tf_prefix>/tf\n", "  0.type= tf/tfMessage\n", "  0.desc= TF related to the detected markers\n", "}", "param{\n", "  0.name = ~<name>/show_camera_image\n", "  0.default = false\n", "  0.type = bool\n", "  0.desc = On true it opens a OpenCV window with debug information\n", "  1.name = ~<name>/skip_frames\n", "  1.default = 0\n", "  1.type = int\n", "  1.desc = Number of frames skipped between processing\n", "  2.name = ~<name>/tracker_single_marker\n", "  2.default = true\n", "  2.type = bool\n", "  2.desc = Sets the single marker mode it does not work with tracker_multi_marker = true\n", "  3.name = ~<name>/tracker_multi_marker\n", "  3.default = false\n", "  3.type = double\n", "  3.desc = Sets the multi marker mode it does not work with tracker_single_marker = true, the multi marker mode requires also a ''~<name>/pattern_file''\n", "  4.name = ~<name>/pattern_file\n", "  4.default = \"\"\n", "  4.type = string\n", "  4.desc = filename of the pattern file used for the  multi marker mode, there is a file within the packages cfg folder\n", "  5.name = ~<name>/tf_prefix\n", "  5.default = the node_name\n", "  5.type = string\n", "  5.desc = prefix for the tf publisher\n", "  6.name = ~<name>/marker_mode\n", "  6.default = \"bch\"\n", "  6.type = string\n", "  6.desc = defines the marker id encoding, options are \"bch\" or \"simple\"\n", "  7.name = ~<name>/pattern_width\n", "  7.default = 0.1\n", "  7.type = double\n", "  7.desc = size of single markers\n", "  8.name = ~<name>/edge_threshold\n", "  8.default = 0\n", "  8.type = int\n", "  8.desc = Edge threshold used for the detection, zero means automode\n", "  9.name = ~<name>/border_width\n", "  9.default = 0\n", "  9.type = double\n", "  9.desc = ratio of the marker border, zero means defined by marker_mode\n", "  10.name = ~<name>/undist_mode\n", "  10.default = \"std\"\n", "  10.type = string\n", "  10.desc = undistorted function used to cope with image distortions, options are \"none\", \"std\" and \"lut\". \"lut\" only works up to 1024x1024\n", "  11.name = ~<name>/undist_iterations\n", "  11.default = 10\n", "  11.type = int\n", "  11.desc = Interactions used on the undistort approximation\n", "  12.name = ~<name>/distorted_input\n", "  12.default = true\n", "  12.type = bool\n", "  12.desc = Defines if the input image is distorted or not.\n", "  13.name = ~<name>/pose_estimation_mode\n", "  13.default = \"rpp\"\n", "  13.type = string\n", "  13.desc = Defines the algorithm used to estimate a markers pose. Options are \"normal\", \"cont\" and \"rpp\"\n", "  14.name = ~<name>/use_multi_marker_lite_detection\n", "  14.default = true\n", "  14.type = bool\n", "  14.desc = Only for multi marker mode, on true it uses a faster detection algorithm to find markers before the pattern pose is computed. This value should be set to true if one, next to the pattern, also wants to use the detected marker which is not part of an pattern.\n", "  14.name = ~<name>/pattern_frame\n", "  14.default = pattern\n", "  14.type = string\n", "  14.desc = name of the pattern tf related to a multi marker\n", "}"]},
{"url": "https://wiki.ros.org/abb", "package": "abb", "package_summary": ["ROS-Industrial support for ABB manipulators (metapackage)."], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "See the ", " metapackage for additional packages. ", "For more information on what is required to be able to use these packages with your ABB controller and manipulator, see the ", " page. ", "See the ", " page for an overview of the available tutorials. "]},
{"url": "https://wiki.ros.org/rqt_moveit", "package": "rqt_moveit", "package_summary": ["An rqt-based tool that assists monitoring tasks\n   for ", " motion planner\n   developers and users. Currently the following items are monitored if they\n   are either running, existing or published:\n   "], "package_details": ["\n", "\n", "Follow ", "'s general installation guide ", ". ", "On ", ", ", " is available as binary pkg that comes within ", " meta package.  ", "If you happened to find any problem, follow the usual steps (defined at ", "), namely, Google search it, ", " if you haven't found a solution/workaround, and possiblly open a issue report or enhancement request ticket on Issue/Bug tracker listed above. "], "package_tt": ["rqt", "Ubuntu", "rqt_moveit", "rqt_moveit"]},
{"url": "https://wiki.ros.org/rgbd_launch", "package": "rgbd_launch", "package_summary": ["Launch files to open an RGBD device and load all nodelets to \n     convert raw depth/RGB/IR streams to depth images, disparity images, \n     and (registered) point clouds."], "package_details": [" ", "\n", " contains all the common launch files required by a driver specific launch package such as ", " or ", ". There are 2 important launch files: ", "\n", " contains many internal launch files to split up processing. Only the following launch files should be used externally: ", "\n", "\n", "\n", "\n", "\n", " contains some example configurations that you can run and test running nodelets in the system: ", "This package contains launch files for using RGB-D devices such as the Microsoft Kinect in ROS. It creates a ", " graph to transform raw data from the device driver into point clouds, disparity images, and other products suitable for processing and visualization. "], "package_tt": ["rgbd_launch", "processing.launch.xml", "kinect_frames.launch", "rgbd_launch", "rgb_processing", "bool", "rgb/image_raw", "rgb/image_mono", "rgb/image_rect_mono", "rgb/image_color", "rgb/image_rect_color", "debayer_processing", "bool", "rgb_processing", "true", "rgb_processing", "false", "rgb/image_rect_color", "ir_processing", "bool", "true", "ir/image_raw", "ir/image_rect_raw", "depth_processing", "bool", "uint16", "float", "depth/image_raw", "depth/image_rect_raw", "depth/image", "depth/image_rect", "depth/points", "depth_registered_processing", "bool", "rgb_processing", "true", "false", "depth_processing", "true", "true", "disparity_processing", "bool", "depth/image_rect_raw", "projector/camera_info", "depth/disparity", "depth_processing", "sw_registered_processing", "bool", "depth/image_rect_raw", "depth_registered/sw_registered/image_rect_raw", "depth_registered/points", "depth_registered/disparity", "hw_registered_processing", "bool", "depth/image_raw", "depth_registered/hw_registered/image_rect_raw", "depth_registered/points", "depth_registered/disparity", "queue_size", "int", "rgb", "string", "rgb", "ir", "string", "ir", "depth", "string", "depth", "depth_registered", "string", "depth_registered", "projector", "string", "projector"], "package_code": ["roslaunch freenect_launch freenect-xyz.launch\n", "roslaunch freenect_launch freenect-registered-xyzrgb.launch"]},
{"url": "https://wiki.ros.org/tuw_multi_robot_rviz", "package": "tuw_multi_robot_rviz", "package_summary": ["Presents rviz plugins to set goal positions for the planner and a tool to visualize generated graphs."], "package_details": ["\n", " ", "Figure: goal selector. ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/octomap_mapping", "package": "octomap_mapping", "package_summary": ["Mapping tools to be used with the ", ", implementing a 3D occupancy grid mapping."], "package_details": ["\n", "\n", "\n", " ", "\n", "To compile this stack from source you need to ", " (trunk or a tagged release), add the source directory to your ROS_PACKAGE_PATH (e.g. in ", "), ", " that file and run  ", "For more documentation, see the documentation of the packages in this stack, in particular ", " and ", ", or the OctoMap library at ", ". ", "Files are available at ", ". ", "Use the alufr-ros-pkg ", " to report bugs or request features. For questions (and FAQ), check ", " or contact  ", ". "], "package_tt": ["~/.bashrc", "source"], "package_code": ["sudo apt-get install ros-fuerte-octomap", "sudo apt-get install ros-fuerte-octomap ros-fuerte-octomap-mapping", "rosdep install octomap_mapping\n", "rosmake octomap_mapping"]},
{"url": "https://wiki.ros.org/kvh_geo_fog_3d_msgs", "package": "kvh_geo_fog_3d_msgs", "package_summary": ["kvh_geo_fog_3d_msgs contains raw messages for the KVH GEO FOG 3D INS devices."], "package_details": [" "]},
{"url": "https://wiki.ros.org/move_basic", "package": "move_basic", "package_summary": ["Simple navigation package"], "package_details": ["\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " ", "This package provides the ", " ROS Node which provides a very basic navigation node. ", "\n", "The ", " node performs very basic navigation. Path planning consists of rotating in place to face the goal and then driving straight towards it. It is designed to provide the same software interfaces as ", ", that is, it implements a  ", " (see ", "), that takes in goals containing ", " messages.  ", "It is assumed that we are dealing with imperfect localization data: ", "->", " is accurate but may be delayed and is at a slow rate and ", "->", " is more frequent, but drifts, particularly after rotating. To counter these issues, ", " plans in the ", " frame, and waits a short time after each step, and executes movement in the ", " frame. If goals in the ", " frame are received, they are interpreted as relative to the robot's current position.  This behavior is different to that of ", ", which will not accept goals in the ", " frame.  ", "Some of the data produced by ", " can be visualized with ", ".  In the screen shot below, the portion of the laser scan data (in white) which is currently in the path of the robot is depicted as a red line.  The light purple line shows the path planned by the robot.   A navigation goal can be sent to ", " by ", " by pressing the ", " button and clicking on the map.   ", "To move forward one meter using ", " (note that ", " completion will provide an empty message that can be filled out): ", "This is an example of a relative goal, since the ", " is set to ", ". The position of the target pose is set to 1 meter in the forward direction, and the orientation is the identity quaternion. "], "package_tt": ["move_basic", "move_basic", "SimpleActionServer", "geometry_msgs/PoseStamped", "map", "base_link", "odom", "base_link", "move_basic", "map", "odom", "base_link", "move_base", "base_link", "move_basic", "move_basic", "rviz", "2D\u00a0nav\u00a0goal", "/move_base/goal", "move_basic", "/move_base/cancel", "/move_base_simple/goal", "move_basic", "/scan", "/sonars", "/tf", "tf", "map", "base_link", "tf", "odom", "base_link", "tf", "odom", "base_link", "laser", "tf", "base_link", "laser", "/move_base/feedback", "/move_base/status", "move_base", "/move_base/result", "move_base", "/cmd_vel", "/plan", "/obstacle_distance", "/obstacle_viz", "~min_angular_velocity", "double", "~max_angular_velocity", "double", "~angular_acceleration", "double", "min_angular_velocity", "max_angular_velocity", "~angular_tolerance", "double", "~min_linear_velocity", "double", "~max_linear_velocity", "double", "~linear_acceleration", "double", "min_linear_velocity", "max_linear_velocity", "~linear_tolerance", "double", "~localization_latency", "double", "~rotation_attempts", "int", "~obstacle_wait_limit", "double", "~reverse_without_turning_threshold", "double", "~map_frame", "string", "~robot_width", "double", "base_link", "~robot_front_length", "double", "base_link", "~robot_back_length", "double", "base_link", "frame_id", "base_link"], "package_code": ["sudo apt install ros-kinetic-move-basic", "rostopic pub /move_base_simple/goal geometry_msgs/PoseStamped \"header:\n", "  seq: 0\n", "  stamp:\n", "    secs: 0\n", "    nsecs: 0\n", "  frame_id: 'base_link'\n", "pose:\n", "  position:\n", "    x: 1.0\n", "    y: 0.0\n", "    z: 0.0\n", "  orientation:\n", "    x: 0.0\n", "    y: 0.0\n", "    z: 0.0\n", "    w: 1.0\" "]},
{"url": "https://wiki.ros.org/abb_irb120_support", "package": "abb_irb120_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 120 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 120 manipulators. This includes the base model (120) and\n      the 120T.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " (Version: ROB0149EN_D, May 2012).\n      All urdfs / xacros are based on the default motion and joint velocity\n      limits, unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Inertial and mass properties were calculated using 3D modelling software, based on the \n      supplied ", ".\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/laser_scan_publisher_tutorial", "package": "laser_scan_publisher_tutorial", "package_summary": ["The laser_scan_publisher_tutorial package"], "package_details": ["This package provides the code for the ", " tutorial for the navigation stack. "]},
{"url": "https://wiki.ros.org/arni_gui", "package": "arni_gui", "package_summary": ["Common functionality for the ARNI rqt_gui overview and detail plugins."]},
{"url": "https://wiki.ros.org/ainstein_radar_drivers", "package": "ainstein_radar_drivers", "package_summary": ["ROS drivers (interfaces) and nodes for Ainstein radars."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", " ", "To configure the radar type prior to testing, use the provided ", " script which depends on ", ". Using eg. ", " is also useful debugging tool to monitor CAN traffic on the SocketCAN interface. ", "These CAN radars require a ", " node publishing CAN frames to the ", " ROS topic (see the launch file below for an example).  This package can be installed with: ", "The file k79_node.cpp implements a ROS node using the ", " interface class to create a UDP socket bound to the host IP address and port (which must match the radar's configuration), launch a thread to read and publish data to the ", " message type. ", "The python script ", " can be used to configure the network parameters and flash new firmware. See the tutorials for more information. ", "The easiest way to get started with any particular radar is to use the corresponding ", ".  "], "package_tt": ["~targets/raw", "~frame_id", "string", "~host_ip", "string", "~host_port", "int", "~radar_ip", "string", "~radar_port", "int", "~targets/raw", "~frame_id", "string", "~host_ip", "string", "~host_port", "int", "~radar_ip", "string", "~radar_port", "int", "received_messages", "~targets/raw", "~targets/tracked", "~frame_id", "string", "~can_id", "int", "~min_range", "float", "~max_range", "float", "~min_angle", "float", "~max_angle", "float", "received_messages", "~targets/raw", "~targets/tracked", "~frame_id", "string", "~radar_type", "int", "~targets/raw", "~frame_id", "string", "~device_id", "string", "~firmware_version", "strind", "candump\u00a0can0", "/received_messages", "bash\u00a0sudo\u00a0apt\u00a0install\u00a0ros-kinetic-socketcan-bridge"]},
{"url": "https://wiki.ros.org/pioneer_bringup", "package": "pioneer_bringup", "package_summary": ["pioneer_bringup provides roslaunch scripts for starting the core functionnalities of Adept MobileRobots Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, AmigoBot, PeopleBot, PatrolBot, PowerBot, Seekur and Seekur Jr.)", "You may get this error message ", ". ", "In that case, simply install usb_cam package from source: "], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "\n", "\n", " is used to communicate with Pioneer robots hardware: ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "A ROS package providing roslaunch scripts for starting the Adept ", " Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, ", ", ", ", ", ", ", ", Seekur and Seekur Jr.) ", "Please refer to the ", " for more information. ", "All the bringup modes call first ", " package which is responsible to link ROS with the robot hardware. ", "Sometimes however, ", " need to communicate throught USB port, and then, you need to replace the followin line in the minimal.launch file: ", "For more information about this modification, please refer to ", ": "], "package_code": ["cd ~/catkin_ws/src\n", "git clone https://github.com/amor-ros-pkg/rosaria.git\n", "source ~/catkin_ws/devel/setup.bash\n", "rosdep install rosaria", "sudo apt-get install ros-indigo-lms1xx", "sudo apt-get install ros-jade-lms1xx", "sudo apt-get install ros-kinetic-lms1xx", "sudo apt-get install ros-indigo-usb-cam", "sudo apt-get install ros-jade-usb-cam", "sudo apt-get install ros-kinetic-usb-cam", "cd ~/catkin_ws/src\n", "git clone https://github.com/bosch-ros-pkg/usb_cam.git\n", "cd ..\n", "catkin_make", "cd ~/catkin_ws/src\n", "git clone https://github.com/amineHorseman/pioneer_bringup.git\n", "cd ..\n", "catkin_make", "roslaunch pioneer_bringup minimal.launch", "roslaunch pioneer_bringup camera.launch", "roslaunch pioneer_bringup laser_lms1xx.launch", "roslaunch pionner_bringup laser_lms1xx.launch _camera:=1", "<param name=\"port\" value=\"/dev/ttyS0\" />", "<param name=\"port\" value=\"/dev/ttyUSB0\" />", "cd ~/catkin_ws/src\n", "git clone https://github.com/bosch-ros-pkg/usb_cam.git\n", "cd ..\n", "catkin_make"]},
{"url": "https://wiki.ros.org/rospeex_core", "package": "rospeex_core", "package_summary": ["This package provides rospeex's core nodes."]},
{"url": "https://wiki.ros.org/maggie_serial_comm_drivers", "package": "maggie_serial_comm_drivers", "package_summary": ["serial_comm drivers for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/maggie_drivers", "package": "maggie_drivers", "package_summary": ["maggie_drivers metapackage"], "package_details": ["\n", "\n", "ROS packages for the devices of the robot ", ". "]},
{"url": "https://wiki.ros.org/qb_device_msgs", "package": "qb_device_msgs", "package_summary": ["This package contains the device-independent custom ROS messages for qbrobotics\u00ae devices."], "package_details": ["\n", "Each ", " device-independent custom ROS message is documented directly in its ", " specification and it is designed to fit most of the users needs. Indeed we recommend to use these messages as they are whenever it is possible. However we understand that your application may require few specific additional information. Since it is difficult to provide one-size-fit-all messages, integrate your specification in a new coherent custom message, and feel free to propose your changes with a Pull Request in our repository if you think that it could be helpful for someone else. "], "package_tt": [".msg"]},
{"url": "https://wiki.ros.org/moveit_tutorials", "package": "moveit_tutorials", "package_summary": ["The moveit_tutorials package"]},
{"url": "https://wiki.ros.org/network_interface", "package": "network_interface", "package_summary": ["Network interfaces and messages."], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/move_base", "package": "move_base", "package_summary": ["The move_base package provides an implementation of an action (see the ", " package) that, given a goal in the world, will attempt to reach it with a mobile base. The move_base node links together a global and local planner to accomplish its global navigation task. It supports any global planner adhering to the nav_core::BaseGlobalPlanner interface specified in the ", " package and any local planner adhering to the nav_core::BaseLocalPlanner interface specified in the ", " package. The move_base node also maintains two costmaps, one for the global planner, and one for a local planner (see the ", " package) that are used to accomplish navigation tasks."], "package_details": [" ", "\n", "\n", " ", "\n", " ", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", "\n", "This package provides the ", " ROS Node which is a major component of the ", ". A detailed description of this Node and its configuration options is found below. ", "The ", " node provides a ROS interface for configuring, running, and interacting with the ", " on a robot. A high-level view of the move_base node and its interaction with other components is shown above. The blue vary based on the robot platform, the gray are optional but are provided for all systems, and the white nodes are required but also provided for all systems. For more information on configuration of the ", " node, and the navigation stack as a whole, please see the ", " tutorial. ", "Running the ", " node on a robot that is properly configured (please see ", " for more details) results in a robot that will attempt to achieve a goal pose with its base to within a user-specified tolerance. In the absence of dynamic obstacles, the move_base node will eventually get within this tolerance of its goal or signal failure to the user. The ", " node may optionally perform recovery behaviors when the robot perceives itself as stuck. By default, the ", " node will take the following actions to attempt to clear out space: ", "First, obstacles outside of a user-specified region will be cleared from the robot's map. Next, if possible, the robot will perform an in-place rotation to clear out space. If this too fails, the robot will more aggressively clear its map, removing all obstacles outside of the rectangular region in which it can rotate in place. This will be followed by another in-place rotation. If all this fails, the robot will consider its goal infeasible and notify the user that it has aborted. These recovery behaviors can be configured using the ", " parameter, and disabled using the ", " parameter. ", "The ", " node provides an implementation of the ", " (see ", "), that takes in goals containing ", " messages. You can communicate with the ", " node over ROS directly, but the recommended way to send goals to ", " if you care about tracking their status is by using the ", ". Please see ", " for more information. ", "The ", " node contains components that have their own ROS APIs. These components may vary based on the values of the ", ", ", ", and ", " respectively. Links to the APIs for the default components can be found below: ", "Class Diagram (partially & not strictly drawn) is available ", ". "], "package_tt": ["move_base", "move_base", "move_base", "move_base", "move_base", "move_base", "move_base", "SimpleActionServer", "geometry_msgs/PoseStamped", "move_base", "move_base", "SimpleActionClient", "move_base/goal", "move_base", "move_base/cancel", "move_base/feedback", "move_base/status", "move_base", "move_base/result", "move_base", "move_base_simple/goal", "cmd_vel", "~make_plan", "move_base", "move_base", "~clear_unknown_space", "~clear_costmaps", "~base_global_planner", "string", "\"navfn/NavfnROS\"", "move_base", "nav_core::BaseGlobalPlanner", "\"NavfnROS\"", "~base_local_planner", "string", "\"base_local_planner/TrajectoryPlannerROS\"", "move_base", "nav_core::BaseLocalPlanner", "\"TrajectoryPlannerROS\"", "~recovery_behaviors", "list", "move_base", "move_base", "move_base", "move_base", "nav_core::RecoveryBehavior", "~/local_costmap/circumscribed_radius", "~controller_frequency", "double", "~planner_patience", "double", "~controller_patience", "double", "~conservative_reset_dist", "double", "move_base", "~recovery_behavior_enabled", "bool", "true", "move_base", "~clearing_rotation_allowed", "bool", "true", "recovery_behaviors", "~shutdown_costmaps", "bool", "false", "move_base", "~oscillation_timeout", "double", "~oscillation_distance", "double", "~oscillation_timeout", "~planner_frequency", "double", "~max_planning_retries", "int32_t", "move_base", "~base_global_planner", "~base_local_planner", "~recovery_behaviors", "nav_core::BaseGlobalPlanner", "nav_core::BaseLocalPlanner", "move_base", "move_base", "move_base", "move_base", "move_base"]},
{"url": "https://wiki.ros.org/kobuki_auto_docking", "package": "kobuki_auto_docking", "package_summary": ["Automatic docking for Kobuki:\n\t    Users owning a docking station for Kobuki can use this tool to let Kobuki find its nest autonomously."], "package_tt": ["~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~min_abs_v", "double", "~min_abs_w", "double"]},
{"url": "https://wiki.ros.org/abseil_cpp", "package": "abseil_cpp", "package_summary": ["The abseil_cpp package"]},
{"url": "https://wiki.ros.org/pepper_bringup", "package": "pepper_bringup", "package_summary": ["The pepper_bringup package"], "package_details": ["\n", "\n", "\n", " ", "\n", " ", "You can start Pepper either with a ", " or ", " version. The pepper_bringup package thus contains two launch files. ", "See the ", " and ", " for further details.  ", "\n"], "package_tt": ["This\u00a0is\u00a0only\u00a0available\u00a0in\u00a0the\u00a0C++\u00a0version"], "package_code": ["sudo apt-get install ros-indigo-pepper-robot ros-indigo-pepper-meshes", "roslaunch pepper_bringup pepper_full.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip> [network_interface:=<eth0|wlan0|vpn0>]", "roslaunch pepper_bringup pepper_full_py.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip>"]},
{"url": "https://wiki.ros.org/naoqi_dcm_driver", "package": "naoqi_dcm_driver", "package_summary": ["Package containing the hardware interface to connect to Nao, Romeo, or Pepper robots."], "package_details": ["\n", "\n", "* ", " ", "* ", " ", "* ", " "]},
{"url": "https://wiki.ros.org/vrpn", "package": "vrpn", "package_summary": ["The VRPN is a library and set of servers that interfaces with virtual-reality systems, such as VICON, OptiTrack, and others."]},
{"url": "https://wiki.ros.org/rospeex_if", "package": "rospeex_if", "package_summary": ["This package provides interface libraries on C++ and Python."]},
{"url": "https://wiki.ros.org/qb_device_hardware_interface", "package": "qb_device_hardware_interface", "package_summary": ["This package contains a device-independent hardware interface for qbrobotics\u00ae devices."], "package_details": ["\n", "This package is barely usable alone since it provides only the common features to be exploited and expanded in the derived packages (cf. ", " and ", "). "], "package_tt": ["/<namespace>/state", "/communication_handler/activate_motors", "success", "true", "/communication_handler/deactivate_motors", "success", "true", "/communication_handler/deregister_device", "/communication_handler/get_info", "message", "/communication_handler/get_measurements", "success", "true", "currents", "positions", "/communication_handler/register_device", "success", "true", "/communication_handler/set_commands", "commands", "~actuators", "string[]", "robot_description", "~device_id", "int", "1", "128", "~joints", "string[]", "robot_description", "~namespace", "string", "~robot_description", "string", "~transmission", "string", "transmission_interface::Transmission"]},
{"url": "https://wiki.ros.org/pdu_msgs", "package": "pdu_msgs", "package_summary": ["Control messages for the PDU"]},
{"url": "https://wiki.ros.org/qb_device", "package": "qb_device", "package_summary": ["This package contains a device-independent ROS interface for qbrobotics\u00ae devices."]},
{"url": "https://wiki.ros.org/pioneer_mrs", "package": "pioneer_mrs", "package_summary": ["The pioneer_mrs ROS package for Pioneer 3-AT Multi-Robot Systems"]},
{"url": "https://wiki.ros.org/rtt", "package": "rtt", "package_summary": ["Orocos/RTT component framework"]},
{"url": "https://wiki.ros.org/roswww", "package": "roswww", "package_summary": ["Feathery lightweight web server for ROS, that is based on ", " web server module."], "package_details": ["\n", "See ", " "]},
{"url": "https://wiki.ros.org/pr2_tilt_laser_interface", "package": "pr2_tilt_laser_interface", "package_summary": ["Provides a set of tools/actions for manipulating the pr2's tilting\n    laser. Simplifies previously complex tasks, such as fetching\n    a single sweep, given a set of desired parameters for both the laser\n    driver and tilting platform."]},
{"url": "https://wiki.ros.org/velo2cam_gazebo", "package": "velo2cam_gazebo", "package_summary": ["Metapackage allowing easy installation of velo2cam_gazebo components."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package includes Gazebo models, plugins and worlds of several sensors and calibration targets to help the process of designing and testing algorithms for extrinsic calibration of lidar-camera pairs. Package developed at ", ", Universidad Carlos III de Madrid. ", "Note: The models included in this repository were designed for evaluating the LIDAR-camera calibration algorithm described in [1], whose code is provided ", ". ", "Velodyne plugin providing ", " with same structure as driver (x, y, z, intensity, ring) and simulated Gaussian noise. (Code from ", ", although minor patch for vertical resolution issue is included) ", "[1] Guindel, C., Beltr\u00e1n, J., Mart\u00edn, D. and Garc\u00eda, F. (2017). Automatic Extrinsic Calibration for Lidar-Stereo Vehicle Sensor Setups. ", ". ", "Pre-print available ", " "], "package_code": ["roslaunch velo2cam_gazebo real_stereoVLP16_trans.launch"]},
{"url": "https://wiki.ros.org/rotors_control", "package": "rotors_control", "package_summary": ["RotorS control package"]},
{"url": "https://wiki.ros.org/asr_mild_base_fake_driving", "package": "asr_mild_base_fake_driving", "package_summary": ["The asr_mild_base_fake_driving package provides a simulation system for the robot driving. It simulates the desired driven way which is calculated by the navigation."], "package_details": [" ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "Look at ", " on how to start the simulated navigation with fake driving,. All simulation launch files use the fake driving. ", "cmd_vel ( ", ") ", "odom ( ", ") "], "package_code": ["roslaunch asr_mild_navigation simulation_manual_rearranged.launch", "rosrun asr_mild_base_fake_driving asr_mild_base_fake_driving"]},
{"url": "https://wiki.ros.org/tuw_voronoi_graph", "package": "tuw_voronoi_graph", "package_summary": ["Contains different nodes to generate routing graphs for the robot router. voronoi_graph_generator generates a voronoi graph out of a map. dxf_to_graph generates a graph out of a dxf file and segments_to_graph creates a graph using a config file with line segments as input."], "package_details": ["\n", " ", "\n", "\n", " (", ") ", "\n", " (", ") ", " (", ") ", "\n", " (", " default: \"0.1\" [m]) ", " (", " default: \"0.9\") ", " (", " default: \"0.2\") ", " (", " default: \"0.4\") ", " (", " default: \".\") ", " (", " default: \"\") ", " (", " default: \"false\") ", "\n", "\n", " ", " ", " ", " ", " ", "\n", "\n", "\n", " (", ") ", "\n", " (", " default: \"segments.yaml\") ", " (", " default: \"/segments\") ", " (", " default: \"0.9\") ", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package includes the ", ", which generates a voronoi graph out of a pixel map and the ", ", which generates a graph out of segments. ", "Receives a pixel map (occupancy_grid) and converts it into a ", " message spanning the whole free space of the map. Additionally the graph is saved to a given folder. If a map is already converted to a graph the graph is loaded from memory to save computation time. ", "This is a standard executable which takes a .dxf file as input and generates a graph which is saved to be loaded with the ", ". ", "Receives a pixel map (occupancy_grid) and converts it into a ", " message spanning the whole free space of the map. Additionally the graph is saved to a given folder. If a map is already converted to a graph the graph is loaded from memory to save computation time. "], "package_tt": ["tuw_voronoi_graph_node", "tuw_segment_to_graph_node", "tuw_multi_robot_msgs/Graph", "~map", "nav_msgs/OccupancyGrid", "~segments", "tuw_multi_robot_msgs/VoronoiGraph", "~map_eroded", "nav_msgs/OccupancyGrid", "~map_inflation", "double", "~segment_length", "float", "~crossing_opimization", "float", "~end_segment_optimization", "float", "~graph_path", "string", "~custom_graph_path", "string", "~publish_map_eroded", "bool", "tuw_voronoi_graph_node", "-h\u00a0[\u00a0--help\u00a0]", "-i\u00a0[\u00a0--input\u00a0]\u00a0arg\u00a0(=./segments.dxf)", "-o\u00a0[\u00a0--output\u00a0]\u00a0arg\u00a0(=./graphs/segments)", "-w\u00a0[\u00a0--width\u00a0]\u00a0arg\u00a0(=0.600000024)", "-l\u00a0[\u00a0--length\u00a0]\u00a0arg\u00a0(=1)", "tuw_multi_robot_msgs/Graph", "~segments", "tuw_multi_robot_msgs/VoronoiGraph", "~segment_file", "string", "~segments_topic", "string", "~segment_length", "float"], "package_code": ["start_x:      [      0,        2,   3.2,    5]\n", "start_y:      [   -1.5,     -1.5,    -2,   -4]\n", "end_x:        [      2,      3.2,     5,    3]\n", "end_y:        [   -1.5,       -2,    -4,   -4]\n", "space:        [    1.0,      1.0,   1.0,  1.0]\n", "origin_x:     -15\n", "origin_y:     -15\n", "resolution:   0.05"]},
{"url": "https://wiki.ros.org/mongodb_log", "package": "mongodb_log", "package_summary": ["The mongodb_log package"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "This package provides nodes that can record any and all data transmitted via ROS topics and stores them in the document-oriented database ", " replicating the message type as document structure. Afterwards, data can be used and queried independently of a particular robot software framework using the existing MongoDB query features with indexes, data locality (sharding) and ", ". This means you can also freely mix in data acquired from other sources, for example using ", ". ", "This project is joint work of the ", " at The Robotics Institute of the Carnegie Mellon University and the ", " at the RWTH Aachen University. For more details please visit the ", ". ", "The logger regularly creates graphs based an a round-robin database (RRD) using ", ". Additionally, the ", " script can be run to create graphs showing the performance of MongoDB. Example graphs look like the following. ", "The ", " package provides two functionalities. For one there is a node to store all messags of one specific topic to the database, for another it provides a library for other nodes to interact with the database. This mongodb_log package compares to the former part. ", "The ", " node of the ", " package stores incoming messages as serialized blobs, much like rosbag does. This way, queries can only be made based on the time of the message. More powerful queries and usage of the data is only possible of a specific node has been created or modified to record data in more verbose documents. ", "The upper graphs shows CPU and memory usage of rosbag, the generic mongodb_log python logger, and the specific C++ logger mongodb_log_tf, all recording the /tf topic at the same time, with transform messages containing 5 transforms at a rate of 100 Hz. We see that the MongoDB C++ logger and rosbag perform with about the same overhead. However, MongoDB is more efficient when writing, because rosbag writes the message type specification for each recorded message (note that MongoDB was writing two topics, one for the Python and the C++ logger each, while rosbag logged only one). The generic Python logger is much more demanding in terms of both, CPU and memory usage. The problem is the inherent Python overhead for deserializing message, which we had also analyzed when developing roslua (cf. ", "). Hence, logging many unknown topics can put a considerable burden on your logging machine. ", "The data acquired can be useful for a plethora of tasks. We have used it for fault analysis and performance evaluation, as described on the ", " and in the ", ". More information will be provided at a later point in time. ", "If you want to get in touch please contact ", ". Feel free to fork the ", " and let us know about your changes. Please report issues on the ", ". "], "package_tt": ["mongodb_rrd", "record_to_db"], "package_code": ["git clone https://github.com/timn/ros-mongodb_log.git mongodb_log\n", "cd mongodb_log\n", "make", "rosrun mongodb_log mongodb_log -a", "  MongoDB document                          rostopic echo /tf\n", "------------------------------------------------------------------------------\n", "{                                        |\n", "  \"_id\" : ObjectId(\"5011...\"),           |\n", "  \"__topic\" : \"/tf\",                     |\n", "  \"__recorded\" : ISODate(\"2012-07...\"),  |\n", "  \"transforms\" : [                       |  transforms:\n", "    {                                    |  -\n", "      \"header\" : {                       |    header:\n", "        \"stamp\" : ISODate(\"2012-07...\"), |    stamp:\n", "                                         |      secs: 1343297357\n", "                                         |      nsecs: 291\n", "        \"frame_id\" : \"/from\",            |      frame_id: /from\n", "        \"seq\" : 0                        |      seq: 0\n", "      },                                 |\n", "      \"transform\" : {                    |    transform:\n", "        \"translation\" : {                |      translation:\n", "        \"x\" : 1,                         |        x: 1.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0                          |        z: 0.0\n", "      },                                 |\n", "      \"rotation\" : {                     |      rotation:\n", "        \"x\" : 0,                         |        x: 0.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0,                         |        z: 0.0\n", "        \"w\" : 1                          |        w: 1.0\n", "      },                                 |\n", "      \"child_frame_id\" : \"/some_other\"   |    child_frame_id: /some_other\n", "    }                                    |\n", "  ]                                      |\n", "}                                        |"]},
{"url": "https://wiki.ros.org/hector_uav_msgs", "package": "hector_uav_msgs", "package_summary": ["hector_uav_msgs is a message package that contains messages for UAV controller inputs and outputs and some sensor readings not covered by sensor_msgs."]},
{"url": "https://wiki.ros.org/abb_experimental", "package": "abb_experimental", "package_summary": ["Experimental packages for ABB manipulators within ROS-Industrial."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It contains experimental packages that will be moved to the ", " package once they've received sufficient testing and review. ", "Packages in distribution branches (ie: ", ") may be expected to be compatible with the corresponding ROS distribution (ie: the ", " branch is usable on Indigo). In the absence of major differences between subsequent ROS releases, the ", " branch may be expected to be compatible with the next release as well (ie: ", " may be used on Jade, as long as no ", " branch exists). ", "Refer to the ", " for more information on building catkin workspaces. ", "See the ", " page for more information. "], "package_tt": ["$ROS_DISTRO-devel", "indigo-devel", "-devel", "indigo-devel", "jade-devel", "$ROS_DISTRO-devel", "apt-get", "kinetic-devel", "apt-get"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/arni_nodeinterface", "package": "arni_nodeinterface", "package_summary": ["The ARNI host manager, which collects host/node statistics and enables the ARNI countermeasure node to run remote commands."], "package_details": ["\n", "\n", "\n", "\n", "\n", " is used to gather the current temperature of the host, maybe. ", "It can be found ", ". ", " "]},
{"url": "https://wiki.ros.org/kuka_kr5_support", "package": "kuka_kr5_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR5 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 5 manipulators. This currently includes the KR 5 arc only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      found in the online datasheet ", ". All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    ", "\n      ", ": this package currently uses non-valid inertia parameters.\n    "]},
{"url": "https://wiki.ros.org/pr2_tuckarm", "package": "pr2_tuckarm", "package_summary": ["Tucks the arms of the PR2 robot into a safe position for moving the base of the robot.\n     This also moves the arms out of the view of the tilting laser scanner, as much as possible."], "package_details": ["\n", "\n", "\n", "\n", "As with all applications, you must first ", ". ", "The tuck arm application is a Python script, ", ": ", "The tuck arm application is a Python script, ", ": "], "package_tt": ["tuckarms.py", "tuck_arms.py"], "package_code": ["USAGE: tuck_arms.py [b | l | r] ", "rosrun pr2_tuckarm tuck_arms.py b", "USAGE: tuck_arms.py [-r <action>] [-l <action>]; <action> is '(t)uck' or '(u)ntuck'.", "rosrun pr2_tuckarm tuck_arms.py -r t -l t", "rosrun pr2_tuckarm tuck_arms.py --right untuck "]},
{"url": "https://wiki.ros.org/qb_device_bringup", "package": "qb_device_bringup", "package_summary": ["This package contains a device-independent bringup utilities for qbrobotics\u00ae devices."], "package_details": ["\n", "\n", " ", "\n", " ", "\n", " ", "\n", "\n", "This package is barely usable alone since it provides only templates to create more structured launch files in the derived packages (cf. ", " and ", "). ", "This launch file calls the other templates ", ", ", " and ", " to bringup a control node for a single device without starting ", ", ", " and ", ". ", "\n", "Since the only difference w.r.t. the ", " launch file is the includes of the ", " rather than the ", ", the parameters are exactly the same as the other a part from ", " which is not used. ", "This launch file calls the other templates ", ", ", " and ", " to bringup a complete control node for a single device. ", "\n", "It provides basically the same configuration parameters as the other launch files a part from ", " and ", " of the ", " which are not exported outside. "], "package_tt": ["use_rviz", "control_action", "string", "foo", "<namespace>_foo_trajectory_controller/follow_joint_trajectory", "control_duration", "double", "device_id", "int", "1", "128", "device_control", "string", "qb_device", "qb_device_control", "device_namespace", "string", "use_waypoints", "bool", "true", "~waypoints", "waypoint_namespace", "string", "my_device", "my_device_waypoints.yaml", "config/", "_control", "waypoint_settings", "string", "qb_device", "qb_device_control", "controllers", "string", "*_trajectory_controller", "controllers_namespace", "string", "my_device", "my_device_controllers.yaml", "config/", "_control", "controllers_settings", "string", "qb_device", "qb_device_control", "use_controller_gui", "bool", "device_description", "string", "qb_device", "qb_device_description", "device_namespace", "string", "my_device", "my_device_joint_...", "my_device_link_...", "device_urdf", "string", "qb_device", "qb_device.urdf.xacro.", "urdf/", "_description", "frequency", "int", "Hz", "source_list", "string", "use_rviz", "bool", "true", "device_urdf", "rviz/", "_description", "frequency", "source_list"]},
{"url": "https://wiki.ros.org/ainstein_radar_gazebo_plugins", "package": "ainstein_radar_gazebo_plugins", "package_summary": ["Radar sensor plugins for the Gazebo simulator."], "package_details": ["\n", "\n", " ", " ", "This package is intended to contain a collection of simulated radar sensor plugins for different Ainstein products. All radar plugins are based on the existing laser ", " with additional processing to convert laser range detections to radar targets and publish them as ", " messages. ", "While the ", " shared library (plugin) is intended to be generic enough to simulate any Ainstein radar, it currently only is valid for 1d radars (a vertical scan dimension could be added and used to fill the elevation angle data), does not support target speed (this might be able to be computed numerically from successive scans) and the SNR is filled from the returned ray intensity (this has not really been tested and may be a bad idea). ", "Once the package has been built (as normal in the catkin workspace), copy the folder(s) inside the ", " directory to somewhere on your ", ", eg. ", " which can be added to your model path (if it isn't already) by adding this to your ", ": ", "Also, make sure that ", " is on your ", " as this is where the shared library will be built. To do this, add the following to your ", ": ", "To test that the sensor is able to be loaded correctly in Gazebo (before adding it to another model), use the provided test.launch file to attempt to start Gazebo with the radar sensor. If you see an error about not finding the .so file, check your ", ". "], "package_tt": ["libgazebo_radar_sensor_plugin.so", "models/", "GAZEBO_MODEL_PATH", "~/.gazebo/models", ".bashrc", "export\u00a0GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:~/.gazebo/models", "~/catkin_ws/devel/lib/", "GAZEBO_PLUGIN_PATH", ".bashrc", "export\u00a0GAZEBO_PLUGIN_PATH=$GAZEBO_PLUGIN_PATH:~/catkin_ws/devel/lib", "GAZEBO_PLUGIN_PATH"]},
{"url": "https://wiki.ros.org/sicktoolbox_wrapper", "package": "sicktoolbox_wrapper", "package_summary": ["sicktoolbox_wrapper is a ROS wrapper for the outstanding ", "\n    library for interfacing with the SICK LMS2xx lasers."], "package_details": [" ", "\n", "\n", "\n", "\n"], "package_tt": ["sicktoolbox_wrapper", "sicktoolbox_wrapper", "sicktoolbox_wrapper", "sicktoolbox_wrapper", "sicklms", "lms_config", "scan", "~use_rep_117", "bool", "~port", "string", "/dev/lms200", "~baud", "int", "~inverted", "bool", "false", "~frame_id", "string", "laser", "~angle", "int", "~resolution", "double", "~connect_delay", "double", "sickld", "ld_config", "scan", "~port", "int", "49152", "~ipaddress", "string", "~inverted", "bool", "false", "~frame_id", "string", "laser", "~timer_smoothing_factor", "double", "~timer_error_threshold", "double", "~resolution", "double", "~start_angle", "double", "~stop_angle", "double", "~scan_rate", "double"]},
{"url": "https://wiki.ros.org/applanix_bridge", "package": "applanix_bridge", "package_summary": ["\n    Contains the adapter node which translates between the Applanix serialized socket\n    format and ROS messages. This node is implemented in Python for now, but could be\n    re-implemented using roscpp if performance is a bottleneck.\n  "]},
{"url": "https://wiki.ros.org/outlet_pose_estimation", "package": "outlet_pose_estimation", "package_summary": ["\n\n     outlet_pose_estimation\n\n  "]},
{"url": "https://wiki.ros.org/mpc_local_planner_msgs", "package": "mpc_local_planner_msgs", "package_summary": ["This package provides message types that are used by the package mpc_local_planner"]},
{"url": "https://wiki.ros.org/segbot_apps", "package": "segbot_apps", "package_summary": ["High-level applications that run on Segway RMP 50 based robots at Learning\n    Agents Research Group (LARG), AI Laboratory, Department of Computer\n    Science, The University of Texas at Austin."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/python_trep", "package": "python_trep", "package_summary": ["Trep: Mechanical Simulation and Optimal Control Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "Full documentation is available at ", ". ", "Trep can create a system model using certain tags from the ", ".  The following tags are supported: ", "The ROSMidpointVI class extends the MidpointVI class available in trep.  This class automatically publishes all frames imported from the URDF to the ", " topic every time ", " is called. ", "An example package called ", " is available at ", ".  This package has two demos which can be called from launch files. After cloning the package to your ROS workspace, run the following command: "], "package_tt": ["/tf", "ROSMidpointVI.step()", "trep_urdf_demo"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", " roslaunch trep_urdf_demo rrbot.launch", " roslaunch trep_urdf_demo puppet.launch"]},
{"url": "https://wiki.ros.org/actionlib", "package": "actionlib", "package_summary": ["The actionlib stack provides a standardized interface for\n    interfacing with preemptable tasks. Examples of this include moving\n    the base to a target location, performing a laser scan and returning\n    the resulting point cloud, detecting the handle of a door, etc."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n ", "To accomplish tasks using actions, we introduce the notion of a goal that can be sent to an ActionServer by an ActionClient. In the case of moving the base, the goal would be a PoseStamped message that contains information about where the robot should move to in the world.  For controlling the tilting laser scanner, the goal would contain the scan parameters (min angle, max angle, speed, etc). ", "\n ", "Feedback provides server implementers a way to tell an ActionClient about the incremental progress of a goal. For moving the base, this might be the robot's current pose along the path.  For controlling the tilting laser scanner, this might be the time left until the scan completes. ", "\n ", "A result is sent from the ActionServer to the ActionClient upon completion of the goal. This is different than feedback, since it is sent exactly once.  This is extremely useful when the purpose of the action is to provide some sort of information.  For move base, the result isn't very important, but it might contain the final pose of the robot.  For controlling the tilting laser scanner, the result might contain a point cloud generated from the requested scan. ", "\n", " ", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "  ", "\n ", "Suppose you have defined ", " in the ", " package. The following snippet shows how to send a goal to a DoDishes ActionServer called \"do_dishes\". ", " For the C++ ", ", the ", " method will only work if a separate thread is servicing the client's callback queue. This requires passing in ", " for the ", " option of the client's constructor, running with a multi-threaded spinner, or using your own thread to service ROS callback queues. ", "\n", "\n", "\n", "  ", "\n ", "Suppose you have defined ", " in the ", " package. The following snippet shows how to write a DoDishes ActionServer called \"do_dishes\". ", "\n", "  ", "\n ", "Suppose you have defined ", " in the ", " package. The following snippet shows how to write a DoDishes ActionServer called \"do_dishes\". ", "\n", "\n", "\n", "In any large ROS based system, there are cases when someone would like to send a request to a node to perform some task, and also receive a reply to the request. This can currently be achieved via ROS ", ". ", "In some cases, however, if the service takes a long time to execute, the user might want the ability to cancel the request during execution or get periodic feedback about how the request is progressing. The ", " package provides tools to create servers that execute long-running goals that can be preempted. It also provides a client interface in order to send requests to the server. ", "For a full discussion of how actionlib operates \"under the hood\", please see the  ", ". ", "The ", " and ", " communicate via a ", ", which is built on top of ROS messages.  The client and server then provide a simple API for users to request goals (on the client side) or to execute goals (on the server side) via function calls and callbacks. ", "In order for the client and server to communicate, we need to define a few messages on which they communicate.  This is with an ", ". This defines the Goal, Feedback, and Result messages with which clients and servers communicate: ", "The action specification is defined using a ", " file.  The ", " file has the goal definition, followed by the result definition, followed by the feedback definition, with each section separated by 3 hyphens (", "). ", "These files are placed in a package's ", " directory, and look extremely similar to a service's ", " file. An action specification for doing the dishes might look like the following: ", "Based on this ", " file, 6 messages need to be generated in order for the client and server to communicate. This generation can be automatically triggered during the make process: ", "Add the following to your CMakeLists.txt file ", " ", ". ", "Additionally, the ", " of the package that includes ", " files must include the following dependencies: ", "Package that depends on actionlib API to implement an action server or use an action client needs another dependency on ", ". ", "For the ", ", the following messages are generated by ", ": ", "These messages are then used internally by actionlib to communicate between the ActionClient and ActionServer. ", "Full API Reference for the ", " ", "Full API reference for the ", " ", "Suppose the ", " exists in the ", " package.  The following snippet shows how to send a goal to a DoDishes ActionServer called \"do_dishes\" using Python. ", "Full API Reference for the ", " ", "Full API Reference for the ", " ", "The ", " implements a single goal policy on top of the ", " class. The specification of the policy is as follows:  ", "Calling ", " accepts a new goal when one is available. The status of ", "this goal is set to active upon acceptance, and the status of any previously ", "active goal is set to preempted. Preempts received for the new goal between ", "checking if ", " or invocation of a goal callback and the ", " call will not trigger a preempt callback.  This means, ", " should be called after accepting the goal even for ", "callback-based implementations to make sure the new goal does not have a ", "pending preempt request. ", "Please refer to the ", " page ", "Please report any bugs on the ", " by detailing your environment (OS, ROS Distro) and a minimal example how how to replicate the issue. "], "package_tt": ["actionlib", ".action", ".action", "---", "./action", ".srv", "./action/DoDishes.action", ".action", "catkin_package()", "package.xml", ".action", "depend", "actionlib", "CMakeLists.txt", "package.xml", "DoDishes.action", "genaction.py", "DoDishesAction.msg", "DoDishesActionGoal.msg", "DoDishesActionResult.msg", "DoDishesActionFeedback.msg", "DoDishesGoal.msg", "DoDishesResult.msg", "DoDishesFeedback.msg", "DoDishes.action", "chores", "SimpleActionClient", "waitForServer", "true", "spin_thread", "DoDishes.action", "chores", "DoDishes.action", "chores", "DoDishes.action", "chores", "SimpleActionServer", "ActionServer", "acceptNewGoal", "isNewGoalAvailable", "acceptNewGoal", "isPreemptRequested"], "package_code": ["# Define the goal\n", "uint32 dishwasher_id  # Specify which dishwasher we want to use\n", "---\n", "# Define the result\n", "uint32 total_dishes_cleaned\n", "---\n", "# Define a feedback message\n", "float32 percent_complete", "find_package(catkin REQUIRED genmsg actionlib_msgs)\n", "add_action_files(DIRECTORY action FILES DoDishes.action)\n", "generate_messages(DEPENDENCIES actionlib_msgs)", "<build_depend>actionlib_msgs</build_depend>\n", "<exec_depend>actionlib_msgs</exec_depend>", "<depend>actionlib</depend>\n", "<depend>actionlib_msgs</depend>", "find_package(catkin REQUIRED genmsg actionlib_msgs actionlib)\n", "add_action_files(DIRECTORY action FILES DoDishes.action)\n", "generate_messages(DEPENDENCIES actionlib_msgs)", "<build_depend>actionlib</build_depend>\n", "<build_depend>actionlib_msgs</build_depend>\n", "<exec_depend>actionlib</exec_depend>\n", "<exec_depend>actionlib_msgs</exec_depend>", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/vapor_master", "package": "vapor_master", "package_summary": ["high availability ros master"], "package_details": ["\n", "\n", " ", " ", "\n", " ", "Vapor_master is a drop in replacement for ", " enabling high availability ROS service discovery. Vapor removes the single point of failure fundamental to ROS1 enabling new options for achieving greater scale, up-time and resiliency in ROS 1.x solutions. ", "Vapor implements the ", " as well as the ", " utilizing a modern micro services approach. Unlike rosmaster, which does only supports an in-memory datastore, vapor persists data to a mongodb database. This enables instances of vapor to come and go without the need to stop all other ROS nodes left running on other computers. ", "In assembly lines and mobile robots utilizing 3 or more computers, vapor_master can be deployed to all compute nodes. While mongodb can be deployed to a minimum of 3 nodes. In this scenario the ROS_MASTER_URI can be set to ", " as if each node were its own rosmaster. In this way an given compute node can come and go as needed without preventing ros parameter access or service discovery. "], "package_tt": ["http://localhost:11311"]},
{"url": "https://wiki.ros.org/uc3m_maps", "package": "uc3m_maps", "package_summary": ["uc3m_maps."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/seed_smartactuator_sdk", "package": "seed_smartactuator_sdk", "package_summary": ["The seed_smartactuator_sdk package"]},
{"url": "https://wiki.ros.org/utilrb", "package": "utilrb", "package_summary": ["\n    This library is a collection of useful Ruby classes\n  "]},
{"url": "https://wiki.ros.org/industrial_robot_status_controller", "package": "industrial_robot_status_controller", "package_summary": ["A ros_control controller that reports robot status using the ROS-Industrial RobotStatus message."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package provide a ", " compatible controller that publishes robot/controller state (e-stopped, in motion, etc) as ", " messages. ", "See the documentation in the repository: ", ". "], "package_tt": ["ros_control", "industrial_msgs/RobotStatus", "hardware_interface", "robot_status", "publish_rate", "float", "RobotStatus", "handle_name", "str", "IndustrialRobotStatusHandle", "hardware_interface"]},
{"url": "https://wiki.ros.org/arbotix_controllers", "package": "arbotix_controllers", "package_summary": ["Extends the arbotix_python package with a number of more sophisticated ROS wrappers for common devices."], "package_details": ["\n", "The arbotix_controllers package contains several controllers that add additional layers of ROS interface onto the basic structure of ", ". "]},
{"url": "https://wiki.ros.org/abb_irb1200_7_70_moveit_config", "package": "abb_irb1200_7_70_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 1200-7/0.7.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 1200-7/0.7 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/rbcar_pad", "package": "rbcar_pad", "package_summary": ["The rbcar_pad package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mir_navigation", "package": "mir_navigation", "package_summary": ["Launch and configuration files for move_base, localization etc. on the MiR robot."]},
{"url": "https://wiki.ros.org/ros_opcua_impl_python_opcua", "package": "ros_opcua_impl_python_opcua", "package_summary": ["The ros_opcua_impl_python_opcua package implement binding for python-opcua - Pure Python OPC-UA / IEC 62541 Client and Server library."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", " ", "This package provides communication interface between ROS and ", " communication standard using ", " library  written in Python. This package currently implements an OPC UA Server mapping all ROS Topics, Services and Actions under defined namespace in the OPC UA address space. ", "Check the ", " page. "], "package_tt": ["namespace", "String"], "package_code": ["roslaunch ros_opcua_impl_python_opcua rosopcua.launch"]},
{"url": "https://wiki.ros.org/area_division", "package": "area_division", "package_summary": ["A package that divides the available environment area among multiple cyber physical systems (CPSs) in a swarm."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", " ", "The communication between CPSs is based on the ", ". ", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["area_division", "id", "integer", "output", "string", "screen", "screen", "log", "param", "area_division.yaml", "area_division", "area_division", "state", "swarm_state", "pos_provider/pose", "area/map", "bridge/uuid", "bridge/events/area_division", "pos_controller/goal_position", "area_division", "area/assigned", "area/rotated", "visualize", "area/downsampled", "visualize", "area/get_rotation", "~loop_rate", "real", "~queue_size", "integer", "~resolution", "real", "~swarm_timeout", "real", "~visualize", "boolean", "~states", "string\u00a0list", "~/optimizer/iterations", "integer", "~/optimizer/variate_weight", "real", "~/optimizer/discrepancy", "integer"], "package_code": ["roslaunch area_division area_division.launch"]},
{"url": "https://wiki.ros.org/phantomx_reactor_arm_controller", "package": "phantomx_reactor_arm_controller", "package_summary": ["The phantomx_reactor_arm_controller package"]},
{"url": "https://wiki.ros.org/ros_ethercat_eml", "package": "ros_ethercat_eml", "package_summary": ["This is an implementation of the EtherCAT master protocol for use wiht ros_ethercar package based on the work done at Flanders' Mechatronics Technology Centre and Willow Garage."]},
{"url": "https://wiki.ros.org/qb_hand_hardware_interface", "package": "qb_hand_hardware_interface", "package_summary": ["This package contains the hardware interface for qbrobotics\u00ae qbhand device."], "package_details": ["\n", "\n", "This package is barely usable alone since it provides only the hardware interface for the ", " device. ", "This library inherits from the base device-independent ", " (therefore provides the same ROS API) and extends its features specifically for the ", ". In brief, it provides the specific transmission interface for the hand, which is the only thing that is really device dependent, and exploits the same hardware interfaces properly initialized (cf. ", ") and the same Communication Handler to talk to the physical device (cf. ", "). "]},
{"url": "https://wiki.ros.org/aruco_msgs", "package": "aruco_msgs", "package_summary": ["The aruco_msgs package"]},
{"url": "https://wiki.ros.org/rgbdslam", "package": "rgbdslam", "package_summary": ["\n    This package can be used to register the point clouds from RGBD sensors such as the kinect or stereo cameras.\n    The rgbdslam node can be connected easily to an octomap_server node to create a memory-efficient 3D map.\n  "], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This page describes the RGB-D SLAM system for ROS Fuerte. ", ", ", " for", ". See ", ". ", "For the electric version and many details that still hold true, see  ", ". ", "Download rgbdslam with the following command to your ", ". ", "If not yet installed, install ", " first, then execute ", "which will take a while. If you encounter problems, here is an example  ", " for a successful build for reference (Revision 3949). ", "As mentioned in ", ", if ROS dependencies are still not met for some reason, you might need to install the following dependencies ", "There are several example launch-files that set the parameters of RGB-D SLAM for certain use cases, a complete list of all options and their current settings can be found in the GUI: \"Settings\"->\"View Current Settings\". For a definitive list of all settings and the default values have a look at their quite readable definition in src/parameter_server.cpp. ", "If you want to use RGB-D SLAM with a Kinect or Xtion Pro, you should install ", ". If you want to edit the saved point clouds you might want to install meshlab. "], "package_tt": ["rgbdslam_v2"], "package_code": ["svn co http://alufr-ros-pkg.googlecode.com/svn/trunk/rgbdslam_freiburg", "rosdep update\n", "rosdep install rgbdslam_freiburg", "rosmake rgbdslam_freiburg", "sudo apt-get install libglew1.5-dev libdevil-dev libsuitesparse-dev", "  roslaunch rgbdslam kinect+rgbdslam.launch", "  roslaunch openni_launch openni.launch\n", "  rosrun rgbdslam rgbdslam", "        roslaunch rgbdslam headless.launch", "        rosservice call /rgbdslam/ros_ui frame # Capture single frames via\n", "        rosservice call /rgbdslam/ros_ui_b pause false # Capture a stream of data\n", "        rosservice call /rgbdslam/ros_ui send_all # Send point clouds with computed transformations (e.g., to rviz or octomap_server)\n", "        rosservice call /rgbdslam/ros_ui_s save_cloud /tmp/mycloud.pcd # Save the registered pointclouds in the given file\n", "        rosservice call /rgbdslam/ros_ui_s save_individual /tmp/filenameprefix # As above, but save every pointcloud in its own file", "# Better pick a mirror close to you.\n", "# See http://ros.org/wiki/ROS/Installation/UbuntuMirrors\n", "sudo sh -c '. /etc/lsb-release && echo \"deb http://packages.ros.org/ros/ubuntu $DISTRIB_CODENAME main\" > /etc/apt/sources.list.d/ros-latest.list'\n", "\n", "wget http://packages.ros.org/ros.key -O - | sudo apt-key add -\n", "\n", "sudo aptitude update\n", "\n", "# This will draw gigabytes from the network:\n", "sudo apt-get install ros-fuerte-perception-pcl ros-fuerte-vision-opencv ros-fuerte-octomap-mapping python-rosdep\n", "\n", "echo 'source /opt/ros/fuerte/setup.bash' >> ~/.bashrc\n", "\n", "echo 'export ROS_PACKAGE_PATH=~/ros:$ROS_PACKAGE_PATH' >> ~/.bashrc\n", "\n", ". ~/.bashrc\n", "\n", "svn co http://alufr-ros-pkg.googlecode.com/svn/trunk/rgbdslam_freiburg ~/ros/rgbdslam_freiburg\n", "\n", "sudo rosdep init\n", "\n", "rosdep update\n", "\n", "rosdep install rgbdslam_freiburg\n", "\n", "roscd rgbdslam\n", "\n", "# This will take a while:\n", "rosmake rgbdslam_freiburg", "sudo apt-get install ros-fuerte-openni-launch"]},
{"url": "https://wiki.ros.org/rosbag_storage", "package": "rosbag_storage", "package_summary": ["This is a set of tools for recording from and playing back ROS\n    message without relying on the ROS client library."]},
{"url": "https://wiki.ros.org/pr2_common_action_msgs", "package": "pr2_common_action_msgs", "package_summary": ["The pr2_common_action_msgs package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/log4cpp", "package": "log4cpp", "package_summary": ["Log4cpp maintained by Orocos developers\n    This version of log4cpp deviates from the official release\n    by adding custom category factories. Orocos requires this for\n    setting up real-time logging."]},
{"url": "https://wiki.ros.org/play_motion", "package": "play_motion", "package_summary": ["Plays a pre-recorded motion on a robot"]},
{"url": "https://wiki.ros.org/abb_irb2600_support", "package": "abb_irb2600_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 2600 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 2600 manipulators. This currently includes the IRB 2600-12/1.65\n      (20/1.65). Variants listed in parenthesis may use the files of the\n      preceding model.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " (Version: ROB0142EN_B, October\n      2010). All urdfs / xacros are based on the default motion and joint\n      velocity limits, unless noted otherwise (ie: no support for high speed\n      joints, extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/khi_robot_bringup", "package": "khi_robot_bringup", "package_summary": ["Package contains bringup scripts/config/tools for KHI Robot"]},
{"url": "https://wiki.ros.org/segbot_sensors", "package": "segbot_sensors", "package_summary": ["Contains sensor specific launch files and all the relevant filters that are\n    applied on sensor data before being used by the segbot."], "package_details": ["\n", "\n", "For UTexas BWI Segbot robots, an extension of the ", " package. Contains special-purpose the sensor and sensor filters launch files. ", "See the ", ". "]},
{"url": "https://wiki.ros.org/rovio_ctrl", "package": "rovio_ctrl", "package_summary": ["The rovio_ctrl package contains nodes to control and query the motor and head position of a WowWee Rovio."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains nodes to control the movement of the Rovio. This includes control the movement of the base itself, as well as controlling the head (camera) position. Furthermore, joystick teleoperation is provided via the ", " node. ", "To install the ", " stack, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file which should be edited with the hostname, username and password to login to your Rovio. This file launches an instance of the ", " and ", " nodes. To launch these nodes, the following command can be used: ", "The ", " package also contains a ", " file which should be edited with the hostname, username and password to login to your Rovio as well as absolute path to the ", " folder within the ", " package. This file launches an instance of the ", ", ", ", ", " and ", "  nodes. To launch these nodes, the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["rovio_ctrl", "rovio_teleop", "rovio_move", "man_drv", "cmd_vel", "geometry_msgs/Twist", "/rovio_shared/host", "/rovio_shared/user", "/rovio_shared/pass", "rovio_head", "head_sensor", "head_ctrl", "/rovio_shared/host", "/rovio_shared/user", "/rovio_shared/pass", "rovio_teleop", "joy", "cmd_vel", "rovio_move", "head_ctrl", "rovio_head", "wav_play", "rovio_audio", "0", "1", "2", "4", "5", "6", "7", "joy", "cmd_vel", "head_ctrl", "0", "1", "2", "wav_play", ".wav", "4", "5", "6", "7", "/rovio_shared/rovio_wav", "wav", "4", "5", "6", "7", "rovio", "rovio_ctrl", "rovio_ctrl.launch", "rovio_move", "rovio_head", "rovio_ctrl", "rovio_teleop.launch", "wav", "rovio_move", "rovio_head", "rovio_audio", "rovio_teleop"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-rovio", "roslaunch rovio_ctrl rovio_ctrl.launch", "roslaunch rovio_ctrl rovio_teleop.launch"]},
{"url": "https://wiki.ros.org/ros_opcua_communication", "package": "ros_opcua_communication", "package_summary": ["The ros_opcua_communication mate-package are ROS bidings for different open-source OPC-UA implementations. Currently following libraries are supported: FreeOpcUa and python-opcua."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack provides communication interface between ROS and ", " communication standard. Currently there are two open-source OPC UA implementations supported ", " (C++) and ", " (Python). ", "Clone your repository into ", "folder of your ROS workspace using: ", "Using ", " clone of the repository OPC UA libraries will be automatically downloaded. After that compile your workspace. "]},
{"url": "https://wiki.ros.org/khi_duaro_description", "package": "khi_duaro_description", "package_summary": ["The khi_duaro_description package"]},
{"url": "https://wiki.ros.org/motoman_robot_pkg_gen", "package": "motoman_robot_pkg_gen", "package_summary": ["The motoman_robot_pkg_gen package generates robot support packages that conform to the ROS-Industrial package specification.  http://wiki.ros.org/Industrial/Tutorials/SuggestedPackageLayoutNewRepositories"], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/segbot_description", "package": "segbot_description", "package_summary": ["Contains URDF descriptions of all robot components and sensors for the\n    segbot, as well as all the different sensor configurations for a segbot.", " ", "Contents", " ", "The segbot_description package contains all the robot and component descriptions. This includes descriptions for: ", "Since the BWI Segbot robot has configurable sensor types and locations, this package also includes all the top level configuration files that might be in use by the BWI project at this time. ", "For every robot configuration provided in the package, suitable URDF code for Gazebo is provided: ", "Full Gazebo Model (", ") - including this xacro file provides relatively accurate collision entries for each link. This is similar to how collisions are typically setup in ROS. ", "Simple Collision Model (", ") - including this xacro file provides null collision models to each joint except for base_link. base_link has a collision of a cylinder roughly the size of the robot. This model does not allow a conventional differential driver controller in Gazebo, but is much faster computationally and better for multi-robot experiments. See ", " on how this robot is controlled. ", "The layout of the package is as follows: ", " - Gazebo specific URDF descriptions. These are only read by the ROS wrapper for Gazebo ", " - Contains meshes for the Hokuyo URG 04LX and the Segway RMP 50\\ ", "The Segway RMP 50 mesh is based on the original mesh be user Jose Prado on Trimble 3D Warehouse. ", " to original model. ", " - Contains all various robot configurations. This folder contains all the top level URDF (Xacro) files that are processed outside this package. ", " - Contains a wrapper around xacro that produces the simple collision model instead of the full collision model. This is done as xacro itself does not accept parameters (see ", ") ", " - Contains a simple script to visualize individual sensor mounts or the sensor configuration on the robot. Mostly used to test that the designs are correct before being used externally. ", " - The main component of this package. Contains all the main URDF resources. ", " - Chassis Components ", " - Individual sensors. These have been replicated from ", " because of small incompatibilities ", " - Our hand designed sensor mounts. "]},
{"url": "https://wiki.ros.org/kinematics_exchanger", "package": "kinematics_exchanger", "package_summary": ["A package that exchanges kinematic properties such as velocity or position between multiple cyber physical systems (CPSs) in a swarm."], "package_details": ["\n", "\n", " (", ", default: 1) ", " (", ", default: ", ") ", "\n", "\n", "\n", "The communication between CPSs is based on the ", ". ", "The following packages of the ", " are required: ", "to launch the ", " node. ", "In the ", " subdirectory there is the parameter file ", " that allows to configure the behavior of the ", " node. ", "This work is supported by the European Commission through the ", " under grant no. 731946. "], "package_tt": ["kinematics_exchanger", "id", "integer", "output", "string", "screen", "screen", "log", "param", "kinematics_exchanger.yaml", "kinematics_exchanger", "kinematics_exchanger", "pos_provider/pose", "vel_provider/velocity", "bridge/events/position", "bridge/events/velocity", "position", "velocity", "swarm_position", "swarm_position_rel", "swarm_velocity_rel", "~loop_rate", "real", "~queue_size", "integer", "~timeout", "real", "~sample_size", "integer", "~init", "integer"], "package_code": ["roslaunch kinematics_exchanger kinematics_exchanger.launch"]},
{"url": "https://wiki.ros.org/nao_interaction_msgs", "package": "nao_interaction_msgs", "package_summary": ["Messages and services declarations for the nao_interaction metapackage"]},
{"url": "https://wiki.ros.org/asctec_hl_interface", "package": "asctec_hl_interface", "package_summary": ["\n\n     Interfaces to the \"HighLevel\" Processor of the Ascending Technologies helicopters where fast IMU datafusion with arbitrary external position input and position control is executed at 1 kHz. \n     Furthermore, all relevant data as IMU, GPS and status can be accessed at configurable rates and baudrates.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package provides a ros interface to communicate with the High Level Processor (HLP) of the AscTec AutoPilot. Therefore, firmware for the HLP is needed which is provided in the ", " package. It does not work with the firmware shipped with the HLP! ", "Using a wired connection is recommended, e.g. to the Ascending Technologies ", ". The cable supplied with the AtomBoard can be used. Connect to the serial port 0 of the Highlevel Processor (\"HL serial 0\") as shown in the AscTec ", " in chapter 4.1. In this case, set ", " to the correct port, and leave ", " and ", " empty.  ", "If you plan to use a wireless serial link, it might be useful to use a dedicated link for each rx and tx for higher bandwidth. In that case, set ", " and ", " accordingly and leave ", " empty.  ", "The baudrate at which the ", " communicates with the HLP can be set with the ", " parameter. If it doesn't match a supported standard baudrate, the closest standard baudrate is chosen. The HLP tries to detect the baudrate automatically at startup or if there wasn't any communication with the hl_node for longer than ~10 seconds. ", " sets up its serial port(s) with the desired baudrate and sends a packet ('a') which the HLP uses to detect the correct baudrate. In order for this to work, always switch on the HLP first, then start ", ". In case you need to restart ", " with a different baudrate, you have to wait ~10 s until the HLP accepts new baudrate configure packets. Restarting with the same baudrate works immediately. Tested baudrates are: 57600, 115200, 230400, 460800, 921600.  ", "Packet rates of certain packets can be configured with the ", " parameters. No polling is done - instead a configuration packet is sent to the HLP which will send the packets in the desired rate accordingly. Note that no checking is done if the packet rates exceed the available bandwidth, so check the correct rate with  ", "In all operation modes, you can enable/disable control output to the LLP by setting the ", " parameters accordingly. This is helpful, e.g. to debug a controller on a single axis first. Directions and orientations follow the ", ". As with the direct interface to the LLP, it only accepts commands when the serial enable switch is on. In failure, flip off this switch and put the flightmode switch to \"acc\". There are three modes you can operate the helicopter which you can select with the ", " parameter: ", "Set ", " to \"off\". This mode just forwards roll, pitch, yaw (angular velocity) and thrust commands to the LLP. This is similar to directly send commands to the LLP's serial interface. Set the values in ", " in rad for roll and pitch, in rad/s for yaw and 0.0 ... 1.0 for thrust and set ", "/type to \"acceleration\". For the scaling to work correctly, you need to set ", " and ", " to the values you can read out from the LLP with the AscTec control software (default 25, 120). Messages have to arrive at least at 10 Hz, otherwise nothing will be forwarded to the LLP. ", " yaw rates are limited to +- 85% so that the motors cannot be switched on/off accidentally in case of bad commands (motors idle, full yaw). ", "Set ", " to \"GPS\" and set ", "/type to \"velocity\" in your messages. Commands are also forwarded to the LLP, but the GPS bit is set additionally. The values in ", " correnspond to velocities in boady coordinates in m/s and rad/s respectively. For the scaling to work correctly, you need to set ", " according to the maximum \"stick-GPS\" velocites which you can read out from the LLP with the AscTec control software. Defaults are 5 m/s for x/y, and 2 m/s for z.      ", "Messages have to arrive at least at 10 Hz, otherwise nothing will be forwarded to the LLP. ", " yaw rates are limited to +- 85% so that the motors cannot be switched on/off accidentally in case of bad commands (full descend rate, full yaw) ", "This is the most interesting part and main motivation for this project. It is designed for position control based on position measurements from e.g. onboard visual SLAM with typically slow update rates. To deal with those delays, datafusion with IMU and position control is performed on the HLP at a rate of 1 kHz. Details on how the controller and datafusion work can be found in ", ". To work with this mode, please go carefully through this ", ". "], "package_tt": ["~serial_port", "~serial_port_rx", "~serial_port_tx", "~serial_port_rx", "~serial_port_tx", "~serial_port", "hl_node", "~baudrate", "hl_node", "hl_node", "hl_node", "~packet_rate_*", "~/enable_*", "~/position_control", "~/position_control", "~/k_stick", "~/k_stick_yaw", "~/position_control", "~/max_velocity_*", "fcu/control", "fcu/pose", "fcu/state", "fcu/ekf_state_in", "fcu/imu_custom", "fcu/imu", "fcu/gps", "fcu/rcdata", "fcu/status", "fcu/debug", "fcu/current_pose", "fcu/ekf_state_out", "fcu/motor_control", "~serial_port_rx", "string", "~serial_port_tx", "string", "~serial_port", "string", "~baudrate", "int", "~frame_id", "string", "~k_stick", "int", "~k_stick_yaw", "int", "~stddev_angular_velocity", "double", "~stddev_linear_acceleration", "double", "~packet_rate_imu", "double", "~packet_rate_rc", "double", "~packet_rate_gps", "double", "~packet_rate_ssdk_debug", "double", "~packet_rate_ekf_state", "double", "~enable_x", "bool", "~enable_y", "bool", "~enable_z", "bool", "~enable_yaw", "bool", "~position_control", "str", "~state_estimation", "str", "~max_velocity_xy", "double", "~max_velocity_z", "double", "~max_velocity_yaw", "double", "~min_pos_x", "double", "~min_pos_y", "double", "~min_pos_z", "double", "~max_pos_x", "double", "~max_pos_y", "double", "~max_pos_z", "double", "~ssdk/listen_on_tf", "bool", "~ssdk/tf_ref_frame_id", "str", "~ssdk/tf_tracked_frame_id", "str", "~ssdk/send", "bool", "~ssdk/omega_0_xy", "double", "~ssdk/omega_0_z", "double", "~ssdk/zeta_xy", "double", "~ssdk/zeta_z", "double", "~ssdk/p<channel>", "double", "world", "mav", "~ssdk/tf_ref_frame_id", "~ssdk/tf_tracked_frame_id", "fcu/waypoint/goal", "fcu/waypoint/result", "fcu/waypoint/feedback", "fcu/current_pose", "fcu/waypoint/goal", "fcu/waypoint/result", "fcu/waypoint/feedback"], "package_code": ["rostopic hz <topic> -w <expected rate>", "rosrun asctec_hl_interface plot_position_input [namespace]\n", "#e.g.\n", "rosrun asctec_hl_interface plot_position_input pelican"]},
{"url": "https://wiki.ros.org/kobuki_safety_controller", "package": "kobuki_safety_controller", "package_summary": ["A controller ensuring the safe operation of Kobuki.\n\n    The SafetyController keeps track of bumper, cliff and wheel drop events. In case of the first two,\n    Kobuki is commanded to move back. In the latter case, Kobuki is stopped.\n    \n    This controller can be enabled/disabled.\n    The safety states (bumper pressed etc.) can be reset. WARNING: Dangerous!"], "package_details": [" ", "\n", "\n", "This controller is usually used together with the minimal configuration of Kobuki or with apps on top, e.g. ", " and ", " navigation. ", "Use github to ", " or ", ". "]},
{"url": "https://wiki.ros.org/kobuki", "package": "kobuki", "package_summary": ["Software for Kobuki, Yujin Robot's mobile research base.", "\n", "Components of this stack: ", " : Automatic docking for Kobuki ", " : Publish bumpers and cliff sensors events as a pointcloud so navistack can use them ", " : Tutorial-related code ", " : URDF and Gazebo model description of Kobuki ", " : Keyboard teleoperation for Kobuki ", " : A ROS node wrapper for the kobuki driver ", " : Random walker demo controller for Kobuki ", " : Watches the bumper, cliff and wheel drop sensor to allow safe operation ", " : Set of tools to thoroughly test Kobuki's hardware ", "\n", "Check out the ", " section to find out about installing and running Kobukibot. ", "\n", "Use github to ", " or ", ". ", "Check ", " for more information! ", "\n", " "], "package_details": [" ", " "], "package_tt": ["/dev/kobuki"]},
{"url": "https://wiki.ros.org/maggie_motor_controller", "package": "maggie_motor_controller", "package_summary": ["motor_controller node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_code": [" $ roslaunch maggie_motor_controller arms_controller.launch robot:=maggie", " $ roslaunch maggie_motor_controller neck_controller.launch robot:=maggie"]},
{"url": "https://wiki.ros.org/screenrun", "package": "screenrun", "package_summary": ["\n      screenrun is a small tool that pushes commands into a screen window.\n      Use \\015 after a command for ENTER, i.e. executing it.\n  "], "package_details": ["\n", "\n", "If ", " is passed, byobu is used instead of screen. ", "A screen session named ", " is started and screen windows with the program  ", "name are created, where the commands are entered. ", "Usually the ", " parameter will come from a configuration or launch file. ", "See this example as a reference: "], "package_code": ["rosrun screenrun screenrun [b]", "-\n", "    name: planner\n", "    commands:\n", "        - roscd tidyup_grasp_actions\\015\n", "        - roslaunch tidyup_grasp_actions continual-planning-tidyup-grasp-tuck.launch \n", "-\n", "    name: dashboard\n", "    commands:\n", "        - rosrun pr2_dashboard pr2_dashboard\\015"]},
{"url": "https://wiki.ros.org/pr2_plugs", "package": "pr2_plugs", "package_summary": ["The pr2_plugs stack provides the low level actions for autonomously plugging the PR2 into a standard wall outlet."], "package_details": ["\n", " ", " ", " ", "\n", "  ", "You need to install the 'pr2 plugs' stack of ROS (see ", "). On Ubuntu, this means: ", "Follow the ", " tutorial. "], "package_code": [" $ sudo apt-get install ros-fuerte-pr2-plugs", "plugs_calibration_offset:\n", "  y: 0.0\n", "  z: 0.0", " $ rosparam load /etc/ros/plugs/hw_calibration.yaml", " $ roslaunch pr2_plugs_actions  pr2_base_application.launch\n", " $ roslaunch pr2_plugs_actions  plug_actions.launch run_sim:=0", "  $ rosrun pr2_plugs_actions  app_plugin.py", "  $ rosrun pr2_plugs_actions  app_unplug.py"]},
{"url": "https://wiki.ros.org/qb_device_control", "package": "qb_device_control", "package_summary": ["This package contains a device-independent control library for qbrobotics\u00ae devices."], "package_details": ["\n", " ", "\n", "\n", "\n", "This package is barely usable alone since it provides only the common features to be exploited and expanded in the derived packages (cf. ", " and ", "). "], "package_tt": ["controllers", "string", "*_trajectory_controller", "namespace", "string", "my_device", "my_device_controllers.yaml", "config/", "_control", "package_prefix", "string", "qb_device", "qb_device_control", "use_controller_gui", "bool", "~<namespaced_action_type>_trajectory_controller/follow_joint_trajectory", "/communication_handler/sync_nodes", "success", "true", "~namespaced_action_type", "string", "device_foo", "device_foo_trajectory_controller/follow_joint_trajectory", "~control_duration", "double", "~waypoints", "list\u00a0of\u00a0maps", "time", "joint_positions", "joint_positions"]},
{"url": "https://wiki.ros.org/kuka_eki_hw_interface", "package": "kuka_eki_hw_interface", "package_summary": ["A ROS-Control hardware interface for use with KUKA EKI"], "package_details": ["\n", "\n", "\n", "This package is part of the ", " program. ", "See the ", " page. ", "This package has been tested with KR C4 controllers. See ", " for more information on how to configure it and setup the robot controller. "]},
{"url": "https://wiki.ros.org/rqt_bag_exporter", "package": "rqt_bag_exporter", "package_summary": ["Export data (images, numerics) from a bag file to create CSV and video files"], "package_details": ["Documentation is here: ", " "]},
{"url": "https://wiki.ros.org/pr2_power_board", "package": "pr2_power_board", "package_summary": ["This provides a ROS node for the PR2 Power Board."], "package_details": ["\n", " controls with the PR2 power board.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data. ", "\n", "\n", "\n", "The ", " runs on the PR2 and controls the PR2 power board. The node regulates the main fan speed of the PR2 based on battery and power board temperature.  "], "package_tt": ["power_node2", "power_node2", "battery/server2", "/diagnostics", "~state", "~control2", "~control", "~sample_frequency", "float", "~transition_frequency", "float", "/diagnostics", "~state", "~control"]},
{"url": "https://wiki.ros.org/rr_control_input_manager", "package": "rr_control_input_manager", "package_summary": ["Filter velocity commands by ensuring that message time stamps do not exceed given timeout thresholds."], "package_details": ["\n", " ", "\n", "\n", " "], "package_tt": ["/cmd_vel/joy", "/cmd_vel/autodock", "/cmd_vel/move_base", "/joystick", "/cmd_vel/joystick", "/a_button", "/b_button", "/x_button", "/y_button", "/joystick/delay", "~max_vel_fwd", "float", "2.6", "~max_vel_turn", "float", "9.0", "~max_vel_flipper", "float", "1.4", "~default_drive_throttle", "integer", "0.15", "~default_flipper_throttle", "integer", "0.6", "~adjustable_throttle", "bool", "true"]},
{"url": "https://wiki.ros.org/robot_setup_tf_tutorial", "package": "robot_setup_tf_tutorial", "package_summary": ["The robot_setup_tf_tutorial package"], "package_details": ["This package provides code for the ", " tutorial for the navigation stack. "]},
{"url": "https://wiki.ros.org/kobuki_capabilities", "package": "kobuki_capabilities", "package_summary": ["Kobuki's capabilities"]},
{"url": "https://wiki.ros.org/checkerboard_pose_estimation", "package": "checkerboard_pose_estimation", "package_summary": ["\n\n     checkerboard_pose_estimation\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/motoman_sia10d_support", "package": "motoman_sia10d_support", "package_summary": [" This package will be removed in ROS Kinetic. The configuration data and\n      models included in this package can now be found in the motoman_sia_support\n      package in ROS Jade.", "ROS-Industrial support for the Motoman SIA10D (and variants).", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman SIA10D manipulators.\n    ", "\n      ", "\n    ", "\n      Joint limits and maximum joint velocities are based on the information \n      found in the online \n      http://www.motoman.com/datasheets/sia10d.pdf\n      All urdfs are based on the default motion and joint velocity limits, \n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/khi_rs_description", "package": "khi_rs_description", "package_summary": ["The khi_rs_description package"]},
{"url": "https://wiki.ros.org/sick_ldmrs_laser", "package": "sick_ldmrs_laser", "package_summary": ["A ROS driver for the SICK LD-MRS series of laser scanners."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "All documentation is on ", ". "]},
{"url": "https://wiki.ros.org/markov_decision_making", "package": "markov_decision_making", "package_summary": ["Markov Decision Making (MDM) is a ROS library for robot decision-making based on MDPs.\n                This metapackage contains: the Markov Decision Making Library itself (mdm_library), \n                the auxiliary packages Predicate Manager (predicate_manager) and Topological Tools (topological_tools),\n                and an example application of MDM (mdm_example)"], "package_details": ["\n", "\n", "\n", " ", "MDM helps you map between the abstract representations of ", ", ", " and ", " that are used in decision-theoretic frameworks, and the actual actuators and sensors of your robots. It also interprets your decision-making policies and lets you configure an appropriate run-time execution strategy. Note that ", ". For that you can use ROS-independent toolboxes such as ", ". But once you have a decision-theoretic policy, MDM helps you execute that policy on your robot. ", "MDM has been used (and is being used) in several international research projects, including ", "; ", "; and ", ". ", "In the following sections, you can find a light technical description of MDM, and information on how to use the library for your own MDP-based applications. For a more in-depth look into MDM, you can also refer to ", ". ", "For an overview of the concepts underlying MDM, please see the page ", ". ", "You can find examples of how to implement each MDM layer in the ", ". ", "MDM is modular and meant to be flexible and easy to adapt to your own applications. You can find more information on various specialized use-cases of MDM in the page: ", " ", "Q: ", "\n ", "A: There are so many generalizations and variants of the MDP framework that it is virtually impossible to design a library that supports all of them out-of-the-box. Rather than trying to explicitly support all MDP variants, MDM gives you the building blocks that you can use (and adapt) to put together a decision-theoretic controller for your robot(s). The underlying motivation is much of the implementation work that goes into deploying a decision-theoretic control policy can be re-used across different robot applications, regardless of the particular MDP variant that you're using. However, if you adapt MDM to your own application, you're encouraged to contribute to the library with your own modifications, since that may help other users in the future. Feel free to contact us, in that case! ", "Q: ", "\n ", "A: Without going into a discussion as to why regular discretizations aren't a particularly good idea, note that as long as your state space is discrete and finite, then your states can be indexed by a fixed-length string of logical values (i.e. in binary). In other words, as long as you have enough predicates, you can represent any (finite) discrete state space. The ", " package is lightweight and designed to handle a very large number of predicates, if needed. If you really want a \"grid world\"-like representation of your state space, you can either write a generic ", " predicate and instantiate it for each your cells, or use the pose_labeler package (included in topological_tools) together with a map of the environment in which each cell is uniquely colored. ", "Q: ", "\n ", "A: Although the default MDM State and Action Layers implicitly describe discrete state and action spaces, you can potentially use the same node layout, and implement a State Layer that outputs real-valued scalars or vectors; a Control Layer that maps that into a real-valued action, and an Action Layer that just maps those into actuator controls. We don't have any plans at this time to extend MDM by ourselves to continuously-valued domains, but if you're interested in doing so, please feel free to contact us. ", "Q: ", "\n ", "A: Yes, there is a (currently experimental) branch in the Git repository that already supports some of the most basic RL algorithms for MDPs (Q-learning, SARSA). "]},
{"url": "https://wiki.ros.org/kobuki_random_walker", "package": "kobuki_random_walker", "package_summary": ["Random walker app for Kobuki"], "package_details": [" ", "\n", "\n"], "package_code": ["  $ roslaunch kobuki_node minimal.launch", " $ roslaunch kobuki_random_walker random_walker_app.launch\n", " # or the safe version (using the kobuki_safety_controller)\n", " $ roslaunch kobuki_random_walker safe_random_walker_app.launch"]},
{"url": "https://wiki.ros.org/navigation_tutorials", "package": "navigation_tutorials", "package_summary": ["Navigation related tutorials."], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/maggie_labjack", "package": "maggie_labjack", "package_summary": ["labjack node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["get_touch_sensors", "get_voltage", "is_plugged", "get_state", "set_state"], "package_code": [" $ roslaunch maggie_labjack labjack.launch robot:=maggie"]},
{"url": "https://wiki.ros.org/rbcar_description", "package": "rbcar_description", "package_summary": ["The rbcar_description package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/aruco_ros", "package": "aruco_ros", "package_summary": ["The ARUCO Library has been developed by the Ava group of the Univeristy of Cordoba(Spain).\n    It provides real-time marker based 3D pose estimation using AR markers."]},
{"url": "https://wiki.ros.org/khi_rs007l_moveit_config", "package": "khi_rs007l_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the khi_rs007l with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/maggie_navigation_config", "package": "maggie_navigation_config", "package_summary": ["navigation config files for Social Robot Maggie."], "package_details": ["\n", "\n", "\n", "This package holds a number of common configuration files for the ", " and ", " nodes meant to be run in an application that requires global navigation with a pre-specified static map. It also contains navigation specific sensor configurations. In particular, it holds parameter settings for the ", ", ", ", and ", " components of the ", " node that are shared between many different configurations of the ", " stack run on the ", ". "], "package_tt": ["launch/real/navigation_real.launch", "launch/simulation/navigation_simulation.launch", "launch/amcl.launch", "launch/move_base.launch", "launch/laser/hokuyo.launch", "launch/laser/sick.launch", "config/base_local_planner_params.yaml", "config/costmap_common_params.yaml", "config/global_costmap_params.yaml", "move_base.launch", "config/initial_pose.yaml", "config/local_costmap_params.yaml", "move_base.launch"]},
{"url": "https://wiki.ros.org/pdu", "package": "pdu", "package_summary": ["Interface for the New Eagle Multiplex Power Distribution Module (MPDM)\n    https://store.neweagle.net/product/multiplexed-power-distribution-module-mpdm/"]},
{"url": "https://wiki.ros.org/qb_move_description", "package": "qb_move_description", "package_summary": ["This package contains the ROS description for qbrobotics\u00ae qbmove device."], "package_details": ["\n", "\n", "This package contains the description resources for the ", " device. It includes the ", "/", " model of the cube with its simplified meshes and its configuration setup. ", "This launch file calls the template ", " with the default settings to visualize a ", " in ", " (and nothing more). "], "package_code": ["roslaunch qb_move_description qb_move.launch"]},
{"url": "https://wiki.ros.org/arni_rqt_detail_plugin", "package": "arni_rqt_detail_plugin", "package_summary": ["The ARNI rqt_gui detail plugin."]},
{"url": "https://wiki.ros.org/pr2_plugs_actions", "package": "pr2_plugs_actions", "package_summary": ["\n\n     pr2_plugs_actions contains actions specific to plugging in the PR2 robot.\n\n  "], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/qb_move_control", "package": "qb_move_control", "package_summary": ["This package contains the ROS control node for qbrobotics\u00ae qbmove device."], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the ROS control node and its structures to control the ", " device. It exploits the features provided by the base device-independent control library (cf. ", ") and the specific hardware interface (cf. ", "). ", "The two launch files start a ROS node for the ", " respectively to control it through a GUI and through predefined configurable waypoints (stored in the ", "). In both cases the controllers setup can be found in the ", "; it is recommended not to change the default settings though. ", "This launch file calls the template ", " with the default settings to bringup a full control node for the ", " based on GUI inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf. ", " to control several devices together). ", "This launch file calls the template ", " with the default settings to bringup a full control node for the ", " based on waypoint inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf. ", " to control several devices together). ", "This control library specifically designed for the ", " extends the ", " and exploits the ", ", therefore it provides all the ROS resources and requires all the specifications of this two base packages. "], "package_tt": ["config/qbmove_waypoints.yaml", "config/qbmove_controllers.yaml"]},
{"url": "https://wiki.ros.org/mir_msgs", "package": "mir_msgs", "package_summary": ["Message definitions for the MiR100 robot"]},
{"url": "https://wiki.ros.org/argos3d_p100", "package": "argos3d_p100", "package_summary": ["The argos3D P100 ROS package"], "package_details": ["\n", "\n", ". ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "There is a new package (", ") that uses the new ", " developed by Bluetechnix for interacting with their sensors. ", "To get more information about the Time of Flight camera Argos3D P100 please visit Bluetechnix website: ", " ", "The ", "' works with ROS versions groovy and hydro.  You can use catkin workspaces or the previous rosbuild to configure, compile and get ready ROS. ", "ROS tutorial: ", " ", "Be sure your libboost library version is >= 1.49. Previous versions as 1.46 generate errors while compiling argos3d_p100-ros-pkg. ", "In Ubuntu/linux copy the file from the driver folder to ", " ", "Clone from repository: ", " to your src/ folder in your catkin workspace and compile it with: "], "package_code": ["argos3d_p100_ros_pkg", "cd driver \n", "sudo cp 10-pmd-ubuntu.rules /etc/udev/rules.d/", "#PMD camera support\n", "/.../PMDSDK/bin\n", "/.../PMDSDK/include", "ldconfig", "apt-get install ros-hydro-pcl-ros ros-hydro-pcl-conversions ros-hydro-perception-pcl", "cd catkin_ws\n", "source devel/setup.bash ## initialize search path to include local workspace\n", "cd src/\n", "git clone https://github.com/voxel-dot-at/argos3d_p100_ros_pkg.git\n", "cd ..\n", "catkin_make", "roscore &", "cd catkin_ws\n", "source devel/setup.bash\n", "rosrun argos3d_p100 argos3d_p100_node", " Using help for argos3d_p100_ros_pkg\n", " You can set default configuration values for the camera with the following options:\n", "\n", " Usage:\n", " rosrun argos3d_p100 argos3d_p100_node\n", "        -it *Integration_Time*\n", "          Integration time(in msec) for the sensor\n", "          (min: 100 | max: 2700 | default: 1500)\n", "        -mf  *Modulation_Frequency*\n", "          Set the modulation frequency(Hz) of the sensor\n", "          (min: 5000000 | max: 30000000 | default: 30000000)\n", "         -fr *Frame_Rate* \n", "          Set the frame rate of the camera by setting the Phase Time (Please be careful when setting values higher than 40 FPS without using an extra cooling system. The camera can stress by overheating and be damaged). \n", "          (min: 1 | max: 160 | default: 40)\n", "         -flip_x *flip_x* \n", "          Flip images in the x coordinate. \n", "          (ON: if set | OFF: default)\n", "         -flip_y *flip_y* \n", "          Flip images in the y coordinate. \n", "          (ON: if set | OFF: default)\n", "        -bf *Bilateral_Filter*\n", "          Turns bilateral filtering on or off\n", "          (ON: if set | OFF: default)\n", "        -af *Amplitude_Filter_On*\n", "          Whether to apply amplitude filter or not. Image pixels with amplitude values less than the threshold will be filtered out\n", "          (ON: if set | OFF: odefault)\n", "        -at *Amplitude_Threshold*\n", "          What should be the amplitude filter threshold. Image pixels with lesser aplitude values will be filtered out. Amplitude Filter Status should be true to use this filter\n", "          (min: 0 | max: 2500 | default: 0)\n", "\n", " Example:", "cp argos3d.cal catkin_ws\n", "cd catkin_ws\n", "rosrun argos3d_p100 argos3d_p100_node ", "rosrun rviz rviz", "rosrun rqt_reconfigure rqt_reconfigure"]},
{"url": "https://wiki.ros.org/pr2_power_drivers", "package": "pr2_power_drivers", "package_summary": ["Power drivers for the PR2 robot."], "package_details": ["\n", " contains the drivers that control the PR2 power system.  You should look at ", " for reading the power state of the robot. ", "\n", "Report new issues on ", " "], "package_tt": ["pr2_power_drivers"]},
{"url": "https://wiki.ros.org/ainstein_radar_filters", "package": "ainstein_radar_filters", "package_summary": ["Filtering and data conversion utilities for radar data."], "package_details": ["\n", "\n", "\n", "\n", "\n"], "package_tt": ["~radar_in", "~cloud_out", "~radar_in", "~scan_out", "~angle_min", "float", "~angle_max", "float", "~angle_increment", "float", "~time_increment", "float", "~scan_time", "float", "~range_min", "float", "~range_max", "float", "~radar_in", "radar_vel", "~radar_out", "~min_speed_thresh", "float", "~max_speed_thresh", "float", "~compute_3d", "bool", "~is_rotated", "bool", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0data>", "map", "~radar_in", "~radar_out", "~min_range", "float", "~max_range", "float", "~radar_in", "~nearest_target", "~nearest_target_array", "~data_lpf_alpha", "float", "~data_lpf_timeout", "float", "~radar_in", "~tracked", "~boxes", "~filter_update_rate", "int", "~filter_min_time", "float", "~filter_timeout", "float", "~filter_val_gate_thresh", "string\u00a0map"]},
{"url": "https://wiki.ros.org/maggie_description", "package": "maggie_description", "package_summary": ["maggie_description urdf files"], "package_details": ["This package will contain the description of the ", " robot. "]},
{"url": "https://wiki.ros.org/agvs_complete", "package": "agvs_complete", "package_summary": ["The agvs package. This package contains all the components to simulate the AGVS robot. An ackermann type robot intended for logistics transport."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ar_tools", "package": "ar_tools", "package_summary": ["CCNY Computer Vision Stack"], "package_details": ["\n", "\n", " ", "\n", "Please use this ", " to report bugs or request new features. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/abb_irb52_support", "package": "abb_irb52_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 52 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 52 manipulators. This currently includes the 7/1.2 and\n      7/1.45 variants.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/asctec_mav_framework", "package": "asctec_mav_framework", "package_summary": ["Framework for data aquisition and position control to be used with the highlevel processor of Ascending Technologies helicopters ", "The following commands will fetch and compile the ", " stack. Version 2012 depends on ", ". Please refer to ", " for installation instructions. ", "If rosmake fails it means that you have downloaded a catkin package. In this case follow the instructions for hydro or indigo. "], "package_details": ["\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "This stack contains drivers, tools, a nonlinear position controller and imu data fusion for ", " MAVs equipped with the AutoPilot sensor board. In contrast to ", " which communicate directly to the low level processor of the AutoPilot board (which has some ", "), this framework is based on the user-programmable high level processor of the AutoPilot board. Features are: ", "Update to be compatible with the 2012 HL SDK and LL Firmware. Currently available in the \"version2012\" branch (see installation instructions). ", ", it will not work with the older versions. ", "The state prediction part of a full EKF runs now on the HLP, which works together with ", ". Not only the obvious states as attitude, position and velocity are estimated, but also IMU biases, (visual) scale of the position measurement (e.g. from ", ") and pose/position-sensor (e.g. camera) to imu calibration. Also, a yaw measurement is not necessary anymore since this can be estimated by the EKF. More detailed information can be found here: "], "package_tt": ["catkin_workspace/src", "asctec_mav_framework", "~max_velocity_xy", "~max_velocity_z"], "package_code": ["# Fetch asctec_mav_framework stack\n", "git clone git://github.com/ethz-asl/asctec_mav_framework.git asctec_mav_framework\n", "\n", "# only if you need to use the 2011 version:\n", "git checkout -b version2011 refs/tags/version2011\n", "\n", "# Update ROS_PACKAGE_PATH (if necessary)\n", "export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/asctec_mav_framework\n", "\n", "# build\n", "rosmake asctec_mav_framework"]},
{"url": "https://wiki.ros.org/psen_scan", "package": "psen_scan", "package_summary": ["The psen_scan package for Pilz laser scanner"], "package_details": ["\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", "For a list of supported devices please refer to our ", ". ", "For getting started quickly please see the ", ". ", "We created a set of ", " that walk you through integrating the Pilz safety laser scanner PSENscan into your existing application, or creating a completely new one. For example you can learn how to store your configurations permanently and how to start multiple scanners simultaneously. ", "You need further information? Our international hotline staff will support you individually about our ROS packages at ", " or visit us at ", ". "]},
{"url": "https://wiki.ros.org/pr2_gazebo", "package": "pr2_gazebo", "package_summary": ["Launch scripts for simulating the PR2 in ", ".\n    The simulation equivalent of pr2.launch is found here.\n    pr2_fingertip_pressure_contact_translator produces the same ROS topics as fingertip_pressure package for simulated PR2."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Spawn a simulated PR2, assuming that an instance of Gazebo is already up.  This launch file is normally not used directly, but rather included in another launch file, as in ", ". ", "This file is meant to mirror the behavior ", ", which is used to bringup a physical PR2, including default controllers. ", "The launch files in ", " are included by the higher-level launch files documented above.  The controller launch files themselves should be modified only be advanced users. ", "The programs in ", " are for developer testing only. ", "Please see the ", " guide for tips on how to debug issues with ", ". "], "package_tt": ["pr2_empty_world.launch", "/pr2.launch", "pr2_gazebo/controllers", "pr2_gazebo/scripts", "pr2_gazebo"]},
{"url": "https://wiki.ros.org/rcll_refbox_peer", "package": "rcll_refbox_peer", "package_summary": ["RCLL refbox communication adapter"], "package_details": ["\n", "\n", "\n", "This package contains nodes providing a ROS-based interface to interact with the ", " of the ", " which is also used in the ", ". ", "Please refer to the ", " package for the interface message types. "], "package_tt": ["rcll/beacon", "rcll/game_state", "rcll/machine_info", "rcll/exploration_info", "rcll/machine_report_info", "rcll/order_info", "rcll/ring_info", "rcll/send_beacon", "rcll/send_machine_report", "rcll/send_prepare_machine", "~team_name", "string", "~robot_name", "string", "~robot_number", "int", "~crypto_key", "string", "~crypto_cipher", "string", "~peer_address", "string", "~peer_public_recv_port\u00a0and\u00a0~peer_public_send_port", "int", "~peer_cyan_recv_port\u00a0and\u00a0~peer_cyan_send_port", "int", "~peer_magenta_recv_port\u00a0and\u00a0~peer_magenta_send_port", "int"]},
{"url": "https://wiki.ros.org/pepper_dcm_bringup", "package": "pepper_dcm_bringup", "package_summary": ["Bring-up the dcm driver to control Pepper"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "To choose the controllers you want to load, modify pepper_control/launch/pepper_control_trajectory.launch. The list of implemented controllers, you can find in pepper_control/config/pepper_trajectory_control.yaml. You can start and stop the ros-controllers using the rqt plugin ", ". "], "package_code": ["sudo apt-get install ros-indigo-pepper-robot ros-indigo-pepper-meshes", "catkin_make", "roslaunch pepper_dcm_bringup pepper_bringup.launch robot_ip:=<ROBOT_IP>", "roslaunch naoqi_driver naoqi_driver.launch nao_ip:=<ROBOT_IP>", "roslaunch pepper_moveit_config moveit_planner.launch", "rosrun actionlib axclient.py <name of the goal topic of the action server>", "rosrun actionlib axclient.py /pepper_dcm/LeftArm_controller/follow_joint_trajectory/goal", "roslaunch pepper_dcm_bringup pepper_dcm_bringup_position.launch robot_ip:=<ROBOT_IP>", "rostopic pub /pepper_dcm/HeadYaw_position_controller/command std_msgs/Float64 \"data: 1\""]},
{"url": "https://wiki.ros.org/rospeex_webaudiomonitor", "package": "rospeex_webaudiomonitor", "package_summary": ["This package provides a browser-based waveform monitor of rospeex's (beta version).\n    This package requires an external web browser: Google Chrome or Firefox."]},
{"url": "https://wiki.ros.org/pepper_gazebo_plugin", "package": "pepper_gazebo_plugin", "package_summary": ["Gazebo plugin for Pepper robot"], "package_details": ["\n", "All documentation is written in the github page ", ". "]},
{"url": "https://wiki.ros.org/motoman_sia5d_support", "package": "motoman_sia5d_support", "package_summary": [" This package will be removed in ROS Kinetic. The configuration data and\n      models included in this package can now be found in the motoman_sia_support\n      package in ROS Jade.", "ROS-Industrial support for the Motoman SIA5D (and variants).", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman SIA5D manipulators.\n    ", "\n      ", "\n    ", "\n      Joint limits and maximum joint velocities are based on the information \n      found in the online \n      http://www.motoman.com/datasheets/sia5d.pdf\n      All urdfs are based on the default motion and joint velocity limits, \n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/maggie_rfid_drivers", "package": "maggie_rfid_drivers", "package_summary": ["rfid drivers for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/microstrain_3dmgx2_imu", "package": "microstrain_3dmgx2_imu", "package_summary": ["A driver for IMUs compatible the microstrain 3DM-GX2 and 3DM-GX3 protocol. Includes \n    a heavily modified standalone driver pulled from the player distribution, \n    and a ROS node."], "package_details": [" ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "While a ", " exists, it has not been reviewed and should be considered unstable. ", "The 3DM-GX2 protocol can be found ", ". "], "package_tt": ["imu_node", "imu/data", "diagnostics", "imu/is_calibrated", "~self_test", "imu/calibrate", "imu/is_calibrated", "imu/is_calibrated", "imu/calibrate", "~port", "string", "~frame_id", "string", "~autocalibrate", "bool", "false", "~orientation_stdev", "double", "~angular_velocity_stdev", "double", "~linear_acceleration_stdev", "double", "~max_drift_rate", "double", "~assume_calibrated", "bool"]},
{"url": "https://wiki.ros.org/power_monitor", "package": "power_monitor", "package_summary": ["The power_monitor collects messages from the ocean_battery_server and\n     the pr2_power_board, and publishes a summary of their data in a\n     friendlier message format."], "package_details": ["\n", "\n", " takes data from ", " and ", " and republishes it in a more user-friendly message format. ", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 0.1) ", "The estimation method that ", " uses is reconfigurable via ", ". Two methods are currently available: "], "package_tt": ["power_monitor", "power_monitor", "/var/ros/power_monitor/power.log", "battery/server2", "power_board/power_state", "power_state", "~frequency", "float", "power_state", "~estimation_method", "string", "~advanced_log_file", "string", "~battery_update_timeout", "double"]},
{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]},
{"url": "https://wiki.ros.org/pr2_controller_configuration", "package": "pr2_controller_configuration", "package_summary": ["Configuration files for PR2 controllers."], "package_details": ["This package contains YAML files that are used to configure the default controllers and the calibration controllers on the pr2. The package also contains a ", " file that configures, loads and starts the default controllers via ", ". The default controllers are: ", "These files are used in places such as ", " to instantiate the default PR2 controllers. ", "For ", ", a clone of this package with separate configuration is in ", ". "]},
{"url": "https://wiki.ros.org/khi_duaro_moveit_config", "package": "khi_duaro_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the khi_duaro with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/agvs_gazebo", "package": "agvs_gazebo", "package_summary": ["The agvs_gazebo package. Launch files and worlds to run Gazebo."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/abb_irb120t_moveit_config", "package": "abb_irb120t_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 120T.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 120T with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/abb_irb1600_support", "package": "abb_irb1600_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 1600 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 1600 manipulators. This package includes the 6kg 1.2m\n      version.  Package based on ABB Document ID: 3HAC023604-001, Rev M.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the ABB data sheets.  All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/nmea_comms", "package": "nmea_comms", "package_summary": ["The nmea_comms package provides helper nodes for transmitting and receiving\n    the NMEA sentences."], "package_details": ["\n", "\n", "\n", "\n", "This package provides nodes which enable bidirectional communication between socket (server) or serial devices and the ", " message type. This may be useful for a number of scenarios, including if you: ", "Finally, the combination of a ", " connected directly to a ", " can create a tee, where a device's serial data is directly available to ROS, but also served over a socket such that a remote machine may listen to it via netcat. This is particularly valuable if your device has a proprietary Windows-only GUI, which you'd like to be able to use while the device is part of a running ROS system. An example of this usage is ", ", which you can launch like so: ", "Once running, you should see the output of your serial NMEA device on the ", " topic, as well as when running ", ". "], "package_tt": ["serial_node", "socket_node", "/navsat/nmea_sentence", "nc\u00a0localhost\u00a029500", "nmea_sentence_out", "nmea_sentence", "~frame_id", "string", "~port", "string", "~baud", "int", "nmea_sentence_out", "nmea_sentence", "~frame_id", "string", "~port", "int"], "package_code": ["roslaunch nmea_comms tee.launch port:=<serial port> baud:=<baud rate>"]},
{"url": "https://wiki.ros.org/purepursuit_planner", "package": "purepursuit_planner", "package_summary": ["The purepursuit_planner package. Planner to follow a list of waypoints implementing the Pure Pursuit algorithm."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mrt_cmake_modules", "package": "mrt_cmake_modules", "package_summary": ["CMake Functions and Modules for automating CMake"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", " ", "Imagine you whould never have to write a ", "  file again. Never forget to install everything, no need to update it  whenever you add a file, not time lost for figuring out how to call and  use find_package for your dependencies, etc. ", "For more information, please refer to the documentation ", " "]},
{"url": "https://wiki.ros.org/artoolkit", "package": "artoolkit", "package_summary": ["\n\t     Artoolkit Library\n\t"], "package_details": ["\n", "\n", " ", "This is ", " packaged for a local ROS installation. This package is primarily to make it easier to install ", ". More information about ", " can be found at their home page. ", "In Ubuntu 11.04 and 11.10, you may encounter errors related to ", ". A possible workaround is to patch the header files manually with: "], "package_code": ["$ roscd artoolkit\n", "$ sed -i 's,#include <linux/videodev.h>,#include <libv4l1-videodev.h>,g' ./build/artoolkit/include/AR/sys/videoLinuxV4L.h\n", "$ sed -i 's,#include <linux/videodev.h>,#include <libv4l1-videodev.h>,g' ./build/artoolkit/lib/SRC/VideoLinuxV4L/video.c"]},
{"url": "https://wiki.ros.org/arni_countermeasure", "package": "arni_countermeasure", "package_summary": ["The ARNI countermeasure node."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The arni_countermeasure package provides the possibillity to define specific reactions when a ros environement is not behaving as defined with ", ". ", "Constraints are definitions of how ", " need to behave for a certain amount of time to trigger ", ". ", "They can be set as parameters withing the namespace /arni/countermeasure/constraints. ", "A statement has to start with only one entry. Multiple statements can be combined with ", " and ", ". ", "Its possible to negate a statement with ", ". ", "Where expected_value can be ", ", ", ", ", ", ", " ", "Additionally a ", " can be set. Only reactions with an autonomy_level <= config/reaction_autonomy_level get executed. "], "package_code": ["seuid: { statistic_type: expected_value, another_s_type: another_value }", "arni:\n", "  countermeasure:\n", "    constraints:\n", "      unique_constraint_name:\n", "        constraint:\n", "        - or:\n", "            some_seuid: {\n", "              cpu_usage_mean: high,\n", "              node_bandwith_mean: low\n", "              }\n", "            another_seuid: {\n", "              ram_usage_mean: high}\n", "        min_reaction_interval: 5\n", "        reaction_timeout: 20\n", "        reactions:\n", "          reaction_name: {\n", "            action: stop,\n", "            autonomy_level: 100,\n", "            node: node1}\n", "          another_reaction_name: {\n", "            action: publish,\n", "            autonomy_level: 13,\n", "            message: node1 has a problem,\n", "            node: node1,\n", "            loglevel: info}\n", "      another_constraint:\n", "        constraint:\n", "        - and:\n", "            some_seuid: {\n", "              node_bandwith_mean: unknown\n", "            }\n", "            another_seuid: {\n", "              node_bandwith_max: ok \n", "            }\n", "            not:\n", "              third_seuid: {\n", "                cpu_usage_mean: high \n", "              }\n", "    config:\n", "      reaction_autonomy_level: 50\n", "      storage_timeout: 10"]},
{"url": "https://wiki.ros.org/kinesis_manager", "package": "kinesis_manager", "package_summary": ["AWS Kinesis stream management library intended for use with the Kinesis Video Producer SDK"], "package_details": ["\n", "\n", "\n", "The kinesis_manager package is a library for interacting with Amazon Kinesis Video Streams. It is used by the ", " package. ", "The source code is released under an ", ". "], "package_tt": ["kinesis_video_streamer"]},
{"url": "https://wiki.ros.org/kuka_kr150_support", "package": "kuka_kr150_support", "package_summary": ["\n      ROS-Industrial support for the KUKA KR 150 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for KUKA KR 150 manipulators. This currently includes the -2 variant\n      only.\n    ", ":", "\n      Joint limits and maximum joint velocities are based on the information\n      found in ", ", version ", ".\n      All urdfs are based on the default motion and joint velocity limits,\n      unless noted otherwise.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/segway_rmp", "package": "segway_rmp", "package_summary": ["segway_rmp"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "There are several variations of Segway RMP's available, but only a few have been tested, if you would like to test one of the platforms or if you need a platform/feature that is not currently supported, ", ". ", "* ", " ", "You could use ", " to install this stack (and potentially others at the same time) that way.  Here is an example ", " file: ", "Once you have the stack in your ROS setup, you can build the ", " stack, by running: ", "There is an older version of this ROS stack that was based on the drivers from ", ".  If you would like to use those packages instead you can checkout their tag in git: ", "The ROS nodes that interface with the RMP200 ATV and RMP400 used to be based on the ", " and ", " drivers from ", ". ", "I would appreciate anyone reporting bugs or requesting features by emailing me at ", ". "], "package_code": ["git clone git://github.com/wjwwood/segway-rmp-ros-pkg.git", "- git:\n", "    uri: 'git://github.com/wjwwood/segway-rmp-ros-pkg.git'\n", "    local-name: segway-rmp-ros-pkg", "rosinstall ~/path/to/install/into ~/path/to/segway-rmp-ros-pkg.rosinstall", "\n", "\n", "roscd segway_rmp\n", "git checkout iri_version"]},
{"url": "https://wiki.ros.org/arni_msgs", "package": "arni_msgs", "package_summary": ["ARNI message types, i.e. host, node and rated statistics."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This page describes the message and service types used by arni. This information might be out of date, for recent data look here: ", " ", "Contains an array of ", " for a node, host , or connection. ", "Represents a single entry of the master API"], "package_code": ["# ip of the host  \n", "string host\n", "\n", "# the statistics apply to this time window\n", "time window_start\n", "time window_stop\n", "\n", "# cpu  \n", "float32 cpu_temp_mean\n", "float32 cpu_temp_stddev\n", "float32 cpu_temp_max\n", "\n", "float32 cpu_usage_mean\n", "float32 cpu_usage_stddev\n", "float32 cpu_usage_max\n", "\n", "float32[] cpu_usage_core_mean\n", "float32[] cpu_usage_core_stddev\n", "float32[] cpu_usage_core_max\n", "\n", "float32[] cpu_temp_core  \n", "float32[] cpu_temp_core_mean\n", "float32[] cpu_temp_core_stddev\n", "float32[] cpu_temp_core_max\n", "\n", "\n", "# gpu\n", "float32[] gpu_temp_mean\n", "float32[] gpu_temp_stddev\n", "float32[] gpu_temp_max\n", "\n", "float32[] gpu_usage_mean\n", "float32[] gpu_usage_stddev\n", "float32[] gpu_usage_max\n", " \n", "\n", "# ram  \n", "float32 ram_usage_mean\n", "float32 ram_usage_stddev\n", "float32 ram_usage_max\n", "  \n", "# network\n", "\n", "string[] interface_name \n", "int32[] message_frequency_mean\n", "int32[] message_frequency_stddev\n", "int32[] message_frequency_max\n", "\n", "# bandwith of each network interface\n", "\n", "float32[] bandwidth_mean\n", "float32[] bandwidth_stddev\n", "float32[] bandwidth_max ", "#ip of the host this node belongs to\n", "string host\n", "\n", "#identifier of this node\n", "string node\n", "\n", "# the statistics apply to this time window\n", "time window_start\n", "time window_stop\n", "\n", "#CPU\n", "\n", "float32 node_cpu_usage_mean\n", "float32 node_cpu_usage_stddev\n", "float32 node_cpu_usage_max\n", "\n", "float32[] node_cpu_usage_core_mean\n", "float32[] node_cpu_usage_core_stddev\n", "float32[] node_cpu_usage_core_max\n", "\n", "\n", "#GPU \n", "\n", "float32[] node_gpu_usage_mean\n", "float32[] node_gpu_usage_stddev\n", "float32[] node_gpu_usage_max\n", "\n", "# ram  \n", "float32 node_ramusage_mean\n", "float32 node_ramusage_stddev\n", "float32 node_ramusage_max\n", "  \n", "# network load of the node\n", " \n", "float32 node_message_frequency_mean\n", "float32 node_message_frequency_stddev\n", "float32 node_message_frequency_max\n", "\n", "float32 node_bandwidth_mean\n", "float32 node_bandwidth_stddev\n", "float32 node_bandwidth_max\n", "\n", "# Drive I/O statistics of the node \n", "\n", "float32 node_write_mean\n", "float32 node_write_stddev\n", "float32 node_write_max\n", "\n", "float32 node_read_mean\n", "float32 node_read_stddev\n", "float32 node_read_max ", "# type of statistic like cpu_usage_core or cpu_usage\n", "string statistic_type\n", "\n", "# the value of the type\n", "string[] actual_value\n", "\n", "# the expected value like \"40 - 70\"\n", "string[] expected_value\n", "\n", "# constant\n", "uint8 HIGH=0\n", "uint8 LOW=1\n", "uint8 UNKNOWN=2\n", "uint8 OK=3\n", "\n", "# state of the metadata from the node/host/connection : \n", "# state: { 0 = high ; 1 = low ; 2 = unknown; 3 = ok}  \n", "uint8[] state ", "# name of node/host/connection \n", "string seuid\n", "\n", "# only used if seuid is a node. is the host ip the node runs on.\n", "string host  \n", "\n", "# the rated statistics apply to statistics from this time window\n", "time window_start\n", "time window_stop\n", "\n", "# an array of rated entities\n", "RatedStatisticsEntity[] rated_statistics_entity ", "string name\n", "string[] content", "# publisher\n", "MasterApiEntity[] pubs\n", "# subscriber\n", "MasterApiEntity[] subs\n", "# services\n", "MasterApiEntity[] srvs ", "# identifier of the affected node\n", "string node\n", "\n", "# action  [restart, stop, command]\n", "string action\n", "\n", "# command (for action command)\n", "string command\n", "---\n", "# message returned upon completion\n", "string returnmessage", "# get all statistics where timestamp in ms is > than timestamp\n", "time timestamp\n", "---\n", "# each statistic has its own rated statistic. \n", "# timestamps can be found at the time windows of each statistic\n", "\n", "HostStatistics[] host_statistics\n", "RatedStatistics[] rated_host_statistics\n", "\n", "NodeStatistics[] node_statistics\n", "RatedStatistics[] rated_node_statistics\n", "\n", "rosgraph_msgs/TopicStatistics[] topic_statistics\n", "RatedStatistics[] rated_topic_statistics"]},
{"url": "https://wiki.ros.org/abb_irb1200_5_90_moveit_config", "package": "abb_irb1200_5_90_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 1200-5/0.9.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 1200-5/0.9 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/ros_monitoring_msgs", "package": "ros_monitoring_msgs", "package_summary": ["Messages for publishing monitoring data about ROS systems"]},
{"url": "https://wiki.ros.org/rosruby", "package": "rosruby", "package_summary": ["This package is a Ruby client library for ROS, the Robot Operating System."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Please refer to the ", " package and read the ", " page. ", "For a more detailed reference, please consult the ", ". "], "package_code": ["sudo apt-get install ros-hydro-rosruby ros-hydro-rosruby-common ros-hydro-rosruby-messages", "source ~/.bashrc", "source /opt/ros/hydro/setup.bash"]},
{"url": "https://wiki.ros.org/point_cloud_publisher_tutorial", "package": "point_cloud_publisher_tutorial", "package_summary": ["The point_cloud_publisher_tutorial package"], "package_details": ["This package provides code for the ", " tutorial for the navigation stack. "]},
{"url": "https://wiki.ros.org/livox_ros_driver", "package": "livox_ros_driver", "package_summary": ["The ROS device driver for Livox 3D LiDARs and Livox Hub"], "package_details": ["\n", " format: ", "\n", "\n", "\n", "Email: ", " ", "ROS packages for Livox 3D LiDARs. This driver provides the measurement data as ", " or Livox defined cloudpoint data. "], "package_tt": ["<dev@livoxtech.com>"], "package_code": ["Header header             # ROS standard message header\n", "uint64 timebase           # The time of first point\n", "uint32 point_num          # Total number of pointclouds\n", "uint8  lidar_id           # Lidar device id number\n", "uint8[3]  rsvd            # Reserved use\n", "CustomPoint[] points      # Pointcloud data", "uint32 offset_time      # offset time relative to the base time\n", "float32 x               # X axis, unit:m\n", "float32 y               # Y axis, unit:m\n", "float32 z               # Z axis, unit:m\n", "uint8 reflectivity      # reflectivity, 0~255\n", "uint8 line              # laser number in lidar"]},
{"url": "https://wiki.ros.org/arni_processing", "package": "arni_processing", "package_summary": ["The ARNI processing node, which rates statistics against their specifications."], "package_details": ["\n", "\n", "\n", "\n", ": If a measured value returns an array (for example bandwidth_max for multiple network adapters) you can give an array of such limits. If you receive more values than you defined limits, spare values will be rated as ", ". If you don't give an array of limits, the given limit will be used for each value. ", "\n", "\n", "\n", "\n", "\n", "The monitoring node retrieves data on the topics ", ", ", " and ", ". It then rates them according to specifications stored in the parameter namespace ", ". The resulting data are published on the topic ", ". ", "For parameters shared across the arni packages see ", ". ", "The processing node rates the incoming statistics based on given specifications. They are read from the namespace ", ". There you might give your desired specifications for a given seuid according to this format: ", "You can pack these specifications as list items in one single list, which will then overwrite the whole list when you load several lists or add one more namespace block with the list like ", ". The latter method allows you to selectively unset specification blocks. ", "Learn more about the ", ". ", "Note that the measurement fields can be basically every field in the respective ", ". See theses for comments on units. ", "Additionally the field ", " determines when the specified item is regarded as \"dead\" (see above). ", " that this field expects a single number unlike the other fields! ", "Usually the limits for a measurement are given as list with minimum and maximum value. If a third parameter is set as \"relative\", the limits will be calculated as ", " etc. ", "Connections use the built-in ", ". "], "package_tt": ["/statistics", "/statistics_node", "/statistics_host", "/arni/specifications", "/statistics_rated", "/statistics", "/arni/specifications", "/arni/specifications/logical_unit1\u00a0=\u00a0[],\u00a0/arni/specifications/logical_unit2\u00a0=\u00a0[]", "alive_timer", "minvalue\u00a0=\u00a0value\u00a0*\u00a0(1\u00a0-\u00a0deviation)"], "package_code": ["- n!example_node: # a seuid\n", "    measurement1: [minvalue, maxvalue]\n", "    # or\n", "    measurement2: [value, deviation, \"relative\"]", "cpu_temp_mean (float32)\n", "cpu_temp_stddev (float32)\n", "cpu_temp_max (float32)\n", "\n", "cpu_usage_mean (float32)\n", "cpu_usage_stddev (float32)\n", "cpu_usage_max (float32)\n", "\n", "cpu_usage_core_mean (float32[])\n", "cpu_usage_core_stddev (float32[])\n", "cpu_usage_core_max (float32[])\n", "\n", "cpu_temp_core_mean (float32[])\n", "cpu_temp_core_stddev (float32[])\n", "cpu_temp_core_max (float32[])\n", "\n", "gpu_temp_mean (float32[])\n", "gpu_temp_stddev (float32[])\n", "gpu_temp_max (float32[])\n", "\n", "gpu_usage_mean (float32[])\n", "gpu_usage_stddev (float32[])\n", "gpu_usage_max (float32[])\n", "\n", "ram_usage_mean (float32)\n", "ram_usage_stddev (float32)\n", "ram_usage_max (float32)\n", "\n", "message_frequency_mean (int32[])\n", "message_frequency_stddev (int32[])\n", "message_frequency_max (int32[])\n", "\n", "bandwidth_mean (float32[])\n", "bandwidth_stddev (float32[])\n", "bandwidth_max (float32[])", "node_cpu_usage_mean (float32)\n", "node_cpu_usage_stddev (float32)\n", "node_cpu_usage_max (float32)\n", "\n", "node_cpu_usage_core_mean (float32[])\n", "node_cpu_usage_core_stddev (float32[])\n", "node_cpu_usage_core_max (float32[])\n", "\n", "node_gpu_usage_mean (float32[])\n", "node_gpu_usage_stddev (float32[])\n", "node_gpu_usage_max (float32[])\n", "\n", "node_ramusage_mean (float32)\n", "node_ramusage_stddev (float32)\n", "node_ramusage_max (float32)\n", " \n", "node_message_frequency_mean (float32)\n", "node_message_frequency_stddev (float32)\n", "node_message_frequency_max (float32)\n", "\n", "node_bandwidth_mean (float32)\n", "node_bandwidth_stddev (float32)\n", "node_bandwidth_max (float32)\n", "\n", "node_write_mean (float32)\n", "node_write_stddev (float32)\n", "node_write_max (float32)\n", "\n", "node_read_mean (float32)\n", "node_read_stddev (float32)\n", "node_read_max  (float32)", "delivered_msgs (int32)\n", "dropped_msgs (int32)\n", "traffic (int32)\n", "bandwidth (int32) # normalized traffic\n", "period_mean (duration)\n", "period_stddev (duration)\n", "period_max (duration)\n", "stamp_age_mean (duration)\n", "stamp_age_stddev (duration)\n", "stamp_age_max (duration)", "delivered_msgs (int32)\n", "dropped_msgs (int32)\n", "packages (int32) # number of packages included in the aggregation\n", "packages_per_second (float32) # packages normalized over their timespan\n", "traffic (int32)\n", "bandwidth (float32) # normalized traffic\n", "frequency (float32)\n", "stamp_age_mean (duration)\n", "stamp_age_stddev (duration)\n", "stamp_age_max (duration)"]},
{"url": "https://wiki.ros.org/arni", "package": "arni", "package_summary": ["Metapackage for Advanced Ros Network Introspection."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", " ", "\n", " ", " ", "\n", " ", "Make sure you have the minimum required ROS Version for statistics. arni shell output and debug messages will tell you if there is any problem on the current host. On remote hosts you have to check their log as well.  ", " ", "This may be due to many different problems. Make sure the host really sends data and that the values in the GUI are changing. If this is the case it might be that the remote host is sending data too seldomly. Currently we do not interpolate between two data points, which means, if the host sends data every ten seconds and the graph show only 10 seconds the graph will move out of range immediately.  ", "The solution is updating the time range, e.g. to 30 seconds.  ", " ", "Advanced ROS Network Introspection (ARNI) extends the ", " features introduced with Indigo and completes the collected data with measurements about the hosts and nodes participating in the network. These are gathered from an extra node that has to run on each host machine. All statistics or metadata can be compared against a set of reference values using the ", ". The rated statistics allow to run optional ", " when a deviation from the reference is detected, in order to remedy the fault or at least bring the system in a safe state. ", "All data can be displayed and monitored through new ", ". ", "a) Publishing ", " data for topics and connections. ", " Publishing /statistics_host and /statistics_node data. ", " Comparing actual values to a YAML specification (d) and publishing /statistics_rated. ", " Automatically acting on rated data, given a YAML countermeasure file (f). g) ARNI rqt_gui to visualize current state of ROS network. h) rqt_gui Node Graph showing /statistics data. ", "If you have any further questions / issues / ideas do not hesitate to either use ", "  or to ", " the current maintainer directly. ", "Get the latest version from our ", " repository: ", "The message types can be founde here: ", " (Note: may be deprecated, see in source code for most recent information. The package arni_msgs contains all needed information). ", "Several Tutorials have been written to ease the use of ARNI. They can be found here:  ", " ", "If you ran into any other problems (and maybe also found a solution?) send us a mail or post it on ", "! "], "package_tt": ["ros-indigo-desktop-full", "pip"], "package_code": ["cd ~/catkin_ws/src\n", "git clone https://github.com/ROS-PSE/arni.git\n", "cd ..\n", "catkin_make", "pip install --user --upgrade psutil\n", "pip install --user pysensors\n", "pip install --user pyqtgraph", "@Inbook{Bihlmaier2016,\n", "author=\"Bihlmaier, Andreas and Hadlich, Matthias and W{\\\"o}rn, Heinz\",\n", "editor=\"Koubaa, Anis\",\n", "chapter=\"Advanced ROS Network Introspection (ARNI)\",\n", "title=\"Robot Operating System (ROS): The Complete Reference (Volume 1)\",\n", "year=\"2016\",\n", "publisher=\"Springer International Publishing\",\n", "pages=\"651-670\",\n", "isbn=\"978-3-319-26054-9\",\n", "doi=\"10.1007/978-3-319-26054-9_25\",\n", "url=\"http://dx.doi.org/10.1007/978-3-319-26054-9_25\"\n", "}\n", "\n", "@inproceedings{bihlmaier14arni,\n", "  title = {Increasing ROS Reliability and Safety Through Advanced Introspection Capabilities},\n", "  author = {Bihlmaier, Andreas and W{\\\"o}rn, Heinz},\n", "  booktitle = {Proceedings of the INFORMATIK 2014},\n", "  pages = {1319--1326},\n", "  year = 2014\n", "}"]},
{"url": "https://wiki.ros.org/abb_irb7600_support", "package": "abb_irb7600_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 7600 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 7600 manipulators. This currently includes the 150/3.50\n      variant only.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", ". All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/rqt_paramedit", "package": "rqt_paramedit", "package_summary": ["rqt_paramedit - a rqt plugin for editing parameters using qt_paramedit."], "package_details": ["\n", " ", "Note: This package replaces groovy's ", " in hydro. "]},
{"url": "https://wiki.ros.org/rr_openrover_stack", "package": "rr_openrover_stack", "package_summary": ["Packages related to the operation of Rover Robotics rover hardware.  This includes a client\n    for interfacing with the hardware (rr_openrover_driver) and a tool for filtering time stamped\n    velocity commands (rr_control_input_manager)."], "package_details": ["\n", "\n", "\n", " ", "The rr_openrover_stack is a collection of software needed to operate the Rover Robotics ", " platform. It provides driver support for serial communication between compute hardware and the ", " platform, as well as support for remote control using Xbox 360 controllers.  This includes all the software required for use of the ", " with the ", ". "], "package_code": ["sudo apt-get install ros-kinetic-rr-openrover-stack"]},
{"url": "https://wiki.ros.org/abb_irb1600_6_12_moveit_config", "package": "abb_irb1600_6_12_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 1600-6/1.2.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 1600-6/1.2 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/abb_irb6650s_support", "package": "abb_irb6650s_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB_6650S (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB_6650S manipulators. This currently includes the base model.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/abb_irb120_moveit_config", "package": "abb_irb120_moveit_config", "package_summary": ["\n      MoveIt package for the ABB IRB 120.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the ABB IRB 120 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/abb_irb6700_support", "package": "abb_irb6700_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 6700 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 6700 manipulators. This currently includes the 200/2.60 and\n      235/2.65 variants.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/abb_irb1200_support", "package": "abb_irb1200_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 1200 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 1200 manipulators. This currently includes the IRB 1200-5/0.9\n      and the IRB 1200-7/0.7 variants.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", ", document ID: ", ".\n      All urdfs / xacros are based on the default motion and joint velocity\n      limits, unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Note 1: inertial and dynamics values for the 5/0.9 variant were calculated\n      from the meshes using ", ", assuming constant density.\n      As the datasheet only provides the mass of the entire robot,\n      the mass of each link was estimated based on its volume, assuming\n      constant density for the entire robot.\n    ", "\n      Note 2: maximum joint effort values for the 5/0.9 variant do not\n      correspond to real world limits of the robot. The current values were\n      chosen to accomodate Gazebo simulations of this specific variant but\n      are fictional values.\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/rr_openrover_driver", "package": "rr_openrover_driver", "package_summary": ["Provides an interface between ros and Rover Robotics rover hardware. Inputs to rr_openrover_driver\n    include emergency stop and velocity commands.  It outputs diagnostic data such as encoder\n    readings and battery charge."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_driver/fan_speed", "/rr_openrover_driver/soft_estop/enable", "/rr_openrover_driver/soft_estop/reset", "/rr_openrover_driver/odom_encoder", "/rr_openrover_driver/raw_fast_rate_data", "/rr_openrover_driver/raw_med_rate_data", "/rr_openrover_driver/raw_slow_rate_data", "/rr_openrover_driver/battery_status_a", "/rr_openrover_driver/battery_status_b", "~use_legacy", "bool", "false", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["roslaunch rr_openrover_driver example.launch", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_driver openrover_driver_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_driver\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"openrover_driver_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover Diagnostics -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>slow_rate_pub"]},
{"url": "https://wiki.ros.org/kobuki_node", "package": "kobuki_node", "package_summary": ["ROS nodelet for Kobuki: ROS wrapper for the Kobuki driver."], "package_details": [" "], "package_tt": ["~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool", "~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "~commands/controller_info", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~controller_info", "~debug/raw_data_stream", "~debug/raw_data_command", "~debug/raw_control_command", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~use_imu_heading", "bool", "True", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool"]},
{"url": "https://wiki.ros.org/abb_irb120_gazebo", "package": "abb_irb120_gazebo", "package_summary": ["\n      ROS-Industrial Gazebo support package for the ABB IRB 120 (and variants).\n    ", "\n      This package contains the configuration data and launch files required\n      to simulate the ABB IRB 120 manipulator in Gazebo. This includes the base\n      model and the 120T.\n    ", "\n      Before using any of the configuration files included in this package, be\n      sure to check they are correct for the particular robot model and\n      configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "This package is part of the ", " program.  ", "See the ", " page. "]},
{"url": "https://wiki.ros.org/simple_navigation_goals_tutorial", "package": "simple_navigation_goals_tutorial", "package_summary": ["The simple_navigation_goals_tutorial package"], "package_details": [" The code in this package does not match the current version of the tutorial. ", "This package provides the code for the ", " tutorial for the navigation stack. "]},
{"url": "https://wiki.ros.org/abb_irb4600_support", "package": "abb_irb4600_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 4600 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 4600 manipulators. This currently includes the 20/2.50, the\n      40/2.55 and the 60/2.05 variants.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", ", ", ".\n      All urdfs / xacros are based on the default motion and joint velocity\n      limits, unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "], "package_details": ["\n", "\n", "\n", ": the Webots integration shown here is provided by Cyberbotics and does not use the models provided by the ", " package. Please contact Cyberbotics for support and usage related questions of this simulation. ", " ", "This package is part of the ", " program. ", "See the ", " page. ", "A ", " simulation model is available for the ABB IRB4600 arm with a ", ". "], "package_tt": ["abb_irb4600_support"]},
{"url": "https://wiki.ros.org/asctec_hl_comm", "package": "asctec_hl_comm", "package_summary": ["\n\n     This Package contains header files for communication with the HL controller on the AscTec AutoPilot and custom message, server, and action definitions \n\n  "]},
{"url": "https://wiki.ros.org/lanelet2_core", "package": "lanelet2_core", "package_summary": ["Lanelet2 core module"]},
{"url": "https://wiki.ros.org/remote_rosbag_record", "package": "remote_rosbag_record", "package_summary": ["The remote_rosbag_record package"]},
{"url": "https://wiki.ros.org/schunk_lwa4p_extended", "package": "schunk_lwa4p_extended", "package_summary": ["schunk_lwa4p_extended"]},
{"url": "https://wiki.ros.org/robot_upstart", "package": "robot_upstart", "package_summary": ["The robot_upstart package provides scripts which may be used to install\n    and uninstall Ubuntu Linux upstart jobs which launch groups of roslaunch files."], "package_details": ["\n", "\n", "Please see usage and docs here: ", " "]},
{"url": "https://wiki.ros.org/manipulator_h_gui", "package": "manipulator_h_gui", "package_summary": ["The manipulator_h_gui package\n    This package provides simple GUI to control ROBOTIS MANIPULATOR-H.\n    This GUI is connected to manipulator_h_base_module."], "package_details": [" ", "\n", "\n", "\n", " "], "package_tt": ["robotis/status", "robotis/base/ini_pose_msg", "robotis/base/set_mode_msg", "robotis/base/joint_pose_msg", "robotis/base/kinematics_pose_msg", "robotis/base/get_joint_pose", "robotis/base/get_kinematics_pose"]},
{"url": "https://wiki.ros.org/robotino_description", "package": "robotino_description", "package_summary": ["The robotino_description package"], "package_details": ["\n", "\n", "\n", "The ", " package contains xacro files and meshes required to create a urdf model of Robotino. This urdf file is used by the ", " package to broadcast transforms and also by ", " for visualization. ", "If the xacro files are modified, then the ", " would have to updated as well. This can be done by running the following command from the ", " directory. "], "package_tt": ["robotino.urdf", "robotino_description/urdf"], "package_code": ["rosrun xacro xacro.py robotino.urdf.xacro > robotino.urdf"]},
{"url": "https://wiki.ros.org/slam6d_exporter", "package": "slam6d_exporter", "package_summary": ["slam6d_exporter package"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/ros_explorer", "package": "ros_explorer", "package_summary": ["A web interface for exploring the ROS graph"], "package_details": ["\n", " is a web-based utility for browsing the ROS graph. ", " ", "\n", "\n", "This will create a server that serves the website on ", ". ", "It should also open the webpage in your default web browser automatically (using the xdg-open command). ", "If this does not work, you can just visit ", " manually. "], "package_tt": ["ros_explorer"], "package_code": ["sudo apt-get install ros-indigo-rosbridge-server", "sudo apt-get install ros-indigo-ros-explorer", "# If you do not already have a websocket server running:\n", "roslaunch ros_explorer ros_explorer_websocket.launch\n", "\n", "# If you are already running a websocket server for other purposes:\n", "roslaunch ros_explorer ros_explorer.launch"]},
{"url": "https://wiki.ros.org/rocon_console", "package": "rocon_console", "package_summary": ["Command line python console utilities (mostly for colourisation)."], "package_details": ["\n", "\n", "\n", " ", " "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rh_p12_rn", "package": "rh_p12_rn", "package_summary": ["ROS messages packages for the ROBOTIS RH-P12-RN (meta package)"], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosmake", "package": "rosmake", "package_summary": ["rosmake is a ros dependency aware build tool which can be used to\n     build all dependencies in the correct order."], "package_details": [" is a tool to assist with building ROS ", ".  It facilitates building packages that have dependencies. ", " will determine ", "'s dependencies (and the dependencies' dependencies, etc.), and will ensure that all dependencies are built prior to building ", ". ", "\n", " runs recursively on the dependencies of the given package(s), eventually running ", " on a each one.  After all dependencies are built, ", " will build the given package(s).  If no package is given, it will try to build the current directory, which must contain a ", ". ", "\n", " ", " ", "\n", "\n", " will skip packages with ", " in the root of the package. ", "\n", " will skip packages with a file ", " in the root of the package if the option --skip-blacklist is enabled. ", "\n", " ", "ROS comprises a large number of packages.  However, with the exception of some core packages that everything else depends on, e.g., ", " and ", ", many of the packages are largely independent.  As such, we have provided a ", " to allow you to only build what is actually necessary to run the packages that you want to run. ", "A package may depend on any number of other packages, requiring that those packages be built first.  These dependencies are specified in the package's ", " file.  However, it would be inconvenient to make you go and look at the dependencies for your package, and then in turn look at the dependencies for those packages and so on.  Instead, we provide ", " to do the ROS-wide build of everything you need for a given package. ", "For example, to build the ", " package, you can simply run: ", "If rosmake fails, there is a good chance you are missing ", " for one or more of the packages you are trying to install. ", "NOTE: you can run ", " from anywhere, as it uses ", " to locate packages. ", "If you really just want to build a package, and you know that its dependencies are up-to-date, you just type ", " in that package's top-level directory. ", "You ", " run ", " multiple times simultaneously on one machine, unless you are sure that the builds don't share any dependencies.  You may end up building the same package simultaneously, which can cause various problems. ", "Options available in ROS Electric and earlier: ", "There are two parallelization options within ", ": ", "You can modify the behavior of ", " by placing files with special names in your directory tree. These file names and their associated behaviors are described below. ", "If the options ", " only packages which declare the detected OS in their manifest (as demonstrated below) will be built. "], "package_tt": ["rosmake", "rosmake", "move_base", "rosmake", "move_base", "move_base", "rosmake", "rosmake", "rosmake", "make", "rosmake", "rosmake", "parallel\u00a0threads", "rosmake", "parallel\u00a0jobs", "rosmake", "ROS_PARALLEL_JOBS", "-jN", "N", "rosmake", "rosmake", "ROS_NOBUILD", "rosmake", "ROS_BUILD_BLACKLIST", "--require-platform", "--require-platform-recursive"], "package_code": ["$ rosmake move_base", "Usage: rosmake [options] [PACKAGE]...\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  --test-only           only run tests\n", "  -t                    build and test packages\n", "  -a, --all             select all packages\n", "  -i, --mark-installed  On successful build, mark packages as installed with\n", "                        ROS_NOBUILD\n", "  -u, --unmark-installed\n", "                        Remove ROS_NOBUILD from the specified packages.  This\n", "                        will not build anything.\n", "  -v                    display errored builds\n", "  -r, -k, --robust      do not stop build on error\n", "  --build-everything    build all packages regardless of errors\n", "  -V                    display all builds\n", "  -s, --specified-only  only build packages specified on the command line\n", "  --buildtest=BUILDTEST\n", "                        package to buildtest\n", "  --buildtest1=BUILDTEST1\n", "                        package to buildtest1\n", "  --output=OUTPUT_DIR   where to output results\n", "  --pre-clean           run make clean first\n", "  --bootstrap           Do the bootstrap packages even if there are no\n", "                        arguments\n", "  --disable-logging     turn off all logs\n", "  --target=TARGET       run make with this target\n", "  --pjobs=ROS_PARALLEL_JOBS\n", "                        Override ROS_PARALLEL_JOBS environment variable with\n", "                        this number of jobs.\n", "  --threads=THREADS     Build up to N packages in parallel\n", "  --profile             print time profile after build\n", "  --skip-blacklist      skip packages containing a file called\n", "                        ROS_BUILD_BLACKLIST (Default behavior will ignore the\n", "                        presence of ROS_BUILD_BLACKLIST)\n", "  --skip-blacklist-osx  deprecated option. it will do nothing, please use\n", "                        platform declarations and --require-platform instead\n", "  --require-platform    do not build a package unless it is marked as\n", "                        supported on this platform\n", "  --require-platform-recursive\n", "                        do not build a package unless it is marked as\n", "                        supported on this platform, and all dependents are\n", "                        also marked\n", "  --status-rate=STATUS_UPDATE_RATE\n", "                        How fast to update the status bar in Hz.  Default: 5Hz", "  --rosdep-install      call rosdep install before running\n", "  --rosdep-yes          call rosdep install with default yes argument\n", "  --no-rosdep           disable the default check of rosdep", "<platform os=\"ubuntu\" version=\"9.10\"/>"]},
{"url": "https://wiki.ros.org/manipulator_h_description", "package": "manipulator_h_description", "package_summary": ["The manipulator_h_description package\n    This package includes URDF model of ROBOTIS MANIPULATOR-H.\n    Additionally, we provide full kinematics and dynamics information of each link."], "package_details": [" ", "\n", " "]},
{"url": "https://wiki.ros.org/report_card", "package": "report_card", "package_summary": ["This package extends functionality of KnowRob system with robot's *log analysis*, *data extraction* and *report card generation*."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " is a CRAM package that extends ", " system and ", " environment with functionality of generating a PDF file that contains easy to read (e.g. pie charts, bar charts, tables) robot experiment statistics. ", "Alternative version of this guide is available ", ". ", "This package is based on ", " and its interpreter - the main log analysis and computations are done therein.   ", "Once the data is prepared part of it is passed to ", " via ", " interface where its processed and needed graphs are prepared. ", " is also used to store statistics and dump them into CSV and RData formats for easy post-processing. ", "Then, links to prepared figures and log statistics are passed via JPL to ", " where they are prepared and injected into selected LaTeX templates with use of ", " ", ". ", "Finally, the same library is used to generate a PDF based on prepared tex files. For details please refer to below figure. ", "To make the package the most universal the report card generation is based on two key concepts ", " and ", ". This approach allows the user to choose the design of the report card and decide which sections should be placed within. Moreover, this design facilitates creating personalised section and including them in the report card without complex code alterations and rebuilding the whole package - see below. ", "This templates specify overall design of the report card - please see ", " for an example. The most important part of it are ", " statements which include specified in ", " sections. The default layout allows up to 10 sections. ", "Section templates specify the structure of each section in the document - please see ", " for an example. There are 4 different types of variables that can be used in each section: ", "To add your custom section to the report card please create a file named ", " in the ", " directory. Use the arguments naming as described above - the order of the arguments is based on the order used in the ", " call done within ", ".   ", "To generate your section from within ", " add a new predicate to ", " file: ", "Where ", " is path to the temporary directory of current report card; ", " is the section name (it MUST contain the exact name you gave to your section file without ", " extension), ", " and ", " are as described above and of type ", " and finally, ", " and ", " are as described above and of type ", ". If you have no data of specific type to be passed to the section creator you should generate empty array for the first two types e.g. ", " and empty array of arrays for latter two types e.g. ", ".   ", "To alter current generator please append your section to ", " predicate as follows: ", "If you prefer to create custom report card generator first add type predicate to the already existing list: ", " and then create custom loader for created type: ", "To manually generate the report card (using ", " shell) please use the following sequence: ", "Before generating a report card remember to load the data e.g. ", "! ", "To perform statistical computations R is accessed via ", " interface in Prolog. As a rough guide please see the example shown below. ", "For details please refer to this ", ". ", "Any section contributions are welcomed, please make a pull request with you custom ", " predicates, ", " declarations, ", " and all additional predicates extending ", ".   ", "Please document all your code and wrap it between ", " and ", ". "], "package_tt": ["report_card", "Prolog", "R", "real", "R", "Java", "report_card/report_card/tex_templates/reportCard.tex", "\\ifthenelse{\u00a0\\equal{$section5}{}\u00a0}{}{\\input{$section5}}", "Prolog", "report_card/report_card/tex_templates/overview.tex", "section_name.tex", "report_card/report_card/tex_templates", "Java", "Prolog", "Prolog", "report_card/prolog/report_card.pl", "RcHomeOs", "Section", ".tex", "Strings", "RawStrings", "SeqStrings", "RawSeqStrings", "jpl_new('[Ljava.lang.String;',\u00a00,\u00a0Strings)", "jpl_new('[[Ljava.lang.String;',\u00a00,\u00a0SeqStrings)", "generate_report_card(card_type(default))", "card_type(custom_card_type).", "Prolog", "load_experiment('/home/ros/datasets/ds4/cram_log.owl').", "report_card.pl"], "package_code": ["generate_section_name(RcHomeOs, SectionPath) :-\n", "  Section = 'section_name',\n", "\n", "  code_to_get_all_statistics,\n", "\n", "  jpl_datums_to_array([YourVariable1, YourVariable2], Strings),\n", "\n", "  jpl_new('[Ljava.lang.String;', 0, RawStrings),\n", "\n", "  jpl_datums_to_array([YourOtherVariable11, YourOtherVariable12], SeqStrings1),\n", "  jpl_datums_to_array([YourOtherVariable21, YourOtherVariable22], SeqStrings2),\n", "  jpl_datums_to_array([SeqStrings1, SeqStrings2], SeqStrings),\n", "\n", "  jpl_new('[[Ljava.lang.String;', 0, RawSeqStrings),\n", "\n", "  jpl_call( 'org.knowrob.report_card.Generator', section, [RcHomeOs, Section, Strings, RawStrings, SeqStrings, RawSeqStrings], SectionPath).", "generate_report_card(card_type(default)) :-\n", "  % initialisation\n", "  rc_temporary_directory(RcTempDir),\n", "  create_directory(RcTempDir),\n", "  prolog_to_os_filename(RcTempDir, RcHomeOs),\n", "\n", "  % report card content\n", "  generate_overview(RcHomeOs, Introduction),\n", "  generate_actions(RcHomeOs, Actions),\n", "  generate_statistics(RcHomeOs, Statistics),\n", "  generate_failures(RcHomeOs, Failures),\n", "  generate_summary(RcHomeOs, Summary),\n", "\n", "  get_experiment_info(experimentId  , TrialId),\n", "\n", "  %%%% custom content\n", "  generate_section_name(RcHomeOs, CustomSection),\n", "  jpl_datums_to_array([Introduction, Actions, CustomSection, Statistics, Failures, Summary], Strings),\n", "  %%%%\n", "\n", "  jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf),\n", "\n", "  % data exporting and information outputting\n", "  export_data(data_format(csv)),\n", "  export_data(data_format(r)),\n", "  write('Your report card is available at:\\n'),\n", "  write(RcPdf), !.", "generate_report_card(card_type(custom_card_type)) :-\n", "  % initialisation\n", "  rc_temporary_directory(RcTempDir),\n", "  create_directory(RcTempDir),\n", "  prolog_to_os_filename(RcTempDir, RcHomeOs),\n", "\n", "  get_experiment_info(experimentId  , TrialId),\n", "\n", "  % report card content\n", "  generate_overview(RcHomeOs, Introduction),\n", "  generate_actions(RcHomeOs, Actions),\n", "  generate_statistics(RcHomeOs, Statistics),\n", "  generate_failures(RcHomeOs, Failures),\n", "  generate_summary(RcHomeOs, Summary),\n", "\n", "  %%%% custom content\n", "  generate_section_name1(RcHomeOs, Section1),\n", "  generate_section_name2(RcHomeOs, Section2),\n", "  generate_section_name3(RcHomeOs, Section3),\n", "  jpl_datums_to_array([Section1, Section2, Section3], Strings),\n", "  %%%%\n", "\n", "  jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf),\n", "\n", "  % data exporting and information outputting\n", "  export_data(data_format(csv)),\n", "  export_data(data_format(r)),\n", "  write('Your report card is available at:\\n'),\n", "  write(RcPdf), !.", "rc_temporary_directory(RcTempDir), create_directory(RcTempDir), prolog_to_os_filename(RcTempDir, RcHomeOs), get_experiment_info(experimentId  , TrialId), generate_section_name1(RcHomeOs, Section1), generate_section_name2(RcHomeOs, Section2), generate_section_name3(RcHomeOs, Section3), jpl_datums_to_array([Section1, Section2, Section3], Strings), jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf), export_data(data_format(csv)), export_data(data_format(r)).", "A = [1, 2, 3, 4, 5, 6],\n", "B = ['a', 'b', 'c', 'd', 'e', 'f'],\n", "a <- A,\n", "b <- B,", "'a.mean' <- mean(a),\n", "Amean <- 'a.mean',\n", "write(Amean),", "<- pdf(file = +\"./filename.pdf\"),\n", "<- pie('a', labels = sprintf(+\"%s of\\n%s\", 'a', 'b'), main = +\"Pie-chart name\"),\n", "<- invisible('dev.off()')."]},
{"url": "https://wiki.ros.org/manipulator_h_manager", "package": "manipulator_h_manager", "package_summary": ["The manipulator_h_manager package\n    This package describes robot manager to execute manipulator_h_base_module."], "package_details": [" ", "\n", "\n", "\n", " "], "package_tt": ["gazebo", "bool", "gazebo_robot_name", "string", "robot_file_path", "string", "init_file_path", "string", "offset_file_path", "string"]},
{"url": "https://wiki.ros.org/reemc_hardware_gazebo", "package": "reemc_hardware_gazebo", "package_summary": ["Gazebo plugin to control a REEM-C robot in simulation."]},
{"url": "https://wiki.ros.org/rocon_app_manager", "package": "rocon_app_manager", "package_summary": ["The public interface and retaskable interface for a robot."], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", "\n", "These services are freely shared to any ros subsystem that wants to consume them via the ", " advertise/pull mechanisms. The purpose is to provide introspection to the robot (i.e. the system that runs the app manager) to make a decision as to whether it wishes to assume control of the robot. Assuming control is managed by making a request to invite the robot. ", "The list of arguments to use for standalone mode robot launcher. ", " ", "The list of arguments to use for concert mode robot launcher. ", " "], "package_tt": ["/platform_info", "/list_rapps", "/status", "/invite", "/start_rapp", "/stop_rapp", "platform_info", "list_rapps", "status", "invite", "start_rapp", "stop_rapp"], "package_code": ["Required Arguments:\n", "  auto_start_rapp: autostart a rapp, e.g. rocon_apps/talker\n", "Optional Arguments:\n", "  auto_rapp_installation (default \"false\"): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation\n", "  capabilities (default \"false\"): enable/disable a capability server\n", "  capabilities_blacklist (default \"[]\"): blacklist specific capabilities\n", "  capabilities_nodelet_manager_name (default \"capability_server_nodelet_manager\")\n", "  capabilities_package_whitelist (default \"[std_capabilities]\"): get capabilities from these packages only\n", "  capabilities_parameters (default \"/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml\"): detailed parameter configuration for the providers\n", "  capabilities_server_name (default \"capability_server\") \n", "  interactions (default \"false\")\n", "  interactions_list (default \"[]\")\n", "  rapp_package_blacklist (default \"[]\")\n", "  rapp_package_whitelist (default \"[rocon_apps]\"): comma separated list of package names\n", "  rapp_preferred_configuration_file (default \"/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml\")\n", "  robot_description (default \"To err is human, to 'arr is pirate.\")\n", "  robot_icon (default \"rocon_icons/cybernetic_pirate.png\") \n", "  robot_name (default \"Cybernetic Pirate\") \n", "  robot_type (default \"pc\")\n", "  rosbridge_address (default \"localhost\")\n", "  rosbridge_port (default \"9090\")\n", "  screen (default \"true\"): verbose output from running apps\n", "  simulation (default \"false\"): if simulated robot\n", "  zeroconf (default \"false\")\n", "  zeroconf_name (default \"Cybernetic Pirate\")\n", "  zeroconf_port (default \"11311\")", "Required Arguments:\n", "  concert_uri: configure concert hub uri for direct connection.\n", "Optional Arguments:\n", "  capabilities (default \"false\"): enables/disables a default capability server in this concert client\n", "  capabilities_blacklist (default \"[]\"): blacklist specific capabilities\n", "  capabilities_package_whitelist (default \"[]\"): get capabilities from these packages only (e.g. std_capabilities)\n", "  capabilities_parameters (default \"/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml\"): detailed parameter configuration for the providers\n", "  concert_watch_period (default \"10\"): the period used by gateways for watching concert connections\n", "  concert_whitelist (default \"[]\"): list of concert names this robot will work with\n", "  disable_zeroconf (default \"false\"): disable zeroconfiguration\n", "  firewall (default \"false\"): typically false (don't let anything in), only for simulation clients\n", "  interactions (default \"false\")\n", "  interactions_list (default \"[]\")\n", "  local_machine_only (default \"false\"): only work with local concerts (testing, simulations)\n", "  rapp_auto_installation (default \"false\"): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation\n", "  rapp_package_blacklist (default \"[]\")\n", "  rapp_package_whitelist (default \"[rocon_apps]\"): comma separated list of package names\n", "  rapp_preferred_configuration_file (default \"/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml\")\n", "  robot_description (default \"To err is human, to 'arr is pirate.\")\n", "  robot_icon (default \"rocon_icons/cybernetic_pirate.png\")\n", "  robot_name (default \"Cybernetic Pirate\")\n", "  robot_type (default \"turtlebot\")\n", "  robot_unique_name (default \"true\"): postfix a uuid to the robot name for uniqueness\n", "  screen (default \"false\"): verbose output from running apps\n", "  simulation (default \"false\"): if simulated robot"]},
{"url": "https://wiki.ros.org/mm_core_msgs", "package": "mm_core_msgs", "package_summary": ["Message definitions and serialisations for core messages."]},
{"url": "https://wiki.ros.org/receive_xsens", "package": "receive_xsens", "package_summary": ["\n\n     ROS driver for Xsens MTi-10 and MTi-100 series motion trackers\n\n  "], "package_details": [" ", "\n", "\n", " ", "\n"], "package_tt": ["/imu/data"], "package_code": ["rosrun receive_xsens receive_xsens", "roslaunch receive_xsens.launch"]},
{"url": "https://wiki.ros.org/robotis_device", "package": "robotis_device", "package_summary": ["The package that manages device information of ROBOTIS robots.\n    This package is used when reading device information with the robot information file\n    from the robotis_controller package."], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/android_extras", "package": "android_extras", "package_summary": ["Various additional and useful general packages, but not core."], "package_details": ["For more general documentation on all things rosjava-android, refer to the ", " and ", " wiki pages. "]},
{"url": "https://wiki.ros.org/schunk_lwa4d", "package": "schunk_lwa4d", "package_summary": ["schunk_lwa4d"]},
{"url": "https://wiki.ros.org/soem_master", "package": "soem_master", "package_summary": ["soem_master contains a C++ wrapper around soem_core, a factory object to register and create drivers and a RTT component that will automatically create the drivers and their services for all the slave for which a driver is known."]},
{"url": "https://wiki.ros.org/robotis_controller", "package": "robotis_controller", "package_summary": ["robotis_controller package for ROBOTIS's platform like Manipulator-H, THORMANG and OP series"], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["/robotis/write_control_table", "/robotis/sync_write_item", "/robotis/set_joint_ctrl_modules", "/robotis/enable_ctrl_module", "/robotis/set_control_mode", "robotis_controller", "DIRECT_CONTROL_MODE", "MOTION_MODULE_MODE", "/robotis/set_joint_states", "/[gazebo_robot_name]/joint_states", "/robotis/goal_joint_states", "/robotis/present_joint_states", "/robotis/present_joint_ctrl_modules", "/robotis/get_present_joint_ctrl_modules", "/robotis/set_present_joint_ctrl_modules", "/robotis/set_present_ctrl_modules"]},
{"url": "https://wiki.ros.org/rosbuild", "package": "rosbuild", "package_summary": ["rosbuild contains scripts for managing the CMake-based build system for ROS."], "package_tt": ["rosbuild", "rosbuild", "rosbuild", "Makefile", "Makefile", "make", "Makefile", "rosbuild", "CMakeLists.txt", "$ROS_ROOT/core/rosbuild/rosconfig.cmake", "$ROS_ROOT/core/rosbuild/rosconfig.cmake", "ROS_BUILD_TYPE", "RelWithDebInfo", "Debug", "Release", "RelWithDebInfo", "RelWithAsserts", "MinSizeRel", "ROS_BUILD_STATIC_EXES", "ROS_BUILD_SHARED_LIBS", "ROS_BUILD_STATIC_LIBS", "ROS_COMPILE_FLAGS", "ROS_LINK_FLAGS", "CMakeLists.txt", "rosconfig.cmake", "ROS_PACKAGE_NAME='\"foo\"'", "foo", "CMakeLists.txt", "$(INTEL_DIR)", "/opt/intel/cc/10.1.008", "ccache", "ccache", "/usr/lib/ccache/gcc", "pre1", "pre4"], "package_code": ["include $(shell rospack find mk)/cmake.mk", "cmake_minimum_required(VERSION 2.4.6)\n", "include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)\n", "# Turn off shared libs and turn on static libs, just for this package\n", "set(ROS_BUILD_STATIC_LIBS true)\n", "set(ROS_BUILD_SHARED_LIBS false)\n", "rosbuild_init()\n", "rosbuild_add_library(mylib mysrc.cpp)", "cmake_minimum_required(VERSION 2.4.6)\n", "include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)\n", "# Turn on higher warnings, because I'm hard-core\n", "set(ROS_COMPILE_FLAGS \"-W -Wall -Wextra -pedantic\")\n", "rosbuild_init()\n", "rosbuild_add_library(mylib mysrc.cpp)", "cmake_minimum_required(VERSION 2.4.6)\n", "include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)\n", "# Go to a release build, because I'm done debugging and I want compiler optimizations\n", "set(ROS_BUILD_TYPE Release)\n", "rosbuild_init()\n", "rosbuild_add_library(mylib mysrc.cpp)", "# I want both static and shared libs for all ROS packages (shared are enabled by default)\n", "set(ROS_BUILD_STATIC_LIBS true)", "# I want just static libs, just for this package\n", "set(ROS_BUILD_STATIC_LIBS true)\n", "set(ROS_BUILD_SHARED_LIBS false)", "set (CMAKE_C_COMPILER $(INTEL_DIR)/bin/icc)\n", "set (CMAKE_CXX_COMPILER $(INTEL_DIR)/bin/icpc)\n", "\n", "set (CMAKE_C_EXECUTABLE $(INTEL_DIR)/bin/xild)\n", "set (CMAKE_CXX_EXECUTABLE $(INTEL_DIR)/bin/xild)\n", "\n", "set (CMAKE_C_FLAGS   \"-msse3 -ip  -no-prec-div         -parallel -O3 -fPIC\" )\n", "set (CMAKE_CXX_FLAGS \"-msse3 -ip  -no-prec-div         -parallel -O3 -fPIC\" )\n", "\n", "set (CMAKE_EXE_LINKER_FLAGS  \"-Wl,-rpath,$(INTEL_DIR)/lib -L$(INTEL_DIR)/lib -lguide -lcxaguard -limf -lsvml -lirc -lpthread -lintlc\" )", "export PATH=/usr/lib/ccache:$PATH", "which gcc", "export DISTCC_HOSTS='@pre1/1 @pre2/1 @pre3/1 @pre4/1'\n", "export CCACHE_PREFIX=distcc"]},
{"url": "https://wiki.ros.org/roboteq_msgs", "package": "roboteq_msgs", "package_summary": ["Messages for Roboteq motor controller"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"roboteq_msgs\" in rosdoc: /home/rosbot/docs/api/roboteq_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/mrpt_generic_sensor", "package": "mrpt_generic_sensor", "package_summary": ["ROS node for interfacing any sensor supported by mrpt-hwdrivers"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mrp2_robot", "package": "mrp2_robot", "package_summary": ["MRP2 robot description and launch files"]},
{"url": "https://wiki.ros.org/roslib", "package": "roslib", "package_summary": ["Base dependencies and support libraries for ROS.\n    roslib contains many of the common data structures and tools that are shared across ROS client library implementations."], "package_details": ["\n", " is the base dependency of all ROS ", " and tools. It contains common tools like the generators for ", " and ", " as well as common message definitions like ", " and ", ". It also contains the common path-bootstrapping code for ROS Python nodes and tools. ", "\n", "\n", "\n", " contains command-line tools for message generation necessary for ROS ", " authors. These tools are ", ". ", "\n", "roslib contains the definition of the ", " and ", " objects used in ", " and other ROS C++ libraries. It also contains functions for querying the ROS package system. Please see the ", " and the ", " for more details. ", "If you are a Python developer, you might be confused that there are both the ", " and ", " packages that support Python development in ROS. In fact, some of the functionality they provide is very similar.  ", "There is only one line of ", " you need to know, which exists for bootstrapping reasons:", "Otherwise, the simple answer is ", ". Unless you're more familiar with ROS Python development, ", " should provide you with all the APIs you need to run a node, call services, access the Parameter Server, etc... roslib is primarily an internal library used by ROS core developers to write tools. ", "Currently no new features are planned for ", ". But as new, common functionality is added to the ROS platform, it will likely be supported by libraries here. "], "package_tt": ["roslib", "Header", "Log", "ros::Time", "ros::Duration", "roslib", "rospy", "roslib", "roslib"], "package_code": ["import roslib; roslib.load_manifest('YOUR_PACKAGE_NAME')"]},
{"url": "https://wiki.ros.org/jaco_description", "package": "jaco_description", "package_summary": ["3D Model and URDF of the Kinova JACO Arm"], "package_details": ["\n", " contains urdf and xacro files for the JACO arm.  It also includes a launch file for reading the robot model and setting up a ", " and ", " for visualization in tools such as rviz. ", "\n", "\n", "\n", "To install the ", " package, you can install from source with the following commands: ", "The ", " package includes a launch file that can be used to load the robot model and setup joint state and robot state publishing used to populate a tf tree and visualize the robot.  Once launched, the JACO model can be visualized in tools such as rviz.  It can be launched with the following command: ", "The launch file also includes a parameter (", ") to launch a GUI which can control each joint to test the model's behavior, which can be launched as follows: "], "package_tt": ["jaco_description", "urdf/", "robots/", "meshes/", "wpi_jaco", "jaco_description", "gui"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch jaco_description display.launch", "roslaunch jaco_description display.launch gui:=true"]},
{"url": "https://wiki.ros.org/rosbash", "package": "rosbash", "package_summary": ["Assorted shell commands for using ros with bash."], "package_details": ["\n", "\n", "\n", "\n", " includes the following command line utilities: ", " ", "\n", " allows you to change directories using a package name, stack name, or special location. ", " without argument will take you to ", ". ", " ", "\n", " is the ", " equivalent of ", ".  It allows you to keep multiple locations in a directory-stack while still using ros package names.  You can then  use the number of any directory in your directory stack to jump back there. ", " ", "\n", " lists the directories in your directory stack.  This is for use with ", ". ", " ", "\n", " allows you to view the contents of a package, stack, or location. ", " ", "\n", " allows you to easily edit files in a ROS package by typing the package name and the name of the file you want to edit: ", " ", "\n", " allows you to conveniently copy a file from a package.  Similar to ", " you can specify any file in the package regardless of hierarchy. ", " ", "\n", " allows you to run an executable in an arbitrary package from anywhere without having to give its full path or ", "/", " there first. ", "\n", " enables tab-completion for its own tools and for a number of other ros utilities: ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ", ". ", "The ", " package contains some useful bash functions and adds tab-completion to a large number of the basic ros utilities. ", "The ", " package includes limited support for ", " and ", " by way of sourcing the ", " or ", " files respectively. We currently do not provide documentation on these shells, though much of the functionality is similar to the bash shell extensions. ", "you can add this statement to the ", " directory to execute it automatically on login, such as ", ". ", "Sourcing a catkin workspace requires using ", ": ", "You can have this done automatically as soon as you ", " to the workspace directory, by adding a further config file (e.g. ", "): ", "Additionally, the ", " environment variable can be used to add additional special locations for use with ", ".  ", " is a colon-separated list of ", " pairs. ", "For example, adding the following to your ", " file: ", "and end up in ", ". ", "The default editor for rosed is vim. To use a different editor, set the ", " environment variable.  E.g., in your ~/.bashrc: ", "You also can change the editor for one ", " call on the fly: ", "Will end up copying the file from ", " ", "It's also possible to pass a ", " using the following syntax (replace the ", " with an ", "): ", "Starting in ", ", rosrun has a ", " option which can be used to run a node in gdb or valgrind. ", "For more example prefixes, see: ", " ", "There are a couple of generic completion rules that may be appropriate for other utilities.  Looking through the ", " source may provide insights into replicating similar functionality for other nodes, however, the code is not yet nicely generalized or re-usable.  In a future release of ROS, we plan to incorporate a more generically re-usable tab-completion framework into rosbash and the other common shells used by ROS. "], "package_tt": ["rosbash", "rosbash", "rosbash", "zsh", "tcsh", "roszsh", "rostcsh", "conf.d", "~/.config/fish/conf.d/rosfish.fish", "cd", "~/.config/fish/conf.d/catkin.autosource.fish", "rosbash", "pushd", "roscd", "roscd", "roscd", "$ROS_WORKSPACE", "ROS_LOCATIONS", "roscd", "ROS_LOCATIONS", "key=path", ".bashrc", "~/ros/dev", "rospd", "pushd", "roscd", "rosd", "rospd", "rosls", "rosed", "EDITOR", "rosed", "roscp", "rosed", "~/ros/pkgs/ros_tutorials/roscpp_tutorials/talker/talker.cpp", "rosrun", "cd", "roscd", "~parameter", "~", "_", "--prefix", "rosbash", "rosbash"], "package_code": ["source ${ROS_ROOT}/tools/rosbash/rosbash", "source /opt/ros/$ROS_DISTRO/setup.bash", "source /opt/ros/$ROS_DISTRO/share/rosbash/rosfish", "bass source ~/catkin_ws/devel/setup.bash", "function catkinSource --on-variable PWD\n", "    status --is-command-substitution; and return\n", "    if test -e \".catkin_workspace\"; or test -e \".catkin_tools\"\n", "        bass source devel/setup.bash\n", "        echo \"Configured the folder as a workspace\"\n", "    end\n", "end", "roscd <package-or-stack>[/subdir]", "roscd roscpp", "roscd roscpp/include/ros", "export ROS_LOCATIONS=\"pkgs=~/ros/pkgs:dev=~/ros/dev\"", "$ roscd dev", "leibs@bar:~$ rospd hokuyo_node/\n", "0 ~/ros/pkgs/laser_drivers/hokuyo_node\n", "1 ~\n", "leibs@bar:~/ros/pkgs/laser_drivers/hokuyo_node$ rospd roscpp_tutorials/\n", "0 ~/ros/pkgs/ros_tutorials/roscpp_tutorials\n", "1 ~/ros/pkgs/laser_drivers/hokuyo_node\n", "2 ~\n", "leibs@bar:~/ros/pkgs/ros_tutorials/roscpp_tutorials$ rospd laser_pipeline/\n", "0 ~/ros/dev/laser_pipeline\n", "1 ~/ros/pkgs/ros_tutorials/roscpp_tutorials\n", "2 ~/ros/pkgs/laser_drivers/hokuyo_node\n", "3 ~\n", "leibs@bar:~/ros/dev/laser_pipeline$ rospd 1\n", "0 ~/ros/pkgs/ros_tutorials/roscpp_tutorials\n", "1 ~/ros/pkgs/laser_drivers/hokuyo_node\n", "2 ~\n", "3 ~/ros/dev/laser_pipeline", "leibs@bar:~/ros/pkgs/laser_drivers/hokuyo_node$ rosd\n", "0 ~/ros/pkgs/laser_drivers/hokuyo_node\n", "1 ~\n", "2 ~/ros/dev/laser_pipeline", "$ rosls roscpp\n", "$ rosls roscpp/include/ros", "$ rosed roscpp_tutorials add_two_ints_server.cpp", "$ rosed roscpp CMakeLists.txt\n", "You have chosen a non-unique filename, please pick one of the following:\n", "1) ~/ros/ros/core/roscpp/test/CMakeLists.txt\n", "2) ~/ros/ros/core/roscpp/CMakeLists.txt\n", "3) ~/ros/ros/core/roscpp/src/CMakeLists.txt\n", "4) ~/ros/ros/core/roscpp/src/libros/CMakeLists.txt\n", "#?", "export EDITOR='emacs -nw'", "EDITOR=geany rosed rosbash rosbash", "$ roscp roscpp_tutorials talker.cpp .", "rosrun <package> <executable>", "rosrun roscpp_tutorials talker", "rosrun package node _parameter:=value", "rosrun my_package my_node _my_param:=value", "rosrun package node __name:=name", "rosrun my_package my_node __name:=my_name", "rosrun --prefix 'gdb -ex run --args' my_package my_node"]},
{"url": "https://wiki.ros.org/rl_env", "package": "rl_env", "package_summary": ["rl_env is is a package containing reinforcement learning (RL) environments."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package contains a variety of environments that can be used for reinforcement learning experiments. These can be used with new RL agents written to use the ", " framework, or with existing agents from the ", " package. The package contains the following environments: ", "The environment can interact with an RL agent in two ways. It can use the ROS messages defined in ", ", or another method can call the agent and environment methods directly, as done in the ", " package. ", "The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (", "), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: ", "Experiments can also be run by calling the agent and environment methods directly (as done in the ", " package). Methods that all environments must implement are defined in the Environment interface in the ", " package (", ").  Seeds can be retrieved from the environment with the getSeedings() method. An action is applied to the environment with a call to apply(action). The current state can be retrieved by calling sensation() and terminal() will indicate if the agent is in a terminal state or not. "], "package_code": ["rosrun rl_env env --env type [options]", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_env env --env carrandom --lag --stochastic --prints"]},
{"url": "https://wiki.ros.org/smach_msgs", "package": "smach_msgs", "package_summary": ["this package contains a set of messages that are used by the introspection\n    interfaces for smach."], "package_details": ["\n", "The smach messages are only used for communication between the introspection server and the ", ", and are considered part of the ", ". "]},
{"url": "https://wiki.ros.org/rl_agent", "package": "rl_agent", "package_summary": ["rl_agent is a package containing reinforcement learning (RL) agents."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package includes a number of reinforcement learning agents that can be used for learning on robots, or learning with the environments in the accompanying ", " package. ", "In addition to these methods, the package contains a general model-based architecture that can be used with any combinations of planners and model learning algorithms. For example, the R-Max implementation is simply the general agent with an R-Max model and Value Iteration for planning and the TEXPLORE agent is the general agent with a random forest model (", ") and UCT (", ") for planning. ", "Included in this package is a general model based agent that can use any model learning or planning method that match the interface defined by the ", " file in the ", " package. ", "Any of these model learning methods can be combined with any of the planners. It is also easy to write new model learning and planning methods that match the interface defined in ", " and use those as well. In addition, there are multiple ways of performing exploration: ", "The RL agent can interact with the environment in two ways: it can use the ROS messages defined in the ", " package, or another method can call the agent and environment methods directly, as done in the ", " package. ", "The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (", "), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: ", "Experiments can also be run by calling the agent methods directly (as done in the ", " package).  The methods that all Agents must implement are defined in the Agent interface in the ", " package (", "). Seeds can be given to the method by calling the seedExp method. The agent can be queried for an action after getting a new state and reward by calling next_action(reward, state). ", "To run the basic Q-Learning (", ") agent, type the following: ", "To run the basic Sarsa (", ") agent, type the following: ", "To run the basic Dyna (", ") agent, type the following: ", "To run the basic R-Max (", ") agent, type the following: ", "To run the basic TEXPLORE or TEXPLORE-VANIR (", ") agent, type the following: ", "TEXPLORE plans greedily with respect to the average of a number of decision tree models of the domain. By default, TEXPLORE uses nmodels = 5, C 4.5 discrete decision trees, and plans using the RTMBA real-time architecture (", ") with an action rate of 10 Hz. ", "To run TEXPLORE with Variance and Novelty Rewards (TEXPLORE-VANIR) (", "), set the coefficients for the variance and novelty explorations: "], "package_code": ["rosrun rl_agent agent --agent type [options]", "qlearner sarsa modelbased rmax texplore dyna savedpolicy", "rosrun rl_agent agent --agent texplore --planner parallel-uct --nmodels 10 --model m5tree --actrate 25 --gamma 0.99", "--model tree --nmodels 10", "rosrun rl_agent agent --agent qlearner", "rosrun rl_agent agent --agent sarsa", "rosrun rl_agent agent --agent dyna", "rosrun rl_agent agent --agent rmax", "rosrun rl_agent agent --agent texplore", "--model m5tree", "--n 5\n", "--v 5", "--history 5", "rosrun rl_agent agent --agent modelbased"]},
{"url": "https://wiki.ros.org/robot_self_filter", "package": "robot_self_filter", "package_summary": ["Filters the robot's body out of point clouds."], "package_details": ["\n", " ", "\n", "\n", "NOTE: for indigo and above users, please take a look at newer repository at ", " ", " ", "Note: this node will output an XYZ ", " with no RGB information. If you need to filter an XYZRGB ", ", look at ", " from the  ", " stack. ", "The ", " package is a filter to remove or mark the points corresponding to robot links in sensor data. The filter is essentially a node wrapper around the ", ". "]},
{"url": "https://wiki.ros.org/smarthome_network_zeroconf", "package": "smarthome_network_zeroconf", "package_summary": ["The zeroconf package"]},
{"url": "https://wiki.ros.org/jaco_sdk", "package": "jaco_sdk", "package_summary": ["JACO Software SDK and API"], "package_details": ["\n", "\n", "The ", " package contains Kinova's API for communicating with the JACO arm for both 32bit and 64bit systems.  The package will install the JACO libraries for use with the other packages in the ", " metapackage. ", "To install the ", " package, you can install from source with the following commands: "], "package_tt": ["jaco_sdk", "wpi_jaco", "wpi_jaco"], "package_code": ["\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/scratch4robots", "package": "scratch4robots", "package_summary": ["scratch4robots"]},
{"url": "https://wiki.ros.org/robotnik_sensors", "package": "robotnik_sensors", "package_summary": ["Robotnik standard sensors description. URDF and meshses."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rflex", "package": "rflex", "package_summary": ["ROS adaptations of the RFLEX driver."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/softkinetic", "package": "softkinetic", "package_summary": ["The softkinetic package"]},
{"url": "https://wiki.ros.org/jackal_gazebo", "package": "jackal_gazebo", "package_summary": ["Launchfiles to use Jackal in Gazebo."], "package_details": ["This package contains launch files to spawn ", " in some example environments. Please see ", " for usage. "]},
{"url": "https://wiki.ros.org/abb_irb6640_support", "package": "abb_irb6640_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 6640 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 6640 manipulators. This currently includes the\n      IRB 6640-185/2.8m (6640-185) only.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " (Version: 3HAC 028284-001 Rev. N). All urdfs /\n      xacros are based on the default motion and joint velocity limits, unless\n      noted otherwise (ie: no support for high speed joints, extended / limited\n      motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/rocon_apps", "package": "rocon_apps", "package_summary": ["Core rocon apps for use with the appmanager and rocon concert."]},
{"url": "https://wiki.ros.org/sensor_fusion_comm", "package": "sensor_fusion_comm", "package_summary": ["\n\n     This package contains messages, services and action definitions needed by ethzasl_sensor_fusion and nodes communicating with it.  \n\n  "]},
{"url": "https://wiki.ros.org/mm_eigen_msgs", "package": "mm_eigen_msgs", "package_summary": ["Message definitions and serialisations for Eigen messages."]},
{"url": "https://wiki.ros.org/asr_mild_kinematic_chain", "package": "asr_mild_kinematic_chain", "package_summary": ["This package provides information about the mild's kinematic chain and contains launch-files to publish the chain to a robot_state_publisher"], "package_details": [" ", "\n", "   ", " ", " ", "\n", " ", " ", " ", "\n", "\n", " ", "\n", "\n", "\n", "The mild's kinematic chain is described in ", "within this package. (See the ", " for a detailed explanation of the urdf format) ", "The kinematic chain consists of two major parts: The robot's environment (map) as well as the robot's base and the camera-system including PTU, Guppy-Cameras (and Kinect as an optional component). The fixed reference Frame is in the PTU and is called ", ". ", "The transformation publisher is usually not run directly from this package. Instead, use the launch files provided in ", ". ", "See ", " for tutorials on how to set up the full kinematic chain. "], "package_code": ["roslaunch asr_mild_kinematic_chain transformation_publishers_kinect_left.launch"]},
{"url": "https://wiki.ros.org/rh_p12_rn_base_module", "package": "rh_p12_rn_base_module", "package_summary": ["Base module using ROBOTIS framework for RH-P12-RN"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/mh5_anomaly_detector", "package": "mh5_anomaly_detector", "package_summary": ["ROS Anomaly Detector for Motoman MH5 robot arm"], "package_details": ["\n", " "]},
{"url": "https://wiki.ros.org/rmp_teleop", "package": "rmp_teleop", "package_summary": ["The rmp_teleop package provides teleoperation functionalities for a Segway Robotics Mobility Platform.\n    This package currently supports the xbox wireless joytsick."], "package_details": ["\n", "\n", "\n", "\n", "\n", " "], "package_tt": ["/rmp440le/joy", "/rmp440le/base/vel_cmd", "/rmp440le/deadman", "/rmp440le/audio_cmd", "joy_topic", "string", "velocity_command_topic", "string", "deadman_topic", "string", "audio_command_topic", "string", "update_frequency", "double", "translational_velocity_scale", "double", "rotational_velocity_scale", "double", "translational_velocity_boost_scale", "double", "rotational_velocity_boost_scale", "double"], "package_code": ["$ roslaunch rmp_teleop joystick.launch"]},
{"url": "https://wiki.ros.org/asr_ivt_bridge", "package": "asr_ivt_bridge", "package_summary": ["This package is used to convert between ROS messages and IVT images"], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains a library which is used to convert image data structures between ROS and ", ". ", "The structure of this library is based on the ", "-package, for more information you can check out the documentation for that. ", "Include", " and/or ", " to your code, depending on what you want to convert (images or camera calibrations). ", "To convert a ", " to a ", "e of the IVT-library call one of the following functions (notice that the ", "-functions create a copy of the input messages while the other ones try to share the data if possible): ", "The return-value is a ", "-object, which contains a ", " member called image. ", "To convert such an ", " back to ROS call one of the following member functions: ", "To convert a ROS ", " to an IVT ", " instantiate either an ", " or an ", " object (depends on your camera system: mono or stereo). Then call one of the provided member functions with the ROS-CameraInfo-message you want to convert (for a stereo system you have to provide messages of both cameras of course): "], "package_code": ["IvtImagePtr toIvtCopy(const sensor_msgs::ImageConstPtr& source, const std::string& encoding = std::string());\n", "IvtImagePtr toIvtCopy(const sensor_msgs::Image& source, const std::string& encoding = std::string());", "IvtImageConstPtr toIvtShare(const sensor_msgs::ImageConstPtr& source, const std::string& encoding = std::string());\n", "IvtImageConstPtr toIvtShare(const sensor_msgs::Image& source, const boost::shared_ptr<void const>& tracked_object, const std::string& encoding = std::string());", "sensor_msgs::ImagePtr toImageMsg() const;\n", "void toImageMsg(sensor_msgs::Image& ros_image) const;", "bool fromCameraInfo(const sensor_msgs::CameraInfo& msg);\n", "bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& msg);", "bool fromCameraInfo(const sensor_msgs::CameraInfo& left, const sensor_msgs::CameraInfo& right);\n", "bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& left, const sensor_msgs::CameraInfoConstPtr& right);", "boost::shared_ptr<CCalibration> getCalibration(bool forRectifiedImages=false) const;\n", "boost::shared_ptr<CStereoCalibration> getStereoCalibration(bool forRectifiedImages=false) const;"]},
{"url": "https://wiki.ros.org/mrp2_display", "package": "mrp2_display", "package_summary": ["Package for managing touch LCD panel on MRP2"]},
{"url": "https://wiki.ros.org/robot_calibration", "package": "robot_calibration", "package_summary": ["Calibrate a Robot"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/manipulator_h_base_module", "package": "manipulator_h_base_module", "package_summary": ["The manipulator_h_base_module package\n    This package describes basic function to control ROBOTIS MANIPULATOR-H.\n    This module is based on position control.\n    We provides joint space and task space control (forward kinematics, inverse kinematics)."], "package_details": [" ", "\n", "\n", "\n", " "], "package_tt": ["robotis/base/ini_pose_msg", "robotis/base/set_mode_msg", "robotis/base/joint_pose_msg", "robotis/base/kinematics_pose_msg", "robotis/status", "robotis/enable_ctrl_module", "robotis/base/get_joint_pose", "robotis/base/get_kinematics_pose"]},
{"url": "https://wiki.ros.org/rocon_interaction_msgs", "package": "rocon_interaction_msgs", "package_summary": ["Messages used by rocon interactions."]},
{"url": "https://wiki.ros.org/mm_radio", "package": "mm_radio", "package_summary": ["Multiplexing many packet types across a two-way radio connection with publishers and subscribers.\n   Great for embedded connections by two-way serial or ethernet types."]},
{"url": "https://wiki.ros.org/nmea_gps_driver", "package": "nmea_gps_driver", "package_summary": ["\n\tPackage to parse NMEA strings and publish standard ROS GPS messages. This package does not require the GPSD deamon.\n  "], "package_details": [" ", ". ", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package provides a ROS interface for GPS devices that output compatible NMEA sentences. See the ", " for details on the raw format. Of the thousands of NMEA-compatible GPS devices, we are compiling a list of ", ". ", "This package is compatible with the ", " project as well as any other nodes that support ", " and/or ", ".  ", "Due to the dependency on ", ", this package is only compatible with ", " or newer. ", "To get up and running quickly, you can use the following command to start outputting your GPS data onto ROS topics. This assumes your GPS is outputting GGA NMEA sentences, is connected to ", " and is communicating at 38400 baud. "], "package_tt": ["/dev/ttyUSB0", "fix", "vel", "time_reference", "time_ref", "~port", "string", "~baud", "int", "~frame_id", "string", "frame_id", "tf_prefix", "~time_ref_source", "string", "~useRMC", "bool", "True", "False"], "package_code": ["$ rosrun nmea_gps_driver nmea_gps_driver.py _port:=/dev/ttyUSB0 _baud:=38400"]},
{"url": "https://wiki.ros.org/rl_msgs", "package": "rl_msgs", "package_summary": ["rl_msgs is a package of ROS message definitions, which are used for a reinforcement learning agent to communicate with an environment."], "package_details": ["\n", " ", "\n", "\n", " ", " ", "This package defines a standard way for agents and environments to communicate through ROS messages. In ROS computation is done by nodes that perform different tasks that communicate through a set of ROS messages. ROS provides the framework to publish, subscribe to and receive these messages, in addition to tools for logging, displaying, plotting, and playing back ROS messages. This package defines a set of ROS messages for a reinforcement learning agent and environment to communicate. These messages are similar to the messages used by RL-Glue (", "), but are simplified and defined in the ROS format. ", "Please take a look at the ", " on how to install, compile, and use this package ", "Check out the code at: ", " ", "Agents from the ", " package can communicate with environments from the ", " package through this interface. In addition, you can write your own agents and environments that will work with the ones in those packages by passing the same messages defined here. ", "The  framework is being designed to be as flexible as possible. While our  algorithms and environments will mostly follow a certain style, we understand that every robot and  every experiment differs. Our hope is to not force our philosophy onto  other people, as long as you adhere to ", " you can design and implement your algorithms and environments in your own style. "]},
{"url": "https://wiki.ros.org/rviz_imu_plugin", "package": "rviz_imu_plugin", "package_summary": ["RVIZ plugin for IMU visualization"], "package_details": ["\n", " ", "\n", " ", "The ", " package is used to display ", "  messages in ", ". Once you download and compile the package, it should be visible as a plugin. ", "The package has been ", " for inclusion in ROS. ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "]},
{"url": "https://wiki.ros.org/langs-dev", "package": "langs-dev", "package_summary": ["Meta package modeling the build-time dependencies for language bindings of messages."]},
{"url": "https://wiki.ros.org/retalis", "package": "retalis", "package_summary": ["Retalis Language for Information Processing and Management in Autonomous Robot Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", "\n", " ", "Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type ", " ", "Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with ", ".  The format of time-stampes are  ", " where ", " encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above ", " message contains a list of ", " messages (only one here). While each  ", " message is time-stamped, the ", " itself does not have a header. Therefore, the corresponding event is stamped with the current time. ", "The following rule calls  the ", " function for every ", " event received by retalis. ", "Each ", " message from ", " contains a list of recognized objects, each represented by a  ", " message. The following rule generates a separate event for each object. ", "where ", " represents a recognized object and ", " encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding ", " message. The events is also time stamped with ", ". ", "Retalis integrates the '", ". ", " supports temporal and logical reasoning on flow of events. Please see ", "  for publications and for examples of rules implementing various event-processing functionalities. ", "This memory instance keeps the history of events of the form ", ", specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. ", "The ", " event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as ", ". ", "We saw in Section 4.1.3 that the ", " and ", " functions are implemented as Prolog clauses. The ", " file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events ", "The Prolog program in ", " together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our ", " list). ", "An example of using ", " and ", " terms is in implementation of the ", " function, in the eventRules.txt. The input values to this function is the ", " of a memory instance, keeping the history of some ", " events, and a time point. The ", " events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time ", ". This is implemented as follows. The last observation before ", " and the first observation after ", " are found using the ", " and ", " terms. Then the position is linearly interpolated by making a function call to the ", " library that has been integrated with retalis. ", "The ", " function in eventRules.txt uses the ", " function to position an object in the world reference frame. Given ", ", the position of an object relative to the camera at time ", ", this function computes ", ", the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between ", ", ", ", ", ", ", " and ", " at the time ", ". Third, it applies these transformations on the ", " by making a function call to the ", " library. It is assumed that the ", " frame is aligned with the world reference frame. ", "We saw in Section 4.1.6 that how calling ", " function interpolates the position between the ", " and ", " coordination frames at time ", ". This function uses ", " and ", " terms to access the first and the last observations after and before ", ", respectively. To interpolate the position at ", ", the position should have been observed, at least once, after ", ". The observations, ", " messages here, are received asynchronously. Therefore, the ", " function should be evaluated only after the ", " memory instance has been updated with an event occurring after ", ". This is realized in retalis using a synchronized event, as follows. ", "The ", " function, performs the ", ", when the ", " are satisfied and then generate the ", ". Consider the following clause from eventRules.txt: ", "This rule computes the position of recognized markers in the world and is read as follows.   For each ", " event, specified in line 6, the position is computed by calling the ", " function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: ", "Such a ", " event encodes the marker's name, its position in the world and the time of recogntion. The ", " are the followings, specified in line 4: ", "These conditions specify that the ", " function should be evaluated, only after all ", ", ", ", ", ", ", " and ", " memory instances have been updated, at least once, with events occurring after time ", ". The time ", " is the time of recognition of the marker. ", "Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized ", " is posponed, until the ", " are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. ", "The subscription subscribes the topic ", " to the ", " events in which ", " is ", ". Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker ", " in the world coordination frame.  The id of the subscription is ", " which can be used to cancel the subscrition at any time. ", "The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the ", " and ", " ros topics. The retalis-ros-converter only subscribes retalis to the ", " topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to ", " and ", " topics in the pub-sub.xml file and instead, set the ", " boolean variable in the retalis_interface.cpp file to ", ". You should also recompile the package. ", "As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to ", " and ", " topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. ", "The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record ", " events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  ", "In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type ", " are added to the NAO example. These memory instances match all ", " events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type ", ". However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. ", "The following figure shows the CPU time for a number of runs where up to 40 memory instances of type ", " and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  ", "The following figure shows the CPU time for a number of runs where up to 640 memory instances of type ", " and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. ", "The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type ", ". The green line shows the CPU time for the case where there are 320 memory instances of type ", ". We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for ", " events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. ", "The brown line shows the CPU time for the case where there are 10 memory instances of type ", " and 320 memory instances of type ", ". ", "Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10 ", " memory instances and 320 ", " memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. ", "The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional ", " memory instance of size 128. This memory instance is queried by 1000 ", " terms for each recognition of an object. In average, 7000 ", " terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000 ", " terms are evaluated per seconds. The figure shows that the costs of the evaluations of ", " and ", " terms are similar. The purple line shows the CPU time of the case where 14,000 ", " terms are evaluated per second. We observe that the cost grows linearly, as expected. ", "The blue line in the following figure visualizes the CPU time of the case where 7000 ", " terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320 ", " memory instances. The purple line visualizes the CPU time of the case where 7000 ", " terms are evaluated per second and there are 320 ", " memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. ", "The green line in the following figure visualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     ", "The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000 ", " queries on a memory instance of size 2500 are evaluated. In addition, for each ", " query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. ", "Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see ", " for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. "], "package_tt": ["add_output_subscription", "delete_output_subscription", "add_memory", "delete_memory", "add_input_subscription", "delete_input_subscription", "__0__", "__0__", "__0__", "__0__", "'\"/odom\"','\"/base_link\"'", "'\u201c/odom\u201d',\u00a0'\u201c/base_link\u201d'", "ToDo", "Event", "RelativePos", "AbsolutePose", "RelativePos", "AbsolutePose", "CameraTop", "RelativePos", "SynchConditions", "Query", "SynchConditions", "Event", "PoseStamped", "SyncConditions", "PoseStamped", "'\"4x4_1\"'", "__0__", "__0__", "CameraTop_frame"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/shm_transport", "package": "shm_transport", "package_summary": ["The shared memory transport package"], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", " ", "A shm_transport::Topic object is an encapsulation of ros::", ". ", "Note that shm_transport::Topic::advertise() has one more parameter comparing to ros::", "::advertise(). This parameter (3 * MSGLEN in the example) indicates the total size of shared memory segment. The total size of shared memory segment should be larger than two messages plus the space used by memory allocation algorithm. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/raspigibbon_description", "package": "raspigibbon_description", "package_summary": ["The raspigibbon_description package"]},
{"url": "https://wiki.ros.org/manipulator_h_bringup", "package": "manipulator_h_bringup", "package_summary": ["The manipulator_h_bringup package\n    This package includes launch file to describe robotis in Rviz."], "package_details": [" ", "\n", " "]},
{"url": "https://wiki.ros.org/rviz_animated_view_controller", "package": "rviz_animated_view_controller", "package_summary": ["A rviz view controller featuring smooth transitions."], "package_details": ["\n", "\n", "\n", "This package provides an RViz view controller plugin that allows users to control the RViz camera by publishing ", " messages (from the ", " package) to the ", " topic. ", "This package has been released into Hydro and Indigo. Installation through ", " is easiest in most cases: ", "See the ", ", ", " and ", " scripts in the ", " package for examples of how to use the functionality provided by this package. "], "package_tt": ["CameraPlacement", "/rviz/camera_placement", "apt-get", "CameraTest", "ControlsTest", "SquareTest"], "package_code": ["sudo apt-get install ros-hydro-rviz-animated-view-controller", "sudo apt-get install ros-indigo-rviz-animated-view-controller"]},
{"url": "https://wiki.ros.org/asr_calibration_tool_dome", "package": "asr_calibration_tool_dome", "package_summary": ["This package provides a tool for calibraiting the kinematic chain of the PdB-Dome. It provides a data-tracking for recording 6D positions of Flock of Birds data glove and a checkerboard mounted on it. With this construction, the kinematic chain is closed. The recorded data is written to a file and can be used for the asr_kinematic_chain_optimizer."], "package_details": [" ", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "The idea of this calibration process is to close the kinematic chain, track several hundred datasets, describe a default TF-configuration and minimize the distances. In addition, the PTU pan- and tilt-angle are also tracked. Dataset are the tracked training data. Each value is a configuration of a non-fix joint. A whole dataset (one row) contains all variables of a kinematic chain (See ", " for further information). A sample Dataset is shown in the following picture: ", "1. Define a kinematic chain as best as you could, or use the old kinematic chain. The format is shown in ", " package. Define also a goal function (e. g. Position of Frame1 and Frame2 should be equal. (See ", " for further information). Make sure that all non-fixed Frames are parameterized (like PTU). ", "2. Construct something, so the kinematic chain is closed. In this case a tracker of the ", " system is attached on a checkerboard detector. Define a transformation between the two tracked frames like you did in 1. ", "4. Run the ", " with you frames and datasets as inputfiles. "], "package_code": ["rostopic echo /fob_objects", "rostopic echo /ptu_driver/state", "rostopic echo /checkerboard_detector/objectdetection_pose", "rosrun asr_flock_of_birds flock_of_birds_remote.sh\n", "\n", "roslaunch asr_flir_ptu_driver ptu_left.launch\n", "\n", "roslaunch asr_resources_for_vision guppy_head_full_pbd.launch\n", "\n", "(roslaunch asr_flir_ptu_driver ptu_gui.launch)\n", "\n", "roslaunch asr_calibration_tool_dome checkerboard_detector_single.launch"]},
{"url": "https://wiki.ros.org/ar_kinect", "package": "ar_kinect", "package_summary": ["\n    This package extends the ar_pose package to handle point clouds + images generated from the kinect for improved AR marker localization.\n  "], "package_details": ["\n", " has a single node that can be run, which takes RGB point clouds from the Kinect and outputs a transform between the camera and a recognized marker. This is based on the ", " node from the ", " package. ", "\n", "\n", "This package is an ROS wrapper for ", ", which improves marker localization using point cloud data from a Kinect.  "], "package_tt": ["ar_multi", "points", "ar_pose_markers", "visualization_marker", "marker_pattern_list", "string", "\"$(find\u00a0ar_kinect)/data/object_kinect\"", "marker_data_directory", "string", "\"$(find\u00a0ar_pose)\"", "threshold", "double", "publish_visual_markers", "bool", "publish_tf", "bool", "camera_frame_id", "marker_frames"]},
{"url": "https://wiki.ros.org/smacha", "package": "smacha", "package_summary": ["SMACHA (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of SMACH into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background."], "package_details": ["\n", " (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of ", " into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background. ", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "The ", " provides an overview of the functionalities and core concepts of SMACHA. "]},
{"url": "https://wiki.ros.org/launchman", "package": "launchman", "package_summary": ["Launch Manager"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/slam_exporter", "package": "slam_exporter", "package_summary": ["\n\n     slam_exporter\n\n  "]},
{"url": "https://wiki.ros.org/simple_drive", "package": "simple_drive", "package_summary": ["A simple robot drive system that includes skid steering joystick teleoperation, control of a panning servo to look around the robot, and Arduino firmware."], "package_details": ["\n", " ", "\n ", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " If your microcontroller supports subscribing to ROS ", " messages (Arduinos can use ", ") then it would be simpler to do that and skip this node. However, this node is written in python so you could more easily add complex functionality in python and then in your microcontroller do the minimum amount of work necessary. ", "\n", "\n", " Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. ", "\n", " We like PlatformIO: \"Single source code. Multiple platforms.\" PlatformIO supports approximately 200", " and all major", ". Learn more on", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", " ", " - Differential drive software with support for a velocity PID target, a small GUI to control the robot, and more. ", " - Differential drive software that is real-time safe, integrates with ", ", and more. ", " ", " - This teleop node converts joy messages to twist messages. ", " - This teleop node takes joy messages and publishes topics or calls actions according a configuration file. ", " ", " - Multiplex several velocity command topics with prioritization or disabling according to a configuration file. ", "\n", "A simple robot drive system. ", ": ", "This package ", ": ", "Package created by Ryerson University students for the ", ", summer 2017. ", "3. Install the ", " onto a microcontroller connected to motors and wheels by PWM. The microcontroller must also be connected to the computer running the simple_drive ROS node by a serial connection (ex. USB). ", "This diagram is also available in ", ". ", "This node converts ", " messages from the ", " node into a variety of commands to drive the robot at low, medium, and high speed, look around with a servo, and cancel move_base goals at any moment. This node simply sends commands to other nodes. Typically the servo is used to move a camera so that the teleoperator can look around the robot. ", "The ", " node receives movement commands on two ", " topics, one for teleoperation and one for autonomous control, typically ", ". Movement commands are multiplexed to a final topic for robot consumption. If any teleoperation command is received autonomous commands are blocked for a set time defined by the ", " parameter. ", "This node communicates with the ", " using a custom serial protocol described below. An example serial data packet could be 0,0.5,0.5 which would mean drive motors forward at half speed and rotate at half speed.   ", "The ", " microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers.  ", "We deploy the ", " to an Arduino microcontroller using PlatformIO. ", "More PlatformIO install info: ", " ", "More PlatformIO info: ", " ", "When a left and right joystick inputs are received by the ", " node, representing left and right wheel velocities (ie. skid steering or differential drive), a ", " with linear and rotational velocities is calculated as: ", "When a ", " containing linear and rotational velocities is received by the ", ", wheel velocities are calculated as: ", "Feature requests, bug reports, and contributions are welcome at ", ". "], "package_tt": ["joy", "teleop/cmd_vel", "servo_pos", "~servo_pan_speed", "int", "~servo_pan_max", "int", "~servo_pan_min", "int", "cmd_vel_mux", "block_duration", "teleop/cmd_vel", "move_base/cmd_vel", "cmd_vel", "block_duration", "~block_duration", "int", "(BYTE)\u00a00,\u00a0(FLOAT)\u00a0LINEAR_VELOCITY,\u00a0(FLOAT)\u00a0ANGULAR_VELOCITY", "(BYTE)\u00a02,\u00a0(FLOAT)\u00a0SERVO_ANGLE", "twist", "cmd_vel", "servo_pos", "~serial_dev", "string", "~baudrate", "int", "drive_firmware", "drive_firmware", "(left_speed\u00a0+\u00a0right_speed)\u00a0/\u00a02.0", "(right_speed\u00a0-\u00a0left_speed)\u00a0/\u00a02.0", "linear_speed\u00a0+\u00a0angular_speed", "linear_speed\u00a0-\u00a0angular_speed"], "package_code": ["$ sudo apt-get install ros-kinetic-simple-drive", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0\n", "$ roslaunch simple_drive cmd_vel_mux.launch\n", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0\n", "\n", "OR all-in-one launch:\n", "$ roslaunch simple_drive drive.launch", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0", "$ roslaunch simple_drive cmd_vel_mux.launch", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0", "$ sudo python -c \"$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)\"\n", "\n", "# Enable Access to Serial Ports (USB/UART)\n", "$ sudo usermod -a -G dialout <your username here>\n", "$ curl\u00a0https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules\u00a0\u00a0> /etc/udev/rules.d/99-platformio-udev.rules\n", "# After this file is installed, physically unplug and reconnect your board.\n", "$ sudo service udev restart", "$ roscd simple_drive\n", "$ cd ./drive_firmware/\n", "# Find the microcontroller that you have in the list of PlatformIO boards\n", "$ pio boards | grep -i mega2560\n", "# Use the name of your board to initialize your project\n", "$ pio init --board megaatmega2560", "$ vim src/main.cpp +4", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ vim src/main.cpp +17", "\n", "\n", "\n", "\n", "\n", "$ pio run --target upload"]},
{"url": "https://wiki.ros.org/rosruby_tutorials", "package": "rosruby_tutorials", "package_summary": ["rosruby_tutorials contains source codes of rosruby tutorials."], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains some samples for tutorials. Please refer to ", " for more detials. "]},
{"url": "https://wiki.ros.org/drc_com_common", "package": "drc_com_common", "package_summary": ["drc_com_common"]},
{"url": "https://wiki.ros.org/robot_state_publisher", "package": "robot_state_publisher", "package_summary": ["This package allows you to publish the state of a robot to\n    ", ". Once the state gets published, it is\n    available to all components in the system that also use ", ".\n    The package takes the joint angles of the robot as input\n    and publishes the 3D poses of the robot links, using a kinematic\n    tree model of the robot. The package can both be used as a library\n    and as a ROS node.  This package has been well tested and the code\n    is stable. No major changes are planned in the near future."], "package_details": [" ", "\n", " All fixed transforms are ", " by 0.5s. ", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", " (", ") ", " (", ") ", "robot_state_publisher uses the URDF specified by the parameter ", " and the joint positions from the topic ", " to calculate the forward kinematics of the robot and publish the results via ", ". ", "Please see the tutorial on ", ".  It will explain how you can publish the state of your robot to ", ", using the robot state publisher. "], "package_tt": ["tf", "tf", "tf", "tf", "tf", "tf", "tf", "tf", "tf", "tf", "robot_description", "joint_states", "joint_states", "robot_description", "urdf\u00a0map", "tf_prefix", "string", "publish_frequency", "double", "ignore_timestamp", "bool", "use_tf_static", "bool", "use_tf_static", "bool"]},
{"url": "https://wiki.ros.org/rocon_python_comms", "package": "rocon_python_comms", "package_summary": ["Service pair libraries for pub/sub non-blocking services."], "package_details": [" ", "\n", "\n", "\n", "Full details and usage examples are in the sphinx documentation (", "), the following is just a brief reference of what is available. "], "package_tt": ["find_xxx", "SubscriberProxy", "ServicePairs"]},
{"url": "https://wiki.ros.org/rosbag_pandas", "package": "rosbag_pandas", "package_summary": ["Create a Pandas data frame from a ros bag file."], "package_details": ["Python library (and some tools) for converting ", " to ", ". Check the Github page for examples and how to use: ", " "]},
{"url": "https://wiki.ros.org/smach", "package": "smach", "package_summary": ["SMACH is a task-level architecture for rapidly creating complex robot\n    behavior. At its core, SMACH is a ROS-independent Python library to build\n    hierarchical state machines. SMACH is a new library that takes advantage of\n    very old concepts in order to quickly create robust robot behavior with\n    maintainable and modular code."], "package_details": ["\n", " ", " ", " ", "\n", " ", "You can build a finite state machine using SMACH, but SMACH can do much more. SMACH is a library for task-level execution and coordination, and provides several types of \"state containers\". One such container, is a finite state machine, but this container can also be a state in another container. See the ", " for a list of containers and states built into SMACH. ", "The ", " provides an overview of the concepts used in SMACH. ", "The ", " contains an extensive set of tutorials to get you up to speed building and running your own state machines.  "]},
{"url": "https://wiki.ros.org/jackal_viz", "package": "jackal_viz", "package_summary": ["Visualization launchers and helpers for Jackal."], "package_details": ["\n", "\n", "\n", "This package provides launchers and ", " configurations to assist with visualizing real or simulated ", " from a desktop environment. For help getting your desktop environment set up to use with Jackal, see the ", ". ", "For more information on simulating Jackal, see ", ". ", "For more examples, see ", ". "], "package_tt": ["robot", "navigation", "2D\u00a0Nav\u00a0Goal", "gmapping", "localization", "2D\u00a0Pose\u00a0Estimate"], "package_code": ["roslaunch jackal_viz view_model.launch", "roslaunch jackal_viz view_robot.launch", "roslaunch jackal_viz view_robot.launch config:=navigation"]},
{"url": "https://wiki.ros.org/omip", "package": "omip", "package_summary": ["This metapackage groups all the packages for Online Multimodal Interactive Perception (OMIP)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "(Main author) Roberto Mart\u00edn-Martin (", ", ", ") ", "Sebastian H\u00f6fer (", ", ", ") ", "Oliver Brock (", ") ", "1. ", ". Three estimation levels: feature tracking, feature-based rigid body tracking, kinematic model estimation. This option can execute only using RGB-D images and therefore requires less computational power.  ", "To try this option, download one of the rosbags with the \"_imgs\" suffix and launch OMIP using the option \"--omip=1\" (or \"--omip=2\" if you want that the terminals  ", "remain open after finishing the execution, for debugging purposes). ", "More frequent problem: The feature tracking is not running and looks like frozen -> Check in feature_tracker/cfg/feature_tracker_cfg.yaml the depth_img_topic name. Depending if you are using ", "openni or openni2 (or rosbags generated from one or the other package) the name of the topic for the depth maps is different. ", "Based on the recursive estimation schema - prediction/correction -  our framework can cope with the high amount of data provided by the robot's sensors ", ". ", "The key (and the main idea of our framework) is to factorize the perceptual problem into smaller *perceptual units*, solve them with single recursive estimation loops and connect all the loops tightly.  ", "The connection of the loops defines a bidirectional information flow between loops: a bottom-up flow to pass estimations as measurements to more abstract levels, and a top-down flow to pass predicted measurements as predicted next states to less abstract levels. ", "By connecting the loops our framework can interpret the combined sensor-action stream as evidence of concepts of different level of abstraction. ", "Each recursive estimation level is realized as a ROS node that implements the interface ", ".  ", "A recursive estimation level is defined by: ", "* Measurement ", "* State ", "* Priors: ", "Internally, each level contains at least one recursive estimation filter. These filters implement the interface ", ". ", "The levels call the corresponding correct-predict methods of the filters and pass the measurements/states up and down. "], "package_tt": ["rosrun\u00a0omip_launch\u00a0omip.sh\u00a0--help"], "package_code": ["git clone https://github.com/tu-rbo/omip.git\n", "git clone https://github.com/tu-rbo/omip_msgs.git", "gsettings set org.gnome.desktop.default-applications.terminal exec 'gnome-terminal'", "cp ~/.config/terminator/config ~/.config/terminator/config.bak\n", "cp omip/omip_launch/cfg/terminator/config ~/.config/terminator/", "sudo apt-get install ros-indigo-pcl-ros ros-indigo-openni-launch ros-indigo-openni-camera\n", "ros-indigo-openni2-launch ros-indigo-openni2-camera ros-indigo-cmake-modules", "sudo apt-get install ros-indigo-bfl", "sudo cp omip/omip/third_party/bflConfig.cmake /opt/ros/indigo/share/bfl/", "git clone https://github.com/roberto-martinmartin/rviz_plugin_camerarenderpublisher.git", "git clone https://github.com/laas/rviz_plugin_covariance.git", "sudo apt-get install ros-indigo-libpointmatcher", "sudo cp your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake.bak", "sudo cp omip/omip/third_party/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/", "touch omip/shape_tracker/CATKIN_IGNORE", "catkin build (omip)", "rosbag decompress rosbagname.bag", "rosrun omip_launch omip.sh --omip=1 --rgbd=0", "rosrun omip_launch omip.sh --help", "rosbag play rosbagname.bag"]},
{"url": "https://wiki.ros.org/smach_ros", "package": "smach_ros", "package_summary": ["The smach_ros package contains extensions for the SMACH library to\n    integrate it tightly with ROS.  For example, SMACH-ROS can call\n    ROS services, listen to ROS topics, and integrate\n    with ", "\n    both as a client, and a provider of action servers.  SMACH is a\n    new library that takes advantage of very old concepts in order to\n    quickly create robust robot behavior with maintainable and modular\n    code."], "package_details": ["\n", "For example, if you want to call an ", " action from SMACH, you can of course write a ", ", which would look something like this: ", "But you can call that same action with much less coding, using the SimpleActionState: ", "SMACH ROS offers the same type of support for ROS services and ROS topics. For more details take a look at the ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rocon_python_utils", "package": "rocon_python_utils", "package_summary": ["Python system and ros utilities."], "package_details": [" ", "\n", "\n "], "package_tt": ["ping", "which", "Popen"]},
{"url": "https://wiki.ros.org/rh_p12_rn_base_module_msgs", "package": "rh_p12_rn_base_module_msgs", "package_summary": ["This package includes ROS messages and services for the rh_p12_rn packages"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/rbcar_robot_control", "package": "rbcar_robot_control", "package_summary": ["The rbcar_robot_control package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ROS", "package": "ROS", "package_summary": ["ROS packaging system"], "package_details": ["\n", "\n", " ", " ", " ", " ", " ", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "For an overview of ROS, please read the ROS ", ". ", "In ROS Diamondback, the ", " stack was separated into four stacks as part of ", ".  REP 100 describes these changes and why they were made.  In summary: "], "package_tt": ["ros", "ros"]},
{"url": "https://wiki.ros.org/robotis_controller_msgs", "package": "robotis_controller_msgs", "package_summary": ["This package includes ROS messages and services for robotis_framework packages"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14691/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20290/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/kobuki_softapps", "package": "kobuki_softapps", "package_summary": ["The kobuki_softapps package"]},
{"url": "https://wiki.ros.org/android_remocons", "package": "android_remocons", "package_summary": ["Remote controllers for rocon appable robots."], "package_details": ["\n", "\n", "This stack includes code for the android remocon and libraries for development of remocon usable android applications. The remocon is used on the ", ". Refer to the ", " page for more information. "]},
{"url": "https://wiki.ros.org/rosjava_extras", "package": "rosjava_extras", "package_summary": ["Extra packages for rosjava_core"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rmp_description", "package": "rmp_description", "package_summary": ["The rmp_description package provides Unified Robot Description Format files to represent a Segway Robotics Mobility Platform."], "package_details": ["\n", "\n", "The rmp_description package provides Unified Robot Description Format files (", ") to represent a Segway Robotics Mobility Platform. "], "package_code": ["$ roslaunch rmp_description display_model.launch", "$ export DEBUG_URDF=true"]},
{"url": "https://wiki.ros.org/rqt_mrta", "package": "rqt_mrta", "package_summary": ["The rqt_mrta package"], "package_details": ["\n", "\n", " ", "\n", " ", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "[1]", " Gerkey, Brian P., and Maja J. Matari\u0107. ", " The International Journal of Robotics Research 23.9 (2004): 939-954. "]},
{"url": "https://wiki.ros.org/pcl", "package": "pcl", "package_summary": ["\n\n", "\n  ", " - ", "oint ", "loud ", "ibrary: a comprehensive open\n  source library for ", " and ", ".\n  The library contains numerous state-of-the art algorithms for: filtering,\n  feature estimation, surface reconstruction, registration, model fitting and\n  segmentation, etc.  \n"], "package_details": [" ", "\n", "\n", "\n", "\n", " ", "The Point Cloud Library (PCL) is a stand-alone C++ library for 3D point cloud processing. You can learn more about PCL by visiting its website, ", ". The documentation on ROS.org will help you get started using PCL in your ROS applications.   ", "For information about how to use PCL's ROS-specific data types and how to publish and subscribe to point cloud data, please consult the ", ".   ", "You can find numerous code examples on PCL's ", ". ", "For examples of how to include PCL code in a ROS node, please refer to the  ", " page. ", "For a reference guide to PCL's ROS-specific APIs, see the ", " for the ", " package. "]},
{"url": "https://wiki.ros.org/asr_cyberglove_visualization", "package": "asr_cyberglove_visualization", "package_summary": ["This package is used to test the functionalities of the CyberGloves and FlockOfBirds. \n    It uses an URDF model of a human hand to provide a visualization of the glove movements in RViz."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The asr_cyberglove_visualization package is used to test and visualize the functionalities of the ", " and ", " packages. It uses an URDF model of a human hand to provide a visualization of the movement data from the gloves and the magnet tracking system (Flock of Birds) in RViz. ", "To use im combination with ", " and ", " the following hardware components are needed: ", "RViz has to be configured to show/add the RobotModel. The RViz configuration files located in ", " can be used when launching to provide an ideal view of the model and its movements in RViz. They are included in the launch files. ", "The sensor data of the Cybergloves is received as ", "messages published by the asr_cyberglove_lib server. The topics to listen to are: ", "The pose data of the Flock of Birds trackers is received as ", " messages published by the asr_flock_of_birds server. The topic to listen to is: ", "The current Cyberglove state data is published to the model as ", " messages. They are published to the following topic: ", "The Flock of Birds data is published using a ", ". "], "package_code": ["roslaunch asr_cyberglove_lib glove_lib.launch\n", "\n", "roslaunch asr_flock_of_birds flock_of_birds.launch", "rosrun asr_cyberglove_lib glove_lib_remote.sh\n", "\n", "rosrun asr_flock_of_birds flock_of_birds_remote.sh"]},
{"url": "https://wiki.ros.org/jackal_simulator", "package": "jackal_simulator", "package_summary": ["Packages for simulating Jackal."], "package_details": ["\n", "\n", "To work with simulated Jackal on your own machine, make sure if have ", " set up, and install the metapackages for desktop and simulation: ", "Please see ", ". "], "package_code": ["sudo apt-get install ros-indigo-jackal-simulator ros-indigo-jackal-desktop"]},
{"url": "https://wiki.ros.org/ros_mppt", "package": "ros_mppt", "package_summary": ["MPPT message sender package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", " MPPT data registration into a xls file for experimental purposes. ", " MPPT ROS package. ", "\n", "\n", " VE.Direct Protocol - Version 3.25. ", " BlueSolar HEX protocol MPPT. ", " ", "\n", " ", " ", " ", " "], "package_code": ["sudo apt-get install ros-kinetic-ros_mppt", "$ git clone https://github.com/AaronPB/ros_mppt.git", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "float64 v_bat\n", "float64 i_bat\n", "float64 v_pv\n", "float64 p_pv", "float64 v_bat\n", "float64 i_bat\n", "float64 v_pv\n", "float64 p_pv\n", "int32 error_mppt", "$ cd ~/catkin_ws\n", "$ catkin_make\n", "$ . ~/catkin_ws/devel/setup.bash", "$ rosrun roscore\n", "$ rosrun ros_mppt vemppt_ros.py", "$ rosbag -a"]},
{"url": "https://wiki.ros.org/raspigibbon_bringup", "package": "raspigibbon_bringup", "package_summary": ["The raspigibbon_bringup package"]},
{"url": "https://wiki.ros.org/ros_statistics_msgs", "package": "ros_statistics_msgs", "package_summary": ["ROS Host and Node Statistics Messages"], "package_details": ["These messages are used with the ", " package's tools. "]},
{"url": "https://wiki.ros.org/rqt_capabilities", "package": "rqt_capabilities", "package_summary": ["rqt package for visualization and management of capabilities"]},
{"url": "https://wiki.ros.org/langs", "package": "langs", "package_summary": ["Meta package modeling the run-time dependencies for language bindings of messages."]},
{"url": "https://wiki.ros.org/kobuki_soft", "package": "kobuki_soft", "package_summary": ["Soft kobuki impementation meta package"], "package_details": ["\n", "Please refer ", " Wiki "]},
{"url": "https://wiki.ros.org/rqt_alliance", "package": "rqt_alliance", "package_summary": ["The rqt_alliance package"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/elevator_move_base_pr2", "package": "elevator_move_base_pr2", "package_summary": ["\n\n     elevator_move_base_pr2\n\n  "], "package_details": ["\n", "\n", " and ", " ", "Documentation is available ", ". ", "Use trac to report ", " or ", ". ", " "]},
{"url": "https://wiki.ros.org/simple_robot_control", "package": "simple_robot_control", "package_summary": ["\n\n     Simple C++ and python interface to move the arms, head, base, torso and grippers of a PR2 robot.\n\n  "], "package_details": ["\n"], "package_code": ["launch/simple_robot_control_without_collision_checking.launch", "launch/simple_robot_control.launch", "#include <ros/ros.h>\n", "\n", "#include <simple_robot_control/robot_control.h>\n", "\n", "\n", "int main(int argc, char** argv){\n", "\n", "\n", "\n", "        ros::init(argc, argv, \"robot_control_test_app\");\n", "        ros::NodeHandle nh;\n", "\n", "        //Create robot controller interface\n", "        simple_robot_control::Robot robot;\n", "\n", "        //look straight\n", "        robot.head.lookat(\"torso_lift_link\", tf::Vector3(0.1, 0.0, 0.0));\n", "\n", "        //do stuff with arms\n", "        robot.left_arm.tuck();\n", "        robot.right_arm.stretch();\n", "\n", "        //specify joint angles for two waypoints\n", "        double tuck_pos_right[] \n", "           = { -0.4,0.0,0.0,-2.25,0.0,0.0,0.0,\n", "               -0.01, 1.35, -1.92, -1.68, 1.35, -0.18,0.31};\n", "        std::vector<double> tuck_pos_vec(tuck_pos_right, tuck_pos_right+14);\n", "        robot.right_arm.goToJointPos(tuck_pos_vec);\n", "\n", "        robot.right_arm.stretch();\n", "\n", "        //grab position from above\n", "        robot.right_arm.moveGripperToPosition(tf::Vector3(0.6,-0.1, 0.0),    \n", "                 \"torso_lift_link\", simple_robot_control::Arm::FROM_ABOVE);\n", "        \n", "        //grab position frontal\n", "        robot.right_arm.moveGripperToPosition(tf::Vector3(0.8,-0.1, 0.1), \n", "                    \"torso_lift_link\", simple_robot_control::Arm::FRONTAL);\n", "\n", "        //specify grab pose with postion and orientation as StampedTransform\n", "        tf::StampedTransform tf_l (tf::Transform(tf::Quaternion(0,0,0,1), \n", "           tf::Vector3(0.8,0.1,0.0)),\n", "           ros::Time::now(),\"torso_lift_link\",\"doesnt_matter\");\n", "        robot.left_arm.moveGrippertoPose(tf_l);\n", "\n", "        //look at left gripper\n", "        robot.head.lookat(\"l_gripper_tool_frame\");\n", "\n", "        //drive 0.5m forward\n", "        robot.base.driveForward(0.5);\n", "\n", "        //raise torso to 10cm above lowest position\n", "        robot.torso.move(0.1);\n", "\n", "        return 0;\n", "\n", "}"]},
{"url": "https://wiki.ros.org/rbcar_gazebo", "package": "rbcar_gazebo", "package_summary": ["The rbcar_gazebo package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/manipulator_h_kinematics_dynamics", "package": "manipulator_h_kinematics_dynamics", "package_summary": ["The manipulator_h_kinematics_dynamics package\n    This packages provides library of kinematics and dynamics information for ROBOTIS MANIPULATOR-H.\n    Additionally, there are some function to calculate kinematics and dynamics."], "package_details": [" ", "\n", " "]},
{"url": "https://wiki.ros.org/robotnik_msgs", "package": "robotnik_msgs", "package_summary": ["The robotnik_msgs package. Common messages and services used by some Robotnik's packages."]},
{"url": "https://wiki.ros.org/sick_visionary_t", "package": "sick_visionary_t", "package_summary": ["Open source driver for the SICK Visionary-T 3D TOF camera."]},
{"url": "https://wiki.ros.org/mrp2_hardware", "package": "mrp2_hardware", "package_summary": ["Hardware files to communicate with MRP2 base."]},
{"url": "https://wiki.ros.org/schunk_lwa4p", "package": "schunk_lwa4p", "package_summary": ["schunk_lwa4p"]},
{"url": "https://wiki.ros.org/image_stream", "package": "image_stream", "package_summary": ["rosweb plugin to serve images as streams (MJPEG, Theora, FLV, etc)"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/nanomsg", "package": "nanomsg", "package_summary": ["The nanomsg package"], "package_details": ["\n", " is a very lightweight (smaller brother of zeromq) communications library accomodating various design patterns. It can be useful for specialised instances where ros doesn't really fit. e.g. Bridging connections to lightweight embedded boards or in grafting your own custom messaging architecture for a specific use case. ", "\n"]},
{"url": "https://wiki.ros.org/detect_cans_in_fridge_201202", "package": "detect_cans_in_fridge_201202", "package_summary": ["\n\n     detect_cans_in_fridge_201202\n\n  "], "package_details": ["\n", "\n", " and ", " ", "Documentation is available ", ". ", "Use trac to report ", " or ", ". ", " "]},
{"url": "https://wiki.ros.org/ackermann_qt", "package": "ackermann_qt", "package_summary": ["\n\n     Qt tele-operation interface for driving a vehicle with Ackermann\n     steering under human control.\n\n  "], "package_details": ["\n", "\n", "\n"], "package_tt": ["ackermann_cmd"], "package_code": ["rosrun ackermann_qt qteleop"]},
{"url": "https://wiki.ros.org/motoman_mpl80_moveit_config", "package": "motoman_mpl80_moveit_config", "package_summary": ["\n      MoveIt package for the Motoman MPL80.\n    ", "\n      An automatically generated package with all the configuration and launch\n      files for using the Motoman MPL80 with the MoveIt Motion Planning\n      Framework.\n    "], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/reemc_controller_configuration_gazebo", "package": "reemc_controller_configuration_gazebo", "package_summary": ["Gazebo-specifig launch files and scripts needed to configure\n    the controllers of the REEM-C robot in simulation."]},
{"url": "https://wiki.ros.org/agvs_common", "package": "agvs_common", "package_summary": ["URDF description of the Agvs and Agvs."], "package_details": ["\n", " ", "\n", "\n", "\n", " ", "This package contains the different controllers and launch files for the ", ", shared for real robot and simulation.  "]},
{"url": "https://wiki.ros.org/airbus_plugin_rviz", "package": "airbus_plugin_rviz", "package_summary": ["The airbus_plugin_rviz package"]},
{"url": "https://wiki.ros.org/shared_serial", "package": "shared_serial", "package_summary": ["\n\n    Shared serial port with locking functionality\n\n  "], "package_details": ["\n", "\n", "Use trac to ", " or ", " [ ", " ] "], "package_code": ["<launch>\n", "        <node name=\"motor_comm\" pkg=\"shared_serial\" type=\"server\">\n", "                <param name=\"port_name\" value=\"/dev/ttyUSB0\"/>\n", "                <param name=\"port_type\" value=\"RS485_FTDI\"/>\n", "                <param name=\"baud_rate\" value=\"921600\"/>\n", "        </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/raspigibbon_ros", "package": "raspigibbon_ros", "package_summary": ["The raspigibbon_ros package"], "package_details": ["\n", " ", "\n", "\n"]},
{"url": "https://wiki.ros.org/scriptable_monitor", "package": "scriptable_monitor", "package_summary": ["scriptable_monitoring"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "Suppose we have a node that publishes current CPU usage to the ", " topic. Each message contains an array named ", " with usage information for each core. We also have a topic with configuration information: ", ". ", "You can activate the script using rqt plugin - ", " "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " #! parameter_name parameter_value", " #! name cpu_monitor"]},
{"url": "https://wiki.ros.org/rbcar_sim", "package": "rbcar_sim", "package_summary": ["The rbcar_sim package. It contains RBCAR simulation packages"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "This package contains the different controllers and launch files for the ", " simulation. "]},
{"url": "https://wiki.ros.org/ridgeback_viz", "package": "ridgeback_viz", "package_summary": ["Visualization launchers and helpers for Ridgeback."], "package_details": ["\n", "\n", "\n", "This package provides launchers and ", " configurations to assist with visualizing real or simulated ", " from a desktop environment. For help getting your desktop environment set up to use with Ridgeback, see the ", ". "], "package_tt": ["robot", "navigation", "2D\u00a0Nav\u00a0Goal", "gmapping", "localization", "2D\u00a0Pose\u00a0Estimate"], "package_code": ["roslaunch ridgeback_viz view_model.launch", "roslaunch ridgeback_viz view_robot.launch", "roslaunch ridgeback_viz view_robot.launch config:=navigation"]},
{"url": "https://wiki.ros.org/rl_experiment", "package": "rl_experiment", "package_summary": ["rl_experiment is a package to run RL experiments using the rl_agent and rl_env packages."], "package_details": ["\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package provides a way of running reinforcement learning experiments with the agents from the ", " package and environments from the ", " package without using the ", " interface. Instead, the code instantiates agent and environment objects and calls their methods directly. It can be set to run for a particular number of episodes and trials, and prints out the sum of rewards for each episode to cerr. ", "There are a number of options available to set parameters of both the agent and environment used.  More details on the agent options are available in the ", " documentation, and more details on the env options are available in the ", " documentation. ", "In addition to these options, there a few variables that can be changed in the code, in the ", ". Near the top of the file are two variables: MAXSTEPS and NUMTRIALS. MAXSTEPS determines the maximum number of steps for an episode. A new episode will be started after this many steps even if the agent has not reached a terminal state. ", "As an example, here is how you would run Q-Learning (", ") on the stochastic Taxi task (", "): ", "Or to run real-time TEXPLORE (", ", ", ") at 10 Hz on the deterministic Fuel World task (", ") with 8 discrete trees: ", "While you should find that the qlearner, sarsa, dyna, and rmax agents work fine on the easier tasks (tworooms, taxi, etc), they will not converge within the default 1000 episodes on more complex tasks like Fuel World. As an example, here is how to run Q-Learning (", ") on the Fuel World task (", ") using the --nepisodes flag to run it for 1,000,000 episodes, which should be enough time for it to converge. ", "Another problem you may run into is when running these methods on the continuous domains (mcar, cartpole, car2to7, car7to2, and carrrandom). For these domains, the tabular RL methods (Q-Learning, SARSA, Dyna, R-Max) will need the state to be discretized. The following command will run Q-Learning (", ") on the Mountain Car task (", ") while discretizing each of the state features into 10 discrete values using the --nstates option. "], "package_code": ["rosrun rl_experiment experiment --agent type --env type [options]", "qlearner sarsa modelbased rmax texplore dyna savedpolicy", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_experiment experiment --agent qlearner --env taxi --stochastic", "rosrun rl_experiment experiment --agent texplore --nmodels 8 --planner parallel-uct --actrate 10 --env fuelworld --deterministic", "rosrun rl_experiment experiment --agent qlearner --env fuelworld --nepisodes 1000000", "rosrun rl_experiment experiment --agent qlearner --env mcar --nstates 10"]},
{"url": "https://wiki.ros.org/rbcar_control", "package": "rbcar_control", "package_summary": ["The rbcar_control package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mr_tools", "package": "mr_tools", "package_summary": ["Some useful nodes for multi-robot teleoperation"], "package_details": ["\n", "\n", " ", "\n", "\n", "This package contains 2 nodes that communicate with the input devices and publishes ", " to an arbitrary number of output topics, which allows control over a multiple number of robots. "], "package_tt": ["joy_cmd_vel", "dev", "string", "\"/dev/input/js0\"", "*input_topics\u00a0parameter*", "set_input", "set_output", "*input_topics\u00a0parameter*", "current_input", "current_output", "input_topics", "dictionary", "output_topics", "list\u00a0of\u00a0strings"]},
{"url": "https://wiki.ros.org/ros_package_web_server", "package": "ros_package_web_server", "package_summary": ["Web server to host ROS package content"], "package_details": ["\n", "\n", "\n", "A webserver that serves ROS package resources. This is useful with ", " for serving resources that would normally be found with rospack. For example when displaying a URDF using ", " the robot model files must be served from somewhere. This package allows for these models to be served directly from the install location instead of having to copy resources to a separate web root. Resources are served with CORS enabled to allow for easy interop with resources served elsewhere. Navigating to the root path will display a list of all installed packages. Resources can then be loaded using by prefixing the path of the resource relative to the share location of the package. For installed packages this is in the share folder in the install location and for non-installed packages this is the package root. "], "package_tt": ["~port", "int"]},
{"url": "https://wiki.ros.org/rosprofiler", "package": "rosprofiler", "package_summary": ["The rosprofiler package provides the rosprofiler and rosgrapher tools.\n      These tools run as nodes publishing their collected information on ros topics.\n      They have been designed to work with the Topic Statistics feature found\n      in ROS Indigo to provide a complete picture of a ROS System."], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", "\n", "\n", "\n", " (", ") ", "The rosprofiler package is commonly used with ", ". "], "package_tt": ["/host_statistics", "/node_statistics", "/topology"], "package_code": ["rosparam set enable_statistics true", "rosrun rosprofiler rosprofiler", "rosrun rosprofiler rosgrapher"]},
{"url": "https://wiki.ros.org/airbus_ssm_tutorial", "package": "airbus_ssm_tutorial", "package_summary": ["The airbus_ssm_tutorial package"]},
{"url": "https://wiki.ros.org/cob_sick_s300", "package": "cob_sick_s300", "package_summary": ["This package published a laser scan message out of a Sick S300 laser scanner."], "package_details": ["\n", "\n", "\n", "The ", " package provides two configurable nodes for operating with the scanners. ", "\n", "This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g. ", " in the ", " stack. ", "For starting use: ", "All hardware configuration is done in the ", " package. A sample parameter file in \"cob_hardware_config/cob3-3/config/laser_front.yaml\" could look like this "], "package_tt": ["cob_sick_s300", "scan", "scan_standby", "/diagnostics", "port", "string", "baud", "int", "scan_duration", "int", "scan_cycle_time", "int", "inverted", "boolean", "scan_id", "int", "frame_id", "string", "publish_frequency", "int", "cob_scan_filter", "scan_in", "scan_out", "scan_intervals", "list\u00a0of\u00a0scan\u00a0intervals"], "package_code": ["roslaunch cob_bringup laser_front.launch\n", "roslaunch cob_bringup laser_rear.launch", "<include file=\"$(find cob_bringup)/components/laser_front.launch\" />\n", "<include file=\"$(find cob_bringup)/components/laser_rear.launch\" />", "port: /dev/ttyScan1\n", "baud: 500000\n", "scan_duration: 0.025 #no info about that in SICK-docu, but 0.025 is believable and looks good in rviz\n", "scan_cycle_time: 0.040 #SICK-docu says S300 scans every 40ms\n", "inverted: true\n", "scan_id: 7\n", "frame_id: /base_laser_front_link\n", "scan_intervals: [[-1.3526, 1.361357]] #[rad] these intervals are included to the scan"]},
{"url": "https://wiki.ros.org/rocon_app_manager_msgs", "package": "rocon_app_manager_msgs", "package_summary": ["Messages used by the platform app manager."]},
{"url": "https://wiki.ros.org/simple_arm", "package": "simple_arm", "package_summary": ["Simple velocity controlled arm. Teleoperation software and firmware."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", " Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. ", "\n", " We like PlatformIO: \"Single source code. Multiple platforms.\" PlatformIO supports approximately 200", " and all major", ". Learn more on", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", "\n", "A simple arm system. ", ": ", "This package ", ": ", "This diagram is also available in ", ". ", "Package created by Ryerson University students for the ", ", summer 2017. ", "3. Install the ", " onto a microcontroller connected to the arm joint motors by PWM. The microcontroller must also be connected to the computer running the simple_arm ROS node by a serial connection (ex. USB). ", "This node converts ", " messages from the ", " node into a variety of commands that are sent over serial to a microcontroller to drive the robot arm. ", "This node communicates with the ", " using a simple serial protocol. Each serial motion command is a list of floats, one for each joint. ", "The ", " microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers. ", "We deploy the ", " to an Arduino microcontroller using PlatformIO. ", "More PlatformIO install info: ", " ", "More PlatformIO info: ", " ", "Feature requests, bug reports, and contributions are welcome at ", ". "], "package_tt": ["joy_arm", "~microcontroller_serial_device", "string", "~baudrate", "int", "arm_firmware", "arm_firmware"], "package_code": ["$ sudo apt-get install ros-kinetic-simple-arm", "$ roslaunch simple_arm simple_arm.launch joystick_serial_dev:=/dev/input/js0 microcontroller_serial_dev:=/dev/ttyACM0", "(FLOAT) GRIP,\n", "(FLOAT) WRIST_ROLL,\n", "(FLOAT) WRIST_PITCH,\n", "(FLOAT) UPPER_ELBOW,\n", "(FLOAT) LOWER_ELBOW,\n", "(FLOAT) BASE_YAW,\n", "(FLOAT) CAMERA", "$ sudo python -c \"$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)\"\n", "\n", "# Enable Access to Serial Ports (USB/UART)\n", "$ sudo usermod -a -G dialout <your username here>\n", "$ curl\u00a0https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules\u00a0\u00a0> /etc/udev/rules.d/99-platformio-udev.rules\n", "# After this file is installed, physically unplug and reconnect your board.\n", "$ sudo service udev restart", "$ roscd simple_arm\n", "$ cd ./arm_firmware/\n", "# Find the microcontroller that you have in the list of PlatformIO boards\n", "$ pio boards | grep -i mega2560\n", "# Use the name of your board to initialize your project\n", "$ pio init --board megaatmega2560", "$ vim src/main.cpp +9", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ vim src/main.cpp +4", "\n", "\n", "\n", "\n", "\n", "$ pio run --target upload"]},
{"url": "https://wiki.ros.org/kingfisher_teleop", "package": "kingfisher_teleop", "package_summary": ["\n    This package contains launch files which enable simple \n    teleoperation of the Clearpath Robotics Kingfisher.\n  "], "package_details": [" ", " "]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14692/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20291/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/neo_msgs", "package": "neo_msgs", "package_summary": ["This package contains copies of former pr2_msgs (ported to ROS indigo) \n\tas well as new messages for neobotix robots."]},
{"url": "https://wiki.ros.org/libviso2", "package": "libviso2", "package_summary": ["\n\n    This is a ROS-Package for libviso2, a library for visual odometry created by Andeas Geiger\n    from the Institute of Measurement and Control Systems at Karlsruhe Institute of Technology.\n\n    Apart from the original libviso2 sources, this package contains\n    a CMakeFile for easier integration into the ROS build system.\n\n    Please note that this code is licensed under GPL. For a commercial usage, please\n    contact Andreas Geiger directly (see\n    ", ").\n\n  "], "package_details": ["See the ", " package for nodes that use this library. ", "Related publications can be found ", ". The main paper that describes this library is: "], "package_code": ["@INPROCEEDINGS{Geiger11,\n", " author = {Andreas Geiger and Julius Ziegler and Christoph Stiller},\n", " title = {StereoScan: Dense 3d Reconstruction in Real-time},\n", " booktitle = {IEEE Intelligent Vehicles Symposium},\n", " year = {2011},\n", " month = {June},\n", " address = {Baden-Baden, Germany}\n", "}"]},
{"url": "https://wiki.ros.org/rb1_base_sim", "package": "rb1_base_sim", "package_summary": ["The rb1_base_sim metapackage"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", " simulation.  "]},
{"url": "https://wiki.ros.org/rocon_bubble_icons", "package": "rocon_bubble_icons", "package_summary": ["Bubble icon library for rocon."], "package_details": [" ", "\n", "\n"]},
{"url": "https://wiki.ros.org/multi_jackal_tutorials", "package": "multi_jackal_tutorials", "package_summary": ["Tutorials for multi-Jackal simulations."], "package_details": ["\n", " provides examples on how to simulate multiple ", " in Gazebo. ", " ", "\n", "\n", "\n", " ", " ", " ", "\n", " ", "\n", " ", "Gazebo will be generating the ROS clock, so it can simulate faster or slower than real time (this is set in the world description). If ", " is set to ", ", the Gazebo client will also appear. This can also be done after launching by running ", " in a new terminal. ", "The namespace ", " must be unique (like jackal0, jackal1, etc), so that individual robots can be identified. The configuration type ", " specifies the components on the jackal. This string must match a file located in ", ". The configuration ID ", " is used if required by the configuration. Movement to goal locations is provided through ", ". The model description (", "), navigation (", "), and controllers (", "), are all called through the Jackal base (", "). ", "Frames have also been prefixed by the namespace (right click -> view image to zoom in): ", "A number of arguments can be specified when creating a Jackal. These are listed in (", "). "], "package_tt": ["multi_jackal_tutorials", "gui", "true", "gzclient", "ns", "config", "config_id"], "package_code": ["rosdep install multi_jackal_tutorials", "sudo apt-get install ros-kinetic-multi-jackal-tutorials", "roslaunch multi_jackal_tutorials one_jackal.launch rviz:=true", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "roslaunch multi_jackal_tutorials two_jackal.launch rviz:=true", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rr_swiftnav_piksi", "package": "rr_swiftnav_piksi", "package_summary": ["Rover Robotics: ROS package for connecting to SwiftNav Piksi"], "package_details": ["\n", " ", "Install binaries via aptitude package manager ", " ", "Install source from github (only use if you want to make custom changes to the source code) ", "\n", "\n", "\n", "This package requires ", "'s ", ". Install before installing this package.  "], "package_tt": ["swiftnav_piksi_tcp_node", "/swift_nav/enable_comms", "/cmd_vel/managed", "/swift_gps/llh/position", "/swift_gps/llh/fix_mode", "/swift_gps/llh/n_sats", "/swift_gps/baseline/ecef/position", "/swift_gps/imu/raw", "~piksi_ip_address", "string", "1.2.3.10", "~piksi_port", "string", "~base_station_ip_address", "string", "111.111.111.111", "~piksi_port", "string", "~computer_ip_address", "string", "1.2.3.55"], "package_code": ["sudo apt install ros-kinetic-rr-swiftnav-piksi", "cd ~/catkin_ws/src/\n", "git clone https://github.com/RoverRobotics/rr_swiftnav_piksi.git\n", "cd ~/catkin_ws/\n", "catkin_make\n", "source devel/setup.bash", "rosrun rr_swiftnav_piksi swiftnav_piksi_tcp.py"]},
{"url": "https://wiki.ros.org/rbcar_sim_bringup", "package": "rbcar_sim_bringup", "package_summary": ["The rbcar_sim_bringup package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/smach_viewer", "package": "smach_viewer", "package_summary": ["The smach viewer is a GUI that shows the state of hierarchical\n    SMACH state machines. It can visualize the possible transitions\n    between states, as well as the currently active state and the\n    values of user data that is passed around between states. The\n    smach viewer uses the SMACH debugging interface based on\n    the ", " to gather information from running state machines."], "package_details": ["\n", " Your state machine needs to run an introspection server to allow the smach viewer to connect to it. See ", " for more details. ", " ", "\n", "\n", " ", "\n", " ", "\n", " "], "package_code": ["rosrun smach_viewer smach_viewer.py"]},
{"url": "https://wiki.ros.org/jaco_teleop", "package": "jaco_teleop", "package_summary": ["Various Nodes for Teleoperating the JACO Arm"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package provides various methods for human control of the JACO and JACO2 arm via keyboard teleoperation and joystick/gamepad teleoperation.  This may work for the MICO as well, but it has not yet been tested. ", "The joystick teleop node currently supports both gamepads with analog triggers and gamepads with digital triggers.  The gamepad type can be set on launch with the ", " parameter.  Currently, the node has been tested with the Logitech Dual Action wired controller (digital triggers), the Logitech Wireless Gamepad (analog triggers), and the Microsoft XBOX 360 wired controller (analog triggers).  If your gamepad does not work with this node, you can remap the axes and buttons using ", " package, or open an issue in the code repository and support for the new controller may be added. ", "To install the ", " package, you can install from source with the following commands: ", "Joystick or keyboard teleop can be started with the launch files ", " and ", ", respectively.  Both files have parameters for velocity limits, which can be set on launch to limit the velocities of the arm's translation, rotation, and finger movement.  Furthermore, ", " includes a parameter for the controller type, which can currently be set to either \"analog\" or \"digital\", representing controllers with analog triggers and digital triggers, respectively. Example launch syntax is given below. "], "package_tt": ["jaco_teleop", "joy", "jaco_arm/angular_cmd", "jaco_arm/cartesian_cmd", "jaco_arm/software_estop", "linear_throttle_factor", "double", "angular_throttle_factor", "double", "finger_throttle_factor", "double", "controller_type", "string", "wpi_jaco/arm_name", "string", "jaco_arm/angular_cmd", "jaco_arm/cartesian_cmd", "linear_throttle_factor", "double", "angular_throttle_factor", "double", "finger_throttle_factor", "double", "wpi_jaco/arm_name", "string", "controller_type", "wpi_jaco", "jaco_joy_teleop.launch", "jaco_key_teleop.launch", "jaco_joy_teleop.launch"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch jaco_teleop jaco_joy_teleop.launch", "roslaunch jaco_teleop jaco_key_teleop.launch", "roslaunch jaco_teleop jaco_joy_teleop.launch linear_throttle_factor:=0.5 angular_throttle_factor:=0.5 finger_throttle_factor:=0.75 controller_type:=\"analog\"", "roslaunch jaco_teleop jaco_key_teleop.launch linear_throttle_factor:=0.5 angular_throttle_factor:=0.5 finger_throttle_factor:=0.75"]},
{"url": "https://wiki.ros.org/multi_jackal_description", "package": "multi_jackal_description", "package_summary": ["Spawns the Jackal model."], "package_details": ["\n", " contains the robot model description for a ", ". It has been extended from the single robot ", " to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time. ", "\n", " ", "There are tutorials on how to spawn robots using this package in ", ". "], "package_tt": ["multi_jackal_description"]},
{"url": "https://wiki.ros.org/asr_kinematic_chain_dome", "package": "asr_kinematic_chain_dome", "package_summary": ["This package provides information about the PbD dome's kinematic chain and contains launch-files to publish the chain to a robot_state_publisher. Available launchfiles are: dome with real PTU, dome with simulated PTU, dome with real PTU and Flock of Birds and additional transformation_publisher from guppy-cameras to the kinect cameras mounted above. It also contains the urdf model."], "package_details": [" ", "\n", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", "\n", "\n", "The kinematic chain consists of two major parts: The camera-system (PTU, Guppy-Cameras and Kinect) and the Flock of Birds magnet tracking system (Receiver and Tracker). Colors form the picture above. The fixed reference Frame is in the PTU and is called ", ". There is an identity transformation to ", " which is mostly used. ", "The TF is published at topic /tf. The visualization is available in the RobotModel. ", "start rviz and", " "], "package_code": ["roslauch asr_kinematic_chain_dome dome_mock.launch", "roslauch asr_kinematic_chain_dome dome.launch", "rosrun asr_kinematic_chain_dome dome_with_fob.sh", "roslauch asr_kinematic_chain_dome transformation_publishers_for_kinect_left.launch"]},
{"url": "https://wiki.ros.org/map_store", "package": "map_store", "package_summary": ["\n\n     Storage manager for OccupancyGrid maps.  Supports naming the most\n     recent map, getting a list of map names, and publishing a\n     specific map.\n\n  "], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/reemc_gazebo", "package": "reemc_gazebo", "package_summary": ["Simulation files for the REEM-C robot."]},
{"url": "https://wiki.ros.org/soem_ebox", "package": "soem_ebox", "package_summary": ["This package contains the components of the soem_ebox package"]},
{"url": "https://wiki.ros.org/rocon_rosjava_core", "package": "rocon_rosjava_core", "package_summary": ["Rocon related libraries in rosjava."], "package_details": ["\n", "For more information on the interactions framework, refer to ", " and example android development, refer to the ", " main page. "]},
{"url": "https://wiki.ros.org/agvs_sim", "package": "agvs_sim", "package_summary": ["agvs Gazebo simulation packages"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "This package contains the different controllers and launch files for the ", " simulation.  ", "1. ", " "]},
{"url": "https://wiki.ros.org/agvs_sim_bringup", "package": "agvs_sim_bringup", "package_summary": ["The agvs_sim_bringup package. It contains multiple launch files to perform different tasks, from creating a map with gmapping to launching amcl."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mrpt_sensors", "package": "mrpt_sensors", "package_summary": ["ROS nodes for various robotics sensors via mrpt-hwdrivers"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "ROS nodes for various robotics sensors via ", ". "]},
{"url": "https://wiki.ros.org/ros_topology_msgs", "package": "ros_topology_msgs", "package_summary": ["Messages describing the topology of the ros graph."], "package_details": ["These messages are used with the tools in the ", " package. "]},
{"url": "https://wiki.ros.org/self_test", "package": "self_test", "package_summary": ["self_test"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "You can get a list of the available subtests with the rosservice command:", "You can then run the self test using rosservice:", "You can get different output with the ", " ", " node: ", "The ", " class will advertise a service \"~self_test\". When called, it will perform a check on the node's connection status, and any other checks a developer wants to perform on a node or device. ", "An example use of the self_test package's API can be found in ", ". ", "self_test contains the ", " class that can be used to sequence a set of tests to be run in order to test a device. It advertises a self_test service. When the service is called, the ", " calls the tests that have been defined in order, and combines the results into a ", " array (see the service definition ", "). A detailed example can be found in ", ". "], "package_tt": ["run_selftest", "self_test::TestRunner", "~node_to_test", "string", "~max_delay", "string", "self_test"], "package_code": ["$ rosservice list | grep \"/self_test$\"\n", "/hokuyo_node/self_test", "$ rosservice call /hokuyo_node/self_test", "$ rosrun self_test run_selftest /hokuyo_node/self_test"]},
{"url": "https://wiki.ros.org/rtt_typelib", "package": "rtt_typelib", "package_summary": ["\n    "]},
{"url": "https://wiki.ros.org/jackal_desktop", "package": "jackal_desktop", "package_summary": ["Packages for working with Jackal from a ROS desktop."], "package_details": ["To get started using Jackal from a desktop ROS environment, see ", ". "]},
{"url": "https://wiki.ros.org/abb_irb4400_support", "package": "abb_irb4400_support", "package_summary": ["\n      ROS-Industrial support for the ABB IRB 4400 (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for ABB IRB 4400 manipulators. This currently includes the L30.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", " (Article No: 3HAC 8770-1).\n      All urdfs / xacros are based on the default motion and joint velocity\n      limits, unless noted otherwise (ie: no support for high speed joints,\n      extended / limited motion ranges or other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/micros_hopfield", "package": "micros_hopfield", "package_summary": ["A package for path planning"], "package_details": ["\n", "\n", "\n", "\n", "Run these commands under ~/catkin_ws directory for the terrain map loading. ", "run different clients in independent terminal. ", "\n", " ", "The package is inspired by and adapted from [1]. Related details about neural network based path planning may also be found in  ", "], ", "] and ", "]. ", "\n"], "package_code": ["cd catkin_ws/src\n", "git clone http://github.com/micros-uav/micros_hopfield\n", "cd ..\n", "catkin_make", "rosrun rviz rviz", "source devel/setup.bash\n", "rosrun micros_hopfield plan_server", "source devel/setup.bash\n", "rosrun micros_hopfield plan_client i"]},
{"url": "https://wiki.ros.org/robot_markers", "package": "robot_markers", "package_summary": ["Generates markers for a robot"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " is a library for creating ", " for a robot, given a ", ". ", " ", "\n", " is the main interface for building a ", " from a URDF. ", "The library's generated documentation explains how to use ", ". ", "First, create a ", " for a given URDF: ", "A notable feature of ", " is the ability to set the joint angles of the robot. ", "To do so, pass in a map that gives the joint angles for a set of joint names. ", " does not check joint angle limits. ", "Once you have configured the visualization, call ", ", passing in a marker array to append the robot markers to. "], "package_tt": ["robot_markers", "robot_markers", "Builder", "Builder", "Builder", "Builder::Build"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/kvh", "package": "kvh", "package_summary": ["A driver for the KVH DSP-3000 single-axis Fiber Optic Gyroscope."]},
{"url": "https://wiki.ros.org/multi_jackal_control", "package": "multi_jackal_control", "package_summary": ["Creates the joint and velocity controllers."], "package_details": ["\n", " contains the launch files and parameters providing joint and velocity controllers for multiple simulated ", ". It has been extended from the single robot ", " to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  ", "\n", "There are tutorials on how to use this package in ", ". "], "package_tt": ["multi_jackal_control"]},
{"url": "https://wiki.ros.org/reemc_simulation", "package": "reemc_simulation", "package_summary": ["REEM-C-specific simulation components. These include plugins\n               and launch scripts necessary for running REEM-C in simulation."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/r2_moveit_config", "package": "r2_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the r2 with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/mm_messages", "package": "mm_messages", "package_summary": ["Message definitions and serialisations for core messages."]},
{"url": "https://wiki.ros.org/soem_beckhoff_drivers", "package": "soem_beckhoff_drivers", "package_summary": ["soem_beckhoff_drivers contains drivers for the ethercat beckhoff modules to work together with the soem_master package, every module creates the necessary services, dataports and properties for its own functionality."]},
{"url": "https://wiki.ros.org/rocon_device_msgs", "package": "rocon_device_msgs", "package_summary": ["Messages used by rocon devices"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ros_in_hand_scanner", "package": "ros_in_hand_scanner", "package_summary": ["The ros_in_hand_scanner package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "This ", " shows a scanning process using Intel ", " Camera. ", "This package needs PCL 1.8.0 to be installed. See ", " for further information. ", "Due to performance issues, a realtime registration is very slow with down to < 0.1 fps. ", "A workaround is to record a rosbag file during the scanprocess itself. You can use the preview window to get a view of your actual scan orientation. ", "Play the rosbag file afterwards with a low rate ~0.1 and start registration now. ", "Follow the hints in the PCL documentation for your scan process. "], "package_tt": ["camera/depth_registered/points"], "package_code": ["#Prepare Workspace\n", "source /opt/ros/indigo/setup.bash\n", "mkdir -p ~/rihs_ws/src\n", "cd ~/rihs_ws/src\n", "catkin_init_workspace\n", "cd ~/rihs_ws/\n", "catkin_make\n", "source devel/setup.bash\n", "\n", "#Get ROS In-hand scanner\n", "cd ~/rihs_ws/src\n", "git clone http://github.com/RodBelaFarin/ros_in_hand_scanner\n", "cd ~/rihs_ws/\n", "\n", "#Install\n", "rosdep update\n", "rosdep install ros_in_hand_scanner\n", "catkin_make", "roscore\n", "rosrun ros_in_hand_scanner ros_in_hand_scanner_node"]},
{"url": "https://wiki.ros.org/schunk_robots", "package": "schunk_robots", "package_summary": ["\n  \n    This stack holds packages for hardware configuration as well as launch files for starting up Schunk components.\n\n  "], "package_details": ["\n", "\n", "\n", "See ", ". ", "Please consult ", " to see if your problem is already known. ", "Use ", " to report bugs or request features. "]},
{"url": "https://wiki.ros.org/rocon_msgs", "package": "rocon_msgs", "package_summary": ["Communication types (msgs/srvs/actions) for robotics in concert (aka multimaster)."], "package_details": ["\n ", "\n", "Use github to report ", ". ", ". "]},
{"url": "https://wiki.ros.org/rh_p12_rn_gazebo", "package": "rh_p12_rn_gazebo", "package_summary": ["This package provides basic message pub and launch file to use RH-P12-RN on Gazebo"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/ackermann_hks", "package": "ackermann_hks", "package_summary": ["\n\n     HKS game controller tele-operation interface for driving a\n     vehicle with Ackermann steering under human control.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", " "], "package_tt": ["ackermann_cmd"], "package_code": ["rosrun ackermann_qt hks_teleop"]},
{"url": "https://wiki.ros.org/asr_mild_base_laserscanner", "package": "asr_mild_base_laserscanner", "package_summary": ["This package provides streams of laser scan messages in cartesian coordinates from a planar sick laser scanner."], "package_details": [" ", "\n", "\n", "\n", " ", " ", "\n", " if you want to start the node with the mild.launch file. ", "\n", " ", "\n", "\n", "\n", "\n", "The main class is sick.cpp. It contains the SICK configuration and starts the code which communicates with the SICK. Also, it publishes the scan data to ROS. All other code is based on the ", " . The toolbox also contains code for other SICK laserscanners. ", "For a successful laserscan you only need to connect the SICK PLS 101-312 laserscanner to your PC. You can use USB or a Serial interface. For a baudrate of 500k you need USB or a RS422 Serial port and cable. To establish a connection, you must adapt the name of the connected port (look at parameter \"serial\"). Then you only need to start a launchfile with the laserscanner node e.g. ", ". ", "_/scan_ ( ", " ", "Look at ", " on how to adapt the parameters. "], "package_code": ["roslaunch asr_mild_base_launch_files mild.launch", "rosrun mild_base_laserscanner mild_base_laserscanner", "Init. complete: Sick PLS is online and ready!\n", "tScan Angle: 180\n", "tScan Resolution: 0.5\n", "tMeasuring Units: cm"]},
{"url": "https://wiki.ros.org/asr_kinematic_chain_optimizer", "package": "asr_kinematic_chain_optimizer", "package_summary": ["This package calculates the best approximation for a kinematic chain's parameters using rosenbrock optimization. For calculation, a layout of the kinematic chain must be provided, as well as a set of transformations between two frames of the chain that has been acquired during calibration."], "package_details": [" ", "\n", "\n", "\n", "\n", ". ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "<Data> ", "</Data> ", " ", "\n", " ", " ", " ", " ", "To specify an input-file use the ", "-tag. This surrounds the whole file. ", "To specify the structure of your kinematic chain use the ", "-tag. In this area the tf-frames are defined. There are some different types of frames: ", "A simple parent-child relation is defined as ", ", with Frame1 is the parent node of Frame 2. ", "To specify the goal function (for closing you kinematic chain) use the ", "-tag. The goal can be ether the position, orientation or both. ", "The position use the ", "-Tag. With this goal, the algorithm tries to set the position of Frame1 equal to the one of Frame2. Same for ", " with the frames orientations. ", "The data-file contains just the n-tuple datasets. One n-tuple is in one line. The single values are separated with a semicolon and a space. The program maps the data in column one to the first parameter (e. g. \"[1]\") and so on. ", " ", "The optimizer outputs the calculated values for the kinematic chain parameters directly to the console. ", " "], "package_code": ["roslaunch asr_kinematic_chain_optimizer optimizer.launch"]},
{"url": "https://wiki.ros.org/b21_description", "package": "b21_description", "package_summary": ["b21_description"], "package_details": [" "]},
{"url": "https://wiki.ros.org/robot_model", "package": "robot_model", "package_summary": [" This metapackage will be removed in ROS M. Replace all dependencies on\n      \"robot_model\" in your package.xml with dependencies on collada_parser,\n      collada_urdf, joint_state_publisher, kdl_parser, resource-retriever, urdf,\n      urdf_parser_plugin, and liburdfdom-tools instead.", " contains packages for modeling various\n    aspects of robot information, specified in the Xml Robot\n    Description Format (URDF). The core package of this stack\n    is ", ", which parses URDF files, and constructs an\n    object model (C++) of the robot."], "package_details": ["\n", "\n", "\n", " provides the following ROS ", ": ", "\n", "  "], "package_tt": ["robot_model", "robot_model", "robot_model", "robot_model", "robot_model", "robot_model", "robot_model", "robot_model", "robot_model", ".iv", ".stl"]},
{"url": "https://wiki.ros.org/scriptable_monitoring", "package": "scriptable_monitoring", "package_summary": ["scriptable_monitoring"], "package_details": ["\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n  ", "Scriptable monitoring provides a tool that runs monitoring scripts (Python or predicate-like), allowing a definition of monitoring rules for values obtained via topic messages, and also alerts about violated rules to the ", " topic, which can be monitored using rqt plugins like ", " or ", ". "], "package_tt": ["scriptable_monitoring"]},
{"url": "https://wiki.ros.org/phoxi_camera", "package": "phoxi_camera", "package_summary": ["The phoxi_camera package"], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", "The phoxi_camera driver provides a ROS interface for ", " devices. ", "The point cloud published by the phoxi_camera node can be viewed with ", ". "], "package_tt": ["/phoxi_camera/pointcloud", "/phoxi_camera/confidence_map", "/phoxi_camera/normal_map", "/phoxi_camera/texture", "~vertical_resolution", "int", "~horizontal_resolution", "int", "~scan_multiplier", "int", "~shutter_multiplier", "int", "~trigger_mode", "int", "~timeout", "int", "~confidence", "double", "~send_point_cloud", "bool", "~send_normal_map", "bool", "~send_texture", "bool", "~send_confidence_map", "bool"], "package_code": ["$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/photoneo/phoxi_camera", "roslaunch phoxi_camera phoxi_camera.launch"]},
{"url": "https://wiki.ros.org/shape_msgs", "package": "shape_msgs", "package_summary": ["This package contains messages for defining shapes, such as simple solid\n    object primitives (cube, sphere, etc), planes, and meshes."]},
{"url": "https://wiki.ros.org/motoman_mh_support", "package": "motoman_mh_support", "package_summary": ["\n      ROS-Industrial support for the Motoman MH series (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman MH series manipulators. This currently includes the MH180-120\n      only.\n    ", "\n      Joint limits and max joint velocities are based on the information in the\n      ", ".\n      All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/neo_watchdogs", "package": "neo_watchdogs", "package_summary": ["The neo_watchdogs package"], "package_details": ["\n", "\n", "\n", "\n"], "package_tt": ["/move_base/goal", "/srb_emergency_stop_state", "/move_base/goal"]},
{"url": "https://wiki.ros.org/create_driver", "package": "create_driver", "package_summary": ["Driver for iRobot Create and Roomba\n    \n    This is a generic driver for iRobot Create that currently holds\n    implementations for Turtlebot and Roomba. Port\n    of pyrobot.py by Damon Kohler.  It is currently labeled as\n    turtlebot_driver pending review by the entire create community\n    before using the name create_driver.\n  \n    For ROS bindings, please see turtlebot_node."]},
{"url": "https://wiki.ros.org/remote_monitor", "package": "remote_monitor", "package_summary": ["The remonot monitor package"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 0.2) ", "\n", " (", ", default: 1.0) ", "\n", "c", " (", ") ", "Remote monitoring package for navigation with ", ". We actually succeeded in remotely monitoring ", "'s pose running in Tsukuba from Fukuoka (", ") ", "How to connect remote PCs with OpenVPN can be seen in ", ". ", "Tutorial to integrate OpenVPN and ROS is ", ". "], "package_tt": ["node", "service", "node", "service", "/amcl_pose", "subscribe", "<catkin_ws>", "tun", "ratio", "double", "interval_dist", "double", "pose_topic", "string", "subscribe", "current", "history", "reset\u00a0history", "history", "plus\u00a0to\u00a0ratio", "minus\u00a0to\u00a0ratio"], "package_code": ["$ roslaunch cirkit_unit03_autorun autorun_gazebo.launch \n", "$ roslaunch remote_monitor remote_monitor_server_gazebo.launch\n", "$ roslaunch remote_monitor remote_monitor_client_gazebo.launch ", "$ cd <catkin_ws>/src\n", "$ git clone https://github.com/CIR-KIT/remote_monitor.git", "$ cd <catkin_ws>\n", "$ wstool init src\n", "$ wstool merge -t src src/remote_monitor/remote_monitor.rosinstall\n", "$ wstool update -t src", "$ rosdep update && rosdep install -r -y --from-paths src --ignore-src", "$ cd <catkin_ws>\n", "$ catkin_make\n", "$ source devel/setup.bash", "$ roslaunch remote_monitor remote_monitor_server.launch map_yaml:=hogehoge.yaml", "$ roslaunch remote_monitor remote_monitor_server_gazebo.launch map_yaml:=hogehoge.yaml", "$ cd /etc/openvpn\n", "$ emacs client.conf", "# \u7701\u7565\n", "\n", "# \u30b0\u30ed\u30fc\u30d0\u30ebIP\u30a2\u30c9\u30ec\u30b9\u3092\u6307\u5b9a\u3059\u308b\uff0e\n", "remote 101.102.103.xxx 1194\n", "\n", "# \u7701\u7565", "$ service openvpn restart", "$ ifconfig", "tun0      Link encap:\u4e0d\u660e\u306a\u30cd\u30c3\u30c8  \u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30a2\u30c9\u30ec\u30b9 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  \n", "          inet\u30a2\u30c9\u30ec\u30b9:10.8.0.6  P-t-P:10.8.0.5  \u30de\u30b9\u30af:255.255.255.255\n", "          UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1500  \u30e1\u30c8\u30ea\u30c3\u30af:1\n", "          RX\u30d1\u30b1\u30c3\u30c8:0 \u30a8\u30e9\u30fc:0 \u640d\u5931:0 \u30aa\u30fc\u30d0\u30e9\u30f3:0 \u30d5\u30ec\u30fc\u30e0:0\n", "          TX\u30d1\u30b1\u30c3\u30c8:12 \u30a8\u30e9\u30fc:0 \u640d\u5931:0 \u30aa\u30fc\u30d0\u30e9\u30f3:0 \u30ad\u30e3\u30ea\u30a2:0\n", "          \u885d\u7a81(Collisions):0 TX\u30ad\u30e5\u30fc\u9577:100 \n", "          RX\u30d0\u30a4\u30c8:2892 (2.8 KB)  TX\u30d0\u30a4\u30c8:504 (504.0 KB)", "$ ping 10.8.0.1", "export ROS_MASTER_URI=http://10.8.0.6:11311\n", "export ROS_HOST_NAME=10.8.0.6\n", "export ROS_IP=10.8.0.6", "roscd remote_monitor/scripts\n", "source vpn_setting_for_robot.sh", "$ env | grep ROS", "$ rosservice list", "/remote_monitor_robot_pose\n", "/remote_monitor_human_pose", "$ roslaunch remote_monitor remote_monitor_client.launch", "$ roslaunch remote_monitor remote_monitor_client_gazebo.launch"]},
{"url": "https://wiki.ros.org/serial_utils", "package": "serial_utils", "package_summary": ["A package which adds useful additions to the serial package."]},
{"url": "https://wiki.ros.org/rosweb", "package": "rosweb", "package_summary": ["rosweb is a temporary package to replace the original rosweb in the ROS\n     repository.  It is placed in the sandbox while development is ongoing, so\n     we are not gated on ROS stack releases.  When the server is more stable,\n     it will be moved to the ROS repository and replace the old rosweb."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rf2o_laser_odometry", "package": "rf2o_laser_odometry", "package_summary": ["Estimation of 2D odometry based on planar laser scans. Useful for mobile robots with innacurate base odometry.\n    For full description of the algorithm, please refer to:\n    Planar Odometry from a Radial Laser Scanner. A Range Flow-based Approach. ICRA 2016\n    Available at: http://mapir.isa.uma.es/mapirwebsite/index.php/mapir-downloads/papers/217"], "package_details": ["\n", "\n", "\n", "\n", "The user is advised to check the related papers (", ") for a more detailed description of the method. "], "package_tt": ["rf2o_laser_odometry", "tf", "laser_scan", "tf", "odom", "tf", "~laser_scan_topic", "string", "~base_frame_id", "string", "tf", "laser_frame", "base_frame", "~odom_frame_id", "string", "~freq", "double"]},
{"url": "https://wiki.ros.org/rosjson", "package": "rosjson", "package_summary": ["rosjson is a Python library for converting ROS messages to JSON\n     (JavaScript Object Notation) representation."], "package_details": ["\n", "\n", "\n", "The JSON (JavaScript Object Notation) format is useful when building Web-based interfaces that need access to ROS data. rosjson is meant to be coupled with a Python Web server so that the JSON objects can be served over a Web connection. ", " is one example Web server implementation, but it is currently in high design flux. ", "No further features are planned for the ROS JSON library as JSON itself is just a data representation. Python 2.6 has a json module that would simplify the existing code and make it more robust, but as the current package is < 50 lines of Python, there's not much to improve upon. "]},
{"url": "https://wiki.ros.org/kingfisher_description", "package": "kingfisher_description", "package_summary": ["URDF description for Kingfisher"], "package_details": [" ", " "]},
{"url": "https://wiki.ros.org/neo_platformctrl_diff", "package": "neo_platformctrl_diff", "package_summary": ["transformation node for neobotix robots woth differential drive"], "package_details": ["\n", "\n", "\n", " "], "package_tt": ["/joint_states", "/cmd_vel", "/odom", "/cmd_joint_traj", "kinematics", "wheelDiameter", "robotWidth", "sendTransform"]},
{"url": "https://wiki.ros.org/scheduler_msgs", "package": "scheduler_msgs", "package_summary": ["Messages used by the rocon scheduler."]},
{"url": "https://wiki.ros.org/softkinetic_camera", "package": "softkinetic_camera", "package_summary": ["Softkinetic cameras drivers, including filters."]},
{"url": "https://wiki.ros.org/receive_ublox", "package": "receive_ublox", "package_summary": ["\n\n     ROS driver for U-blox GPS receivers\n\n  "], "package_details": [" ", "\n", "\n"], "package_tt": ["/gps/data"], "package_code": ["roslaunch receive_ublox.launch"]},
{"url": "https://wiki.ros.org/rv4fl_moveit_config", "package": "rv4fl_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the rv4fl with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/lower_step_detector", "package": "lower_step_detector", "package_summary": ["The lower_step_detector package"], "package_details": ["\n", "\n", "\n", "\n", "To install the ", " package, you can install from source with the following commands: "], "package_tt": ["lower_step_detector"], "package_code": ["\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/roslang", "package": "roslang", "package_summary": ["roslang is a common package that all ", " depend on.\n    This is mainly used to find client libraries (via 'rospack depends-on1 roslang')."], "package_details": ["\n", "The ", " package is only of interest to those implementing a ROS ", ". Client libraries marks themselves as such by depending on the ", " package, which allows ", " and other tools to perform appropriate actions, such as ", "- and ", "-based code generation. The ", " package itself contains no actual code. "], "package_tt": ["roslang", "roslang", "roslang"]},
{"url": "https://wiki.ros.org/multi_jackal_nav", "package": "multi_jackal_nav", "package_summary": ["Localization and navigation for the Jackal."], "package_details": ["\n", " contains the launch files and parameters providing localization and waypoint following for multiple simulated ", ". It has been extended from the single robot ", " to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  ", "\n", "There are tutorials on how to use this package in ", ". "], "package_tt": ["multi_jackal_nav"]},
{"url": "https://wiki.ros.org/omip_msgs", "package": "omip_msgs", "package_summary": ["Messages for OMIP - Online Multimodal Interactive Perception"], "package_details": ["\n", "\n", "Package defining the messages for OMIP ", ". ", "(Main author) Roberto Mart\u00edn-Martin (", ", ", ") ", "Sebastian H\u00f6fer (", ", ", ") ", "Oliver Brock (", ") "]},
{"url": "https://wiki.ros.org/prosilica_gige_sdk", "package": "prosilica_gige_sdk", "package_summary": ["AVT GigE SDK version 1.26 for ROS"], "package_details": ["NOTE: The recommended way of using Prosilica cameras in ROS is through the driver in ", ". You need only use this package directly if you are writing your own software for interacting with Prosilica cameras without going through ROS. "], "package_code": ["$ rosrun prosilica_gige_sdk EXE_NAME [OPTIONS]", "$ SampleViewer", "$ ListCameras", "$ Ping <IP>", "$ ListAttributes [IP]", "$ ResetCamera <IP>"]},
{"url": "https://wiki.ros.org/joint_tracker", "package": "joint_tracker", "package_summary": ["Tracker of the kinematic model (structure and state) based on the motion of a set of rigid bodies"]},
{"url": "https://wiki.ros.org/neo_base_mpo_700", "package": "neo_base_mpo_700", "package_summary": ["launchfiles for MPO_500"]},
{"url": "https://wiki.ros.org/airbus_pyqt_extend", "package": "airbus_pyqt_extend", "package_summary": ["The airbus_pyqt_extend package"]},
{"url": "https://wiki.ros.org/sound_play", "package": "sound_play", "package_summary": ["sound_play provides a ROS node that translates commands on a ROS topic (", ") into sounds. The node supports built-in sounds, playing OGG/WAV files, and doing speech synthesis via festival. C++ and Python bindings allow this node to be used without understanding the details of the message format, allowing faster development and resilience to message format changes."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " If you need the information in this section for something other than satisfying curiosity, you are probably doing something wrong. ", "The ", " node considers each sound (built-in, wave file or synthesized text) as an entity that can be playing, playing repeatedly or stopped. Nodes change the state of a sound by publishing to the ", " topic. Multiple sounds can be played at once. ", "C++ and Python bindings are provided. It should be unnecessary to directly generate messages when playing sounds from C++ or Python. Documentation of the language bindings are in ", ". ", "The following utilities can be used to play sound when ", " is running. For help on getting ", " running refer to the ", ". ", "The ", " script can play any ", " or ", " file. The file must be available on the computer on which ", " is running, and an absolute path should be given. ", "Some standard sounds are built-into the driver, and can be played only by specifying their integer identifier using ", ". ", "For example (", " should be running first): ", "To get an up-to-date list of the built-in sounds, consult the definition of the ", " message. The relevant information is below the \"", "\" comment. ", "The sound node can also be used to synthesize speech using the ", ". The ", " script gives command-line access to this functionality. This script can take its input from the command line, or if the command-line is empty it can take input from standard input. ", "Examples (", " should be running first): ", "The most immediate way to silence the robot is to use ", " to mute or lower the volume. In some cases, a node that had requested a continuous sound could crash with the sound still playing. In order to stop that sound the ", " script can be used. ", "The ", " script sends a stop command on all sounds every 100ms until it is terminated. This behavior will immediately stop any continuous sounds that were playing, and will cut short any new sounds that are played. It will not completely silence the robot, however, as the first tens of milliseconds of newly requested sounds will be played before they are silenced. ", "To test that ", " is operating correctly, you can use the ", " script. It will play the various built-in sounds, and exercise the ", " playing and text-to-speech capabilities. To run it: ", "The following launch file, which starts ", ", can be found in ", ": ", "Sound commands are issued to ", " via a ", " message. Commands define two things: a sound, and what to do with that sound.  ", "The sound is defined by the ", " (int) and ", " (string) fields of the message, and can be one of four types: ", "Each message on the ", " topic will cause a sound to transition between the playing continuously, playing once (or twice) and stopped states. For example, a backing up sound could be initiated by sending a command for a backing up sound to play continuously. When the robot stops backing up, a stop command will stop playback. Likewise, verbal debugging messages could be used by telling a sound to play once. In this case there is no need to stop playing the sound. "], "package_tt": ["robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "robotsound", "sound_play", "robotsound", "soundplay_node.py", "soundplay_node.py", "play.py", ".WAV", ".OGG", "soundplay_node.py", "playbuiltin.py", "soundplay_node.py", "Sounds", "say.py", "soundplay_node.py", "alsamixer", "shutup.py", "shutup.py", "soundplay_node.py", "test.py", ".WAV", "soundplay_node.py", "robotsound", "robotsound", "diagnostics", "soundplay_node.py", "soundplay_node.launch", "robotsound", "soundplay_node.py", "sound", "arg", "sound", "PLAY_FILE", "sound", "soundplay_node.py", "arg", "SAY", "sound", "arg", "ALL", "sound", "robotsound"], "package_code": ["$ rosrun sound_play play.py --help\n", "Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/play.py sound_to_play.(ogg|wav)\n", "\n", "Plays an .OGG or .WAV file. The path to the file should be absolute, and be valid on the computer on which sound_play is running.", "$rosrun sound_play play.py /usr/share/xemacs21/xemacs-packages/etc/sounds/im_so_happy.wav\n", "Playing \"/usr/share/xemacs21/xemacs-packages/etc/sounds/im_so_happy.wav\".", "$ rosrun sound_play playbuiltin.py \n", "Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/playbuiltin.py <sound_id>\n", "\n", "Plays one of the built-in sounds based on its integer ID. Look at the <<MsgLink(sound_play/SoundRequest)>> message definition for IDs.", "$ rosrun sound_play playbuiltin.py 2\n", "Playing sound 2\".", "$ cat `rospack find sound_play`/msg/SoundRequest.msg\n", "# Sounds\n", "byte BACKINGUP = 1\n", "byte NEEDS_UNPLUGGING = 2\n", "byte NEEDS_PLUGGING = 3\n", "byte NEEDS_UNPLUGGING_BADLY = 4\n", "byte NEEDS_PLUGGING_BADLY = 5\n", "\n", "# Sound identifiers that have special meaning\n", "byte ALL = -1 # Only legal with PLAY_STOP\n", "byte PLAY_FILE = -2\n", "byte SAY = -3\n", "\n", "byte sound # Selects which sound to play (see above)\n", "\n", "# Commands\n", "byte PLAY_STOP = 0 # Stop this sound from playing\n", "byte PLAY_ONCE = 1 # Play the sound once\n", "byte PLAY_START = 2 # Play the sound in a loop until a stop request occurs\n", "\n", "byte command # Indicates what to do with the sound\n", "\n", "string arg # file name or text to say", "$ rosrun sound_play say.py --help\n", "$ rosrun sound_play say.py --help\n", "Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/say.py 'String to say.'\n", "       /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/say.py < file_to_say.txt\n", "\n", "Says a string. For a string on the command line, you must use quotes as\n", "appropriate. For a string on standard input, the command will wait for\n", "EOF before saying anything.", "$ rosrun sound_play say.py 'Hello world'\n", "Saying: Hello world.\n", "$ echo Hello again|rosrun sound_play say.py\n", "Awaiting something to say on standard input.\n", "Saying: Hello again", "$ rosrun sound_play shutup.py \n", "Sending stopall command every 100 ms.\n", "Note: This will not prevent a node that is continuing to issue commands\n", "from producing sound.\n", "Press Ctrl+C to exit.", "$ rosrun sound_play test.py", "<launch>\n", "  <node name=\"soundplay_node\" pkg=\"sound_play\" type=\"soundplay_node.py\"/>\n", "</launch>"]},
{"url": "https://wiki.ros.org/mm_mux_demux", "package": "mm_mux_demux", "package_summary": ["Multiplexing many packet types across a single connection. Great for embedded connections\n   by serial or ethernet types."]},
{"url": "https://wiki.ros.org/rbcar_joystick", "package": "rbcar_joystick", "package_summary": ["The rbcar_joystick package"]},
{"url": "https://wiki.ros.org/sick_visionary_t_driver", "package": "sick_visionary_t_driver", "package_summary": ["Open source driver for the SICK Visionary-T 3D TOF camera."], "package_details": ["\n", "  ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "This is an open source driver for the ", ". The visionary-T is a 3D camera based on the time-of- flight (TOF) principle. It provides real-time 3D data at up to 30 frame per second (fps). ", "The 3D camera is configured and its images visualized via the ", " software. ", "The digital i/o channel interface of this driver is considered ", " and ", " yet. ", "The ", " parameter in the launch file needs to be set to the verified device IP address. This easiest way is to provide the parameter is in the launch file (", "). "], "package_tt": ["remote_device_ip", "launch/sick_visionary_t_driver.launch", "camera/camera_info", "camera/depth", "uint16", "camera/confidence", "uint16", "camera/intensity", "uint16", "camera/ios", "/diagnostics", "camera/scan", "camera/cartesian", "enable_depth_map", "enable_height_map", "enable_polar_scan", "~remote_device_ip", "string", "~frame_id", "string", "~prevent_frame_skipping", "bool", "~io_polling_interval", "double", "~channel", "string", "~user", "string"]},
{"url": "https://wiki.ros.org/manipulator_h_gazebo", "package": "manipulator_h_gazebo", "package_summary": ["The manipulator_h_gazebo package\n    This package provides GAZEBO simulation environment for ROBOTIS MANIPULATOR-H.\n    We provides two controllers such as position and effort controllers."], "package_details": [" ", "\n", " "]},
{"url": "https://wiki.ros.org/ros_wild", "package": "ros_wild", "package_summary": ["The ros_wild package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "Most usages are listed in ", " and some examples scripts are in ", ". "], "package_code": ["$ sudo apt install ros-kinetic-ros-wild", "$ cd /path/to/your/catkin_ws/src/\n", "$ git clone https://github.com/yuma-m/ros_wild.git\n", "$ cd ../\n", "$ catkin_make"]},
{"url": "https://wiki.ros.org/futaba_serial_servo", "package": "futaba_serial_servo", "package_summary": ["The futaba_serial_servo package"]},
{"url": "https://wiki.ros.org/rosunit", "package": "rosunit", "package_summary": ["Unit-testing package for ROS. This is a lower-level library for rostest and handles unit tests, whereas rostest handles integration tests."], "package_details": [" ", "\n", " is an internal tool for running unit tests within ROS.  While it can be run by a regular user, most users will generally use ", " indirectly via ", " test macros.  The main feature that ", " provides is terminating a unit test based on a timeout and generating an appropriate test failure.  The rosbuild system uses this feature to ensure that unit tests properly terminate. ", " currently supports: ", "\n", "\n", " ", " ", " ", " ", " ", " ", "\n", " ", "The library that comes with ", " can be used as described at ", " ", "These helper scripts are intended for use only by the ", " and test reporting infrastructure. ", "Historically, rosunit is based on a refactoring of ", ". It provides the unit-test infrastructure and rostest provides the integration test infrastructure. rostest is also allowed to interact with a running ROS graph. ", "The initial separation was not perfect. There is more room to migrate more code from rostest into rosunit. Similarly, there is code within rosunit that would be better supported by a graph-less version of ", ", i.e. a process monitor unattached to a ROS master. Until that happens, rosunit contains code that is a copy of internal libraries within roslaunch. "], "package_tt": ["rosunit", "rosunit", "rosunit", "rosunit", "unittest", "rosunit", "-t", "--text", "--name", "python", "--time-limit", "clean_junit_xml.py", "test_results/_hudson", "check_test_ran.py\u00a0<test-file.xml>", "check_test_ran.py\u00a0--rostest\u00a0<pkg-name>\u00a0<test-file.xml>", "--rostest", "summarize_results.py\u00a0<package>", "test_results_dir.py", "pycoverage_to_html.py", "coverage.py"], "package_code": ["$ rosrun rosunit rosunit -h\n", "\n", "Usage: rosunit [options] <file> [test args...]\n", "\n", "Options:\n", "  -h, --help            show this help message and exit\n", "  -t, --text            Run with stdout output instead of XML output\n", "  --time-limit=TIME_LIMIT\n", "                        Set time limit for test\n", "  --name=TEST_NAME      Test name"]},
{"url": "https://wiki.ros.org/mrp2_control", "package": "mrp2_control", "package_summary": ["Teleoperation and ros controls related launch files and configurations."]},
{"url": "https://wiki.ros.org/pano_ros", "package": "pano_ros", "package_summary": ["\n\n\tThe ros frontend to the pano subsystem.\n\n  ", "To be documented. "], "package_tt": ["stitch_client.py", "pano_capture/snap", "pano_capture/stop", "stop", "snap", "snap", "`pwd`/pano.bag", "`pwd`/"], "package_code": ["roslaunch openni_camera openni_kinect.launch ", "rosrun pano_ros capture_server.py camera:=/camera/rgb", "rosrun image_view image_view image:=/pano_capture/stitch", "rosrun pano_ros capture_client.py `pwd`/pano01.bag 10 1", "rosrun pano_ros capture_server.py camera:=/kinect/rgb", "In [1]: actions.pano_capture('camera/rgb')", "In [1]: topics.pano_capture.snap()\n", "\n", "In [2]: topics.pano_capture.snap()\n", "\n", "In [3]: topics.pano_capture.stop()", "In [1]: actions.pano_capture('camera/rgb')\n", "Out[1]: \n", "pano_id: 1292382284\n", "n_captures: 6\n", "bag_filename: /tmp/pano_1292382284.bag", "rosrun pano_ros capture_client.py `pwd`/pano.bag 30", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "rosrun pano_ros bag_stitcher.py", "rosrun pano_ros stitch_client.py test_pano.bag stitch.jpg\n", "eog stitch.jpg"]},
{"url": "https://wiki.ros.org/pano_core", "package": "pano_core", "package_summary": ["\n\n        Library for the opencv-based panorama stitching algorithm\n\n  "]},
{"url": "https://wiki.ros.org/kingfisher_msgs", "package": "kingfisher_msgs", "package_summary": ["\n\n     kingfisher_msgs\n\n  "], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"kingfisher_msgs\" in rosdoc: /home/rosbot/docs/api/kingfisher_msgs/manifest.yaml ", " ", "Used on the ", " from ", ". "]},
{"url": "https://wiki.ros.org/gazebo_gripper", "package": "gazebo_gripper", "package_summary": ["\n\n     gazebo_gripper\n\n  "]},
{"url": "https://wiki.ros.org/rocon_std_msgs", "package": "rocon_std_msgs", "package_summary": ["Standard messages used by other rocon specific package types."]},
{"url": "https://wiki.ros.org/multi_jackal_base", "package": "multi_jackal_base", "package_summary": ["The Jackal simulation base that combines all components."], "package_details": ["\n", " provides a launch file for spawning all components of a simulated ", ". It has been extended from the single robot ", " to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  ", "\n", "\n", "There are tutorials on how to use this package in ", ". ", "A number of arguments can be provided when launching ", ". ", "If you only want to use local odometry for positioning, set ", " to ", " and ", " to ", ". ", "If you want to use the Jackals GPS, set ", " to ", ", and ", " to ", ". ", "If you want to use your own fusion, set them both to ", ". "], "package_tt": ["multi_jackal_base", "jackal_base.launch", "ns", "x", "y", "z", "roll", "pitch", "yaw", "config", "config_id", "use_move_base", "use_global_tf", "map", "ns/odom", "use_global_ekf", "map", "ns/odom", "use_global_tf", "true", "use_global_ekf", "false", "use_global_ekf", "true", "use_global_tf", "false", "false"]},
{"url": "https://wiki.ros.org/rl_common", "package": "rl_common", "package_summary": ["rl_common is a package of common RL files needed by both the agent and the\nenvironment. Mainly the interfaces defining their class methods, and some other\nutility methods."], "package_details": ["\n", "\n", "\n", "StateActionInfo is the struct that the model must return when quering the model for its predictions for a given state action. It has a confidence (a float), a boolean telling if it is a 'known' transition or not, a float predicting the reward, a float predicting the termination probability, and a map of states (vectors of floats) to floats that gives the probabilities of next states. Full documentation for the StateActionInfo struct is available ", ". ", "\n", "\n", "\n", "\n", " ", "This package defines interfaces for agents, environments, models, and plannersin the file ", ". All agents, environments, models, and planners should inherit from their appropriate base class. ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "First, an experience <s,a,r,s'> tuple is defined, which is used to update the model. The state s the agent came from is a vector of floats, the action it took is an int, the reward it received is a float, and the next state s' it transitioned to is a vector of floats. In addition, there's a bool indicating if the transition was terminal or not. Full documentation for the experience struct is available ", ". ", "Agent is defined with a number of methods. Mainly it has first_action(state) which is called for the first action in an episode and returns an action. After that next_action(reward, state) should be called, which returns an action. Finally upon reaching a terminal state, last_action(reward) can be called. In addition to these methods, seedExp(vector of experiences) can be used to seed the agent with a set of experiences. Full documentation for the Agent class is available ", ". ", "The environment has a sensation() method which returns the current state vector and a terminal() method tells if the agent is in a terminal state or not. The agent can act upon the environment by calling apply(action) which returns a reward. A set of experience seeds to initialize agents is available using the getSeedings() method. There are also a number of methods to get information about the environment such as getNumActions, getMinMaxFeatures, getMinMaxReward, and isEpisodic. Full documentation for the Environment class is available ", ". ", "Full documentation for the MDPModelclass is available ", ". ", "Full documentation for the Planner class is available ", ". "]},
{"url": "https://wiki.ros.org/jaco_interaction", "package": "jaco_interaction", "package_summary": ["Interactive manipulation with the JACO Arm"], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package provides interactive marker-based control of the end effector pose and issuing of manipulation commands for the JACO and JACO2. ", "To install the ", " package, you can install from source with the following commands: ", "The interactive markers can be launched using two launch files: ", " and ", ".  The ", " file launches all of the necessary ROS nodes to publish the interactive markers and send commands back to the arm, and as such it should be launched first on a computer connected directly to the JACO arm.  The ", " file launches rviz with a preset configuration to show the arm model and the interactive markers.  This can be launched on any computer capable of displaying a GUI.  The syntax for launching these nodes is as follows: "], "package_tt": ["jaco_interaction", "jaco_arm/manipulation/gripper", "jaco_arm/manipulation/lift", "jaco_arm/joint_states", "jaco_arm/cartesian_cmd", "jaco_arm/kinematics/fk", "jaco_conversions/quaternion_to_euler", "wpi_jaco/arm_name", "string", "wpi_jaco", "im_backend.launch", "im_frontend.launch", "im_backend.launch", "im_frontend.launch"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch jaco_interaction im_backend.launch", "roslaunch jaco_interaction im_frontend.launch"]},
{"url": "https://wiki.ros.org/rh_p12_rn_description", "package": "rh_p12_rn_description", "package_summary": ["3D models of the RH-P12-RN for simulation and visualization"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/riskrrt", "package": "riskrrt", "package_summary": ["riskrrt is a risk-based rapidly exploring random tree algorithm for human aware navigation"], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", "Some example scenarios can be run using: "], "package_tt": ["traj", "amcl_pose", "controller_feedback", "cmd_vel", "goal", "map", "robot_*/base_pose_ground_truth", "robot_*/cmd_vel", "ogarray", "ogarray", "goal", "controller_feedback", "amcl_pose", "odom", "traj", "~timeStep", "double", "~maxDepth", "int", "~nv", "int", "~nphi", "int", "~threshold", "double", "~socialWeight", "double", "~rotationWeight", "double", "~growTime", "double", "~bias", "double", "~windowSize", "double", "~goalTh", "double", "~robotLength", "double", "~robotWidth", "double", "~vMin", "double", "~vMax", "double", "~accMax", "double", "~omegaMax", "double", "~accOmegaMax", "double"], "package_code": ["roslaunch riskrrt scenario_name.launch"]},
{"url": "https://wiki.ros.org/rviz_fixed_view_controller", "package": "rviz_fixed_view_controller", "package_summary": ["A simple rviz view controller that follows a TF frame."]},
{"url": "https://wiki.ros.org/rb_tracker", "package": "rb_tracker", "package_summary": ["Tracker of rigid bodies using visual features and/or shape-based poses (extensible to use other modalities as source of information)"]},
{"url": "https://wiki.ros.org/rmp_base", "package": "rmp_base", "package_summary": ["The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform. \n    In addition, navigation and status data are also published such as odometry, imu, mottor and battery status, ..."], "package_details": ["\n", "\n", "\n", "\n", "The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform (", "). It supports USB and UDP interfaces. ", "This package has only been tested on the RMP 440LE (", "). "], "package_tt": ["/rmp440le/base/vel_cmd", "/rmp440le/deadman", "/rmp440le/audio_cmd", "/rmp440le/odom", "/rmp440le/joint_states", "/rmp440le/inertial", "/rmp440le/pse", "/rmp440le/motor_status", "/rmp440le/battery", "/rmp440le/fault_status", "transport_type", "string", "ip_address", "string", "port_number", "int", "device_port", "string", "update_frequency", "double", "odometry_topic", "string", "joint_states_topic", "string", "inertial_topic", "string", "pse_topic", "string", "motor_status_topic", "string", "battery_topic", "string", "velocity_command_topic", "string", "deadman_topic", "string", "audio_command_topic", "string", "fault_status_topic", "string", "max_translational_velocity", "double", "max_turn_rate", "string"], "package_code": ["$ roslaunch rmp_base rmp440le.launch"]},
{"url": "https://wiki.ros.org/feature_tracker", "package": "feature_tracker", "package_summary": ["Tracker of 3-D features (up to now, only LK point features, extensible to other type of basic features) on an RGB-D stream"], "package_details": [" ", "\n", " ", "The feature_tracker package is a versatile tool to detect and track point features in a RGB-D video stream. The framework can be easily modified to use different detection & tracking algorithms. The current implementation uses Kanade-Lucas-Tomasi algorithm (opencv implementation) to first detect corner features on the first frame and then track them in consecutive frames. it maintains a constant number of features by detecting new ones. "]},
{"url": "https://wiki.ros.org/prbt_grippers", "package": "prbt_grippers", "package_summary": ["The package provides gripper support for the pilz_robots package."]},
{"url": "https://wiki.ros.org/ipcamera_driver", "package": "ipcamera_driver", "package_summary": ["Simple node to publish regular IP camera video streams to a ros topic."], "package_details": [" "]},
{"url": "https://wiki.ros.org/mjpeg_server", "package": "mjpeg_server", "package_summary": ["A node that provides a mjpeg server which is able to subscribe to any ros image stream."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "In a ", ", run the mjpeg_server: ", "Optionally, you can set a different port on the command line when launching ", ": ", "Here, /IMAGE_TOPIC is a ROS topic generated by the ", " module, e.g. ", " in case you are using a PR2. ", "Please send bug reports to the ", ". Feel free to contact us at any point with questions and comments.  "], "package_tt": ["mjpeg_server", "mjpeg_server", "/wide_stereo/left/image_color", "width", "integer", "height", "integer", "quality", "integer", "invert", "none"], "package_code": ["\n", "\n", "\n", "\n", "sudo apt-get install ros-groovy-mjpeg-server", "rosrun mjpeg_server mjpeg_server", "rosrun mjpeg_server mjpeg_server _port:=8181", "http://localhost:8080/stream?topic=/IMAGE_TOPIC", "http://localhost:8080/snapshot?topic=/IMAGE_TOPIC", "http://localhost:8080/stream?topic=/IMAGE_TOPIC?param1=value1?param2=value2?param3=value3"]},
{"url": "https://wiki.ros.org/rocon_service_pair_msgs", "package": "rocon_service_pair_msgs", "package_summary": ["Paired pubsubs generators for non-blocking services."]},
{"url": "https://wiki.ros.org/message_multiplexing", "package": "message_multiplexing", "package_summary": ["Lightweight communication patterns built on top of nanomsg for\n    use in embedded scenarios where only a single socket connection is desirable."]},
{"url": "https://wiki.ros.org/ros_pytest", "package": "ros_pytest", "package_summary": ["The ros_pytest package"]},
{"url": "https://wiki.ros.org/rostune", "package": "rostune", "package_summary": ["rostune is a tool that helps ROS developers distribute their nodes in the most effective way. It collects statistics for topics and nodes, such as CPU and network usage."]},
{"url": "https://wiki.ros.org/kobuki_softnode", "package": "kobuki_softnode", "package_summary": ["ROS nodelet for fake Kobuki."]},
{"url": "https://wiki.ros.org/airbus_docgen", "package": "airbus_docgen", "package_summary": ["The airbus_docgen package"], "package_details": ["\n", " ", " "], "package_code": ["roslaunch airbus_docgen airbus_docgen.launch output_path:=\"/tmp/docu\" ros_pkg:=\"/home/user/my_workspace\"", "roslaunch airbus_docgen airbus_docgen.launch output_path:=\"/tmp/docu\" ros_pkg:=\"package_name\"", "rosrun airbus_docgen index.py"]},
{"url": "https://wiki.ros.org/r2_msgs", "package": "r2_msgs", "package_summary": ["\n\n     r2_msgs\n\n  "]},
{"url": "https://wiki.ros.org/mr_rqt", "package": "mr_rqt", "package_summary": ["Multi-robot teleoperation package collection"], "package_details": ["\n", " ", "\n", " ", "\n"], "package_tt": ["keyboard_cmd_vel", "mouse_cmd_vel", "/output_topics", "list\u00a0of\u00a0strings"]},
{"url": "https://wiki.ros.org/robot_controllers_msgs", "package": "robot_controllers_msgs", "package_summary": ["Messages for use with robot_controllers framework."]},
{"url": "https://wiki.ros.org/robot_face", "package": "robot_face", "package_summary": ["\n\n     This is an application to display a talking head on your robot for human robot interaction. It displays text and synchronized mouthmovements. It is also able to show emotions.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "To model a robot face for the ros-package ", " you have to follow this guidelines to get a working model in the application. This guideline will not tell you how to model a complete face, but helps you to get things work. ", "To get a working model in the ", " application, please follow this guidelines. "]},
{"url": "https://wiki.ros.org/mico_description", "package": "mico_description", "package_summary": ["3D Model and URDF of the Kinova MICO Arm"], "package_details": ["\n", " contains urdf and xacro files for the MICO arm.  It also includes a launch file for reading the robot model and setting up a ", " and ", " for visualization in tools such as rviz. ", "\n", "\n", "\n", "To install the ", " package, you can install from source with the following commands: ", "The ", " package includes a launch file that can be used to load the robot model and setup joint state and robot state publishing used to populate a tf tree and visualize the robot.  Once launched, the MICO model can be visualized in tools such as rviz.  It can be launched with the following command: ", "The launch file also includes a parameter (", ") to launch a GUI which can control each joint to test the model's behavior, which can be launched as follows: "], "package_tt": ["mico_description", "urdf/", "robots/", "meshes/", "wpi_jaco", "mico_description", "gui"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch mico_description display.launch", "roslaunch mico_description display.launch gui:=true"]},
{"url": "https://wiki.ros.org/settlerlib", "package": "settlerlib", "package_summary": ["Defines helper functions and routines that greatly help when trying to create a settler\n    for a specific sensor channel. This package is experimental and unstable.\n    Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mrp2_bringup", "package": "mrp2_bringup", "package_summary": ["Launch files and configurations for starting MRP2 robot in a real environment."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/rosbag_image_compressor", "package": "rosbag_image_compressor", "package_summary": ["The rosbag_image_compressor package.\n  This package has a script to compress and decompress images inside a bag file."]},
{"url": "https://wiki.ros.org/rocon_tutorial_msgs", "package": "rocon_tutorial_msgs", "package_summary": ["Messages used by rocon tutorials."]},
{"url": "https://wiki.ros.org/kingfisher_viz", "package": "kingfisher_viz", "package_summary": ["Visualization and rviz helpers for Kingfisher"], "package_details": [" ", " "]},
{"url": "https://wiki.ros.org/razer_hydra", "package": "razer_hydra", "package_summary": ["Unofficial driver and ROS node for Razer Hydra"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "Please report bugs and request features on the github issue tracker: ", " "], "package_tt": ["hydra_calib", "hydra_raw", "hydra_joy", "~device", "string", "~publish_tf", "bool", "false", "true", "hydra_base", "hydra_<left/right>_pivot", "hydra_<left/right>_grab", "~polling_ms", "int", "~corner_hz", "double", "~use_grab_frame", "bool", "false", "true", "grab_frame", "pivot_frame", "~px,py,pz", "double", "hydra_<left/right>_pivot", "~gx,gy,gz", "double", "hydra_<left/right>_grab"], "package_code": ["roscd razer_hydra\n", "./configure_udev_rules", "roslaunch razer_hydra hydra.launch publish_tf:=true/false", "rostopic echo /hydra_calib", "roslaunch razer_hydra hydra.launch corner_hz:=2.5"]},
{"url": "https://wiki.ros.org/b21_teleop", "package": "b21_teleop", "package_summary": ["Teleop Controller for B21"]},
{"url": "https://wiki.ros.org/kinect_aux", "package": "kinect_aux", "package_summary": ["A standalone driver for the Kinect accelerometers and tilt motor."], "package_details": [" ", " is now a standalone package. In Electric it was a package in ", ", which is deprecated. ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This driver provides access to additional features present in the Kinect sensor: accelerometer, tilt, and LED. One may use it in parallel with the ", " driver. ", "Assuming a catkin workspace has been created as described in ", ", follow the steps below. "], "package_tt": ["kinect_aux", "/tilt_angle", "/led_option", "/imu", "/cur_tilt_angle", "/cur_tilt_status", "device_index", "int"], "package_code": ["$ sudo apt-get install ros-groovy-kinect-aux", "$ sudo apt-get install ros-hydro-kinect-aux", "$ sudo apt-get install ros-indigo-kinect-aux", "$ sudo apt-get install libusb-1.0-0 libusb-1.0-0-dev", "$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/muhrix/kinect_aux.git -b groovy\n", "$ cd ~/catkin_ws\n", "$ catkin_make", "$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/muhrix/kinect_aux.git -b hydro\n", "$ cd ~/catkin_ws\n", "$ catkin_make", "$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/muhrix/kinect_aux.git -b indigo\n", "$ cd ~/catkin_ws\n", "$ catkin_make", "$ rosrun kinect_aux kinect_aux_node", "$ rostopic pub /tilt_angle std_msgs/Float64 -- -15", "$ rostopic echo /cur_tilt_angle"]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20293/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/create_gazebo_plugins", "package": "create_gazebo_plugins", "package_summary": ["Gazebo plugins for the iRobot Create"], "package_details": [" ", "\n", "\n", "\n", "\n", "The plugin is configured throught the parameters given in the URDF description. See the ", " for details. ", "Have a look at the ", " package to find out how to use this plugin. "]},
{"url": "https://wiki.ros.org/pr2_sith", "package": "pr2_sith", "package_summary": ["An extension of the PR2 props demo, but instead of high fives, the PR2 swings a lightsaber until it detects an impact."], "package_details": ["\n", "\n", "\n", "\n", "This, along with ", " gave me an idea. Essentially, what if you did the same exact demo, with slightly different arm positions, and a plastic lightsaber in the robots hand.  "]},
{"url": "https://wiki.ros.org/rqt_py_trees", "package": "rqt_py_trees", "package_summary": ["rqt_py_trees provides a GUI plugin for visualizing py_trees behaviour trees based on rqt_tf_tree."], "package_details": ["\n", " ", "See also ", ", ", ", ", " "]},
{"url": "https://wiki.ros.org/remote_manipulation_markers", "package": "remote_manipulation_markers", "package_summary": ["A set of interactive markers for various methods of remote teleoperation manipulation of 6-DOF robot end-effectors"], "package_details": ["\n", "\n", " ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"remote_manipulation_markers\" in rosdoc: /home/rosbot/docs/api/remote_manipulation_markers/manifest.yaml ", "\n", "\n", "\n", "\n", "\n", "The ", " package contains interactive marker servers for a set of remote manipulation interaction approaches.  The approaches include Free Positioning, Constrained Positioning, and Point-and-Click.  These interactive marker servers are intended for use with rviz or with Robot Web Tools interfaces. ", "This package includes three approaches:  Free Positioning (FP), Constrained Positioning (CP), and Point-and-Click (P&C).  The three approaches are shown below, with interaction points for setting initial poses shown in yellow, and interaction points for adjusting poses shown in blue. ", "Free positioning uses a ring-and-arrow marker which can be clicked and dragged to individually adjust translation along and rotation about each Cartesian axis.  Constrained positioning uses a sphere marker to first set a grasp point, followed by setting an approach angle by clicking on the surface of the sphere.  The approach angle is constrained to pass through the grasp point.  Point-and-click makes use of autonomous grasp calculation, and involves the user selecting a previously calculated grasp for execution from a list of potential grasps.  Further details on these can be found in ", ", published in HRI 2017.  The approaches are designed for both 2D and 3D visualization modes.  For full details and a comparison of the efficiency and effectiveness of each approach in both 2D and 3D visualization modes, see our IJRR 2019 article ", ". Videos of the approaches in action can be found ", " and ", ". ", "To install the ", " package, you can install from source with the following commands: ", "Note that ", " and ", " include a boolean parameter ", ".  Setting ", " to true will launch a ", " node that corresponds to the free or constrained positioning node. ", "If you use this package in your work, please cite our ", ": ", "David Kent, Carl Saldanha, and Sonia Chernova.  Leveraging Depth Data in Remote Robot Teleoperation Interfaces for General Object Manipulation. ", ", 2019. "], "package_tt": ["remote_manipulation_markers", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "gripper_marker_pose", "reset_marker_pose", "base_link", "string", "eef_link", "string", "grasp_topic", "string", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "gripper_marker_pose", "clear_gripper_marker", "clear_full_marker", "create_sphere", "grasp_topic", "string", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "/grasp_sampler/sampled_grasps", "calculatedPosesTopic", "cycle_grasps", "grasp_topic", "string", "calculated_poses_topic", "string", "/free_positioning/gripper_marker_pose", "marker_node_name", "marker_node_name", "string", "remote_manipulation_markers", "free_positioning.launch", "constrained_positioning.launch", "run_separate_vis", "run_seperate_vis", "gripper_marker_vis"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch remote_manipulation_markers free_positioning.launch", "roslaunch remote_manipulation_markers constrained_positioning.launch", "roslaunch remote_manipulation_markers point_and_click.launch"]},
{"url": "https://wiki.ros.org/scriptable_monitor_rqt", "package": "scriptable_monitor_rqt", "package_summary": ["scriptable_monitoring"]},
{"url": "https://wiki.ros.org/rh_p12_rn_manager", "package": "rh_p12_rn_manager", "package_summary": ["Manager package using ROBOTIS framework to control the RH-P12-RN"], "package_details": [" ", "\n", "\n", "\n", "\n"], "package_tt": ["gazebo", "bool", "offset_file_path", "string", "robot_file_path", "string", "init_file_path", "string", "device_name", "string", "baud_rate", "int"]},
{"url": "https://wiki.ros.org/rqt_graphprofiler", "package": "rqt_graphprofiler", "package_summary": ["An experimental visualization system for anonymous publish subscribe architectures."], "package_details": [" "]},
{"url": "https://wiki.ros.org/alliance", "package": "alliance", "package_summary": ["This package implements the ALLIANCE multi-robot task allocation architecture."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/neo_base_mpo_500", "package": "neo_base_mpo_500", "package_summary": ["launchfiles for MPO_500"]},
{"url": "https://wiki.ros.org/libsegwayrmp", "package": "libsegwayrmp", "package_summary": ["This is a C++ library for interfacing with Segway's RMP line of robotic platforms."], "package_details": [" ", " ", " ", "This is an external library that provides access to the segway rmp's.  It is maintained by William Woodall ", ". "]},
{"url": "https://wiki.ros.org/object_recognition_clusters", "package": "object_recognition_clusters", "package_summary": ["The object_recognition_clusters package"]},
{"url": "https://wiki.ros.org/kdl_wrapper", "package": "kdl_wrapper", "package_summary": ["C++ wrapper for easily using KDL kinematic solvers with robots defined in ROS through URDF files. Wraps the kdl and kdl_parser packages for generating KDL kinematic chains from URDF by just taking as inputs the IDs of the root and tip of the kinematic chain of a robot manipulator."], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", " ", "This package requires the ", " package to be installed. ", "An example C++ code for doing inverse kinematics with the PR2 is given under ", " : ", "3. Compile the ", " package. "], "package_tt": ["kdl_wrapper"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-<rosdistro>-pr2-common", "roslaunch pr2_description upload_pr2.launch kinect:=TRUE", "rosrun kdl_wrapper pr2_kdl_wrapper_example"]},
{"url": "https://wiki.ros.org/robotino_msgs", "package": "robotino_msgs", "package_summary": ["Message defintions for the Festo Robotion robot"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"robotino_msgs\" in rosdoc: /home/rosbot/docs/api/robotino_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/robotis_framework_common", "package": "robotis_framework_common", "package_summary": ["The package contains commonly used Headers for the ROBOTIS Framework."], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/rrt_exploration", "package": "rrt_exploration", "package_summary": ["A ROS package that implements a multi-robot RRT-based map exploration algorithm. It also has the image-based frontier detection that uses image processing to extract frontier points"], "package_details": [" If you are using this package in your research work, please cite this ", ". ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", "A mobile robot that can be used with the ", " (publishes /odom and /tf. Receives velocity commands ..). The robot must also be equipped with a laser scanner or any sensor that publishes laser scan message (", "). ", "This package provides an exploration strategy for single or multiple robots. However, for it to work, you should have set your robots ready using the navigation stack. And each robot should run the \"slam_gmapping\" node from the ", " package. ", "Note: If you want to quickly run and test the package, you can try out the ", " package which provides Gazebo simulation for single and multiple robots, you can use it directly with this package. ", "The move_base_node node, which brings up the navigation stack on the robot, must be running. This package (rrt_exploration) generates target exploration goals, each robot must be able to receive these points and move towards them. This is why the navigation stack is needed. Additionally, each robot must have a global and local cost maps. All of these are proivded from the ", ". ", "The robot should have a local map generated from the ", " package. ", "For the multi-robot configuration, the package doesn't require special network configuration, it simply works by having a single ROS master (can be one of the robots). So on the other robots, the ", " parameter should be pointing at the master's address. For more information on setting up ROS on multiple machines, follow ", " link. ", "All robot's frames should be prefixed by its name. Naming of robots starts from \"/robot_1\", \"/robot_2\", \"/robot_3\", .. and so on. So for robot_1, the frames in the ", " tree should look like this: ", "The move_base_node node, which brings up the navigation stack on the robot, must be running. This package (rrt_exploration) generates target exploration goals, each robot must be able to receive these points and move towards them. This is why the navigation stack is needed. Additionally, each robot must have a global and local cost maps. All of these are proivded from the ", ". ", "Each robot should have a local map generated from the ", " package. ", "There should be a node that merges all the local maps into one global map. You can use the ", " package developed by Jiri Horner. "], "package_tt": ["map", "clicked_point", "detected_points", "~shapes", "~map_topic", "string", "~eta", "float", "map", "clicked_point", "detected_points", "~shapes", "~/robot_1/base_link", "string", "~map_topic", "string", "~eta", "float", "map", "detected_points", "shapes", "~map_topic", "string", "map", "robot_x/move_base_node/global_costmap/costmap", "The\u00a0goals\u00a0topic", "frontiers", "centroids", "filtered_points", "~map_topic", "string", "~costmap_clearing_threshold", "float", "~info_radius", "float", "~goals_topic", "string", "~n_robots", "float", "~namespace", "string", "~namespace_init_count", "float", "~rate", "float", "map", "Filtered\u00a0frontier\u00a0points\u00a0topic", "The\u00a0goals\u00a0topic", "~map_topic", "string", "~info_radius", "float", "~info_multiplier", "float", "~hysteresis_radius", "float", "~hysteresis_gain", "float", "~frontiers_topic", "string", "~n_robots", "float", "~namespace", "string", "~namespace_init_count", "float", "~delay_after_assignement", "float", "~global_frame", "string"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-gmapping", "sudo apt-get install ros-$ROS_DISTRO-navigation", "sudo apt-get install python-opencv", "sudo apt-get install python-numpy", "sudo apt-get install python-scikits-learn", "@INPROCEEDINGS{8202319,\n", "author={H. Umari and S. Mukhopadhyay},\n", "booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n", "title={Autonomous robotic exploration based on multiple rapidly-exploring randomized trees},\n", "year={2017},\n", "volume={},\n", "number={},\n", "pages={1396-1402},\n", "keywords={},\n", "doi={10.1109/IROS.2017.8202319},\n", "ISSN={},\n", "month={Sept},}"]},
{"url": "https://wiki.ros.org/modelica_bridge", "package": "modelica_bridge", "package_summary": ["ROS package for bridging ROS with Modelica tools via TCP/IP sockets.\n    Meant for use along with the ROS_Bridge Modelica package, made by the same developer."], "package_details": [" ", "\n", " establishes a bridge between ", ", a component-oriented equation-centric modeling language, and ROS. The connection is done via TCP/IP sockets; in ROS, the ", " provides a node to run the server socket. ", ", ", "'s companion package in ", ", contains a ", " component which runs a client socket connection to ROS. Using TCP/IP sockets allow the messages transmitted between ", " and ROS with preservation of order and content. The combination of ", " and ", " lets ", " models and ROS control architectures communicate with each other without any additional internal configurations. ", " ", " ", "\n", " is a ROS package, and so can only be run in Linux; ", " similarly can only be run on ", " systems, due to the current method of implementing sockets. Below is a list of ", " tools and operating systems ", " has been tested on: ", "\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 9091) ", " (", ", default: 20) ", " ", "To get a better understanding of the way the bridge works, view the image below, depicting the flow of information between ", " and ROS.  ", "Here are a few ", " that explain how to use the ", " package in detail: "], "package_tt": ["modelica_bridge", "modelica_bridge", "modelica_bridge", "Modelica", "block", "Modelica", "modelica_bridge", "ROS_Bridge", "Modelica", "Modelica", "Modelica", "ROS_Bridge", "Modelica", "modelica_bridge", "modelica_bridge", "Modelica", "Modelica", "Modelica", "n", "n", "n-1", "n", "n", "n+1", "samplePeriod", "Modelica", "modelica_bridge", "ROS_Bridge", "Modelica", "ROS_Bridge", "modelica_bridge", "modelica_bridge", "modelica_bridge", "/control_values", "/model_values", "port_num_", "int", "update_rate_", "int"]},
{"url": "https://wiki.ros.org/smartek_camera", "package": "smartek_camera", "package_summary": ["Node for publishing frames from a Smartek camera"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosruby_common", "package": "rosruby_common", "package_summary": ["rosruby_common libraries"], "package_details": [" ", "\n", "See ", ". "]},
{"url": "https://wiki.ros.org/airbus_ssm_core", "package": "airbus_ssm_core", "package_summary": ["The airbus_ssm_core package"], "package_details": ["\n", " ", " ", " ", " ", " ", " ", " ", "\n", " ", "The SSM_core package is a SMACH overhaul including an interpretor of SCXML files.(", "). ", "It creates a finite state machine (based on SMACH) using the data from the SCXML file. ", "It can be usefull if you want to create a state machine using a GUI that generate a SCXML file like : ", "Using the 'id' \"skill\" and set the 'expr' value to ", "the name of the skill you want to use", ". ", "In order to maintain the consistency of the ", ", you have to link every outcome of this State inside the SCXML. If you forget to link one, them the ", " consistency check will fail. ", "If you want to put the skill.xml file in a different folder/pkg, use this syntax ", " ", "If you want to put scxml files in a different folder, use this syntax ", " or you can give the pull path to the file. "], "package_code": ["<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n", "<scxml initial=\"Input Number\">\n", "    <datamodel>\n", "        <data id=\"skill_file\" expr=\"${airbus_ssm_tutorial}/resources/skills.xml\"/>\n", "    </datamodel>\n", "    <state id=\"Input Number\">\n", "        <datamodel>\n", "            <data id=\"skill\" expr=\"Input\"/>\n", "        </datamodel>\n", "        <transition event=\"Out\" target=\"Primes\"/>\n", "        <transition event=\"Test\" target=\"IsPrime\"/>\n", "        <transition event=\"Retry\" target=\"Input Number\"/>\n", "    </state>\n", "    <state id=\"Primes\">\n", "        <datamodel>\n", "            <data id=\"skill\" expr=\"Primes\"/>\n", "        </datamodel>\n", "        <transition event=\"Off\" target=\"End\"/>\n", "        <transition event=\"Reset\" target=\"Input Number\"/>\n", "        <transition event=\"Continue\" target=\"Input Number\"/>\n", "    </state>\n", "    <state id=\"IsPrime\">\n", "        <transition type=\"external\" event=\"Return\" target=\"Input Number\"/>\n", "        <datamodel>\n", "            <data id=\"skill\" expr=\"isPrime\"/>\n", "        </datamodel>\n", "    </state>\n", "    <final id=\"End\"/>\n", "</scxml>", "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n", "<scxml initial=\"Input Number\">\n", "     <datamodel>\n", "        <data id=\"skill_file\" expr=\"${airbus_ssm_tutorial}/resources/skills.xml\"/>\n", "    </datamodel>\n", "    ...\n", "</scxml>", "<?xml version=\"1.0\"?>\n", "<skills>\n", "  <skill name=\"Input\"   pkg=\"airbus_ssm_tutorial\" module=\"airbus_ssm_tutorial1.skills\" class=\"Input\"/>\n", "  <skill name=\"isPrime\" pkg=\"airbus_ssm_tutorial\" module=\"airbus_ssm_tutorial1.skills\" class=\"isPrime\"/>\n", "  <skill name=\"Primes\"  pkg=\"airbus_ssm_tutorial\" module=\"airbus_ssm_tutorial1.skills\" class=\"Primes\"/>\n", "</skills>", "<state id=\"IsPrime\">\n", "  <datamodel>\n", "     <data id=\"skill\" expr=\"isPrime\"/>\n", "  </datamodel>\n", "  ...\n", "</state>", "roslaunch airbus_ssm_core ssm_descriptor.launch skill_xml_file:=empty_register.xml output_file:=/tmp/descriptor.txt", "<state id=\"Parent\">\n", "  <initial>\n", "    <transition type=\"external\" target=\"foo\"/>\n", "  </initial>\n", "  <state id=\"foo\">\n", "     <transition event=\"to_bar1\" target=\"Final_5\"/>\n", "     <transition event=\"to_bar2\" target=\"Final_7\"/>\n", "   </state>\n", "   <final id=\"Final_5\"/>\n", "   <final id=\"Final_7\"/>\n", "   <transition event=\"to_bar1\" target=\"bar1\"/>\n", "   <transition event=\"to_bar2\" target=\"bar2\"/>\n", "</state>", "<parallel id=\"Parallel_1\">\n", "  <state id=\"A\"/>\n", "  <state id=\"B\"/>\n", "  <state id=\"C\"/>\n", "  <transition event=\"Transition1\" target=\"bar1\" cond=\"A.outA1 AND B.outB1\"/>\n", "  <transition event=\"Transition2\" target=\"bar2\" cond=\"B.outB2 OR C.outC\"/>\n", "  <transition event=\"Transition3\" target=\"bar3\" cond=\"A.outA2\"/>\n", "</parallel>", "\"/state/./outcome/\" \"AND/OR\" \"/state/./outcome/\"", "roslaunch airbus_ssm_core ssm.launch scxml_file:=default", "roslaunch airbus_ssm_core ssm.launch scxml_file:=${airbus_ssm_core}/resources/defaulf.scxml", "roslaunch airbus_ssm_core ssm_action_server.launch "]},
{"url": "https://wiki.ros.org/libfovis", "package": "libfovis", "package_summary": ["\n\n  Fovis is a visual odometry library that estimates the 3D motion of a camera using a source of depth information for each pixel. It's designed for sensors such as calibrated stereo cameras and RGB-D cameras like the Microsoft Kinect.\n\n  "], "package_details": [" Albert S. Huang, Abraham Bachrach, Peter Henry, Michael Krainin, Daniel Maturana, Dieter Fox, and Nicholas Roy. Int. Symposium on Robotics Research (ISRR), Flagstaff, Arizona, USA, Aug. 2011 ", ". "]},
{"url": "https://wiki.ros.org/airbus_plugin_rqt", "package": "airbus_plugin_rqt", "package_summary": ["The airbus_plugin_rqt package"]},
{"url": "https://wiki.ros.org/rv7fl_moveit_config", "package": "rv7fl_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the rv7fl with the MoveIt! Motion Planning Framework"]},
{"url": "https://wiki.ros.org/mr_teleoperator", "package": "mr_teleoperator", "package_summary": ["Multi-robot teleoperation package collection"], "package_details": [" ", "\n", "\n"], "package_tt": ["mr_teleoperator"]},
{"url": "https://wiki.ros.org/pano_py", "package": "pano_py", "package_summary": ["\n\n        This is a python wraper around the pano_core library (I think)\n\n  "], "package_details": [" "]},
{"url": "https://wiki.ros.org/mrpt_sensorlib", "package": "mrpt_sensorlib", "package_summary": ["C++ library for the base generic MRPT sensor node"]},
{"url": "https://wiki.ros.org/rosboost_cfg", "package": "rosboost_cfg", "package_summary": ["Contains scripts used by the rosboost-cfg tool for determining cflags/lflags/etc. of boost on your system"]},
{"url": "https://wiki.ros.org/robot_pose_publisher", "package": "robot_pose_publisher", "package_summary": ["A Simple Node to Publish the Robot's Position Relative to the Map using TFs"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains a ROS node that will publish the transform between the ", " frame and the ", " frame as a pose message. This information is useful if you are interested in the robots position but do not want to stream the entire TF tree to get this information. An example use case is for web widgets. ", "To run the node, ensure that a valid transform exists between the ", " frame and the ", " frame (e.g., from a navigation node), and run the following: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["robot_pose_publisher", "/base_link", "/map", "robot_pose_publisher", "/base_link", "/map", "robot_pose", "/base_link", "/map", "robot_pose_publisher", "robot_pose_publisher", "robot_pose_publisher", "robot_pose_publisher", "/base_link", "/map"], "package_code": ["\n", "\n", "\n", "\n", "sudo apt-get install ros-fuerte-robot-pose-publisher", "\n", "\n", "\n", "\n", "sudo apt-get install ros-groovy-robot-pose-publisher", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-robot-pose-publisher", "\n", "\n", "\n", "\n", "sudo apt-get install ros-jade-robot-pose-publisher", "rosrun robot_pose_publisher robot_pose_publisher"]},
{"url": "https://wiki.ros.org/rosjava", "package": "rosjava", "package_summary": ["Contents", " ", "\n", "Rosjava provides both a ", " for ros communications in java as well as growing list of core tools (e.g. tf, geometry) and drivers (e.g. hokuyo). ", "Official source code for rosjava projects can be found on github in the ", ". ", "Rosjava is largely used to build Android applications. For information specific to that use case refer to the ", " wiki page. ", "\n", "The documentation on the wiki here provides a general overview of the rosjava ecosystem and install/build instructions. For tutorials and coding level API documentation, refer to the github generated documentation. Links below. ", " : what to expect and what tools are used for rosjava development. ", " : list of all official and semi-official packages in the rosjava-android ecosystem. ", " : the anatomy of a typical rosjava package. ", " : some environment variables that can influence the build of rosjava stacks. ", " : messages are handled slightly differently in rosjava. ", " : detailed coding level documentation and tutorial information. ", " : frequently asked questions. ", "\n", "\n", "These tutorials revolve mostly around development in a catkin-rosjava workspace environment (aside from the installation).  ", "Installation instructions from debs, sources, or maven. ", "Script wizards for conveniently creating rosjava packages and projects. ", "How to create, compile, and execute a simple publisher and subscriber in rosjava. ", "It shows how to create, compile and execute a service (both server and client) in Rosjava. ", "How to create, compile and deploy rosjava libraries (maven artifacts). ", "Generating ros-java message jars and artifacts ", "Useful tips on how to survive in a catkin-gradle based rosjava workspace. ", " ", "\n", "Regular development on top of rosjava (free of catkin/ros itself) should not require any expertise aside from that which you already have and as such, is only briefly mentioned in the ", " tutorial. ", "\n", "Packaging your java (possibly mixed) projects as debs. ", "Share java and android artifacts via our github maven repo. ", " ", "\n", " ", " ", " ", " "], "package_details": ["\n "]},
{"url": "https://wiki.ros.org/rocon_uri", "package": "rocon_uri", "package_summary": ["Module for working with rocon uri strings."], "package_details": [" ", "\n", "\n", "\n"], "package_tt": ["rocon:/turtlebot2/cybernetic_pirate#rocon_apps/im_here_to_make_you_lazy", "rocon:/pr2/bob#rocon_apps/look_menacing"], "package_code": ["rocon://concert_name/hardware_platform/name/application_framework/operating_system#rocon_app", "Utility for introspecting on rocon uri strings.\n", "\n", "Commands:\n", "        rocon_uri parse URI     parse and attempt to validate a rocon URI.\n", "        rocon_uri fields        print a full list of permitted fields in a rocon uri string.\n", "        rocon_uri rules         print a full list of the ebnf rules for a rocon uri string."]},
{"url": "https://wiki.ros.org/manipulator_h_base_module_msgs", "package": "manipulator_h_base_module_msgs", "package_summary": ["The manipulator_h_base_module_msgs package\n    This package includes ROS messages and services for manipulator_h_base_module_msgs"], "package_details": [" ", "\n", "\n", " ", "\n  ", " ", "\n  ", "\n", " ", "\n ", " ", "\n ", " "]},
{"url": "https://wiki.ros.org/manipulator_h", "package": "manipulator_h", "package_summary": ["ROS packages for the ROBOTIS MANIPULATOR-H (metapackage)"], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/pyclearsilver", "package": "pyclearsilver", "package_summary": ["A bunch of libraries to interface clearsilver with python and many databases."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/phm_tools", "package": "phm_tools", "package_summary": ["The phm_tools meta package"], "package_details": ["\n", "\n", " ", " ", " Autonomous Transfer Vehicle ", " ", "Use Case Scenario Module, Sub-Module and Components List ", " ", " Use Case General Block Diagram ", " ", " General Failure Rates and Reliabilities of Components ", " ", " System Hazard Rate and Reliability at Different Temperature Conditions ", " Reliability of System at Different Temperatures ", " ", " ", " GAZEBO Test Environment ", " Locations of Some Specific Points ", " Followed Paths and Distance Between Each Neighbour Points ", " System PoTC for Each Route Segment ", "\n", "In the motor sub-module, failure rate of this component is selected as ", ". In encoder sub-module, we selected magnetic rotary encoder unit. Only use parameters  \u03bb", " (other parameters are negligible), the failure rate of encoder unit selected as ", ". ", "In the sensor module, there is only one component which is SICK S300 Laser Sensor and the failure rate of this component selected as ", " using product datasheet.  ", "In order to calculate hazard rate of the power card sub-module, we utilized diodes, capacitors and inductors. In addition, hazard rate of the fuse in the power card sub-modules selected as ", ". Hazard rate of the selected buck converter (LM 2596), is found as ", ". There is one more component in the Power Module which is battery and the failure rate of this component selected as ", ". ", "General failure rates and reliabilities of the all components at 35 \u2103 are shown in Table 2.  ", "Using Table 2, hazard rate of the system \u03bb", " calculated as ", ". In order to calculate the reliability of the system, we use Exponential Distribution function with the system hazard rate and time. Usage time selected as 1000 hours. The reliability of the system  R", " calculated as ", ".  "]},
{"url": "https://wiki.ros.org/baxter_ikfast_right_arm_plugin", "package": "baxter_ikfast_right_arm_plugin", "package_summary": ["The baxter_ikfast_right_arm_plugin package"]},
{"url": "https://wiki.ros.org/neo_platformctrl_mecanum", "package": "neo_platformctrl_mecanum", "package_summary": ["transformation Node for neobotix robots with omnidirectional drive"], "package_details": ["\n", "\n", "\n", " "], "package_tt": ["/joint_states", "/cmd_vel", "/odom", "/cmd_joint_traj", "kinematics", "wheelDiameter", "robotWidth", "robotLength", "sendTransform"]},
{"url": "https://wiki.ros.org/kdl_acc_solver", "package": "kdl_acc_solver", "package_summary": ["Wraps the kdl and kdl_parser packages for generating KDL kinematic chains from URDF."], "package_details": [" "]},
{"url": "https://wiki.ros.org/segwayrmp", "package": "segwayrmp", "package_summary": ["segwayrmp"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ridgeback_desktop", "package": "ridgeback_desktop", "package_summary": ["Packages for working with Ridgeback from a ROS desktop."], "package_details": ["To get started using Ridgeback from a desktop ROS environment, see ", ". "]},
{"url": "https://wiki.ros.org/rosclean", "package": "rosclean", "package_summary": ["rosclean: cleanup filesystem resources (e.g. log files)."], "package_details": [" ", "\n", "\n", "\n", " ", " will remove directories associated with storing ROS-related log files. You will be asked to confirm each deletion and it is important that you verify the command that ", " executes is correct. Otherwise you ", " "], "package_tt": ["rosclean\u00a0purge", "rosclean\u00a0purge"], "package_code": ["Usage: rosclean <command>\n", "\n", "Commands:\n", "  rosclean check        Check usage of log files\n", "  rosclean purge        Remove log files", "$ rosclean check\n", "348K ROS node logs\n", "20K rosmake logs", "$ rosclean purge\n", "Purging ROS node logs.\n", "PLEASE BE CAREFUL TO VERIFY THE COMMAND BELOW!\n", "Okay to execute:\n", "\n", "rm -rf /u/username/.ros/log\n", "(y/n)?"]},
{"url": "https://wiki.ros.org/melfa_description", "package": "melfa_description", "package_summary": ["The melfa_description package"]},
{"url": "https://wiki.ros.org/rh_p12_rn_gui", "package": "rh_p12_rn_gui", "package_summary": ["This package provides GUI interface to control the RH-P12-RN"], "package_details": [" ", "\n"]},
{"url": "https://wiki.ros.org/robot_localization", "package": "robot_localization", "package_summary": ["Provides nonlinear state estimation through sensor fusion of an abritrary number of sensors.", "Documentation for ", " is now ", ". "], "package_details": ["  Use GitHub to ", ". [", "]", "\n "], "package_tt": ["robot_localization", "robot_localization", "robot_localization", "robot_localization", "robot_localization", "robot_localization", "robot_localization"]},
{"url": "https://wiki.ros.org/ros_glass_tools", "package": "ros_glass_tools", "package_summary": ["The ros_glass_tools package - Provides ROS interface to Google Glass for topic\n        monitoring and robot voice control"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "<rosparam name=\"monitors\"> ", "</rosparam> ", "\n", "\n", "\n", "<rosparam param=\"global_commands\"> [ [stop, /all_stop], [go, /all_go] ] ", "</rosparam> ", "<rosparam param=\"robots\"> ", "<rosparam param=\"robot_commands\"> [ [forward, move_forward], [backward, move_backward] ] </rosparam> ", "\n", " ", "To successfully communicate to the ROS server from the Google Glassware, the rosbridge_suite package is required.  Follow the instructions to install and run the rosbridge webserver at ", ". ", "Next, the ROS tools must be configured as to enable communication in and functionality between the ROS and the Google Glasses.  Obtain the source code from github (", ") and build the  package using the catkin tools.  It is important that the \"Commands\" and \"Topics\" services are built.  After building, the ROS system is ready to be run. ", "To run the glass applications, it is first necessary to setup your development environment to use the Glass Development Kit Sneak Peak. Instructions to do so can be found at ", ".   It is important that you install the latest version, as the API has changed, and the code will not compile on the older versions of the GDK.  The Glassware must also have debug mode enabled.  The instructions to do so are also found on the Google Glass development site above. ", "After the environment is setup, the applications must be imported into the Eclipse Android environment.  This is done by selecting \"import\" -> \"Existing Android Code Into Workspace\" -> and selecting the \"Applications\" directory in the ros_glass_tools package.  All three applications can be imported in this way. After importing, ensure that the \"Glass Development Kit Sneak Peek\" is selected as the Android Build Target in the project properties.   Additionally, this project relies on the Autobahn Websocket library (", ").  Ensure that these jars are in the libs directory and on the build path. ", "public final static String HOST_ADDRESS = \"ws://", "\"; ", "[a, b] </rosparam> ", "\"robot one forward\" -> a/move_forward ", "\"robot two backward\" -> b/move_backward ", "\"all forward\" -> a/move_forward & b/move_forward ", "\"execute stop\"  \u2013> /stop ", "\"execute go\" \u2013> /go ", "\"robot one forward\" \u2013> /a/forward "]},
{"url": "https://wiki.ros.org/sensor_msgs", "package": "sensor_msgs", "package_summary": ["This package defines messages for commonly used sensors, including\n    cameras and scanning laser rangefinders."], "package_details": ["A number of these messages have ROS ", " dedicated to manipulating them.  "]},
{"url": "https://wiki.ros.org/slam_constructor", "package": "slam_constructor", "package_summary": ["The package provides implementation of several 2D laser-based simultaneous\n    localization and mapping (SLAM) algorithms (tinySLAM, vinySLAM, GMapping)\n    created with the SLAM constructor framework. The framework provides common\n    SLAM components that may help to develop custom SLAM algorithms and can be\n    accessed by provided links."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The SLAM constructor framework provides common functionality and classes that may be used to create custom SLAM algorithms (currently only 2D laser scan-based methods are supported). It also includes implementation of several SLAM algorithms ", ", ", " and ", ", which can be used as a base of a new SLAM algorithm. ", "Current implementation requires odometry data and laser scans to be provided by the ROS topics (see ", "). It also supposes that a laser scanner is fixed in (0, 0) of a robot and mounted horizontally. ", "Each algorithm is supplied with ", "-files for the ", " and ", " datasets that give the idea of how to launch algorithms. The ", " launch-files can be used in general case if data provided by a dataset do not require any preprocessing. For example, tinySLAM can be launched in the following way: ", "In order to run an algorithm on data received in real time you can remove a dataset player node from a launch file, but make sure that sensor data are provided through ", ". ", "GMapping has the following additional parameters (note that ", " shouldn't be provided or ", " be ", "), see ", " documentation for details: ", "The package provides the tool ", " to launch algorithms in the offline mode to process ", " datasets. "], "package_tt": ["_mit_", "~in/lscan2D/ros/topic/name", "/base_scan", "~in/odometry/ros/tf/odom_frame_id", "odom_combined", "~ros/tf/map_frame_id", "map", "~ros/tf/robot_pose_frame_id", "robot_pose", "~ros/tf/async_correction", "false", "true", "map", "odom", "~ros/subscribers_queue_size", "1000", "~ros/tf/buffer_duration", "5.0", "~ros/filter_queue_size", "1000", "~ros/rviz/map_publishing_rate", "5.0", "~ros/skip_exceeding_lsr_vals", "false", "true", "false", "~slam/map/height_in_meters", "10.0", "~slam/map/width_in_meters", "10.0", "~slam/map/meters_per_cell", "0.1", "~slam/performance/use_trig_cache", "false", "~slam/occupancy_estimator/type", "const", "const", "area", "~slam/occupancy_estimator/base_occupied/prob", "0.95", "~slam/occupancy_estimator/base_occupied/qual", "1.0", "~slam/occupancy_estimator/base_empty/prob", "0.01", "~slam/occupancy_estimator/base_empty/qual", "1.0", "~slam/mapping/blur", "0.0", "~slam/mapping/max_range", "<infinity>", "~slam/scmtch/type", "<undefined>", "MC", "~slam/scmtch/MC/attempts_limit", "100", "~slam/scmtch/MC/seed", "<random>", "~slam/scmtch/MC/dispersion/translation", "0.2", "~slam/scmtch/MC/dispersion/rotation", "0.1", "~slam/scmtch/MC/dispersion/failed_attempts_limit", "20", "HC", "~slam/scmtch/HC/distortion/translation", "0.1", "~slam/scmtch/HC/distortion/rotation", "0.1", "~slam/scmtch/HC/distortion/failed_attempts_limit", "6", "BF", "~slam/scmtch/BF/[x,\u00a0y,\u00a0t]/from", "-0.5", "-0.5", "-5\u00b0", "~slam/scmtch/BF/[x,\u00a0y,\u00a0t]/to", "0.5", "0.5", "5\u00b0", "~slam/scmtch/BF/[x,\u00a0y,\u00a0t]/step", "0.1", "0.1", "1\u00b0", "~slam/scmtch/spe/type", "<undefined>", "wmpp", "~slam/scmtch/spe/wmpp/weighting/type", "<undefined>", "even", "viny", "ahr", "~slam/scmtch/spe/wmpp/sp_skip_rate", "0", "~slam/scmtch/spe/wmpp/sp_max_usable_range", "-1.0", "~slam/scmtch/oope/type", "obstacle", "obstacle", "max", "mean", "overlap", "~slam/cell/type", "base", "base", "avg", "~slam/scmtch/oope/type", "custom", "~slam/particles/number", "30", "~slam/particles/sample/xy/mean", "0.0", "~slam/particles/sample/xy/sigma", "0.1", "~slam/particles/sample/theta/mean", "0.0", "~slam/particles/sample/theta/sigma", "0.03", "~slam/particles/sm_delta_lim/xy/min", "0.6", "~slam/particles/sm_delta_lim/xy/max", "0.8", "~slam/particles/sm_delta_lim/theta/min", "0.3", "~slam/particles/sm_delta_lim/theta/max", "0.4", "~slam/scmtch/oope/custom/fullness_threshold", "0.1", "~slam/scmtch/oope/custom/window_size", "1", "/tf", "/base_scan", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "odom_frame_id", "odom_combined", "map_frame_id", "odom_frame_id", "map_frame_id", "robot_pose_frame_id", "lslam2d_bag_runner", "<slam\u00a0type>", "viny", "tiny", "gmapping", "<bag\u00a0file>", "-v", "-t\u00a0<traj\u00a0file>", "traj\u00a0file", "-m\u00a0<map\u00a0file>", "map\u00a0file", "-p\u00a0<properties\u00a0file>", "key=value"], "package_code": ["roslaunch slam_constructor tiny_mit_run.launch path:=[path to dataset]", "lslam2d_bag_runner <slam type> <bag file>\n", "                   [-v] [-t <traj file>] [-m <map file>] [-p <properties file>]"]},
{"url": "https://wiki.ros.org/abb_resources", "package": "abb_resources", "package_summary": ["\n      Shared configuration data for ABB manipulators.\n    ", "\n      This package contains common urdf / xacro resources used by\n      ABB related packages.\n    "], "package_details": ["\n", "This package is part of the ", " program.  "]},
{"url": "https://wiki.ros.org/airbus_plugin_node_manager", "package": "airbus_plugin_node_manager", "package_summary": ["The airbus_plugin_node_manager package"]},
{"url": "https://wiki.ros.org/raspigibbon_msgs", "package": "raspigibbon_msgs", "package_summary": ["The raspigibbon_msgs package"]},
{"url": "https://wiki.ros.org/robotis_math", "package": "robotis_math", "package_summary": ["This package is a set of basic math fuctions for ROBOTIS's robots.\n    We provide some linear algebra and trajectory generation funntions and classes."], "package_details": [" ", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/baxter_ikfast_left_arm_plugin", "package": "baxter_ikfast_left_arm_plugin", "package_summary": ["The baxter_ikfast_left_arm_plugin package"]},
{"url": "https://wiki.ros.org/kurt_navigation_config", "package": "kurt_navigation_config", "package_summary": ["\n    This package holds common configuration files for running the ", " node on the Kurt\n    robot. It is modeled after pr2_navigation_config.\n  "]},
{"url": "https://wiki.ros.org/r2_moveit_generated", "package": "r2_moveit_generated", "package_summary": ["r2_moveit_generated"]},
{"url": "https://wiki.ros.org/create_node", "package": "create_node", "package_summary": ["iRobot Create ROS driver node\n    \n    ROS bindings for the Create/Roomba driver.\n    \n    This is based on otl_roomba driver by OTL, ported to use\n    create_driver's implementation instead. \n    This also contains a 'bonus' feature from the turtlebot \n    driver by Xuwen Cao and Morgan Quigley."]},
{"url": "https://wiki.ros.org/motoman_mpl_support", "package": "motoman_mpl_support", "package_summary": ["\n      ROS-Industrial support for the Motoman MPL series (and variants).\n    ", "\n      This package contains configuration data, 3D models and launch files\n      for Motoman MPL series manipulators. This currently includes the 80\n      model only.\n    ", "\n      Joint limits and max joint velocities are based on the information in\n      the Motoman data sheets. All URDFs / XACROs are based on the\n      default motion and joint velocity limits, unless noted otherwise (ie:\n      no support for high speed joints, extended / limited motion ranges or\n      other options).\n    ", "\n      Before using any of the configuration files and / or meshes included\n      in this package, be sure to check they are correct for the particular\n      robot model and configuration you intend to use them with.\n    "]},
{"url": "https://wiki.ros.org/kurt_navigation_slam", "package": "kurt_navigation_slam", "package_summary": ["\n    This package holds launch files for running the ", " node in\n    conjunction with [[gmapping | SLAM]] on a Kurt robot. It is modeled after\n    pr2_navigation_slam.\n  "]},
{"url": "https://wiki.ros.org/asr_mild_base_driving", "package": "asr_mild_base_driving", "package_summary": ["This package calculates and publishes the odometry information, transforms the velocity command into differential drive commands and writes it on the mild_base_driving bus"], "package_details": [" ", "\n", "\n", " ", " ", " ", " ", "\n", "\n", " if you want to start the node with the mild.launch files. ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "Get \"Ticks\" from the incremental encoder. Calculate the odometry from the ticks and publish them on the ROS-Topic /odom (", "). ", "This picture shows you how a differential drive robot drives, with different wheel velocities (al and ar). If al > ar the robot drives a curve to the right. If al = ar the robot drives straight. ", "- Dukenmotors Typ GR63x55 (", ") ", "- Maxon motorcontroller (", ") ", "cmd_vel ( ", ") ", "odom ( ", ") ", "Look at ", " on how to adapt the parameters. "], "package_code": ["roslaunch asr_mild_base_launch_files mild.launch", "rosrun asr_mild_base_driving mild_base_driving", "Can: Socket set successfully.\n", "CanListener: Started successfully.\n", "BaseController: Started successfully."]},
{"url": "https://wiki.ros.org/asr_mild_base_launch_files", "package": "asr_mild_base_launch_files", "package_summary": ["This package contains the launch files and different documents needed to start the system"], "package_details": [" ", "\n", "\n", " ", "\n", "\n", "\n", "Includes the mild.launch file which starts the ", " node and the ", " node. ", "Also here you can adapt the parameters for the laserscanner and the speed up of the velocity (look at the ", " and ", " documentation). "], "package_code": ["<launch>\n", "    <env name=\"ROSCONSOLE_CONFIG_FILE\" value=\"$(find asr_mild_base_launch_files)/log/rosconsole.config\" />\n", "\n", "    <node name=\"sick\" pkg=\"asr_mild_base_laserscanner\" type=\"asr_mild_base_laserscanner\" output=\"screen\" required=\"true\"/>\n", "    <param name=\"topic\" value=\"scan\" />\n", "    <!-- Laserscanner baudrate. Only four values: 9600, 19200, 38400, 500000. 38400 means 4 complete measurements in 1 sec. -->\n", "    <param name=\"baudrate\" value=\"500000\" />\n", "    <param name=\"serial\" value=\"/dev/rs422b\" />\n", "    <param name=\"init_attempts\" value=\"10\" />\n", "\n", "    <node name=\"can\" pkg=\"asr_mild_base_driving\" type=\"asr_mild_base_driving\" output=\"screen\" required=\"true\"/>\n", "    <!-- Speedup of the mild. 1 = normal velocity. 2 = double velocity. Float value. --> <param name=\"velocity\" value=\"1\" />\n", "</launch>", "roslaunch asr_mild_base_launch_files mild.launch"]},
{"url": "https://wiki.ros.org/rqt_wrapper", "package": "rqt_wrapper", "package_summary": ["A wrapper for keeping rqt programs alive."], "package_details": ["Documentation and examples in the ", ". "]},
{"url": "https://wiki.ros.org/android_core", "package": "android_core", "package_summary": ["Android support packages for rosjava."], "package_details": ["\n", "For core library and example documentation, refer to the ", " and ", " sphinx documentation. ", "For more general documentation on all things rosjava-android, refer to the ", " and ", " wiki pages. "]},
{"url": "https://wiki.ros.org/airbus_cobot_gui", "package": "airbus_cobot_gui", "package_summary": ["The airbus_cobot_gui package"], "package_details": ["\n", "\n", " ", "\n", "\n", " ", "Additionally the package ", " includes a library to customise easily qt applications. ", "The user can also call this launch file to run a different configuration, using the input parameters ", " and ", " ", "The configuration of the cobot_gui can be defined via a ", ": ", "For further information about the parameters see: ", " ", "The user is allow to create and add new dashboards and plugins, by adding new entry lines to the dashboards_register.xml file and the plugins_register.xml. See the package ", " as example. ", "Where the ", "l includes an entry for a new dashboard: ", "The package ", " define the python code of the qt level that will be popup inside your cobot_gui. ", "Being the package ", " where the plugin functions is defined. "], "package_code": ["roslaunch airbus_cobot_gui default.launch", "roslaunch airbus_cobot_gui default.launch config_path:='${PKG_NAME}/folder' file_name:='file.conf'", "<?xml version=\"1.0\"?>\n", "\n", "<app mode=\"debug\">\n", "    <translate type=\"en\"/>\n", "    <window display-mode=\"-d\">\n", "        <default-size>\n", "            <width>1280</width>\n", "            <height>720</height>\n", "        </default-size>\n", "        <header>\n", "            <dashboards src=\"${airbus_cobot_gui}/config/default_dashboards_register.xml\">\n", "            </dashboards>\n", "        </header>\n", "        <launcher default-view=\"Rviz\" default-mode=\"manu\">\n", "            <plugins src=\"${airbus_cobot_gui}/config/default_plugins_register.xml\">\n", "                <plugin name=\"Rviz\"/>\n", "                <plugin name=\"Rqt\"/>\n", "                <group name=\"Monitoring\" icon=\"${airbus_cobot_gui}/resources/images/icon_monitoring.png\">\n", "                    <plugin name=\"NodeManager\"/>\n", "                    <plugin name=\"LogManager\"/>\n", "                </group>\n", "           </plugins>\n", "        </launcher>\n", "    </window>\n", "</app>", "<?xml version=\"1.0\"?>\n", "\n", "<app mode=\"debug\">\n", "    <translate type=\"en\"/>\n", "    <window display-mode=\"-d\">\n", "        <default-size>\n", "            <width>1280</width>\n", "            <height>720</height>\n", "        </default-size>\n", "        <header>\n", "            <dashboards src=\"${airbus_templates}/config/default_dashboards_register.xml\">\n", "                                <dashboard name=\"Template\"/>\n", "            </dashboards>\n", "        </header>\n", "        <launcher default-view=\"Template\" default-mode=\"manu\">\n", "            <plugins src=\"${airbus_templates}/config/default_plugins_register.xml\">\n", "                                <plugin name=\"Template\"/>\n", "                <plugin name=\"Rviz\"/>\n", "                <plugin name=\"Rqt\"/>\n", "                <group name=\"Monitoring\" icon=\"${airbus_cobot_gui}/resources/images/icon_monitoring.png\">\n", "                    <plugin name=\"NodeManager\"/>\n", "                    <plugin name=\"LogManager\"/>\n", "                </group>\n", "           </plugins>\n", "        </launcher>\n", "    </window>\n", "</app>", "<?xml version='1.0' encoding='utf8'?>\n", "<dashboards-register>\n", "        <dashboard label=\"Template\" package=\"airbus_template_dashboard\" />\n", "</dashboards-register>", "<?xml version='1.0' encoding='utf8'?>\n", "<plugins-register>\n", "  <plugin label=\"Rviz\"           package=\"airbus_plugin_rviz\" />\n", "  <plugin label=\"Rqt\"            package=\"airbus_plugin_rqt\" />\n", "  <plugin label=\"NodeManager\"    package=\"airbus_plugin_node_manager\" />\n", "  <plugin label=\"LogManager\"     package=\"airbus_plugin_log_manager\" />\n", "  <plugin label=\"Template\"       package=\"airbus_template_plugin\" />\n", "</plugins-register>"]},
{"url": "https://wiki.ros.org/interaction_cursor_3d", "package": "interaction_cursor_3d", "package_summary": ["Metapackage for interaction cursor functionality."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/motoman_config", "package": "motoman_config", "package_summary": ["\n\n     The motoman_config package includes common configurations and 3D models for motoman manipulators\n     \n  "], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package is part of the ", " program. It currently contains config files and meshes for the ", " meta-package. ", "See the ", " page for an overview of the available tutorials. "]},
{"url": "https://wiki.ros.org/motoman_experimental", "package": "motoman_experimental", "package_summary": ["Experimental packages for Motoman manipulators within ROS-Industrial.", ": This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status ", "."], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This repository is part of the ", " program. It contains experimental packages that will be moved to the ", " repository once they've received sufficient testing and review. ", "See the ", " page for more information. "]},
{"url": "https://wiki.ros.org/airbus_plugin_log_manager", "package": "airbus_plugin_log_manager", "package_summary": ["The airbus_plugin_log_manager package"]},
{"url": "https://wiki.ros.org/kingfisher_desktop", "package": "kingfisher_desktop", "package_summary": ["The kingfisher_desktop metapackage"], "package_details": ["Metapackage of desktop tools supporting ", ". "]},
{"url": "https://wiki.ros.org/melfa_driver", "package": "melfa_driver", "package_summary": ["The melfa_driver package"]},
{"url": "https://wiki.ros.org/photo", "package": "photo", "package_summary": ["The photo package provides access to digital cameras. Much of the underlying functionality is provide by the gPhoto libary. The system package libgphoto2-2-dev or equivalent is required.>"], "package_details": ["\n", "\n", "\n", "The photo package provides access to digital cameras. Much of the underlying functionality is provide by the ", " libary. The system package libgphoto2-2-dev or equivalent is required. ", "Calls the set_config service of photo_node and attempts to set the exptime parameter to ", ". "], "package_tt": ["get_config", "set_config", "capture", "20"]},
{"url": "https://wiki.ros.org/prbt_pg70_support", "package": "prbt_pg70_support", "package_summary": ["PRBT support for Schunk pg70 gripper."]},
{"url": "https://wiki.ros.org/create_dashboard", "package": "create_dashboard", "package_summary": ["The Create dashboard is a RQT-based plug-in for visualising data from the Create and giving easy access\n    to basic functionalities."], "package_details": [" ", "\n", "The Create dashboard is part of the ", ". Head over there to find out how to use it and what it can do. "]},
{"url": "https://wiki.ros.org/kurt_2dnav", "package": "kurt_2dnav", "package_summary": ["\n     This application allows the Kurt robot to navigate autonomously with a\n     pre-specified static map. This package is modeled after pr2_2dnav.\n  "]},
{"url": "https://wiki.ros.org/move_base_to_manip", "package": "move_base_to_manip", "package_summary": ["Move the robot base until a desired end-effector pose can be reached."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "For mobile manipulators, this package calculates a robot base location where the end-effector (EE) can reach a desired pose (a.k.a. inverse reachability). The method is computationally fast (since it depends on a ", " Cartesian motion plan), simple (~300 lines), and easy to use (requiring just a service to provide the desired pose). ", "Below, the first image shows a mobile manipulator which is too far to grasp the object of interest. The desired EE pose is shown in green. The second image shows the freshly-calculated base position (red cube) which will allow the robot to reach that pose. <<Please ignore the bad camera calibration>> ", "This package uses ", " for base commands and ", " for manipulator motion planning.  ", "^This launches a ROS service that will make a desired pose available to the move_base_to_manip node. It also displays this desired pose in Rviz. When the client sends ", " on the service request, this node will shut down after providing the pose. ", "^This node requests the desired pose from the other node. It then moves the end-effector to the desired height and orientation. From there, it plans a Cartesian move to the desired pose. The % completion of the Cartesian move informs the base on how far it must move. If the Cartesian move is able to complete 100%, the arm moves and the program exits. Otherwise, there is a call to ", " to get closer to the object: ", "The planner reads optional parameters on the ", ". They can be adjusted from the command line, programmatically, or left as their default values. They are: ", "* ", ": A fraction between 0 and 1. A value of 1 means the EE will barely be able to reach the desired pose when fully extended. A value of 0 means the base motion will bring the EE to the desired pose without additional arm motion. Default: 0.15.  ", "* ", ": Use a Cartesian motion for the final arm approach, or a regular ", " motion? The Cartesian motion may be useful if your task requires the gripper to maintain a constant orientation (like grasping often does). Default: false, i.e. do a regular motion. ", "* ", ": Clear the octomap collision scene before the final arm approach? This is often necessary for grasping -- otherwise sensor noise/resolution may lead the robot to expect a collision. Default: true, i.e. the collision scene will be cleared. ", "* ", ": Clear the move_base costmaps before base motion? Default: true. ", "* ", ": Ask the user before making any motion? This is useful if you're just starting to use the package and aren't sure what to expect. Default: true. ", "* ", ": This is the \"request\" part of the service call. Can be used as a signal that the server can shutdown. Default: true (which I use to signal the pose provider node to shut down). ", "* ", ": A smaller number results in a more accurate prediction of the distance to the pose of interest. Default: 0.005m ", "* ", ": Default \"right_ur5\" ", "* ", ": Default \"RRTConnectkConfigDefault\" ", "* ", ": % of maximum robot speed for all arm motions. Default: 0.1 ", "* ", ": Default \"base_link\" ", "* ", ": Position tolerance for arm motions. It may be useful to bump this up if you are having trouble finding plans. Default: 0.01 m ", "* ", ": Orientation tolerance for arm motions. Default: 0.0001 rad ", "* ", ": If true, the planner will try to flip the EE +/-180 deg about Z (i.e. ", ") when it cannot reach a desired pose. Then it will attempt to plan again. Useful for 2-finger grippers. Default: true ", "Here are some hints to get more suitable trajectories from ", ": ", "* Make sure the resolutions of your costmap and ", " planners are fine enough to get the accuracy you require. ", "Here are ", " from the creator of ", ". ", "This package only calculates one base position which can reach the desired pose. If the base is not able to move there, it fails. However, ", " has some built-in obstacle avoidance capabilities and if it fails, it will generally be close to the goal. ", "* (untested) Use the ", " package to calculate a good location for the manipulator's base. From the manipulator's position, calculate a mobile base location. This is the \"inverse reachability database\" approach. "], "package_code": ["$ sudo apt-get install ros-indigo-move-base-to-manip", "$ rosrun move_base_to_manip provide_target", "$ roslaunch move_base_to_manip move_base_to_manip.launch", "ac.sendGoal(goal);"]},
{"url": "https://wiki.ros.org/neo_base_mp_500", "package": "neo_base_mp_500", "package_summary": ["launchfiles for MP_500"]},
{"url": "https://wiki.ros.org/linux_hardware", "package": "linux_hardware", "package_summary": ["\n\n     Simple scripts which help utilise, monitor, interact with computer\n     hardware abstracted by a linux OS.\n\n  "], "package_details": [" ", "This functionality has been moved out in indigo in favour of using the standard drivers in the ", " group. "]},
{"url": "https://wiki.ros.org/apriltags_ros", "package": "apriltags_ros", "package_summary": ["A package that provides a ROS wrapper for the apriltags C++ package"], "package_details": ["\n", "\n", "\n", "\n", " ", "A ROS wrapper for the ", ". ", "The nodelet functions equivalently to the ", " node. "], "package_tt": ["apriltag_ros", "apriltag_ros", "apriltag_detector_node"]},
{"url": "https://wiki.ros.org/asr_mild_navigation", "package": "asr_mild_navigation", "package_summary": ["The mild_navigation package. Launchfiles to start the navigation relevant nodes. Parameter for navigation and maps."], "package_details": [" ", "\n", "\n", " ", " ", " ", " ", "\n", " ", "\n", " ", " ", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", " ", "The asr_mild_navigation uses the standard ", " with some specific components. There are three overlay packages: ", "Asr_move_base and asr_navcore are only needed if you use the asr_ftc_local_planner which is the standard local planner for the asr_mild_navigation. Look at the ", " documentation on how to use and include the asr_move_base and asr_nav_core packages. The asr_ftc_local_planner implements a new local planner and is used instead of the ", " or ", ". The asr_navfn package includes an upgraded version of the standard navfn (check out the asr_navfn documentation). There are also two launch files to start the gazebo simulation with different rooms. ", "There are also a launch file (launch/amcl_diff.launch\") to start ", ", this is automaticly started if you launch \"launch/navigation.launch\". "], "package_code": ["roslaunch asr_mild_navigation simulation_manual_rearranged.launch", "roslaunch asr_mild_navigation navigation.launch", "<node name=\"map_server\" pkg=\"map_server\" type=\"map_server\" args=\"$(find your_package)/your_map.yaml\" required=\"true\"/>", "roslaunch asr_mild_navigation gazebo_mild_manual_rearranged.launch"]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5052/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/oculus_sdk", "package": "oculus_sdk", "package_summary": ["The Oculus Rift SDK"]},
{"url": "https://wiki.ros.org/mrp2_common", "package": "mrp2_common", "package_summary": ["Necessary packages in common for both simulation and real environment."]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14693/6 ", " "]},
{"url": "https://wiki.ros.org/fake_odom", "package": "fake_odom", "package_summary": ["The fake_odom package"], "package_details": ["\n", "\n", "\n", "To start the ", " in a faked odometry mode the '_fake' launch files in wheeled_robin_bringup. "], "package_tt": ["cmd_vel", "odom", "joint_states", "odom", "base_footprint", "base_footprint", "base_link"]},
{"url": "https://wiki.ros.org/asr_flock_of_birds", "package": "asr_flock_of_birds", "package_summary": ["The asr_flock_of_birds package is the driver for Ascension Technology Corp magnet-tracking system \"Flock of Birds\". It provides the remote server which publishes two 6d posemarker and the nessesary TF from the magnettracking system. It also contains launchfiles and calibration tools for the use of it."], "package_details": [" ", "\n", "\n", " ", " ", "\n", "\n", "\n", " magnet tracking system \"Flock of Birds\" is needed. ", "\n", "\n", "The asr_flock_of_birds package is the driver for ", " magnet tracking system \"Flock of Birds\" (FoB). It provides the remote server which publishes two 6d posemarker and the necessary TF from the magnet tracking system. It also contains launch-files and calibration tools for the use of it. ", "Flock of Birds is a 6D tracking system which can very precisely track position and orientation of three sensors in a magnetic field in front of the receiver. Each tracker is connected to an data-glove and so only two trackers are used currently (for left and right hand). If started, the node publishes periodically the pose of the trackers as TF-publisher as well as ", "-Messages on the ", "-Topic. ", "This package can be used as a standalone-driver for the Flock of Birds tracker system, but it is recommended to use it as a part of the ", ". ", "This package depends on ", "-Package for the publication of the fob_objects. ", "There are mainly two ways to start the Flock of Birds server: To start it directly form the PC which the hardware is connected with, use ", " To start from another PC, the package provides a remote script. But Firstly, a ssh connection have to be set up. Secondly, use ", " ", "The launched Node publishes ", "-Messages on the ", "-Topic. There are no configuration or controlling elements. "]},
{"url": "https://wiki.ros.org/rosruby_actionlib", "package": "rosruby_actionlib", "package_summary": ["actionlib for rosruby."], "package_details": ["\n", "See ", ". "]},
{"url": "https://wiki.ros.org/atlas_v3_moveit_config", "package": "atlas_v3_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the atlas with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/create_description", "package": "create_description", "package_summary": ["Model description for the iRobot Create"], "package_details": ["This just stores the urdf's of the create base for the turtlebot. The actual application of the urdf's happen in ", " where it is stitched together with the other turtlebot components. "]},
{"url": "https://wiki.ros.org/rqt_dyn_tune", "package": "rqt_dyn_tune", "package_summary": ["The graphical user interface for dyn_tune package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/mrp2_description", "package": "mrp2_description", "package_summary": ["URDF and xacro description files for MRP2."]},
{"url": "https://wiki.ros.org/ptu46", "package": "ptu46", "package_summary": ["Driver for the Directed Perception ptu46 pan/tilt driver, forked from player"], "package_details": ["\n"], "package_tt": ["~cmd", "~state", "~hz", "Integer", "~port", "String", "~baud", "Integer", "~min_tilt,\u00a0~max_tilt,\u00a0~min_pan,\u00a0~max_pan", "Float", "~min_tilt_speed,\u00a0~max_tilt_speed,\u00a0~min_pan_speed,\u00a0~max_pan_speed", "Float", "~tilt_step,\u00a0~pan_step", "Float"]},
{"url": "https://wiki.ros.org/interaction_cursor_rviz", "package": "interaction_cursor_rviz", "package_summary": ["The interaction_cursor_rviz package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "You may also need ", ", which unfortunately must go in a rosbuild workspace. ", "You can add the option start_hydra:=false, or change the radius of the hydra workspace with radius:=<a number>. ", "Please send bug reports, feature requests, etc. to the ", ".  "], "package_tt": ["https://github.com/ros-visualization/visualization_tutorials"], "package_code": ["sudo apt-get install ros-groovy-rviz-animated-view-controller", "- git: {local-name: ros_3d_interaction_cursor, uri: 'https://github.com/aleeper/ros_3d_interaction_cursor.git'}\n", "- git: {local-name: razer_hydra, uri: 'https://github.com/aleeper/razer_hydra.git'}\n", "- git: {local-name: interactive_markers, uri: 'https://github.com/ros-visualization/interactive_markers.git'}\n", "- git: {local-name: rviz, uri: 'https://github.com/ros-visualization/rviz.git'}", "roscd razer_hydra\n", "./configure_udev_rules", "roslaunch interaction_cursor_demo demo.launch"]},
{"url": "https://wiki.ros.org/rosthrottle", "package": "rosthrottle", "package_summary": ["ROS Python package for throttling ROS topics programatically in Python. Sits on top of the \n        ros_comm topic_tools throttle utility."]},
{"url": "https://wiki.ros.org/asr_aruco_marker_recognition", "package": "asr_aruco_marker_recognition", "package_summary": ["This package contains a marker recognition system using the ArUco library. \n    It can be used with a mono or stereo camera system but yields better results with the latter."], "package_details": ["\n", " ", " ", " ", " ", "\n", "\n", "\n", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The objects are detected in the image(s) using the ", "-library. Depending on the used camera system (mono or stereo), the found markers are further processed. If a mono system is used, the found poses of the ", "-library are published, if on the other hand a stereo system is used, the final marker pose is calculated based on the positions of the markers in the left and right image: If a marker with the same id was found in each of them, the 3D corner points are calculated using triangulation of the 2D corner points in each image. The final pose is then calculated using ICP and then published. ", "Marker images can be created by using the marker creator tool this package contains. They need to be printed and then they can be attached to corresponding objects in the scene. This correspondance can be specified by adding mesh-models to the ", " and naming the object depending on the used marker id (compare already created objects in the database for more information). ", "In this example 4 markers are in the scene, two of which have a corresponding object stored in the ", " (monitor and mouse). The markers each have the size of 1.5x1.5mm and the used cameras have a resolution of 1292x964. ", "The following parameters can be changed in the ", " file in the param folder: ", "The marker creator has the following parameters specified in ", " in the param folder: ", "This package calls a service provided by the ", " to get information about the objects corresponding to the used markers: "], "package_code": ["roslaunch asr_aruco_marker_recognition aruco_marker_recognition.launch", "rosservice call /asr_aruco_marker_recognition/get_recognizer", "rosservice call /asr_aruco_marker_recognition/release_recognizer", "roslaunch asr_aruco_marker_recognition marker_creator.launch"]},
{"url": "https://wiki.ros.org/neo_relayboard", "package": "neo_relayboard", "package_summary": ["Communication Node with neo_relayboard"]},
{"url": "https://wiki.ros.org/mrp2_analyzer", "package": "mrp2_analyzer", "package_summary": ["The diagnostic package for MRP2."]},
{"url": "https://wiki.ros.org/jointstick", "package": "jointstick", "package_summary": ["Move any joint with any controller!"]},
{"url": "https://wiki.ros.org/ptu_control", "package": "ptu_control", "package_summary": ["Actionlib interface for PTUs which listen for JointState messages (such as PTU46)"], "package_details": ["\n", "\n"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/android_apps", "package": "android_apps", "package_summary": ["Applications for robot-android pairing.."], "package_details": ["\n", "Applications for use with ", ". Many of these are found on the ", ". Refer to the ", " page for more information. "]},
{"url": "https://wiki.ros.org/interaction_cursor_msgs", "package": "interaction_cursor_msgs", "package_summary": ["The interaction_cursor_msgs package"], "package_details": ["\n", "\n", "These are structured in a similar way to ", " Update/Feedback messages. ", "In particular, a server application (such as interaction_cursor_demo) sends ", " messages that are received by a client application (such as Rviz running the interaction_cursor_rviz display plugin). The client plugin is then responsible for sending feedback messages to the server. ", "Please send bug reports, feature requests, etc. to the ", ". "]},
{"url": "https://wiki.ros.org/kurt_2dnav_slam", "package": "kurt_2dnav_slam", "package_summary": ["\n     This application allows the Kurt to navigate autonomously while also\n     building a map of its environment as it drives along. It is modeled after\n     pr2_2dnav_slam.\n  "]},
{"url": "https://wiki.ros.org/melfa_robot", "package": "melfa_robot", "package_summary": ["The melfa_robot meta package"]},
{"url": "https://wiki.ros.org/nav2_navigation", "package": "nav2_navigation", "package_summary": ["ROS navigation config and launch files for Nav2 Robot Platform"]},
{"url": "https://wiki.ros.org/modbus", "package": "modbus", "package_summary": ["The modbus package"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", " "], "package_tt": ["modbus_wrapper/output", "modbus_wrapper/input", "modbus_server/read_from_registers", "modbus_server/write_to_registers"]},
{"url": "https://wiki.ros.org/moveit_robots", "package": "moveit_robots", "package_summary": ["moveit_robots meta-package contains multiple robots moveit configuration packages."]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5053/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosruby_messages", "package": "rosruby_messages", "package_summary": ["rosruby_messages is precompiled rosruby messages."]},
{"url": "https://wiki.ros.org/asr_cyberglove_lib", "package": "asr_cyberglove_lib", "package_summary": ["This package is used to start a server that provides the current joint state values received from the CyberGloves via ROS topics"], "package_details": [" ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "Instead of using the preconfigured .launch-file, the server can also be started via ", ", e.g. with: ", "If the hardware is connected to a ROS Indigo Lab-PC and it is needed to start the asr_cyberglove_lib server from a remote ROS Kinetic Lab-PC, some workarounds / dirty hacks are needed. For the following, it is assumed that both ROS systems use the same file system and that the corresponding catkin workspaces are ", " and ", ". ", "Open the terminal and source Kinetic (if not already sourced via ~/", "): ", "Additional ssh environment setups are needed (", "): ", "A ssh connection can now be established, but the ~/", " needs to be modified to be able to start the server on ROS Indigo: ", "To listen to the publishing ROS-Topic in a new terminal, ROS Kinetic has to be sourced again (or modify the ~/", " again before opening the new terminal): ", "Alternatively, the glove movements can also be visualized with the ", " package (Kinetic needs to be sourced again): ", "The sensor data of the Cybergloves are published as ", "messages to the following topics: ", "As mentioned in subsection 2.3, the asr_cyberglove_lib server can be started directly via ", " without using the preconfigured .launch-file. For this case, it is needed to specify the ", " arguments. The following arguments can be passed: "], "package_code": ["roslaunch asr_cyberglove_lib glove_lib.launch", "rosrun asr_cyberglove_lib gloveServer_node -r --calibration-file-right $(find asr_cyberglove_lib)/cfg/GloveCalibrationRight.cal --tty-right /dev/ttyD2 -d 0", "rosrun asr_cyberglove_lib glove_lib_remote.sh"]},
{"url": "https://wiki.ros.org/rb1_base_gazebo", "package": "rb1_base_gazebo", "package_summary": ["The rb1_base_gazebo package"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/kurt_navigation_global", "package": "kurt_navigation_global", "package_summary": ["\n     This package holds XML files for running the ", " node on a Kurt\n     robot. The ", " node\n     is configured to run over a pre-specified static map. This package is\n     modeled after pr2_navigation_global.\n  "]},
{"url": "https://wiki.ros.org/interaction_cursor_demo", "package": "interaction_cursor_demo", "package_summary": ["A demo 3D cursor interaction application."]},
{"url": "https://wiki.ros.org/atlas_moveit_config", "package": "atlas_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the atlas with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/muse_bldc_motor_drive", "package": "muse_bldc_motor_drive", "package_summary": ["The muse_bldc_motor_drive package"], "package_details": ["\n", "\n", "\n", "\n", "<feedback_topic_name> (muse_bldc_motor_drive/feedback.msg) ", "\n", "<control_commands_topic_name> (muse_bldc_motor_drive/control_cmd.msg) ", "<state_machine_commands_topic_name> (muse_bldc_motor_drive/state_machine_cmd.msg) ", "\n", " ", "Now ", " node publishes a list with Muse Drives that are visible on the network and is ready to listen to your commands. "], "package_code": ["rosrun muse_bldc_motor_drive muse_bldc_motor_drive", "rosrun muse_bldc_motor_drive muse_bldc_motor_drive <feedback_frequency(Hz)> <control_frequency(Hz)>"]},
{"url": "https://wiki.ros.org/airbus_coop", "package": "airbus_coop", "package_summary": ["The airbus_coop metapackage"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/neato_driver", "package": "neato_driver", "package_summary": ["\n\n    This is a generic drivers for the Neato XV-11 Robotic Vacuum.\n\n    ROS Bindings can be found in the neato_node package.\n\n  "]},
{"url": "https://wiki.ros.org/moveit_goal_builder", "package": "moveit_goal_builder", "package_summary": ["The moveit_goal_builder package"], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " is a library for building ", ". ", "This is useful for when you want to use the ", " actionlib interface directly, instead of using the ", " class. ", "This allows you to poll when the action is done, which the normal ", " interface does not allow you to do. ", "\n", "\n", "\n"], "package_tt": ["moveit_goal_builder", "Build()", "build"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/baxter_moveit_config", "package": "baxter_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the baxter with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/clam_moveit_config", "package": "clam_moveit_config", "package_summary": ["clam_moveit_config"]},
{"url": "https://wiki.ros.org/eband_local_planner", "package": "eband_local_planner", "package_summary": ["eband_local_planner implements a plugin to the\n    base_local_planner. It implements the Elastic Band method on the\n    SE2 manifold."], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " (", ", default: 0.1) ", " ", " (", ", default: 0.5) ", " ", " (", ", default: 0.7) ", " ", " (", ", default: 0.75) ", " ", "The original implementation for this ROS ", " local planner only supported omni-directional (holonomic) robots. ", "The current version was modified to work with differential drive machines. Set ", " to ", " to enable lateral/holonomic motion, but that mode has not been tested for a long time and should be considered experimental. ", "This plugin runs inside the move_base process. Its parameter namespace is prefixed by that of ", " and the ", " name under which it was launched, typically ", ", e.g.: "], "package_tt": ["differential_drive", "false", "xy_goal_tolerance", "rotation_threshold_multiplier", "xy_goal_tolerance", "rotation_threshold_multiplier", "move_base", "base_local_planner", "EBandPlannerROS", "~/EBandPlannerROS/xy_goal_tolerance", "double", "~/EBandPlannerROS/yaw_goal_tolerance", "double", "~/EBandPlannerROS/rot_stopped_vel", "double", "~/EBandPlannerROS/trans_stopped_vel", "double", "~/EBandPlannerROS/marker_lifetime", "double", "~/EBandPlannerROS/eband_min_relative_overlap", "double", "~/EBandPlannerROS/eband_tiny_bubble_distance", "double", "~/EBandPlannerROS/eband_tiny_bubble_expansion", "double", "~/EBandPlannerROS/eband_internal_force_gain", "double", "~/EBandPlannerROS/eband_external_force_gain", "double", "~/EBandPlannerROS/num_iterations_eband_optimization", "int", "~/EBandPlannerROS/eband_equilibrium_approx_max_recursion_depth", "int", "~/EBandPlannerROS/eband_equilibrium_relative_overshoot", "double", "~/EBandPlannerROS/eband_significant_force_lower_bound", "double", "~/EBandPlannerROS/costmap_weight", "double", "~/EBandPlannerROS/max_vel_lin", "double", "~/EBandPlannerROS/max_vel_th", "double", "~/EBandPlannerROS/min_vel_lin", "double", "~/EBandPlannerROS/min_vel_th", "double", "~/EBandPlannerROS/min_in_place_vel_th", "double", "~/EBandPlannerROS/in_place_trans_vel", "double", "~/EBandPlannerROS/k_prop", "double", "~/EBandPlannerROS/k_damp", "double", "~/EBandPlannerROS/Ctrl_Rate", "double", "~/EBandPlannerROS/max_acceleration", "double", "~/EBandPlannerROS/virtual_mass", "double", "~/EBandPlannerROS/max_translational_acceleration", "double", "~/EBandPlannerROS/max_rotational_acceleration", "double", "~/EBandPlannerROS/rotation_correction_threshold", "double", "~/EBandPlannerROS/differential_drive", "bool", "~/EBandPlannerROS/bubble_velocity_multiplier", "double", "~/EBandPlannerROS/rotation_threshold_multiplier", "double", "~/EBandPlannerROS/disallow_hysteresis", "bool"], "package_code": ["  <node pkg=\"move_base\" type=\"move_base\" name=\"move_base\">\n", "    <param name=\"base_local_planner\" value=\"eband_local_planner/EBandPlannerROS\"/>\n", "    ...\n", "  </node>"]},
{"url": "https://wiki.ros.org/mrp2_navigation", "package": "mrp2_navigation", "package_summary": ["Launch files, parameters and maps for different navigation applications."]},
{"url": "https://wiki.ros.org/infinisoleil", "package": "infinisoleil", "package_summary": ["This package provides a ROS driver for Infinisoleil sensors."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["range_image", "ir_image", "point_cloud", "/diagnostics", "~hostname", "str", "~port_number", "str", "~connect_timeout", "int", "~send_timeout", "int", "~receive_timeout", "int", "~range_frame_id", "str", "~ir_frame_id", "str", "~point_cloud_frame_id", "str", "~diagnostics_enable", "bool", "~measure_mode", "int", "~measure_point_x", "int", "~measure_point_y", "int", "~swing_fs", "int", "~swing_ss", "int", "~xy_surface_count", "int", "~frame_cycle", "int", "~max_measure_mode", "int", "~xy_serial_number", "str", "~logic_version", "str", "~firm_version", "str", "~product_number", "str"], "package_code": ["$ rosrun nodelet nodelet manager\n", "$ rosrun nodelet nodelet load infinisoleil/FX8DriverNodelet manager", "$ rosrun nodelet nodelet manager\n", "$ rosrun nodelet nodelet load infinisoleil/FX8DriverNodelet manager _hostname:=192.168.0.81", "$ roslaunch infinisoleil fx8_driver.launch", "$ roslaunch infinisoleil fx8_node.launch", "$ roslaunch infinisoleil fx8_node.launch hostname:=192.168.0.81", "$ roslaunch infinisoleil fx8_driver.launch diagnostics_enable:=false", "  <launch>\n", "    <!-- launch fx8_driver.launch -->\n", "    <include file=\"$(find infinisoleil)/launch/fx8_driver.launch\"/>\n", "  \n", "    <!-- Add another driver nodelet -->\n", "    <node pkg=\"nodelet\" type=\"nodelet\" name=\"add_driver\"\n", "      args=\"load infinisoleil/FX8DriverNodelet fx8_nodelet_manager\"\n", "      output=\"screen\">\n", "      <remap from=\"range_image\" to=\"add_driver/range_image\"/>\n", "      <remap from=\"ir_image\" to=\"add_driver/ir_image\"/>\n", "      <remap from=\"point_cloud\" to=\"add_driver/point_cloud\"/>\n", "      <param name=\"hostname\" type=\"str\" value=\"192.168.0.81\"/>\n", "    </node>\n", "  </launch>", "$ rostest infinisoleil fx8_driver_hertz.test", "$ rostest infinisoleil fx8_driver_hertz.test set_hostname:=192.168.0.81", "$ rostest infinisoleil fx8_driver_hertz.test set_measure_mode:=1 hz:=16.0"]},
{"url": "https://wiki.ros.org/alliance_msgs", "package": "alliance_msgs", "package_summary": ["This package contains the definition of the message, service and action files of the alliance stack."]},
{"url": "https://wiki.ros.org/r2_control", "package": "r2_control", "package_summary": ["Ready Poses for the Robonaut2"]},
{"url": "https://wiki.ros.org/apriltags", "package": "apriltags", "package_summary": ["A catkin version of the C++ apriltags library"], "package_details": ["\n", "A catkin version of the ", " "], "package_tt": ["apriltag_ros", "apriltag_ros"]},
{"url": "https://wiki.ros.org/gazebo_taskboard", "package": "gazebo_taskboard", "package_summary": ["\n\n     gazebo_taskboard\n\n  "]},
{"url": "https://wiki.ros.org/mtig_driver", "package": "mtig_driver", "package_summary": ["ROS driver for Xsens MTI-G-700 series motion trackers\n\t  - modified to publish GPS messages"], "package_details": ["\n", "\n", "\n", "\n", "Download the MT Software Suite and install it on a Windows machine (you may skip this step and use default sensor configuration), then download the MT SDK for Linux and install it on a Linux machine (this should be the machine that ROS is installed on). Here is the software website: ", ". ", "Follow the instructions in the MT SDK for Linux to install the software  and make sure the examples run correctly with the sensor. You may need to install the kernel available at ", ". "], "package_tt": ["/xsens/imu", "/xsens/gps", "/xsens/velocity", "/xsens/temperature", "/xsens/pressure", "/xsens/magnetic", "/xsens/gps_extra"], "package_code": [" $ ls /dev/ttyUSB0", " $ sudo adduser this_user dialout", " $ roslaunch mtig_driver mtig_driver.launch", "<launch>\n", "        <arg name=\"frame\" default=\"xsens\" />\n", "        <node pkg=\"mtig_driver\" type=\"mtig_driver_node\" name=\"mtig_driver\">\n", "                <!-- Error parameters /-->\n", "                <param name=\"roll_error\" value=\"0.2\" />\n", "                <param name=\"pitch_error\" value=\"0.2\" />\n", "                <param name=\"yaw_error\" value=\"1.0\" />\n", "                <param name=\"acc_noise\" value=\"0.00015\" />\n", "                <param name=\"gyr_noise\" value=\"0.01\" />\n", "\n", "                <!-- Frame Parameter /-->\n", "                <param name=\"frame_id\" value=\"$(arg frame)\" />\n", "\n", "                <!-- Override Mode /-->\n", "                <param name=\"override\" value=\"true\" />\n", "\n", "                <!-- Module Setup Parameters /-->\n", "                <param name=\"orientation_enabled\" value=\"true\"/>\n", "                <param name=\"orientation_frequency\" value=\"0\"/>\n", "                <param name=\"gps_enabled\" value=\"true\"/>\n", "                <param name=\"gps_frequency\" value=\"0\"/>\n", "                <param name=\"temperature_enabled\" value=\"true\"/>\n", "                <param name=\"temperature_frequency\" value=\"0\"/>\n", "                <param name=\"acceleration_enabled\" value=\"true\"/>\n", "                <param name=\"acceleration_frequency\" value=\"0\"/>\n", "                <param name=\"pressure_enabled\" value=\"true\"/>\n", "                <param name=\"pressure_frequency\" value=\"0\"/>\n", "                <param name=\"magnetic_enabled\" value=\"true\"/>\n", "                <param name=\"magnetic_frequency\" value=\"0\"/>\n", "                <param name=\"altitude_enabled\" value=\"true\"/>\n", "                <param name=\"altitude_frequency\" value=\"0\"/>\n", "                <param name=\"velocity_enabled\" value=\"true\"/>\n", "                <param name=\"velocity_frequency\" value=\"0\"/>\n", "                <param name=\"gyroscope_enabled\" value=\"true\"/>\n", "                <param name=\"gyroscope_frequency\" value=\"0\"/>\n", "        </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/nav2_driver", "package": "nav2_driver", "package_summary": ["ROS driver node for the Nav2 base"]},
{"url": "https://wiki.ros.org/lslidar_n301", "package": "lslidar_n301", "package_summary": ["Basic ROS support for the Leishen N301 LIDARs."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " that this launch file launches both the driver and the decoder, which is the only launch file needed to be used. ", "\n", "\n", " ", "Bug Report Prefer to open an issue. You can also send an E-mail to ", " . "], "package_code": ["cd your_work_space\n", "catkin_make --pkg lslidar_n301_driver lslidar_n301_decoder --cmake-args -DCMAKE_BUILD_TYPE=Release", "roslauch lslidar_n301_decoder lslidar_n301_decoder_nodelet.launch"]},
{"url": "https://wiki.ros.org/r2_gazebo", "package": "r2_gazebo", "package_summary": ["\n\n     r2_gazebo\n\n  "]},
{"url": "https://wiki.ros.org/nav2_platform", "package": "nav2_platform", "package_summary": ["ROS stack  containing all nodes, config, and launch files for Nav2 mobile robotics platform."], "package_details": ["\n", "\n", "The ", " stack contains several component packages: ", "To configure the ", " robot for usage, you should edit the launch files located in the ", " package. This is best done by cloning the package into your catkin workspace overlay, and making your changes locally: ", "The Nav2 base can be controlled immediately by setting the appropriate IP/Hostname and port in the ", " launch file. This launch file will start the ", " node with the appropriate parameters, meaning that it will listen for Twist commands on the ", " topic, and output the appropriate transforms and odometry messages on ", " and ", " respectively. ", "To use the Nav2 with ROS navigation and mapping packages, you need to configure the sensor and appropriate parameters. Demo configurations for OpenNI (e.g. MS Kinect, Asus Xtion) and Hokuyo (i.e. URG-XX) compatible sensors are provided (but commented out) in the ", " launch file. "], "package_tt": ["nav2_platform", "nav2_bringup", "nav2_driver", "nav2_navigation", "nav2_bringup", "nav2_robot.launch", "nav2_driver", "/cmd_vel", "/tf", "odom", "nav2_robot.launch"], "package_code": ["#Create a catkin workspace if you don't have one yet\n", "source /opt/ros/$(rosversion -d)/setup.bash\n", "mkdir -p ~/catkin_ws/src\n", "catkin_init_workspace ~/catkin_ws/src", "#Clone the nav2_platform git repo\n", "cd ~/catkin_ws/src\n", "git clone https://github.com/paulbovbel/nav2_platform.git\n", "cd ~/catkin_ws/\n", "catkin_make\n", "source devel/setup.bash", "#Configure correct IP/Hostname and port\n", "rosed nav2_bringup nav2_robot.launch\n", "#Launch the robot bringup launch file\n", "roslaunch nav2_bringup nav2_robot.launch"]},
{"url": "https://wiki.ros.org/neato_robot", "package": "neato_robot", "package_summary": ["\n    This stack contains drivers for the Neato XV-11 robot. It also contains sample configuration files for running the Navigation stack on an XV-11.\n  "], "package_details": ["\n", "\n", "We are currently using the ", ". "]},
{"url": "https://wiki.ros.org/lslidar_c16", "package": "lslidar_c16", "package_summary": ["Basic ROS support for the Leishen C16 LIDARs."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", "This ", " package is a linux ROS driver for lslidar c16 from Shenzhen Leishen Intelligence System Co, Ltd. "], "package_tt": ["lidar_ip", "string", "default:\u00a0192.168.1.200", "device_port", "int", "default:\u00a02368", "frame_id", "string", "default:\u00a0laser", "add_multicast", "bool", "default:\u00a0false", "group_ip", "string", "default:\u00a0234.2.3.2", "lslidar_packets", "lslidar_c16_msgs/LslidarC16Packet", "min_range", "double", "0.15", "max_range", "double", "150.0", "frequency", "frequency", "10.0", "publish_point_cloud", "bool", "true", "use_gps_ts", "bool", "false", "angle3_disable_min", "double", "-1", "angle3_disable_max", "double", "-1", "lslidar_sweep", "lslidar_c16_msgs/LslidarC16Sweep", "lslidar_point_cloud", "sensor_msgs/PointCloud2", "publish_point_cloud", "true", "lslidar_packets", "lslidar_c16_msgs/LslidarC16Packet", "eth0"], "package_code": ["sudo tcpdump -i eth0", "roslaunch lslidar_c16_decoder lslidar_c16.launch --screen"]},
{"url": "https://wiki.ros.org/neato_2dnav", "package": "neato_2dnav", "package_summary": ["This package contains configuration and launch files for using the navigation stack with the Neato XV-11 robot."], "package_details": ["\n", "\n", "\n", " can be used to create maps, as with any other robot. We've yet to find just the right set of parameters (work on the beam likelihood is probably needed), but the following seems to work on the Neato for smaller maps such as the one shown below: ", " "], "package_code": ["roslaunch neato_node bringup.launch\n", "roslaunch neato_2dnav move_base.launch", "rosrun gmapping slam_gmapping scan:=base_scan _srr:=0.001 _srt:=0.001 _str:=0.000001 _stt:=0.000001 _linearUpdate:=0.5 _angularUpdate:=0.4"]},
{"url": "https://wiki.ros.org/gazebo_interface", "package": "gazebo_interface", "package_summary": ["\n\n     gazebo_interface\n\n  "]},
{"url": "https://wiki.ros.org/neato_node", "package": "neato_node", "package_summary": ["\n    This package contains a node that connects to the Neato Robotics XV-11. It enables control of motors through a geometry_msgs/Twist topic and publishes laser scans and odometry.\n  "], "package_details": ["\n", "\n", "\n", "\n"], "package_tt": ["/cmd_vel", "/base_scan", "/odom", "~port", "str"], "package_code": ["lsusb", "sudo modprobe usbserial vendor=0x2108 product=0x780b", "roslaunch neato_node bringup.launch"]},
{"url": "https://wiki.ros.org/problib", "package": "problib", "package_summary": ["problib"], "package_details": ["\n", "Problib is a probabilistic library containing tools that can be used for representing or converting probabilistic information. It is part of the ", " stack. "]},
{"url": "https://wiki.ros.org/ompl_ros_interface", "package": "ompl_ros_interface", "package_summary": ["\n\n     ompl_ros_interface\n\n  "], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "To install this package, you will have to install the ", " stack: ", "Examples for how to setup and configure motion planners for your robot can be found in the accompanying ", ".  ", "A quick example for use with the PR2 robot in simulation (Gazebo) can be found in the ", " in Gazebo. Follow the instructions on that page to see ompl_ros_interface in action. ", "The tabletop manipulation stacks in diamondback now use the ompl_ros_interface for planning using OMPL. To run these stacks on the PR2 robot, try the tabletop manipulation demo ", ". "], "package_tt": ["\u00a0sudo\u00a0apt-get\u00a0install\u00a0ros-electric-arm-navigation"]},
{"url": "https://wiki.ros.org/nav_core_adapter", "package": "nav_core_adapter", "package_summary": ["This package contains adapters for using `nav_core` plugins as `nav_core2` plugins and vice versa (more or less).\n      See README.md for more information."], "package_details": [" "]},
{"url": "https://wiki.ros.org/raspigibbon_control", "package": "raspigibbon_control", "package_summary": ["The raspigibbon_control package"]},
{"url": "https://wiki.ros.org/mrp2_viz", "package": "mrp2_viz", "package_summary": ["RViz configurations and launch files for visualization."]},
{"url": "https://wiki.ros.org/pr2_object_manipulation", "package": "pr2_object_manipulation", "package_summary": ["\n    Contains PR2-specific implementations of some of the generic\n    functionality needed for pickup and place tasks. \n  "], "package_details": ["\n", "\n", "\n", "  ", "In general, PR2 specific implementations contained here will implement general interfaces defined in the ", " stack. Contains PR2 specific launch files for using the manipulation functionality. ", "To launch the manipulation pipeline complete with sensor input and execute pickup and place tasks using the PR2 robot, tutorials and launch files are provided in ", ". "]},
{"url": "https://wiki.ros.org/raspimouse_ros", "package": "raspimouse_ros", "package_summary": ["The raspimouse package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\u65e5\u672c\u8a9e\u7248wiki\u306f", "\u3067\u3059\u3002 "]},
{"url": "https://wiki.ros.org/nj_oa_costmap", "package": "nj_oa_costmap", "package_summary": ["The nj_oa_costmap package is a navigating jockey for the Large\n\t  Maps framework. Its role is to drive the robot forward while avoiding\n\t  obstacles. It uses a local map which position is relative to the robot\n\t  but which orientation is constant."], "package_details": ["\n", "\n", "\n", "The ", " package implements a navigating jockey for the Large Maps Framework (", ") that drives the robot while avoiding obstacles. ", "It is based on a local map (", "). ", "The local map has a fixed position relative to the robot but its orientation is constant in the world reference frame. ", "It is a reactive, memory-less jockey. ", "Moreover, the package provides the class ", " that computes an appropriate ", " from a ", " in order to go as forward as possible while avoiding obstacles. "], "package_tt": ["nj_oa_costmap", "TwistHandler", "~<name>/local_map", "~<name>/cmd_vel", "~<name>/robot_radius", "Float", "~<name>/min_distance", "Float", "~<name>/long_distance", "Float", "~<name>/turnrate_collide", "Float", "~<name>/max_vel", "Float", "~<name>/vel_close_obstacle", "Float", "~<name>/turnrate_factor", "Float", "~<name>/laser_frame", "String", "~<name>/navigating_jockey_server_name", "String"]},
{"url": "https://wiki.ros.org/naoqi_libqi", "package": "naoqi_libqi", "package_summary": ["Aldebaran's libqi: a core library for NAOqiOS development"]},
{"url": "https://wiki.ros.org/openslam_gmapping", "package": "openslam_gmapping", "package_summary": ["ROS-ified version of gmapping SLAM. Forked from https://openslam.informatik.uni-freiburg.de/data/svn/gmapping/trunk/"]},
{"url": "https://wiki.ros.org/mrp2_desktop", "package": "mrp2_desktop", "package_summary": ["Visualization tools and configurations for MRP2 robot."]},
{"url": "https://wiki.ros.org/pr2_gui", "package": "pr2_gui", "package_summary": ["\n\n    Contains GUI tools for working with PR2s.\n\n  "], "package_details": [" is meant to be a collection of GUI tools for working specifically with PR2 robots.  Currently the only package included is ", ", which provides status and debugging information, as well as allowing you to do things like reset breakers, motors, etc. ", " (replaced by ", " in ROS Groovy and later) ", "\n", "  "], "package_tt": ["pr2_gui"]},
{"url": "https://wiki.ros.org/openrtm_aist_python", "package": "openrtm_aist_python", "package_summary": ["Python binding of OpenRTM-AIST (see", "for further information).", "(", ")"]},
{"url": "https://wiki.ros.org/pal_hardware_gazebo", "package": "pal_hardware_gazebo", "package_summary": ["The pal_hardware_gazebo package"]},
{"url": "https://wiki.ros.org/opencv_apps", "package": "opencv_apps", "package_summary": ["opencv_apps provides various nodes that run internally OpenCV's functionalities and publish the result as ROS topics. With opencv_apps, you can skip writing OpenCV application codes for a lot of its functionalities by simply running a launch file that corresponds to OpenCV's functionality you want.", "The most of code is originally taken from https://github.com/Itseez/opencv/tree/master/samples/cpp"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "With ", ", you can run a lot of functionalities ", " provides in the simplest manner in ROS, i.e., running a launch file that corresponds to the functionality. "], "package_tt": ["opencv_apps", "OpenCV", "indigo", "opencv_apps", "image", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~edge_type", "int", "~canny_threshold1", "int", "~canny_threshold2", "int", "~apertureSize", "int", "~apply_blur_pre", "bool", "~postBlurSize", "int", "~postBlurSigma", "int", "~apply_blur_post", "bool", "~L2gradient", "bool", "~queue_size", "int", "image", "image", "lines", "~use_camera_info", "bool", "~debug_view", "bool", "~hough_type", "int", "~threshould", "int", "~rho", "double", "~theta", "double", "~minLineLength", "double", "~maxLineGrap", "double", "~queue_size", "int", "image", "image", "circles", "~use_camera_info", "bool", "~debug_view", "bool", "~canny_threshold", "int", "~accumulator_threshold", "int", "~gaussian_blur_size", "int", "~gaussian_sigma_x", "double", "~gaussian_sigma_y", "double", "~dp", "int", "~min_circle_radius", "int", "~max_circle_radius", "int", "~queue_size", "int", "image", "image", "contours", "~use_camera_info", "bool", "~debug_view", "bool", "~canny_low_threshold", "int", "~queue_size", "int", "image", "image", "hulls", "~use_camera_info", "bool", "~debug_view", "bool", "~threshold", "int", "~queue_size", "int", "image", "image", "rectangles", "ellipses", "~use_camera_info", "bool", "~debug_view", "bool", "~threshold", "int", "~queue_size", "int", "image", "image", "moment", "~use_camera_info", "bool", "~debug_view", "bool", "~canny_low_threshold", "int", "~queue_size", "int", "image", "image", "faces", "face_image", "~queue_size", "~use_camera_info", "bool", "~debug_view", "bool", "~face_cascade_name", "string", "~eyes_cascade_name", "string", "~queue_size", "int", "image", "faces", "~output", "~debug_image", "~approximate_sync", "bool", "~queue_size", "int", "~model_method", "string", "~use_saved_data", "bool", "~save_train_data", "bool", "~data_dir", "string", "~face_model_width", "int", "~face_model_height", "int", "~face_padding", "double", "~model_num_components", "int", "~model_threshold", "double", "~lbph_radius", "int", "~lbph_neighbors", "int", "~lbph_grid_x", "int", "~lbph_grid_y", "int", "~queue_size", "int", "image", "image", "found", "~use_camera_info", "bool", "~debug_view", "bool", "~hit_threshold", "double", "~win_stride", "int", "~padding", "int", "~scale0", "double", "~group_threshold", "int", "~queue_size", "int", "image", "image", "corners", "~use_camera_info", "bool", "~debug_view", "bool", "~max_corners", "int", "~queue_size", "int", "image", "image", "back_project", "track_box", "~use_camera_info", "bool", "~debug_view", "bool", "~histogram", "array", "~vmin", "int", "~vmax", "int", "~smin", "int", "~queue_size", "int", "image", "image", "flows", "~use_camera_info", "bool", "~debug_view", "bool", "~queue_size", "int", "image", "image", "flows", "initialize_points", "delete_points", "toggle_night_mode", "~use_camera_info", "bool", "~debug_view", "bool", "~quality_level", "double", "~min_distance", "int", "~block_size", "int", "~harris_k", "double", "~queue_size", "int", "image", "image", "shift", "~use_camera_info", "bool", "~debug_view", "bool", "~queue_size", "int", "image", "flows", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~scale", "int", "~queue_size", "int", "image", "image", "contours", "area", "update_bg_model", "~use_camera_info", "bool", "~debug_view", "bool", "~queue_size", "int", "image", "contours", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~queue_size", "int", "image", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~r_limit_max", "int", "~r_limit_min", "int", "~g_limit_max", "int", "~g_limit_min", "int", "~b_limit_max", "int", "~b_limit_min", "int", "~queue_size", "int", "image", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~h_limit_max", "int", "~h_limit_min", "int", "~s_limit_max", "int", "~s_limit_min", "int", "~l_limit_max", "int", "~l_limit_min", "int", "~queue_size", "int", "image", "image", "~use_camera_info", "bool", "~debug_view", "bool", "~h_limit_max", "int", "~h_limit_min", "int", "~s_limit_max", "int", "~s_limit_min", "int", "~v_limit_max", "int", "~v_limit_min", "int", "~queue_size", "int"]},
{"url": "https://wiki.ros.org/polled_camera", "package": "polled_camera", "package_summary": ["polled_camera contains a service and C++ helper classes for implementing a polled\n     camera driver node and requesting images from it. The package is currently for\n     internal use as the API is still under development."], "package_details": ["\n", " defines the ROS interface that client nodes use to request images from a polling camera driver node (e.g. ", "). The protocol is: ", "\n", "\n", "\n", "See the ", " (unstable) for more information on writing polled camera drivers or clients. "], "package_tt": ["polled_camera", "<camera>/request_image", "<response_namespace>/image_raw", "<response_namespace>/camera_info", "<output>/image_raw", "output", "<output>/camera_info", "output", "<camera>/request_image", "camera"], "package_code": ["# Poll \"my_camera\" at 5 Hz, publishing in namespace my_polled_output/.\n", "$ poller 5 camera:=my_camera output:=my_polled_output"]},
{"url": "https://wiki.ros.org/object_manipulation", "package": "object_manipulation", "package_summary": ["\n    Functionality for performing object pickup and placing, while\n    avoiding collisions with the environment. This stack is designed\n    to be robot independent. It contains a complete interface for\n    pickup and place tasks, as well as general implementation of most\n    of the needed functionality.\n\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "  ", "This stack provides the core-functionality for pick and place tasks, implemented in a robot-independent way. For details and documentation, see the ", " package page. ", "Complete applications of the functionality contained here on PR2 robot can be found, along with demos and launch files as well as documentation and tutorials, on the ", " page. ", "To launch the manipulation pipeline and execute pickup and place tasks using the PR2 robot, tutorials and launch files are provided on the ", " page. "]},
{"url": "https://wiki.ros.org/openni_launch", "package": "openni_launch", "package_summary": ["Launch files to open an OpenNI device and load all nodelets to \n     convert raw depth/RGB/IR streams to depth images, disparity images, \n     and (registered) point clouds."], "package_tt": ["openni_launch", "openni_launch", "/camera_depth_optical_frame", "/camera/depth/points", "/camera/driver", "depth_registration", "/camera/depth_registered/points", "RGB8", "depth_registered/image_rect_raw", "depth_registered/*", "camera/depth/*", "camera/depth_registered", "camera/depth_registered/image_raw", "camera/depth/image_raw", "camera", "string", "<camera>", "device_id", "string", "rgb_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/rgb_B00367707227042B", "depth_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/depth_B00367707227042B", "depth_registration", "bool", "load_driver", "bool", "rgb_frame_id", "string", "/<camera>_rgb_optical_frame", "depth_frame_id", "string", "/<camera>_depth_optical_frame", "publish_tf", "bool", "rgb", "string", "rgb", "ir", "string", "ir", "depth", "string", "depth", "depth_registered", "string", "depth_registered", "projector", "string", "projector", "debug", "bool", "respawn", "bool", "camera/rgb/camera_info", "camera/rgb/image_raw", "camera/rgb/image_mono", "camera/rgb/image_color", "camera/rgb/image_rect", "camera/rgb/image_rect_color", "camera/depth/camera_info", "camera/depth/image_raw", "uint16", "camera/depth/image", "float", "camera/depth/image_rect", "float", "camera/depth/disparity", "camera/depth/points", "PointCloud<PointXYZ>", "camera/depth_registered/camera_info", "camera/rgb/camera_info", "camera/depth_registered/image_raw", "uint16", "camera/depth_registered/image", "float", "camera/depth_registered/image_rect", "float", "camera/depth_registered/disparity", "camera/depth_registered/points", "PointCloud<PointXYZRGB>", "camera/ir/camera_info", "camera/ir/image_raw", "uint16", "camera/ir/image_rect", "camera/projector/camera_info", "depth/camera_info", "depth", "projector", "/<camera>_rgb_optical_frame", "/<camera>_depth_optical_frame", "image_mode", "integer", "depth_mode", "integer", "depth_registration", "bool", "depth_skip", "integer", "depth_time_offset", "double", "image_time_offset", "double", "depth_ir_offset_x", "double", "depth_ir_offset_y", "double", "z_offset_mm", "int", "z_scaling", "double", "openni_launch", "openni_launch", "launch/openni.launch", "/camera_depth_optical_frame", "/camera/depth/points", "/camera/driver", "depth_registration", "/camera/depth_registered/points", "RGB8", "openni_launch", "openni.launch", "camera", "string", "<camera>", "device_id", "string", "rgb_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/rgb_B00367707227042B", "depth_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/depth_B00367707227042B", "depth_registration", "bool", "load_driver", "bool", "rgb_frame_id", "string", "/<camera>_rgb_optical_frame", "depth_frame_id", "string", "/<camera>_depth_optical_frame", "publish_tf", "bool", "tf_prefix", "string", "openni.launch", "rgb", "string", "rgb", "ir", "string", "ir", "depth", "string", "depth", "depth_registered", "string", "depth_registered", "projector", "string", "projector", "debug", "bool", "respawn", "bool", "num_worker_threads", "int", "openni_launch", "openni.launch"], "package_code": ["roslaunch openni_launch openni.launch", "rosrun rviz rviz", "rosrun image_view disparity_view image:=/camera/depth/disparity", "rosrun rqt_reconfigure rqt_reconfigure", "rosrun image_view disparity_view image:=/camera/depth_registered/disparity", "rosrun image_view image_view image:=/camera/rgb/image_color", "rosrun image_view image_view image:=/camera/rgb/image_mono", "[ERROR] [1351028964.484342461]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/compressedDepth/set_parameters]\n", "[ERROR] [1351028964.489915028]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/compressed/set_parameters]\n", "[ERROR] [1351028964.495383139]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/theora/set_parameters]", "roslaunch openni_launch openni.launch", "rosrun rviz rviz", "rosrun image_view disparity_view image:=/camera/depth/disparity", "rosrun rqt_reconfigure rqt_reconfigure", "rosrun image_view disparity_view image:=/camera/depth_registered/disparity", "rosrun image_view image_view image:=/camera/rgb/image_color", "rosrun image_view image_view image:=/camera/rgb/image_mono"]},
{"url": "https://wiki.ros.org/raspigibbon_master_slave", "package": "raspigibbon_master_slave", "package_summary": ["The raspigibbon_master_slave package"]},
{"url": "https://wiki.ros.org/openhrp3", "package": "openhrp3", "package_summary": ["This package does not only wrap ", " but actually provides the built artifact from the code from its ", ". Being ROS-agnostic by itself, you can also use this via ROS together with the packages in ", " that bridge between two framework.", " (", "). ", "The package version number is synchronized to that of mainstream, based on ", "."]},
{"url": "https://wiki.ros.org/panda_moveit_config", "package": "panda_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the panda with the MoveIt! Motion Planning Framework"], "package_details": ["Documentation is available at ", ". "]},
{"url": "https://wiki.ros.org/raspigibbon_utils", "package": "raspigibbon_utils", "package_summary": ["The raspigibbon_utils package"]},
{"url": "https://wiki.ros.org/nj_costmap", "package": "nj_costmap", "package_summary": ["The nj_costmap package implements a navigation jockey for the\n\t  Large Maps framework (LaMa) based on a local costmap (costmap position is\n\t  relative to the sensor but orientation is absolute)."], "package_details": ["\n", "\n", "\n", "\n", "The ", " package implements a navigation jockey for the Large Maps Framework (", ") based on a local costmap such as those provided by the ", " package (costmap position is relative to the sensor but orientation is absolute). "], "package_tt": ["nj_costmap", "~<name>/local_costmap", "~<name>/cmd_vel", "~<name>/crossing_marker", "~<name>/exits_marker", "~<name>/\u00a0place_profile", "~<name>/abs_crossing", "~<name>/odom_frame", "String", "~<name>/frontier_width", "Float", "~<name>/robot_radius", "Float", "~<name>/laser_frame", "String", "~<name>/navigating_jockey_server_name", "String"]},
{"url": "https://wiki.ros.org/mrp2_simulator", "package": "mrp2_simulator", "package_summary": ["Simulation-related packages for MRP2"]},
{"url": "https://wiki.ros.org/o3m151_driver", "package": "o3m151_driver", "package_summary": ["ROS device driver for Ifm O3M151 TOF camera."]},
{"url": "https://wiki.ros.org/ompl", "package": "ompl", "package_summary": ["OMPL is a free sampling-based motion planning library."], "package_details": [". Please see ", " on how to use it directly. Please see ", " for more on motion planning. ", "Please report issues / send contribution to ", ". "], "package_tt": ["\u00a0sudo\u00a0apt-get\u00a0install\u00a0ros-fuerte-ompl", "\u00a0sudo\u00a0apt-get\u00a0install\u00a0ros-electric-arm-navigation"]},
{"url": "https://wiki.ros.org/raspigibbon_gazebo", "package": "raspigibbon_gazebo", "package_summary": ["The raspigibbon_gazebo package"]},
{"url": "https://wiki.ros.org/open_karto", "package": "open_karto", "package_summary": ["Catkinized ROS packaging of the OpenKarto library"]},
{"url": "https://wiki.ros.org/mrp2_hardware_gazebo", "package": "mrp2_hardware_gazebo", "package_summary": ["Gazebo plugin of MRP2 robot hardware used in simulation."]},
{"url": "https://wiki.ros.org/r2_controllers_ros", "package": "r2_controllers_ros", "package_summary": ["\n\n     r2_controllers_ros\n\n  "]},
{"url": "https://wiki.ros.org/numatac_can_driver", "package": "numatac_can_driver", "package_summary": ["The numatac_can_driver package"], "package_details": ["\n", "\n", " ", " ", " ", "\n", "\n", " ", "The numatac_can_driver package provides a ROS interface to ", " tactile sensors over a CAN interface. See ", " for details. ", "To bring up the ", " tactile sensors, plug in the USB connector.  Configure the CAN interface by running the following command in a command line prompt: "], "package_tt": ["sudo\u00a0ip\u00a0link\u00a0set\u00a0can0\u00a0type\u00a0can\u00a0bitrate\u00a01000000", "sudo\u00a0ifconfig\u00a0can0\u00a0up", "roslaunch\u00a0numatac_can_driver\u00a0numatac_can_driver.launch", "hand_pressure", "~canbus_dev", "~number_of_sensors", "~tare"]},
{"url": "https://wiki.ros.org/mrp2_gazebo", "package": "mrp2_gazebo", "package_summary": ["Launch files and simulation files to run MRP2 in Gazebo."]},
{"url": "https://wiki.ros.org/raspigibbon_apps", "package": "raspigibbon_apps", "package_summary": ["The raspigibbon_apps package"]},
{"url": "https://wiki.ros.org/openrtm_aist", "package": "openrtm_aist", "package_summary": ["This package represents ", " that's built within ROS eco system. Although being ROS-agnostic by itself, you can use this via ROS together with the packages in ", " that bridge between two framework.", " (", ")", "Its development is happening at ", ". The repository listed below is where the development of its ROS wrapper happening."]},
{"url": "https://wiki.ros.org/nanotron_swarm", "package": "nanotron_swarm", "package_summary": ["Driver for Nanotron radio ranging sensors which uses the Swarm API firmware.\n     This driver will publish range measurements between the host node and \n     other nodes available in the wireless sensor network."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", " ", "\n", " "], "package_tt": ["nanotron_swarm", "range", "nanotron_swarm", "range"]},
{"url": "https://wiki.ros.org/rangeonly_msgs", "package": "rangeonly_msgs", "package_summary": ["The rangeonly_msgs package constains generic ROS messages for range-only sensors."], "package_details": ["\n", "\n", " This message is used to store range-only measurements between a pair of devices (i.e. distance measurements between two sensors). The message includes other kind of information like the type of range-only sensor technology (ultrsonic, radio-based, etc), the unique identifiers of the ranging sensors, etc. As an example, this message has been used with the ", " driver for a radio-based range-only sensor in this ", ". ", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package is part of ", " stack. The package contains generic ROS messages for range-only sensors. "]},
{"url": "https://wiki.ros.org/raspigibbon_sim", "package": "raspigibbon_sim", "package_summary": ["The raspigibbon_sim package"]},
{"url": "https://wiki.ros.org/nav_core2", "package": "nav_core2", "package_summary": ["Interfaces for Costmap, LocalPlanner and GlobalPlanner. Replaces nav_core."], "package_details": [" "]},
{"url": "https://wiki.ros.org/nao_msgs", "package": "nao_msgs", "package_summary": ["\n\n     Message and service declarations for the Nao humanoid\n\n  "]},
{"url": "https://wiki.ros.org/planning_models", "package": "planning_models", "package_summary": ["\n    A set of robot models that can be instantiated from a parsed URDF file.\n  "], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/orocos_kdl", "package": "orocos_kdl", "package_summary": ["This package contains a recent version of the Kinematics and Dynamics\n    Library (KDL), distributed by the Orocos Project."], "package_details": [" "]},
{"url": "https://wiki.ros.org/orrosplanning", "package": "orrosplanning", "package_summary": ["\n    Contains robot ik solvers, planners, and commonly used functions that integrate with the ROS framework.\n  "], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/nav_msgs", "package": "nav_msgs", "package_summary": ["nav_msgs defines the common messages used to interact with the\n    ", " stack."]},
{"url": "https://wiki.ros.org/nav_grid_iterators", "package": "nav_grid_iterators", "package_summary": ["Iterator implementations for moving around the cells of a nav_grid in a number of common patterns."], "package_details": [" "]},
{"url": "https://wiki.ros.org/nj_oa_laser", "package": "nj_oa_laser", "package_summary": ["The nj_oa_laser package is a navigating jockey for the Large\n\t  Maps framework. Its role is to drive the robot forward while avoiding\n\t  obstacles. It uses a LaserScan."], "package_details": ["\n", "\n", "\n", "The ", " package implements a navigating jockey for the Large Maps Framework (", ") that drives the robot while avoiding obstacles. ", "It is based on a laser scan (", "). ", "It is a reactive, memory-less jockey. ", "Moreover, the package provides the class ", " that computes an appropriate ", " from a ", " in order to go as forward as possible while avoiding obstacles. "], "package_tt": ["nj_oa_laser", "TwistHandler", "~<name>/base_scan", "~<name>/cmd_vel", "~<name>/robot_radius", "Float", "~<name>/min_distance", "Float", "~<name>/long_distance", "Float", "~<name>/turnrate_collide", "Float", "~<name>/max_vel", "Float", "~<name>/vel_close_obstacle", "Float", "~<name>/turnrate_factor", "Float", "rad.m^-1.s^-1", "~<name>/laser_frame", "String", "~<name>/navigating_jockey_server_name", "String"]},
{"url": "https://wiki.ros.org/openni2_launch", "package": "openni2_launch", "package_summary": ["Launch files to start the openni2_camera drivers using rgbd_launch."], "package_details": ["\n", "\n", "This package contains launch files for using OpenNI-compliant devices in ROS. It supports the Asus Xtion, Xtion Pro, and multiple version of the Primesense 1.08 and 1.09 cameras. It does NOT support any versions of the Kinect. ", " or ", " is the recommended package for using a Kinect with ROS. ", "More is documented ", " "], "package_code": ["roslaunch openni2_launch openni2.launch"]},
{"url": "https://wiki.ros.org/nlj_dummy", "package": "nlj_dummy", "package_summary": ["The nlj_dummy package"], "package_details": ["\n", "The role of this jockey is to demonstrate some functionalities of the Large Maps Framework (", "). ", "The node ", " starts two jockeys (", " servers): a localizing jockey and a navigating jockey. ", "The localizing jockey (", ") generates 4 randoms integer values (", ") and stores them into the map. ", "The navigating jockey (", ") prints on the console the edge it was asked to traversed and its associated descriptor, and waits a random time. "], "package_tt": ["nlj_dummy", "lj_dummy", "nj_dummy"], "package_code": ["roslaunch nlj_dummy random_walk.launch"]},
{"url": "https://wiki.ros.org/opencv3", "package": "opencv3", "package_summary": ["OpenCV 3.x"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " will only pull in ", " as an extra dependency while ", " will also pull in ", ", ", " and ", " so it depends on whether you go for something small or something you need. ", "\n", "\n", "Since Indigo, there is a package for OpenCV3. It contains the ", " and ", " repos from ", ". Some modules might not get included because the dependencies are hard to package for all platforms (e.g. the optical character recognition module that needs tesseract). ", "Since Kinetic, OpenCV3 is the default. Discussion happened on ", ". ", "Switching code to OpenCV3 can be done following the official guide at ", ". ", "The rosdep key is ", ". ", "Also, if you write OpenCV3 code, chances are high that it will also compile with OpenCV 2.4.9+. E.g., in color conversion, when replacing ", " by ", ", your code will also compile in OpenCV2 as this API has been backported (and not documented ...).  ", "Instead of depending on ", ", you should depend on ", " or ", ". Depending on one of those two keys transitively makes you depend on ", " on Jade and below, or ", " on Kinetic and above. ", "Then, just download the opencv3-release repo at ", " and: "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "#include \"opencv2/core/version.hpp\"\n", "#if CV_MAJOR_VERSION == 2\n", "// do opencv 2 code\n", "#elif CV_MAJOR_VERSION == 3\n", "// do opencv 3 code\n", "#endif", "if(OpenCV_VERSION VERSION_LESS \"3.0\")\n", "# use 2.4 modules\n", "else()\n", "# use 3.x modules\n", "endif()", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "git-bloom-release kinetic"]},
{"url": "https://wiki.ros.org/nj_escape_crossing", "package": "nj_escape_crossing", "package_summary": ["The nj_escape_crossing package is a navigating jockey used to move a robot from away from a crossing"], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package implements a navigating jockey for the Large Maps Framework (", ") which role is to drive the robot away from the crossing center, where the robot is awaited to be when the jockey is started. "], "package_tt": ["nj_escape_crossing", "~<name>/odometry", "~<name>/direction", "~<name>/cmd_vel", "~<name>/kp_v", "Float", "~<name>/kp_w", "Float", "~<name>/min_linear_velocity", "Float", "~<name>/min_angular_velocity", "Float", "~<name>/escape_distance", "Float", "~<name>/crossing_interface_name", "String", "~<name>/exit_angle_interface_name", "String", "~<name>/exit_angle_topic_name", "String"]},
{"url": "https://wiki.ros.org/naoqi_libqicore", "package": "naoqi_libqicore", "package_summary": ["Aldebaran's libqicore: a layer on top of libqi"]},
{"url": "https://wiki.ros.org/prosilica_driver", "package": "prosilica_driver", "package_summary": ["\n    This stack contains the ROS driver and SDK for AVT/Prosilica cameras.\n  "], "package_details": [" ", "\n", "\n", "\n", " ", "ROS driver and SDK for AVT/Prosilica GigE cameras. See ", " for usage and tutorials. ", "Prior to Fuerte, these packages resided in ", ". ", "This stack works with Allied Vision Tech / Prosilica ", ". "]},
{"url": "https://wiki.ros.org/nj_laser", "package": "nj_laser", "package_summary": ["The nj_laser package"], "package_details": ["\n", "\n", "\n", "\n", "The ", " package implements a navigation jockey for the Large Maps Framework (", ") based on a ", ". "], "package_tt": ["nj_laser", "~<name>/local_costmap", "~<name>/cmd_vel", "~<name>/crossing_marker", "~<name>/exits_marker", "~<name>place_profile", "~<name>/crossing", "~<name>/frontier_width", "Float", "~<name>/robot_radius", "Float", "~<name>/max_frontier_distance", "Float", "~<name>/navigating_jockey_server_name", "String"]},
{"url": "https://wiki.ros.org/openni2_camera", "package": "openni2_camera", "package_summary": ["Drivers for the Asus Xtion and Primesense Devices. For using a kinect\n  with ROS, try the "], "package_details": ["\n", "\n", "This package contains launch files for using OpenNI-compliant devices in ROS. It supports the Asus Xtion, Xtion Pro, and multiple version of the Primesense 1.08 and 1.09 cameras. It does NOT support any versions of the Kinect. ", " or ", " is the recommended driver for using a Kinect with ROS. ", "It is recommended to use this driver through the launch files provided in ", " "]},
{"url": "https://wiki.ros.org/openni_tracker", "package": "openni_tracker", "package_summary": ["\n\nopenni_tracker broadcasts the OpenNI skeleton frames using tf.\n\n  "], "package_details": [" ", " is now a unary stack. Previously it was a package in ", ". ", " ", "\n", " - Independent node that does not require other nodes to run (however, make sure your ", " is powered. For example, on ", ", ", " needs to be run successfully). ", "\n", "Once running, stand in front of the Kinect and surrender (i.e. hit the ", ". You should see some variation on the following messages.  ", "The user's pose will be published as a set of transforms (", ") with the following frame names.  "], "package_tt": ["openni_tracker", "rosrun\u00a0openni_tracker\u00a0openni_tracker", "Kinect", "Turtlebot", "kinect.launch", "/tf", "/head", "/neck", "/torso", "/left_shoulder", "/left_elbow", "/left_hand", "/right_shoulder", "/right_elbow", "/right_hand", "/left_hip", "/left_knee", "/left_foot", "/right_hip", "/right_knee", "/right_foot", "camera_frame_id", "string", "/tf"], "package_code": ["New User 1\n", "Pose Psi detected for user 1\n", "Calibration started for user 1\n", "Calibration complete, start tracking user 1\n", "Lost User 1"]},
{"url": "https://wiki.ros.org/python_orocos_kdl", "package": "python_orocos_kdl", "package_summary": ["This package contains the python bindings PyKDL for the Kinematics and Dynamics\n    Library (KDL), distributed by the Orocos Project."], "package_details": [" "]},
{"url": "https://wiki.ros.org/pyros", "package": "pyros", "package_summary": ["Provides Python to ROS multiprocess API, useful for using ROS from different multiprocess environment (think webserver, celery, etc.) while keeping both isolated."]},
{"url": "https://wiki.ros.org/libvlfeat", "package": "libvlfeat", "package_summary": ["The libvlfeat package"]},
{"url": "https://wiki.ros.org/opencv2", "package": "opencv2", "package_summary": [], "package_details": ["\n", "\n", "\n", "For documentation on OpenCV, please see the ", ". For additional libraries to help you use OpenCV with ROS, please see the ", " package and ", " stack. ", "If your issue is related to the OpenCV packaged in ROS (it is too old, you would like to see a backport in there ...), please file a bug using the link at ", ". "], "package_tt": ["opencv2", "opencv2", "<depend\u00a0package=\"opencv2\"\u00a0/>", "find_package()", "CMakeLists.txt", "find_package()", "manifest.xml", "manifest.xml", "stack.xml", "CMakeLists.txt", "find_package()", "manifest.xml", "manifest.xml", "stack.xml", ".deb", "OpenCV2", "libopencv*", "OpenCV", "libopencv*"], "package_code": ["find_package(OpenCV REQUIRED)\n", "#define some target ...\n", "target_link_libraries(my_target ${OpenCV_LIBRARIES})", "  <rosdep name=\"opencv2\"/>", "  <depend package=\"cv_bridge\" />\n", "\n", "  <rosdep name=\"opencv2.3\"/>", "  <depend stack=\"vision_opencv\" />", "rosdep install <your-package>", "sudo apt-get update\n", "sudo apt-get install libopencv2.3-dev", "find_package(OpenCV REQUIRED)\n", "#define some target ...\n", "target_link_libraries(my_target ${OpenCV_LIBS})", "  <rosdep name=\"opencv2\"/>", "  <depend package=\"cv_bridge\" />\n", "\n", "  <rosdep name=\"opencv2\"/>", "  <depend stack=\"vision_opencv\" />", "rosdep install <your-package>", "sudo apt-get update\n", "sudo apt-get install ros-fuerte-opencv2", "$ rosversion opencv2"]},
{"url": "https://wiki.ros.org/ompl_visual_tools", "package": "ompl_visual_tools", "package_summary": ["Rviz 3-D visualizer for planning algorithms implemented with the Open Motion Planning Library (OMPL)"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/lama_test", "package": "lama_test", "package_summary": ["The lama_test package"], "package_details": ["\n", "The ", " package provides a few launch files to test the functionalities of the Large Maps Framework (", "). ", "To test the high-level node ", ": "], "package_tt": ["lama_test", "dfs_explorer/explorer.py", "roslaunch\u00a0dfs_explorer\u00a0explorer.py\u00a0__costmap:=false"], "package_code": ["\n"]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5054/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/lj_laser_heading", "package": "lj_laser_heading", "package_summary": ["Localizing jockey from LaserScan and absolute heading.\n    Implements a localizing jockey from a LaserScan and absolute heading.\n    The associated descriptors are sensor_msgs/LaserScan[] and\n    lama_msgs/Crossing."], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package implements a localizing jockey that computes place dissimilarities based on a ", " and absolute heading. ", "The behavior and properties are similar to those of the ", " jockey. ", "The heading is given either as ", " or ", ". ", "The role of this jockey is to get the dissimilarity of the ", " descriptor of all vertices with the current place profile (represented by a ", "). ", "The action is done when the dissimilarities are computed. ", "Implemented actions: "], "package_tt": ["lj_laser_heading", "GET_VERTEX_DESCRIPTOR", "GET_SIMILARITY", "~<name>/base_scan", "~<name>/pose", "~<name>/odom", "~<name>/dissimilarity_server", "~<name>/laser_interface_name", "String", "~<name>/crossing_interface_name", "String", "~<name>/dissimilarity_server_name", "String"]},
{"url": "https://wiki.ros.org/openni_camera", "package": "openni_camera", "package_summary": ["A ROS driver for OpenNI depth (+ RGB) cameras. These include: \n       Microsoft Kinect,\n       PrimeSense PSDK,\n       ASUS Xtion Pro and Pro Live\n\n    The driver publishes raw depth, RGB, and IR image streams.", "Contents", " ", "\n", "This package provides a ROS interface to depth sensors using the ", ". These currently include: ", "PrimeSense PSDK 5.0 ", " ", " is the best place to begin using your Kinect or similar device. It provides processed outputs such as point clouds. ", "As of Electric, ", " has been trimmed down to just the driver node(let) publishing the raw depth, IR and (if applicable) RGB images. As of Fuerte, it has been trimmed of some heavyweight dependencies (OpenCV, PCL) and made a unary stack to ease installing and running ", " on resource-constrained systems. ", "(If you are using the old, monolithic driver API dating to Diamondback, see ", " for migration instructions and API reference.) ", "\n", "It is highly recommended to use this package through ", ", which provides additional RGB-D processing capabilities for the data produced by ", " ", "\n", "\n", "To install only openni_camera: ", "It's also recommended to install ", ": ", "To use the Microsoft Kinect you also need a driver: ", "PPA: ", " ", "Source: ", " ", "\n", "\n", "\n", "Please report all bugs at ", " ", "\n", " "], "package_details": ["\n", "Note: This is the ", " for your usage of openni_camera / openni_launch for Kinect in ROS. You have to firstly install the Driver for Kinect on Ubuntu and make sure your kinect can work properly on ubuntu. ", "To get started, please Refer ", " and you may meet some incompatible contents, do not worry, the thought and path is correct. ", "The very important doc you should read carefully is that on ", " and that on ", ". "], "package_tt": ["openni_camera", "/openni_rgb_optical_frame", "/camera/rgb/points", "/openni_node1", "openni_camera", "rgb/camera_info", "rgb/image_raw", "~depth_registration", "depth/camera_info", "depth/image_raw", "uint16", "~depth_registration", "depth_registered/camera_info", "rgb/camera_info", "depth_registered/image_raw", "depth_registered/image_raw", "uint16", "ir/camera_info", "ir/image_raw", "uint16", "projector/camera_info", "depth/camera_info", "depth", "projector", "rgb/set_camera_info", "ir/set_camera_info", "~device_id", "string", "~rgb_frame_id", "string", "/openni_rgb_optical_frame", "~depth_frame_id", "string", "/openni_depth_optical_frame", "~rgb_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/rgb_B00367707227042B", "~depth_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/depth_B00367707227042B", "~time_out", "double", "~time_out", "~image_mode", "int", "~depth_mode", "int", "~depth_registration", "bool", "~data_skip", "int", "~depth_time_offset", "double", "~image_time_offset", "double", "~depth_ir_offset_x", "double", "~depth_ir_offset_y", "double", "~z_offset_mm", "int", "openni_node", "openni_camera", "openni_camera", "openni_node", "rgb/camera_info", "rgb/image_raw", "~depth_registration", "depth/camera_info", "depth/image_raw", "uint16", "~depth_registration", "depth_registered/camera_info", "rgb/camera_info", "depth_registered/image_raw", "depth_registered/image_raw", "uint16", "ir/camera_info", "ir/image_raw", "uint16", "projector/camera_info", "depth/camera_info", "depth", "projector", "rgb/set_camera_info", "ir/set_camera_info", "~device_id", "string", "~rgb_frame_id", "string", "/openni_rgb_optical_frame", "~depth_frame_id", "string", "/openni_depth_optical_frame", "~rgb_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/rgb_B00367707227042B", "~depth_camera_info_url", "string", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "$HOME/.ros/camera_info/depth_B00367707227042B", "~time_out", "double", "~time_out", "~image_mode", "int", "~depth_mode", "int", "~depth_registration", "bool", "~data_skip", "int", "~depth_time_offset", "double", "~image_time_offset", "double", "~depth_ir_offset_x", "double", "~depth_ir_offset_y", "double", "~z_offset_mm", "int", "openni_node"], "package_code": ["rosmake openni_camera", "roslaunch openni_camera openni_node.launch", "rosrun rviz rviz", "rosrun image_view image_view image:=/camera/rgb/image_color", "rosrun image_view image_view image:=/camera/rgb/image_mono", "rosrun dynamic_reconfigure reconfigure_gui", "/openni_camera\n", "|\n", "|> /openni_rgb_frame\n", "|  |\n", "|  |> /openni_rgb_optical_frame  (Z forward)\n", "|\n", "|> /openni_depth_frame\n", "   |\n", "   |> /openni_depth_optical_frame (Z forward)", "sudo apt-get install ros-electric-openni-camera", "sudo apt-get install ros-electric-openni-launch", "sudo apt-get install ros-<rosdistro>-openni-camera", "sudo apt-get install ros-<rosdistro>-openni-launch"]},
{"url": "https://wiki.ros.org/kinect_2d_scanner", "package": "kinect_2d_scanner", "package_summary": ["A ROS node to \nread range data from a Kinect sensor and convert it (in a flexible way) into 2D equivalent range scans. This allows low-cost implementation of classic SLAM and localization techniques originally designed to work with more expensive laser range finders."], "package_details": ["\n", " are considered and the minimum distance is kept in each direction. The horizontal FOV of the frustum is automatically computed from the intrinsic parameters of the range camera, but the vertical FOV must be provided by the user, and ", " which may be useful depending on the zone of interest where to look for obstacles. See ", " for an illustration of the frustum geometry and 3D obstacle points. ", "\n", "The node ", " makes easy to connect to a Kinect sensor and publish equivalent 2D \"fake laser\" scans. ", "Internally, the node uses ", " which in turn uses ", " to directly open the sensor. Since only 2D scan data is published here, you should employ this node only if you won't need the 3D points.  ", "All spatial transformations are riguorously taken into account in this class, using the depth camera intrinsic calibration parameters. ", " should be provided in the format expected by MRPT (explain me!), but default values will be used otherwise. ", "Read ", " for more details. ", "This node implements the ", " interface. "], "package_tt": ["mrpt-hwdrivers", "libfreenect"], "package_code": ["roscd kinect_2d_scanner\n", "roslaunch kinect_2d_scanner_test.launch"]},
{"url": "https://wiki.ros.org/innok_heros_control", "package": "innok_heros_control", "package_summary": ["package to control the Innok Heros with several devices (e. g. joystick and keyboard)"]},
{"url": "https://wiki.ros.org/pykdl_utils", "package": "pykdl_utils", "package_summary": ["\n\n    pykdl_utils contains kdl_parser.py, for parsing URDF objects\n     from the robot_model_py stack into PyKDL trees and chains, \n     and kdl_kinematics.py, for wrapping KDL kinematics calls, making\n     kinematics requests in Python far simpler.  jointspace_kdl_kin.py\n     also contains a KDLKinematics superclass which subscribes to /joint_states,\n     automatically filling the FK and jacobian requests with the current joint\n     angles.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "For running all of the unit tests, you can either pass a URDF xml file to use or leave it blank and have the URDF pulled from the parameter ", " on the parameter server. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "rosrun pykdl_utils kdl_parser.py [robot.xml]\n", "rosrun pykdl_utils kdl_kinematics.py [robot.xml]\n", "rosrun pykdl_utils joint_kinematics.py [robot.xml]"]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14694/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20304/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/map_ray_caster", "package": "map_ray_caster", "package_summary": ["The map_ray_caster package provides a class for cached ray casting\n  on maps. The origin of all rays is fixed relative to the map, it is the map center."], "package_details": [" provides a cached ray casting on a map, such as those provided by ", " of the Large Maps Framework (", "). ", "\n", " provides a cached ray casting on a map, such as those provided by ", ". The origin of all rays is fixed relative to the map, it is the map center. It takes as input a costmap (", ") and returns a laser scan (", "). The ray casting will be from ", " to ", ". Moreover, other value of the input scan are used so that the scan message must be initialized with non-default values. ", "\n", "To use the ", " class to compute a fake  ", " from an occupancy grid in C++: "], "package_tt": ["map_ray_caster", "local_map", "map_ray_caster", "local_map", "scan.angle_min", "scan.angle_max", "map_ray_caster::MapRayCaster"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/jaguar_msgs", "package": "jaguar_msgs", "package_summary": ["Messages for DrRobot's Jaguar 4X4"]},
{"url": "https://wiki.ros.org/jaguar_navigation", "package": "jaguar_navigation", "package_summary": ["Navigation package for DrRobot's Jaguar 4X4"]},
{"url": "https://wiki.ros.org/jaguar_description", "package": "jaguar_description", "package_summary": ["A robot description package for Dr Robot's Jaguar 4x4"]},
{"url": "https://wiki.ros.org/innok_heros_gazebo", "package": "innok_heros_gazebo", "package_summary": ["Innok Heros launch files for Gazebo6"], "package_details": ["\n", "The robot model was successfully tested with Gazebo6 thus ", ". To install Gazebo6 see ", ". ", "\n"]},
{"url": "https://wiki.ros.org/aras_visual_servo_controller", "package": "aras_visual_servo_controller", "package_summary": ["The aras_visual_servo package"], "package_details": ["\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/ackermann_controller", "package": "ackermann_controller", "package_summary": ["The ackermann_controller package"]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14695/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20305/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/lpms_imu", "package": "lpms_imu", "package_summary": ["ROS driver for lpms_imu sensors."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/innok_heros_lights", "package": "innok_heros_lights", "package_summary": ["ROS driver for LED lights installed on Innok Heros"]},
{"url": "https://wiki.ros.org/look_at_pose", "package": "look_at_pose", "package_summary": ["Rotate camera to look at a given pose."], "package_details": ["\n", " ", "This camera has a rough initial alignment with the object of interest (the pink cylinder) and it is nearly upside-down. The pose returned from a call to look_at_pose is well-aligned and the camera is upright. ", " ", " ", "\n", "\n", " ", "\n", "\n", "or, clone and build from ", ". ", "In RViz, turn on ", " and ", " (topic: visualization_marker) to see the original camera frame, new camera frame, and point of interest. ", "* ", ":  The current pose of the camera. This should  be point (0,0,0) and quaternion (0,0,0,1) in the camera's own frame. ", "* ", ": Where should the camera look? The orientation actually isn't used. ", "* ", ": A vector that defines \"UP.\" If Z of the camera frame is up, then it would be (0,0,1). ", "The service response is another ", " in the initial camera frame: ", "* ", " ", "It's currently assumed that X is the \"lens vector\" of the camera and Z of the camera frame should point up. If your situation requires something else, please create an issue on the ", ". "], "package_code": ["sudo apt install ros-kinetic-look-at-pose", "rosrun rviz rviz", "rosrun look_at_pose look_at_pose_server", "rosrun look_at_pose test_client"]},
{"url": "https://wiki.ros.org/lj_costmap", "package": "lj_costmap", "package_summary": ["Implements a localizing jockey for the\n\t  Large Maps framework (LaMa) based on a local costmap (costmap position is\n\t  relative to the sensor but orientation is absolute).\n\n\t  Implement a localizing jockey from a LaserScan. The associated\n\t  descriptors are LaserScan[] and Crossing."], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package is a localizing jockey for the Large Maps Framework (", ") that computes place dissimilarities based on a local cost map, such as those obtained from the ", " package. ", "The role of this jockey is to get the dissimilarity of the ", " descriptors of all vertices with the current place profile. ", "The action is done when the dissimilarities are computed. ", "Implemented actions: "], "package_tt": ["lj_costmap", "GET_VERTEX_DESCRIPTOR", "GET_SIMILARITY", "~<name>/local_costmap", "~<name>/dissimilarity_server", "~<name>/costmap_interface_name", "String", "~<name>/crossing_interface_name", "String", "~<name>/dissimilarity_server_name", "String"]},
{"url": "https://wiki.ros.org/anj_featurenav", "package": "anj_featurenav", "package_summary": ["The anj_featurenav package provides a learning jockey and a\n    navigating jockey for the Large Maps framework (LaMa). It learns a\n    path by saving image features and is able to follow the same path.\n    It is based on algorithms provided by OpenCV (free ones)."], "package_details": ["\n", " implements a feature-based learning and navigating jockey based on free OpenCV feature descriptor and matcher. The package defines the feature extractor and the descriptor matcher functions required by the ", " package to obtain a working couple learning/navigating jockeys. ", "\n", "\n", "\n", "The SimpleBlog algorithm takes no parameter, cf. ", ". ", "The FlannBased algorithm takes no parameter, cf. ", ". "], "package_tt": ["anj_featurenav", "featurenav_base", "~<name>/feature_detector/type", "String", "~<name>/descriptor_extractor/type", "String", "~<name>/descriptor_matcher/type", "String", "~<name>/feature_detector/threshold", "Int", "~<name>/feature_detector/nonmax_suppression", "Bool", "~<name>/feature_detector/max_size", "Int", "~<name>/feature_detector/response_threshold", "Int", "~<name>/feature_detector/line_threshold_projected", "Int", "~<name>/feature_detector/line_threshold_binarized", "Int", "~<name>/feature_detector/suppress_nonmax_size", "Int", "~<name>/feature_detector/scale_factor", "Float", "~<name>/feature_detector/n_features", "Int", "~<name>/feature_detector/n_levels", "Int", "~<name>/feature_detector/edge_threshold", "Int", "~<name>/feature_detector/first_level", "Int", "~<name>/feature_detector/wta_k", "Int", "~<name>/feature_detector/score_type", "Int", "~<name>/feature_detector/patch_size", "Int", "~<name>/feature_detector/delta", "Int", "~<name>/feature_detector/min_area", "Int", "~<name>/feature_detector/max_area", "Int", "~<name>/feature_detector/max_variation", "Float", "~<name>/feature_detector/min_diversity", "Float", "~<name>/feature_detector/max_evolution", "Int", "~<name>/feature_detector/area_threshold", "Float", "~<name>/feature_detector/min_margin", "Float", "~<name>/feature_detector/edge_blur_size", "Int", "~<name>/feature_detector/max_corners", "Int", "~<name>/feature_detector/block_size", "Int", "~<name>/feature_detector/quality_level", "Float", "~<name>/feature_detector/min_distance", "Float", "~<name>/feature_detector/k", "Float", "~<name>/feature_detector/use_harris_detector", "Bool", "~<name>/feature_detector/feature_scale_levels", "Int", "~<name>/feature_detector/init_xy_step", "Int", "~<name>/feature_detector/init_img_bound", "Int", "~<name>/feature_detector/init_feature_scale", "Float", "~<name>/feature_detector/feature_scale_mul", "Float", "~<name>/feature_detector/vary_xy_step_with_scale", "Bool", "~<name>/feature_detector/vary_img_bound_with_scale", "Bool", "~<name>/descriptor_extractor/scale_factor", "Float", "~<name>/descriptor_extractor/n_features", "Int", "~<name>/descriptor_extractor/n_levels", "Int", "~<name>/descriptor_extractor/edge_threshold", "Int", "~<name>/descriptor_extractor/first_level", "Int", "~<name>/descriptor_extractor/wta_k", "Int", "~<name>/descriptor_extractor/score_type", "Int", "~<name>/descriptor_extractor/patch_size", "Int", "~<name>/descriptor_extractor/bytes", "Int", "~<name>/descriptor_matcher/norm", "String", "~<name>/descriptor_matcher/cross_check", "Bool"]},
{"url": "https://wiki.ros.org/dfs_explorer", "package": "dfs_explorer", "package_summary": ["An explorer with depth-first search for finite worlds for the Large Maps Framework (LaMa)."], "package_details": ["\n", "\n", "The ", " package implements the node ", " which is an explorer with depth-first-search-like algorithm for finite worlds for the Large Maps Framework (", "). It proceeds as follows: ", "A test launch file can be found in the ", " package: "], "package_tt": ["dfs_explorer", "explorer.py"], "package_code": ["\n"]},
{"url": "https://wiki.ros.org/lkh", "package": "lkh", "package_summary": ["ROS packages for solving the TSP and GTSP problems using LKH heuristic"], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/log_server", "package": "log_server", "package_summary": ["The log_server package"]},
{"url": "https://wiki.ros.org/goto_crossing", "package": "goto_crossing", "package_summary": ["The goto_crossing package provides a goToGoal behavior\n\t  to a crossing center if the crossing has at least three\n\t  frontiers and some kind of move forward behavior if it\n\t  has two or less frontiers."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The goto_crossing provides a Go-To-Goal behavior to reach the center of a crossing (", " message) for the Large Maps Framework (", "). ", "The goto_crossing provides a Go-To-Goal behavior to reach the center of a crossing (", " message). ", "Launch the node with ", ". ", "To use the ", " as class instance, one uses ", " to compute the twist necessary to reach the crossing center: "], "package_tt": ["rosrun\u00a0goto_crossing\u00a0goto_crossing", "goto_crossing::CrossingGoer", "goto_crossing::CrossingGoer::goto_crossing", "~<name>/crossing", "center", "~<name>/cmd_vel", "~<name>/goal_reached", "reach_distance", "~<name>/reset_integrals", "~<name>/kp_v", "float", "~<name>/kp_w", "float", "~<name>/ki_v", "float", "~<name>/ki_w", "float", "~<name>/min_linear_velocity", "float", "~<name>/max_linear_velocity", "float", "~<name>/min_angular_velocity", "float", "~<name>/max_angular_velocity", "float", "~<name>/reach_distance", "float", "~<name>/dtheta_force_lef", "float", "~<name>/threshold_w_only", "float", "~<name>/max_sum_v", "float", "~<name>/max_sum_w", "float"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cassandra_ros", "package": "cassandra_ros", "package_summary": ["\n\n     Library and tools for dynamically storing ROS messages in Apache Cassandra.\n\n  "], "package_details": ["\n", "\n", " ", " partitioner is required to retrieve requested data ordered, otherwise it will appear. For more information, have look on the documentation on ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "5514/1 ", "Then change the Cassandra partitioner to \"", "\", which can be set in  ", "partitioner: org.apache.cassandra.dht.", " ", "The option -f hinders Cassandra to start a deamon in backgroud, for more information and help visit : ", " ", "Check the following link: ", " ", "How does it work? If you take a look into cassandra_ros/lib ... you will see a couple of files in the form of ", "_'format'.py, which are all descendants of ", "_.py. And each of them overwrites the methods: ", "As you could see so far, you only work with the single class of ", ". In fact, this class inherits those methods, required for encoding and decoding of messages, and only those of the required parent class. If you are seeking for more information, have a look at the follwing link:  ", " ", "If you want to analyze your data by using CQL, the ", ", you will have to generate at first secondary indexes. Because this might be expensive and not required for every part of a message, this has to be done manually, as follows: ", "For more information on CQL, check the following website: ", " "], "package_code": ["$ bin/cassandra -f", "$ roslaunch cassandra_ros recordCamera.launch", "$ roslaunch cassandra_ros replayCamera.launch", "$ roslaunch cassandra_ros deleteCamera.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/innok_heros_description", "package": "innok_heros_description", "package_summary": ["Innok Heros URDF description and RVIZ launch file"], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/joystick_sdl", "package": "joystick_sdl", "package_summary": ["A cross-platform joystick node, backed by SDL2."]},
{"url": "https://wiki.ros.org/lj_laser", "package": "lj_laser", "package_summary": ["Localizing jockey from LaserScan\n\n\t  Implement a localizing jockey from a LaserScan. The associated descriptor\n\t  are LaserScan[] and Crossing."], "package_details": ["\n", "\n", "\n", "\n", "\n", "The ", " package is a localizing jockey for the Large Maps Framework ", "(", ") that computes place dissimilarities based on a ", "360-degree ", ". "], "package_tt": ["lj_laser", "GET_VERTEX_DESCRIPTOR", "GET_SIMILARITY", "~<name>/base_scan", "~<name>/dissimilarity_server", "~<name>/laser_interface_name", "String", "~<name>/crossing_interface_name", "String", "~<name>/dissimilarity_server_name", "String"]},
{"url": "https://wiki.ros.org/lkh_solver", "package": "lkh_solver", "package_summary": ["ROS package for solving the Traveling Salesman Problem using the\n    Lin-Kernighan heuristic."]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14696/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20307/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/aras_visual_servo_camera", "package": "aras_visual_servo_camera", "package_summary": ["The aras_visual_servo_camera package"], "package_details": [" ", " ", " "]},
{"url": "https://wiki.ros.org/featurenav_base", "package": "featurenav_base", "package_summary": ["The featurenav_base package provides base functionality\n    for learning and navigating jockeys based on feature detection for\n    the Large Maps Framework (LaMa)."], "package_details": ["\n", " provides base class for feature-based navigation for the Large Maps Framework (", "). Feature-based navigation implement the base functionalities of two jockeys. The first one, the learning jockey learns a path while the robot is driving externally. The learned path is a series of image descriptors with extra information. The second one, the navigating jockey can then drive the robot and follow this path. "], "package_tt": ["featurenav_base"]},
{"url": "https://wiki.ros.org/lama_interfaces", "package": "lama_interfaces", "package_summary": ["The lama_interfaces package provides the interfaces between ROS nodes\n\t  (such as jockeys from lama_jockeys) and the map."], "package_details": [" provides the interfaces to the database as ROS services for the Large Maps Framework (", "). ", "\n", " provides the interfaces to the database as ROS services. ", "\n", "\n", "\n", "\n", "The data storage is realized through a database. All databases supported by Python sqlalchemy can be used. The default database is an SQLite database which will be save as ", ". The environment is represented as a directed graph, where vertices are points of interest such as crossings. Descriptors can be associated to vertices and edges, they give some information about the environment, so that jockeys can localize or drive the robot. Any ROS message can be saved as descriptor after a trivial implementation of two services (srv files), one to write the descriptor into the database and one to retrieve it. Other variable types can use the ", " message type. Descriptor storage occurs either in binary or clear-text mode. ", "The first node that should be used when working with the LaMa Framework is ", ": ", "This node will run several services: ", ", ", ", ", ", and ", ", which are described in further sections. ", "This service of type ", " is used for all actions over vertices and edges in the map. ", "This service of type ", " is used to generate two services for each descriptor type, one to write the descriptor into the database and one to retrieve it. Descriptor storage occurs either in binary or clear-text mode (specified through the ", " service attribute. The name of these two services will be the name of the interface (", " attribute) to which \"", "\" or \"", "\" are added. ", "For example, to create a clear-text interface for ", " in C++: ", "To add a database interface in Python, one can either use the ", " service or call the equivalent Python function. For example, for a \"", "\" descriptor with binary storage: ", "The services ", " and ", " provide direct access to the graph vertices or edges. These functionalities are provided by the ", ", which should be preferred. "], "package_tt": ["lama_interfaces", "lama_interfaces", "~/.ros/lama.sqlite", "map_node", "/lama_map_agent", "/interface_factory", "/lama_object_getter", "/lama_object_setter", "interface_type", "interface_name", "_getter", "_setter", "float64", "/interface_factory", "sensor_msgs/LaserScan[]", "/lama_object_getter", "/lama_object_setter", "/lama_map_agent"], "package_code": ["rosrun lama_interfaces map_node", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/lama_msgs", "package": "lama_msgs", "package_summary": ["lama_msgs provides messages for the lama framework such as\n\t  Frontier, Crossing."], "package_details": [" contains messages that represent places for the Large Maps Framework (", "). ", "\n", " contains messages that represent places. These messages are used as descriptors for vertices. ", "Newly proposed, mistyped, or obsolete package. Could not find package \"lama_msgs\" in rosdoc: /home/rosbot/docs/api/lama_msgs/manifest.yaml "], "package_tt": ["lama_msgs", "lama_msgs"]},
{"url": "https://wiki.ros.org/ardrone2islab", "package": "ardrone2islab", "package_summary": ["The ardrone2islab package"], "package_details": ["\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5055/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/local_map", "package": "local_map", "package_summary": ["The local_map package\n\t  The local_map package takes as input a LaserScan message and outputs\n\t  a local map as OccupancyGrid. The local map orientation is the same\n\t  as the one of the global frame."], "package_details": [" provides a simple local cost map for several jockeys for the Large Maps Framework (", "). The map is centered on the frame of the laser range finder on which it is based but its orientation is fixed. ", "\n", " ", "\n", "\n", "\n", "The image shows the map in player on the left and the local map obtained from the LaserScan (red dots) on the right. The robot's orientation is approximately 45\u00b0 but the map's orientation is fixed. "], "package_tt": ["local_map", "~<name>/footprint", "~<name>/local_map", "~<name>/map_width", "float", "~<name>/map_height", "float", "~<name>/map_resolution", "double"]},
{"url": "https://wiki.ros.org/crossing_detector", "package": "crossing_detector", "package_summary": ["The crossing_detector package recognize frontiers from a LaserScan"], "package_details": ["\n", " ", " ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"crossing_detector\" in rosdoc: /home/rosbot/docs/api/crossing_detector/manifest.yaml ", "The ", " package implements a method to recognize a crossing, i.e. a place from where the robot can take clearly distinctive paths. It is part of the Large Maps Framework (", "). ", "The computation is based on a costmap such as those provided by the ", " package, a ", " message, or a ", " message. It is meant to be used in the form of a class instance but two nodes are provided that compute a ", " from a ", " or a ", ", respectively, as a service. ", "Packages ", " and ", " use the functionalities provided by the ", " package and can be used as example. "], "package_tt": ["crossing_detector", "crossing_detector"]},
{"url": "https://wiki.ros.org/kobuki_led_controller", "package": "kobuki_led_controller", "package_summary": ["Convenient modules to control kobuki leds"], "package_details": ["\n", "\n", "Python library to control ", " LEDs. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/aras_visual_servo_gazebo", "package": "aras_visual_servo_gazebo", "package_summary": ["The aras_visual_servo_gazebo package"], "package_details": ["\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/lama_common", "package": "lama_common", "package_summary": ["Utilities for the LaMa package"], "package_details": [" provides functionalities to convert messages of the ", " package to other ROS messages and to visualize these messages in rviz. It belongs to the Large Maps Framework (", "). ", "\n", " provides functionalities to convert messages of the ", " package to other ROS messages and to visualize these messages in ", ". "], "package_tt": ["lama_common", "lama_common"]},
{"url": "https://wiki.ros.org/lost_comms_recovery", "package": "lost_comms_recovery", "package_summary": ["If your robot loses connection to the base station it will stop motors or navigate home."], "package_details": ["\n", "\n", "\n", "\n", "\n", ": Instead of relying on this this feature, you're better off with motor control software that sets zero velocity after a certain amount of time not receiving any new commands. ", "\n", "\n", "\n", "\n", "\n", "If move_base is not running when communication failure occurs then motors and joysticks are set to zero by publishing a zero ", " message and a zero ", " message. "], "package_tt": ["geometry_msgs/Twist", "sensor_msgs/Joy", "move_base", "recovery_pose", "goal_frame_id", "cmd_vel", "Twist", "joy", "Joy", "~goal_frame_id", "string", "move_base", "~ping_fail_count", "int", "~ips_to_monitor", "string"], "package_code": ["$ sudo apt-get install ros-kinetic-lost-comms-recovery", "$ roslaunch lost_comms_recovery lost_comms_recovery.launch ips_to_monitor:=192.168.1.2", "$ roslaunch lost_comms_recovery lost_comms_recovery.launch ips_to_monitor:=192.168.190.136\n", "\n", "[INFO] Monitoring base station on IP(s): 192.168.190.136.\n", "[INFO] Connected to base station.\n", "[INFO] Connected to base station.\n", "...\n", "[ERROR] No connection to base station.\n", "[INFO] Executing move_base goal to position (x,y) 0.0, 0.0.\n", "[INFO] Initial goal status: PENDING\n", "[INFO] This goal has been accepted by the simple action server\n", "[INFO] Final goal status: SUCCEEDED\n", "[INFO] Goal reached."]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5056/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/glkh_solver", "package": "glkh_solver", "package_summary": ["ROS package for solving the Generalized Traveling Salesman Problem using\n    the Lin\u2013Kernighan heuristic."]},
{"url": "https://wiki.ros.org/jaco_gazebo", "package": "jaco_gazebo", "package_summary": ["The jaco_gazebo package"]},
{"url": "https://wiki.ros.org/homer_gui", "package": "homer_gui", "package_summary": ["commander interface"], "package_details": [" "]},
{"url": "https://wiki.ros.org/image_publisher", "package": "image_publisher", "package_summary": ["\n      Contains a node publish an image stream from single image file\n      or avi motion file.\n    "], "package_details": ["\n", " provides a node/nodelets for publishing image as a ROS image topic. ", "\n", "\n", "\n", "\n"], "package_tt": ["image_publisher", "image_raw", "camera_info", "filename", "string", "flip_horizontal", "bool", "flip_vertical", "bool", "frame_id", "string", "publish_rate", "double", "camera_info_uri", "string", "image_raw", "camera_info", "Same\u00a0as\u00a0image_publisher\u00a0node"], "package_code": ["rosrun image_publisher image_publisher /opt/ros/indigo/share/rviz/images/splash.png", "<launch>                                                                        \n", "  <node pkg=\"image_publisher\" type=\"image_publisher\" name=\"image_publisher\"\n", "        args=\"$(find rviz)/images/splash.png\" >\n", "    <param name=\"flip_horizontal\" value=\"false\" />\n", "    <param name=\"flip_vertical\" value=\"false\" />\n", "    <param name=\"frame_id\" value=\"my_camera\" />\n", "    <param name=\"publish_rate\" value=\"1\" />\n", "    <param name=\"camera_info_url\" value=\"file:///$(env HOME)/.ros/camera_info/camera.yaml\" />   <!-- relative to ~/.ros/ -->\n", "  </node>\n", "</launch>", "<launch>                                                                        \n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"manager\" args=\"manager\"/>\n", "\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"image_publisher\"\n", "        args=\"load image_publisher/image_publisher manager\">\n", "    <param name=\"filename\" value=\"$(find rviz)/images/splash.png\" />\n", "    <param name=\"flip_horizontal\" value=\"false\" />\n", "    <param name=\"flip_vertical\" value=\"false\" />\n", "  </node>\n", "  <param name=\"/manager/frame_id\" value=\"my_camera\" />\n", "  <param name=\"/manager/publish_rate\" value=\"1\" />\n", "  <param name=\"camera_info_url\" value=\"file:///$(env HOME)/.ros/camera_info/camera.yaml\" />  <!-- relative to ~/.ros/ -->\n", "</launch>"]},
{"url": "https://wiki.ros.org/imu_complementary_filter", "package": "imu_complementary_filter", "package_summary": ["Filter which fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into a quaternion to represent the orientation of the device wrt the global frame. Based on the algorithm by Roberto G. Valenti etal. described in the paper \"Keeping a Good Attitude: A Quaternion-Based Orientation Filter for IMUs and MARGs\" available at http://www.mdpi.com/1424-8220/15/8/19302 ."], "package_details": ["\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n "], "package_tt": ["imu/data_raw", "imu/mag", "imu/data", "imu/rpy/filtered", "imu_data", "~publish_debug_topics", "imu/steady_state", "~publish_debug_topics", "~gain_acc", "double", "~gain_mag", "double", "~bias_alpha", "double", "~do_bias_estimation", "bool", "true", "~do_adaptive_gain", "bool", "true", "~use_mag", "bool", "false", "~fixed_frame", "string", "odom", "publish_tf", "~publish_tf", "bool", "false", "fixed_frame", "~reverse_tf", "bool", "false", "true", "imu_frame", "fixed\u00a0frame", "~constant_dt", "double", "~publish_debug_topics", "bool", "false", "true", "fixed_frame", "imu_frame", "fixed_frame", "header.frame_id"]},
{"url": "https://wiki.ros.org/image_transport_plugins", "package": "image_transport_plugins", "package_summary": ["A set of plugins for publishing and subscribing to sensor_msgs/Image topics\n    in representations other than raw pixel data. For example, for viewing a\n    stream of images off-robot, a video codec will give much lower bandwidth\n    and latency. For low frame rate tranport of high-definition images, you\n    might prefer sending them as JPEG or PNG-compressed form."], "package_details": ["\n", " contains plugins to ", " for sending ", " topics in compressed representations. Its contents include: ", "\n", "\n", " ", "These transports will only be available if the plugins are built on your system! On Ubuntu, they are included in the ", " deb for each distribution. If building from source, you must explicitly build the ", " stack. "], "package_tt": ["image_transport_plugins", "ros-<distro>-image-transport-plugins", "image_transport_plugins"]},
{"url": "https://wiki.ros.org/image_cb_detector", "package": "image_cb_detector", "package_summary": ["Provide a node that extracts checkerboard corners from ROS images.\n    This package is still experimental and unstable.\n    Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/laser_cb_detector", "package": "laser_cb_detector", "package_summary": ["Extracts checkerboard corners from a dense laser snapshot.\n     This package is experimental and unstable. Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/image_transport", "package": "image_transport", "package_summary": ["image_transport should always be used to subscribe to and publish images. It provides transparent\n     support for transporting images in low-bandwidth compressed formats. Examples (provided by separate\n     plugin packages) include JPEG/PNG compression and Theora streaming video."], "package_details": ["\n", "\n", " should always be used to publish and subscribe to images. At this basic level of usage, it is very similar to using ROS Publishers and Subscribers. Using ", " instead of the ROS primitives, however, gives you great flexibility in how images are communicated between nodes. ", "\n", " publishers advertise individual ROS ", " for each available transport - unlike ROS Publishers, which advertise a single topic. The topic names follow a standard naming convention, outlined below. Note, however, that all code interfaces take only a \"base topic\" name (to which the transport type is automatically appended); typically you should not directly reference the transport-specific topic used by a particular plugin. ", "\n", " does not yet support Python, though it is on the ", ". If you need to interface a Python node with some compressed image transport, try interposing a ", " node. ", "\n", "\n", "\n", " publishers are used much like ROS Publishers, but may offer a variety of specialized transport options (JPEG compression, streaming video, etc.). Different subscribers may request images from the same publisher using different transports. ", "\n", " publishers advertise individual ROS ", " for each available transport - unlike ROS Publishers, which advertise a single topic. The topic names follow a standard naming convention, outlined below. Note, however, that all code interfaces take only a \"base topic\" name; typically you should not directly reference the transport-specific topic used by a particular plugin. ", "\n", " publishers have no independent parameters, but plugins are permitted to make use of the ", " for configuration options, e.g. bit rate, compression level, etc. See the plugin package documentation. ", "\n", " subscribers are used much like ", "'s ", ", but may use a specialized transport to receive images. ", "\n", " may be used to specify a different namespace for parameter lookup. This is useful to remap ", " into a separate namespace to allow different transports for different image subscriptions. The node writer may even specify a parameter name other than ", ", although this is discouraged for the sake of consistency. Nodes that subscribe to image topics should document what parameter(s) control transport, especially if different from ", ". ", "\n", "\n", "\n", "\n", " itself does not make use of the ", ". Plugins may read or set plugin-specific parameters, however. ", "\n", "\n", " lists the declared image transport options across all ROS packages and attempts to determine whether they are currently available for use (packages built, plugins able to be loaded properly, etc.). ", "\n", "When working with images we often want specialized transport strategies, such as using image compression or streaming video codecs. ", " provides classes and nodes for transporting images in arbitrary over-the-wire representations, while abstracting this complexity so that the developer only sees ", " messages. ", "Specialized transports are provided by plugins. ", " itself provides only ", " transport so as not to impose unnecessary dependencies on client packages. Other transports will only be available if they are built on your system. On Ubuntu, the ", " debians include the ", " and ", " transports provided by the ", " stack. ", "For complete examples of publishing and subscribing to images using ", ", see the ", ". ", "If you have implemented a new transport option in a public repository and would like to see it added to this list, please email our ", ". ", "ROS Publishers and Subscribers are used to transport messages of any type. ", " offers publishers and subscribers specialized for images. Because they encapsulate complicated communication behavior, ", " publishers and subscribers have a public ROS API as well as a C++ code API. Please see the separate ", " documentation for C++ usage. The ROS API is documented below. ", "C++: ", " (", "), ", " (", ") ", "The raw ", " is published on the base topic, just as with using a normal ", " ", ". If additional plugins are available, they advertise subtopics of the base topic, conventionally of the form ", ". For example, using plugins for ", " and ", " transports, with a base topic of ", ", the topics would be: ", "Publisher plugin parameters give subscribers hooks to configure the publisher-side encoding to suit the needs on the client side. Lookup therefore occurs in the public namespace defined by ", ", rather than the private namespace of the publishing node. Note that these parameters are a shared resource, controlling the behavior observed by all subscribers to the image topic. ", "C++: ", " (", "), ", " (", ") ", "A ", " instance is created with a \"base topic\" name and the name of the transport to use. It subscribes to the transport-specific ROS topic associated with the base topic. For example, if the base topic is ", ", the subscribed topics for transports ", " and ", " are respectively: ", "If this parameter is not set, the transport from the ", " argument of ", " is used. ", "Subscriber plugins are permitted to make use of the ", " for configuration options, e.g. video post-processing level. See the plugin package documentation. ", "Subscriber plugin parameters configure the behavior of one particular subscriber. They affect how the data received is interpreted (decoded). This differs from publisher plugin parameters, which are a shared resource affecting the data sent to all subscribers. The namespace used for parameter lookup is again specified through ", ", defaulting to the private namespace of the subscribing node. "], "package_tt": ["image_transport", "image_transport", "\"raw\"", "ros-<distro>-base", "\"compressed\"", "\"theora\"", "image_transport", "image_transport", "image_transport", "image_transport", "image_transport", "\"raw\"", "\"compressed\"", "\"theora\"", "image_transport", "image_transport", "image_transport", "image_transport::Publisher", "image_transport::CameraPublisher", "image_transport", "ros::Publisher", "<base\u00a0topic>/<transport\u00a0name>", "\"compressed\"", "\"theora\"", "/stereo/left/image", "image_transport", "<base_topic>", "<base\u00a0topic>/<transport\u00a0name>_image_transport_<parameter\u00a0name>", "type", "<base_topic>", "stereo/compressed_image_transport_jpeg_quality", "int", "\"compressed\"", "stereo", "<base\u00a0topic>/<transport\u00a0name>/<parameter\u00a0name>", "type", "/camera/image/compressed/jpeg_quality", "int", "\"compressed\"", "/camera/image", "image_transport", "ros::Subscriber", "image_transport::Subscriber", "image_transport::CameraSubscriber", "Subscriber", "/stereo/left/image", "\"raw\"", "\"compressed\"", "image_transport::TransportHints", "image_transport::ImageTransport::subscribe()", "image_transport::TransportHints", "~image_transport", "~image_transport", "~image_transport", "image_transport::TransportHints", "~<transport\u00a0name>_image_transport_<parameter\u00a0name>", "type", "~foo_image_transport_post_processing_level", "int", "\"foo\"", "~<transport\u00a0name>/<parameter\u00a0name>", "type", "~theora/post_processing_level", "int", "\"theora\"", "\"theora\"", "ros::Subscriber", "image_transport::Publisher", "republish", "list_transports"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ rosrun image_transport republish [in_transport] in:=<in_base_topic> [out_transport] out:=<out_base_topic>", "$ rosrun image_transport republish theora in:=camera/image raw out:=camera/image_decompressed", "$ rosrun image_transport republish raw in:=camera/image out:=camera/image_repub", "$ rosrun image_transport list_transports"]},
{"url": "https://wiki.ros.org/libntcan", "package": "libntcan", "package_summary": ["This package wraps the libntcan to use it as a ros dependency."]},
{"url": "https://wiki.ros.org/jaco_msgs", "package": "jaco_msgs", "package_summary": ["This contains the messages, actions and services for interfacing with the Kinova\n  Jaco arm through ROS."]},
{"url": "https://wiki.ros.org/image_proc", "package": "image_proc", "package_summary": ["Single image rectification and color processing."], "package_tt": ["image_proc", "image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "image_proc", "image_proc", "/my_camera/image_raw", "/my_camera/camera_info", "image_proc", "/my_camera", "image_raw", "camera_info", "/my_camera", "image_proc", "image_raw", "camera_info", "image_raw", "camera_info", "image_mono", "image_rect", "image_color", "image_rect_color", "image_proc", "image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "image_proc", "image_proc", "/my_camera/image_raw", "/my_camera/camera_info", "image_proc", "/my_camera", "image_raw", "camera_info", "/my_camera", "image_proc", "image_raw", "camera_info", "image_raw", "camera_info", "image_mono", "image_rect", "image_color", "image_rect_color", "~queue_size", "int", "image_proc", "image_proc", "debayer", "rectify", "image_raw", "image_mono", "image_color", "~debayer", "int", "Bilinear", "EdgeAware", "EdgeAwareWeighted", "VNG", "image_mono", "camera_info", "image_rect", "~queue_size", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Lanczos4", "camera", "camera_out", "camera/image_raw", "camera/camera_info", "camera_out/image_raw", "camera_out/camera_info", "~queue_size", "int", "~decimation_x", "int", "~decimation_y", "int", "~x_offset", "int", "~y_offset", "int", "~width", "int", "~height", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Area", "Lanczos4", "image", "camera_info", "~image", "~camera_info", "image_proc", "image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "image_proc", "image_proc", "/my_camera/image_raw", "/my_camera/camera_info", "image_proc", "/my_camera", "image_raw", "camera_info", "/my_camera", "image_proc", "image_raw", "camera_info", "image_raw", "camera_info", "image_mono", "image_rect", "image_color", "image_rect_color", "~queue_size", "int", "image_proc", "image_proc", "debayer", "rectify", "image_raw", "image_mono", "image_color", "~debayer", "int", "Bilinear", "EdgeAware", "EdgeAwareWeighted", "VNG", "image_mono", "camera_info", "image_rect", "~queue_size", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Lanczos4", "camera", "camera_out", "camera/image_raw", "camera/camera_info", "camera_out/image_raw", "camera_out/camera_info", "~queue_size", "int", "~decimation_x", "int", "~decimation_y", "int", "~x_offset", "int", "~y_offset", "int", "~width", "int", "~height", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Area", "Lanczos4", "image", "camera_info", "~image", "~camera_info", "image_proc", "image_proc", "rostopic\u00a0list\u00a0|\u00a0grep\u00a0image_raw", "image_proc", "image_proc", "/my_camera/image_raw", "/my_camera/camera_info", "image_proc", "/my_camera", "image_raw", "camera_info", "/my_camera", "image_proc", "image_raw", "camera_info", "image_raw", "camera_info", "image_mono", "image_rect", "image_color", "image_rect_color", "~queue_size", "int", "image_proc", "image_proc", "debayer", "rectify", "image_raw", "image_mono", "image_color", "~debayer", "int", "Bilinear", "EdgeAware", "EdgeAwareWeighted", "VNG", "image_mono", "camera_info", "image_rect", "~queue_size", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Lanczos4", "camera", "camera_out", "camera/image_raw", "camera/camera_info", "camera_out/image_raw", "camera_out/camera_info", "~queue_size", "int", "~decimation_x", "int", "~decimation_y", "int", "~x_offset", "int", "~y_offset", "int", "~width", "int", "~height", "int", "~interpolation", "int", "NN", "Linear", "Cubic", "Area", "Lanczos4", "image", "camera_info", "~image", "~camera_info", "debayer", "rectify", "image_proc", "image_proc", "manager", "string", "/my_manager", "respawn", "bool", "image_proc"], "package_code": ["$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc", "$ rosrun image_view image_view image:=my_camera/image_rect_color", "$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc", "$ rosrun image_view image_view image:=my_camera/image_rect_color", "$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc", "$ rosrun image_view image_view image:=my_camera/image_rect_color", "$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc", "$ rosrun image_view image_view image:=my_camera/image_rect_color"]},
{"url": "https://wiki.ros.org/image_view", "package": "image_view", "package_summary": ["A simple viewer for ROS image topics. Includes a specialized viewer\n  for stereo + disparity images."], "package_tt": ["/camera/image", "frame0000.jpg", "frame0001.jpg", "theora", "~image_transport", "/my_stereo_cam/left/image_rect_color", "/my_stereo_cam/right/image_rect_color", "stereo_view", "left0000.jpg", "right0000.jpg", "left0001.jpg", "right0001.jpg", "image", "~autosize", "bool", "~filename_format", "string", "\"frame%04i.jpg\"", "~image_transport", "string", "\"raw\"", "image_view", "~window_name", "string", "<stereo>/left/<image>", "stereo", "image", "<stereo>/right/<image>", "stereo", "image", "<stereo>/disparity", "~autosize", "bool", "~filename_format", "string", "\"%s%04i.jpg\"", "\"left\"", "\"right\"", "~image_transport", "string", "\"raw\"", "/camera/image", "frame0000.jpg", "frame0001.jpg", "theora", "~image_transport", "/my_stereo_cam/left/image_rect_color", "/my_stereo_cam/right/image_rect_color", "stereo_view", "left0000.jpg", "right0000.jpg", "disp0000.jpg", "left0001.jpg", "right0001.jpg", "disp0001.jpg", "image_view", "image", "~autosize", "bool", "~filename_format", "string", "\"frame%04i.jpg\"", "~image_transport", "string", "\"raw\"", "image_view", "~window_name", "string", "image", "~autosize", "bool", "~window_name", "string", "<stereo>/left/<image>", "stereo", "image", "<stereo>/right/<image>", "stereo", "image", "<stereo>/disparity", "~autosize", "bool", "~filename_format", "string", "\"%s%04i.jpg\"", "\"left\"", "\"right\"", "~image_transport", "string", "\"raw\"", "~approximate_sync", "bool", "~queue_size", "int", "image", "~autosize", "bool", "~filename_format", "string", "\"frame%04i.jpg\"", "~image_transport", "string", "\"raw\"", "image_view", "~window_name", "string", "image", "~autosize", "bool", "~window_name", "string", "rosrun\u00a0image_view\u00a0image_saver\u00a0image:=[your\u00a0topic]", "image", "save", "~filename_format", "string", "left%04d.%s", "~encoding", "string", "~save_all_image", "bool", "image_saver", "image", "~filename_format", "string", "frame%04d.jpg", "~sec_per_frame", "double", "output.avi", "image", "~filename", "string", "output.avi", "~fps", "int", "~codec", "string", "MJPG", "~encoding", "string", "bgr8"], "package_code": ["image_view image:=<image topic> [image transport type]", "image_view image:=/camera/image", "image_view image:=/camera/image theora", "image_view image:=/camera/image _image_transport:=theora", "stereo_view stereo:=<stereo namespace> image:=<image topic identifier>", "stereo_view stereo:=/my_stereo_cam image:=image_rect_color", "rosrun image_view image_view image:=<image topic> [image transport type]", "rosrun image_view image_view image:=/camera/image", "rosrun image_view image_view image:=/camera/image theora", "rosrun image_view image_view image:=/camera/image _image_transport:=theora", "rosrun image_view stereo_view stereo:=<stereo namespace> image:=<image topic identifier>", "rosrun image_view stereo_view stereo:=/my_stereo_cam image:=image_rect_color"]},
{"url": "https://wiki.ros.org/joint_states_settler", "package": "joint_states_settler", "package_summary": ["Provides a node that reports how long a subset of joints has been\n     settled. That is, it calculates how long a set of joints has remained\n     within a specified threshold. This package is experimental and unstable.\n     Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/image_pipeline", "package": "image_pipeline", "package_summary": ["image_pipeline fills the gap between getting raw images from a camera driver and higher-level vision processing."], "package_details": ["\n", "\n", "\n", "\n", "  ", "The ", " stack is designed to process raw camera images into useful inputs to vision algorithms: rectified mono/color images, stereo disparity images, and stereo point clouds. Components include: ", "The image pipeline will work with any conforming ROS camera driver node. See ", " for cameras already supported in ROS. The minimal requirements for such a node are: ", "Camera drivers normally have parameters (exposure, gain, etc.) that you can configure at runtime. ", " has runtime-configurable stereo processing parameters of its own. The ", " is useful for tweaking your configuration to get best results. "], "package_tt": ["image_pipeline", "image_raw", "camera_info", "set_camera_info"]},
{"url": "https://wiki.ros.org/ir_trans_drivers", "package": "ir_trans_drivers", "package_summary": ["irtrans drivers third party code for Maggie robot"], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/libphidgets", "package": "libphidgets", "package_summary": ["This package wraps the libphidgets to use it as a ros dependency"], "package_details": [" The following doc might be significantly outdated. Please consider contributing to update it. ", "\n"], "package_code": ["rosdep install libphidgets\n", "rosmake libphidgets", "roscd libphidgets\n", "sudo ./install_phidgets.sh"]},
{"url": "https://wiki.ros.org/kdl_conversions", "package": "kdl_conversions", "package_summary": ["Conversion functions between KDL and geometry_msgs types."]},
{"url": "https://wiki.ros.org/laser_drivers", "package": "laser_drivers", "package_summary": ["\n  This stack contains drivers for laser rangefinders, including Hokuyo SCIP 2.0-compliant and SICK models.\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " contains a ", " for Leuze rotoScan ROD-4 laser range-finders. "], "package_tt": ["scan"]},
{"url": "https://wiki.ros.org/kdl", "package": "kdl", "package_summary": ["\n\nThis package contains a recent version of the Kinematics and Dynamics\nLibrary (KDL), distributed by the Orocos Project. It is a meta-package that depends on orocos_kdl which contains the c++ version and python_orocos_kdl which contains the generated python bindings \n\n"], "package_details": [" ", " ", "\n", "\n", "\n", "\n", " ", "See the ", " ", "The \"rosmake\" command checks out code from the KDL svn repository (see ", "). ", "KDL is a 3rd party library that is part of the Orocos project  ", ".  "], "package_code": ["  $ rosdep install kdl", "  $ rosmake kdl"]},
{"url": "https://wiki.ros.org/mk", "package": "mk", "package_summary": ["A collection of .mk include files for building ROS architectural elements.\n    Most package authors should use cmake .mk, which calls CMake for the build of the package.\n    The other files in this package are intended for use in exotic situations that mostly arise when importing 3rdparty code."], "package_details": [" ", " when using ", " to find the ", "-package, the ", " needs to be set accordingly. Thus, you should have a dependency to ", " in your ", ", as this provides the respective ", " that set this. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Most packages, and all stacks, use CMake to build. But every package must provide a ", " if it does any building.  The following files are provided to simplify the ", " in most packages, and all stacks: ", "Use these files by including them, as explained in the ", " and ", ". ", "For a 3rdparty package that pulls code from an tarball (or equivalent downloadable file), you should use ", ", like so: ", "The following variables should be defined prior to including ", ": ", "After including ", ", you can make targets depend on the ", " file; it will be created (and updated) after the tarball has been downloaded, unpacked, and (optionally) patched. ", "Some packages that use ", ": ", "For a 3rdparty package that pulls code from an SVN repository, you should use ", ", like so: ", "The following variables should be defined prior to including ", ": ", "After including ", ", you can make your targets depend on the ", " file; it will be created after the working copy is checked out and (optionally) patched. ", "Some packages that use ", ": ", "Similar to ", ", there are also: ", "These are based on ", ", so you can generally use them by substituting the appropriate three-letter abbreviation for ", ". ", "svn checkouts are both slow and more prone to downtime.  A hybrid approach using the tarball for distribution, and a fancy makefile can be done with a script like the ", " package ", "  This uses the svn_checkout script to build the tarball when developing, but most users simply use the tarball.   "], "package_tt": ["rospack", "mk", "ROS_PACKAGE_PATH", "roslib", "package.xml", "Makefile", "Makefile", "cmake.mk", "cmake_stack.mk", "download_unpack_build.mk", "download_unpack_build.mk", "TARBALL", "build/", "TARBALL_URL", "SOURCE_DIR", "build/", "INITIAL_DIR", "SOURCE_DIR", "build/", "UNPACK_CMD", "tar\u00a0xzf", "MD5SUM_FILE", "md5sum", "TARBALL_PATCH", "download_unpack_build.mk", "$(SOURCE_DIR)/unpacked", "download_unpack_build.mk", "svn_checkout.mk", "svn_checkout.mk", "SVN_DIR", "SVN_URL", "SVN_REVISION", "-r", "-r\u00a08262", "SVN_CMDLINE", "svn", "svn\u00a0--non-interactive", "SVN_PATCH", "svn_checkout.mk", "patched", "svn_checkout.mk", "svn_checkout.mk", "git_checkout.mk", "hg_checkout.mk", "bzr_checkout.mk", "svn_checkout.mk", "SVN"], "package_code": ["all: paramiko\n", "\n", "TARBALL = build/paramiko-1.7.5.tar.gz\n", "TARBALL_URL = http://pr.willowgarage.com/downloads/paramiko-1.7.5.tar.gz\n", "SOURCE_DIR = build/paramiko-1.7.5\n", "MD5SUM_FILE = paramiko-1.7.5.tar.gz.md5sum\n", "UNPACK_CMD = tar xzf\n", "include $(shell rospack find mk)/download_unpack_build.mk\n", "\n", "paramiko: $(SOURCE_DIR)/unpacked\n", "        mkdir -p src\n", "        cd $(SOURCE_DIR) && python setup.py build \n", "        rm -rf src\n", "        mv `python find_pylib.py paramiko $(SOURCE_DIR)/build/` src\n", "        touch paramiko\n", "clean:\n", "        -rm -rf src $(SOURCE_DIR) paramiko\n", "wipe: clean\n", "        -rm -rf build", "all: installed\n", "\n", "SVN_DIR = build/stage-svn\n", "SVN_URL = https://playerstage.svn.sourceforge.net/svnroot/playerstage/code/stage/branches/stage-ros\n", "SVN_REVISION = -r 8262\n", "include $(shell rospack find mk)/svn_checkout.mk\n", "\n", "installed: $(SVN_DIR) patched Makefile.stage\n", "        cd $(SVN_DIR) && autoreconf -i -s\n", "        cd $(SVN_DIR) && ./configure --prefix=`pwd`/../..\n", "        cd $(SVN_DIR) && make install\n", "        touch installed\n", "\n", "clean:\n", "        -cd $(SVN_DIR) && make clean\n", "        rm -rf stage installed patched\n", "\n", "wipe: clean\n", "        rm -rf $(SVN_DIR)"]},
{"url": "https://wiki.ros.org/monocam_settler", "package": "monocam_settler", "package_summary": ["Listens on a ImageFeatures topic, and waits for the data to settle.\n     This package is experimental and unstable.\n     Expect its APIs to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/image_common", "package": "image_common", "package_summary": ["Common code for working with images in ROS."], "package_details": ["\n", "\n"]},
{"url": "https://wiki.ros.org/knowrob_common", "package": "knowrob_common", "package_summary": ["\n\n     knowrob_common\n\n  "]},
{"url": "https://wiki.ros.org/knowrob_omics", "package": "knowrob_omics", "package_summary": ["\n\n     knowrob_omics\n\n  "]},
{"url": "https://wiki.ros.org/imu_filter_madgwick", "package": "imu_filter_madgwick", "package_summary": ["Filter which fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into an orientation. Based on code by Sebastian Madgwick, http://www.x-io.co.uk/node/8#open_source_ahrs_and_imu_algorithms."], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "The ", " package is used to filter and fuse raw data from IMU devices. It fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into an orientation quaternion, and publishes the fused data on the ", " topic. The package has been tested using the raw data output of a Phidgets IMU (Spatial 3/3/3) device. The package is a wrapper of Sebastian Madgwick's IMU filter [1]. ", "Two drivers are available: ", " and ", ". Their parameters and topics are identical. ", "[1] ", " ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers.` "], "package_tt": ["imu/data", "imu_filter_node", "imu_filter_nodelet", "imu/data_raw", "imu/mag", "sensor_msgs/MagneticField", "geometry_msgs/Vector3Stamped", "use_magnetic_field_msg", "imu/data", "~gain", "double", "~zeta", "double", "~mag_bias_x", "double", "~mag_bias_y", "double", "~mag_bias_z", "double", "~orientation_stddev", "double", "~world_frame", "string", "\"nwu\"", "\"enu\"", "~use_mag", "bool", "true", "~use_magnetic_field_msg", "bool", "false", "true", "true", "/imu/mag", "sensor_msgs/MagneticField", "false", "geometry_msgs/Vector3Stamped", "~fixed_frame", "string", "odom", "publish_tf", "~publish_tf", "bool", "true", "fixed_frame", "~reverse_tf", "bool", "false", "true", "imu_frame", "fixed\u00a0frame", "~constant_dt", "double", "~publish_debug_topics", "bool", "false", "true", "~stateless", "bool", "false", "true", "~remove_gravity_vector", "bool", "false", "true", "acceleration"]},
{"url": "https://wiki.ros.org/libg2o", "package": "libg2o", "package_summary": ["The libg2o library from http://openslam.org/g2o.html"], "package_details": ["See: ", " "]},
{"url": "https://wiki.ros.org/json_prolog", "package": "json_prolog", "package_summary": ["\n    json_prolog provides an interface to SWI prolog through ROS\n    services. It is implemented in Java by using rosjava and JPL.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package provides methods for querying the ", " ontology via ROS. ", "json_prolog can load the ", " file of a ros package at startup. Just pass the corresponding ros package name as first parameter. ", "Examples on how to use the different client libraries can be found in the ", " subdirectory. ", "For interfacing json_prolog, the python client library provides the class Prolog as an interface for making queries and the class PrologQuery to encapsulate results. ", "Solutions are python dictionaries that map variables to their bindings. Prolog lists are represented as lists. Atoms are represented as strings. More complex terms are represented as dictionaries with the sole mapping from ", " to a list of values. The first value is always an atom, i.e. a python string. The other values can be of any valid result type, i.e. again a dictionary containing a ", ", a string, a list or a number. ", "The main interface class of the C++ client is ", ". It provides the methods: ", "The class ", " provides a very simplistic container like interface to a sequence of bindings. In particular, it provides the methods ", " that returns an iterator to the beginning of the prolog result, ", " that returns a past-end iterator and the method ", " to close the query. ", "Dereferencing a PrologQueryProxy::Iterator returns an instance of type ", ". This class essentially is a std::map<std::string, json_prolog::PrologValue> that maps variables to their actual values. The PrologValue class is a wrapper around boost::any with support for the types ", "To check if a PrologValue contains a specific type, it provides the methods ", "To get the value as a specific type, the casting operator to the desired type and the method as<type>() are implemented. ", "Lists are represented as std::vector<PrologValue>. Terms are represented by the special class PrologTerm which provides the following method: ", "The method ", " returns a pretty printed representation of the contained value. ", "Prolog expressions are either ", ", ", ", ", ", ", " or ", ". All types apart from terms, lists and variables are represented by their native JSON format. Terms, lists and variables are represented as dictionaries with exactly one mapping. For terms, they contain a mapping from ", " to a list with the name of the term as first element and the parameters as the rest of the list. For lists, they contain a mapping from ", " to the (JSON) list of the members. For variables, they contain a mapping from ", " to the name of the variable. Strings should always be enclosed by \\\" to prevent the JSON parser from doing something stupid. The following example shows how a the Prolog query  ", "Please note that for calling the service ", ", the outer map has to be omitted, i.e. only the list corresponding to the outer ", " must be passed to the service. "], "package_tt": ["init.pl", "examples", "term", "term", "query(query_str,\u00a0incremental=False)", "incremental", "solutions()", "finish()", "once(query_str", "json_prolog::Prolog", "query(const\u00a0std::string\u00a0&query_str,\u00a0bool\u00a0incremental=false)", "once(const\u00a0std::string\u00a0&query_str)", "json_prolog::!Prolog", "begin()", "end()", "finish()", "json_prolog::!PrologBindings", "type()", "isValid()", "isDouble()", "isInt()", "isString()", "isTerm()", "isList()", "name()", "arity()", "values()", "operator[]", "toString", "~query", "query", "~simple_query", "query", "~next_solution", "~finish", "term", "list", "variable", "~query", "term"], "package_code": ["rosrun json_prolog json_prolog comp_germandeli", "member(X, [1, 2, 3]), Y = foo(X)", "{\\\"term\\\":[\\\",\\\",{\\\"term\\\":[\\\"MEMBER\\\",{\\\"variable\\\":\\\"X\\\"},{\\\"list\\\":[1,2,3]}]},{\\\"term\\\":[\\\"=\\\",{\\\"variable\\\":\\\"Y\\\"},{\\\"term\\\":[\\\"foo\\\",{\\\"variable\\\":\\\"X\\\"}]}]}]}", "X = 1, Y = 2", "{\\\"X\\\":1, \\\"Y\\\":2}"]},
{"url": "https://wiki.ros.org/mod_vis", "package": "mod_vis", "package_summary": ["\n\n     Visualization module for the Prolog knowledge base.\n\n     Instances in the knowledge base can be pushed to the visualization\n     canvas, are then drawn and can be further inspected.\n\n     Currently supported: Action sequences, linked to the resp. human pose\n     sequence, as well as most objects that are relevant in the IAS kitchen.\n\n  "], "package_details": ["\n", "\n", "\n", "The visualization is written in ", " and Java. ", "You can either call the services directly or, from within Java, use the wrapper function in the ", " class: ", "See here for documentation: ", " "], "package_code": ["comm_vis_set_left_img\n", "comm_vis_set_right_img\n", "comm_vis_set_req_text\n", "comm_vis_set_res_text", " rosrun mod_vis communication_vis", " CommunicationVisApplet.visualizeCommunication(\"Retrieving model...\", \"\", null, \"cop.png\");"]},
{"url": "https://wiki.ros.org/libpcan", "package": "libpcan", "package_summary": ["This package wraps the libpcan to use it as a ros dependency"], "package_details": ["\n", "\n", "You can use this package with a PCAN-USB or a PCAN-PCI adapter from ", ". ", "If you need additional documentation you can read the manual : ", " "], "package_code": ["rosdep install libpcan\n", "rosmake libpcan", "roscd libpcan\n", "sudo ./install_pcan.sh", "sudo modprobe pcan", "ls -l /dev/pcan*"]},
{"url": "https://wiki.ros.org/lizi", "package": "lizi", "package_summary": ["The main Lizi robot package"], "package_details": ["\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "The lizi package is the main package which allows to communicate and control the Lizi robot which is made by ", ". ", "\n", "This command should be executed on the lizi robot computer. For remote operation see the ", " package. ", "The id number sets the robot name to be lizi_<ID>, this is extremely important when working with several Lizi robot as a group of robots. This allows giving each robot in the group a unique name. ", "The id argument can be any desired id number. The id number affect the namespace and the robot description file links and joint names. All the topics, services and parameters will have a lizi_<ID> prefix. ", "The lizi.launch can also be used to load nodes for the front webcam, the Asus RGB-D camera and the Hokuyo laser scanner. "], "package_tt": ["cmd_vel", "gps_pub", "imu_pub", "odom_pub", "Rangers/Left_URF", "Rangers/Rear_URF", "Rangers/Right_URF", "set_odom", "Lizi_ID", "str", "fuse_imu_roll_pitch", "boolean", "fuse_imu_roll_pitch", "boolean", "wheel_diameter", "double", "wheel_base_length", "double", "encoder_cpr", "double", "command", "pan_tilt", "lizi_status", "raw_gps", "lizi_raw", "reset_encoders", "imu_calib", "pid_constants", "float\u00a0array"], "package_code": ["$ roslaunch lizi lizi.launch id:=<ID>", "$ roslaunch lizi lizi.launch id:=1"]},
{"url": "https://wiki.ros.org/ias_knowledge_base", "package": "ias_knowledge_base", "package_summary": ["\n\n    The KnowRob ontology and some other required OWL files (e.g. owl.owl defining the OWL language, and rdf-schema.xml defining the RDFS concepts).\n\n  "], "package_details": [" ", "This package contains the basic ", " ontology, the base for the IAS knowledge processing system. ", "Currently, the documentation can be found in the ", " wiki: ", " "]},
{"url": "https://wiki.ros.org/kinematics_base", "package": "kinematics_base", "package_summary": ["\n    This is a base class for kinematics implementations\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Note this wiki is for the deprecated Arm Navigation version of ", ". For the much newer ", " Kinematics Base, see ", ". ", "You can create your own plugin implementation of kinematics - essentially a wrapper that wraps your custom kinematics solver by inheriting from the base class defined in this package. The typical procedure for this would be to create your own package (named example_kinematics) and have a dependency on both the ", " and ", " packages. ", "Then, have a look at the ", ". You will need to implement all the pure virtual functions after inheriting from the base class. ", "Make sure you add the following lines to the manifest.xml file in ", ".  ", "In a file named ", " in your example_kinematics package, add the following lines and modify them to match the names you have chosen for your components. ", "In the manifest.xml file for example_kinematics, make sure the following lines are present in the ", " tag: "], "package_code": [" <depend package=\"pluginlib\"/>\n", " <depend package=\"kinematics_base\"/>", "<library path=\"lib/libarm_kinematics_constraint_aware_lib\">\n", "  <class name=\"arm_kinematics_constraint_aware/KDLArmKinematicsPlugin\" type=\"arm_kinematics_constraint_aware::KDLArmKinematicsPlugin\" base_class_type=\"kinematics::KinematicsBase\">\n", "    <description>\n", "      A generic implementation of kinematics as a plugin based on KDL.\n", "    </description>\n", "  </class>\n", "</library>", "<library path=\"lib/libexample_kinematics\">", "  <kinematics_base plugin=\"${prefix}/example_plugins.xml\" />", "PLUGINLIB_DECLARE_CLASS(example_kinematics,ExampleKinematicsPlugin, example_kinematics::ExampleKinematicsPlugin, kinematics::KinematicsBase)"]},
{"url": "https://wiki.ros.org/rosR_demos", "package": "rosR_demos", "package_summary": ["\n\n     rosR_demos\n\n  "], "package_details": ["\n", "\n", " ", "\n", " ", "14698/6 ", " "]},
{"url": "https://wiki.ros.org/rosR", "package": "rosR", "package_summary": ["\n\n     rosR\n\n  "], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "20312/10 ", " ", "See also ", ". ", "Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual (", ") and we guess, you already have installed Ubuntu on your PC. ", "The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new ", " is currently 0: "], "package_code": ["$ sudo apt-get install swig3.0", "$ sudo apt-get install r-base", "$ sudo apt-get install r-cran-rcpp", "$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu precise main\" > /etc/apt/sources.list.d/ros-latest.list'", "$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -", "$ sudo apt-get install ros-groovy-desktop", "$ sudo apt-get install r-base      # R base system\n", "$ sudo apt-get install r-cran-rcpp # the R-development package\n", "$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R\n", "$ sudo apt-get install subversion  # svn, to be able to download our package", "# to set all required variables\n", "source /opt/ros/groovy/setup.bash\n", "export ROS_MASTER_URI=http://localhost:11311/\n", "# this is the path where we will install and run our local packages\n", "export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH", "$ source ~/.bashrc", "$ sudo rosdep init\n", "$ rosdep update", "$ mkdir $HOME/ros-projects", "$ cd $HOME/ros-projects", "$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR", "$ cd rosR", "$ rosmake", "$ roslaunch rosR random.launch", "$ roslaunch rosR sensor.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/rosshell", "package": "rosshell", "package_summary": ["\n\t\tTwo simple nodes that can be used as mediators for shell commands.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type ", ". ", "\n", " is just a simple commandline-calculator ", "\n", "\n", "\n", "\n", "5058/2 ", "This package provides the two nodes, that enable to run and interact with different non-ros-programs. ", " can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use ", " to receive and send messages from stdin, stdout, and stderr. ", "both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at ", " ...  "], "package_tt": ["rosshell", "rosshellX", "rosshellX", "bc", "bc", "bc", "rosshellX.launch", "/rosshellX/stdin", "/rosshellX/stdout", "/rosshellX/stderr", "command", "string", "\"\"", "stdout", "string", "stdin", "string", "stderr", "string"], "package_code": ["$ rosrun rosshell rosshell.py \"command\"", "$ rosrun rosshell rosshellX.py \"command\"", "$ rosrun rosshell rosshell.py \"aplay -c 2 -f S16_LE -r 44100 /dev/urandom\"", "$ rosrun rosshell rosshell.py \"cat /dev/random > test.txt\"", "$ rosrun rosshell rosshell.py \"ls -Shal > test.txt\"", "$ rosrun rosshell rosshellX.py \"bc\"", "$ rostopic echo /rosshellX/stdout", "\n", "\n", "\n", "\n", "$ rostopic echo /rosshellX/stderr", "\n", "$ rosrun rosshell rosshellX.py \"ls -Shal\"", "$ rosrun rosshell rosshellX.py _command:=\"ls -Shal\"", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/audio_common_msgs", "package": "audio_common_msgs", "package_summary": ["Messages for transmitting audio via ROS"], "package_details": ["See ", " for usage. "]},
{"url": "https://wiki.ros.org/audio_play", "package": "audio_play", "package_summary": ["Outputs audio to a speaker from a source node."], "package_details": ["See ", " for usage. "]},
{"url": "https://wiki.ros.org/baxter_maintenance_msgs", "package": "baxter_maintenance_msgs", "package_summary": ["Messages and Services required for use with maintenance procedures\n    with the Baxter Research Robot from Rethink Robotics."]},
{"url": "https://wiki.ros.org/baxter_gazebo", "package": "baxter_gazebo", "package_summary": ["Baxter Gazebo plugins and launch files"]},
{"url": "https://wiki.ros.org/asr_object_database", "package": "asr_object_database", "package_summary": ["This package is used to store and provide objects and their information which can be used by other packages like object recognizers"], "package_details": [" ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "There are several services this package offers to access the object models which are stored in the ", " directory located at the base path of it. Inside this directory in ", "there are subdirectories which group the objects together based on their usage (mostly depending on the recognizer which is used to detect them in a scene). Take note that groups and their objects within can only be queried by services if they are declared in config.xml in the ", " directory. This doesn't apply for example to the environment objects, which are only used for visualization purposes by other packages; they can be accessed by specifying the path to them directly without any service call. "], "package_code": ["rosrun asr_object_database asr_object_database"]},
{"url": "https://wiki.ros.org/asctec_hl_firmware", "package": "asctec_hl_firmware", "package_summary": ["\n\n     Firmware code for the Asctec Autopilot HighLevel Processor \n\n  "], "package_details": ["\n", "You need to flash the HLP with a custom firmware (", ") which is provided in this package. Flash the HLP following the instructions in the AscTec ", ".  "], "package_tt": ["main.hex"]},
{"url": "https://wiki.ros.org/asr_ros_uri", "package": "asr_ros_uri", "package_summary": ["The asr_ros_uri package delivers functionality equally to resource_finder.\n    With one exception: It doesn't load the resource into memory but just delivers the uri path to a given file or a file path for a given uri."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "The functionality is similar to that of ", " with the exception that this package does not load the given resource into memory and just delivers the uri path to a given file or the file path for a given uri. ", "See ", " on how to use the provided functions. "]},
{"url": "https://wiki.ros.org/aws_ros1_common", "package": "aws_ros1_common", "package_summary": ["Common utilities for ROS1 nodes using Amazon Web Services"], "package_details": ["\n", "\n", "\n", "This is the common library for all AWS ", " ROS1 packages. ", "The source code is released under an ", ". "]},
{"url": "https://wiki.ros.org/aruco_detect", "package": "aruco_detect", "package_summary": ["Fiducial detection based on the aruco library"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " (", ", default: 7) ", "There are two categories of ROS ", " that can be used to configure the ", " node: general and detection. ", "The ", " used in the library are paramaters of the ", " node.  They can also be set via ", ". "], "package_tt": ["/camera", "/camera_info", "/fiducial_vertices", "/fiducial_transforms", "aruco_detect", "~dictionary", "int", "~fiducial_len", "double", "~fiducial_len_override", "string", "fiducial_len", "\"1-10:\u00a00.05,\u00a012:\u00a00.06\"", "~ignore_fiducials", "string", "\"1-10,\u00a012\"", "~publish_images", "bool", "aruco_detect", "~adaptiveThreshConstant", "int", "~adaptiveThreshWinSizeMax", "int", "~adaptiveThreshWinSizeMin", "int", "~adaptiveThreshWinSizeStep", "int", "~cornerRefinementMaxIterations", "int", "~cornerRefinementWinSize", "int", "~cornerRefinementMinAccuracy", "double", "~doCornerRefinement", "bool", "~errorCorrectionRate", "double", "~minCornerDistanceRate", "double", "~markerBorderBits", "int", "~maxErroneousBitsInBorderRate", "double", "~minDistanceToBorder", "int", "~minMarkerDistanceRate", "double", "~minMarkerPerimeterRate", "double", "~maxMarkerPerimeterRate", "double", "~minOtsuStdDev", "double", "~perspectiveRemoveIgnoredMarginPerCell", "double", "~perspectiveRemovePixelPerCell", "int", "~polygonalApproxAccuracyRate", "double"]},
{"url": "https://wiki.ros.org/baxter_sim_controllers", "package": "baxter_sim_controllers", "package_summary": ["Baxter specific controllers for Gazebo use"]},
{"url": "https://wiki.ros.org/asr_rapidxml", "package": "asr_rapidxml", "package_summary": ["This package contains a Ros wrapper for RapidXML (version 1.13)"], "package_details": [" ", "\n", "\n", "\n", "\n", "This package contains a ROS-Wrapper for the", " (version 1.13). ", "Add this package to the list of dependencies of your project and then you can use the rapidxml library as it is stated in its", ". "]},
{"url": "https://wiki.ros.org/asr_resources_for_vision", "package": "asr_resources_for_vision", "package_summary": ["This package holds bits and pieces that are related to the acquisition of color and depth-image data streams with robot heads. \n    Currently, it contains a hierarchy of launch scripts to start up simultaneous data acquisition from complex setups of vision sensors as encountered on robot heads \n    (e.g. RGB-D in combination with a color camera or a stereo camera setup)."], "package_details": [" ", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "The launch system of the kinect uses ", " and ", " to process the data and the scripts in ", "are used to call those nodes with the correct parameters. ", "Kinect", "camera", " ", "Stereo camera", " ", "For more information on the image processing parameters and the general functionality check out the ", "/ ", " packages. "]},
{"url": "https://wiki.ros.org/angles", "package": "angles", "package_summary": ["This package provides a set of simple math utilities to work\n        with angles. The utilities cover simple things like\n        normalizing an angle and conversion between degrees and\n        radians. But even if you're trying to calculate things like\n        the shortest angular distance between two joint space\n        positions of your robot, but the joint motion is constrained\n        by joint limits, this package is what you need. The code in\n        this package is stable and well tested. There are no plans for\n        major changes in the near future."], "package_details": ["\n", "The best place to find out how to use this package is the ", " "]},
{"url": "https://wiki.ros.org/asr_next_best_view", "package": "asr_next_best_view", "package_summary": ["This package estimates Next-Best-Views as well as configurations (target positions and orientations) for a robot, where it is most likely to find and recognize searched objects the poses of which have, e.g., been predicted by means of ISM trees."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", " ", "This tool uses an iterative generate-and-test algorithm. Each iteration results in a ", ", the algorithm stops if the ", " of two consecutive iteration steps have almost no improvement. The idea of the ", " is that it tells you where it is most probable that objects will be found. ", "The following images describe basic concepts to understand the next_best_view node: ", " ", " ", " ", "In each iteration step, views are generated and then rated. The view with the best rating is chosen as NextBestView for that iteration step. ", "To get a set of viewports from a set of positions and orientations, the cross product between those two sets is used. The resulting set of viewports is filtered by world and hypotheses information (MapHelper and CameraModelFilter class). ", "The following two images show the orientation and position sampling. Each arrow on the sphere shows the endposition of one direction vector which starts in the center of the sphere. The red rectangle limits the space sampling area. All hexagon corners and the center of the rectangle are used to generate viewports. ", " ", " ", "The NextBestViewCalculator class manages all modules. ", "To find a NextBestView, we must first call the SetAttributedPointCloud and SetInitRobotState service calls, then we can use the GetNextBestView service call to get our NextBestView. SetAttributedPointCloud sets and visualizes the pointcloud as shown above in the second and third image, triggerFrustumVisualization is used to display the blue frustum which can be seen above in the first image. ", "To invalidate hypotheses in a frustum, call the UpdatePointCloud service call with the camera pose. ", "Just run ", " to get the next_best_view node running for the simulation or ", "to get it running in a real environment. "]},
{"url": "https://wiki.ros.org/audio_common", "package": "audio_common", "package_summary": ["Common code for working with audio in ROS"], "package_details": ["\n", "Note: This stack is downloadable in debian package format as part of the ", " package. "], "package_tt": ["ros-*-audio-common"]},
{"url": "https://wiki.ros.org/baxter_examples", "package": "baxter_examples", "package_summary": ["Example programs for Baxter SDK usage."]},
{"url": "https://wiki.ros.org/baxter_core_msgs", "package": "baxter_core_msgs", "package_summary": ["Messages and Services required for communication with the Baxter\n    Research Robot from Rethink Robotics."]},
{"url": "https://wiki.ros.org/baxter_description", "package": "baxter_description", "package_summary": ["Description of Baxter Research Robot from Rethink Robotics.\n    This package contains the URDF and meshes describing Baxter."]},
{"url": "https://wiki.ros.org/baxter_tools", "package": "baxter_tools", "package_summary": ["Useful operational and maintenance tools for use with the Baxter Research\n    Robot from Rethink Robotics"]},
{"url": "https://wiki.ros.org/aws_common", "package": "aws_common", "package_summary": ["Common AWS SDK utilities, intended for use by ROS packages using the AWS SDK"], "package_details": ["\n", "\n", "\n", " ", "This is the common library for all AWS ", " packages. ", "The source code is released under ", ". "]},
{"url": "https://wiki.ros.org/asr_sick_lms_400", "package": "asr_sick_lms_400", "package_summary": ["This package is used to access the sick lms400 laser range-finder. It contains all necessary functionality to communicate with the sensor via rosmessages."], "package_details": [" ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", " (string) ", " (string) ", " (int) ", " ", " (int) ", " (int) ", " (int) ", " (int) ", " ", " (double) ", " (int) ", " (bool) ", " (int) ", "A ", " is required to use this package. ", "_/laser_scan_ (", " "], "package_code": ["rosrun asr_sick_lms_400 asr_sick_lms_400"]},
{"url": "https://wiki.ros.org/actionlib_msgs", "package": "actionlib_msgs", "package_summary": ["actionlib_msgs defines the common messages to interact with an\n     action server and an action client.  For full documentation of\n     the actionlib API see\n     the ", "\n     package."]},
{"url": "https://wiki.ros.org/astra_launch", "package": "astra_launch", "package_summary": ["Drivers for Orbbec Astra Devices."]},
{"url": "https://wiki.ros.org/asr_robot_model_services", "package": "asr_robot_model_services", "package_summary": ["This package provides services to perform calculations related to the mild's kinematic model."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", " ", "\n", " ", " ", "\n", " ", "  ", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "- with ", ", ", " as the 2D position of the robot's base, ", " as the robot's rotation on the 2D map and ", ", ", " as the angles of the PTU unit - ", "Considering this simplified version of the kinematic chain, an optimization algorithm provided by the ", " package is used to find an optimal solution for pan and tilt angles, as well as the base rotation. ", "The goal is to find a camera pose (and a corresponding view frustum - red), that faces the center of the target view frustum (black) in the same distance ", " while minimizing the angle deviation ", " as much as possible. ", "Given the position of the target view frustum center ", ", the camera distance to the center ", ", the projected distance between tilt joint and camera center point ", " as well as the tilt joint's constant height above ground ", ", the tilt angle can be determined. ", "Once a solution for the tilt angle has been found, the position of ", "can be calculated directly. ", "A more detailed description of how this problem is being solve can be found here ", ". ", "Starting the ", " for the ", " robot model: ", "Starting the ", " for the ", " robot model: ", "This file specifies the names of key frames in the robot's kinematic chain.", "See", "for an overview over the mild's kinematic chain. ", "The functionality for the pose correction is described here:", " "], "package_code": ["(x, y, z, uw, ux, uy, uz)", "(x, y, alpha, ptu-pan, ptu-tilt)", "(ptu-pan, ptu-tilt)", "launch asr_robot_model_services RobotModelServiceReal.launch", "launch asr_robot_model_services RobotModelServiceSim.launch", "launch asr_robot_model_services set_focus_point.launch"]},
{"url": "https://wiki.ros.org/axis_camera", "package": "axis_camera", "package_summary": ["Python ROS drivers for accessing an Axis camera's MJPG\n    stream. Also provides control for PTZ cameras."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "ROS camera driver for ", ". ", "Parameters are resolved starting with the driver's private namespace. If desired, they may be defined in some containing namespace. That is useful for sharing parameters with the ", " node. ", "The ", " must already be running before any of these example commands. ", "While you can run the driver in the ROS root namespace, the image pipeline prefers running each camera in its own subordinate namespace. These examples use the ", " namespace. With multiple cameras, use something unique to the device, like the camera name. ", "Pass the network host name and password of the camera on the command line, assuming the default username (\"root\"). This example uses the ", " local ", " address, alternatively one could provide the static IP address for which the camera is configured. ", "This publishes two topics: ", " and ", ". ", "To see the raw image, run ", " in another terminal this way: ", "The ", " parameter is necessary, because the camera is actually publishing a motion JPEG stream, via the ROS ", " message. ", "Wide-angle network camera lenses generally exhibit significant intrinsic distortion. For robotics work, it is very helpful to calibrate each camera and use ", " to provide rectified output. ", "Since the driver produces compressed motion JPEG, and ", " expects raw ", " data, an extra step is needed to convert the data stream: ", "To see the rectified color image, run ", " in another terminal this way: ", "The ", " parameter is not needed in this case, because image_proc publishes its output using ", ". ", "Then, in a third terminal, run ", ": ", "Then, follow the instructions in the ", ". ", "The resulting calibration parameters will be stored in ", ", which resolves to ", " in this example (assuming $ROS_HOME points to the default ", " directory). The next time the driver runs on the same machine it should automatically pick up the existing calibration information in that same location. ", "You can store the calibration elsewhere by setting ", " appropriately for the driver. For example, to store it in a package named ", ", append this to the driver's argument list: ", "See ", " for details. "], "package_tt": ["axis_ptz", "roscore", "axis", "/axis/camera_info", "/axis/image_raw/compressed", "_image_transport", "image_proc", "_image_transport", "file://${ROS_HOME}/camera_info/${NAME}.yaml", "~/.ros/camera_info/axis_00408c8ae301_local.yaml", "~/.ros", "~camera_info_url", "my_calibrations"], "package_code": [" $ export ROS_NAMESPACE=axis\n", " $ rosrun axis_camera axis.py _hostname:=axis-00408c8ae301.local _password:=xxxxxxxx", " $ rosrun image_view image_view image:=/axis/image_raw _image_transport:=compressed", " $ export ROS_NAMESPACE=axis\n", " $ rosrun image_transport republish compressed in:=image_raw raw out:=image_raw", " $ ROS_NAMESPACE=axis rosrun image_proc image_proc", " $ rosrun image_view image_view image:=/axis/image_rect_color", " $ export ROS_NAMESPACE=axis\n", " $ rosrun axis_camera axis.py _hostname:=axis-00408c8ae301.local _password:=xxxxxxxx", " $ export ROS_NAMESPACE=axis\n", " $ rosrun image_transport republish compressed in:=image_raw raw out:=image_raw", " $ rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 \\\n", "          image:=/axis/image_raw camera:=/axis", "_camera_info_url:=package://my_calibrations/info/${NAME}.yaml", "http://IP_ADDRESS_OF_YOUR_CAMERA -> Setup -> Basic Setup -> Users", "rosrun axis_camera axis_ptz.py _hostname:=IP_ADDRESS_OF_YOUR_CAMERA"]},
{"url": "https://wiki.ros.org/baxter_interface", "package": "baxter_interface", "package_summary": ["Convenient python interface classes for control\n    of the Baxter Research Robot from Rethink Robotics."], "package_details": ["Since ", " API Doc is ", ". "]},
{"url": "https://wiki.ros.org/baxter_sim_io", "package": "baxter_sim_io", "package_summary": ["The Navigator buttons for the Baxter Research Robot are simulated, and their states are captured and published on the corresponding rostopics"]},
{"url": "https://wiki.ros.org/async_web_server_cpp", "package": "async_web_server_cpp", "package_summary": ["Asynchronous Web/WebSocket Server in C++"]},
{"url": "https://wiki.ros.org/actionlib_tutorials", "package": "actionlib_tutorials", "package_summary": ["The actionlib_tutorials package"], "package_details": ["\n", "actionlib_tutorials is a series of tutorials for using the ", " client API. You can browse these tutorials by installing ", " and ", "-ing to the ", " package, i.e. "], "package_tt": ["roscd", "actionlib_tutorials", "ROS", "~/tutorials/workspace", ".bashrc", ".bashrc", "src", "catkin", "learning_actionlib", "ROS_PACKAGE_PATH", "rosbuild_genmsg()", "learning_actionlib/CMakeLists.txt"], "package_code": ["$ apt-get install ros-$ROS_DISTRO-common-tutorials\n", "$ roscd actionlib_tutorials", "- other: { local-name: workspace }", "rosinstall ~/tutorials /opt/ros/$ROS_DISTRO>> ~/tutorials.rosinstall", "source ~/tutorials/setup.bash", "$ source /opt/ros/$ROS_DISTRO/setup.bash\n", "$ mkdir -p ~/tutorial_ws/src\n", "$ cd ~/tutorial_ws\n", "$ catkin_init_workspace src\n", "$ catkin_make", "$ source devel/setup.bash", "$ cd %YOUR_CATKIN_WORKSPACE%/src\n", "$ catkin_create_pkg actionlib_tutorials actionlib message_generation roscpp rospy std_msgs actionlib_msgs", "$ roscd tutorials\n", "$ roscreate-pkg learning_actionlib actionlib roscpp rospy roslib std_msgs actionlib_msgs", "$ rosmake learning_actionlib"]},
{"url": "https://wiki.ros.org/airbus_ssm_plugin", "package": "airbus_ssm_plugin", "package_summary": ["The airbus_ssm_plugin package"]},
{"url": "https://wiki.ros.org/battery_monitor_rmp", "package": "battery_monitor_rmp", "package_summary": ["Monitor for the Segway Batteries"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package uses the feedback provided by the RMP to monitor the segway batteries and then uses espeak to tell the user if a battery is getting low. It also publishes this information. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["battery_monitor_rmp", "monitor_rmp.py", "rmp_feedback", "battery_status_rmp", "~front_base_batt_1", "~front_base_batt_2", "~rear_base_batt_1", "~rear_base_batt_2", "~aux_batt", "battery_monitor_rmp", "battery_monitor_rmp", "battery_monitor_rmp.launch", "battery_monitor_rmp.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-battery-monitor-rmp", "roslaunch battery_monitor_rmp battery_monitor_rmp.launch "]},
{"url": "https://wiki.ros.org/audio_capture", "package": "audio_capture", "package_summary": ["Transports audio from a source to a destination. Audio sources can come\n      from a microphone or file. The destination can play the audio or save it\n      to an mp3 file."], "package_details": ["See ", " for usage. "]},
{"url": "https://wiki.ros.org/ecl_config", "package": "ecl_config", "package_summary": ["These tools inspect and describe your system with macros, types \n     and functions."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "When autodetection fails (you have a very embedded board, or your toolchain has been patched together in a very non-standard way) there is provision to manually supply details via the ", " macro. Refer to the ", ". ", "Checking for ", ": "], "package_tt": ["ecl/config/ecl.hpp", "ECL", "ECL_IS_POSIX", "ECL_IS_CUSTOM"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "// Platform macros - automatically detected by the build.\n", "- ECL_IS_POSIX || ECL_IS_WIN32 || ECL_IS_APPLE || ECL_IS_CUSTOM\n", "- ECL_HAS_POSIX_THREADS || ECL_HAS_WIN32_THREADS\n", "- ECL_SIZE_OF_CHAR\n", "- ECL_SIZE_OF_SHORT\n", "- ECL_SIZE_OF_INT\n", "- ECL_SIZE_OF_LONG\n", "- ECL_SIZE_OF_LONG_LONG\n", "- ECL_SIZE_OF_FLOAT\n", "- ECL_SIZE_OF_DOUBLE\n", "- ECL_SIZE_OF_LONG_DOUBLE\n", "- ECL_CHAR_IS_SIGNED || ECL_CHAR_IS_UNSIGNED\n", "- ECL_HAS_SHARED_LIBS || ECL_HAS_STATIC_LIBS\n", "// ECL Development macros\n", "- ECL_DISABLE_EXCEPTIONS\n", "- ECL_DONT_INLINE\n", "- ECL_DEPRECATED\n", "- ECL_PUBLIC || ECL_LOCAL", "- ecl::int8,  ecl::uint8\n", "- ecl::int16, ecl::uint16\n", "- ecl::int32, ecl::uint32\n", "- ecl::int64, ecl::uint64\n", "- ecl::float32\n", "- ecl::float64 \n", "- ecl::float96 \n", "- ecl::float128", "// The function operates like a macro, and a good compiler will compile\n", "// out the if mechanism and leave behind the required section of code.\n", "if ( ecl::is_big_endian() {\n", "    // ...\n", "}", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cob_cartesian_controller", "package": "cob_cartesian_controller", "package_summary": ["This package provides nodes that broadcast tf-frames along various (model-based) Cartesian paths (e.g. Linear, Circular).\n    The tf-frames are interpolated using a given velocity profile (e.g. Ramp, Sinoid) and can be used as targets for the cob_frame_tracker/cob_twist_controller."]},
{"url": "https://wiki.ros.org/ecl_containers", "package": "ecl_containers", "package_summary": ["The containers included here are intended to extend the stl containers.\n    In all cases, these implementations are designed to implement\n    c++ conveniences and safety where speed is not sacrificed. \n\n    Also includes techniques for memory debugging of common problems such\n    as buffer overruns."], "package_details": ["\n", "\n", "\n", "See the programs in the ", " and ", " subdirectories. "], "package_tt": ["src/test", "src/examples"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cob_teleop", "package": "cob_teleop", "package_summary": ["Teleop node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This package uses a joystick or keyboard for teleoperation of Care-O-bot. To use this package you need either a real Care-O-bot or a simulated one (see ", "). ", "The ", " package provides both, a configurable node for teleoperation by joystick or by keyboard. ", "\n", "To be able to use the joystick the ", " has to be pressed all the time, as soon as the button is released a stop will be send to all hardware components. Have a look at the following image to see which buttons command which components. ", " ", "For ", ": Hold the ", " button and use the base ", " and ", " axis to move the base. ", "For ", ": Hold the ", " button and the ", " or ", " neck button, then use the ", " or ", " axis to move the torso. ", "For ", ": Hold the ", " button and the ", " button, then use the ", " axis to move the tray. ", "For ", ": Hold the ", " button and one of the ", " buttons, then use the ", " or ", " axis to move the selected arm joints. "], "package_tt": ["cob_teleop", "joy", "/joint_states", "arm_controller/command", "torso_controller/command", "tray_controller/command", "base_controller/command", "~run_factor", "float", "~lower_neck_button", "int", "~upper_neck_button", "int", "~tray_button", "int", "~arm_joint12_button", "int", "~arm_joint34_button", "int", "~arm_joint56_button", "int", "~arm_joint7_button", "int", "~deadman_button", "int", "~run_button", "int", "~axis_vx", "int", "~axis_vy", "int", "~axis_vth", "int", "~lower_tilt_step", "float", "~lower_pan_step", "float", "~upper_tilt_step", "float", "~upper_pan_step", "float", "~tray_step", "float", "~arm_left_right_step", "float", "~arm_up_down_step", "float", "~max_vx", "float", "~max_vy", "float", "~max_vth", "float", "~max_ax", "float", "~max_ay", "float", "~max_ath", "float", "deadman_button", "deadman", "rotation", "translation", "deadman", "upper", "lower", "up_down", "left_right", "deadman", "tray", "up_down", "deadman", "arm", "up_down", "left_right"], "package_code": ["roslaunch cob_bringup teleop.launch", "<include file=\"$(find cob_bringup)/tools/teleop.launch\" />", "roslaunch cob_teleop teleop_keyboard.launch", "# common params\n", "run_factor: 2.0\n", "\n", "# buttons\n", "lower_neck_button: 6\n", "upper_neck_button: 4\n", "tray_button: 3\n", "arm_joint12_button: 0\n", "arm_joint34_button: 1\n", "arm_joint56_button: 2\n", "arm_joint7_button: 3\n", "deadman_button: 5\n", "run_button: 7\n", "\n", "# axes\n", "axis_vx: 1\n", "axis_vy: 0\n", "axis_vth: 2\n", "up_down: 5 #tray--up/down; tilt--front/back, here we just name up_down\n", "left_right: 4 #pan--left/right\n", "\n", "# velocities in rad/sec, m/sec\n", "lower_tilt_step: 0.05\n", "lower_pan_step: 0.05\n", "upper_tilt_step: 0.075\n", "upper_pan_step: 0.075\n", "tray_step: 0.15\n", "arm_left_right_step: 0.1\n", "arm_up_down_step: 0.1\n", "max_vx: 0.3\n", "max_ax: 0.5\n", "max_vy: 0.2\n", "max_ay: 0.5\n", "max_vth: 0.3\n", "max_ath: 0.7"]},
{"url": "https://wiki.ros.org/class_loader", "package": "class_loader", "package_summary": ["The class_loader package is a ROS-independent package for loading plugins during runtime and the foundation of the higher level ROS \"pluginlib\" library. class_loader utilizes the host operating system's runtime loader to open runtime libraries (e.g. .so/.dll files), introspect the library for exported plugin classes, and allows users to instantiate objects of said exported classes without the explicit declaration (i.e. header file) for those classes."], "package_details": [" ", "\n", " is a ROS-independent package that allows one to dynamically load exported C++ classes during runtime from a runtime library (i.e. .so/.dll file) and create objects of those classes. What makes a class loaded through ", " different from just linking against a runtime library and using classes from it is that your code does not require the definition of the class (i.e. the header file for the class) in your client code. Classes loaded in this fashion are also often called ", ".  ", "\n", " is used in the implementation of the higher-level ROS package ", " which is the encouraged method for loading plugins in the ROS  ", "ecosystem. ", " ", "\n", " is simple to use and requires linking against a single library (", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " as of version 1.9 and class_loader HIGHLY discourage linking applications directly against libraries containing plugins. Often times users will place plugins into libraries along side code intended to directly be linked. Other times they want to be able to use classes as plugins as well as directly use them without a ", ". This was fine in previous versions of pluginlib, but as version 1.9, pluginlib sits on top of class_loader for plugin loading which cannot handle this.  ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "  ", "It is important to note that the ", " can only inspect classes and create objects of those classes if those classes are registered to be exportable.  For any classes you want to export, make sure to have a declaration of the following macro for each class within your source (.cpp) files: ", "where ", " refers to the name of the class to be exported and ", " refers to the name of the class from which it is derived. Though you do not need the definition of the Derived class in the code that will load the class, you still need to have a definition to its base class so as to be able to use the plugin. Notice in the code examples that when introspecting the library via ", " or creating a plugin via ", " that both methods require a template type argument indicating the base class. If the correct base class is not given, the class will not be seen or instantiable by the ", ". It is ok to have classes with different base classes registered or even register the same class multiple times with different bases in the same library and transitively the same ", ". Just note the base class argument must be provided at compile time via a template argument for methods where it matters. ", "Once you have built all your source files using the macro, you can package the object files into a runtime library and then load that library via the ", ". ", "All methods to ", " and ", " are thread safe. The use of templates allows for all types to be statically verified and it is impossible to load an invalid plugin with an incompatible interface. This is a powerful concept in guaranteeing the integrity of plugins at both compile and runtime which is of course very important in robotics. ", "When one uses the ", " to create and destroy plugins, it results in the opening and closing of the runtime libraries containing those plugins. When a runtime library is loaded by an operating system, symbols in the host executable that are stubs to the runtime library are resolved. When the library is unloaded, the symbols at those corresponding memory addresses are unavailable as the code has been removed from executable's address space and [possibly] unloaded from memory. If one attempts to use symbols that are unresolved, it leads to a runtime link error. This means if I create an object from a class defined within a runtime library, I then unload the library, and then I try to use the object...things will go bad.  ", "In the example code above, the library is loaded and unloaded by ", " automatically, though ", " provides methods for explicitly loading and unloading the underlying library (", " and ", " respectively). The ", " is smart in that it will automatically load a library when created and unload it when the ", " goes out of scope. One may wonder why the load and unload methods are then exposed. In order to understand that, we must first understand the ", "'s on-demand (lazy) load/unload mode. ", "The ", " constructor provides an optional boolean flag (", ") to indicate if the ", " is to perform on-demand (lazy) loading of a library as needed and automatically closing it after the last plugin in created by it is destroyed. By default, this flag is set to false. When set to false, the ", " loads the library at construction time and unloads it at destruction time. In on-demand mode, the library is only opened when the first plugin is created via ", " and unloaded when the only remaining plugin created by the ", " is destroyed. This mode is helpful when we want to minimize the number of libraries loaded in memory. ", "It is often useful, particularly in on-demand mode, to control when the library is loaded and unloaded. One can force this by calling ", ". When one calls ", " and ", ", the library is forcefully loaded into memory and cannot be unloaded automatically by the system until ", " is called. This allows multiple threads sharing the same ", " to force a shared library, even if it's open in on-demand mode, to stay in memory until it's done. This is not a thread safety issue, but rather one for performance to prevent a library from continuously being loaded/unloaded if a thread is going to need it heavily for some period of time and wants to guarantee the library stays in memory. ", "A ", " allows one to create objects in the form of ", " values so as to provide automatic cleanup of objects. Another one of the important reasons this is implemented is so that the user cannot unload the library prematurely. The user is free to create unmanaged objects via the alternate ", " method, but this will prevent the ", " from stopping the user on unloading the library when there are still objects in memory. This is because the ", " cannot be aware of the state of unmanaged instances. ", "Many ", " methods will raise an exception of base class type ", " if an error occurs. The subclasses of ", " are defined in ", " and indicate the various problems. These include: ", "The ", " is designed to be bound only to a single runtime library. Often it is convenient to have multiple libraries open and be able to load/unload classes from them through a uniform interface. That is why the class ", " is provided. This class provides as an almost identical interface to ", " but allows one to bind several libraries to a single loader object. Internally, the ", " is just a manager for a collection of ", " objects. ", "The issue is that the way class_loader implements plugin introspection is by having plugin ", "  automatically register themselves when the library is opened. This is not how pluginlib prior to version 1.9 operated. However, the problem is is that when you directly link an executable against a library with plugins, when that program starts up, all the plugin factories will be created outside the scope of a ", ". See ", " for more details. ", "For those interested in understanding the internals of ", ", go to the ", " page. "], "package_tt": ["class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader/class_loader.h", "class_loader::ClassLoader", "CLASS_LOADER_REGISTER_CLASS(Derived,\u00a0Base)", "getAvailableClasses()", "createInstance()", "class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "loadLibrary()", "unloadLibrary()", "ondemand_loadunload", "createInstance()", "loadLibrary", "loadLibary", "unloadLibrary", "unloadLibrary", "class_loader::ClassLoader", "boost::shared_ptr", "class_loader::ClassLoader::createUnmanagedInstance", "class_loader::ClassLoader::createInstance()", "class_loader::ClassLoaderException", "class_loader::ClassLoaderException", "class_loader/class_loader_exceptions.h", "class_loader::LibraryLoadException", "class_loader::LibraryUnloadException", "class_loader::CreateClassException", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "class_loader::ClassLoader"], "package_code": ["   class_loader::ClassLoader loader(\"libMyLibrary.so\");", "   std::vector<std::string> classes = loader.getAvailableClasses<MyBase>()", " for(unsigned int c = 0; c < classes.size(); ++c)\n", " {\n", "   boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);\n", "   plugin->someMethod();\n", "   //'plugin' will automatically be deleted when it goes out of scope\n", " }", "#include <class_loader/class_loader.h>\n", "#include \"MyBase.h\" //Defines class MyBase\n", "\n", "int main()\n", "{\n", "  class_loader::ClassLoader loader(\"libMyLibrary.so\");\n", "  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();\n", "  for(unsigned int c = 0; c < classes.size(); ++c)\n", "  {\n", "    boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);\n", "    plugin->someMethod();\n", "  }\n", "}", "#include <class_loader/multi_library_class_loader.h>\n", "#include \"MyBase.h\" //Defines class MyBase\n", "\n", "int main()\n", "{\n", "  class_loader::MultiLibraryClassLoader loader;\n", "  loader.loadLibrary(\"libSomeLib.so\");\n", "  loader.loadLibrary(\"libAnotherLib.so\");\n", "  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();\n", "  for(unsigned int c = 0; c < classes.size(); ++c)\n", "  {\n", "    boost::shared_ptr plugin<MyBase> = loader.createInstance<MyBase>(classes[c]);\n", "    plugin->someMethod();\n", "  }\n", "}"]},
{"url": "https://wiki.ros.org/control_box_rst", "package": "control_box_rst", "package_summary": ["The control_box_rst package provides C++ libraries for predictive control, \n               direct optimal control, optimization and simulation."]},
{"url": "https://wiki.ros.org/depth_image_proc", "package": "depth_image_proc", "package_summary": ["Contains nodelets for processing depth images such as those\n     produced by OpenNI camera. Functions include creating disparity\n     images and point clouds, as well as registering (reprojecting)\n     a depth image into another camera frame."], "package_details": [" ", " has found a new home in ", ". In Electric it resided in ", ". ", "\n", " provides basic processing for depth images, much as ", " does for traditional 2D images. The two packages are complementary; for example, you can (and should!) rectify your depth image before converting it to a point cloud. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "See ", " for details on depth image representation. The REP recommends that, wherever possible, producers and consumers of depth data use depth images (of type ", ") instead of ", ". ", "All nodelets (besides ", ") in this package support both standard floating point depth images and OpenNI-specific ", " depth images. Thus when working with OpenNI cameras (e.g. the Kinect), you can save a few CPU cycles by using the ", " raw topics instead of the ", " topics. ", "For an example of ", " in practice, examine the contents of ", ". "], "package_tt": ["depth_image_proc", "depth_image_proc", "convert_metric", "uint16", "uint16", "float", "depth_image_proc", "uint16", "float", "image_raw", "uint16", "image", "float", "left/image_rect", "right/camera_info", "left/disparity", "min_range", "double", "max_range", "double", "delta_d", "double", "queue_size", "int", "camera_info", "image_rect", "points", "PointCloud<PointXYZ>", "queue_size", "int", "rgb/camera_info", "rgb/image_rect_color", "depth_registered/image_rect", "depth_registered/points", "PointCloud<PointXYZRGB>", "queue_size", "int", "rgb/camera_info", "depth/camera_info", "depth/image_rect", "depth_registered/camera_info", "rgb/camera_info", "depth_registered/image_rect", "depth_registered/image_rect", "queue_size", "int", "/depth_optical_frame", "/rgb_optical_frame", "/depth_optical_frame", "/rgb_optical_frame"]},
{"url": "https://wiki.ros.org/comp_spatial", "package": "comp_spatial", "package_summary": ["\n\n     Routines for spatial reasoning in Prolog.\n\n     Contains Prolog computables for calculating qualitative spatial relations,\n     but also those for extracting certain elements from the string representation\n     of a matrix.\n\n  "], "package_details": ["This package is part of the ", " knowledge processing system. "]},
{"url": "https://wiki.ros.org/cassandra_ros", "package": "cassandra_ros", "package_summary": ["\n\n     Library and tools for dynamically storing ROS messages in Apache Cassandra.\n\n  "], "package_details": ["\n", "\n", " ", " partitioner is required to retrieve requested data ordered, otherwise it will appear. For more information, have look on the documentation on ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "5515/1 ", "Then change the Cassandra partitioner to \"", "\", which can be set in  ", "partitioner: org.apache.cassandra.dht.", " ", "The option -f hinders Cassandra to start a deamon in backgroud, for more information and help visit : ", " ", "Check the following link: ", " ", "How does it work? If you take a look into cassandra_ros/lib ... you will see a couple of files in the form of ", "_'format'.py, which are all descendants of ", "_.py. And each of them overwrites the methods: ", "As you could see so far, you only work with the single class of ", ". In fact, this class inherits those methods, required for encoding and decoding of messages, and only those of the required parent class. If you are seeking for more information, have a look at the follwing link:  ", " ", "If you want to analyze your data by using CQL, the ", ", you will have to generate at first secondary indexes. Because this might be expensive and not required for every part of a message, this has to be done manually, as follows: ", "For more information on CQL, check the following website: ", " "], "package_code": ["$ bin/cassandra -f", "$ roslaunch cassandra_ros recordCamera.launch", "$ roslaunch cassandra_ros replayCamera.launch", "$ roslaunch cassandra_ros deleteCamera.launch", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cob_command_gui", "package": "cob_command_gui", "package_summary": ["This package provides a simple GUI for operating Care-O-bot."], "package_details": [" ", "\n", "\n", "\n", "To use this package you don't need any hardware, but it is intended to be used with either a real Care-O-bot or a simulated one (see ", " or ", "). ", "The ", " package provides a configurable node for operating different hardware parts of Care-O-bot. The command_gui uses the functionalities of the ", " package. ", "\n", "The parameters of the command_gui are  defined in ", " and ", " and loaded in the parameter server.  "], "package_tt": ["knoeppkes.py"], "package_code": ["rosdep install cob_command_gui\n", "rosmake cob_command_gui", "export ROBOT=cob3-3\n", "export ROBOT_ENV=ipa-kitchen\n", "roslaunch cob_bringup dashboard.launch"]},
{"url": "https://wiki.ros.org/camera_info_manager_py", "package": "camera_info_manager_py", "package_summary": ["Python interface for camera calibration information.\n\n    This ROS package provides a CameraInfo interface for Python camera\n    drivers similar to the C++ camera_info_manager package."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", ": a driver can now handle more than one camera, using a different ", " with the CameraInfoManager class instance of each device.  ", "\n", "\n", "It provides a Python module for camera drivers to manage the ", " required by the ", ". ", "The API includes a camera name, which is written when ", " is saved and checked when data are loaded, with a warning logged if the name read does not match. ", "Camera driver authors should refer to the ", " for syntax details and recommendations for assigning camera names.  ", "The location for getting and saving calibration data is expressed by Uniform Resource Locator (URL). These URLs are commonly used in the APIs of this package and may also contain substitution variables to refer to common locations. Please see the ", " for supported URLs, file formats and substitution variables, which include ", " and the camera name, ", ". ", "This package does not read ROS parameters directly. Where appropriate, we recommend that drivers provide a ", " parameter for the URL string passed to CameraInfoManager. ", "Open a link from ", " in the top-right corner of this web page. "], "package_tt": ["CameraInfo", "${ROS_HOME}", "${NAME}", "set_camera_info", "~camera_info_url", "Code\u00a0API"]},
{"url": "https://wiki.ros.org/diffdrive_gazebo_plugin", "package": "diffdrive_gazebo_plugin", "package_summary": ["This package provides Gazebo plugins for differential drive robots. It is based on turtlebot_gazebo_plugins by Nate Koenig."], "package_details": ["\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "For installation instructions, see ", ". "]},
{"url": "https://wiki.ros.org/concert_scheduler_requests", "package": "concert_scheduler_requests", "package_summary": ["Python interfaces for managing ROCON scheduler requests."], "package_details": ["This package was renamed from ", ". The older version is now ", ". "]},
{"url": "https://wiki.ros.org/bwi_msgs", "package": "bwi_msgs", "package_summary": ["Contails messages used in the utexas-bwi codebase."], "package_details": ["\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"bwi_msgs\" in rosdoc: /home/rosbot/docs/api/bwi_msgs/manifest.yaml ", "This package collects ROS messages, services and actions that are specific to the Building-Wide Intelligence project of the University of Texas at Austin.  It simplifies the dependencies between various ", " repository components.  "]},
{"url": "https://wiki.ros.org/dbw_mkz_twist_controller", "package": "dbw_mkz_twist_controller", "package_summary": [" The package dbw_mkz_twist_controller has been deprecated with migration to dataspeed_ulc_can. The drive-by-wire firmware now includes a much better twist control implementation.", "Twist (speed and angular rate) controller for brake/throttle/steering"]},
{"url": "https://wiki.ros.org/cob_gazebo_ros_control", "package": "cob_gazebo_ros_control", "package_summary": ["This package contains a specialization of the gazebo_ros_control plugin.\n    The cob_gazebo_ros_control plugin allows Multi-HardwareInterface-Support."]},
{"url": "https://wiki.ros.org/diagnostic_msgs", "package": "diagnostic_msgs", "package_summary": ["This package holds the diagnostic messages which provide the\n    standardized interface for the diagnostic and runtime monitoring\n    systems in ROS. These messages are currently used by\n    the ", "\n    Stack, which provides libraries for simple ways to set and access\n    the messages, as well as automated ways to process the diagnostic\n    data.\n\n    These messages are used for long term logging and will not be\n    changed unless there is a very important reason."], "package_details": ["\n", "\n", "The ", " package in the ", " stack assists in sending diagnostics ", "There are several ways to view diagnostics in the ", " package in the ", " stack.  "]},
{"url": "https://wiki.ros.org/bwi_tools", "package": "bwi_tools", "package_summary": ["Contains commonly used Python and C++ structures and tools in the BWI\n    project codebase"]},
{"url": "https://wiki.ros.org/depthimage_to_laserscan", "package": "depthimage_to_laserscan", "package_summary": ["depthimage_to_laserscan"], "package_details": ["\n", "\n", " ", "\n", " ", "\n", " projected on top of the ", ". ", " ", "\n", " ", "\n", "\n", "\n", " ", "Note the ", " overlayed in color on the ", ".  Red is close to camera, purple is far from camera. ", "Top down view of the ", ". "], "package_tt": ["depthimage_to_laserscan", "image", "camera_info", "scan", "image", "/camera/depth/image_raw", "image_rect", "camera_info", "image", "scan", "~scan_height", "int", "~scan_time", "double", "~range_min", "double", "~range_max", "double", "~output_frame_id", "str", "depthimage_to_laserscan/DepthImageToLaserScanNodelet"]},
{"url": "https://wiki.ros.org/dynamixel_msgs", "package": "dynamixel_msgs", "package_summary": ["Common messages used throughout dynamixel_motor stack."]},
{"url": "https://wiki.ros.org/cob_footprint_observer", "package": "cob_footprint_observer", "package_summary": ["The cob_footprint_observer package adjusts the footprint of the robot based on the setup (e.g. arm and/or tray)."], "package_details": [" The ", " only works with rectangular footprints. ", "\n", "\n", "\n", "The ", " observes the setup of the Care-O-Bot (including arm and tray) and inflates the footprint to contain the arm and the tray. ", "It allows for reading the adjusted footprint using either the ", " service or the published ", " topic. ", "To use this package you need either need a real or a simulated Care-O-Bot (see ", " and ", " respectively). ", "The ", " package provides a configurable node for checking and adjusting the footprint based on the current setup. ", "\n"], "package_tt": ["cob_footprint_observer", "GetFootprint", "adjusted_footprint", "cob_footprint_observer", "cob_footprint_observer", "tf::TransformListener", "adjusted_footprint", "/get_footprint", "~footprint_source", "string", "~frames_to_check", "string", "~robot_base_frame", "string", "collision_velocity_filter"], "package_code": ["roslaunch cob_bringup base_collision_observer.launch", "<!-- start footprint observer node -->\n", "<node pkg=\"cob_footprint_observer\" type=\"footprint_observer\" name=\"footprint_observer\" output=\"screen\">\n", "  <!-- load parameter file -->\n", "  <rosparam file=\"$(find cob_hardware_config)/$(env ROBOT)/config/footprint_observer_params.yaml\" command=\"load\" />\n", "</node>", "# node from which initial footprint is read\n", "footprint_source: /local_costmap_node/costmap\n", "\n", "# \n", "robot_base_frame: /base_link\n", "# frames to check for footprint adjustment\n", "frames_to_check: /sdh_tip_link /arm_6_link /arm_4_link"]},
{"url": "https://wiki.ros.org/cob_dashboard", "package": "cob_dashboard", "package_summary": ["cob_dashboard is a modified version of [[pr2_dashboard]]."]},
{"url": "https://wiki.ros.org/concert_service_teleop", "package": "concert_service_teleop", "package_summary": ["Teleop by request from a rocon interactive program."]},
{"url": "https://wiki.ros.org/bond", "package": "bond", "package_summary": ["A bond allows two processes, A and B, to know when the other has\n    terminated, either cleanly or by crashing.  The bond remains\n    connected until it is either broken explicitly or until a\n    heartbeat times out."]},
{"url": "https://wiki.ros.org/concert_service_admin", "package": "concert_service_admin", "package_summary": ["A general purpose admin service (mostly configures rocon interactions)."]},
{"url": "https://wiki.ros.org/bondcpp", "package": "bondcpp", "package_summary": ["C++ implementation of bond, a mechanism for checking when\n    another process has terminated."], "package_details": ["\n", "\n", " ", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "bondcpp is an implementation of ", " in C++.  To use bondcpp, please see the example below as well as the ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/calibration_launch", "package": "calibration_launch", "package_summary": ["This package contains a collection of launch files that can be helpful in configuring\n    the calibration stack to run on your robot."]},
{"url": "https://wiki.ros.org/concert_msgs", "package": "concert_msgs", "package_summary": ["Shared communication types for the concert framework."]},
{"url": "https://wiki.ros.org/cob_camera_sensors", "package": "cob_camera_sensors", "package_summary": ["For more information read the readme.htm file located in"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " package is a collection of ROS compatible drivers for the cameras installed on Care-O-bot 3. These include two color cameras (either of type ", " or ", ") and one ", " time-of-flight sensor from Mesa Imaging or the ", " sensor. All camera types are supported for Windows and Linux. To enable Windows compatibility, remove all ", " flags from ", " located at ", ". The two Prosilica GC1380CH are natively supported by ROS with the ", " package. The binaries of the ", " package are executed within the related launch files. The same holds for the Kinect whose driver is located in the ", " package. ", "Setting the camera parameters for the ", " and ", " is different from the suggested ROS standard. Instead of setting all parameters within the ROS launch file, camera specific parameters are set within IPA specific configuration files. This originates from IPA internal requirements to maintain backward compatibility to existing components. The ROS launch file only holds parameters related to the camera setup (e.g. specifying the used camera types) and a link to the IPA internal configuration file. ", "In order to launch the camera nodes, do the following (Replace ", " with your personal Care-O-bot identifier) ", "For quitting do not close the viewer window, but hit ", " on your console ", "For quitting do not close the viewer window, but hit ", " on your console ", "The IPA configuration file is located at ", " in a folder related to your sensor setup e.g. ", " or ", ". The configuration is XML-based. It holds one XML-tag for each camera e.g. ", " for a AVT Pike C145 camera. The number within the tag-name is used to differentiate several camera of the same type. Here is an excerpt from the IPA configuration file of one of our Care-O-bots. ", "Camera intrinsics may be set for each camera within the designated tags. The information is later published with the images using the ROS ", " from the ", " package. The user has the possibility of specifying different intrinsic for one camera. This is related to stereo vision, where intrinsics are optimize to fit to another camera. Within the ROS node that publishes camera images, the non-optimized intrinsic are published with the images. Extrinsic specify the rotation and translation relative to another camera. These parameters are not yet published and for IPA internal usage only. ", "For each camera there is also a related ", " tag. This is also related to backward compatibility issues and not used within ROS. Originally, it provided support for loading saved image data from disk and using it as if it came from a real camera device. However, ROS already provides more sophisticated means to record and play back data using ", " and ", ". ", "ROS launch files are located in ", " and hold information about the overall sensor setup not related to a specific camera. There is a launch file to start each camera independently (", ") and a launch file to start all Care-O-bot cameras at once (", "). Before you can start these launch files, you have to specify your robot id via ", " for example. Each launch file specifies the location of the related IPA configuration file and the used color camera or time-of-flight camera type. The robot specific launch and configuration files are located in the ", " folders. The following camera types are supported: ", "The Prosilica GC1380CH color camera is supported through the ROS ", " package. To get more information, have a look at their tutorial. The camera specific launch files have an additional parameter specifying the camera's ID which is related to the number within the tag-name in the IPA configuration file e.g. ", ". ", "A detailed guide for configuring and starting the stereo pair of ", " cameras can be found in the ", ". ", "A detailed guide for configuring and starting the stereo pair of ", " cameras can be found in the ", ". ", "Instructions for the usage of the Swissranger 3000 or 4000 sensor mounted on the Care-O-Bot can be found at ", ". ", "Instructions for the usage of the Microsoft Kinect sensor mounted on the Care-O-Bot can be found at ", ". "], "package_tt": ["-D__LINUX__", "cob3-2", "CTRL-C", "CTRL-C", "/stereo/left/image_color", "/stereo/left/camera_info", "/stereo/right/image_color", "/stereo/right/camera_info", "/cam3d/depth/camera_info", "/cam3d/depth/image", "/cam3d/depth/points", "/cam3d/rgb/camera_info", "/cam3d/rgb/image_color", "/cam3d/rgb/image_mono", "/cam3d/rgb/points", "~ip_address", "str", "~trigger_mode", "str", "<AVTPikeCam_0>", "<VirtualXXXCam_X>", "cob_driver/cob_camera_sensors/ros/launch", "cam3d.launch,\u00a0left.launch,\u00a0right.launch", "all_cameras.launch", "export\u00a0ROBOT=cob3-1", "cob_driver/cob_camera_sensors/ros/launch/$ROBOT"], "package_code": ["export ROBOT=cob3-2\n", "roslaunch cob_camera_sensors all_cameras.launch", "roslaunch cob_camera_sensors left.launch\n", "roslaunch cob_camera_sensors right.launch", "roslaunch cob_camera_sensors cam3d.launch", "rosrun image_view image_view image:=/stereo/left/image_color", "rosrun image_view image_view image:=/stereo/right/image_color", "roslaunch cob_camera_sensors tof_camera_viewer.launch", "<!-- Camera sensors initialization file -->\n", "<LibCameraSensors>\n", "\n", "<AVTPikeCam_0>\n", "  <!-- Holds the 64-Bit GUID of a connected node -->\n", "  <!-- A GUID consists of a 32-Bit high part that holds the VendorId (Highest 24 Bits) -->\n", "  <!-- and the ChipIdHigh (8 Bits) and a 32-Bit low part that holds the ChipIdLow. -->\n", "  <!-- The GUID is unique for all FireWire devices on the world. -->\n", "  <GUID high=\"000A4701\" low=\"10077005\" />\n", "\n", "  <!-- The master initializes and releases the camera library and is -->\n", "  <!-- respnsible for emitting the trigger signal to other cameras -->\n", "  <!-- The slave is synchronizing its image acquisition with the trigger signal -->\n", "  <!-- Valid roles: MASTER oR SLAVE -->\n", "  <Role value=\"MASTER\" />\n", "\n", "  <!-- Valid values: appropriate framerte or AUTO and DEFAULT -->\n", "  <FrameRate fps=\"3\" />\n", "\n", "    <!-- Valid values: FORMAT_0, FORMAT_1, FORMAT_2 ,FORMAT_7, DEFAULT-->\n", "  <VideoFormat type=\"FORMAT_7\" />\n", "\n", "  <!-- Valid values: MODE_0 - MODE_7, DEFAULT -->\n", "  <VideoMode type=\"MODE_0\" />\n", "  ...\n", "<AVTPikeCam_0/>\n", "<LibCameraSensors/>"]},
{"url": "https://wiki.ros.org/dynamixel_driver", "package": "dynamixel_driver", "package_summary": ["This package provides low level IO for Robotis Dynamixel servos.\n    Fully supports and was tested with AX-12, AX-18, RX-24, RX-28,\n    MX-28, RX-64, EX-106 models. Hardware specific constants are\n    defined for reading and writing information from/to Dynamixel\n    servos. This low level package won't be used directly by most\n    ROS users. The higher level dynamixel_controllers and specific\n    robot joint controllers make use of this package."]},
{"url": "https://wiki.ros.org/concert_service_msgs", "package": "concert_service_msgs", "package_summary": ["Messages used by official rocon services."]},
{"url": "https://wiki.ros.org/control", "package": "control", "package_summary": ["control"], "package_details": [" ", "\n", "\n", "  "]},
{"url": "https://wiki.ros.org/brics_actuator", "package": "brics_actuator", "package_summary": ["Message defined in the BRICS project"]},
{"url": "https://wiki.ros.org/collada_parser", "package": "collada_parser", "package_summary": ["This package contains a C++ parser for the Collada robot\n    description format. The parser reads a Collada XML robot\n    description, and creates a C++ URDF model. Although it is possible\n    to directly use this parser when working with Collada robot\n    descriptions, the preferred user API is found in the urdf package."], "package_details": [" ", "\n", "The code API for this package is for internal use only.  Please use the ", " package instead. "]},
{"url": "https://wiki.ros.org/dwb_local_planner", "package": "dwb_local_planner", "package_summary": ["Plugin based local planner implementing the nav_core2::LocalPlanner interface."], "package_details": [" "]},
{"url": "https://wiki.ros.org/console_bridge", "package": "console_bridge", "package_summary": ["Lightweight tool for forwarding output from libraries to other logging systems."], "package_details": [" console_bridge ", " Mirza Shah (", "), Ioan Sucan (", ") ", " Ioan Sucan (", ") ", " ", " ", "\n", " is a ROS-independent, pure CMake (i.e. non-catkin and non-rosbuild package) that provides logging calls that mirror those found in ", ", but for applications that are not necessarily using ROS.  ", " ", "\n", "\n", "Normally in ROS C++ code, developers can log data via ", " using the macros ROS_DEBUG, ROS_INFO, ROS_WARN, and ROS_ERROR. These logging messages are not only outputted to the screen (depending on log level of course), but are also published to ", " so that other ROS nodes can subscribe to them. Applications like ", " and its predecessor ", " provide graphical interfaces for seeing logs during application runtime. ", "Once you use ", ", the implementations of ", " will simply become equivalent to ", " respectively. "], "package_tt": ["/rosout", "logDebug,\u00a0logInform,\u00a0logWarn,\u00a0and\u00a0logError", "ROS_DEBUG,\u00a0ROS_INFO,\u00a0ROS_WARN,\u00a0and\u00a0ROS_ERROR"], "package_code": ["logDebug  -- ROS_DEBUG\n", "logInform -- ROS_INFO\n", "logWarn   -- ROS_WARN\n", "logError  -- ROS_ERROR", "$ git clone git://github.com/ros/console_bridge.git\n", "$ cd console_bridge\n", "$ cmake .\n", "$ make\n", "$ sudo make install"]},
{"url": "https://wiki.ros.org/cob_twist_controller", "package": "cob_twist_controller", "package_summary": ["The main purpose of the cob_twist_controller is to convert target twists into joint velocities. \n  Therefore it makes use of several implemented inverse kinematics approaches at the first order differential level. \n  The inverse differential kinematics solver considers kinematic chain extensions, singularity robustness, \n  redundancy resolution and priority-based methods.\n  To avoid hardware destruction there is a limiter interface active as well. \n  Via parameter server users can dynamically configure the solving strategy."]},
{"url": "https://wiki.ros.org/control_msgs", "package": "control_msgs", "package_summary": ["control_msgs contains base messages and actions useful for\n    controlling robots.  It provides representations for controller\n    setpoints and joint and cartesian trajectories."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/cob_control_mode_adapter", "package": "cob_control_mode_adapter", "package_summary": ["The cob_control_mode_adapter package provides a node that automatically loads respective ros_controllers depending on required control mode."]},
{"url": "https://wiki.ros.org/common_tutorials", "package": "common_tutorials", "package_summary": ["Metapackage that contains common tutorials"], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/bwi_services", "package": "bwi_services", "package_summary": ["High-level services for the UTexas Building-Wide Intelligence project."]},
{"url": "https://wiki.ros.org/compressed_image_transport", "package": "compressed_image_transport", "package_summary": ["Compressed_image_transport provides a plugin to image_transport for transparently sending images\n    encoded as JPEG or PNG."], "package_details": ["\n", " is a plugin package for ", ". It enables any node using ", " classes to publish and subscribe to compressed image topics. Compression format (JPEG or PNG) and quality can be changed on the fly. ", " ", "\n", "\n", "\n", "\n", "\n", "See ", " for general instruction on using ", ". ", " is featured in the ", " tutorial ", ". ", "Some cameras (particularly webcams) output their image data already in JPEG format. When writing a driver for such a camera, a quick and dirty approach is to simply copy the JPEG data into a ", " message and publish it on a topic of the form ", ". Then any ROS node using ", " can subscribe to ", " with transport ", ", just as if ", " were used on the publisher side. Of course, the other transport topics (including ", " itself) will not be available. "], "package_tt": ["compressed_image_transport", "image_transport", "image_transport", "compressed_image_transport", "image_transport", "<base_topic>/compressed", "<base_topic>", "/image", "/compressed_image_transport_jpeg_quality", "/image/compressed_image_transport_jpeg_quality", "<base_topic>/compressed_image_transport_format", "string", "<base_topic>/compressed_image_transport_jpeg_quality", "int", "<base_topic>/compressed_image_transport_png_level", "int", "<base_topic>/compressed/format", "string", "<base_topic>/compressed/jpeg_quality", "int", "<base_topic>/compressed/png_level", "int", "<base_topic>/compressed", "image_raw/compressed", "image_raw", "compressed", "image_transport", "image_raw"]},
{"url": "https://wiki.ros.org/driver_base", "package": "driver_base", "package_summary": ["A framework for writing drivers that helps with runtime reconfiguration, diagnostics and self-test.\n\n    This package is deprecated."], "package_details": ["\n", "This package is for internal use only. Its API is stable, but ", " recommended for use by new packages. "]},
{"url": "https://wiki.ros.org/collada_urdf", "package": "collada_urdf", "package_summary": ["This package contains a tool to convert Unified Robot Description Format (URDF) documents into COLLAborative Design Activity (COLLADA) documents.\n\n    Implements robot-specific COLLADA extensions as defined by\n    http://openrave.programmingvision.com/index.php/Started:COLLADA"], "package_details": ["\n", "\n", "\n", "The urdf_to_collada tool will convert ", " files into COLLADA ", " files. "], "package_tt": [".urdf", ".dae"], "package_code": ["rosrun collada_urdf urdf_to_collada <input-urdf> <output.dae>", "rosrun collada_urdf urdf_to_collada pr2.urdf pr2.dae", "rosrun collada_urdf collada_to_urdf <input.dae> <output.urdf>"]},
{"url": "https://wiki.ros.org/clearpath_base", "package": "clearpath_base", "package_summary": ["\n     The base drivers needed to connect with the onboard system for all Clearpath Robotics platforms.\n  "], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"clearpath_base\" in rosdoc: /home/rosbot/docs/api/clearpath_base/manifest.yaml "]},
{"url": "https://wiki.ros.org/cob_light", "package": "cob_light", "package_summary": ["This package contains scripts to operate the LED lights on Care-O-bot."], "package_details": ["\n", "\n", "\n", "The ", " package provides a node that connects to the light hardware board and offers a message interface over ", ". The current state of the light is published as a ", ". ", "\n"], "package_tt": ["cob_light.py", "command", "marker", "~devicestring", "string", "~baudrate", "int"], "package_code": ["roslaunch cob_bringup light.launch", "<include file=\"$(find cob_bringup)/components/light.launch\" />", "devicestring: /dev/ttyUSB3\n", "baudrate: 230400", "rosrun cob_light test.py"]},
{"url": "https://wiki.ros.org/dnn_detect", "package": "dnn_detect", "package_summary": ["DNN based detection"], "package_details": ["\n", "\n", "\n", "\n", "A camera node, such as ", " needs to be running ", "Then ", " can be launched: "], "package_tt": ["/camera", "/dnn_objects", "/dnn_images", "~detect", "~single_shot", "bool", "detect", "~publish_images", "bool", "~data_dir", "string", "~protonet_file", "string", "data_dir", "~caffe_model_file", "string", "data_dir", "~min_confidence", "float", "~im_size", "int", "~scale_factor", "float", "~mean_val", "float", "~class_names", "string", "dnn_detect"], "package_code": ["sudo apt install ros-kinetic-dnn-detect", "rosrun usb_cam usb_cam_node", "roslaunch dnn_detect dnn_detect.launch camera:=/usb_cam image:=image_raw", "rostopic echo /dnn_objects"]},
{"url": "https://wiki.ros.org/capabilities", "package": "capabilities", "package_summary": ["Package which implements capabilities, including code to parse capability interface specs, to parse capability provider specs, and implement the capability server."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "There are tutorials located here: ", " ", "The provided (Python) API can be used to discover local packages which define one or more of the spec files defined by this package, load them, and interact with them. It also provides an API to discover what capabilities are provided by a ", " running on a remote machine, which is useful for tools like the ", " plugin. ", "This package provides the ", " ROS node which loads all capability spec files from packages on the ", " and provides a ROS interface for querying and running those capabilities. ", "The ", " is documented in the CodeAPI (linked to on the right). "], "package_tt": ["capability_server", "capability_server", "ROS_PACKAGE_PATH", "capability_server"]},
{"url": "https://wiki.ros.org/dynamicvoronoi", "package": "dynamicvoronoi", "package_summary": ["\n\n", "\nThis package provides software to compute and update Euclidean distance maps (DM) and Euclidean Voronoi diagrams (GVD) on 2D grid maps.\n", "\nThe program is initialized with a binary occupancy grid map and computes the corresponding DM and GVD. When provided with points that mark newly occupied or freed cells, the DM and GVD can be updated efficiently to reflect the changes in the environment.\n", "\nDetails on the algorithms can be found in the corresponding paper. Please cite the paper if you use it for scientific work:", "\nB. Lau, C. Sprunk and W. Burgard, Improved Updating of Euclidean Distance Maps and Voronoi Diagrams, IEEE Intl. Conf. on Intelligent Robots and Systems (IROS), Taipei, Taiwan, 2010.", "\nSee also ", "\n"]},
{"url": "https://wiki.ros.org/bwi_interruptable_action_server", "package": "bwi_interruptable_action_server", "package_summary": ["This wraps the move_base node from the standard ROS navigation\n    stack. The purpose of the interruptable navigator is to allow\n    seamless multi-robot interactions by temporarily interrupting\n    robots and diverting them when two robots are about to collide."]},
{"url": "https://wiki.ros.org/concert_service_gazebo", "package": "concert_service_gazebo", "package_summary": ["Sets up the gazebo robot manager as a service to assist in spawning/killing robots as concert clients."], "package_details": ["\n", "\n", "\n", "\n", "An example is available in the ", " package. "], "package_tt": ["RobotManager", "/services/<service-name>/", "/use_sim_time", "true"]},
{"url": "https://wiki.ros.org/cob_relayboard", "package": "cob_relayboard", "package_summary": ["cob_relayboard"], "package_details": [" "]},
{"url": "https://wiki.ros.org/csm", "package": "csm", "package_summary": ["This is a ROS 3rd-party wrapper ", " of Andrea Censi's CSM package. \n\n    From ", ":\n    "], "package_details": ["\n", "\n", " ", "Please submit your tickets through ", " (requires github account) or by emailing the maintainers. "]},
{"url": "https://wiki.ros.org/costmap_prohibition_layer", "package": "costmap_prohibition_layer", "package_summary": ["ROS-Package that implements a costmap layer to add prohibited areas to the costmap-2D by a user configuration."], "package_details": ["\n", " If used in combination with a local costmap, make sure that the global-frame parameter of the local costmap coincides with global costmap's parameter. ", "Furthermore, the global-frame should be fixed (e.g. /map and not /odom), since currently no coordinate transformations are performed internally. ", "\n", "\n", "\n", "The costmap2D from ros is able to add plugins (see ", "). ", "In step two you see how to add the YAML file to the parameters. If you're doing this in the launch file of the move base, you should load them into the namespace ", ". The underlayed namespace (", " should accord with the plugin name, defined in the next step: ", "In step three it is described how to add the plugin itself. ", "For this plugin you have to add: "], "package_code": ["prohibition_areas:\n", " # your first prohibited area is only a point\n", " - [17.09, -6.388]\n", " # now we define a line\n", " # it will become the thickness of the costmap resolution\n", " - [[8.33, 2.11],\n", "    [8.26, 5.11]]\n", " # and last but not least a polygon with an individual number of points\n", " - [[-11.15, -15.614],\n", "    [-12.35, -13.89],\n", "    [-10.05, -12.218]]", "   plugins:\n", "     # ... your own plugins     \n", "     - {name: costmap_prohibition_layer,       type: costmap_prohibition_layer_namespace::CostmapProhibitionLayer\"}"]},
{"url": "https://wiki.ros.org/cob_phidgets", "package": "cob_phidgets", "package_summary": ["cob_phidgets"], "package_details": ["\n", "\n", "Make sure your user is in the group \"dialout\" with ", ". "], "package_tt": ["groups"], "package_code": ["sudo echo 'SUBSYSTEM==\"usb\", ATTRS{idVendor}==\"06c2\", MODE=\"0666\", GROUP=\"dialout\"' >>  /etc/udev/rules.d/10-persistent-usb.rules && sudo chmod a+r /etc/udev/rules.d/10-persistent-usb.rules && sudo udevadm control --reload-rules "]},
{"url": "https://wiki.ros.org/compressed_depth_image_transport", "package": "compressed_depth_image_transport", "package_summary": ["Compressed_depth_image_transport provides a plugin to image_transport for transparently sending\n    depth images (raw, floating-point) using PNG compression."], "package_details": ["\n", " is a plugin package for ", ". It enables any node using ", " classes to publish and subscribe to compressed depth image/map topics. Compression parameters can be changed on the fly using the dynamic_reconfigure package. ", " works only with floating-point or 16-bit integer encoded depth images. ", " ", "\n", "\n", "\n", "\n", "See ", " for general instruction on using ", ". ", " works similar to ", " which is featured in the ", " tutorial ", ". "], "package_tt": ["compressed_depth_image_transport", "image_transport", "compressed_depth_image_transport", "image_transport", "compressed_depth_image_transport", "compressed_image_transport", "image_transport", "<base_topic>/compressedDepth", "<base_topic>/compressed/format", "string", "<base_topic>/compressed/jpeg_quality", "int", "<base_topic>/compressed/png_level", "int", "<base_topic>/compressedDepth"]},
{"url": "https://wiki.ros.org/diagnostic_common_diagnostics", "package": "diagnostic_common_diagnostics", "package_summary": ["diagnostic_common_diagnostics"], "package_details": ["\n", "\n"], "package_tt": ["diagnostics", "rosrun\u00a0diagnostic_common_diagnostics\u00a0ntp_monitor.py\u00a0-h", "diagnostics", "sensors", "diagnostics", "~ignore_fans", "bool", "tf", "diagnostics"]},
{"url": "https://wiki.ros.org/concert_service_indoor_2d_map_prep", "package": "concert_service_indoor_2d_map_prep", "package_summary": ["Services to initilise indoor 2d map environment. Make a map and annotation"]},
{"url": "https://wiki.ros.org/calibration", "package": "calibration", "package_summary": ["Provides a toolchain running through the robot calibration process. This\n     involves capturing calibration data, estimating parameters, and\n     then updating the URDF."], "package_details": ["\n", "\n", "\n", "Documentation is coming for setting up your own robot. See ", " or ", " package for an example ", "Please report bugs at: ", " "], "package_code": ["- hg:\n", "    local-name: calibration\n", "    uri: 'http://kforge.ros.org/calibration/calibration'\n", "- hg:\n", "    local-name: pr2_calibration\n", "    uri: 'http://kforge.ros.org/calibration/pr2_calibration'\n", "- svn:\n", "    local-name: pr2_common\n", "    uri: 'https://code.ros.org/svn/wg-ros-pkg/stacks/pr2_common/trunk'\n", "- other:\n", "    local-name: /opt/ros/electric/ros\n", "- other:\n", "    local-name: /opt/ros/electric/stacks", "rosinstall PATH new_calibration.rosinstall\n", "rosmake pr2_calibration"]},
{"url": "https://wiki.ros.org/concert_master", "package": "concert_master", "package_summary": ["The ros master at the heard of the concert subsystem along with a few utility functions."]},
{"url": "https://wiki.ros.org/camera1394", "package": "camera1394", "package_summary": ["ROS driver for devices supporting the IEEE 1394 Digital Camera\n    (IIDC) protocol. Supports the ROS image_pipeline, using libdc1394\n    for device access."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", "This package provides a ROS interface for digital cameras meeting the ", " using ", ", which supports ", ". Of the thousands of IIDC models, we are accumulating a ", " with this driver. ", "It works with the ROS ", " like other streaming ", ". ", "For help, please check ", ". If your question is not answered, open a new one with the ", " tag, so we can see it and respond. ", "To report problems or request new features: ", " ", "The ", " driver was first released with ROS C-Turtle. That API is stable. ", "Additional features have been added since. They are all compatible with the previous release, except for the default ", " value. ", "By default, ", " requires the message timestamps for both images to match exactly, which the ", " driver cannot do. The Diamondback release of ", " provided a solution for this problem (enhancement ", "). ", "The ", " had some significant limitations. Some have been removed in later releases. Please check the specific documentation for that release, if you are still using ROS C-Turtle. ", "For each supported feature there is a corresponding ", " parameter providing user control. Different cameras handle these controls in various ways. ", "When setting an IIDC feature to a specific value, it is necessary to set the corresponding control state to ", " (3), otherwise the corresponding value will be ignored unless the device is already in the ", " state when the driver starts. ", "For example, to set ", " to 256 on the command line: ", "Many IIDC cameras use ", " to provide color information. For cameras of this type, set ", " to an appropriate ", " value, and select the correct ", ". If the ", " is ", ", all ", " images are monochrome. ", "Best performance is likely to come from using the default ", " method while running ", " and ", " nodelets both in a single process (see the ", " example below). ", "In both cases the ", " image stream is compatible with the ROS ", ". ", "Format7 parameters specify image size, position and pixel format. Some Format7 modes may provide binning, combining groups of hardware pixels into a single image pixel. The Format7 Region of Interest (ROI) selects a rectangular subset from the full hardware image. These options sometimes allow the camera to send images at a faster rate. (The ", " parameter has no effect in Format7.) ", "With an available ", " selected, a number of Format7-specific parameters ", " be supported, depending on the device: ", "All these parameters are ignored when ", " is not one of the Format7 options. ", "This driver publishes the same topics and provides the same parameters as the ", " version. ", "Run a standalone ", ", this behaves almost the same as running ", ".  ", " For that, see the following example. ", "To run the driver nodelet and ", " all in a single address space with zero-copy message passing between those nodelets, use a ", " like this: ", "Depending on specific needs, some of the ", " nodelets could be omitted. But, they do not incur much overhead when not being used. "], "package_tt": ["camera1394", "reset_on_open", "reset_on_open", "False", "video_mode", "frame_rate", "camera1394", "camera1394", "stereo_image_proc", "auto_", "brightness", "video_mode", "mono8", "bayer_pattern", "bayer_pattern", "\"\"", "mono8", "bayer_method", "\"\"", "bayer_method", "bayer_decoding", "image_proc/debayer", "camera1394/driver", "camera/image_raw", "image_pipeline", "~frame_rate", "video_mode", "~binning_x", "~binning_y", "~roi_width", "~roi_height", "~x_offset", "~y_offset", "~format7_color_coding", "raw8", "~bayer_method", "~bayer_pattern", "video_mode", "camera/image_raw", "camera/camera_info", "camera/image_raw", "video_mode", "diagnostics", "camera/set_camera_info", "~guid", "str", "~reset_on_open", "bool", "~video_mode", "str", "~frame_id", "str", "~frame_rate", "double", "~iso_speed", "int", "~camera_info_url", "str", "~binning_x", "int", "~binning_y", "int", "~roi_width", "int", "~roi_height", "int", "~x_offset", "int", "~y_offset", "int", "~format7_packet_size", "int", "~format7_color_coding", "str", "~bayer_pattern", "str", "~bayer_method", "str", "~auto_brightness", "int", "~brightness", "double", "~auto_exposure", "int", "~exposure", "double", "~auto_focus", "int", "~focus", "double", "~auto_gain", "int", "~gain", "double", "~auto_gamma", "int", "~gamma", "double", "~auto_hue", "int", "~hue", "double", "~auto_iris", "int", "~iris", "double", "~auto_saturation", "int", "~saturation", "double", "~auto_sharpness", "int", "~sharpness", "double", "~auto_shutter", "int", "~shutter", "double", "~auto_white_balance", "int", "~white_balance_BU", "double", "~white_balance_RV", "double", "~auto_zoom", "int", "~zoom", "double", "~num_dma_buffers", "int", "~max_consecutive_errors", "int", "camera1394_nodelet", "camera1394_node", "image_proc"], "package_code": ["$ rosrun camera1394 camera1394_node _auto_brightness:=3 _brightness:=256.0", "$ rosrun nodelet nodelet standalone camera1394/driver", "<launch>\n", "\n", "  <!-- nodelet manager process -->\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"camera_nodelet_manager\"\n", "        args=\"manager\" />\n", "\n", "  <!-- camera driver nodelet -->\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"camera1394_nodelet\"\n", "        args=\"load camera1394/driver camera_nodelet_manager\" />\n", "    \n", "  <!-- Bayer color decoding -->\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"image_proc_debayer\"\n", "        args=\"load image_proc/debayer camera_nodelet_manager\">\n", "    <remap from=\"image_color\" to=\"camera/image_color\" />\n", "    <remap from=\"image_mono\" to=\"camera/image_mono\" />\n", "    <remap from=\"image_raw\" to=\"camera/image_raw\" />\n", "  </node>\n", "\n", "  <!-- mono rectification -->\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"image_proc_rect\"\n", "        args=\"load image_proc/rectify camera_nodelet_manager\">\n", "    <remap from=\"image_mono\" to=\"camera/image_mono\" />\n", "    <remap from=\"image_rect\" to=\"camera/image_rect\" />\n", "  </node>\n", "\n", "  <!-- color rectification -->\n", "  <node pkg=\"nodelet\" type=\"nodelet\" name=\"image_proc_rect_color\"\n", "        args=\"load image_proc/rectify camera_nodelet_manager\">\n", "    <remap from=\"image_mono\" to=\"camera/image_color\" />\n", "    <remap from=\"image_rect\" to=\"camera/image_rect_color\" />\n", "  </node>\n", "\n", "</launch>"]},
{"url": "https://wiki.ros.org/bond_core", "package": "bond_core", "package_summary": ["A bond allows two processes, A and B, to know when the other has\n    terminated, either cleanly or by crashing. The bond remains\n    connected until it is either broken explicitly or until a\n    heartbeat times out."], "package_details": ["\n", ": the bond packages are now part of bond_core.  In previous releases, they were part of ", ". ", "\n", "  ", "Groovy and above, please use the infrastructure at: ", " "]},
{"url": "https://wiki.ros.org/calibration_estimation", "package": "calibration_estimation", "package_summary": ["Runs an optimization to estimate the a robot's kinematic parameters. This package is a\n    generic rewrite of pr2_calibration_estimation."]},
{"url": "https://wiki.ros.org/bwi_mapper", "package": "bwi_mapper", "package_summary": ["Mapping package that provides utilties for handling ROS \n    style maps. Also provides functions for generating topological graphs from \n    pixel maps."]},
{"url": "https://wiki.ros.org/catkin_virtualenv", "package": "catkin_virtualenv", "package_summary": ["Bundle python requirements in a catkin package via virtualenv."], "package_details": ["See ", " for package documentation. "]},
{"url": "https://wiki.ros.org/bwi_logging", "package": "bwi_logging", "package_summary": ["Logging package that creates ROS bag files"]},
{"url": "https://wiki.ros.org/catkin", "package": "catkin", "package_summary": ["Low-level build system macros and infrastructure for ROS."], "package_details": ["\n", "\n", " ", "Catkin is included by default when ROS is installed. Catkin can also be installed from source or prebuilt packages. Most users will want to use the prebuilt packages, but installing it from source is also quite simple. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "For an explanation of the design goals and design decisions, in addition to the rationale for why Catkin (\"", "\") was created, see the ", " page. ", "If you are using a ROS binary distribution (Groovy or higher) on Ubuntu then you can install catkin with ", ": ", "If you are ", " on Ubuntu you can install ", " from ", " via pip. ", "See ", " ", "See the external ", " containing: ", "See ", " "], "package_tt": ["apt-get", "catkin_pkg", "cmake\u00a0-DCMAKE_BUILD_TYPE=Release\u00a0../", "RelWithDebInfo", "Debug", "Release"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-catkin", "sudo apt-get install cmake python-catkin-pkg python-empy python-nose python-setuptools libgtest-dev build-essential", "mkdir build && cd build && cmake ../ && make && sudo make install"]},
{"url": "https://wiki.ros.org/cob_script_server", "package": "cob_script_server", "package_summary": ["The cob_script_server package provides a simple interface to operate Care-O-bot. It can be used via the python API or the actionlib interface."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "This package was created to be used with Care-O-bot but is not limited to one specific robot. It can be used for a real robot as well as for a simulated one (see ", "). ", "This package provides all methods as a python API (see ", "). The table below shows a summary of the most important commands and their parameters. ", "Each of the above function (except ", ", which returns the keyboard input) returns a handle which offers the following commands.  ", "you can access all script_server commands in an ipython terminal with the prefix ", ", e.g. ", "All functions from the python API are also available as ", " calls. ", "All the parameters that are loaded in the name space /script_server are defined in .yaml files in the package ", ". ", "Tutorials can be found on the ", ". "], "package_tt": ["init()", "sss.init(\"base\")", "recover", "sss.recover(\"base\")", "stop", "sss.stop(\"base\")", "move", "sss.move(\"torso\",\"front\")", "move", "sss.move(\"torso\",", "\u00a0\u00a0[[0,\u00a00,\u00a00,\u00a00],", "\u00a0\u00a0[0.1,\u00a00,\u00a00.2,\u00a00],", "\u00a0\u00a0[...],\u00a0...])", "move", "sss.move(\"base\",\"home\")", "move", "sss.move(\"base\",[0,\u00a00,\u00a00])", "move_base_rel", "sss.move_base_rel(\"base\",[0,\u00a00,\u00a01.57])", "sleep", "sss.sleep(2.0)", "wait_for_input", "ret\u00a0=\u00a0sss.wait_for_input()", "say", "sss.say(\"sentence1\")", "say", "sss.say([\"Hello.\"])", "set_light", "sss.set_light(\"red\")", "set_light", "sss.set_light([0.5,0.5,0.5])", "wait_for_input", "wait()", "handle.wait()", "wait(timeout)", "handle.wait(2.0)", "timeout", "get_state()", "handle.get_state()", "sss", "script_server/goal", "script_server/result", "script_server/feedback"], "package_code": ["rosrun cob_script_server cob_console", "sss.move(\"head\",\"front\")", "roslaunch cob_script_server script_server.launch", "rosrun cob_script_server test_script.py", "rosrun cob_script_server script_viewer.py"]},
{"url": "https://wiki.ros.org/code_coverage", "package": "code_coverage", "package_summary": ["CMake configuration to run coverage"]},
{"url": "https://wiki.ros.org/cob_description", "package": "cob_description", "package_summary": ["This package contains the description (mechanical, kinematic, visual,\n  etc.) of the Care-O-bot robot. The files in this package are parsed and used by\n  a variety of other components. Most users will not interact directly\n  with this package."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "In the package ", " you can find for each robot the urdf file that load the component descriptions together. "], "package_code": [" sed -i '0,/RE/s/solid/robot/' */*.stl"]},
{"url": "https://wiki.ros.org/common_rosdeps", "package": "common_rosdeps", "package_summary": ["common_rosdeps declares commonly used rosdep system dependencies."]},
{"url": "https://wiki.ros.org/distance_field", "package": "distance_field", "package_summary": ["\n\nThis package contains algorithms that can compute the\nEuclidean Distance Transform (EDT) of a 3-D voxel grid. The input to these algorithms is\nan array of points (which could represent the positions of obstacles in the world). \nThe EDT provides a voxel grid in which in which each cell contains the distance to the\nclosest obstacle. The VoxelGrid class can also be used as a generic, templatized container for a discretized 3-D voxel grid.\n\n  "], "package_details": ["\n", "Further details are available in the ", ". "]},
{"url": "https://wiki.ros.org/camera_calibration", "package": "camera_calibration", "package_summary": ["camera_calibration allows easy calibration of monocular or stereo\n     cameras using a checkerboard calibration target."], "package_details": ["\n", " will work with any camera driver node satisfying the standard ROS camera interface. See the ", ". ", "\n", "\n", "\n", " supports the following options: ", "\n", " ", "\n", " ", "\n", "\n", " ", "\n", " ", "This package uses OpenCV camera calibration, described ", ".  For detailed information on the parameters produced by the calibration, see ", ". ", "There are tutorials on how to run the calibration tool for ", " and ", " cameras. ", "To run the ", " node for a monocular camera using an 8x6 chessboard with 108mm squares: ", "To run the ", " node for a stereo camera: ", "By default, the ", " assumes that stereo cameras are triggered to capture images simultaneously, and that matching image pairs have identical timestamps. This is the ideal situation, but requires hardware support. ", "To enable approximate timestamp matching, give the ", " option. This permits a \"slop\" of 0.01s between image pairs. If you still don't see a display window, or it is sporadically updated, try increasing the slop. ", "To use multiple checkerboards, give multiple ", " and ", " options for additional boards. Make sure the boards have different dimensions, so the calibration system can tell them apart. "], "package_tt": ["camera_calibration", "cameracalibrator.py", "cameracalibrator.py", "cameracalibrator.py", "image_pipeline", "--approximate=0.01", "--size", "--square", "cameracalibrator.py", "image", "left", "right", "camera/set_camera_info", "left_camera/set_camera_info", "right_camera/set_camera_info", "cameracheck.py", "monocular/image", "monocular/camera_info", "stereo/left/image", "stereo/right/image", "stereo/camera_info"], "package_code": ["rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/my_camera/image camera:=/my_camera", "rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 right:=/my_stereo/right/image_raw left:=/my_stereo/left/image_raw left_camera:=/my_stereo/left right_camera:=/my_stereo/right", "  Chessboard Options:\n", "    You must specify one or more chessboards as pairs of --size and\n", "    --square options.\n", "\n", "    -p PATTERN, --pattern=PATTERN\n", "                        calibration pattern to detect - 'chessboard',\n", "                        'circles', 'acircles'\n", "    -s SIZE, --size=SIZE\n", "                        chessboard size as NxM, counting interior corners\n", "                        (e.g. a standard chessboard is 7x7)\n", "    -q SQUARE, --square=SQUARE\n", "                        chessboard square size in meters\n", "\n", "  ROS Communication Options:\n", "    --approximate=APPROXIMATE\n", "                        allow specified slop (in seconds) when pairing images\n", "                        from unsynchronized stereo cameras\n", "    --no-service-check  disable check for set_camera_info services at startup\n", "\n", "  Calibration Optimizer Options:\n", "    --fix-principal-point\n", "                        fix the principal point at the image center\n", "    --fix-aspect-ratio  enforce focal lengths (fx, fy) are equal\n", "    --zero-tangent-dist\n", "                        set tangential distortion coefficients (p1, p2) to\n", "                        zero\n", "    -k NUM_COEFFS, --k-coefficients=NUM_COEFFS\n", "                        number of radial distortion coefficients to use (up to\n", "                        6, default 2)", "rosrun camera_calibration cameracheck.py --size 8x6 monocular:=/forearm image:=image_rect", "rosrun camera_calibration cameracheck.py --size 8x6 stereo:=/wide_stereo image:=image_rect"]},
{"url": "https://wiki.ros.org/diagnostics", "package": "diagnostics", "package_summary": ["diagnostics"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "The diagnostics toolchain is built around the ", " topic. On this topic, hardware drivers and devices publish ", " messages with the device names, status and specific data points.  ", "The ", " and ", " packages allow nodes to collect and publish diagnostics data. The ", " can categorize and analyze diagnostics at runtime. Operators and developers can view the diagnostics data using the ", " package. The ", " package can convert diagnostics logs to CSV files for examination and after-the-fact analysis. ", "To collect and publish diagnostics data, nodes can use tools in the ", " package. The updater allows nodes, especially hardware drivers, to collect and publish diagnostics data. Using the tools in the updated package, drivers can monitor frequency and connection status. The ", " package uses the ", " to perform a self test on a driver, using a special service call. ", "The ", " package contains tools for categorizing and analyzing diagnostics at runtime. Using a plug-in model, a diagnostic aggregator can be configured for different types of robots to allow simple analysis of diagnostics. It is easy to summarize hundreds of diagnostic items into just a few categories. The diagnostic aggregator plug-ins can allow developers to give users easy to understand messages for common problems. ", "The ", " package contains the ", " tool which displays the processed data from a ", " in graphical form. ", "For robots without a ", ", the ", " package contains a simple monitor that displays data from the ", " topic. ", "The tools in ", " allow users to convert diagnostics bag files into one or more CSV files for plotting or viewing with off-the-shelf spreadsheet software. The ", " tool allows the bag file to be converted into several CSV files, with each diagnostic status name made into its own file. ", "Further information will be found in the ", ". "], "package_tt": ["/diagnostics", "robot_monitor", "diagnostic_aggregator", "diagnostic_aggregator", "/diagnostics", "export_csv.py"]},
{"url": "https://wiki.ros.org/cob_frame_tracker", "package": "cob_frame_tracker", "package_summary": ["The cob_frame_tracker package contains nodes that publish Twist commands based on the distance to the desired tf frame target."]},
{"url": "https://wiki.ros.org/control_toolbox", "package": "control_toolbox", "package_summary": ["The control toolbox contains modules that are useful across all controllers."], "package_details": ["This package contains several C++ classes useful in writing controllers, and so the main documentation can be found on the ", ". "]},
{"url": "https://wiki.ros.org/diagnostic_updater", "package": "diagnostic_updater", "package_summary": ["diagnostic_updater contains tools for easily updating diagnostics. it is commonly used in device drivers to keep track of the status of output topics, device status, etc."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "A working example of a diagnostic_updater can be found in ", ". This example goes through some of the most common uses of an updater. ", "The ", " class eases the pain of filling out a ", " message. It handles setting the summary, possibly with ", "-type formatting of the message field, and setting of key-value pairs with type-conversion and formatting of the values. It also has facilities for merging multiple ", " messages without losing information in the status message. ", "The ", " class manages a set of diagnostic update functions, and their periodic publication. ", "Monitoring a topic's frequency, a common diagnostics feature, and the validity of its timestamps can be done using pre-packaged diagnostic update functions. A ", " wraps a Publisher and standard diagnostics that relate to it in a single class. "], "package_tt": ["printf"]},
{"url": "https://wiki.ros.org/dynamic_reconfigure", "package": "dynamic_reconfigure", "package_summary": ["This unary stack contains the dynamic_reconfigure package which provides a means to change\n    node parameters at any time without having to restart the node."], "package_tt": ["dynamic_reconfigure", "reconfigure_gui", "reconfigure_gui", "dynparam", "dynparam", "dynparam\u00a0list", "dynparam\u00a0get", "dynparam\u00a0set", "dynparam\u00a0set_from_parameters", "dynparam\u00a0dump", "dynparam\u00a0load", "list", "get\u00a0node_name", "-t\u00a0secs", "set\u00a0node_name\u00a0parameter_name\u00a0parameter_value", "set\u00a0node_name\u00a0yaml_dictionary", "-t\u00a0secs", "set_from_parameters\u00a0node_name", "-t\u00a0secs", "dump\u00a0node_name\u00a0file.yaml", "-t\u00a0secs", "load\u00a0node_name\u00a0file.yaml", "-t\u00a0secs", "dynamic_reconfigure.client", "dynamic_reconfigure", "reconfigure_gui", "rqt", "dynparam", "dynparam", "dynparam\u00a0list", "dynparam\u00a0get", "dynparam\u00a0set", "dynparam\u00a0set_from_parameters", "dynparam\u00a0dump", "dynparam\u00a0load", "list", "get\u00a0node_name", "-t\u00a0secs", "set\u00a0node_name\u00a0parameter_name\u00a0parameter_value", "set\u00a0node_name\u00a0yaml_dictionary", "-t\u00a0secs", "set_from_parameters\u00a0node_name", "-t\u00a0secs", "dump\u00a0node_name\u00a0file.yaml", "-t\u00a0secs", "load\u00a0node_name\u00a0file.yaml", "-t\u00a0secs", "dynamic_reconfigure.client"], "package_code": ["$ rosrun dynamic_reconfigure reconfigure_gui", "$ rosrun dynamic_reconfigure dynparam COMMAND", "$ rosrun dynamic_reconfigure dynparam list", "$ rosrun dynamic_reconfigure dynparam get /node", "$ rosrun dynamic_reconfigure dynparam set /node parameter_name value", "$ rosrun dynamic_reconfigure dynparam set wge100_camera \"{'camera_url':'foo', 'brightness':58}\" ", "$ rosrun dynamic_reconfigure dynparam set_from_parameters /node", "$ rosrun dynamic_reconfigure dynparam dump /node dump.yaml", "$ rosrun dynamic_reconfigure dynparam load /node dump.yaml", "$ rosrun dynamic_reconfigure dynparam COMMAND", "$ rosrun dynamic_reconfigure dynparam list", "$ rosrun dynamic_reconfigure dynparam get /node", "$ rosrun dynamic_reconfigure dynparam set /node parameter_name value", "$ rosrun dynamic_reconfigure dynparam set wge100_camera \"{'camera_url':'foo', 'brightness':58}\" ", "$ rosrun dynamic_reconfigure dynparam set_from_parameters /node", "$ rosrun dynamic_reconfigure dynparam dump /node dump.yaml", "$ rosrun dynamic_reconfigure dynparam load /node dump.yaml"]},
{"url": "https://wiki.ros.org/camera_calibration_parsers", "package": "camera_calibration_parsers", "package_summary": ["camera_calibration_parsers contains routines for reading and writing camera calibration parameters."], "package_details": ["\n", " contains C++ functions for reading and writing camera parameters. These are mainly used internally by camera drivers and camera calibration tools, but the formats are human-readable. ", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "For usage, see the ", ". "], "package_tt": ["camera_calibration_parsers"], "package_code": ["$ rosrun  camera_calibration_parsers convert  in-file out-file", "$ rosrun  camera_calibration_parsers convert  cal.yml cal.ini", "$ mv ost.txt ost.ini\n", "$ rosrun  camera_calibration_parsers convert  ost.ini cal.yml", "# Prosilica camera intrinsics\n", "\n", "[image]\n", "\n", "width\n", "2448\n", "\n", "height\n", "2050\n", "\n", "[prosilica]\n", "\n", "camera matrix\n", "4827.93789 0.00000 1223.50000\n", "0.00000 4835.62362 1024.50000\n", "0.00000 0.00000 1.00000\n", "\n", "distortion\n", "-0.41527 0.31874 -0.00197 0.00071 0.00000\n", "\n", "rectification\n", "1.00000 0.00000 0.00000\n", "0.00000 1.00000 0.00000\n", "0.00000 0.00000 1.00000\n", "\n", "projection\n", "4827.93789 0.00000 1223.50000 0.00000\n", "0.00000 4835.62362 1024.50000 0.00000\n", "0.00000 0.00000 1.00000 0.00000", "image_width: 2448\n", "image_height: 2050\n", "camera_name: prosilica\n", "camera_matrix:\n", "  rows: 3\n", "  cols: 3\n", "  data: [4827.94, 0, 1223.5, 0, 4835.62, 1024.5, 0, 0, 1]\n", "distortion_model: plumb_bob\n", "distortion_coefficients:\n", "  rows: 1\n", "  cols: 5\n", "  data: [-0.41527, 0.31874, -0.00197, 0.00071, 0]\n", "rectification_matrix:\n", "  rows: 3\n", "  cols: 3\n", "  data: [1, 0, 0, 0, 1, 0, 0, 0, 1]\n", "projection_matrix:\n", "  rows: 3\n", "  cols: 4\n", "  data: [4827.94, 0, 1223.5, 0, 0, 4835.62, 1024.5, 0, 0, 0, 1, 0]"]},
{"url": "https://wiki.ros.org/ecl_converters", "package": "ecl_converters", "package_summary": ["Some fast/convenient type converters, mostly for char strings or strings.\n     These are not really fully fleshed out, alot of them could use the addition for\n     the whole range of fundamental types (e.g. all integers, not just int, unsigned int).\n     \n     They will come as the need arises."], "package_details": ["\n", "\n"], "package_code": ["\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cob_srvs", "package": "cob_srvs", "package_summary": ["This Package contains Care-O-bot specific service definitions."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/dynamixel_sdk", "package": "dynamixel_sdk", "package_summary": ["This package is wrapping version of ROBOTIS Dynamixel SDK for ROS. The ROBOTIS Dynamixel SDK, or SDK, is a software development library that provides Dynamixel control functions for packet communication. The API is designed for Dynamixel actuators and Dynamixel-based platforms."], "package_details": [" ", "\n", "  ", " ", "\n", "\n", "\n", "\n", "This package wraps the ", " to be available for ROS. The ROBOTIS Dynamixel SDK is a software development library that provides Dynamixel control functions for packet communication. The API is designed for Dynamixel actuators and Dynamixel-based platforms. "]},
{"url": "https://wiki.ros.org/cob_sound", "package": "cob_sound", "package_summary": ["This package implements a sound play module using text2wave and aplay through python."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "By default ", " is used.  ", "For ", " you need to buy a license key.  ", "Download and install voice. Adopted from ", ". ", "* apply fix for Ubuntu > 12.04 ", "* Register voice with license (you need to buy a license from ", ", for IPA robots ask UHR or FMW for license key) "], "package_code": ["roslaunch cob_sound sound.launch", "rosservice call /sound/say \"Hello, my name is Care-O-bot.\"", "rosservice call /sound/mute\n", "rosservice call /sound/unmute", "rosparam set /sound/mode cepstral", "wget http://www.cepstral.com/downloads/installers/linux32/Cepstral_David_i386-linux_6.2.3.873.tar.gz\n", "wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_David_x86-64-linux_6.2.3.873.tar.gz", "wget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Diane_i386-linux_6.2.3.873.tar.gz\n", "wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Diane_x86-64-linux_6.2.3.873.gz", "wget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Matthias_i386-linux_6.2.3.873.tar.gz\n", "wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Matthias_x86-64-linux_6.2.3.873.tar.gz", "wget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Katrin_i386-linux_6.2.3.873.tar.gz\n", "wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Katrin_x86-64-linux_6.2.3.873.tar.gz", "tar xzvf Cepstral_David_x86-64-linux_6.2.3.873.tar.gz\n", "cd Cepstral_David_x86-64-linux_6.2.3.873\n", "sudo ./install.sh\n", "sudo touch /etc/ld.so.conf.d/cepstral.conf\n", "sudo sh -c 'echo \"/opt/swift/lib\" > /etc/ld.so.conf.d/cepstral.conf'\n", "sudo ldconfig", "roscd cob_sound\n", "sudo ./fix_swift_for_precise.sh", "sudo apt-get install alsa-oss", "if test -x /usr/bin/padsp ; then  exec aoss /opt/swift/bin/swift \"$@\" ; else  exec /opt/swift/bin/swift \"$@\" ; fi", "sudo swift --reg-voice", "alsamixer", "amixer -c 1 set Speaker xx%", "amixer -c 1 set PCM xx%", "sudo alsactl store"]},
{"url": "https://wiki.ros.org/common_msgs", "package": "common_msgs", "package_summary": ["common_msgs contains messages that are widely used by other ROS packages.\n    These includes messages for\n    actions (", "),\n    diagnostics (", "),\n    geometric primitives (", "),\n    robot navigation (", "),\n    and common sensors (", "), such as laser range finders, cameras, point clouds."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "  ", "This is a summary of the ", " and ", " types available in the various ROS ", " in the ", " stack. For more documentation, please see the relevant package. ", "Please see ", " for documentation on the standard units of measure and coordinate conventions followed here. ", "Please see the ", ". "], "package_tt": ["common_msgs"]},
{"url": "https://wiki.ros.org/ecl_exceptions", "package": "ecl_exceptions", "package_summary": ["Template based exceptions - these are simple and practical\n     and avoid the proliferation of exception types. Although not\n     syntatactically ideal, it is convenient and eminently practical."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "If outside ros, you will also need to link to ", ". ", "These are in ", ". "], "package_tt": ["src/examples/exceptions.cpp", "src/examples/exception_tracer.cpp", "/src/benchmarks/exceptions.cpp"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/ecl_build", "package": "ecl_build", "package_summary": ["Collection of cmake/make build tools primarily for ecl development itself, but also\n     contains a few cmake modules useful outside of the ecl."]},
{"url": "https://wiki.ros.org/cob_base_drive_chain", "package": "cob_base_drive_chain", "package_summary": ["This package contains classes that are able to control the platform of the Care-O-Bot. This means to establish a CAN communication to drive and steering motors of the platform and later send motion commands and receive motor information."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", "To keep the communication with the Care-O-Bot platform variable (as different motors or CAN-hardware could be used), ", " implements the communication to different motors through a generic interface ", " and for different CAN modules through ", ". The used CAN module is specified in an .ini-File, as well as motor-specific parameters. Each motor-object is loaded with appropriate parameters and during initialization each wheel is homed. ", "After initialization, the user can easily command the platform using the provided functions of ", " like ", ". ", "It is implemented in ", " and again provided to the ROS network via services. To use the Elmo Recorder without the services, you can use the interface of ", " directly as desribed below. ", "There are two other levels of \u201cuser\u201d-interfaces, to keep the drive interface-classes slight. The function ", " basically is just a wrapper function for the main Elmo-Recorder interface in ", ". With these arguments you can control all of the Recorders features. ", " specifies the general task, you are going to set up: ", "To avoid that effect, the user only has to start-up the read-out process. From then, the transfer process is running autonomously, triggered by the receive of data packets, which are led to the appropriate functions after having been fetched from the CAN-buffer. During such a segmented SDO transfer, the data is collected in the ", " collection class. It also holds some SDO-transfer-specific features like the state of the transmission. When receiving the last segment of a transfer, the collected data is handed to an adequate processing function. In our case, it's ", ". Finally, the collected data is saved to a file; you also could imagine of keeping it temporarily in a variable to give the calling function the opportunity to process the data itself. ", "How to read out data from the Elmo Recorder is described in ", ". "], "package_tt": ["cob_base_drive_chain::CanCtrlPltfCOb3", "cob_canopen_motor::CanDriveItf", "cob_generic_can::CanItf", "cob_base_drive_chain::CanCtrlPltfCOb3", "setVelGearRadS", "joint_command", "JointState", "Diagnostic", "Init", "Reset", "Shutdown", "GetJointState", "ElmoRecorderConfig", "ElmoRecorderReadout", "cob_base_drive_chain::CanCtrlPltfCOb3", "cob_base_drive_chain::CanCtrlPltfCOb3", "CanCtrlPltfCOb3::ElmoRecordings", "cob_canopen_motor::CanDriveHarmonica::setRecorder(int\u00a0iFlag,\u00a0int\u00a0iParam,\u00a0std::string\u00a0sParam)", "iFlag", "iFlag\u00a0=\u00a00", "iFlag\u00a0=\u00a01", "iFlag\u00a0=\u00a02", "iFlag\u00a0=\u00a099", "cob_canopen_motor::SDOSegmented", "ElmoRecorder::processData()"]},
{"url": "https://wiki.ros.org/boost_numpy", "package": "boost_numpy", "package_summary": ["Python wrappers for converting Boost C++ datatypes into Numpy objects."]},
{"url": "https://wiki.ros.org/calibration_msgs", "package": "calibration_msgs", "package_summary": ["This package defines messages for storing calibration samples\n     to be used in full robot calibration procedures. This package\n     is still unstable. Expect the messages to change."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/convex_decomposition", "package": "convex_decomposition", "package_summary": ["Convex Decomposition Tool for Robot Model"], "package_details": ["\n", "This is a thirdparty package with ", ". "], "package_tt": ["convex_decomposition", "convex_decomposition", "convex_decomposition"]},
{"url": "https://wiki.ros.org/driver_common", "package": "driver_common", "package_summary": ["The driver_common stack contains classes and tools that are useful\n    throughout the driver stacks. It currently contains:\n\n    driver_base: A base class for sensors to provide a consistent state machine\n    (retries, error handling, etc.) and interface\n\n    timestamp_tools: Classes to help timestamp hardware events"], "package_details": ["\n", ": the ", " package (formerly part of this stack) became a separate stack. ", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/bwi_planning", "package": "bwi_planning", "package_summary": ["The planner_krr14 package"], "package_details": ["\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This package is now ", ". A newer version is now in the ", " package: "]},
{"url": "https://wiki.ros.org/diagnostic_aggregator", "package": "diagnostic_aggregator", "package_summary": ["diagnostic_aggregator"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " contains a ROS node, ", ", that listens to ", " messages on the ", " topic, processes and categorizes the data, and republishes on ", ". The ", " loads \"Analyzer\" plugins to perform the diagnostics processing and categorization. The configuration and setup for each diagnostic aggregator is specific to each robot and can be determined by users or developers. ", "The two analyzers in this package, ", " and ", ", hold and categorize diagnostic messages. They're useful for categorizing components or systems. They can warn when an item is stale, but do not do additional analysis of the diagnostics. Other analyzers can be loaded as plugins by the ", " on startup. ", "The aggregated diagnostic output can be displayed in the ", " tool. The ", " displays these messages in a hierarchical format. To determine the hierarchy, the diagnostic aggregator prepends diagnostic status names with a path, joined with \"/\". For example: ", "This shows how an ", " might categorize and analyze diagnostics data from a simple robot. ", "Using the diagnostic aggregator, we can move these diagnostic messages into easy to understand categories to display in our ", ". To do this, just prepend the name of the category to the status names, and separate them with \"/\". ", "The ", " will load analyzers to store and process the diagnostic data. Each analyzer inherits from the base class ", ". Analyzers must be in packages that depend directly on ", " and ", ". ", "The base analyzer class is the pure virtual ", " class. All derived classes must implement these methods: ", "Analyzers can choose the error state for any ", " message they analyze and report. Generally, the \"parent\" of an analyzer has an error state of the maximum of its children, but some analyzers may have more advanced methods. ", "The analyzers are responsible for correctly setting the names of each item they analyze. The ", " does not do any checking or enforcement of the diagnostic status name hierarchy. ", "Users can create Analyzers to load as plugins for different robots. See the tutorial ", " for details. ", "For a full tutorial, see the tutorial ", ". ", "Under each sub namespace under ", ", a different analyzer is configured. Analyzers can be robot specific, or they can be general purpose ones like the ", ". ", "Each analyzer needs a special parameter, ", ", in the namespace. The ", " parameter gives the ", " the class name of the ", ". ", "The ", " parameter (publish rate of ", ") is optional, and defaults to 1.0. The ", " is prepended to all ", " output, and defaults to \"\" (empty string). ", "To look for an example of an aggregator in use, look in the \"diagnostic_aggregator/demo\" directory. Users specify each ", " in the private parameter space of the ", ", then start the node.  ", "In the ", " package, the two analyzer types provided: ", " and ", ". The ", " can be used to categorize and track stale items. The ", " categorizes analyzers themselves, allowing users to \"sub-categorize\" analyzers. ", "The ", " class is useful for categorizing diagnostics data. It's mostly used for a particular device or category, like a Hokuyo node or EtherCAT devices. It can be configured to analyze almost any set of diagnostics data. ", "For a full tutorial on the ", ", see ", " ", "The ", " can load a group of analyzers as a sub group. This can be useful for analyzing a group of similar items, like 4 different cameras. The ", " can use any type of analyzer as one of the sub-analyzers.  ", "The above example can analyze the instruments on a PR2. The ", " uses the parameter ", " to prepend to all output names. In the above example,  ", "All sub-analyzers should go under the ", " namespace of the ", ". They should be specified in the same way that any diagnostic analyzer would be specified. ", "Note: The diagnostic aggregator uses the ", " internally, which is why this is very similar to setting up a diagnostic aggregator. ", "The ", " is a subclass of the ", ". It will \"match\" any item that the ", " matches, but will discard the items and not report it. ", "The ", " will simply ignore all parameters in its namespace, and not match or report anything.  ", "The difference between this and the ", " above is that since the ", " doesn't match anything, anything that it is ignoring will be reported in \"Other\". The ", " will suppress any output from anything that it matches. ", "PR2 robots use the ", " and the ", " for diagnostic display. The launch files in \"pr2_bringup/pr2.launch\" contain the configuration file for the ", ".  ", "The \"diagnostic_aggregator/demo\" directory has an example of an ", " used for testing and demonstrations. "], "package_tt": ["diagnostic_aggregator", "aggregator_node", "/diagnostics", "/diagnostics_agg", "aggregator_node", "GenericAnalyzer", "AnalyzerGroup", "aggregator_node", "robot_monitor", "prosilica:\u00a0Frequency\u00a0Status", "My\u00a0Robot/Sensors/Prosilica/prosilica:\u00a0Frequency\u00a0Status", "aggregator_node", "robot_monitor", "aggregator_node", "diagnostic_aggregator::Analyzer", "init()", "match()", "analyze()", "report()", "getPath()", "getName()", "aggregator_node", "~analyzers", "GenericAnalyzer", "type", "type", "aggregator_node", "Analyzer", "pub_rate", "/diagnostics_agg", "base_path", "/diagnostics_agg", "Analyzer", "aggregator_node", "diagnostic_aggregator", "GenericAnalyzer", "AnalyzerGroup", "GenericAnalyzer", "AnalyzerGroup", "GenericAnalyzer", "GenericAnalyzer", "AnalyzerGroup", "AnalyzerGroup", "path", "tilt_hokuyo_node:\u00a0Frequency\u00a0Status", "Sensors/Tilt\u00a0Hokuyo/tilt_hokuyo_node:\u00a0Frequency\u00a0Status", "~analyzers", "AnalyzerGroup", "AnalyzerGroup", "DiscardAnalyzer", "GenericAnalyzer", "GenericAnalyzer", "IgnoreAnalyzer", "DiscardAnalyzer", "IgnoreAnalyzer", "DiscardAnalyzer", "/diagnostics", "/diagnostics_agg", "/diagnostics_toplevel_state", "~pub_rate", "double", "~base_path", "string", "~analyzers", "{}", "~analyzers", "{}", "aggregator_node", "robot_monitor", "aggregator_node", "aggregator_node"], "package_code": ["Left Wheel\n", "Right Wheel\n", "SICK Frequency\n", "SICK Temperature\n", "SICK Connection Status\n", "Stereo Left Camera\n", "Stereo Right Camera\n", "Stereo Analysis\n", "Stereo Connection Status\n", "Battery 1 Level\n", "Battery 2 Level\n", "Battery 3 Level\n", "Battery 4 Level\n", "Voltage Status", "My Robot/Wheels/Left\n", "My Robot/Wheels/Right\n", "My Robot/SICK/Frequency\n", "My Robot/SICK/Temperature\n", "My Robot/SICK/Connection Status\n", "My Robot/Stereo/Left Camera\n", "My Robot/Stereo/Right Camera\n", "My Robot/Stereo/Analysis\n", "My Robot/Stereo/Connection Status\n", "My Robot/Power System/Battery 1 Level\n", "My Robot/Power System/Battery 2 Level\n", "My Robot/Power System/Battery 3 Level\n", "My Robot/Power System/Battery 4 Level\n", "My Robot/Power System/Voltage Status", "My Robot\n", "  -- Wheels\n", "    -- Left\n", "    -- Right\n", "  -- SICK\n", "    -- etc ...\n", "  -- Stereo\n", "  -- Power System", "pub_rate: 1.0 # Optional, defaults to 1.0\n", "base_path: 'PRE' # Optional, defaults to \"\"\n", "analyzers:\n", "  motors:\n", "    type: PR2MotorsAnalyzer\n", "  joints:\n", "    type: GenericAnalyzer\n", "    path: 'Joints'\n", "    regex: 'Joint*'", "\n", "\n", "\n", "\n", "\n", "type: AnalyzerGroup\n", "path: Sensors\n", "analyzers:\n", "  base_hk:\n", "    type: GenericAnalyzer\n", "    path: Base Hokuyo\n", "    startswith: base_hokuyo_node\n", "    num_items: 3\n", "  tilt_hk:\n", "    type: GenericAnalyzer\n", "    path: Tilt Hokuyo\n", "    startswith: tilt_hokuyo_node\n", "    num_items: 3\n", "  imu:\n", "    type: GenericAnalyzer\n", "    path: IMU\n", "    startswith: imu_node\n", "    num_items: 3"]},
{"url": "https://wiki.ros.org/dbw_pacifica_description", "package": "dbw_pacifica_description", "package_summary": ["URDF and meshes describing the Pacifica."]},
{"url": "https://wiki.ros.org/carl_dynamixel", "package": "carl_dynamixel", "package_summary": ["Configuration for CARLS's Head Dynamixel Servo"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"carl_dynamixel\" in rosdoc: /home/rosbot/docs/api/carl_dynamixel/manifest.yaml ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package is a package which launches the correct nodes and controllers from the 'dynamixel_motors' package. It also has a sensor_msgs/JointState publisher. ", "The ", " package contains a ", " This file launches an instance of the ", " and ", " nodes from the 'dynamixel_motor' metapackage. It also launches the 'back_joints_node' and ", ", as well as the ", " node for velocity commands. To launch these nodes, the following command can be used: ", "The id for the servo can be found from the 'motor_states/<port>' topic ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments. "], "package_tt": ["carl_dynamixel", "back_joint_node", "motor_states/back_port", "dynamixel_back", "back_servos/num_servos", "back_servos/1/id", "back_servos/1/link_name", "front_joint_node", "motor_states/front_port", "dynamixel_front", "front_servos/num_servos", "front_servos/1/id", "front_servos/1/link_name", "servo_pan_tilt", "asus_controller/tilt", "creative_controller/pan", "dynamixel_back", "dynamixel_front", "asus_controller/command", "creative_controller/command", "asus_controller/look_at_point", "asus_controller/look_at_frame", "carl_dynamixel", "carl_servos.launch", "dynamixel_manager", "tilt_controller_spawner", "front_joints_node", "servo_pan_tilt", "asus_controller/command", "creative_controller/command", "asus_controller/tilt", "creative_controller/pan", "motor_states/back_port", "motor_states/front_port", "asus_controller/state", "creative_controller/state"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-carl-bot", "roslaunch carl_dynamixel carl_servos.launch", "example_controller:\n", "    controller:\n", "        package: dynamixel_controllers\n", "        module: joint_position_controller\n", "        type: JointPositionController\n", "    joint_name: example_joint\n", "    joint_speed: 0.5\n", "    motor:\n", "        id: 1\n", "        init: 512\n", "        min: 0\n", "        max: 1023", "<!-- Start example joint controller -->\n", "    <rosparam file=\"$(find carl_dynamixel)/config/example.yaml\" command=\"load\"/>\n", "    <node name=\"example_controller_spawner\" pkg=\"dynamixel_controllers\" type=\"controller_spawner.py\"\n", "          args=\"--manager=dxl_manager\n", "                --port back_port\n", "                example_controller\"\n", "          output=\"screen\"/>", "\"2\": \n", "    id: 2\n", "    link_name: joint_2", "back_servos: \n", "   num_servos: 3\n", "   \"1\": \n", "    id: 1\n", "    link_name: asus_servo_asus_servo_arm_joint \n", "   \"2\": \n", "    id: 2\n", "    link_name: joint_2\n", "   \"3\": \n", "    id: 12\n", "    link_name: joint_3 "]},
{"url": "https://wiki.ros.org/cob_object_detection_msgs", "package": "cob_object_detection_msgs", "package_summary": ["This package contains message type definitions for object detection"]},
{"url": "https://wiki.ros.org/ecl_command_line", "package": "ecl_command_line", "package_summary": ["Embeds the TCLAP library inside the ecl. This is a very convenient\n     command line parser in templatised c++."], "package_details": ["\n", "\n", "\n", "\n", "\n"], "package_tt": ["boost::program_options", "src/examples/command_line.cpp"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/catch_ros", "package": "catch_ros", "package_summary": ["ROS integration for the Catch unit test framework"]},
{"url": "https://wiki.ros.org/ecl_devices", "package": "ecl_devices", "package_summary": ["Provides an extensible and standardised framework for input-output devices."], "package_details": ["\n", "\n", "\n", "\n", "If outside ros, you will also need to link against ", ". ", "These are in ", ". "], "package_tt": ["src/examples/serial_timeout.cpp", "src/benchmarks/files.cpp", "src/demos/socket_client.cpp", "src/demos/socket_server.cpp", "src/utils/hex.cpp", "src/utils/serial.cpp"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/cmvision", "package": "cmvision", "package_summary": ["Node for the Color Machine Vision Project, used for fast color blob detection"], "package_details": ["\n", "\n", " ", "\n", "\n", "\n", "\n", "The above command will bring up an interface that provides a means for graphically selecting desired colors for blobs. ", " displays values for ", " and ", " which can be used in a colors file. ", "Blob parameters are specified to ", " using two components: ", "Example ", " for detecting a ", " RWI B21r ", "Multiple blob colors can be specified in the same file by adding lines under ", " and ", ". "], "package_tt": ["colorgui", "RGB", "YUV", "cmvision", "RGB", "YUV", "colors.txt", "colors", "thresholds", "image", "image", "blobs", "/cmvision/color_file", "string", "/cmvision/mean_shift_on", "bool", "true", "/cmvision/debug_on", "bool", "/cmvision/spatial_radius_pix", "int", "/cmvision/color_radius_pix", "int"], "package_code": ["rosrun cmvision colorgui image:=<image topic>", "[colors]\n", "(159,  62, 71) 0.000000 7 ResearchRobotRed\n", "\n", "[thresholds]\n", "(56:99, 108:117, 173:193)", "rosparam set /cmvision/color_file /path/to/colors.txt\n", "rosrun cmvision cmvision image:=<image topic>"]},
{"url": "https://wiki.ros.org/cyberglove", "package": "cyberglove", "package_summary": ["This is a generic ROS interface to the Cyberglove from Immersion. It reads data from the Cyberglove, calibrate them\n     and streams them to two different /joint_states topic: calibrated and raw data."], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", "\n", "This node publishes ", "/jointState messages on two topics for the raw and calibrated values. The two topics are ", " and ", " ", "The calibration file is loaded from  the ", "/param/cyberglove.cal file. To change which file you want to use, you can simply edit the parameter ", " of the ", " file. ", "A calibration process is available in the ", " plugin of the ", ". ", "The standard Cyberglove connected to the serial port has been tested, as well as the bluetooth version of the cyberglove. To use the bluetooth version, you need to pair it with your computer. A good howto is available on the ", ". "], "package_code": ["<node pkg=\"cyberglove\" name=\"cyberglove\" type=\"cyberglove\">\n", "    <param name=\"cyberglove_prefix\" type=\"string\" value=\"/cyberglove\" />\n", "    <param name=\"publish_frequency\" type=\"double\" value=\"20.0\" />\n", "    <param name=\"path_to_glove\" type=\"string\" value=\"/dev/ttyS0\" />\n", "    <param name=\"path_to_calibration\" type=\"string\" value=\"$(find\n", "    sr_control_gui)/param/cyberglove.cal\" />\n", "</node>"]},
{"url": "https://wiki.ros.org/catkin_pip", "package": "catkin_pip", "package_summary": ["Catkin macros to allow using pure python packages in usual catkin workspaces with normal python workflow."]},
{"url": "https://wiki.ros.org/bfl", "package": "bfl", "package_summary": ["This package contains a recent version of the Bayesian Filtering\n  Library (BFL), distributed by the Orocos Project.  For stability\n  reasons, this package is currently locked to revision 31655 (April\n  19, 2010), but this revision will be updated on a regular basis to\n  the latest available BFL trunk.  This ROS package does not modify\n  BFL in any way, it simply provides a convenient way to download and\n  compile the library, because BFL is not available from an OS package\n  manager.  This ROS package compiles BFL with the Boost library for\n  matrix operations and random number generation."], "package_details": [" ", "\n", "\n", "This is a third party package with ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/camera_info_manager", "package": "camera_info_manager", "package_summary": ["This package provides a C++ interface for camera calibration\n     information.  It provides CameraInfo, and handles SetCameraInfo\n     service requests, saving and restoring the camera calibration\n     data."], "package_details": ["\n", "\n", "\n", "\n", ": the URL may now contain substitution variables, including the camera name and ", ". ", "\n", "\n", "\n", "\n", "\n", " class ", ": the global ", " class is no longer available, use ", " instead. ", ": a new ", " method allows the caller to set ", " parameters directly. ", "\n", "It provides a C++ class used by many camera drivers to manage the ", " required by the ", ". ", "For camera drivers written in Python, the ", " package provides a similar interface. ", "For ROS Diamondback, this package moved to the ", " stack. For C Turtle, it was part of ", ". ", "In ROS Diamondback the ", " class moved to the ", " namespace. For compatibility with ROS C Turtle, the global ", " class name is still supported. It is deprecated in Electric Emys and removed in Fuerte. ", "The API includes a camera name, which is written when ", " is saved, and checked when data are loaded, with a warning logged if the name read does not match. ", "Camera driver authors should refer to the ", " for syntax details and recommendations for assigning camera names.  ", "The location for getting and saving calibration data is expressed by Uniform Resource Locator (URL). These URLs are commonly used in the APIs of this package and may also contain substitution variables to refer to common locations. Please see the ", " for supported URLs, file formats and substitution variables. ", "This package does not read ROS parameters directly. Where appropriate, we recommend  that drivers provide a ", " parameter for the URL string passed to CameraInfoManager. ", "For compatibility with C Turtle, the global ", " class name was still supported, but it was ", " in Electric. ", "The camera_info_manager is used in the ", " driver.  Search for ", " in the source code to see where the CameraInfoManager class is used. In particular, note the handling of Header time stamps and transform frame IDs. "], "package_tt": ["CameraInfoManager", "camera_info_manager", "CameraInfoManager", "CameraInfo", "${ROS_HOME}", "set_camera_info", "~camera_info_url", "CameraInfoManager", "CameraInfoManager", "camera_info_manager::CameraInfoManager", "setCameraInfo()", "CameraInfo", "cinfo_"]},
{"url": "https://wiki.ros.org/cob_trajectory_controller", "package": "cob_trajectory_controller", "package_summary": ["This package provides a trajectory controller which controlls velocities for a chain of joints. This controller can be used e.g. with [[schunk_powercube_chain]]."], "package_details": ["\n", "\n"], "package_tt": ["cob_trajectory_controller", "joint_trajectory_action/goal", "joint_trajectory_action/result", "joint_trajectory_action/feedback", "/joint_states", "command_vel", "set_joint_velocity", "set_joint_acceleration", "~ptp_vel", "double", "~ptp_acc", "double", "~max_error", "double"]},
{"url": "https://wiki.ros.org/dynamixel_controllers", "package": "dynamixel_controllers", "package_summary": ["This package contains a configurable node, services and a spawner script\n        to start, stop and restart one or more controller plugins. Reusable\n        controller types are defined for common Dynamixel motor joints. Both speed and\n        torque can be set for each joint. This python package can be used by more\n        specific robot controllers and all configurable parameters can be loaded\n        via a yaml file."], "package_tt": ["start_controller/serial_port_name", "stop_controller/serial_port_name", "restart_controller/serial_port_name", "~port_name", "str", "~baud_rate", "int", "~min_motor_id", "int", "~max_motor_id", "int", "~update_rate", "int", "joint_controller_name/controller/package", "str", "joint_controller_name/controller/module", "str", "joint_controller_name/controller/type", "str", "joint_controller_name/command", "motor_states/serial_port_name", "joint_controller_name/state", "joint_controller_name/set_speed", "joint_controller_name/torque_enable", "joint_controller_name/set_compliance_slope", "joint_controller_name/set_compliance_margin", "joint_controller_name/set_compliance_punch", "joint_controller_name/set_torque_limit", "joint_controller_name/joint_name", "str", "joint_controller_name/joint_max_speed", "float", "joint_controller_name/joint_speed", "float", "joint_controller_name/joint_compliance_slope", "int", "joint_controller_name/joint_compliance_margin", "int", "joint_controller_name/joint_compliance_punch", "int", "joint_controller_name/joint_torque_limit", "float", "<manager_namespace>/<port_namespace>/start_controller", "<manager_namespace>/<port_namespace>/stop_controller", "<manager_namespace>/<port_namespace>/restart_controller", "~namespace", "str", "~diagnostics_rate", "float", "~serial_ports", "map", "~serial_ports/<port_namespace>/port_name", "str", "~serial_ports/<port_namespace>/baud_rate", "int", "~serial_ports/<port_namespace>/min_motor_id", "int", "~serial_ports/<port_namespace>/max_motor_id", "int", "~serial_ports/<port_namespace>/update_rate", "int", "~serial_ports/<port_namespace>/diagnostics/error_level_temp", "int", "~serial_ports/<port_namespace>/diagnostics/warn_level_temp", "int", "joint_controller_name/controller/package", "str", "joint_controller_name/controller/module", "str", "joint_controller_name/controller/type", "str", "<joint_controller_name>/command", "motor_states/<serial_port_name>", "<joint_controller_name>/state", "<joint_controller_name>/set_speed", "<joint_controller_name>/torque_enable", "<joint_controller_name>/set_compliance_slope", "<joint_controller_name>/set_compliance_margin", "<joint_controller_name>/set_compliance_punch", "<joint_controller_name>/set_torque_limit", "~<joint_controller_name>/joint_name", "str", "~<joint_controller_name>/joint_max_speed", "float", "~<joint_controller_name>/joint_speed", "float", "~<joint_controller_name>/joint_compliance_slope", "int", "~<joint_controller_name>/joint_compliance_margin", "int", "~<joint_controller_name>/joint_compliance_punch", "int", "~<joint_controller_name>/joint_torque_limit", "float"]},
{"url": "https://wiki.ros.org/bwi_planning_common", "package": "bwi_planning_common", "package_summary": ["Common data structures, messages and service defintions used for\n    deterministic planning work in the BWI project at the University of Texas\n    at Austin"]},
{"url": "https://wiki.ros.org/costmap_converter", "package": "costmap_converter", "package_summary": ["A ros package that includes plugins and nodes to convert occupied costmap2d cells to primitive types."], "package_details": ["\n", "\n", "\n", " ", " ", "\n", " (", ", default: 0.4) ", "\n", " ", "\n", " (", ", default: 0.4) ", "\n", " ", " ", "\n", " (", ", default: 0.4) ", "\n", " ", " ", "\n", " (", ", default: 0.4) ", "\n", "This package defines an ", " interface and provides some plugins for converting occupied cells of ", " to geometric primitives. This primitives (points, lines, polygons) represent obstacles in the map. ", "It is intendend for nodes that incorporate obstacles (e.g. in navigation) and do not rely on cost cells, but consider obstacles defined by shapes in the plane (e.g. polygons). ", "The costmap is still favorable in conjunction with ", " since it fuses multiple range sensors with a global static map and some filtering might be applied. ", "A naive approach to further incorporate the costmap is to take each occupied cell as point-obstacle. However, by integrating the costmap_converter interface the costmap is converted continuously during runtime and if desired the conversion is invoked in a separate thread. ", "For that purpose the internal ", " node (", ") might be employed. Currently, parameters are hardcoded. These are going to be substituted with changeble parameters in an upcoming release. Before then please inspect the source code for further details. "], "package_tt": ["~<name>/cluster_max_distance", "double", "~<name>/cluster_min_pts", "int", "~<name>/cluster_max_pts", "int", "~<name>/convex_hull_min_pt_separation", "double", "~<name>/cluster_max_distance", "double", "~<name>/cluster_min_pts", "int", "~<name>/cluster_max_pts", "int", "~<name>/convex_hull_min_pt_separation", "double", "~<name>/concave_hull_depth", "double", "~<name>/cluster_max_distance", "double", "~<name>/cluster_min_pts", "int", "~<name>/cluster_max_pts", "int", "~<name>/convex_hull_min_pt_separation", "double", "~<name>/support_pts_max_dist", "double", "~<name>/support_pts_max_dist_inbetween", "double", "~<name>/min_support_pts", "int", "~<name>/cluster_max_distance", "double", "~<name>/cluster_min_pts", "int", "~<name>/cluster_max_pts", "int", "~<name>/ransac_inlier_distance", "double", "~<name>/ransac_min_inliers", "int", "~<name>/ransac_no_iterations", "int", "~<name>/ransac_remainig_outliers", "int", "~<name>/ransac_convert_outlier_pts", "bool", "~<name>/ransac_filter_remaining_outlier_pts", "bool", "~<name>/convex_hull_min_pt_separation", "double", "standalone_converter"]},
{"url": "https://wiki.ros.org/comp_temporal", "package": "comp_temporal", "package_summary": ["\n\n     Temporal reasoning methods for the knowledge base.\n\n     Time points and intervals are supported, and the system can\n     calculate if one interval subsumes another one, happens before\n     or after another, and how long it takes.\n\n  "], "package_details": ["This package is part of the ", " knowledge processing system. "]},
{"url": "https://wiki.ros.org/blob", "package": "blob", "package_summary": ["blob provides a new message type blob/Blob for binary data."], "package_details": ["\n", "Use GitHub to ", ". [", "]", "\n "]},
{"url": "https://wiki.ros.org/camera_drivers", "package": "camera_drivers", "package_summary": ["\n    This stack contains drivers for a variety of cameras, and some\n    associated tools.\n  "], "package_details": ["\n", ": each camera driver formerly included here now resides in its own separate stack. For backwards compatibility, those stacks are listed as ", " dependencies, but external dependencies should refer directly to the desired driver stack. ", ": the camera_drivers metapackage is no longer supported. Update dependencies to refer to specific drivers, instead. ", "\n", "\n", "\n", "  ", "To encourage compatibility between camera nodes, it is recommended that cameras provide one or both of the the following minimal APIs. The ", " package provides a CameraPublisher class to help implementing this API. The ", " package exports a CameraInfoManager C++ class that provides ", " data and handles ", " service requests. ", "\n"], "package_tt": ["camera_drivers", "camera/image_raw", "camera/camera_info", "camera/set_camera_info", "response_namespace", "request_image", "<response_namespace>/image_raw", "<response_namespace>/camera_info", "set_camera_info", "request_image"]},
{"url": "https://wiki.ros.org/cmake_modules", "package": "cmake_modules", "package_summary": ["A common repository for CMake Modules which are not distributed with CMake but are commonly used by ROS packages."], "package_details": [" "]},
{"url": "https://wiki.ros.org/geometry2", "package": "geometry2", "package_summary": ["A metapackage to bring in the default packages second generation Transform Library in ros, tf2."], "package_details": ["This is a metapackage see ", " for more detailed information. "]},
{"url": "https://wiki.ros.org/geometry_experimental", "package": "geometry_experimental", "package_summary": ["The second generation Transform Library in ros.  This metapackage is deprecated, but is kept for backwards compatability."], "package_details": ["\n", "\n", "  "]},
{"url": "https://wiki.ros.org/head_action", "package": "head_action", "package_summary": ["The head action is a node that provides an action interface for\n  pointing the head of the configured robot. It passes trajectory goals to the\n  controller, and reports success when they have finished executing."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "See ", " for information on the controller that the head action communicates with. ", "An example of using the head action on ", " can be found on the video below. ", "The joint trajectory action provides an action server (see ", ") that takes in goals of the type ", ".  It reports success when the head is pointed at the target. "], "package_tt": ["~pan_link", "string", "~tilt_link", "string", "~success_angle_threshold", "double", "~point_head_action/goal", "~point_head_action/cancel", "~point_head_action/feedback", "~point_head_action/status", "~point_head_action/result", "~state", "~command"]},
{"url": "https://wiki.ros.org/eigen_stl_containers", "package": "eigen_stl_containers", "package_summary": ["This package provides a set of typedef's that allow\n  using Eigen datatypes in STL containers"]},
{"url": "https://wiki.ros.org/executive_smach", "package": "executive_smach", "package_summary": ["This metapackage depends on the SMACH library and ROS SMACH integration\n    packages."], "package_details": ["\n", "\n", "\n", "  ", "See ", " for SMACH state classes with a variety of additional behaviors. ", "On the ", " you can find a number of easy examples. But if you are looking for some 'real' examples running SMACH: "]},
{"url": "https://wiki.ros.org/ecl_mobile_robot", "package": "ecl_mobile_robot", "package_summary": ["Contains transforms (e.g. differential drive inverse kinematics)\n    for the various types of mobile robot platforms."]},
{"url": "https://wiki.ros.org/gazebo_ros_control", "package": "gazebo_ros_control", "package_summary": ["gazebo_ros_control"]},
{"url": "https://wiki.ros.org/filters", "package": "filters", "package_summary": ["This library provides a standardized interface for processing data as a sequence \n    of filters.  This package contains a base class upon which to build specific implementations\n    as well as an interface which dynamically loads filters based on runtime parameters."], "package_details": [": filters is now a separate stack.  In previous releases, it was part of ", ". ", "\n", "\n", "\n", "\n", " ", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", " (list(Filters)) ", "\n", "\n", "\n", "\n", ": A new simpler plugin macro is now recommended: ", "\n", "Filters are closely linked to ", ".  Please make sure that you are familiar with the ", " before continuing.   ", "It is recommended to use a ", " whenever using more than one instances of ", ". However, you need to understand the base Filter C++ API first before using the Filter Chain API. ", "The core of the ", " Package is a templated base class ", " which defines the external API to any filter.  The methods are ", " and ", ".  It also provides helper methods for a Filter implementation. To use a Filter simply instantiate it in your code.   ", "Filters are configured from parameters on the ", ".  The configure method passes in the parameter namespace to read from of the Parameter Server.   ", "A Filter expects to find a map with three elements: ", ", ", " and ", ".   ", "The ", " class has been designed to facilitate dynamically loading a sequence of Filters based on runtime parameters.  The Filter Chain is configured from the ", " just like Filters.  Based on the parameters the Filter Chain will dynamically load the Filters by their name.   ", "The public API looks just like the Filter API with ", " and ", " methods.   ", "Here's an example of a multi-channel filter chain for doubles.  To do a non-vector style use a ", " and change ", " and ", " to type ", ".   ", "Implementing a ", " is simply a specific form of a dynamically loaded class for ", ".   ", "This whole document refers simply to ", " and ", ".  However there are ", " versions of both.  Instead of the templated data type, ", ", they expect ", " on the update calls.  And the configure method has one extra argument which is the number of channels expected(aka how many elements are expected in the ", ").   "], "package_tt": ["filters::FilterChain", "filters::Filter", "filters", "filters::FilterBase<TemplateType>", "configure()", "update()", "name", "type", "params", "name", "string", "type", "string", "params", "map", "filters::FilterChain", "configure()", "update()", "filter_chain", "filters::FilterChain<double>", "in", "out", "double", "Filter", "FilterBase<T>", "configure()", "update()", "filters", "filters::FilterBase", "filters::FilterChain", "MultiChannel", "T", "std::vector<T>", "vector"], "package_code": ["parameter_namespace_passed_to_configure:\n", "  name: unique_name\n", "  type: FilterName\n", "  params: { param1: a, param2: b}", "param_namespace_passed_to_configure:\n", "  filter_chain:\n", "    -\n", "      name: median_test_unique\n", "      type: MultiChannelMedianFilterDouble\n", "      params: {number_of_observations: 5}\n", "    - \n", "      name: median_test2\n", "      type: MultiChannelMedianFilterDouble\n", "      params: {number_of_observations: 5}", "filters::MultiChannelFilterChain<double> chain(\"double\"); //Node template type and argument must match\n", "chain.configure(\"param_namespace_passed_to_configure\");\n", "std::vector<double> in, out; ", "chain.update(in, out);", "PLUGINLIB_REGISTER_PLUGIN(UniqueFullClassNameSoSpecialCharacters, my_package::ClassName, filters::FilterBase<Type>)", "PLUGINLIB_EXPORT_PLUGIN(my_package::ClassName, filters::FilterBase<Type>)"]},
{"url": "https://wiki.ros.org/gennodejs", "package": "gennodejs", "package_summary": ["Javascript ROS message and service generators."], "package_details": ["This package generates the Javascript messages for ROS packages and is used by ", ". "]},
{"url": "https://wiki.ros.org/fanuc_experimental", "package": "fanuc_experimental", "package_summary": ["Experimental packages for Fanuc manipulators within ROS-Industrial."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n ", "This stack is part of the ", " program. It contains experimental packages that will be moved to the ", " package once they've received sufficient testing and review. ", "Packages in distribution branches (ie: ", ") may be expected to be compatible with the corresponding ROS distribution (ie: the ", " branch is usable on Indigo). In the absence of major differences between subsequent ROS releases, the ", " branch may be expected to be compatible with the next release as well (ie: ", " may be used on Jade, as long as no ", " branch exists). ", "Refer to the ", " for more information on building catkin workspaces. ", "See the ", " page for more information. ", "For questions related to the Fanuc support or ROS-Industrial in general, please contact the developers by posting a message in the ", " on ROS Discourse. "], "package_tt": ["$ROS_DISTRO-devel", "indigo-devel", "-devel", "indigo-devel", "jade-devel", "$ROS_DISTRO-devel", "apt-get", "indigo-devel", "apt-get"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/hector_worldmodel_msgs", "package": "hector_worldmodel_msgs", "package_summary": ["hector_worldmodel_msgs is a message package to comes with the hector_worldmodel stack.\n     The messages can be used to send percepts from images (hector_worldmodel_msgs/ImagePercept) or other sources\n     (hector_worldmodel_msgs/PosePercept) to the hector_object_tracker node. The tracker publishes model updates as\n     hector_worldmodel_msgs/Object messages and latches the whole model state as a hector_worldmodel_msgs/ObjectModel message."]},
{"url": "https://wiki.ros.org/freenect_stack", "package": "freenect_stack", "package_summary": ["A libfreenect-based ROS driver for the Microsoft Kinect"], "package_details": ["\n", "\n", "\n", "\n", "\n", ", you need to blacklist the kernel module that gets loaded by default for the Kinect: ", "\n", "\n", "\n", "The freenect_stack ROS driver supports USB 3.0, but users running Ubuntu 12.04 (precise) or older Ubuntu versions will have to patch their Kernel or upgrade to Kernel 3.4.2 or later to get this to work. See ", " for more details. ", "As mentioned in this thread ", ", you need to forward all 3 devices (camera, motor, audio) to the VM for libfreenect to work properly. "], "package_code": ["sudo apt-get install ros-fuerte-freenect-stack", "sudo apt-get install ros-groovy-freenect-stack", "sudo apt-get install ros-hydro-freenect-stack", "sudo modprobe -r gspca_kinect\n", "echo 'blacklist gspca_kinect' | sudo tee -a /etc/modprobe.d/blacklist.conf"]},
{"url": "https://wiki.ros.org/gencpp", "package": "gencpp", "package_summary": ["C++ ROS message and service generators."]},
{"url": "https://wiki.ros.org/fcl", "package": "fcl", "package_summary": ["\n\n     fcl\n\n  "], "package_details": [" Please see ", " ", "\n", "\n", "\n", "\n", "\n", "For more technical details, check out the ", " ", "More collision detection and proximity collision packages developed at UNC Chapel Hill are available in ", ". "], "package_code": ["git clone git://github.com/flexible-collision-library/fcl.git"]},
{"url": "https://wiki.ros.org/fake_joint_launch", "package": "fake_joint_launch", "package_summary": ["Collection of the launch files for fake_joint_driver."]},
{"url": "https://wiki.ros.org/eigen_conversions", "package": "eigen_conversions", "package_summary": ["Conversion functions between:\n      - Eigen and KDL\n      - Eigen and geometry_msgs."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ecl_geometry", "package": "ecl_geometry", "package_summary": ["Any tools relating to mathematical geometry. \n     Primarily featuring polynomials and interpolations."], "package_details": ["\n", "\n", "\n", "If outside ros, you will also need to link to ", ". ", "There are quite a few useful tools also in eigen's geometry module. You can use these directly from eigen or via the ", " package. "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/four_wheel_steering_msgs", "package": "four_wheel_steering_msgs", "package_summary": ["ROS messages for robots using FourWheelSteering."]},
{"url": "https://wiki.ros.org/hrpsys", "package": "hrpsys", "package_summary": ["An ", "-based robot controller. This package is the most tailored for humanoid (dual-arm and/or biped) robots for historical reason.", "hrpsys package does not only wraps but build and installs the code from its mainstream repository (", ").", "The package version number is synchronized to that of mainstream, based on ", ". Its semantics:", "\n    ", "API document is ", ".\n   "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "As a 3rd party package to ROS we need some extra chores to release. Discussed ", ". NOTE for 2 different repositories are involved: "], "package_tt": ["hrpsys", "fkanehiro/hrpsys-base", "catkin_generate_changelog", "package.xml", "catkin_prepare_release"]},
{"url": "https://wiki.ros.org/grizzly_msgs", "package": "grizzly_msgs", "package_summary": ["Common messages for Grizzly."], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"grizzly_msgs\" in rosdoc: /home/rosbot/docs/api/grizzly_msgs/manifest.yaml ", "\n", "Included as well in this package is a helper to assist with using ", " messages in conjunction with Eigen. See the ", ". "]},
{"url": "https://wiki.ros.org/grasping_msgs", "package": "grasping_msgs", "package_summary": ["Messages for describing objects and how to grasp them."]},
{"url": "https://wiki.ros.org/fetch_navigation", "package": "fetch_navigation", "package_summary": ["Configuration and launch files for running ROS navigation on Fetch."]},
{"url": "https://wiki.ros.org/ecl_sigslots", "package": "ecl_sigslots", "package_summary": ["Provides a signal/slot mechanism (in the same vein as qt sigslots, \n     boost::signals etc for intra-process communication. These include \n     some improvements - they do not need a preprocessor, are fully type safe,\n     allow for simple connections via a posix style string identifier \n     and are multithread-safe."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "You will also need to link to ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/euslisp", "package": "euslisp", "package_summary": ["EusLisp is an integrated programming system for the\n  research on intelligent robots based on Common Lisp and\n  Object-Oriented programming"], "package_details": ["\n", "\n", " ", "Documentation is available ", ". ", "Use trac to report ", " or ", ". ", " "]},
{"url": "https://wiki.ros.org/graph_msgs", "package": "graph_msgs", "package_summary": ["ROS messages for publishing graphs of different data types"], "package_details": ["\n", "See ", " for full documentation. "]},
{"url": "https://wiki.ros.org/hokuyo_node", "package": "hokuyo_node", "package_summary": ["A ROS node to provide access to SCIP 2.0-compliant Hokuyo laser range finders (including 04LX)."], "package_details": [" ", "\n", "\n", "\n", "\n", ": ", ": ", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "Image credit: ", " ", "On the UTM-30LX, unless the ", " option is selected, the hokuyo_node will limit the angular range to values that are known to work. The angular range limit depends on the firmware version, and is proportional to the ", " parameter. ", "The ", " and ", " programs can be used to get information about a hokuyo laser scanner. Each of them can be invoked in a human readable way: ", "The ", " program can be used to get the hardware ID of a Hokuyo device given its port. Combined with udev, this allows a consistent device name to be given to each device, even if the order in which they are plugged in varies. The following udev rule should work universally on any ROS system: "], "package_tt": ["cluster", "skip", "intensity", "min_ang", "max_ang", "cluster", "skip", "intensity", "min_ang", "max_ang", "~allow_unsafe_settings", "cluster", "hokuyo_node", "scan", "diagnostics", "~self_test", "~use_rep_117", "bool", "~min_ang", "double", "~max_ang", "double", "~intensity", "bool", "false", "~cluster", "int", "~skip", "int", "~port", "string", "/dev/ttyACM0", "~calibrate_time", "bool", "true", "~frame_id", "string", "laser", "~time_offset", "double", "~allow_unsafe_settings", "bool", "~min_ang_limit", "double", "~min_ang", "~max_ang_limit", "double", "~max_ang", "~min_range", "double", "~max_range", "double", "intensity", "skip", "intensity", "min_ang", "max_ang", "getID", "getFirmwareVersion", "getID"], "package_code": ["$ rosrun hokuyo_node getID /dev/ttyACM0\n", "Device at /dev/ttyACM0 has ID H0807228", "$ rosrun hokuyo_node getID /dev/ttyACM0 --\n", "H0807228", "KERNEL==\"ttyACM[0-9]*\", ACTION==\"add\", ATTRS{idVendor}==\"15d1\", MODE=\"0666\", GROUP=\"dialout\", PROGRAM=\"/opt/ros/hydro/env.sh rosrun hokuyo_node getID %N q\", SYMLINK+=\"sensors/hokuyo_%c\"", "$ ls -l /etc/ros/sensors/base_hokuyo\n", "lrwxrwxrwx 1 root root 28 2010-01-12 15:53 /etc/ros/sensors/base_hokuyo -> /dev/sensors/hokuyo_H0902620\n", "$ ls -l /dev/sensors/hokuyo_H0902620\n", "lrwxrwxrwx 1 root root 10 2010-04-12 12:34 /dev/sensors/hokuyo_H0902620 -> ../ttyACM1"]},
{"url": "https://wiki.ros.org/geometric_shapes", "package": "geometric_shapes", "package_summary": ["This package contains generic definitions of geometric shapes and bodies."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/household_objects_database_msgs", "package": "household_objects_database_msgs", "package_summary": ["The household_objects_database_msgs package"], "package_details": [" This package is ", ". You probably want to use ", " where some have been moved to. See also ", ". ", "This package defines the ROS API for the household objects database. For the API documentation as well as details on the database, see the ", " package page. "]},
{"url": "https://wiki.ros.org/ecl_linear_algebra", "package": "ecl_linear_algebra", "package_summary": ["Ecl frontend to a linear matrix package (currently eigen)."], "package_details": ["\n", "\n", "\n", "Using ros eigen now, but you can also opt to use the internal ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/genmsg", "package": "genmsg", "package_summary": ["Standalone Python library for generating ROS message and service data structures for various languages."], "package_details": ["See the ", " "]},
{"url": "https://wiki.ros.org/eml", "package": "eml", "package_summary": ["This is an implementation of the EtherCAT master protocol for the PR2 robot based on the work done at Flanders' Mechatronics Technology Centre."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/fanuc", "package": "fanuc", "package_summary": ["ROS-Industrial support for Fanuc manipulators (metapackage).", "\n", ": This status indicates that this software is not yet production ready code.  The software has some level of unit-testing.  There are known issues and missing functionality.  The APIs are unstable but unlikely to change drastically.  Use in production systems will likely require modifications including improvements and/or bug fixes.  For more information see the ROS-Industrial software status ", ".", "Contents", " ", "\n", "This repository is part of the ", " program. It currently contains packages that provide nodes for communication with Fanuc industrial robot controllers and urdf models for various Fanuc manipulators. ", "See the ", " metapackage for additional packages, such as ", " configuration packages and ", " plugins. ", "\n", "Not all packages in this repository have been released into ROS Kinetic. Most notably the various ", " configuration and plugins packages have not. All robot support packages, ", " and ", " have been released (and can be installed using ", "). ", "They can however be used after building them from source. Refer to the ", " page for instructions on how to do this. ", "\n", "See the ", " specific version of this page for information on requirements, access to the tutorials, the Troubleshooting page and other information. "], "package_details": ["\n"], "package_tt": ["apt-get", "apt-get", "apt-get", "fanuc_driver", "fanuc_resources", "apt\u00a0install", "fanuc_driver", "fanuc_resources", "apt\u00a0install"], "package_code": ["sudo apt-get install ros-groovy-fanuc", "sudo apt-get install ros-hydro-fanuc", "sudo apt-get install ros-indigo-fanuc"]},
{"url": "https://wiki.ros.org/fetch_driver_msgs", "package": "fetch_driver_msgs", "package_summary": ["Messages for the fetch_drivers package"]},
{"url": "https://wiki.ros.org/ecl_time", "package": "ecl_time", "package_summary": ["Timing utilities are very dependent on the system api provided for their use.\n\tThis package provides a means for handling different timing models. Current support\n\t\n\t- posix rt : complete.\n\t- macosx : posix timers only, missing absolute timers.\n\t- win : none."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "Many of the classes/methods in this package have many characteristics in common with the ", " package - in fact they are almost identical. It was made before ros came about and is kept in the ecl for both legacy reasons and because it is still sometimes useful outside a ros runtime environment (particularly when cross-compiling). ", "If outside ros, you will also need to link to ", ". "], "package_tt": ["clock_gettime", "clock_nanosleep"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/hector_mapping", "package": "hector_mapping", "package_summary": ["hector_mapping is a SLAM approach that can be used without odometry as well as on platforms that exhibit roll/pitch motion (of the sensor, the platform or both).\n    It leverages the high update rate of modern LIDAR systems like the Hokuyo UTM-30LX and provides 2D pose estimates at scan rate of the sensors (40Hz for the UTM-30LX).\n    While the system does not provide explicit loop closing ability, it is sufficiently accurate for many real world scenarios. The system has successfully been used on\n    Unmanned Ground Robots, Unmanned Surface Vehicles, Handheld Mapping Devices and logged data from quadrotor UAVs."], "package_details": ["\n", "\n", "\n", " ", "\n", "available ", " . ", "To use ", ", you need a source of ", " data (for example a Hokuyo UTM-30LX LIDAR or bagfiles). The node uses ", " for transformation of scan data, so the LIDAR does not have to be fixed related to the specified base frame. Odometry data is not needed. "], "package_tt": ["hector_mapping", "hector_mapping", "scan", "syscommand", "map_metadata", "map", "slam_out_pose", "poseupdate", "dynamic_map", "~base_frame", "string", "~map_frame", "string", "~odom_frame", "string", "~map_resolution", "double", "~map_size", "int", "~map_start_x", "double", "~map_start_y", "double", "~map_update_distance_thresh", "double", "~map_update_angle_thresh", "double", "~map_pub_period", "double", "~map_multi_res_levels", "int", "~update_factor_free", "double", "~update_factor_occupied", "double", "~laser_min_dist", "double", "~laser_max_dist", "double", "~laser_z_min_value", "double", "~laser_z_max_value", "double", "~pub_map_odom_transform", "bool", "~output_timing", "bool", "~scan_subscriber_queue_size", "int", "~pub_map_scanmatch_transform", "bool", "~tf_map_scanmatch_transform_frame_name", "string", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_frame", "tf", "map", "odom"], "package_code": ["@INPROCEEDINGS{KohlbrecherMeyerStrykKlingaufFlexibleSlamSystem2011,\n", "  author = {S. Kohlbrecher and J. Meyer and O. von Stryk and U. Klingauf},\n", "  title = {A Flexible and Scalable SLAM System with Full 3D Motion Estimation},\n", "  year = {2011},\n", "  month = {November},\n", "  booktitle = {Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR)},\n", "  organization = {IEEE},\n", "}"]},
{"url": "https://wiki.ros.org/gazebo_ros_pkgs", "package": "gazebo_ros_pkgs", "package_summary": ["Interface for using ROS with the ", " simulator.", " ", " ", "A list of all the changes are available at the ", ". ", ": some ROS specific code could need to be upgraded when upgrading. The instructions are well covered in the ", " "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "gazebo_ros_pkgs is a set of ROS packages that provide the necessary interfaces to simulate a robot in the ", " 3D rigid body simulator for robots. It integrates with ROS using ROS messages, services and dynamic reconfigure. "]},
{"url": "https://wiki.ros.org/humanoid_nav_msgs", "package": "humanoid_nav_msgs", "package_summary": ["Messages and services for humanoid robot navigation"]},
{"url": "https://wiki.ros.org/ecl_formatters", "package": "ecl_formatters", "package_summary": ["The formatters here simply format various input types to a specified\n   text format. They can be used with most streaming types (including both\n   ecl and stl streams)."], "package_details": ["\n", "\n", "\n", "\n", "Typically c/c++ libraries bundle streaming and formatting within the same tool (printf, iostream, ...). This tends to make them cumbersome for simple tasks. The formatter classes in this package externalise the formatting task from the io manipulation (which is usually just (u)char manipulation), This increases the efficiency of low level operations whilst also maintaining type safety. They typically do this by making use of the lower level functionality provided by ", ". ", "The formatter classes can be used standalone, with stl streams or with ", ". ", "If outside of ros, you will also need to link to ", ". ", "Each standard formatter is a template specialisation of the form ", " where the available input types are: "], "package_tt": ["Format<inputType>"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/hector_gazebo_plugins", "package": "hector_gazebo_plugins", "package_summary": ["hector_gazebo_plugins provides gazebo plugins from Team Hector.\n     Currently it contains a 6wd differential drive plugin, an IMU sensor plugin,\n     an earth magnetic field sensor plugin, a GPS sensor plugin and a\n     sonar ranger plugin."], "package_details": ["\n", "\n", "\n", " is a replacement for the ", " plugin in package ", ". It simulates an Inertial Measurement Unit (IMU) affected by Gaussian noise and low-frequency random drift. The orientation returned mimics a simple Attitude and Heading Reference System (AHRS) using the (erroneous) rates and accelerations. ", "\n", "\n", "\n", "\n", " simulates a GNSS (Global Navigation Satellite System) receiver which is attached to a robot. It publishs ", " messages with the robot's position and altitude in WGS84 coordinates. The reference point that corresponds to the origin of the gazebo frame can be configured using the XML parameters. The conversion between gazebo coordinates and WGS84 is done using a simple ", ", which is accurate enough if you do not go far away from the configured reference point and if you do not want to use the plugin for polar regions. ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This plugin simulates a 3-axis magnetometer like PNI Corp's ", ". Like for the GPS plugin, the orientation of the gazebo frame can be specified via the referenceHeading parameter. Declination, inclination and field magnitude have to be configured depending on your location on earth. The default parameters are valid for Europe and North America without magnitude information (normalized vector). Check ", " for exact parameters. ", "The ", " plugin is a ROS controller for gazebo's built-in ray sensor. The value returned as sonar range is the minimum of all rays, as a sonar ranger returns the distance corresponding to the first echo returned from a object within it's field of view. The behavior of this controller plugin depends mainly on the parameters of the sensor it is attached to. ", "The <controller:hector_gazebo_ros_sonar> tag is only valid within a surrounding ", " tag. You should use the macro defined in ", " in package ", " to include a sonar sensor to your model. ", "You can find some more plugins useful for aerial vehicles in package ", ". "], "package_tt": ["GazeboRosImu", "GazeboRosImu", "imu", "imu/calibrate", "imu/set_accel_bias", "imu/set_gyro_bias", "updateRate", "robotNamespace", "bodyName", "topicName", "imu", "serviceName", "[topicName]/calibrate", "accelOffset", "accelDrift", "accelDriftFrequency", "accelGaussianNoise", "rateOffset", "rateDrift", "rateDriftFrequency", "rateGaussianNoise", "yawOffset", "yawDrift", "yawDriftFrequency", "yawGaussianNoise", "rpyOffsets", "accelOffset", "yawOffset", "gaussianNoise", "GazeboRosGps", "fix", "fix_velocity", "updateRate", "robotNamespace", "bodyName", "frameId", "topicName", "fix", "velocityTopicName", "fix_velocity", "referenceLatitude", "referenceLongitude", "referenceHeading", "referenceAltitude", "status", "STATUS_FIX", "service", "SERVICE_GPS", "offset", "drift", "driftFrequency", "gaussianNoise", "velocityOffset", "velocityDrift", "velocityDriftFrequency", "velocityGaussianNoise", "magnetic", "updateRate", "robotNamespace", "bodyName", "topicName", "magnitude", "referenceHeading", "declination", "inclination", "offset", "drift", "driftFrequency", "gaussianNoise", "GazeboRosSonar", "<sensor:ray>", "sonar_sensor.urdf.xacro", "sonar", "updateRate", "robotNamespace", "frameId", "topicName", "sonar", "offset", "drift", "driftFrequency", "gaussianNoise"]},
{"url": "https://wiki.ros.org/gazebo_plugins", "package": "gazebo_plugins", "package_summary": ["Robot-independent Gazebo plugins for sensors, motors and dynamic reconfigurable components."], "package_details": ["\n"], "package_tt": ["Gazebo"]},
{"url": "https://wiki.ros.org/hector_nav_msgs", "package": "hector_nav_msgs", "package_summary": ["hector_nav_msgs contains messages and services used in the hector_slam stack."]},
{"url": "https://wiki.ros.org/ee_cart_imped_msgs", "package": "ee_cart_imped_msgs", "package_summary": ["\n\n     Messages for ee_cart_imped stack.\n\n  "], "package_details": ["See the ", " for the message and action definitions. "]},
{"url": "https://wiki.ros.org/fzi_icl_core", "package": "fzi_icl_core", "package_summary": ["The fzi_icl_core package"]},
{"url": "https://wiki.ros.org/genrb", "package": "genrb", "package_summary": ["ruby ROS message and service generators"]},
{"url": "https://wiki.ros.org/graft", "package": "graft", "package_summary": ["Graft is not yet finished. It's intended to be a full replacement to robot_pose_ekf, including native absolute references, and arbitrary topic configuration. If you try to use Graft now, please note that not all parameters are configured and you will not always see a change in behavior by modifying the parameters."]},
{"url": "https://wiki.ros.org/geometry", "package": "geometry", "package_summary": ["A metapackage for geometry library suite.", ": Since ROS Hydro, tf has been \"deprecated\" in favor of ", ". tf2 is an iteration on tf providing generally the same feature set more efficiently. As well as adding a few new features.", "\n    As tf2 is a major change the tf API has been maintained in its current form. Since tf2 has a superset of the tf features with a subset of the dependencies the tf implementation has been removed and replaced with calls to tf2 under the hood. This will mean that all users will be compatible with tf2. It is recommended for new work to use tf2 directly as it has a cleaner interface. However tf will continue to be supported for through at least J Turtle.\n    "], "package_details": ["\n", "\n", "\n", " ", " ", "\n", "Use GitHub to ", ". [", "]", "\n  "]},
{"url": "https://wiki.ros.org/fetch_moveit_config", "package": "fetch_moveit_config", "package_summary": ["An automatically generated package with all the configuration and launch files for using the fetch_urdf with the MoveIt Motion Planning Framework"]},
{"url": "https://wiki.ros.org/gps_common", "package": "gps_common", "package_summary": ["GPS messages and common routines for use in GPS drivers"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package is a space to stage messages and common GPS-processing routines that are undergoing a standardization process. Its contents will probably be moved into ", " once they've matured. ", "gps_common defines two common messages for GPS drivers to output: ", " and ", ". ", "See ", " for an example of a sender node that uses this package's messages. "], "package_tt": ["utm_odometry_node", "fix", "odom", "~rot_covariance", "double", "~frame_id", "string", "frame_id", "fix", "~child_frame_id", "string"]},
{"url": "https://wiki.ros.org/fetch_gazebo", "package": "fetch_gazebo", "package_summary": ["Gazebo package for Fetch."]},
{"url": "https://wiki.ros.org/genjava", "package": "genjava", "package_summary": ["Java ROS message and service generators."], "package_details": ["\n", "\n", "See the ", " tutorial for more information. "]},
{"url": "https://wiki.ros.org/ecl_utilities", "package": "ecl_utilities", "package_summary": ["Includes various supporting tools and utilities for c++ programming."], "package_details": ["\n"]},
{"url": "https://wiki.ros.org/ee_cart_imped_action", "package": "ee_cart_imped_action", "package_summary": ["\n\n     An action server and interface for the ee_cart_imped_control package.  The EECartImped Controller should always be accessed through this action.\n\n  "], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ee_cart_imped_action is a node that provides an action interface for the ", " node.  Specifically, it allows tracking trajectories that involve force control and sending goals and cancel signals to the controller.  The action can also put constraints on the trajectory and aborts trajectory execution when the constraints are violated.  All interaction with the ", " package should be done through this action interface. ", "For more videos, look at the ", ". ", "Example configuration (from ", "/pr2_arms_cart_imped_controller.yaml): ", "The EECartImpedAction provides an ", " that takes in goals of the type ", " and publishes feedback of the type ", ". ", "In general, interaction with the action server should take place through an action client.  To facilitate this process, we have written C++ and python wrappers around the ", " and included them in the package.  To use the these clients, look at their code APIs ", " ", " or the ", ". "], "package_tt": ["constraints/goal/time", "double", "constraints/goal/", "geometry_msgs/Pose", "constraints/goal/effort", "double", "constraints/trajectory/", "geometry_msgs/Pose", "constraints/trajectory/effort", "double", "ee_cart_imped_action/goal", "ee_cart_imped_action/cancel", "ee_cart_imped_action/feedback", "ee_cart_imped_action/status", "ee_cart_imped_action/result", "state", "command"], "package_code": ["  r_arm_cart_imped_action_node:\n", "    constraints:\n", "      goal:\n", "        time: 0.0\n", "        position:\n", "          x: 0.2\n", "          y: 0.2\n", "          z: 0.2\n", "        orientation:\n", "          x: 0.2\n", "          y: 0.2\n", "          z: 0.2\n", "          w: 0.2\n", "        effort: 0.002\n", "      trajectory:\n", "        effort: -1.0"]},
{"url": "https://wiki.ros.org/gazebo_ros", "package": "gazebo_ros", "package_summary": ["Provides ROS plugins that offer message and service publishers for interfacing with ", " through ROS.\n    Formally simulator_gazebo/gazebo"], "package_details": [": This package replaces ", " in ROS Hydro ", "\n", "See ", " "]},
{"url": "https://wiki.ros.org/fetch_teleop", "package": "fetch_teleop", "package_summary": ["Teleoperation for fetch and freight."]},
{"url": "https://wiki.ros.org/ecl_streams", "package": "ecl_streams", "package_summary": ["These are lightweight text streaming classes that connect to standardised\n     ecl type devices."], "package_details": ["\n", "\n", "\n", "\n", "If outside ros, you will also need to link to ", ". "], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/geographic_msgs", "package": "geographic_msgs", "package_summary": ["ROS messages for Geographic Information Systems."], "package_details": ["\n", "\n", "\n", "\n", "Map points, features and segments all have universally unique identifier names (", "), using ", " messages. ", "Each UUID is stored as an array of unsigned bytes. UUID generation is up to the programmer, but the intent is for matching features within a domain such as Open Street Map to yield the same UUID.  The ", " package provides C++ and Python interfaces for generating them: use the ", " method on a URL constructed from the map source. ", "Here, ", " is the decimal representation of the integer OSM node, way, or ", "relation ID without leading zeros. ", "The ", " service takes a map URL and optional ", ", returning a ", ", ", "The map contains a ", " vector and a ", " vector. Each point or feature is identified by a ", ", and optional ", " properties describing their roles.  ", "Not all way points in a map are drivable by any particular vehicle. Some delimit buildings, rivers, or property boundaries. The ", " message represents drivable paths as a directed graph using a ", " vector and a ", " vector. Each segment represents an edge from one point to another. Unless the path is one-way, another segment will point in the opposite direction. "], "package_tt": ["fromURL()", "http://openstreetmap.org/node/999999", "http://openstreetmap.org/way/999999", "http://openstreetmap.org/relation/999999", "999999"]},
{"url": "https://wiki.ros.org/face_recognition", "package": "face_recognition", "package_summary": ["A ROS package for face recognition in video stream.\nFace recognition is performed using Eigenfaces (also called \"Principal Component Analysis\" or PCA) by utilizing the c++ source code provided by Shervin Emami (http://www.shervinemami.info/faceRecognition.html)"], "package_details": ["\n", "\n", " "], "package_code": ["$ cd ~/rosbuild_ws\n", "$ rosws set face_recognition --git git://github.com/procrob/procrob_functional.git\n", "$ rosws update", "$ rosmake face_recognition", "$ roscd face_recognition\n", "$ rosrun face_recognition Fserver", "$ roscore", "$ roscd gscam/bin\n", "$ rosrun gscam gscam /gscam/image_raw:=/camera/image_raw", "$ rosrun face_recognition Fserver\n", "$ rosrun face_recognition Fclient", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 \"your_name\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 3 \"none\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 \"none\" ", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 \"your_friend's_name\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 0 \"none\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 \"none\" ", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 4 \"none\" ", "$ cd ~/catkin_ws/src\n", "$ git clone https://github.com/procrob/procrob_functional.git --branch catkin\n", "$ cd ~/catkin_ws\n", "$ catkin_make\n", "$ source ~/catkin_ws/devel/setup.bash", "$ roscd face_recognition\n", "$ rosrun face_recognition Fserver", "$ roscore", "$ rosrun usb_cam usb_cam_node usb_cam_node/image_raw:=camera/image_raw _image_height:=<usb_cam_height> _image_width:=<usb_cam_width>", "$ rosrun face_recognition Fserver\n", "$ rosrun face_recognition Fclient", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 \"your_name\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 3 \"none\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 \"none\" ", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 \"your_friend's_name\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 0 \"none\"", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 \"none\" ", "$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 4 \"none\" "]},
{"url": "https://wiki.ros.org/hls_lfcd_lds_driver", "package": "hls_lfcd_lds_driver", "package_summary": ["ROS package for LDS(HLS-LFCD2).\n    The LDS (Laser Distance Sensor) is a sensor sending the data to Host for the simultaneous localization and mapping (SLAM). Simultaneously the detecting obstacle data can also be sent to Host. HLDS(Hitachi-LG Data Storage) is developing the technology for the moving platform sensor such as Robot Vacuum Cleaners, Home Robot, Robotics Lawn Mower Sensor, etc."], "package_details": [" ", "\n", " ", "\n", "\n", "\n", "\n", "360 Laser Distance Sensor 'HLS-LFCD-LDS' (a.k.a. LDS-01) is a 2D laser scanner capable of sensing 360 degrees that collects a set of data around the robot to use for SLAM (Simultaneous Localization and Mapping) and Navigation. The LDS-01 is used for TurtleBot3 Burger, Waffle and Waffle Pi models. It supports USB interface(USB2LDS) and is easy to install on a PC. It supports UART interface for embedded baord. This hls_lfcd_lds_driver package is a driver for LDS-01. "]},
{"url": "https://wiki.ros.org/genpy", "package": "genpy", "package_summary": ["Python ROS message and service generators."]},
{"url": "https://wiki.ros.org/gateway_msgs", "package": "gateway_msgs", "package_summary": ["Messages used by the gateway model."]},
{"url": "https://wiki.ros.org/geneus", "package": "geneus", "package_summary": ["EusLisp ROS message and service generators."]},
{"url": "https://wiki.ros.org/geometry_msgs", "package": "geometry_msgs", "package_summary": ["geometry_msgs provides messages for common geometric primitives\n    such as points, vectors, and poses. These primitives are designed\n    to provide a common data type and facilitate interoperability\n    throughout the system."]},
{"url": "https://wiki.ros.org/handle_detector", "package": "handle_detector", "package_summary": ["ROS package to detect handles."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", " This requires an openni-compatible device, and has only been tested with an Asus Xtion Pro. ", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "If you like this package and use it in your own work, please cite our ", ". ", "For the given point cloud file (", "), the output in rviz should look like this: ", "If you like this package and use it in your own work, please cite our ", ": ", "Andreas ten Pas and Robert Platt. ", " International Symposium on Experimental Robotics (ISER), Morocco, June 2014. "]},
{"url": "https://wiki.ros.org/ee_cart_imped_control", "package": "ee_cart_imped_control", "package_summary": ["\n\n     A force/impedance controller.\n\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The controller is an open-loop Jacobian-transpose force controller.  At every point on the trajectory the desired stiffness or desired wrench is converted into a Cartesian force/wrench vector and ultimately into a joint torque vector using the transpose of the arm's instantaneous Jacobian matrix.  No guarantee is made to the ", " of the applied force/wrench/impedance because this is an open-loop controller.  There is currently not adequate feedback on the arm to determine the applied force/wrench/impedance.  Joint stiction, joint position limits,  motor torque limits, and sometimes the arm configuration (at a singularity, for example) will cause the applied force/wrench/impedance to deviate from the desired values.  Generally, unless the arm is at a singularity or a joint is at its limit, the ", " of the force/wrench/impedance will be correct. ", "This controller should never be used directly; rather, all interaction with it should take place through the ", ". ", "In this video, the PR2 first moves its gripper to the center of its body and then applies a constant force in the ", " direction (towards/away from the robot).  As you can see, the force is light so the human can easily stop the motion.  However, with no intervention, the robot hand will continue to move as far in the ", " direction as it can go.  There is no sense of trying to achieve a goal in this direction.  This type of control is useful if you wish to exert a constant force against something. ", "In this video, the PR2 first moves its gripper to the center of its body and then tries to extend the gripper about 25 cm farther away, but with low stiffness in the ", " direction (towards/away from the robot).  Since the stiffness is low, it is easy for a human to move the hand away from the center of the body in the ", " direction and it returns slowly.  In the ", " and ", " directions, however, where the stiffness is set to the maximum, it takes a lot of strength to displace the gripper and it returns very quickly to its set point. ", "For even more videos, see the ", ". ", "Example configuration (from ", "/pr2_arms_cart_imped_controller.yaml): "], "package_tt": ["root_name", "string", "tip_name", "string", "state", "command"], "package_code": ["r_arm_cart_imped_controller:\n", "  type: EECartImpedControlPlugin\n", "  root_name: torso_lift_link\n", "  tip_name: r_gripper_tool_frame"]},
{"url": "https://wiki.ros.org/gazebo", "package": "gazebo", "package_summary": ["\n\n\n  This ROS package checks out, patches and compiles a pre-release version of the\n    ", "\n  from a WG branch which is based on svn trunk with some local patches and contains wrappers for using Gazebo with ROS.\n  The local patch provides modifications for performance, debug outputs, ROS-specific customizations, capabilities, etc.\n  The less ROS-specific patches are pushed back to the Gazebo repository incrementally as the package evolves.\n\n  This package will update to newer revisions of Gazebo incrementally as new updates are made stable.\n  \n  ", "Contents", " ", "\n", "This is primarily a third party wrapper package with ", ".  ", "\n", "Beginning with C-Turtle (latest releases) distro, gazebo is started as a ROS node, offering the following ROS API interfaces. ", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ") ", "\n", "\n"], "package_details": [" ", ". ", " Also, pure ", " questions (without ", " involved) should be asked on its ", ". "], "package_tt": ["Gazebo", "ROS", "gazebo/set_link_state", "gazebo/set_model_state", "/use_sim_time", "Bool", "/clock", "/clock", "/use_sim_time", "gazebo/link_states", "gazebo/model_states", "gazebo/spawn_urdf_model", "gazebo/spawn_gazebo_model", "gazebo/delete_model", "gazebo/get_model_properties", "gazebo/get_model_state", "gazebo/get_world_properties", "gazebo/get_joint_properties", "gazebo/get_link_properties", "gazebo/get_link_state", "gazebo/get_physics_properties", "gazebo/set_link_properties", "gazebo/set_physics_properties", "gazebo/set_model_state", "gazebo/set_joint_properties", "gazebo/set_link_state", "gazebo/pause_physics", "gazebo/unpause_physics", "gazebo/apply_body_wrench", "gazebo/apply_joint_effort", "gazebo/clear_joint_forces", "gazebo/clear_body_wrenches", "gazebo/set_link_state", "gazebo/set_model_state", "/use_sim_time", "Bool", "/clock", "/clock", "/use_sim_time", "gazebo/link_states", "gazebo/model_states", "gazebo/spawn_urdf_model", "gazebo/spawn_gazebo_model", "gazebo/delete_model", "gazebo/get_model_properties", "gazebo/get_model_state", "gazebo/get_world_properties", "gazebo/get_joint_properties", "gazebo/get_link_properties", "gazebo/get_link_state", "gazebo/get_physics_properties", "gazebo/set_link_properties", "gazebo/set_physics_properties", "gazebo/set_model_state", "gazebo/set_model_configuration", "gazebo/set_joint_properties", "gazebo/set_link_state", "gazebo/pause_physics", "gazebo/unpause_physics", "gazebo/apply_body_wrench", "gazebo/apply_joint_effort", "gazebo/clear_joint_forces", "gazebo/clear_body_wrenches", "gazebo/set_link_state", "gazebo/set_model_state", "/use_sim_time", "Bool", "/clock", "/clock", "/use_sim_time", "gazebo/link_states", "gazebo/model_states", "gazebo/spawn_urdf_model", "gazebo/spawn_gazebo_model", "gazebo/delete_model", "gazebo/get_model_properties", "gazebo/get_model_state", "gazebo/get_world_properties", "gazebo/get_joint_properties", "gazebo/get_link_properties", "gazebo/get_link_state", "gazebo/get_physics_properties", "gazebo/set_link_properties", "gazebo/set_physics_properties", "gazebo/set_model_state", "gazebo/set_model_configuration", "gazebo/set_joint_properties", "gazebo/set_link_state", "gazebo/pause_physics", "gazebo/unpause_physics", "gazebo/apply_body_wrench", "gazebo/apply_joint_effort", "gazebo/clear_joint_forces", "gazebo/clear_body_wrenches", "/clock", "gzserver", "gzserver", "~/set_link_state", "~/set_model_state", "/use_sim_time", "Bool", "/clock", "/clock", "/use_sim_time", "~/link_states", "~/model_states", "~/spawn_urdf_model", "~/spawn_gazebo_model", "~/delete_model", "~/get_model_properties", "~/get_model_state", "~/get_world_properties", "~/get_joint_properties", "~/get_link_properties", "~/get_link_state", "~/get_physics_properties", "~/set_link_properties", "~/set_physics_properties", "~/set_model_state", "~/set_model_configuration", "~/set_joint_properties", "~/set_link_state", "~/pause_physics", "~/unpause_physics", "~/apply_body_wrench", "~/apply_joint_effort", "~/clear_joint_forces", "~/clear_body_wrenches", "/clock", "gzserver", "gzserver", "~/set_link_state", "~/set_model_state", "/use_sim_time", "Bool", "/clock", "/clock", "/use_sim_time", "~/link_states", "~/model_states", "~/spawn_urdf_model", "~/spawn_gazebo_model", "~/delete_model", "~/get_model_properties", "~/get_model_state", "~/get_world_properties", "~/get_joint_properties", "~/get_link_properties", "~/get_link_state", "~/get_physics_properties", "~/set_link_properties", "~/set_physics_properties", "~/set_model_state", "~/set_model_configuration", "~/set_joint_properties", "~/set_link_state", "~/pause_physics", "~/unpause_physics", "~/apply_body_wrench", "~/apply_joint_effort", "~/clear_joint_forces", "~/clear_body_wrenches"]},
{"url": "https://wiki.ros.org/ecto_ros", "package": "ecto_ros", "package_summary": ["A set of generic cells to interact with ROS"]},
{"url": "https://wiki.ros.org/gl_dependency", "package": "gl_dependency", "package_summary": ["This encapsulates the GL dependency for a specific ROS distribution and its Qt version"]},
{"url": "https://wiki.ros.org/frontier_exploration", "package": "frontier_exploration", "package_summary": ["Implementation of ", " for ROS, extending on the existing navigation stack (costmap_2d, move_base).\n  It accepts exploration goals via ", " (Rviz UI provided), sends movement commands to ", "."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", "\n", "\n", "Please check the ", " for common problems, or open an ", " if still unsolved. ", "The best way to try ", " is using the demo provided in ", ", see the ", ". ", "The ", " package provides a ", " layer plugin ", ", and ", " client/server nodes ", " and ", ". ", "The provided nodes can be used to demo the functionality of the costmap layer by executing a frontier exploration task bounded by a user-defined polygon area. Layer ", " can certainly be used for more complex exploration tasks, functionality is exposed through two ", ": ", " and ", ". ", "To run this demo on your host, see ", " section. ", "Also, this video is an example of ", " integrated with ", " (", "). ", "At this point the demo robot should start moving ", ". ", "If you just want to start taking advantage of the functionality of this package, ", " helps. ", "If you like to understand a little more in depth, generally, when launched ", " will spin until it receives an exploration goal. To submit a goal: ", "Once the server receives a goal, it will create the initial exploration map, start processing sensor/costmap data, and issuing ", " action goals. By default, the exploration task will explore all areas within boundary (whether previously visited or not). Sample launch files for several use cases are provided below. ", "When running the action server/client without a global ", " information source, enable the ", " parameter to dynamically resize the map based on the action goal's polygon boundary. Error messages thrown up by ", " regarding the sensor being outside of map bounds will occur when the robot is traveling outside the exploration boundary. These can be safely ignored, and could be suppressed using ", " configuration files. ", "If not using ", " (e.g. running unbounded exploration), make sure the costmap is configured with a large enough height/width. ", "Sample launch file: ", " ", "When running the action server/client with a global ", " information source (either from ", " or ", "), the exploration costmap will match size/resolution to the external map source map loaded by the static layer, so it is important to disable the ", " parameter and that the ", " of the exploration costmap matches that of the external /map. ", "When exploring with ", ", you must also disable ", " to prevent the node from re-exploring known areas. ", "Sample launch file: ", " ", "The ", " node executes exploration actions for any connected clients. It uses a ", " object to keep track of the exploration progress, and creates movement goals for ", " as necessary. "], "package_tt": ["frontier_exploration", "frontier_exploration", "BoundedExploreLayer", "explore_client", "explore_server", "BoundedExploreLayer", "UpdatePolygonBoundary", "GetNextFrontier", "frontier_exploration", "/map", "Marker\u00a0plugin", "Displays\u00a0-->\u00a0Marker\u00a0-->\u00a0Marker\u00a0Topic", "exploration_polygon_marker", "Publish\u00a0Point", "n", "explore_server", "explore_client", "exploration_polygon_marker", "move_base", "/map", "resize_to_boundary", "costmap_2d", "rosconsole", "resize_to_boundary", "/map", "map_server", "gmapping", "resize_to_boundary", "global_frame", "gmapping", "explore_clear_space", "explore_client", "ExploreTask", "explore_server", "explore_server", "explore_server", "/clicked_point", "exploration_polygon_marker", "explore_server", "explore_server", "move_base", "move_base", "~explore_costmap/explore_boundary/update_boundary_polygon", "~explore_costmap/explore_boundary/get_next_frontier", "~explore_costmap", "plugins", "BoundedExploreLayer", "~frequency", "float", "0.0", "move_base", "move_base", "~goal_aliasing", "float", "frequency", "0.0", "~goal_aliasing", "move_base", "sensor_range/2", "~goal_aliasing", "0.0", "frontier_exploration::BoundedExploreLayer", "~frontiers", "pcl::Pointcloud<pcl::PointXYZI>", "~get_next_frontier", "~update_boundary_polygon", "~get_next_frontier", "~resize_to_boundary", "bool", "~update_boundary_polygon", "~frontier_travel_point", "string", "pose", "~get_next_frontier", "pose.position", "closest", "middle", "centroid", "~explore_clear_space", "bool"], "package_code": ["sudo apt-get install ros-$ROS_DISTRO-frontier-exploration ros-$ROS_DISTRO-navigation-stage", "roslaunch navigation_stage move_base_gmapping_5cm.launch\n", "\n", "roslaunch navigation_stage move_base.xml\n", "\n", "roslaunch frontier_exploration global_map.launch"]},
{"url": "https://wiki.ros.org/epos_driver", "package": "epos_driver", "package_summary": ["ROS driver for EPOS controller"], "package_details": ["\n", "\n", "\n", " ", "Package includes C library (", ") to control the EPOS motor control from maxon motor (", ") using a GNU/Linux system and ROS wrapper. "], "package_tt": ["/tf", "/EPOSState", "/MoveTo", "/MoveCycle"]},
{"url": "https://wiki.ros.org/find_object_2d", "package": "find_object_2d", "package_summary": ["The find_object_2d package"], "package_details": ["\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "Simple Qt interface to try OpenCV implementations of SIFT, SURF, FAST, BRIEF and other feature detectors and descriptors. Using a webcam, objects can be detected and published on a ROS topic with ID and position (pixels in the image). This package is a ROS integration of the ", " application. ", "Visit ", " for some tutorials. ", "\n", "Kinect v2 example (you will need ", " package and ", "): "], "package_tt": ["image", "subscribe_depth", "rgb/image_rect_color", "subscribe_depth", "rgb/camera_info", "subscribe_depth", "registered_depth/image_raw", "subscribe_depth", "objects", "objectsStamped", "~subscribe_depth", "bool", "\"true\"", "~gui", "bool", "\"true\"", "~objects_path", "string", "\"\"", "~session_path", "string", "\"\"", "objects_path", "~settings_path", "string", "\"\"", "~object_prefix", "string", "\"object\""], "package_code": ["@misc{labbe11findobject,\n", "   Author = {{Labb\\'{e}, M.}},\n", "   Howpublished = {\\url{http://introlab.github.io/find-object}},\n", "   Note = {accessed YYYY-MM-DD},\n", "   Title = {{Find-Object}},\n", "   Year = 2011\n", "}", " $ roscore &\n", " # Launch your preferred usb camera driver\n", " $ rosrun uvc_camera uvc_camera_node &\n", " $ rosrun find_object_2d find_object_2d image:=image_raw", " $ rosrun find_object_2d print_objects_detected\n", "  (...)\n", "  ---\n", "  Object 6 detected at (271.389282,138.113373)\n", "  Object 7 detected at (115.537971,151.215271)\n", "  ---\n", "  Object 6 detected at (271.389862,138.345398)\n", "  Object 7 detected at (115.422760,163.439835)\n", "  (...)", "$ roslaunch openni_launch openni.launch depth_registration:=true\n", "$ roslaunch find_object_2d find_object_3d.launch\n", "$ rosrun rviz rviz  (for visualisation purpose: set \"fixed_frame\" to \"/camera_link\" and add TF display)", "$ roslaunch kinect2_bridge kinect2_bridge.launch publish_tf:=true\n", "$ roslaunch find_object_2d find_object_3d_kinect2.launch"]},
{"url": "https://wiki.ros.org/genlisp", "package": "genlisp", "package_summary": ["Common-Lisp ROS message and service generators."]},
{"url": "https://wiki.ros.org/fiducial_slam", "package": "fiducial_slam", "package_summary": ["ROS node to build a 3D map of fiducials and estimate robot pose from fiducial transforms"], "package_details": ["\n", "\n", "\n", " ", ", ", " and ", " specify the translation of the fiducial from the origin in meters, and ", ", ", ", and ", " specify its orientation in degrees. The fields ", " and ", " represent how good the pose estimate is considered to be, and how many observations were used to generate it.  ", " is a list of the ids of fiducials that have been observed at the same time as the current fiducial. ", "The coordinate frame used is the ", " frame, which is relative to the floor, so markers of the ceiling will have been rotated.  The supplied launch files specify the map file as ", ". ", " "], "package_tt": ["fiducial_slam", "/fiducial_transforms", "/tf", "/fiducial_pose", "fiducials", "/fiducial_map", "/tf", "~clear_map", "~map_file", "string", "~odom_frame", "string", "tf", "tf", "odom", "base_link", "tf", "map", "odom", "~map_frame", "string", "~base_frame", "string", "tf", "~future_date_transforms", "double", "~publish_6dof_pose", "bool", "z", "~read_only_map", "bool", "~tf_publish_interval", "float", "id\u00a0x\u00a0y\u00a0z\u00a0pan\u00a0tilt\u00a0roll\u00a0variance\u00a0numObservations\u00a0links", "x", "y", "z", "pan", "tilt", "roll", "variance", "numObservations", "links", "map", "~/.ros/slam/map.txt"]},
{"url": "https://wiki.ros.org/gscam", "package": "gscam", "package_summary": ["A ROS camera driver that uses gstreamer to connect to\n    devices such as webcams."], "package_details": ["\n", " is meant as a simple approach to using a webcam in ROS that maximizes compatibility. ", " leverages ", ", a multimedia framework similar to DirectShow. Specifically: Gstreamer can be used to build up multimedia \"pipelines\" consisting of sources, sinks, and filters.  For example: a v4l webcam ", " might be ", " by an upscaler before being sent to the screen (a ", "). Alternately, a mp4 file might act as a source and be filtered into an avi file as a sink. There are many possibilities.  For an overview see: ", ". ", " can attach itself to a specially formatted pipeline. Provided this pipeline is processing RGB video, ", " will rebroadcast the video over as ", " a standard ROS image transport ", " a ROS Camera. Since Gstreamer is compatibile with almost every video capture standard under Linux (and many on OSX), ", " makes ROS defacto compatible with almost every Linux webcam or video system available. Moreover, because there are a number of Gstreamer filters for processing video (e.g. white-balancing, cropping, etc.) gscam allows for a more advanced video processing even with cheaper webcams. ", "\n", " expects an environmental variable, ", ", to contain a gstreamer ", "pipeline definition for it to launch. There is one important restriction: ", "\n", " is fully compatible with the ROS Camera interface and can be calibrated to provided rectified images. For details, see the appropriate ROS documentation on the ", " wiki page. ", "\n", "\n", "\n", "\n", "If you see a \"Processing...\" message, it means ", " is happily publishing. ", "You need to set the TF frame via the ", " service described above. "], "package_tt": ["gscam", "gscam", "gscam", "gscam", "gscam", "gscam", "GSCAM_CONFIG", "gscam", "/dev/video2", "gscam", "gscam", "gst-inspect-0.10", "GSCAM_CONFIG", "gscam", "image_raw", "camera_info", "set_camera_info", "set_camera_info"], "package_code": ["roscd gscam\n", "cd bin\n", "export GSCAM_CONFIG=\"v4l2src device=/dev/video2 ! video/x-raw-rgb,framerate=30/1 ! ffmpegcolorspace\"\n", "rosrun gscam gscam", "<launch>\n", "  <!-- Set this to your camera's name -->\n", "  <arg name=\"cam_name\" value=\"creative_cam\" />\n", "\n", "  <!-- Start the GSCAM node -->\n", "  <env name=\"GSCAM_CONFIG\" value=\"v4l2src device=/dev/video0 ! video/x-raw-yuv,framerate=30/1,width=640,height=480 ! ffmpegcolorspace \" />\n", "  <node pkg=\"gscam\" type=\"gscam\" name=\"$(arg cam_name)\">\n", "    <param name=\"camera_name\" value=\"$(arg cam_name)\" />\n", "    <param name=\"camera_info_url\" value=\"package://localcam/calibrations/${NAME}.yaml\" />\n", "    <remap from=\"camera/image_raw\" to=\"$(arg cam_name)/image_raw\" />\n", "  </node>\n", "\n", "  <!-- Provide rectification -->\n", "  <node pkg=\"image_proc\" type=\"image_proc\" name=\"creative_image_proc\"\n", "        ns=\"$(arg cam_name)\" />\n", "\n", "  <!-- View the raw and rectified output -->\n", "  <node pkg=\"image_view\" type=\"image_view\" name=\"creative_view\" >\n", "    <remap from=\"image\" to=\"/$(arg cam_name)/image_raw\" />\n", "  </node>\n", "    \n", "  <node pkg=\"image_view\" type=\"image_view\" name=\"creative_view_rect\" >\n", "    <remap from=\"image\" to=\"/$(arg cam_name)/image_rect_color\" />\n", "  </node>\n", "</launch>", "MessageFilter [target=/map ]: Discarding message from [/gscam_publisher] due to empty frame_id.  This message will only print once."]},
{"url": "https://wiki.ros.org/gazebo_msgs", "package": "gazebo_msgs", "package_summary": ["Message and service data structures for interacting with Gazebo from ROS."], "package_details": ["\n", "See ", " "]},
{"url": "https://wiki.ros.org/ecl_threads", "package": "ecl_threads", "package_summary": ["This package provides the c++ extensions for a variety of threaded \n     programming tools. These are usually different on different \n     platforms, so the architecture for a cross-platform framework\n     is also implemented."], "package_details": ["\n", "\n", "\n", "\n", "If outside ros, you will also need to link to ", ". "], "package_tt": ["Mutex", "Thread", "Threadable"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "find_package(catkin REQUIRED COMPONENTS\n", "   ecl_threads\n", "   # other dependencies ...\n", ")"]},
{"url": "https://wiki.ros.org/fs100_motoman", "package": "fs100_motoman", "package_summary": ["The fs100_motoman package. Contains a node for connect and streaming to a FS100 controller."], "package_details": ["\n", "\n", "\n", "\n", "\n", "Source: ", " ", "The fs100_motoman package was created together with the Technical University of Denmark (DTU), Institute for Automation and Control (", "). The reason for this package was to provide an easy way to continuously stream a trajectory to the FS100 controller, to enable real-time sensor based control. ", "Use github to report a bug and view current issues. ", " "], "package_tt": ["fs100_motoman/mh5l/joint_target", "fs100_motoman/mh5l/joint_state", "fs100_motoman/mh5l/reset_trajectory", "IP", "string"], "package_code": ["sudo apt-get install ros-hydro-fs100-motoman"]},
{"url": "https://wiki.ros.org/geometry_tutorials", "package": "geometry_tutorials", "package_summary": ["Metapackage of geometry tutorials ROS."], "package_details": ["\n", "\n", " ", "See ", ". "]},
{"url": "https://wiki.ros.org/freenect_launch", "package": "freenect_launch", "package_summary": ["Launch files for freenect_camera to produce rectified, registered\n    or disparity images.  Also produce point clouds and registered\n    point clouds.  Based on the openni_launch package."], "package_details": [" ", "\n", "\n", " contains a few modifications from ", " apart from running the libfreenect based driver. These are documented below. ", "\n", "\n", "This package contains launch files for using a Microsoft Kinect using the libfreenect library. This folder replicates the API offered by ", " in an effort to maintain maximum compatibility with the OpenNI driver. Differences are mentioned below. ", "To use this package, please refer to ", " and ", " documentation. The migration guide to/from the OpenNI driver is documented ", ". ", "There are a few additional launch files in ", " that demonstrate running a different constellation of nodelets. This is useful for launching the minimum set of required processing nodelets, as well as avoid unnecessary warnings during launch. For example: "], "package_tt": ["freenect_launch", "freenect.launch", "openni.launch", "freenect.launch\u00a0supports", "freenect-ns.launch", "freenect.launch", "freenect-diagnostics.launch", "freenect.launch", "freenect-debug.launch", "freenect_launch", "freenect-xyz.launch", "/camera/depth/points", "freenect-registered-xyzrgb.launch", "/camera/depth_registered/points"], "package_code": ["roslaunch freenect_launch freenect.launch"]},
{"url": "https://wiki.ros.org/geodesy", "package": "geodesy", "package_summary": ["Python and C++ interfaces for manipulating geodetic coordinates."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "All C++ symbols defined by this package reside in the ", " namespace.  ", "This is the base type for communicating geodetic information between ROS nodes, using ", " and  ", " messages. ", "All Python modules defined by this package reside in the ", " namespace.  "]}
]
