W0,https://wiki.ros.org/rosbridge_server,Wiki,rosbridge_server,"A WebSocket interface to rosbridge.

Rosbridge server is part of the rosbridge_suite of packages, providing a  transport layer. A  is a low-latency, bidirectional communication layer between clients (web browsers) and servers. By providing a  connection, rosbridge server allows webpages to talk ROS using the rosbridge protocol. Rosbridge server creates a  connection and passes any JSON messages from the  to rosbridge_library, so rosbridge library can convert the JSON strings into ROS calls. The reverse also happens, with rosbridge library converting any ROS responses into JSON, then passing it to rosbridge server to send over the  connection. Check out  for a  library that talks to rosbridge server over . While rosbridge server provides a  connection, rosbridge itself is not tied to any particular transport layer. You could add a rosbridge TCP package or node, for example, that communicates with rosbridge using TCP sockets. No  or browsers needed.  for these additional transport layers are encouraged! "
W1,https://wiki.ros.org/jsk_rqt_plugins,Wiki,jsk_rqt_plugins,The jsk_rqt_plugins packageDoc:  
W2,https://wiki.ros.org/ethercat_trigger_controllers,Wiki,ethercat_trigger_controllers,"Controllers to operate the digital output of the motor controller
    boards and the projector board. This package has not been reviewed and
    should be considered unstable.
"
W3,https://wiki.ros.org/rqt_joint_trajectory_controller,Wiki,rqt_joint_trajectory_controller,"Graphical frontend for interacting with joint_trajectory_controller instances.
 Graphical frontend for interacting with  instances. joint_trajectory_controller"
W4,https://wiki.ros.org/zeroconf_msgs,Wiki,zeroconf_msgs,General ros communications used by the various zeroconf implementations.Messages supporting the  and  stacks. 
W5,https://wiki.ros.org/asr_msgs,Wiki,asr_msgs,"This package contains all messages that are particular to our Active Scene Recognition - Framework at 
		Humanoids and Intelligence Systems Lab (HIS), Karlsruhe Institute of Technology (KIT).
	  These messages make up the interfaces between the different collaborating components of this system.
	  They are of critical importance and structured by the ROS communication capabilities. 

 "
W6,https://wiki.ros.org/pmb2_controller_configuration_gazebo,Wiki,pmb2_controller_configuration_gazebo,"Gazebo-specifig launch files and scripts needed to configure
    the controllers of the PMB2 robot in simulation."
W7,https://wiki.ros.org/ocl,Wiki,ocl,"Orocos component library
    This package contains standard components for the Orocos Toolchain

Read the  for detailed information on how to use the deployer. rosrun ocl deployer-gnulinux -ldebug -s deploy.ops












<?xml version=""1.0"" encoding=""UTF-8""?>                                                                                                                            
  <!DOCTYPE properties SYSTEM ""cpf.dtd"">                                                                                                                            
    <properties>
     <simple name=""init_file"" type=""string""><description>Name of the initialisation file</description><value>init.xml</value></simple>
    </properties>   <launch>                                                                                                                                                 
   <node name=""myNodeName"" pkg=""ocl"" type=""deployer-gnulinux"" launch-prefix=""konsole -e"" args=""-ldebug -s $(find myRosPkg)/deploy.ops --"">
   </node>           
  </launch> "
W8,https://wiki.ros.org/lanelet2_routing,Wiki,lanelet2_routing,Routing module for lanelet2
W9,https://wiki.ros.org/multisense,Wiki,multisense,multisense catkin driver
W10,https://wiki.ros.org/pr2_gripper_sensor_controller,Wiki,pr2_gripper_sensor_controller,"The pr2_gripper_sensor_controller package is a real-time controller that integrates signals from the PR2 hand-mounted accelerometer and finger-mounted pressure sensors with motor control of the gripper joint to do highly responsive sensing and low-latency closed-loop control.
  



The  package is a real-time controller that is intended to support the  interface and allow it to: The  package continuously publishes several messages defined in the  package, which are intended for use in the action servers of  and not for normal user usage, but can provide useful information for more advanced users. The   two important PR2 sensors to be available: A simple test to check if these sensors exist is to run the command  and check to make sure the  and  fields are present. If you are not using a prebuilt installation you may have to compile the  package. Since the  package is a real-time controller, it is important to remember to compile the package  launching your robot, otherwise it will fail to register and load correctly with . Compiling can be done simply by typing: Or by building any of the higher-level packages (such as  which depend on this package)  launching your robot. See the  launch instructions, which will automatically launch the  package for both the left and right PR2 grippers. Specific left/right launch files are available in the  package, but it is unecessary for the end user to launch them independently. rostopic list/accelerometer/pressurerosmake pr2_gripper_sensor_controller"
W11,https://wiki.ros.org/combined_robot_hw,Wiki,combined_robot_hw,"Combined Robot HW class.
 High-resolution version can be found . A short summary of CombinedRobotHW can be found in  ROScon 2016 talk. "
W12,https://wiki.ros.org/turtlebot3_description,Wiki,turtlebot3_description,"3D models of the TurtleBot3 for simulation and visualization 

turtlebot3_(model).urdf.xacro<turtlebot3_(model)/>turtlebot3_(model).gazebo.xacro<turtlebot3_(model)_sim/>common_properties.xacro"
W13,https://wiki.ros.org/pluginlib,Wiki,pluginlib,"The pluginlib package provides tools for writing and dynamically loading plugins using the ROS build infrastructure.
    To work, these tools require plugin providers to register their plugins in the package.xml of their package.polygon_interface_packagerectangle_plugintriangle_pluginrectangle_plugintriangle_pluginpolygon_interface_package.cpppluginlibclass_list_macros.hclass_list.cpplibrectanglerectangle_pluginrectangle_plugin.xmlexportrectangle_pluginexportrectangle_pluginmanifest.xmlClassLoaderclass_loader.hClassLoaderrectanglepolygonpolygon_interfacerectangle_plugintriangle_pluginrectangle_plugintriangle_pluginpolygon_interfacePLUGINLIB_EXPORT_CLASSclass_list.cpplibrectanglerectangle_pluginrectangle_plugin.xmlexportrectangle_pluginexportrectangle_plugincatkin/package.xmlClassLoaderclass_loader.hClassLoaderrectanglepolygonPLUGINLIB_REGISTER_CLASSPLUGINLIB_DECLARE_CLASSPLUGINLIB_EXPORT_CLASS





<library path=""lib/librectangle"">
  <class name=""example_pkg/Rectangle"" type=""rectangle_namespace::Rectangle"" base_class_type=""polygon_namespace::Polygon"">
  <description>
  This is a rectangle plugin
  </description>
  </class>
</library><export>
  <polygon_interface_package plugin=""${prefix}/rectangle_plugin.xml"" />
</export>  <depend package=""polygon_interface_package"" />rospack plugins --attrib=plugin nav_core






















<library path=""lib/librectangle"">
  <class type=""rectangle_namespace::Rectangle"" base_class_type=""polygon_namespace::Polygon"">
  <description>
  This is a rectangle plugin
  </description>
  </class>
</library><export>
  <polygon_interface plugin=""${prefix}/rectangle_plugin.xml"" />
</export>  <build_depend>polygon_interface</build_depend>
  <run_depend>polygon_interface</run_depend>rospack plugins --attrib=plugin nav_core

















 plugin_macro_update<library path=""lib/librectangle"">
  <class name=""rviz/Rectangle"" type=""rectangle_namespace::Rectangle"" base_class_type=""polygon_namespace::Polygon"">
  <description>
  This is a rectangle plugin
  </description>
  </class>
</library>"
W14,https://wiki.ros.org/lanelet2_projection,Wiki,lanelet2_projection,Lanelet2 projection library for lat/lon to local x/y conversion
W15,https://wiki.ros.org/interactive_marker_tutorials,Wiki,interactive_marker_tutorials,The interactive_marker_tutorials packageSee  for the tutorials based on this package. 
W16,https://wiki.ros.org/rosauth,Wiki,rosauth,"Server Side tools for Authorization and Authentication of ROS Clients



The rosbridge server is responsible for calling the /authenticate service on a request of the client. This can be done using the authenticate method of roslibjs:  authenticate~allowed_time_deltafloat~secret_file_locationstringroslaunch rosbridge_server rosbridge_websocket.launch authenticate:=trueecho ""1234567890abcdef"" > /tmp/secret.txt  # Example secret
rosrun rosauth ros_mac_authentication _secret_file_location:=/tmp/secret.txt _allowed_time_delta:=-1echo -n ""1234567890abcdefclientdestrand0level0"" | sha512sumrosservice call /authenticate ""mac: '19d9d2166799f1ffd6fee6379f957502aff8716bfebc8cc8b3bac57ade14441bb9678be89d0a7eec9c81291f854d754d7a4de2278bede56f162c2faeb468c68a'
client: 'client'
dest: 'dest'
rand: 'rand'
t: {secs: 0, nsecs: 0}
level: 'level'
end: {secs: 0, nsecs: 0}""authenticated: Truelet secret = 'myawesomesecret1'
let dest = this.url
let rand = randomString(10)
let time = new Date().getTime() / 1000
let timeEnd = time + 1000
let level = ""admin""
let mac = sha512(secret + client.getUA() + dest + rand + parseInt(time).toString() + level + parseInt(timeEnd).toString())  // using sha512 library js-sha512 and client library clientjs
this.authenticate(mac, client.getUA(), dest, rand, time, level, timeEnd)  // method from roslibjs"
W17,https://wiki.ros.org/rc_genicam_api,Wiki,rc_genicam_api,"GenICam/GigE Vision Convenience Layer.

      This package combines the Roboception convenience layer for images with the
      GenICam reference implementation and a GigE Vision transport layer. It is a
      self contained package that permits configuration and image streaming of
      GenICam / GigE Vision 2.0 compatible cameras like the Roboception rc_visard.

      This package also provides some tools that can be called from the command line
      for discovering cameras, changing their configuration and streaming images.
      Although the tools are meant to be useful when working in a shell or in a
      script, their main purpose is to serve as example on how to use the API for
      reading and setting parameters, streaming and synchronizing images.

      See LICENSE.md for licensing terms of the different parts.










 All three options can be seen in the output of . If the given ID contains a colon (i.e. ), the part before the (first) colon is interpreted as interface ID and the part after the first colon is treated as device ID. This is the format that  shows. A device with the given ID is only sought on the specified interface. This can be useful if there are several ways to reach a device from a host computer, e.g. via wireless and wired network connection, but a certain connection type (e.g. wired) is preferred due to higher bandwidth and lower latency. Examples: ,  or  The  script performs some simple checks and should be run while or after streaming images via GigE Vision. These values can be changed during runtime with  or written to  for persistence across reboots. If the number of UDP  increases while streaming, increasing the socket receive buffer size usually fixes the problem. Check the   or Check with  and increase the values if needed: :_00_14_2d_2c_6e_bbrc_visard:my:name02911931gc_config -l:gc_config -leth0:00_14_2d_2c_6e_bbeth1:02911931wlan0:rc_visardnet_perf_check.shsysctl/etc/sysctl.confRcvbufErrorsRcvbufErrors withnet_perf_check.shnet_perf_check.sh  gc_stream <ID> ComponentSelector=Intensity ComponentEnable=1 ComponentSelector=Disparity ComponentEnable=0 n=10./net_perf_check.sh --helpsudo ifconfig eth0 mtu 9000netstat -us | grep RcvbufErrorssudo sysctl -w net.core.rmem_max=33554432sudo sysctl -w net.core.netdev_max_backlog=2000
sudo sysctl -w net.core.netdev_budget=600"
W18,https://wiki.ros.org/nav_2d_utils,Wiki,nav_2d_utils,A handful of useful utility functions for nav_core2 packages. 
W19,https://wiki.ros.org/rqt_py_console,Wiki,rqt_py_console,rqt_py_console is a Python GUI plugin providing an interactive Python console.
W20,https://wiki.ros.org/jsk_pr2_startup,Wiki,jsk_pr2_startup,"

     jsk_pr2_startup

  "
W21,https://wiki.ros.org/sick_scan,Wiki,sick_scan,"A ROS driver for the SICK TiM and SICK MRS series of laser scanners.
    This package is based on the original sick_tim-repository of Martin Günther et al.




 ROS packages for SICK laser scaners. This driver provides the measurement data as  and  data. The use of  data is recommended. The  data should only be used for debugging purposes. They provide the raw data for each scan plane in a different coordinate frame. Due to the geometry of the scanning planes of the MRS1104 there is no coordinate transformation between the scan planes that can be described by  messages, therefore no  messages are published. That is why the  data should be used. nc -z -v -w5 $SCANNERIPADDRESS 2112source /opt/ros/<rosdistro>/setup.bash
mkdir -p ~/ros_catkin_ws/src/
cd ~/ros_catkin_ws/src/
git clone -b devel --single-branch git://github.com/SICKAG/sick_scan.git
cd ..
catkin_make
source ~/ros_catkin_ws/install/setup.bash roslaunch sick_scan sick_mrs_1xxx.launch rviz rviz"
W22,https://wiki.ros.org/moveit_ros_benchmarks,Wiki,moveit_ros_benchmarks,Enhanced tools for benchmarks in MoveIt!
W23,https://wiki.ros.org/novatel_msgs,Wiki,novatel_msgs,"ROS messages which represent raw Novatel SPAN data.

These messages are the low-level binary interface between a NovAtel SPAN unit and ROS. Typical use cases should not require working with these messages. Please see the related package, . "
W24,https://wiki.ros.org/moveit_planners_chomp,Wiki,moveit_planners_chomp,The interface for using CHOMP within MoveIt!
W25,https://wiki.ros.org/mrpt_map,Wiki,mrpt_map,"The mrpt_map is able to publish a mrpt map as ros occupancy grid like the map_server


The  node publishes (static, prebuilt) metric maps stored in MRPT formats:  or .  Most ROS packages expect the map to be a unique occupancy grid map. This node supports those simple maps, plus all other . mrpt_mapmap~map_filemap_metadata~map_filestatic_map~ini_filestring""map.ini""~map_filestring.simplemap.gridmap~debugbool~frequencydouble~frame_idstring"
W26,https://wiki.ros.org/rosflight_pkgs,Wiki,rosflight_pkgs,ROS interface for the ROSflight autpilot stack
W27,https://wiki.ros.org/velodyne_laserscan,Wiki,velodyne_laserscan,Extract a single ring of a Velodyne PointCloud2 and publish it as a LaserScan message
W28,https://wiki.ros.org/swri_image_util,Wiki,swri_image_util,swri_image_util
W29,https://wiki.ros.org/pr2_mechanism_controllers,Wiki,pr2_mechanism_controllers,"The pr2_mechanism_controllers package contains realtime
    controllers that are meant for specific mechanisms of the PR2.

At the present time, the controllers in this stack are not intended for direct use. The controllers should be used via their  interfaces, e.g., , , , and .    The  library is stable. "
W30,https://wiki.ros.org/qt_gui_cpp,Wiki,qt_gui_cpp,"qt_gui_cpp provides the foundation for C++-bindings for qt_gui and creates bindings for every generator available.
    At least one specific binding must be available in order to use C++-plugins."
W31,https://wiki.ros.org/agni_tf_tools,Wiki,agni_tf_tools,"This package provides a gui program as well as a rviz plugin to publish static transforms.
  Both support the transformation between various Euler angle representations.
  The rviz plugin also allows to configure the transform with an interactive marker. 


 Dependent on the order of rotation axes, there are different sets of Euler angles. One common set is roll-pitch-yaw (the default in ROS), which corresponds to rotations about x, y, and z axes w.r.t. the fixed frame. To specify Euler angles w.r.t. a different set or order of axes, simply specify the desired order instead of rpy. For example,  will rotate by 30° about the y axis, then by 50° about the x axis, and finally by 70° about the y axis. In order to transform a given Euler angle representation into another one, simply enter the desired axes order - replacing the whole text field including the angular values. To specify whether rotations should be performed w.r.t. the tatic or the moving / otationg frame (corresponding to left resp. right matrix multiplication), it's possible to prefix the axes order by """" or """". Omitting the prefix, corresponds to """" or right matrix multiplication. The rviz plugin also supports frame transformations. If you want to compute the entered transform w.r.t. another parent frame, simply enable the checkbox """" and subsequently change the . If the checkbox is not ticked, changing the parent frame doesn't change the relative transform, but moves the interactive marker. The entered transform is published as soon as a empty frame names are provided and the """" checkbox is enabled. yxz: 30, 50, 70adapt transformationparent framepublish transform"
W32,https://wiki.ros.org/wfov_camera_msgs,Wiki,wfov_camera_msgs,Messages related to the Point Grey camera driver.
W33,https://wiki.ros.org/py_trees_ros,Wiki,py_trees_ros,"Ros extensions and behaviours for py_trees.
 
Get started at the  for the project. "
W34,https://wiki.ros.org/ps3joy,Wiki,ps3joy,"Playstation 3 SIXAXIS or DUAL SHOCK 3 joystick driver.
    Driver for the Sony PlayStation 3 SIXAXIS or DUAL SHOCK 3
    joysticks. In its current state, this driver is not compatible
    with the use of other Bluetooth HID devices. The driver listens
    for a connection on the HID ports, starts the joystick
    streaming data, and passes the data to the Linux uinput device
    so that it shows up as a normal joystick.


 is known to work with Ubuntu 12.10, Ubuntu 12.04, Ubuntu Jaunty 9.04, and Ubuntu Hardy 8.04. To make it work with Ubuntu Karmic 9.10, you will have to follow these . 



 
 

      



    also exposes the joystick's three-axis accelerometer and the single-axis gyroscope: 
This driver exists because Linux's native support for the PS3 joystick is unreliable, and does not give access to the joystick's accelerometers and gyroscope. This driver solves both problems. However in its current form, . In future releases, we plan to allow first non-HID and later any bluetooth device to coexist with this driver. If you have a need for such functionality, let it be known. The  is a good starting point for how to use this package. This is the same for  and . Or you could write a sudo script for sourcing ROS and starting ps3joy_node; I use  to automatically start the  after booting and a ROS-check. There is . With these #defines you can access the PS3 buttons within the  without worrying about magic numbers: ps3joy.pysudojoy/set_feedback/diagnosticsps3joy.pyps3joy_node.py--inactivity-timeout--no-disable-bluetoothdps3joy.py--redirect-outputps3joy.py--continuous-outputps3joy_nodesudo apt-get install ros-%ROSDISTRO%-joystick-drivers
sudo apt-get install ros-indigo-joystick-drivers       (ROS Indigo for example)$ ./ps3joy.py --help
usage: ps3joy.py [--inactivity-timeout=<n>] [--no-disable-bluetoothd] [--redirect-output]=<f>
<n>: inactivity timeout in seconds (saves battery life).
<f>: file name to redirect output to.
Unless --no-disable-bluetoothd is specified, bluetoothd will be stopped..../ps3joy$ sudo bash -c ""source /home/myself/.bashrc; ./scripts/ps3joy_node.py --inactivity-timeout=300""rostopic pub  /joy/set_feedback sensor_msgs/JoyFeedbackArray '[ [0, 3, 1], [1, 1, 0.8] ]'// note on plain values:
// buttons are either 0 or 1
// button axes go from 0 to -1
// stick axes go from 0 to +/-1

#define PS3_BUTTON_SELECT            0
#define PS3_BUTTON_STICK_LEFT        1
#define PS3_BUTTON_STICK_RIGHT       2
#define PS3_BUTTON_START             3
#define PS3_BUTTON_CROSS_UP          4
#define PS3_BUTTON_CROSS_RIGHT       5
#define PS3_BUTTON_CROSS_DOWN        6
#define PS3_BUTTON_CROSS_LEFT        7
#define PS3_BUTTON_REAR_LEFT_2       8
#define PS3_BUTTON_REAR_RIGHT_2      9
#define PS3_BUTTON_REAR_LEFT_1       10
#define PS3_BUTTON_REAR_RIGHT_1      11
#define PS3_BUTTON_ACTION_TRIANGLE   12
#define PS3_BUTTON_ACTION_CIRCLE     13
#define PS3_BUTTON_ACTION_CROSS      14
#define PS3_BUTTON_ACTION_SQUARE     15
#define PS3_BUTTON_PAIRING           16

#define PS3_AXIS_STICK_LEFT_LEFTWARDS    0
#define PS3_AXIS_STICK_LEFT_UPWARDS      1
#define PS3_AXIS_STICK_RIGHT_LEFTWARDS   2
#define PS3_AXIS_STICK_RIGHT_UPWARDS     3
#define PS3_AXIS_BUTTON_CROSS_UP         4
#define PS3_AXIS_BUTTON_CROSS_RIGHT      5
#define PS3_AXIS_BUTTON_CROSS_DOWN       6
#define PS3_AXIS_BUTTON_CROSS_LEFT       7
#define PS3_AXIS_BUTTON_REAR_LEFT_2      8
#define PS3_AXIS_BUTTON_REAR_RIGHT_2     9
#define PS3_AXIS_BUTTON_REAR_LEFT_1      10
#define PS3_AXIS_BUTTON_REAR_RIGHT_1     11
#define PS3_AXIS_BUTTON_ACTION_TRIANGLE  12
#define PS3_AXIS_BUTTON_ACTION_CIRCLE    13
#define PS3_AXIS_BUTTON_ACTION_CROSS     14
#define PS3_AXIS_BUTTON_ACTION_SQUARE    15
#define PS3_AXIS_ACCELEROMETER_LEFT      16
#define PS3_AXIS_ACCELEROMETER_FORWARD   17
#define PS3_AXIS_ACCELEROMETER_UP        18
#define PS3_AXIS_GYRO_YAW                19"
W35,https://wiki.ros.org/libsiftfast,Wiki,libsiftfast,Library to compute SIFT features
W36,https://wiki.ros.org/yocs_velocity_smoother,Wiki,yocs_velocity_smoother,"Bound incoming velocity messages according to robot velocity and acceleration limits.Contents 


Take a look to the  to learn how yocs_velocity_smoother works together with other components to build up a safe and flexible control system. 
By robot feedback we mean the current velocity at which robot ""thinks"" he moves now. The two common ways to know this are: Option 0 of course ignores any robot feedback. There are some reasons to use robot feedback. The two we face more often are: So the recommended option is 2 in most cases (if there aren't concurrent controllers it will have no effect), letting option 1 just for special situations. If people don't find it useful at all, we will probably remove.  ~raw_cmd_vel~odometry~smooth_cmd_vel~accel_lim_vdouble~accel_lim_wdouble~speed_lim_vdouble~speed_lim_wdouble~decel_factordouble~frequencydouble~raw_cmd_vel~odometry~robot_cmd_vel~smooth_cmd_vel~accel_lim_vdouble~accel_lim_wdouble~speed_lim_vdouble~speed_lim_wdouble~decel_factordouble~frequencydouble~robot_feedbackint~raw_cmd_vel~odometry~robot_cmd_vel~smooth_cmd_vel~accel_lim_vdouble~accel_lim_wdouble~speed_lim_vdouble~speed_lim_wdouble~decel_factordouble~frequencydouble~robot_feedbackint"
W37,https://wiki.ros.org/map_msgs,Wiki,map_msgs,"This package defines messages commonly used in mapping packages.This package provides a preliminary implementation of messages defined in the work-in-progress REP 129. For more information, please have a look at the . "
W38,https://wiki.ros.org/julius,Wiki,julius,julius: Open-Source Large Vocabulary CSR Engine (http://julius.sourceforge.jp/index.php)
W39,https://wiki.ros.org/controller_manager_msgs,Wiki,controller_manager_msgs,Messages and services for the controller manager.
W40,https://wiki.ros.org/rcdiscover,Wiki,rcdiscover,This package contains tools for the discovery of Roboception devices via GigE Vision. rcdiscoverrcdiscover-gui
W41,https://wiki.ros.org/urg_c,Wiki,urg_c,The urg_c package
W42,https://wiki.ros.org/ros_core,Wiki,ros_core,"A metapackage to aggregate the packages required to use publish / subscribe, services, launch files, and other core ROS concepts."
W43,https://wiki.ros.org/turtlebot3,Wiki,turtlebot3,"ROS packages for the Turtlebot3 (meta package) 
  is a new generation mobile robot that is modular, compact and customizable. Let’s explore ROS and create exciting applications for education, research and product development. The goal of  is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and  can be customized in various ways.  is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. 



TurtleBot3TurtleBot3TurtleBot3"
W44,https://wiki.ros.org/rqt_gui_py,Wiki,rqt_gui_py,rqt_gui_py enables GUI plugins to use the Python client library for ROS.
W45,https://wiki.ros.org/pr2eus_openrave,Wiki,pr2eus_openrave,"

     pr2eus_openrave

  

 and  Documentation is available . Use trac to report  or .  "
W46,https://wiki.ros.org/mbf_costmap_core,Wiki,mbf_costmap_core,"This package provides common interfaces for navigation specific robot actions. It contains the CostmapPlanner, CostmapController and CostmapRecovery interfaces. The interfaces have to be implemented by the plugins to make them available for Move Base Flex using the mbf_costmap_nav navigation implementation. That implementation inherits the mbf_abstract_nav implementation and binds the system to a local and a global costmap."
W47,https://wiki.ros.org/moveit_planners_ompl,Wiki,moveit_planners_ompl,MoveIt! interface to OMPL
W48,https://wiki.ros.org/sr_ethercat_hand_config,Wiki,sr_ethercat_hand_config,"

    sr_ethercat_hand_config contains the different yaml files storing the parameters used on the etherCAT hand.

  "
W49,https://wiki.ros.org/xdot,Wiki,xdot,"
    , 
    is an interactive viewer for graphs written in Graphviz's dot
    language.

    This package adds front-end capabilities to XDot including WX Widget
    support and a mechanism for receiving callbacks when nodes are clicked. This extension is provided as BSD.

  
  
 Please see  and  for more information. rosrun xdot xdot.py [file]"
W50,https://wiki.ros.org/lidar_camera_calibration,Wiki,lidar_camera_calibration,"ROS package to find a rigid-body transformation between a LiDAR and a camera We maintain a very detailed README and other information regarding the lidar_camera_calibration package at the  repo for the package. For more information regarding setting up lidar_camera_calibration, detailed usage, package capabilities and tutorials, please visit the  repository at . For technical information please visit:  "
W51,https://wiki.ros.org/roslisp_utilities,Wiki,roslisp_utilities,Some utility functionality to interact with ROS using roslisp.
W52,https://wiki.ros.org/moveit_ros_planning,Wiki,moveit_ros_planning,Planning components of MoveIt! that use ROS
W53,https://wiki.ros.org/teleop_tools_msgs,Wiki,teleop_tools_msgs,The teleop_tools_msgs package
W54,https://wiki.ros.org/rqt_logger_level,Wiki,rqt_logger_level,"rqt_logger_level provides a GUI plugin for configuring the logger level of ROS nodes.
   
  rqt_logger_level takes over `wx`-based tool [[rxloggerlevel]].
 is an application for adjusting the logger level of ros nodes 
rqt_logger_level$ rosrun rqt_logger_level rqt_logger_level"
W55,https://wiki.ros.org/mbf_msgs,Wiki,mbf_msgs,"The move_base_flex messages package providing the action definition files for the action GetPath, ExePath, Recovery and MoveBase. The action servers providing these action are implemented in ."
W56,https://wiki.ros.org/seed_r7_robot_interface,Wiki,seed_r7_robot_interface,The seed_r7_robot_interface package
W57,https://wiki.ros.org/moveit_plugins,Wiki,moveit_plugins,Metapackage for moveit plugins.
W58,https://wiki.ros.org/joystick_interrupt,Wiki,joystick_interrupt,Interrupt cmd_vel by joystick input
W59,https://wiki.ros.org/resource_retriever,Wiki,resource_retriever,"This package retrieves data from url-format files such as http://,
   ftp://, package:// file://, etc., and loads the data into memory.
   The package:// url for ros packages is translated into a local
   file:// url.  The resourse retriever was initially designed to load
   mesh files into memory, but it can be used for any type of
   data. The resource retriever is based on the the libcurl library.
 has an extremely simple C++ API, consisting of two classes and one method.  also has a very similar Python API. The  class is the gateway into downloading files.  Its  method returns a  which contains the file in memory.  The  tutorial details how to use both classes. resource_retrieverget()resource_retriever"
W60,https://wiki.ros.org/jsk_tools,Wiki,jsk_tools,"Includes emacs scripts, ros tool alias generator, and launch doc generator.Documentation is available . "
W61,https://wiki.ros.org/pmb2_gazebo,Wiki,pmb2_gazebo,Simulation files for the PMB2 robot.
W62,https://wiki.ros.org/ira_laser_tools,Wiki,ira_laser_tools,"The ira_laser_tools package. These nodes are meant to provide some utils for lasers, like listen to different laser scan sources and merge them in a single scan or generate virtual laser scans from a pointcloud. The documentation is at the moment very brief, for any question please contact us at  or  Paper link:  "
W63,https://wiki.ros.org/stomp_core,Wiki,stomp_core,This package  provides the core STOMP (Stochastic Trajectory Optimization for Motion Planning) algorithm that can be used for robot motion planning tasks or other similar optimization tasks
W64,https://wiki.ros.org/phidgets_ik,Wiki,phidgets_ik,Driver for the Phidgets InterfaceKit devices
W65,https://wiki.ros.org/mrpt_tutorials,Wiki,mrpt_tutorials,"Example files used as tutorials for MRPT ROS packages
 comprises demo files for . 
mrpt_tutorials"
W66,https://wiki.ros.org/mrpt_localization,Wiki,mrpt_localization,"Package for robot 2D self-localization using dynamic or static (MRPT or ROS) maps.
	The interface is similar to amcl (http://wiki.ros.org/amcl)
   but supports different particle-filter algorithms, several grid maps at
   different heights, range-only localization, etc.







 The  node wraps MRPT particle-filter localization algorithms through a ROS interface. See demo launch-file and tutorials above. mrpt_localizationroslaunch mrpt_localization demo.launchroslaunch mrpt_localization demo_ro.launchroslaunch mrpt_localization demo.launch"
W67,https://wiki.ros.org/pmb2_controller_configuration,Wiki,pmb2_controller_configuration,"Launch files and scripts needed to configure
    the controllers of the PMB2 robot."
W68,https://wiki.ros.org/yocs_waypoints_navi,Wiki,yocs_waypoints_navi,"Simple tool for waypoints navigation with two functions:
     * Command the robot to go to a goal by passing through a series of waypoints.
     * Command the robot to constantly loop through a series of waypoints, useful for patrol.
"
W69,https://wiki.ros.org/zeroconf_avahi,Wiki,zeroconf_avahi,"Provides zeroconf services on avahi for ros systems.
     This is a c++ implementation.

 are used to discover the appearance and disappearance of all  services belong to a specific service type (e.g. _ros-master._tcp). The usual process is to add a listener and then sit back and wait for the callbacks (either c++ or ros subscription) to arrive signifying addition or removal of the specified services.  are zeroconf services you wish to publish on the network. They require a name, service type, port and description. If there is a name collision, this package and avahi will rename the service so that it is unique for the lifetime of the current connection. 


 This package provides implementations for  on top of linux's . There are two implementations: The c++ library can be manipulated directly through the  class whereas the  provides similar handles through ros topics, services and parameters exposed by the. Both the c++ and node implementations operate on two entities,  and .  If you're using the library, it should be relatively straightforward - simply follow the  class documentation. There is also an example in . Alternatively, using the ros node can be done in a variety of ways, refer to the . See the example on static configuration for an illustration of the usage of the   and  parameters: new_connectionslost_connectionsadd_listeneradd_serviceremove_servicelist_discovered_serviceslist_published_services~servicesarray[structs]"
W70,https://wiki.ros.org/urg_node,Wiki,urg_node,"urg_node 


: : 

 

Image credit:  Allow Unsafe Settings Option is not available, please consider using the legacy  for UTM-30LX with certain configurations.  (Or provide a  to add support for unsafe_settings.) The  program can be used to get information about a hokuyo laser scanner. Each of them can be invoked in a human readable way: The  program can be used to get the hardware ID of a Hokuyo device given its port. Combined with udev, this allows a consistent device name to be given to each device, even if the order in which they are plugged in varies. On the PR2 we use the following udev rule: clusterskipintensitymin_angmax_angclusterskipintensitymin_angmax_anggetIDgetID$ rosrun urg_node getID /dev/ttyACM0
Device at /dev/ttyACM0 has ID H0807228$ rosrun urg_node getID /dev/ttyACM0 --
H0807228SUBSYSTEMS==""usb"", KERNEL==""ttyACM[0-9]*"", ACTION==""add"", ATTRS{idVendor}==""15d1"", ATTRS{idProduct}==""0000"", MODE=""666"", PROGRAM=""/opt/ros/hydro/lib/urg_node/getID /dev/%k q"", SYMLINK+=""sensors/hokuyo_%c"", GROUP=""dialout""$ ls -l /etc/ros/sensors/base_hokuyo
lrwxrwxrwx 1 root root 28 2010-01-12 15:53 /etc/ros/sensors/base_hokuyo -> /dev/sensors/hokuyo_H0902620
$ ls -l /dev/sensors/hokuyo_H0902620
lrwxrwxrwx 1 root root 10 2010-04-12 12:34 /dev/sensors/hokuyo_H0902620 -> ../ttyACM1"
W71,https://wiki.ros.org/ur_dashboard_msgs,Wiki,ur_dashboard_msgs,Messages around the UR Dashboard server.
W72,https://wiki.ros.org/jsk_recognition_msgs,Wiki,jsk_recognition_msgs,ROS messages for jsk_pcl_ros and jsk_perception.
W73,https://wiki.ros.org/rospatlite,Wiki,rospatlite,"rospatlite is a ROS driver for patlite Signal Tower NHx series. 
 


rospatliteroslaunch rospatlite patlite.launch IP:=<patlite ip>patlite ip~set/red~set/yellow~set/green~set/blue~set/white~set/buzzer~hoststring~portint~timeoutfloat$ roslaunch rospatlite patlite.launch IP:=10.68.0.10$ rostopic pub /patlite/set/buzzer std_msgs/Int8 1 # <- buzzer ON
$ rostopic pub /patlite/set/buzzer std_msgs/Int8 0 # <- buzzer OFF
$ rostopic pub /patlite/set/red std_msgs/Int8 1 # <- red light ON
$ rostopic pub /patlite/set/yellow std_msgs/Int8 2 # <- yellow light blink"
W74,https://wiki.ros.org/pr2_controllers_msgs,Wiki,pr2_controllers_msgs,"Messages, services, and actions used in the pr2_controllers stack.

 This package seems to be replaced by the PR2-agnostic package , stated by . "
W75,https://wiki.ros.org/image_view2,Wiki,image_view2,A simple viewer for ROS image topics with draw-on features Documentation: See  
W76,https://wiki.ros.org/transmission_interface,Wiki,transmission_interface,"Transmission Interface.
  contains data structures for representing mechanical transmissions, and  methods for propagating position, velocity and effort variables between  actuator and joint spaces. In the same spirit as the   package, this package wraps existing raw data (eg. current actuator  position, reference joint command, etc.) under a consistent interface.  By not imposing a specific layout on the raw data, it becomes easier to  support arbitrary hardware drivers to software control. The  is  used by controllers themselves (it does not implement a ) but instead operates before or after the controllers update, in the read() and write() methods (or equivalents) of the robot abstraction. See the  page,  and the  for more information. "
W77,https://wiki.ros.org/zbar_ros,Wiki,zbar_ros,"Lightweight ROS wrapper for Zbar barcode/qrcode reader library (http://zbar.sourceforge
    .net/)


This package is a lightweight wrapper around the  barcode processing library. It provides a node and a nodelet with equivalent interface. The  topic is a lazy subscription that is active only when the  topic has a client. Same API as node, available as . imagebarcodebarcode_reader_nodeimagebarcode~throttle_repeated_barcodesdouble0.0zbar_ros/barcode_reader_nodelet"
W78,https://wiki.ros.org/yocs_controllers,Wiki,yocs_controllers,Library for various controller types and algorithms 
W79,https://wiki.ros.org/pr2_bringup_tests,Wiki,pr2_bringup_tests,"Complete functionality tests for PR2. Contains utilities designed to test and verify devices, mechanicals and sensors.
 - Information qualifying the mechanical calibration of newly built robots "
W80,https://wiki.ros.org/ur_robot_driver,Wiki,ur_robot_driver,"The new driver for Universal Robots UR3, UR5 and UR10 robots with CB3 controllers and the e-series.






Use GitHub to . []
  For robots with Polyscope  or older, please see whether  is sufficient. Make sure the controller runs  or newer for CB3, or  or newer for e-Series controllers. Most documentation is handled inside the Githhub  files. v1.8.xv3.7v5.1"
W81,https://wiki.ros.org/jsk_calibration,Wiki,jsk_calibration,The jsk_calibration package
W82,https://wiki.ros.org/yocs_ar_pair_tracking,Wiki,yocs_ar_pair_tracking,"The AR pair tracking package


 explains what to configure. 

update_ar_pairs~spotted_markers~initial_pose~relative_target_posepublish_transformsboolglobal_framestringmarker_framestringbase_framestring"
W83,https://wiki.ros.org/qt_build,Wiki,qt_build,"Currently just maintains a cmake api for simplifying the building
    of qt apps within the ros framework.package.xmlCMakeLists.txtinclude/qdude/*.hppsrcuiresources  <buildtool_depend>catkin</buildtool_depend>
  <build_depend>qt_build</build_depend>
  <build_depend>roscpp</build_depend>
  <run_depend>roscpp</run_depend>find_package(catkin REQUIRED COMPONENTS qt_build roscpp)
rosbuild_prepare_qt4(QtCore QtGui) # Add qt components to the list here

...file(GLOB QT_FORMS RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} ui/*.ui)
file(GLOB QT_RESOURCES RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} resources/*.qrc)
file(GLOB_RECURSE QT_MOC RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} FOLLOW_SYMLINKS include/qdude/*.hpp)

QT4_ADD_RESOURCES(QT_RESOURCES_CPP ${QT_RESOURCES})
QT4_WRAP_UI(QT_FORMS_HPP ${QT_FORMS})
QT4_WRAP_CPP(QT_MOC_HPP ${QT_MOC})

file(GLOB_RECURSE QT_SOURCES RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} FOLLOW_SYMLINKS src/*.cpp)include_directories(${catkin_INCLUDE_DIRS})
add_executable(qdude ${QT_SOURCES} ${QT_RESOURCES_CPP} ${QT_FORMS_HPP} ${QT_MOC_HPP})
target_link_libraries(qdude ${QT_LIBRARIES} ${catkin_LIBRARIES})install(TARGETS qdude RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION})"
W84,https://wiki.ros.org/jsk_footstep_planner,Wiki,jsk_footstep_planner,jsk_footstep_planner
W85,https://wiki.ros.org/sicktoolbox,Wiki,sicktoolbox,"SICK Toolbox drivers for SICK laser rangefinders

    This package contains the ROS fork of the SICK LIDAR Matlab/C++ Toolbox, available from .

    The SICK LIDAR Matlab/C++ Toolbox offers stable and easy-to-use C++ drivers for SICK LMS 2xx and SICK LD LIDARs.  Also included are config utilities, examples, and tutorials. 
Please see the  package to use this library with ROS. "
W86,https://wiki.ros.org/pr2_gripper_sensor_msgs,Wiki,pr2_gripper_sensor_msgs,"The pr2_gripper_sensor_msgs package contains various actions and messages that are used in the pr2_gripper_sensor* packages. The structure of the API used by pr2_gripper_sensor_action, and pr2_gripper_sensor_controller packages is as follows: 

Users will send a goal to an Action in the message format of PR2Gripper*Command (where * replaces the name of the particular Action from pr2_gripper_sensor_action). Feedback and Result information for the action is then returned in the format of PR2Gripper*Data. 
Please refer to the  and  packages for additional information. The messages in this package are largely used for communication between these packages, as indicated by the red arrows in the diagram below.   "
W87,https://wiki.ros.org/rqt_rviz,Wiki,rqt_rviz,"rqt_rviz provides a GUI plugin embedding .
    Note that this rqt plugin does NOT supersede RViz but depends on it."
W88,https://wiki.ros.org/rqt_bag,Wiki,rqt_bag,"rqt_bag provides a GUI plugin for displaying and replaying ROS bag files., which is deprecated since  . 
 is an application for recording and managing bag files. Primary features:  can be extended via a plugin mechanism.  Core plugins are contained in the  package available in the  metapackage.  


  Don't forget to use simulation time when republishing from a bag file:  


 
 

 

 currently has a proof-of-concept plugin API, which is used in the  package.  and select from  -->  --> . Or simply the following (with this you can't open  with other rqt tools). Right-click on the name of the topic you want to publish, then select   (as in the image below). The messages are shown at the timestamp stored in the bag file.  This timestamp may differ from the message's  timestamp (if any), e.g.  stores the time the message was received. For details on common message views such as images and plotting, see . rqt_bagROSrqt_bagrqt_bagPluginsLoggingBagrqt_bagPublishHeaderrosbag recordrqt_bag$ rqt$ rqt_bag"
W89,https://wiki.ros.org/mrpt1,Wiki,mrpt1,"Mobile Robot Programming Toolkit (MRPT) version 1.5.xThe  package provides the C++ libraries for MRPT 1.5.x, required in distributions where the official packages are older. mrpt1"
W90,https://wiki.ros.org/rqt_tf_tree,Wiki,rqt_tf_tree,rqt_tf_tree provides a GUI plugin for visualizing the ROS TF frame tree. 
W91,https://wiki.ros.org/actionlib_lisp,Wiki,actionlib_lisp,"actionlib_lisp is a native implementation of the famous actionlib
   in Common Lisp. It provides a client and a simple server.






actionlib_lisp is a native implementation of  in Common Lisp. It provides a simple server and a client. In contrast to the implementations of actionlib in C++ and Python which provide a simple action client/server and a complex one, the lisp equivalent provides only one server and client implementation. The server is similar to the simple action server and the client is a little bit more powerful than the simple action client but not as complex as the complex C++ equivalent. (make-action-client action-name action-type)action-nameaction-type(wait-for-server action-client &optional timeout)timeoutNILT(send-goal client goal &optional done-cb feedback-cb active-cb state-change-cb)clientACTION-CLIENTdone-cbfeedback-cbactive-cbstate-change-cb(cancel-goal goal-handle)goal-handle(wait-for-result goal-handle &optional timeout)(send-goal-and-wait client goal &key exec-timeout result-timeout feedback-cb)wait-for-resultfeedback-signalabort-goalclientgoalexec-timeoutresult-timeoutfeedback-cbsend-goal-and-wait(call-goal client goal &key timeout result-timeout feedback-cb)(connected-to-server client)T(make-action-goal client &rest args)clientmake-msg(start-action-server action-name action-type exec-callback &key separate-thread)action-nameaction-typeexec-callbackseparate-thread(def-exec-callback name args &body body)preempt-currentsucceed-currentabort-currentcancel-request-receivedpublish-feedbackbody(succeed-current &rest args)argsmake-msg(abort-current &rest args)argsmake-msg(preempt-current &rest args)argsmake-msg(publish-feedback &rest args)argsmake-msg(cancel-request-received)T(defparameter *ac* (make-action-client ""/fibonacci"" ""actionlib_tutorials/FibonacciAction""))

(send-goal-and-wait *ac* (make-action-goal *ac* :order 10) :exec-timeout 20 :result-timeout 0.5)(def-exec-callback fib-callback (order)
  ""This function takes in the FibonacciGoal message and pursues the action.""
  (ros-debug (fib callback) ""entering callback with goal ~a"" order)
  (let ((a 1) (b 1) (seq (make-array 0 :adjustable t :fill-pointer 0)))
    (dotimes (i order)
      (when (cancel-request-received)
        (ros-debug (fib callback) ""goal ~a canceled"" order)
        (preempt-current :sequence seq)) ;; Note that this exits the callback
        
      (psetq a b b (+ a b))
      (vector-push-extend a seq) 
      (ros-debug (fib callback) ""publishing feedback for goal ~a"" order)
      (publish-feedback :sequence seq)
      (sleep 1.0))
    (ros-debug (fib callback) ""succeeding on goal ~a"" order)
    (succeed-current :sequence seq)))

      
(defun fib-server ()
  (with-ros-node (""fib"")
    (start-action-server ""fibonacci"" ""actionlib_tutorials/FibonacciAction"" #'fib-callback)))"
W92,https://wiki.ros.org/mini_maxwell,Wiki,mini_maxwell,mini_maxwell
W93,https://wiki.ros.org/spatio_temporal_voxel_layer,Wiki,spatio_temporal_voxel_layer,"The spatio-temporal 3D obstacle costmap package
 The spatio-temporal voxel layer incorporates information from the sensors in the form of  or . This information is converted into 3D and populated into an efficient voxel grid for each sensor cycle. More information, ROS API, demos, and resources are given in the  page. "
W94,https://wiki.ros.org/jsk_perception,Wiki,jsk_perception,ROS nodes and nodelets for 2-D image perception.
W95,https://wiki.ros.org/qt_gui_core,Wiki,qt_gui_core,"Integration of the ROS package system and ROS-specific plugins for a Qt-based GUI.
"
W96,https://wiki.ros.org/qt_dotgraph,Wiki,qt_dotgraph,qt_dotgraph provides helpers to work with dot graphs.
W97,https://wiki.ros.org/ros_controllers,Wiki,ros_controllers,"Library of ros controllers
See  for more information. @article{ros_control,
author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\""u}dtke, Mathias and Fern{\'a}ndez Perdomo, Enrique},
title = {ros\_control: A generic and simple control framework for ROS},
journal = {The Journal of Open Source Software},
year = {2017},
doi = {10.21105/joss.00456},
URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}
}"
W98,https://wiki.ros.org/rostwitter,Wiki,rostwitter,The rostwitter package
W99,https://wiki.ros.org/pr2_self_test,Wiki,pr2_self_test,The pr2_self_test package
W100,https://wiki.ros.org/rqt_launch,Wiki,rqt_launch,"This rqt plugin ROS package provides easy view of .launch files.
  User can also start and end node by node that are defined in those files. This package is still experimental. Feedback from early users are appreciated. 




,  doesn't guarantee that the nodes start running in any order. In , however, nodes get started in the order in the  file (still doesn't mean that each process finished initialization procedure in the started order - it depends on how much time they take). 

And choose  from  menu.  See  for more options. Sample image using :  Sample image using :  This list is just a clarification/disclaimer. Enhancement request is welcomed at Bugtracker (link is available at  of this page). LaunchPluginsKDEGnome.launch.launchARGARG.launchPackage Summary.launch.launchrqt_launchrqt_launch.launch% rqt"
W101,https://wiki.ros.org/message_generation,Wiki,message_generation,Package modeling the build-time dependencies for generating language bindings of messages.
W102,https://wiki.ros.org/rqt_publisher,Wiki,rqt_publisher,rqt_publisher provides a GUI plugin for publishing arbitrary messages with fixed or computed field values. 
W103,https://wiki.ros.org/pilz_control,Wiki,pilz_control,"This package provides a specialized joint_trajectory_controller that can be moved into holding state via service call.
  No further trajectories will be accepted/followed in this state."
W104,https://wiki.ros.org/xsens_driver,Wiki,xsens_driver,"ROS Driver for XSens MT/MTi/MTi-G devices.

 

  is a Python module that is both a library to communicate to devices through the  class, and a standalone script to configure such a device. Note that you can use the module in an interactive session to diagnose or configure the device with a bit more flexibility.  Changing the baudrate to values other than 115200 might not work for some devices (despite mentioned in the vendor documentation) and might require the emergency procedure to recover communication with the device. 

This package provides a driver for the third and fourth generation of Xsens IMU devices. The driver is in two parts, a small implementation of most of the MT protocol in Python and a . It works both on serial and USB interfaces. These MT* devices can store their configuration and will retrieve it at each boot and then stream data according to this configuration. The node only forwards the data streamed onto ROS topics. In order to configure your device, you can use the  script (or the vendor tool on Windows). Compared to the other MTi drivers ( and ), this one can handle other configurations than the default and the GPS module of the MTi-G. It is also a clean rewrite of the communication protocol easier to maintain (and possibly extend) than the old vendor based multi-layered architecture. The ROS node is a wrapper around the  class to publish the data that the IMU streams. It can publish the following topics, depending on the configuration of the device (topics are only advertised when there is data to publish): 
It also publishes  information. If the IMU is set to raw mode, the values in of the ,  and  topics are the 16 bits output of the AD converters. The covariance information in the  message are filled with default values from the MTx/MTi/MTi-G documentation but may not be exact; it also does not correspond to the covariance of the internal XKF. It might be necessary to add the user to the  group so that the node can communicate with the device. mtdevice::MTDeviceimu/datafixvelocityimu/magtemperaturepressureanalog_in1analog_in2eceftime_referenceimu_data_str/imu/data/velocity/magnetic~devicestring""auto""~baudrateint""auto""0~timeoutfloat~frame_idstring~frame_localstring~frame_idmtdevice.pyMTDevicedialoutUsage:
    ./mtdevice.py [commands] [opts]

Commands:
    -h, --help
        Print this help and quit.
    -r, --reset
        Reset device to factory defaults.
    -a, --change-baudrate=NEW_BAUD
        Change baudrate from BAUD (see below) to NEW_BAUD.
    -c, --configure=OUTPUT
        Configure the device (see OUTPUT description below).
    -e, --echo
        Print MTData. It is the default if no other command is supplied.
    -i, --inspect
        Print current MT device configuration.
    -x, --xkf-scenario=ID
        Change the current XKF scenario.
    -l, --legacy-configure
        Configure the device in legacy mode (needs MODE and SETTINGS arguments
        below).
    -v, --verbose
        Verbose output.

Generic options:
    -d, --device=DEV
        Serial interface of the device (default: /dev/ttyUSB0). If 'auto', then
        all serial ports are tested at all baudrates and the first
        suitable device is used.
    -b, --baudrate=BAUD
        Baudrate of serial interface (default: 115200). If 0, then all
        rates are tried until a suitable one is found.

Configuration option:
    OUTPUT
        The format is a sequence of ""<group><type><frequency>?<format>?""
        separated by commas.
        The frequency and format are optional.
        The groups and types can be:
            t  temperature (max frequency: 1 Hz):
                tt  temperature
            i  timestamp (max frequency: 2000 Hz):
                iu  UTC time
                ip  packet counter
                ii  Integer Time of the Week (ITOW)
                if  sample time fine
                ic  sample time coarse
                ir  frame range
            o  orientation data (max frequency: 400 Hz):
                oq  quaternion
                om  rotation matrix
                oe  Euler angles
            b  pressure (max frequency: 50 Hz):
                bp  baro pressure
            a  acceleration (max frequency: 2000 Hz (see documentation)):
                ad  delta v
                aa  acceleration
                af  free acceleration
                ah  acceleration HR (max frequency 1000 Hz)
            p  position (max frequency: 400 Hz):
                pa  altitude ellipsoid
                pp  position ECEF
                pl  latitude longitude
            n  GNSS (max frequency: 4 Hz):
                np  GNSS PVT data
                ns  GNSS satellites info
            w  angular velocity (max frequency: 2000 Hz (see documentation)):
                wr  rate of turn
                wd  delta q
                wh  rate of turn HR (max frequency 1000 Hz)
            g  GPS (max frequency: 4 Hz):
                gd  DOP
                gs  SOL
                gu  time UTC
                gi  SV info
            r  Sensor Component Readout (max frequency: 2000 Hz):
                rr  ACC, GYR, MAG, temperature
                rt  Gyro temperatures
            m  Magnetic (max frequency: 100 Hz):
                mf  magnetic Field
            v  Velocity (max frequency: 400 Hz):
                vv  velocity XYZ
            s  Status (max frequency: 2000 Hz):
                sb  status byte
                sw  status word
        Frequency is specified in decimal and is assumed to be the maximum
        frequency if it is omitted.
        Format is a combination of the precision for real valued numbers and
        coordinate system:
            precision:
                f  single precision floating point number (32-bit) (default)
                d  double precision floating point number (64-bit)
            coordinate system:
                e  East-North-Up (default)
                n  North-East-Down
                w  North-West-Up
        Examples:
            The default configuration for the MTi-1/10/100 IMUs can be
            specified either as:
                ""wd,ad,mf,ip,if,sw""
            or
                ""wd2000fe,ad2000fe,mf100fe,ip2000,if2000,sw2000""
            For getting quaternion orientation in float with sample time:
                ""oq400fw,if2000""
            For longitude, latitude, altitude and orientation (on MTi-G-700):
                ""pl400fe,pa400fe,oq400fe""

Legacy options:
    -m, --output-mode=MODE
        Legacy mode of the device to select the information to output.
        This is required for 'legacy-configure' command.
        MODE can be either the mode value in hexadecimal, decimal or
        binary form, or a string composed of the following characters
        (in any order):
            t  temperature, [0x0001]
            c  calibrated data, [0x0002]
            o  orientation data, [0x0004]
            a  auxiliary data, [0x0008]
            p  position data (requires MTi-G), [0x0010]
            v  velocity data (requires MTi-G), [0x0020]
            s  status data, [0x0800]
            g  raw GPS mode (requires MTi-G), [0x1000]
            r  raw (incompatible with others except raw GPS), [0x4000]
        For example, use ""--output-mode=so"" to have status and
        orientation data.
    -s, --output-settings=SETTINGS
        Legacy settings of the device. This is required for 'legacy-configure'
        command.
        SETTINGS can be either the settings value in hexadecimal,
        decimal or binary form, or a string composed of the following
        characters (in any order):
            t  sample count (excludes 'n')
            n  no sample count (excludes 't')
            u  UTC time
            q  orientation in quaternion (excludes 'e' and 'm')
            e  orientation in Euler angles (excludes 'm' and 'q')
            m  orientation in matrix (excludes 'q' and 'e')
            A  acceleration in calibrated data
            G  rate of turn in calibrated data
            M  magnetic field in calibrated data
            i  only analog input 1 (excludes 'j')
            j  only analog input 2 (excludes 'i')
            N  North-East-Down instead of default: X North Z up
        For example, use ""--output-settings=tqMAG"" for all calibrated
        data, sample counter and orientation in quaternion.
    -p, --period=PERIOD
        Sampling period in (1/115200) seconds (default: 1152).
        Minimum is 225 (1.95 ms, 512 Hz), maximum is 1152
        (10.0 ms, 100 Hz).
        Note that for legacy devices it is the period at which sampling occurs,
        not the period at which messages are sent (see below).

Deprecated options:
    -f, --deprecated-skip-factor=SKIPFACTOR
        Only for mark III devices.
        Number of samples to skip before sending MTData message
        (default: 0).
        The frequency at which MTData message is send is:
            115200/(PERIOD * (SKIPFACTOR + 1))
        If the value is 0xffff, no data is send unless a ReqData request
        is made."
W105,https://wiki.ros.org/moveit_resources,Wiki,moveit_resources,Resources used for MoveIt! testing
W106,https://wiki.ros.org/pmb2_bringup,Wiki,pmb2_bringup,Launch files and scripts needed to bring up the ROS nodes of a PMB2 robot.
W107,https://wiki.ros.org/rqt_reconfigure,Wiki,rqt_reconfigure,"This rqt plugin succeeds former dynamic_reconfigure's GUI
    (reconfigure_gui), and provides the way to view and edit the parameters
    that are accessible via dynamic_reconfigure.
    
    (12/27/2012) In the future, arbitrary parameters that are not associated
    with any nodes (which are not handled by dynamic_reconfigure) might
    become handled.
    However, currently as the name indicates, this pkg solely is dependent
    on dynamic_reconfigure that allows access to only those params latched
    to nodes.
 To launch reconfigure_gui in Groovy, run:    




You can also launch the  via : Generally speaking, try isolating GUI and non-GUI issue. 's  are helpful for doing that. () If nothing returned then the issue is your  itself, not . reconfigure_guidynamic_reconfiguredynamic_reconfigurerqt-reconfigurerosrun rqt_reconfigure rqt_reconfigurerosrun rqt_gui rqt_guirosrun dynamic_reconfigure dynparam list"
W108,https://wiki.ros.org/xbot_talker,Wiki,xbot_talker,"The xbot_talker package

 
xbot_talker/xbot/talker_state/welcome/leave/xbot/play/xbot/chat~base_pathstring""$(find xbot_talker)"""
W109,https://wiki.ros.org/dynamic_edt_3d,Wiki,dynamic_edt_3d,The dynamicEDT3D library implements an inrementally updatable Euclidean distance transform (EDT) in 3D. It comes with a wrapper to use the OctoMap 3D representation and hooks into the change detection of the OctoMap library to propagate changes to the EDT.
W110,https://wiki.ros.org/kdl_parser,Wiki,kdl_parser,"The Kinematics and Dynamics Library (KDL) defines a tree structure
   to represent the kinematic and dynamic parameters of a robot
   mechanism.  provides tools to construct a KDL
   tree from an XML robot representation in URDF. 

 If you want to take advantage of the powerful features of the , the kdl parser provides an easy way to construct a full KDL Tree object. Starting from either a  or a Collada xml description of your robot, the kdl parser automatically generates a KDL Tree. kdl_parserkdl_parserkdl_parserkdl_parserkdl_parserkdl_parserkdl_parserkdl_parserkdl_parserkdl_parser"
W111,https://wiki.ros.org/roseus_tutorials,Wiki,roseus_tutorials,roseus_tutorialsDocumentation is available  
W112,https://wiki.ros.org/openrtm_tools,Wiki,openrtm_tools,The openrtm_tools package
W113,https://wiki.ros.org/rosconsole_bridge,Wiki,rosconsole_bridge,"rosconsole_bridge is a package used in conjunction with console_bridge and rosconsole for connecting console_bridge-based logging to rosconsole-based logging.
 is a package used in conjunction with  and  for connecting -based logging to -based logging. 

If you have an application or library that is utilizing  for logging, the logging information will be written to stdout. Applications/libraries that utilize  do not follow this behavior, but rather write their output to both stdout (depending on log level) as well as the ROS topic /rosout. If you have a console_bridge application or library, you can have its output be written to /rosout by simply having your package depend on rosconsole_bridge. Additionally, a call to REGISTER_ROSCONOLE_BRIDGE has to be added to the ROS node. (See ). "
W114,https://wiki.ros.org/pmb2_robot,Wiki,pmb2_robot,PMB2 robot description and launch files
W115,https://wiki.ros.org/nav_2d_msgs,Wiki,nav_2d_msgs,"Basic message types for two dimensional navigation, extending from geometry_msgs::Pose2D."
W116,https://wiki.ros.org/lanelet2_io,Wiki,lanelet2_io,Parser/Writer module for lanelet2
W117,https://wiki.ros.org/seed_r7_navigation,Wiki,seed_r7_navigation,The seed_r7_navigation package
W118,https://wiki.ros.org/summit_xl_sim_bringup,Wiki,summit_xl_sim_bringup,"Launch files for Summit XL simulation.
"
W119,https://wiki.ros.org/force_torque_sensor_controller,Wiki,force_torque_sensor_controller,"Controller to publish state of force-torque sensors
See the  page for more information. "
W120,https://wiki.ros.org/rosgraph_msgs,Wiki,rosgraph_msgs,"Messages relating to the ROS Computation Graph. These are generally considered to be low-level messages that end users do not interact with.
 contains message relating to the ROS Computation Graph. Most users are not expected to interact with messages in this package, and it is strongly advised against.  These messages are generally wrapped in higher level APIs. 
 is the underlying message data structure for logging to . If you use the client API methods in  and , you will be protected against any future revisions to this message.  is used for simulated  in ROS. Only nodes that provide simulated time sources are expected to use this message.   is used by  and  for publishing statistics on topic connections on /statistics. See  for more information. Prior to Diamondback, these messages were in the  package.  They were migrated to this package as part of . rosgraph_msgs"
W121,https://wiki.ros.org/turtlebot3_slam,Wiki,turtlebot3_slam,"The turtlebot3_slam package provides roslaunch scripts for starting the SLAM 


~base_framestring~odom_framestring~map_update_intervaldouble~maxUrangedouble~minimumScorefloat~linearUpdatefloat~angularUpdatefloat~temporalUpdatefloat~deltafloat~lskipint~particlesint~sigmafloat~deltafloat~kernelSizeint~lstepfloat~astepfloat~iterationsint~lsigmafloat~ogainfloat~srrfloat~srtfloat~srrfloat~sttfloat~resampleThresholdfloat~xminfloat~yminfloat~xmaxfloat~ymaxfloat~llsamplerangefloat~llsamplestepfloat~lasamplerangefloat~lasamplestepfloat"
W122,https://wiki.ros.org/safe_teleop_base,Wiki,safe_teleop_base,"This package provides automatic collision avoidance and is intended to be used for safer teleoperation of a robot base.




 (, default: 2.5) This node takes as input commands for a robot base and outputs the nearest safe commands. The core functionality has some similarities to . Many of the parameters are identical to those of the  package. ~<name>/safe_vel~<name>/user_plan~<name>/local_plan/base_velocity/odom~<name>/clear_costmaps~<name>/acc_lim_xdouble~<name>/acc_lim_ydouble~<name>/acc_lim_thdouble~<name>/sim_timedouble~<name>/sim_granularitydouble~<name>/vx_samplesinteger~<name>/vy_samplesinteger~<name>/vtheta_samplesinteger~<name>/user_biasdouble~<name>/occdist_scaledouble~<name>/max_vel_xdouble~<name>/min_vel_xdouble~<name>/max_vel_ydouble~<name>/min_vel_ydouble~<name>/min_vel_ydouble~<name>/max_rotational_velocitydouble~<name>/world_modelstring~<name>/holonomic_robotbool~<name>/dwabool~<name>/safe_backwardsbool"
W123,https://wiki.ros.org/gripper_action_controller,Wiki,gripper_action_controller,"The gripper_action_controller package
See the  page for more information. "
W124,https://wiki.ros.org/jackal_tutorials,Wiki,jackal_tutorials,Jackal's tutorials.Please see the generated tutorial content . 
W125,https://wiki.ros.org/seed_r7_description,Wiki,seed_r7_description,The seed_r7_description package
W126,https://wiki.ros.org/rqt_service_caller,Wiki,rqt_service_caller,rqt_service_caller provides a GUI plugin for calling arbitrary services.
W127,https://wiki.ros.org/visp_ros,Wiki,visp_ros,"An extension of ViSP library that interfaces ROS into usual ViSP classes and a basket of generic ros nodes based on ViSP.
  is a library:  contains also a set of ROS nodes that allow to control specific hardware such as for the moment robots (Afma6, Pioneer). 

 
 
 

 visp_ros is an extension of  library developed by Inria. While ViSP is independent to ROS, in visp_ros we benefit from ROS features. To illustrate  behavior let us focus on a visual servoing example. Using  allows to completely separate the code that is specific to the material (frame grabber, robot) from the one that does the visual servoing. In  we introduce a new class named vpROSGrabber that is able to subscribe to an image topic. This class can be used to replace any ViSP grabber. We also introduce vpROSRobot that is able to publish cmd_vel velocities on a given topic. The tutorial  explains how to build and install visp_ros in a catkin workspace. #include <visp/vpImage.h> 
#include <visp/vp1394TwoGrabber.h> 
#include <visp/vpRobotViper850.h>

int main() 
{
  vpImage<unsigned char> I; 
  vpRobotViper850 robot; 
  robot.init();

  vp1394TwoGrabber g; 
  g.open(I); 

  while(1) {
    g.acquire(I); 
    // Visual servoing code 
    robot.setVelocity(vpRobot::CAMERA_FRAME, v);
  }
}#include <visp/vpImage.h> 
#include <visp_ros/vpROSGrabber.h>
#include <visp_ros/vpROSRobot.h>

int main() 
{
  vpImage<unsigned char> I; 
  vpROSRobot robot; 
  robot.setCmdVelTopic(""/myrobot/cmd_vel"");
  robot.init();

  vpROSGrabber g; 
  g.setImageTopic(""/camera/image_raw"");
  g.open(I); 

  while(1) {
    g.acquire(I); 
    // Visual servoing code 
    robot.setVelocity(vpRobot::CAMERA_FRAME, v);
  }
}  ...
  vpROSGrabber g; 
  g.setImageTopic(""/camera/image_jpg""); // Name of the compressed topic
  g.setImageTransport(""jpeg"");          // Type of compression. Must differ from ""raw""
  g.open(I); 
  ...#include <visp/vpImage.h> 
#include <visp_ros/vpROSGrabber.h>
#include <visp_ros/vpROSRobot.h>

int main(int argc, char **argv) 
{
  vpImage<unsigned char> I; 
  vpROSRobot robot; 
  robot.setCmdVelTopic(""/myrobot/cmd_vel"");
  robot.init(argc, argv);

  vpROSGrabber g; 
  g.setImageTopic(""/camera/image_raw"");
  g.open(argc, argv); 

  while(1) {
    g.acquire(I); 
    // Visual servoing code 
    robot.setVelocity(vpRobot::CAMERA_FRAME, v);
  }
}"
W128,https://wiki.ros.org/jsk_recognition,Wiki,jsk_recognition,Metapackage that contains recognition package for jsk-ros-pkg
W129,https://wiki.ros.org/volksbot_driver,Wiki,volksbot_driver,"Driver for the Volksbot robot.


Use GitHub to . []
 sudo apt install ros-melodic-volksbot-driverSUBSYSTEM==""usb"",ATTRS{idVendor}==""0403"",ATTRS{idProduct}==""a8b0"",MODE=""0660"",OWNER=""robot_user"""
W130,https://wiki.ros.org/xacro,Wiki,xacro,"Xacro (XML Macros)

    Xacro is an XML macro language. With xacro, you can construct shorter and more readable XML files by using macros that expand to larger XML expressions.


: Properties are local if defined inside of a . See . 
: 
: The more powerful evaluation capabilities in ROS Jade allow for much more complex expression. Virtually any python expression that evaluates to a Boolean is feasible: 
: Since ROS Indigo, it is also possible to define defaults like so: 
Comments in front of macros will be removed during processing. They are considered to be related to the macro (e.g. explaining the macro). If you want to keep a comment in the final document, separate it with an empty line from the macro. 
 Macro parameters can have default values: Often, you need to pass external variables into local macro params (as above for x). To ease this task, you can employ the ^ syntax: 
Properties and macros defined within a macro are local to this macro, i.e. not visible outside. Using the optional attribute , a property definition can be exported to the parent scope of a macro (or the global scope). 

 Properties can be dictionaries or lists too - manually declared with python syntax, like so: 
: While this cmake code provides full control over the target name and build order, there is a conveniency macro too: 
: In order to add elements or attributes with a dynamically defined name, you can use the special xacro tags  and : 
: 
:  This package is most useful when working with large XML documents such as robot descriptions.  It is heavily used in packages such as the .  See for example,  for how xacro is used to simplify urdf files. See , for an example showing the use of the advanced features (python evaluation, yaml integration) introduced in Jade. Many of the features highlighted as ""New in Jade"" below are also accessible from Indigo. To use them, the  flag is required. This flag is discussed , and for some background information see this . Put simply, this flag is used to trigger Jade-enabled xacro processing on Indigo. Properties are named values that can be inserted anywhere into the XML document.  Property blocks are named snippets of XML that can be inserted anywhere that XML is allowed.  Both use the property tag to define values. Property tags cannot be declared inside of a . Since ROS Jade, Xacro employs  to evaluate expressions enclosed in dollared-braces, . This allows for more complex arithmetic expressions. Functions and constants from the  math module (e.g.  and trigonometric functions) are available for use. Examples: Xacro allows you to use certain rospack commands with dollared-parentheses (). Xacro currently supports all the rospack commands that roslaunch supports using . Arguments need to be specified on the command line using the  syntax. You can include other xacro files using the  tag: The file ""other_file.xacro"", will be included and expanded by xacro.  : Relative filenames are interpreted relative to the currently processed file. : When including files within a macro, not the macro-defining but the macro-calling file is the one that processes the include! $(cwd) explicitly allows to access files in the current working directory. or loaded from  files like so: If you want the generated files to have a  extension it is possible to provide input files terminating with , the  suffix will be removed by the CMake function. This results in files with a  extension. Usage example for : Classicly Xacro first loads all includes, then processes all property and macro definitions and finally instantiates macros and evaluates expressions. Thus, . Additionally, the conditional tags, <if> and <unless>, have no effect on macro or property definitions nor the inclusion of additional files. Since ROS Jade, Xacro provides the command-line option , that allows to process the whole document in read order. Hence the latest definition of a property or macro , will be used. This is a much more intuitive evaluation process that allows for some nice new features as well: If there are any differences shown, you should check and adapt your xacro file. A common reason will be the late loading of calibration data (as properties). In this case, simply move them up front, i.e. before usage. To facilitate search for wrongly placed property definitions, you can run xacro with option . If there are any problematic properties, they will be listed on stderr: Using the command-line option  or  one can increase verbosity level to log all defintions of properties. To suppress the legacy interpretation of sloppy xacro tags and allow their usage in the target XML, you can use the command line option . --inorderxacro:macroxacro:macropython${}pythonpi$()myvar:=truescope=""parent | global""xacro:includeprops.yamlpropsval1.urdf.urdf.xacro.xacro.urdf<xacro:element><xacro:attribute><xacro:attribute>--inorder--check-order-vv-vvv--xacro-ns<xacro:macro name=""pr2_arm"" params=""suffix parent reflect"">
  <pr2_upperarm suffix=""${suffix}"" reflect=""${reflect}"" parent=""${parent}"" />
  <pr2_forearm suffix=""${suffix}"" reflect=""${reflect}"" parent=""elbow_flex_${suffix}"" />
</xacro:macro>

<xacro:pr2_arm suffix=""left"" reflect=""1"" parent=""torso"" />
<xacro:pr2_arm suffix=""right"" reflect=""-1"" parent=""torso"" /><pr2_upperarm suffix=""left"" reflect=""1"" parent=""torso"" />
<pr2_forearm suffix=""left"" reflect=""1"" parent=""elbow_flex_left"" />
<pr2_upperarm suffix=""right"" reflect=""-1"" parent=""torso"" />
<pr2_forearm suffix=""right"" reflect=""-1"" parent=""elbow_flex_right"" /><xacro:property name=""the_radius"" value=""2.1"" />
<xacro:property name=""the_length"" value=""4.5"" />

<geometry type=""cylinder"" radius=""${the_radius}"" length=""${the_length}"" /><xacro:property name=""front_left_origin"">
  <origin xyz=""0.3 0 0"" rpy=""0 0 0"" />
</xacro:property>

<pr2_wheel name=""front_left_wheel"">
  <xacro:insert_block name=""front_left_origin"" />
</pr2_wheel><xacro:property name=""radius"" value=""4.3"" />
<circle diameter=""${2 * radius}"" /><xacro:property name=""R"" value=""2"" />
<xacro:property name=""alpha"" value=""${30/180*pi}"" />
<circle circumference=""${2 * pi * R}"" pos=""${sin(alpha)} ${cos(alpha)}"" />
<limit lower=""${radians(-90)}"" upper=""${radians(90)}"" effort=""0"" velocity=""${radians(75)}"" /><xacro:if value=""<expression>"">
  <... some xml code here ...>
</xacro:if>
<xacro:unless value=""<expression>"">
  <... some xml code here ...>
</xacro:unless><xacro:property name=""var"" value=""useit""/>
<xacro:if value=""${var == 'useit'}""/>
<xacro:if value=""${var.startswith('use') and var.endswith('it')}""/>

<xacro:property name=""allowed"" value=""${[1,2,3]}""/>
<xacro:if value=""${1 in allowed}""/><foo value=""$(find xacro)"" />
<foo value=""$(arg myvar)"" /><xacro:arg name=""myvar"" default=""false""/><param name=""robot_description"" command=""$(find xacro)/xacro.py $(arg model) myvar:=true"" /><xacro:macro name=""pr2_caster"" params=""suffix *origin **content **anothercontent"">
  <joint name=""caster_${suffix}_joint"">
    <axis xyz=""0 0 1"" />
  </joint>
  <link name=""caster_${suffix}"">
    <xacro:insert_block name=""origin"" />
    <xacro:insert_block name=""content"" />
    <xacro:insert_block name=""anothercontent"" />
  </link>
</xacro:macro>

<xacro:pr2_caster suffix=""front_left"">
  <pose xyz=""0 1 0"" rpy=""0 0 0"" />
  <container>
    <color name=""yellow""/>
    <mass>0.1</mass>
  </container>
  <another>
    <inertial>
      <origin xyz=""0 0 0.5"" rpy=""0 0 0""/>
      <mass value=""1""/>
      <inertia ixx=""100""  ixy=""0""  ixz=""0"" iyy=""100"" iyz=""0"" izz=""100"" />
    </inertial>
  </another>
</xacro:pr2_caster><joint name=""caster_front_left_joint"">
  <axis xyz=""0 0 1"" />
</joint>
<link name=""caster_front_left"">
  <pose xyz=""0 1 0"" rpy=""0 0 0"" />
  <color name=""yellow"" />
  <mass>0.1</mass>
  <inertial>
    <origin xyz=""0 0 0.5"" rpy=""0 0 0""/>
    <mass value=""1""/>
    <inertia ixx=""100""  ixy=""0""  ixz=""0"" iyy=""100"" iyz=""0"" izz=""100"" />
  </inertial>
</link><xacro:macro name=""reorder"" params=""*first *second"">
  <xacro:insert_block name=""second""/>
  <xacro:insert_block name=""first""/>
</xacro:macro>
<reorder>
  <first/>
  <second/>
</reorder><a>
  <xacro:macro name=""foo"" params=""x"">
    <in_foo the_x=""${x}"" />
  </xacro:macro>

  <xacro:macro name=""bar"" params=""y"">
    <in_bar>
      <xacro:foo x=""${y}"" />
    </in_bar>
  </xacro:macro>

  <xacro:bar y=""12"" />
</a><a>
  <in_bar>
    <in_foo the_x=""12.0""/>
  </in_bar>
</a><xacro:macro name=""foo"" params=""x:=${x} y:=${2*y} z:=0""/><xacro:macro name=""foo"" params=""p1 p2:=expr_a p3:=^ p4:=^|expr_b""><xacro:include filename=""$(find package)/other_file.xacro"" />
<xacro:include filename=""other_file.xacro"" />
<xacro:include filename=""$(cwd)/other_file.xacro"" /><xacro:include filename=""other_file.xacro"" ns=""namespace""/>${namespace.property}<xacro:property name=""props"" value=""${dict(a=1, b=2, c=3)}""/>
<xacro:property name=""numbers"" value=""${[1,2,3,4]}""/><xacro:property name=""yaml_file"" value=""$(find package)/config/props.yaml"" />
<xacro:property name=""props"" value=""${load_yaml(yaml_file)}""/>val1: 10
val2: 20<xacro:property name=""val1"" value=""${props['val1']}"" /># Generate .world files from .world.xacro files
find_package(xacro REQUIRED)
# You can also add xacro to the list of catkin packages:
#   find_package(catkin REQUIRED COMPONENTS ... xacro)

# Xacro files
file(GLOB xacro_files ${CMAKE_CURRENT_SOURCE_DIR}/worlds/*.world.xacro)

foreach(it ${xacro_files})
  # remove .xacro extension
  string(REGEX MATCH ""(.*)[.]xacro$"" unused ${it})
  set(output_filename ${CMAKE_MATCH_1})

  # create a rule to generate ${output_filename} from {it}
  xacro_add_xacro_file(${it} ${output_filename})

  list(APPEND world_files ${output_filename})
endforeach(it)

# add an abstract target to actually trigger the builds
add_custom_target(media_files ALL DEPENDS ${world_files})file(GLOB xacro_files worlds/*.world.xacro)
xacro_add_files(${xacro_files} TARGET media_files)<xacro:element xacro:name=""${element_name}"" [other attributes]>
 [content]
</xacro:element>
<xacro:attribute name=""${attribute_name}"" value=""${attribute_value}""/><xacro:property name=""foo"" value=""my_attribute_name""/>
<tag>
    <xacro:attribute name=""${foo}"" value=""my_attribute_value""/>
</tag><tag my_attribute_name=""my_attribute_value"" />rosrun xacro xacro file.xacro > /tmp/old.xml
rosrun xacro xacro --inorder file.xacro > /tmp/new.xml
diff /tmp/old.xml /tmp/new.xmlDocument is incompatible to --inorder processing.
The following properties were redefined after usage:
foo redefined in issues.xacrofind . -iname ""*.xacro"" | xargs sed -i 's#<\([/]\?\)\(if\|unless\|include\|arg\|property\|macro\|insert_block\)#<\1xacro:\2#g'"
W131,https://wiki.ros.org/mrpt_rawlog,Wiki,mrpt_rawlog,"This package enables you to record a rawlog from a ROS drive robot.
  At the moment the package is able to deal with odometry and 2d laser scans.



See  online. See  online. mrpt_rawlog/rawlog_record_nodemrpt_rawlog/rawlog_play_noderosbag playrawlog_play_noderosbag playtf~base_framestring""base_link""mapodomrawlog_record_noderosbag recordtf~raw_log_folderstring""~/""roslaunch mrpt_rawlog demo_play.launchroslaunch mrpt_rawlog demo_record.launch"
W132,https://wiki.ros.org/yocs_cmd_vel_mux,Wiki,yocs_cmd_vel_mux,"A multiplexer for command velocity inputs. Arbitrates incoming cmd_vel messages from several topics,
     allowing one topic at a time to command the robot, based on priorities. It also deallocates current
     allowed topic if no messages are received after a configured timeout. All topics, together with their
     priority and timeout are configured through a YAML file, that can be reload at runtime.Contents 


We configure the Command Velocity Multiplexer with a YAML file. We reproduce here the example file that comes with the sources: As you can see, for every input we must specify 4 parameters: The last line gives the name for the output topic. 
Take a look to the  to learn how cmd_vel_mux works together with other components to build up a safe and flexible control system.  ~input/cmd_vel~output/cmd_vel~active~yaml_cfg_filestring~input/cmd_vel~output/cmd_vel~active~yaml_cfg_filestring~input/cmd_vel~output/cmd_vel~active~yaml_cfg_filestringsubscribers:
  - name:        ""Default input""
    topic:       ""input/default""
    timeout:     0.1
    priority:    0
    short_desc:  ""The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here""
  - name:        ""Navigation stack""
    topic:       ""input/navigation""
    timeout:     0.5
    priority:    1
    short_desc:  ""Navigation stack controller""

    ...

  - name:        ""Web application""
    topic:       ""input/webapp""
    timeout:     0.3
    priority:    8
  - name:        ""Keyboard operation""
    topic:       ""input/keyop""
    timeout:     0.1
    priority:    7
publisher:       ""output/cmd_vel""subscribers:
  - name:        ""Default input""
    topic:       ""input/default""
    timeout:     0.1
    priority:    0
    short_desc:  ""The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here""
  - name:        ""Navigation stack""
    topic:       ""input/navigation""
    timeout:     0.5
    priority:    1
    short_desc:  ""Navigation stack controller""

    ...

  - name:        ""Web application""
    topic:       ""input/webapp""
    timeout:     0.3
    priority:    8
  - name:        ""Keyboard operation""
    topic:       ""input/keyop""
    timeout:     0.1
    priority:    7
publisher:       ""output/cmd_vel""subscribers:
  - name:        ""Default input""
    topic:       ""input/default""
    timeout:     0.1
    priority:    0
    short_desc:  ""The default cmd_vel, controllers unaware that we are multiplexing cmd_vel should come here""
  - name:        ""Navigation stack""
    topic:       ""input/navigation""
    timeout:     0.5
    priority:    1
    short_desc:  ""Navigation stack controller""

    ...

  - name:        ""Web application""
    topic:       ""input/webapp""
    timeout:     0.3
    priority:    8
  - name:        ""Keyboard operation""
    topic:       ""input/keyop""
    timeout:     0.1
    priority:    7
publisher:       ""output/cmd_vel"""
W133,https://wiki.ros.org/mbf_utility,Wiki,mbf_utility,The mbf_utility package
W134,https://wiki.ros.org/voice_text,Wiki,voice_text,voice_text (www.voicetext.jp)
W135,https://wiki.ros.org/checkerboard_detector,Wiki,checkerboard_detector,"Uses opencv to find checkboards and compute their 6D poses with respect to the image. Requires the image to be calibrated.
    Parameters:
    
"
W136,https://wiki.ros.org/sophus,Wiki,sophus,"C++ implementation of Lie Groups using Eigen.

  
This is a ros 3rd party package that provides Hauke Strasdat's  library.  See the . $ sudo apt-get install ros-kinetic-sophus


























"
W137,https://wiki.ros.org/turtlebot_gazebo,Wiki,turtlebot_gazebo,"Gazebo launchers and worlds for TurtleBot simulation$ sudo apt-get install ros-indigo-turtlebot-gazebo$ source /opt/ros/indigo/setup.bash
$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch"
W138,https://wiki.ros.org/phidgets_drivers,Wiki,phidgets_drivers,"API and ROS drivers for Phidgets devices

 


Please see the  documentation for an example on how to implement new types of Phidgets. For installing from source, it is best to follow the instructions in the README.md file in the . Phidget


"
W139,https://wiki.ros.org/libcmt,Wiki,libcmt,libCMT ROS Wrapper
W140,https://wiki.ros.org/pi_tracker,Wiki,pi_tracker,"

    Skeleton Tracker Teleop Package for the Pi Robot Project

  












 Tracker command requires one or more services from each node it commands.  In its current form, the tracker command node sends simple string commands to control nodes via their  service.  For example, sending the command ""STOP"" to the  node (see below) tells the base to stop moving. skeleton_tracker/skeletontracker_command/skeletontracker_base_controller/skeleton/cmd_veltracker_joint_controller/skeleton/cmd_joints/skeleton~tracking_rateint~fixed_framestringfixed_frameheadfixed_frameneckfixed_frametorsofixed_frameleft_shoulderfixed_frameleft_elbowfixed_frameleft_handfixed_frameright_shoulderfixed_frameright elbowfixed_frameright_handfixed_frameleft_hipfixed_frameleft_kneefixed_frameleft_footfixed_frameright_hipfixed_frameright_kneefixed_frameright_foot/skeleton~command_rateintset_commandtracker_base_controller/skeleton/cmd_vel~set_command~base_controller_rateint~max_drive_speeddouble~maximum_rotation_speeddouble~base_control_sidestring~scale_drive_speeddouble~scale_rotation_speeddouble~holonomicbooleantracker_base_controllerxyTwist/skeleton/cmd_joints~set_command~joint_controller_rateint~default_joint_speeddouble~use_real_robotboolean/joint_state~skel_to_joint_mapdict<launch>
  <arg name=""fixed_frame"" value=""camera_depth_frame"" />
 
  <param name=""/use_sim_time"" value=""False"" />
 

  <arg name=""debug"" value=""False"" />
  <arg name=""launch_prefix"" value=""xterm -e gdb --args"" />
 
  <param name=""robot_description"" command=""$(find xacro)/xacro.py '$(find pi_tracker)/urdf/pi_robot/pi_robot_with_two_arms.xacro'"" />
 
  <node name=""robot_state_publisher"" pkg=""robot_state_publisher"" type=""state_publisher"">
    <param name=""publish_frequency"" value=""20.0""/>
  </node>
    
  <include file=""$(find rgbd_launch)/launch/kinect_frames.launch"" />

  <group if=""$(arg debug)"">
    <node launch-prefix=""$(arg launch_prefix)"" pkg=""skeleton_markers"" name=""skeleton_tracker"" type=""skeleton_tracker"" output=""screen""    >
      <param name=""fixed_frame"" value=""$(arg fixed_frame)"" />
      <param name=""load_filepath"" value=""$(find pi_tracker)/params/SamplesConfigNewOpenNI.xml"" />
    </node>
  </group>
  <group unless=""$(arg debug)"">
    <node name=""skeleton_tracker"" pkg=""skeleton_markers"" type=""skeleton_tracker"">
      <param name=""fixed_frame"" value=""$(arg fixed_frame)"" />
      <param name=""load_filepath"" value=""$(find pi_tracker)/params/SamplesConfigNewOpenNI.xml"" />
    </node>
  </group>
</launch><launch>
    <node name=""tracker_command"" pkg=""pi_tracker"" type=""tracker_command.py"" output=""screen"">
        <rosparam command=""load"" file=""$(find pi_tracker)/params/tracker_params.yaml"" />
    </node>
    <node name=""tracker_base_controller"" pkg=""pi_tracker"" type=""tracker_base_controller.py"" output=""screen"">
        <rosparam command=""load"" file=""$(find pi_tracker)/params/tracker_params.yaml"" />
    </node>
    <node name=""tracker_joint_controller"" pkg=""pi_tracker"" type=""tracker_joint_controller.py"" output=""screen"">
        <rosparam command=""load"" file=""$(find pi_tracker)/params/tracker_params.yaml"" />
    </node>
</launch>command_rate: 2
tracking_rate: 2
base_controller_rate: 2
joint_controller_rate: 2
default_joint_speed: 0.6
max_drive_speed: 0.3
max_rotation_speed: 0.3
base_control_side: right

use_real_robot: True

# Use these values for a typical non-holonomic robot.
scale_drive_speed: 1.0
scale_rotation_speed: 1.0
reverse_rotation: False
holonomic: False

# Use the following scale factors for the Rovio.
#scale_drive_speed: 4.0
#scale_rotation_speed: 0.4
#reverse_rotation: True
#holonomic: True

fixed_frame: openni_depth

skel_to_joint_map: {
   head: head_pan_joint,
   neck: head_tilt_joint,
   torso: torso_joint,
   left_shoulder: left_shoulder_lift_joint,
   left_elbow: left_elbow_joint,
   left_hand: left_hand_joint,
   right_shoulder: right_shoulder_joint,
   right_elbow: right_elbow_joint,
   right_hand: right_hand_joint,
   left_hip: no_joint,
   left_knee: no_joint,
   left_foot: no_joint,
   right_hip: no_joint,
   right_knee: no_joint,
   right_foot: no_joint
}"
W141,https://wiki.ros.org/rqt_web,Wiki,rqt_web,rqt_web is a simple web content viewer for rqt. Users can show web content in Qt-based window by specifying its URL.
W142,https://wiki.ros.org/rc_dynamics_api,Wiki,rc_dynamics_api,"The rc_dynamics_api provides an API for easy handling of the dynamic-state data
      streams provided by Roboception's stereo camera with self-localization.
      See http://rc-visard.com

      Dynamic-state estimates of the rc_visard relate to its self-localization and
      ego-motion estimation. These states refer to rc_visard's current pose,
      velocity, or acceleration and are published on demand via several data streams.
      For a complete list and descriptions of these dynamics states and the
      respective data streams please refer to rc_visard's user manual.


./tools/rcdynamics_stream -v 10.0.2.99 -s imu./tools/rcdynamics_stream -v 10.0.2.99 -s pose_rt -i eth0 -a -t10 -o poses.csv"
W143,https://wiki.ros.org/webkit_dependency,Wiki,webkit_dependency,This encapsulates the WebKit dependency for a specific ROS distribution and its Qt version
W144,https://wiki.ros.org/jsk_teleop_joy,Wiki,jsk_teleop_joy,jsk_teleop_joy
W145,https://wiki.ros.org/urdfdom_py,Wiki,urdfdom_py,"Python implementation of the URDF parser.

 presently has its own package page, which redirects here. 
 The  package provides the  Python module providing both functions to parse an URDF model from a file or the parameter server and Python classes mapping the URDF information to a Python structure. The  script allows the user to display the parsing result. It can be used either with a path to an URDF file (i.e. ) or without any argument. In this case, it connects to the parameter server to retrieve the robot configuration. This package comes from the following prior packages: , , , and . Once you have retrieved the  object, please consult the package Python API to know how to browse the structure. urdfdom_pyurdf_parser_pydisplay_urdfrosrun urdf_parser_py display_urdf /tmp/robot.urdfrobot




































"
W146,https://wiki.ros.org/laser_assembler,Wiki,laser_assembler,"Provides nodes to assemble point clouds from either LaserScan or PointCloud messages


  


  



Laser Rangefinder sensors (such as Hokuyo's ) generally output a stream of scans, where each scan is a set of range readings of detected objects (in polar coordinates) in the plane of the sensor. Many robotic systems, like PR2's tilting laser platform, articulate a laser rangefinder in order to get a 3D view of the world. The  package provides nodes that listen to streams of scans and then assemble them into a larger 3D Cartesian coordinate (XYZ) point cloud. The ROS API of this package is considered stable. We don't foresee making any large changes to  anytime soon. The  subscribes to  messages on the  topic.  These scans are processed by the Projector and Transformer, which project the scan into Cartesian space and then transform it into the . This results in a  that can be added to the rolling buffer. Clouds in the rolling buffer are then assembled on service calls. Note that the Transformer automatically receives  data without any user intervention. The  looks very similar to the , except that the projection step is skipped, since the input clouds are already in Cartesian coordinates. The main interaction with the assemblers is via ROS services. The  and  both provide the  service, which is documented below. NOTE: For laser_pipeline releases < 0.5.0, this service is called . Launch an assembler operating on   messages in the base_link frame, with a buffer of 400 scans. Launch an assembler operating on   messages in the  frame, with a buffer of 400 scans. As of laser_pipeline 0.4.0. A large part of the laser_assembler's ROS API was deprecated. The API reference for the deprecated API is available on the  page. laser_assemblerlaser_scan_assemblerpoint_cloud_assemblerlaser_assemblerlaser_scan_assemblerscanfixed_framepoint_cloud_assemblerlaser_scan_assemblerlaser_scan_assemblerpoint_cloud_assemblerassemble_scansbuild_cloudscanassemble_scansassemble_scansbeginend~fixed_frameintensitiesindexdistancesstampsassemble_scans2~fixed_framestring~tf_cache_time_secsdouble~max_scansint~ignore_laser_skewbooltruecloudassemble_scansassemble_scansbeginend~fixed_frame~fixed_framestring~tf_cache_time_secsdouble~max_cloudsinttilt_scanmy_cloud_inbase_link<launch>
  <node type=""laser_scan_assembler"" pkg=""laser_assembler""
        name=""my_assembler"">
    <remap from=""scan"" to=""tilt_scan""/>
    <param name=""max_scans"" type=""int"" value=""400"" />
    <param name=""fixed_frame"" type=""string"" value=""base_link"" />
  </node>
</launch><launch>
  <node type=""point_cloud_assembler"" pkg=""laser_assembler""
        name=""my_assembler"">
    <remap from=""cloud"" to=""my_cloud_in""/>
    <param name=""max_clouds"" type=""int"" value=""400"" />
    <param name=""fixed_frame"" type=""string"" value=""base_link"" />
  </node>
</launch>





























"
W147,https://wiki.ros.org/safe_teleop_pr2,Wiki,safe_teleop_pr2,Launch files for running safe_teleop_base on pr2
W148,https://wiki.ros.org/position_controllers,Wiki,position_controllers,"position_controllers
See the  page for more information. "
W149,https://wiki.ros.org/joint_trajectory_action,Wiki,joint_trajectory_action,"The joint_trajectory_action is a node that exposes an action interface
     to a joint trajectory controller.
 







See:  The joint trajectory action provides an action server (see ) that takes in goals of the type . You can find an example of using the joint trajectory action in  for moving the arm on the PR2. jointsArray of stringsconstraints/goal_timedoubleconstraints/<joint>/goaldoubleconstraints/<joint>/trajectorydoubleconstraints/stopped_velocity_tolerancedoublejoint_trajectory_action/goaljoint_trajectory_action/canceljoint_trajectory_action/feedbackjoint_trajectory_action/statusjoint_trajectory_action/resultstatecommandjoint_trajectory_action_node:
  joints:
    - r_shoulder_pan_joint
    - r_shoulder_lift_joint
    - r_upper_arm_roll_joint
    - r_elbow_flex_joint
    - r_forearm_roll_joint
    - r_wrist_flex_joint
    - r_wrist_roll_joint
  constraints:
    goal_time: 0.3
    r_shoulder_pan_joint:
      goal: 0.04
    r_shoulder_lift_joint:
      goal: 0.04
    r_upper_arm_roll_joint:
      goal: 0.04
    r_elbow_flex_joint:
      goal: 0.04
    r_forearm_roll_joint:
      goal: 0.04
    r_wrist_flex_joint:
      goal: 0.04
    r_wrist_roll_joint:
      goal: 0.04"
W150,https://wiki.ros.org/moveit_core,Wiki,moveit_core,Core libraries used by MoveIt!
W151,https://wiki.ros.org/rqt_top,Wiki,rqt_top,"RQT plugin for monitoring ROS processes.
Originally made as . "
W152,https://wiki.ros.org/yocs_joyop,Wiki,yocs_joyop,Joystick teleoperation for your robot robot core
W153,https://wiki.ros.org/rospy_message_converter,Wiki,rospy_message_converter,"Converts between Python dictionaries and JSON to rospy messages.
Check out the  for examples. "
W154,https://wiki.ros.org/pilz_testutils,Wiki,pilz_testutils,"This package contains testing utilities used by Pilz packages.
For package documentation please see the . "
W155,https://wiki.ros.org/libpointmatcher,Wiki,libpointmatcher,"

     Fetches libpointmatcher through git submodule and makes it available to ROS

  
Tutorials on how to use libpointmatcher can be found . "
W156,https://wiki.ros.org/nlopt,Wiki,nlopt,nlopt
W157,https://wiki.ros.org/rosapi,Wiki,rosapi,"Provides service calls for getting ros meta-information, like list of
    topics, services, params, etc."
W158,https://wiki.ros.org/roslisp_common,Wiki,roslisp_common,"Common libraries to control ROS based robots. This stack contains
    an implementation of actionlib (client and server) in Common Lisp,
    a transformation library and an implementation of tf in Common
    Lisp.

  Contains commonly used libraries for , including Lisp implementations of  and . "
W159,https://wiki.ros.org/lanelet2_examples,Wiki,lanelet2_examples,Examples for working with Lanelet2
W160,https://wiki.ros.org/lanelet2_python,Wiki,lanelet2_python,Python bindings for lanelet2
W161,https://wiki.ros.org/ackermann_steering_controller,Wiki,ackermann_steering_controller,"Controller for a steer drive mobile base.










 () 
 () 
 (, default: 50.0) 
 (, default: base_link) 
 (, default: 1.0) 
 (, default: false) 
 () 





 An example of using the packages can be seen in . The controller inherits  to work with wheel joints through a  interface for a linear wheel and a  interface for a front steer wheel, which is the the most basic configuration for the ackermann steering driving mechanism. If you want  to show states of robot's actual joint interfaces'  through  and , you need to convert the two interfaces of  to your robot's specific ones via  or RobotHWSim (generally used for ). This is because the controller only update it's basic interfaces mentioned in the previous section. The controller main input is a  topic in the namespace of the controller. An example for usage of  with  can be grabbed from . We developped a general RobotHWSim plugin for usage of . You can get the plugin from  and also see an example of application on . We also provide a recovery behavior plugin of  specifically desigined for ackermann steering mechanism base robots in . Feel free to see  to learn how to use it. ackermann_steering_controllercmd_velodom/tfrear_wheelstringfront_steerstringpose_covariance_diagonaldouble[6]twist_covariance_diagonaldouble[6]publish_ratedoublecmd_vel_timeoutdoublebase_frame_idstringodom_frame_idstringenable_odom_tfboolwheel_separation_h_multiplierdoublewheel_radius_multiplierdoublesteer_pos_multiplierdoublelinear/x/has_velocity_limitsboollinear/x/max_velocitydoublelinear/x/min_velocitydoublelinear/x/has_acceleration_limitsboollinear/x/max_accelerationdoublelinear/x/min_accelerationdoublelinear/x/has_jerk_limitsboollinear/x/max_jerkdoubleangular/z/has_velocity_limitsboolangular/z/max_velocitydoubleangular/z/min_velocitydoubleangular/z/has_acceleration_limitsboolangular/z/max_accelerationdoubleangular/z/min_accelerationdoubleangular/z/has_jerk_limitsboolangular/z/max_jerkdoublewheel_separation_hdoublewheel_radiusdoubleackermann_steering_controllermobile_base_controller:
  type: ""ackermann_steering_controller/AckermannSteeringController""
  rear_wheel: 'rear_wheel_joint'
  front_steer: 'front_steer_joint'
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]mobile_base_controller:
  type        : ""ackermann_steering_controller/AckermannSteeringController""
  rear_wheel: 'rear_wheel_joint'
  front_steer: 'front_steer_joint'
  publish_rate: 50.0               # default: 50
  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]

  # Wheel separation between the rear and the front, and diameter of the rear. 
  # These are both optional.
  # ackermann_steering_controller will attempt to read either one or both from the
  # URDF if not specified as a parameter.
  wheel_separation_h : 1.0
  wheel_radius : 0.3

  # Wheel separation and radius multipliers for odometry calibration.
  wheel_separation_h_multiplier: 1.0 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0

  # Steer position angle multipliers for fine tuning.
  steer_pos_multiplier       : 1.0

  # Velocity commands timeout [s], default 0.5
  cmd_vel_timeout: 0.25

  # Base frame_id
  base_frame_id: base_footprint #default: base_link

  # Odom frame_id
  odom_frame_id: odom

  # Velocity and acceleration limits
  # Whenever a min_* is unspecified, default to -max_*
  linear:
    x:
      has_velocity_limits    : true
      max_velocity           : 1.0  # m/s
      min_velocity           : -0.5 # m/s
      has_acceleration_limits: true
      max_acceleration       : 0.8  # m/s^2
      min_acceleration       : -0.4 # m/s^2
      has_jerk_limits        : true
      max_jerk               : 5.0 # m/s^3

  angular:
    z:
      has_velocity_limits    : true
      max_velocity           : 1.7  # rad/s
      has_acceleration_limits: true
      max_acceleration       : 1.5  # rad/s^2
      has_jerk_limits        : true
      max_jerk               : 2.5 # rad/s^3"
W162,https://wiki.ros.org/opt_camera,Wiki,opt_camera,opt_camera
W163,https://wiki.ros.org/pilz_industrial_motion,Wiki,pilz_industrial_motion,"The pilz_industrial_motion package

For package documentation please see the . "
W164,https://wiki.ros.org/interactive_markers,Wiki,interactive_markers,"3D interactive marker communication library for RViz and similar tools.
 

Use GitHub to . []
 The tutorials can be found in . For an overview an further links, see . An app that uses interactive markers for controlling the PR2 is . "
W165,https://wiki.ros.org/mrpt_icp_slam_2d,Wiki,mrpt_icp_slam_2d,"mrpt_icp_slam_2d contains a wrapper on MRPT's 2D ICP-SLAM algorithms.






 The sections below describe the API of this package which allows ICP-based SLAM in 2D . The SLAM algorithm is a simple  using ICP to align 2D laser scans to the map, which can be either a  or an  . [For now, only point maps] Using this technique allows building , as long as errors do not grow excessively before closing any long loop. Building larger maps requires more advanced SLAM techniques. However, this simple icp-slam algorithm is an efficient and well-tested method which suffices for many practical situations. The ROS node  is a wrapper for the C++ class ,  part of MRPT. Thus, check out the documentation of that class for further  details. This node has been designed to provide an interface similar to that of   for the convenience of users which already knew that package. For the convention on coordinate frames see . Using  requires a horizontally-mounted, fixed, laser range-finder. Odometry is optional. The  node will attempt to transform each incoming scan  into the  (odometry)  frame.  See the """"  for more on required transforms. In order to use mrpt_icp_slam_2d package it is necessary to install the last  build and the(see also the ) . mrpt_icp_slam_2dmrpt_icp_slam_2dmrpt_icp_slam_2dodommrpt_icp_slam_2dtfscanPointCloudMapmaprobot_pose~global_frame_idstring""map""~base_frame_idstring""base_link""~odom_frame_idstring""odom""~sensor_sourcestring""scan""""scan""~ini_filenamestring~rawlog_filenamestring~rawlog_play_delayfloat<the frame attached to incoming scans>base_linktfbase_linkodommapodomroslaunch mrpt_icp_slam_2d icp_slam.launchroslaunch mrpt_icp_slam_2d icp_slam_rawlog.launch"
W166,https://wiki.ros.org/tts,Wiki,tts,"Package enabling a robot to speak with a human voice by providing a Text-To-Speech ROS service
: Amazon Polly is a service that turns text into lifelike speech, allowing you to create applications that talk, and build entirely new categories of speech-enabled products. Amazon Polly is a Text-to-Speech service that uses advanced deep learning technologies to synthesize speech that sounds like a human voice. With dozens of lifelike voices across a variety of languages, you can select the ideal voice and build speech-enabled applications that work in many different countries. : 

The  ROS node enables a robot to speak with a human voice by providing a Text-To-Speech service. Out of the box this package listens to a speech topic, submits text to the Amazon Polly cloud service to generate an audio stream file, retrieves the audio stream from Amazon Polly, and plays the audio stream via the default output device. The nodes can be configured to use different voices as well as custom lexicons and SSML tags which enable you to control aspects of speech, such as pronunciation, volume, pitch, speed rate, etc. A  with this node, and more details on speech customization are available within the . The source code is released under an . tts"
W167,https://wiki.ros.org/yocs_math_toolkit,Wiki,yocs_math_toolkit,"Math toolkit for Yujin open control system. This package is intended to contain common use functions,
    mostly for simple mathematics but also for tf-related conversions.
    By no means it pretends to be an efficient and robust, widely used math library, but a play ground where
    to put common code that is typically repeated in many robot control programs. "
W168,https://wiki.ros.org/jsk_pr2eus,Wiki,jsk_pr2eus,Metapackage that contains robot eus client package for jsk-ros-pkg
W169,https://wiki.ros.org/skeleton_markers,Wiki,skeleton_markers,"
    Skeleton Markers: Publish a list of joint markers for viewing in RViz
  Display the skeleton joints returned by the  package (or using the skeleton_tracker node included in this package) as markers in RViz.  This package contains two nodes for reading the tracked skeleton in two different ways:  the  node subscribes to the Skeleton message topic returned by the skeleton_tracker node included in the package.  The  node can read the transforms directly from the  package or the included skeleton_tracker node. 


Use the  file: Note: use the  RViz configuration file. Note: use the  RViz configuration file. 









 To make this package work with ROS Indigo, you will need the Kinect drivers for Ubuntu 14.04.  The following instructions were taken from .  The steps below are for a 64-bit system.  Use the 32-bit files for a 32-bit system. Use the  file: /skeleton/skeleton_markers~fixed_framestr~rateint~scalefloat~lifetimefloat~nsstr~idint~colordictionary/skeleton/skeleton_markers~fixed_framestr~rateint~scalefloat~lifetimefloat~nsstr~idint~colordictionary/skeleton_markers~fixed_framestr~rateint~scalefloat~lifetimefloat~nsstr~idint~colordictionary~tf_prefixstr $ mkdir ~/src
 $ cd ~/src
 $ git clone https://github.com/avin2/SensorKinect
 $ cd SensorKinect/Bin
 $ tar xjf SensorKinect093-Bin-Linux-x64-v5.1.2.1.tar.bz2
 $ cd Sensor-Bin-Linux-x64-v5.1.2.1
 $ sudo ./install.sh$ cd ~/ros_workspace (change to match your rosbuild workspace directory)
$ svn co http://pi-robot-ros-pkg.googlecode.com/svn/trunk/skeleton_markers
$ cd skeleton_markers
$ rosmake$ cd ~/ros_workspace (change to match your rosbuild workspace directory)
$ git clone https://github.com/pirobot/skeleton_markers.git
$ cd skeleton_markers
$ git checkout groovy-devel
$ rosmake$ cd ~/catkin_ws/src (change to match your catkin workspace directory)
$ git clone -b hydro-devel https://github.com/pirobot/skeleton_markers.git
$ cd ~/catkin_ws
$ catkin_make
$ rospack profile$ roscd skeleton_markers
$ rosrun rviz rviz -d markers.vcg
$ roslaunch skeleton_markers markers.launch$ roscd skeleton_markers
$ rosrun rviz rviz -d markers.rviz
$ roslaunch skeleton_markers markers.launch$ roslaunch skeleton_markers markers_from_tf.launch
$ roscd skeleton_markers
$ rosrun rviz rviz -d markers_from_tf.vcg$ roslaunch skeleton_markers markers_from_tf.launch
$ roscd skeleton_markers
$ rosrun rviz rviz -d markers_from_tf.rviz<launch>
  <include file=""$(find skeleton_markers)/launch/skeleton.launch"" />

  <node pkg=""skeleton_markers"" name=""skeleton_markers"" type=""skeleton_markers.py"" output=""screen"">
    <rosparam file=""$(find skeleton_markers)/params/marker_params.yaml"" command=""load"" />
  </node>
</launch><launch>
  <include file=""$(find skeleton_markers)/launch/skeleton.launch"" />

  <node pkg=""skeleton_markers"" name=""skeleton_markers"" type=""markers_from_skeleton_msg.py"" output=""screen"">
    <rosparam file=""$(find skeleton_markers)/params/marker_params.yaml"" command=""load"" />
  </node>
</launch><launch>
  <include file=""$(find openni_camera)/launch/openni_node.launch"" />
  
  <node pkg=""openni_tracker"" name=""openni_tracker"" type=""openni_tracker"" output=""screen"">
    <param name=""tf_prefix"" value=""skeleton"" />
  </node>
  
  <node pkg=""skeleton_markers"" name=""skeleton_markers"" type=""markers_from_tf.py"" output=""screen"">
    <rosparam file=""$(find skeleton_markers)/params/marker_params.yaml"" command=""load"" />
  </node>
</launch>"
W170,https://wiki.ros.org/joy_teleop,Wiki,joy_teleop,"A (to be) generic joystick interface to control a robot
 takes the output of the , and publishes topics or calls actions according to it's configuration. An example of using  with TIAGo can be found on the video below.  





joy_teleopjoy_teleop~teleoparray~joyteleop:
  move:
    type: topic
    message_type: geometry_msgs/Twist
    topic_name: cmd_vel
    axis_mappings:
      -
        axis: 1
        target: linear.x
        scale: 1.0
      -
        axis: 2
        target: angular.z
        scale: 1.0

  joy_priority:
    type: action
    action_name: joy_priority_action
    buttons: [9]

  joy_turbo_decrease:
    type: action
    action_name: joy_turbo_decrease
    buttons: [1, 4, 5]

  joy_turbo_increase:
    type: action
    action_name: joy_turbo_increase
    buttons: [3, 4, 5]

  torso_up:
    type: action
    action_name: /torso_controller/increment
    action_goal:
      increment_by: [0.05]
    buttons: [4] # right pad, top button

  torso_down:
    type: action
    action_name: /torso_controller/increment
    action_goal:
      increment_by: [-0.05]
    buttons: [6] # right pad, bottom button

  close_hand:
    type: action
    action_name: /play_motion
    action_goal:
      motion_name: 'close_hand'
      skip_planning: True
    buttons: [7]"
W171,https://wiki.ros.org/rqt_pose_view,Wiki,rqt_pose_view,rqt_pose_view provides a GUI plugin for visualizing 3D poses.  
W172,https://wiki.ros.org/urdf_tutorial,Wiki,urdf_tutorial,"This package contains a number of URDF tutorials.
This package is intended to be used in conjunction with the . "
W173,https://wiki.ros.org/julius_ros,Wiki,julius_ros,The julius_ros package
W174,https://wiki.ros.org/moveit_ros_visualization,Wiki,moveit_ros_visualization,Components of MoveIt! that offer visualization
W175,https://wiki.ros.org/librealsense,Wiki,librealsense,"Library for capturing data from the Intel(R) RealSense(TM) F200, SR300, R200, LR200 and ZR300 cameras. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of RealSense(TM); devices are implemented in this project, including multi-camera capture.
 is a cross-platform library (Linux, OSX, Windows) for capturing data from the Intel® ™ R200, F200, and SR300 cameras. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of ™ devices are implemented in this project, including multi-camera capture. 

 requires patches to the  loadable kernel module to support various cameras. Intel® ™ R200 camera support is upstreamed in the 4.4.x linux kernel, but older kernels and all other Intel® ™ cameras require patches. 







  
  

 Developer kits containing the necessary hardware to use this library are . This project is separate from the production software stack available in the , namely that this library only encompasses camera capture functionality without additional computer vision algorithms. Update your  file and/or  to uncomment (or add) the  entries for all of the entries for the  repositories. Below is an  for ubuntu 16.04 (Xenial). The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS  packages. Please  concerning this package to the realsense_camera  Issues. For updated details on this library see the . librealsenselibrealsenseuvcvideo/etc/apt/sources.list/etc/apt/sources.list.d/*.listdeb-srcmainwget -O enable_kernel_sources.sh https://raw.githubusercontent.com/IntelRealSense/librealsense/rosdebian/scripts/enable_kernel_sources.sh
bash ./enable_kernel_sources.shdeb-src http://us.archive.ubuntu.com/ubuntu/ xenial main restricted
deb-src http://us.archive.ubuntu.com/ubuntu/ xenial-updates main restricted
deb-src http://us.archive.ubuntu.com/ubuntu/ xenial-backports main restricted universe multiverse
deb-src http://security.ubuntu.com/ubuntu xenial-security main restrictedsudo apt-get updatesudo apt-get install linux-image-generic-lts-xenial
sudo rebootsudo apt-get dist-upgradesudo apt-get --reinstall install 'ros-*-librealsense'roslaunch realsense_camera [cam_type]_nodelet_[mode].launchsudo modprobe uvcvideomake KERNELRELEASE=4.4.0-43-generic -C /var/lib/dkms/uvcvideo/1.1.1-3-realsense/build/linux-src M=drivers/media/usb/uvc/....(bad exit status: 2)
Error! Bad return status for module build on kernel: 4.4.0-43-generic (x86_64)dkms remove -m uvcvideo -v ""1.1.1-3-realsense"" --all"
W176,https://wiki.ros.org/sr_config,Wiki,sr_config,"sr_config

  "
W177,https://wiki.ros.org/pr2_self_test_msgs,Wiki,pr2_self_test_msgs,"Messages used in PR2 hardware testing.
Messages/Services used by the  and  stacks. These messages are  and not API reviewed. "
W178,https://wiki.ros.org/kobuki_dock_drive,Wiki,kobuki_dock_drive,"Dock driving library for Kobuki. Users owning a docking station for Kobuki 
	    can use this tool to develop autonomous docking drive algorithms."
W179,https://wiki.ros.org/random_numbers,Wiki,random_numbers,"This  library contains wrappers for generating floating point values, integers, quaternions using boost libraries.

  The constructor of the wrapper is guaranteed to be thread safe and initialize its random number generator to a random seed.
  Seeds are obtained using a separate and different random number generator."
W180,https://wiki.ros.org/moveit_fake_controller_manager,Wiki,moveit_fake_controller_manager,A fake controller manager plugin for MoveIt.
W181,https://wiki.ros.org/turtlebot_simulator,Wiki,turtlebot_simulator,"Catkin metapackage for the turtlebot_simulator stack$ sudo apt-get install ros-indigo-turtlebot-simulator$ sudo apt-get install ros-hydro-turtlebot-simulator$ source /opt/ros/hydro/setup.bash
$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch$ sudo apt-get install ros-fuerte-turtlebot-simulator$ source /opt/ros/fuerte/setup.bash
$ roslaunch turtlebot_gazebo turtlebot_empty_world.launch"
W182,https://wiki.ros.org/jsk_robot,Wiki,jsk_robot,Metapackage that contains robot packages for jsk-ros-pkg
W183,https://wiki.ros.org/hardware_interface,Wiki,hardware_interface,"Hardware Interface base class.
See the  page and the  for more information. "
W184,https://wiki.ros.org/phidgets_high_speed_encoder,Wiki,phidgets_high_speed_encoder,"Driver for the Phidgets high speed encoder devices

joint_statesJointStatejoint_states_ch{0,1,2,3}_decim_speedEncoderDecimatedSpeedserial_namejoint{0,1,2,3}_namenameJointStatejoint{0,1,2,3}_tick2radPUBLISH_RATESPEED_FILTER_SAMPLES_LENSPEED_FILTER_IDLE_ITER_LOOPS_BEFORE_RESET
"
W185,https://wiki.ros.org/nmea_msgs,Wiki,nmea_msgs,"The nmea_msgs package contains messages related to data in the NMEA format.
"
W186,https://wiki.ros.org/jsk_network_tools,Wiki,jsk_network_tools,jsk_network_tools
W187,https://wiki.ros.org/jsk_roseus,Wiki,jsk_roseus,Metapackage that contains roseus package for jsk-ros-pkg
W188,https://wiki.ros.org/swri_console_util,Wiki,swri_console_util,swri_console_util
W189,https://wiki.ros.org/jackal_msgs,Wiki,jackal_msgs,"Messages exclusive to Jackal, especially for representing low-level motor commands and sensors.
These messages are the low-level interface between 's ARM MCU and integrated PC. Most users of Jackal should be able to use standard ROS interfaces (eg. , ) to command and monitor the robot. Possible exceptions are: "
W190,https://wiki.ros.org/moveit_runtime,Wiki,moveit_runtime,moveit_runtime meta package contains MoveIt! packages that are essential for its runtime (e.g. running MoveIt! on robots).
W191,https://wiki.ros.org/moveit_ros_control_interface,Wiki,moveit_ros_control_interface,ros_control controller manager interface for MoveIt!
W192,https://wiki.ros.org/task_compiler,Wiki,task_compiler,task_compiler Compiler that translate task description in PDDL (Planning Domain Description Language) to SMACH (state machine based execution and coordination system) description.
W193,https://wiki.ros.org/moveit_simple_controller_manager,Wiki,moveit_simple_controller_manager,"A generic, simple controller manager plugin for MoveIt."
W194,https://wiki.ros.org/pilz_extensions,Wiki,pilz_extensions,"The pilz_extensions package. Here are classes extending the functionality of other packages.
  On the long run these extensions should become pull requests on the respective packages."
W195,https://wiki.ros.org/resized_image_transport,Wiki,resized_image_transport,ROS nodes to publish resized images.
W196,https://wiki.ros.org/kinesis_video_msgs,Wiki,kinesis_video_msgs,Messages for transmitting video frames to Kinesis Video Streams
W197,https://wiki.ros.org/zeroconf_avahi_demos,Wiki,zeroconf_avahi_demos,"Several demos and launch-tests for the avahi based zero-configuration.
 for getting the launchers up and running with some scripts.  "
W198,https://wiki.ros.org/jsk_tilt_laser,Wiki,jsk_tilt_laser,The jsk_tilt_laser package
W199,https://wiki.ros.org/rqt_bag_plugins,Wiki,rqt_bag_plugins,"rqt_bag provides a GUI plugin for displaying and replaying ROS bag files.
 

 
  To access these plugins, launch the  GUI tool (see  for details), right-click on the timeline of the desired topic select a view type from the context menu. The following plugins are currently provided for : The image view displays raw image data for  and  messages: The plot view displays a time series plot of numeric fields in a ROS message. The view inherits from the  code base, so all plotting options are the same as with . rqt_bagrqt_bagrqt_plotrqt_plot"
W200,https://wiki.ros.org/mbf_costmap_nav,Wiki,mbf_costmap_nav,"The mbf_costmap_nav package contains the costmap navigation server implementation of Move Base Flex (MBF). The costmap navigation server is bound to the  representation. It provides the Actions for planning, controlling and recovering. At the time of start MBF loads all defined plugins. Therefor, it loads all plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions. 

        Additionally the mbf_costmap_nav package comes with a wrapper for the old navigation stack and the plugins which inherits from the  base classes. Preferably it tries to load plugins for the new API. However, plugins could even support both  and  by inheriting both base class interfaces located in the  package and in the  package."
W201,https://wiki.ros.org/costmap_queue,Wiki,costmap_queue,Tool for iterating through the cells of a costmap to find the closest distance to a subset of cells. 
W202,https://wiki.ros.org/prbt_support,Wiki,prbt_support,"Mechanical, kinematic and visual description
  of the Pilz light weight arm PRBT."
W203,https://wiki.ros.org/lanelet2_validation,Wiki,lanelet2_validation,"Package for sanitizing lanelet mapsTo test a map, simply run , or better , where lat/lon is an origin close to your map data. The tool will output errors and warnings that were found in your map. For advanced usage like running only a fraction of the tests, try . rosrun lanelet_validation lanelet2_validate <mymap>rosrun lanelet2_validation lanelet2_validate <mymap> --lat <lat> --lon <lon>rosrun lanelet2_validation lanelet2_validate --help"
W204,https://wiki.ros.org/dynamic_tf_publisher,Wiki,dynamic_tf_publisher,dynamically set the tf trensformation
W205,https://wiki.ros.org/pr2_gripper_sensor_action,Wiki,pr2_gripper_sensor_action,"The pr2_gripper_sensor_action package provides an action interface for talking to the pr2_gripper_sensor_controller real-time controller.

  It provides several different actions for getting high-level sensor information from the PR2 palm-mounted accelerometers, fingertip pressure arrays, and gripper motor/encoder, as well as several sensor-based gripper control actions that respond with low-latency in real-time. 
 








 














Tactile feedback provides critical information for completing any sensitive manipulation task. Often this tactile feedback needs to be used for closed-loop control to obtain a responsive and reliable system. The package  achieves this by bypassing the ROS messaging system and integrating sensory feedback with gripper control in real-time. This  package is used to communicate with the  at a higher level, and allows the user to send target goals to the real-time controller. Currently this package provides several capabilities in the form of action servers including: Below you can see a diagram of how these various action servers communicate with the real-time . Users who merely want to open or close the gripper with maximum joint effort do  need to use this package. If you are not worried about damaging the object being grasped, and are not interested in the signals generated during this interaction, you should refer to the simpler  package. The  package contains a set of action nodes. The  nodes provide implementations of  (see ).  The various actions subscribe and publish to a series of messages found in , but this API is not intended for use outside of the pr2_gripper_sensor_* packages. The public API for the various action servers is described in the following subsections, as well as a high-level description of what the node does. This package relies on several parameters being loaded onto the ROS . Currently this is done when the node is  by invoking the  file from the  package. If you wish to permanently edit any of the below values you should see this file. Many users may wish to modify some of these values temporarily and repeatedly during program run time. This can be done by loading a new value for the parameter below onto the param server, and then invoking the  to push these changes into the real-time controller. All the parameters listed below are currently loaded within the namespace of the real-time controller for each of the two PR2 grippers,  and . A  below indicates that the parameter is not reloadable with the . Users should refer to the  section for specific examples on using the action nodes defined below. Currently three  are provided to the user. These services communicate directly with the  package. Most users will generally not need to use them, however, advanced users may find them to come in handy. All services communicate using the standard Empty Request and Response message types. Please refer to the  page to understand the hardware dependencies necessary for this package to run properly. If you are not using pre-built libraries it is necessary to compile the real-time controller   to launching the PR2. By compiling the  library before launching the robot the  package will be automatically included as a dependency. SimpleActionServerpr2_gripper_sensor_controller.yamlr_gripper_sensor_controllerl_gripper_sensor_controller*close_speeddoublemax_joint_effortdoublefingertip_force_limitdoubledeformation_limitdoubleforce_lightestdoublehp_force_triggerdoubleforce_servo_force_tolerancedoubleforce_servo_velocity_tolerancedoubleslip_servo_start_forcedoubleposition_servo_position_tolerancedoubleposition_opendoublejoint_name*stringaccelerometer_name*stringleft_pressure_sensor_name*stringright_pressure_sensor_name*stringgrabposition_openclose_speedslip_servograbgripper_actionfind_contactforce_servoslip_servofind_contactforce_servo/r_gripper_sensor_controller/grabgripper_actionforce_servofind_contactslip_servograbposition_openreleaseevent_detectorreleaseposition_opengripper_action/r_gripper_sensor_controller/releasegripper_actionforce_servofind_contactslip_servograbposition_open/r_gripper_sensor_controller/gripper_actiongripper_actionforce_servofind_contactslip_servograbmax_effortmax_joint_effortmax_joint_effortposition_servo_position_toleranceforce_servo_force_toleranceforce_servo_velocity_tolerance/r_gripper_sensor_controller/force_servofind_contactforce_lightestforce_lightestfingertip_forcegripper_actionforce_servofind_contactslip_servograbmax_joint_effortfingertip_force_limitdeformation_limitforce_lightestforce_servo_force_toleranceforce_servo_velocity_toleranceclose_speedcontact_conditions/r_gripper_sensor_controller/find_contactzero_fingertip_sensorsfind_contacttrueforce_lightesthp_force_triggergripper_actionforce_servofind_contactslip_servograbclose_speedmax_joint_efforthp_force_triggerforce_servoslip_servo/r_gripper_sensor_controller/slip_servoslip_servo_gaingripper_actionforce_servofind_contactslip_servograbmax_joint_effortfingertip_force_limitdeformation_limitforce_lightestslip_servo_force_toleranceslip_servo_start_forcetrigger_conditions/r_gripper_sensor_controller/event_detectorgripper_actionforce_servofind_contactslip_servograbfind_contactzero_fingertip_sensorstruefind_contact/r_gripper_sensor_controller/zero_fingertip_sensors/r_gripper_sensor_controller/reload_params/r_gripper_sensor_controller/stop_motor_outputrosmake pr2_gripper_sensor_actionroslaunch pr2_gripper_sensor_action pr2_gripper_sensor_actions.launch"
W206,https://wiki.ros.org/jsk_robot_startup,Wiki,jsk_robot_startup,The jsk_robot_startup package
W207,https://wiki.ros.org/rqt_topic,Wiki,rqt_topic,"rqt_topic provides a GUI plugin for displaying debug information about ROS topics including publishers, subscribers, publishing rate, and ROS Messages.

sensor_msgs/Imagerqt"
W208,https://wiki.ros.org/nerian_stereo,Wiki,nerian_stereo,"Driver node for SceneScan and SP1 stereo vision sensors by Nerian Vision GmbH
 

 
 () 
 (, default: ) 
 

  The  by Nerian Vision Technologies is a stand-alone processing system for performing stereo matching in real time. It is connected to two industrial USB cameras that provide input image data.   correlates the images of both cameras and produces a disparity map, which is transmitted through gigabit ethernet. The disparity map describes a mapping of image points from the left camera image to corresponding image points in the right camera image. With this information it is possible to reconstruct the 3D location of the corresponding scene points. The data delivered by  can be received using the available open source API. Using the API directly is recommended for high performance applications. Alternatively the  ROS node can be used for publishing the received data as ROS messages. A Nodelet version is also provided. The behaviour of the node can be configured through various parameters. An example parameterization can be found in the included launch file . The following parameters are supported: The topics published by the nerian_stereo node can be viewed with . The disparity map can also be visualized with the  node. In this case color coding should be activated such that the disparity map can be displayed on a screen. In order to do so, please launch the image_view node as follows: nerian_stereo/nerian_stereo/point_cloud/nerian_stereo/disparity_map/nerian_stereo/left_image/nerian_stereo/right_image/nerian_stereo/stereo_camera_infonerian_stereo.launch~point_cloud_intensity_channelstring""mono8""~ros_coordinate_systembool""true""~ros_timestampsbool""true""~color_code_disparity_mapstring""none""~color_code_legendbool""true""~framestring""world""~remote_hoststring""0.0.0.0""~remote_portstring""7681""~use_tcpbool""false""~calibration_filestring""""~delay_executiondouble0~max_depthdouble-1sudo apt-get update
sudo apt-get install ros-`rosversion -d`-nerian-stereoroslaunch nerian_stereo nerian_stereo.launch device_address:=192.168.10.10 node_name:=nerian_stereo_01rosrun image_view image_view image:=/nerian_stereo/disparity_maprosrun image_view image_view image:=/nerian_stereo/left_imagerosrun rqt_reconfigure rqt_reconfigure"
W209,https://wiki.ros.org/rqt,Wiki,rqt,"rqt is a Qt-based framework for GUI development for ROS. It consists of three parts/metapackages
     (also builds against fuerte)  
 is a software framework of  that implements the various GUI tools in the form of plugins. One can run all the existing GUI tools as dockable windows within rqt! The tools can still run in a traditional standalone method, but rqt makes it easier to manage all the various windows on the screen at one moment.  supercedes the former GUI tools of ROS , which now is deprecated since ROS . 
 consists of three (+1) : 












 You can run any  tools/plugins easily by: Users can create their own plugins for rqt with either  or .  (as of Feb 2013) have already been created and more are slated for development. There's a policy for the development repositories of  and  (): ROSrqtrosrunrqtPythonC++rqtmetapackagesQtrqtQt 4.8Qt 5.3rqtrqtPythonC++rqtrqtrqtrqt_**rqtros-usersgroovy-develmaster$ rqt$ rosrun rqt_gui rqt_gui"
W210,https://wiki.ros.org/rviz_python_tutorial,Wiki,rviz_python_tutorial,Tutorials showing how to call into rviz internals from python scripts.
W211,https://wiki.ros.org/qt_ros,Wiki,qt_ros,"Simple qt cmake build tools and master-chooser style application template.

Refer to the . Use github to  or . roscreate-qt-legacy-pkg> sudo apt-get install ros-electric-qt-ros- git:
    uri: https://github.com/stonier/qt_ros.git
    local-name: qt_ros
    version: electric> sudo apt-get install ros-fuerte-qt-ros> sudo apt-get install python-pip
> sudo pip install --upgrade roscreate- git:
    uri: https://github.com/stonier/qt_ros.git
    local-name: qt_ros
    version: fuerte"
W212,https://wiki.ros.org/imu_sensor_controller,Wiki,imu_sensor_controller,"Controller to publish state of IMU sensors
See the  page for more information. "
W213,https://wiki.ros.org/youbot_gazebo_worlds,Wiki,youbot_gazebo_worlds,Gazebo worlds configurations
W214,https://wiki.ros.org/xbot_tools,Wiki,xbot_tools,"The xbot_tools package






"
W215,https://wiki.ros.org/turtlebot3_example,Wiki,turtlebot3_example,"This package provides four TurtleBot3 basic example include move using interactive marker, move and stop using LDS, move to goal position, move to custom routes. The interactions node is that you can control the TurtleBot3 front and back side or rotate to goal position. The obstacle node is that when the robot meets an obstacle, it stops. The patrol node is that TurtleBot3 move to custom route. There are 3 route(square, triangle, circle) in this package. You can add your route and move the TurtleBot3. The pointop node is that you can insert goal position include distance x-axis, y-axis and angluar z-axis. 







 () 
 () 

 () 
 () 
turtlebot3_marker_servercmd_velturtlebot3_marker_server/updateturtlebot3_marker_server/update_fulljoint_statestftf_staticscancmd_velodomcmd_velturtlebot3/resultturtlebot3/goalturtlebot3_server/goalturtlebot3_server/resultturtlebot3_server/feedbackjoint_statesodom"
W216,https://wiki.ros.org/joint_trajectory_controller,Wiki,joint_trajectory_controller,"Controller for executing joint-space trajectories on a group of joints.





 Even when a goal has been aborted, the controller will still attempt to execute the trajectory as best as possible. 













 The controller is templated to work with multiple hardware interface types.  Currently joints with ,  and  interfaces are supported. For position-controlled joints, desired positions are simply forwarded to the joints; while for velocity (effort) joints, the position+velocity trajectory following error is mapped to velocity (effort) commands through a PID loop. Example controller configurations can be found . There are two mechanisms for sending trajectories to the controller: by means of the  or the . Both use the  message to specify trajectories, and require specifying values for  the controller joints (as opposed to only a subset) if allow_partial_joints_goal is not set to True. The primary way to send trajectories is through the , and should be favored when execution monitoring is desired. Action goals allow to specify not only the trajectory to execute, but also (optionally) path and goal tolerances. When no tolerances are specified, the defaults given in the parameter server are used (see  below). If tolerances are violated during trajectory execution, the action goal is aborted and the client is notified. The  is a fire-and-forget alternative. Use this interface if you don't care about execution monitoring. The controller's path and goal tolerance specification is  used in this case, as there is no mechanism to notify the sender about tolerance violations. Note that although some degree of monitoring is available through the  service and  topic (see  below), it is much more cumbersome to realize than with the action interface. Only one action goal can be active at any moment, or none if the topic interface is used. Path and goal tolerances are checked  for the trajectory segments of the active goal. Sending an  message from the  (not the action interface) will stop the execution of all queued trajectories and enter position hold mode. The  parameter controls the duration of the stop motion. Joint trajectory messages allow to specify the time at which a new trajectory should start executing by means of the header timestamp, where zero time (the default) means . The arrival of a new trajectory command does  mean that the controller will completely discard the currently running trajectory and substitute it with the new one. Rather, the controller will take the useful parts of both and combine them appropriately. Please refer to the  page for a detailed description of this behavior. The controller exposes a  interface in the  namespace of the controller. See the action definition for more information on what to send. query_statestatestop_trajectory_durationfollow_joint_trajectorycommandstatequery_statejointsstring[]constraints/goal_timedoubleconstraints/stopped_velocity_tolerancedoubleconstraints/<joint>/goaldoubleconstraints/<joint>/trajectorydoublegains/<joint>associative arrayvelocity_ff/<joint>doublestop_trajectory_durationdoublestate_publish_ratedoubleaction_monitor_ratedoubleallow_partial_joints_goalboolhead_controller:
  type: ""position_controllers/JointTrajectoryController""
  joints:
    - head_1_joint
    - head_2_jointhead_controller:
  type: ""velocity_controllers/JointTrajectoryController""
  joints:
    - head_1_joint
    - head_2_joint

  gains: # Required because we're controlling a velocity interface
    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}
    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}head_controller:
  type: ""velocity_controllers/JointTrajectoryController""
  joints:
    - head_1_joint
    - head_2_joint

  gains: # Required because we're controlling a velocity interface
    head_1_joint: {p: 10,  d: 1, i: 1, i_clamp: 1} # Smaller 'p' term, since ff term does most of the work
    head_2_joint: {p: 10,  d: 1, i: 1, i_clamp: 1} # Smaller 'p' term, since ff term does most of the work

  velocity_ff:
    head_1_joint: 1.0
    head_2_joint: 1.0head_controller:
  type: ""effort_controllers/JointTrajectoryController""
  joints:
    - head_1_joint
    - head_2_joint

  gains: # Required because we're controlling an effort interface
    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}
    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}head_controller:
  type: ""effort_controllers/JointTrajectoryController""
  joints:
    - head_1_joint
    - head_2_joint

  constraints:
    goal_time: 0.5                   # Override default
    stopped_velocity_tolerance: 0.02 # Override default
    head_1_joint:
      trajectory: 0.05               # Not enforced if unspecified
      goal: 0.02                     # Not enforced if unspecified
    head_2_joint:
      goal: 0.01                     # Not enforced if unspecified

  gains: # Required because we're controlling an effort interface
    head_1_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}
    head_2_joint: {p: 100,  d: 1, i: 1, i_clamp: 1}

  state_publish_rate:  25            # Override default
  action_monitor_rate: 30            # Override default
  stop_trajectory_duration: 0        # Override default"
W217,https://wiki.ros.org/rtmbuild,Wiki,rtmbuild,Build scripts for OpenRTM and OpenHRP
W218,https://wiki.ros.org/lanelet2_traffic_rules,Wiki,lanelet2_traffic_rules,Package for interpreting traffic rules in a lanelet map
W219,https://wiki.ros.org/mavros_extras,Wiki,mavros_extras,"Extra nodes and plugins for .





 only. Require  package, use . 

This package provides additional nodes and plugins not included to . All utilities provides <util> --help and <util> <command> --help information.  Extra set of communication plugins loaded by . mavlink/frommavlink/gcs_imagemavlink/to~gcs_urlstring~jpeg_qualityintlocal_positionlocal_setpointtrack_markersvehicle_markerwp_markers~fixed_frame_idstring~child_frame_idstring~marker_scaledouble~num_rotorsint~arm_lendouble~body_widthdouble~body_heightdouble~max_track_sizeintsudo pip install fusepy~distance_sensor/<sensor_name>~distance_sensor/<sensor_name>~distance_sensor/<sensor_name>/subscriberbool~distance_sensor/<sensor_name>/idint~distance_sensor/<sensor_name>/orientationstring~image/camera_image~image/frame_idstring~mocap/pose~mocap/tf~mocap/use_tfbool~mocap/use_poseboolOPTICAL_FLOW_RAD~px4flow/raw/optical_flow_rad~px4flow/ground_distance~px4flow/temperature~px4flow/frame_idstring~px4flow/ranger_fovdouble~px4flow/ranger_min_rangedouble~px4flow/ranger_max_rangedouble~vision_pose/pose~vision_pose/pose_cov~vision_pose/tf/listenbool~vision_pose/tf/frame_idstring~vision_pose/tf/child_frame_idstring~vision_pose/tf/rate_limitdouble~vision_speed/speed_vector~vision_speed/speed_twist~vision_speed/listen_twistboolusage: mavteleop [-h] [-n MAVROS_NS] [-v] (-rc | -att | -vel | -pos)

Teleoperation script for Copter-UAV

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose output
  -rc, --rc-override    use rc override control type
  -att, --sp-attitude   use attitude setpoint control type
  -vel, --sp-velocity   use velocity setpoint control type
  -pos, --sp-position   use position setpoint control typeusage: mavftpfuse [-h] [-n MAVROS_NS] [-v] [-d] path

FUSE for MAVLink-FTP mavros plugin

positional arguments:
  path                  mount point

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose output
  -d, --debug           libfuse debug"
W220,https://wiki.ros.org/rosping,Wiki,rosping,"rosping is the tool to send ICMP ECHO_REQUEST to network hosts where roscore is running, and send back to you as rostopic message. 
    For echoing ROS node, use . is the tool to send ICMP ECHO_REQUEST to network hosts and send back to you as rostopic message 
 


 send ICMP ECHO_REQUEST to <host> rospingrosping <host>hostrosping~delay~ratefloat$ rosrun rosping rosping 8.8.8.8
32 bytes from 8.8.8.8: icmp_seq=131, ttl=45, time=40.958 ms
32 bytes from 8.8.8.8: icmp_seq=132, ttl=45, time=40.856 ms
$ rostopic echo ping/delay
data: 40.903
---
data: 40.961"
W221,https://wiki.ros.org/rosflight_firmware,Wiki,rosflight_firmware,"Firmware library for software-in-the-loop of the ROSflight ROS stack
This package provides a ROS wrapper for the , and also provides a board implementation with UDP serial communication functionality. These are used by the  package for software-in-the-loop simulation. "
W222,https://wiki.ros.org/rqt_srv,Wiki,rqt_srv,"A Python GUI plugin for introspecting available ROS message types.
  Note that the srvs available through this plugin is the ones that are stored
  on your machine, not on the ROS core your rqt instance connects to."
W223,https://wiki.ros.org/py_trees_msgs,Wiki,py_trees_msgs,Messages used by py_trees_ros and some extras for the mock demos/tests.
W224,https://wiki.ros.org/velodyne_msgs,Wiki,velodyne_msgs,"ROS message definitions for Velodyne 3D LIDARs.

This package collects all ROS messages that are specific to Velodyne 3D LIDARs, simplifying the dependencies between  stack components and their users.  It also provides bag migration scripts for translating old captured data to the latest format using the  command. "
W225,https://wiki.ros.org/yocs_virtual_sensor,Wiki,yocs_virtual_sensor,"Virtual sensor that uses semantic map information to ""see"" obstacles undetectable by robot sensors.
      
      Current implementation cannot read obstacles from YAML files. Until this feature gets implemented, we
      use auxiliary scripts to read and publish files' content. Data directory contains some example files."
W226,https://wiki.ros.org/roslisp,Wiki,roslisp,"Lisp client library for ROS, the Robot Operating System.




See the  for a guide to roslisp's features. Roslisp is part of the stable ROS core distribution, and follows the .   See the  for future changes. Roslisp is based on the  version of Common Lisp. It is defined as a system dependency in the roslisp ROS package. "
W227,https://wiki.ros.org/bayesian_belief_networks,Wiki,bayesian_belief_networks,"The bayesian_belief_networks package form https://github.com/eBay/bayesian-belief-networks, Authored by Neville Newey, Anzar Afaq, Copyright 2013 eBay Software Foundation"
W228,https://wiki.ros.org/nav2_bringup,Wiki,nav2_bringup,ROS launch files for Nav2 Robot Platform bringup
W229,https://wiki.ros.org/rosbridge_library,Wiki,rosbridge_library,"The core rosbridge package, repsonsible for interpreting JSON andperforming
    the appropriate ROS action, like subscribe, publish, call service, and
    interact with params.Rosbridge library is a Python library responsible for taking JSON strings and converting them to ROS messages, and vice versa. Rosbridge library is meant to be used as a library for transport layer packages. For example, the rosbridge_server package creates a  connection and uses the rosbridge library to handle the JSON to ROS conversion. "
W230,https://wiki.ros.org/qt_gui,Wiki,qt_gui,"qt_gui provides the infrastructure for an integrated graphical user interface based on Qt.
    It is extensible with Python- and C++-based plugins (implemented in separate packages) which can contribute arbitrary widgets.
    It requires either PyQt or PySide bindings."
W231,https://wiki.ros.org/seed_r7_typef_moveit_config,Wiki,seed_r7_typef_moveit_config,An automatically generated package with all the configuration and launch files for using the SEED-Noid-Mover-typeF with the MoveIt! Motion Planning Framework
W232,https://wiki.ros.org/rqt_joint_trajectory_plot,Wiki,rqt_joint_trajectory_plot,"The rqt_joint_trajectory_plot package
    This package is to plot  message and  action in real time. Then launch ! Now you can control the UR5 using . Then run rqt and add  plugin. Choose the trajectory topic.  $ roslaunch fake_joint_launch ur5.launch  $ roslaunch ur5_moveit_config ur5_moveit_planning_execution.launch sim:=true  $ rqt "
W233,https://wiki.ros.org/librealsense2,Wiki,librealsense2,"Library for capturing data from the Intel(R) RealSense(TM) SR300, D400 Depth cameras and T2xx Tracking devices. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of RealSense(TM); devices are implemented in this project.
 is a cross-platform library (Linux, OSX, Windows) for capturing data from the Intel® ™ SR300 and D400 cameras. It allows depth and color streaming, and provides intrinsic and extrinsic calibration information. The library also offers synthetic streams (pointcloud, depth aligned to color and vise-versa), and a built-in support for record and playback of streaming sessions. This effort was initiated to better support researchers, creative coders, and app developers in domains such as robotics, virtual reality, and the internet of things. Several often-requested features of ™ devices are implemented in this project, including multi-camera capture. 


 The Intel® ™ D415 and D435 cameras are . Installation instructions can be found . The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS  packages. Please  concerning this package to the realsense2_camera  Issues. For updated details on this library see the . "
W234,https://wiki.ros.org/moveit_ros_warehouse,Wiki,moveit_ros_warehouse,Components of MoveIt! connecting to MongoDB
W235,https://wiki.ros.org/jsk_common,Wiki,jsk_common,"Metapackage that contains commonly used toolset for jsk-ros-pkg

  "
W236,https://wiki.ros.org/astra_camera,Wiki,astra_camera,"Drivers for Orbbec Astra Devices.









 If you didn't add source $YOUR_WORKSPACE/devel/setup.bash to your .bashrc, remember to source it when open a new terminal  This package provides multiple  for users to get useful information and set up devices. To know more about using these services, please check . sudo apt install ros-*-rgbd-launch ros-*-libuvc ros-*-libuvc-camera ros-*-libuvc-rosmkdir -p
/catkin_ws/src
/catkin_ws/
catkin_make/catkin_ws/src
git clone https://github.com/orbbec/ros_astra_cameraroscd astra_camera
./scripts/create_udev_rules/catkin_ws
catkin_make --pkg astra_camerarosservice call /camera/get_ir_exposurerosservice call /camera/set_ir_exposurerosservice call /camera/set_laser
rosservice call /camera/set_laserrosservice call /camera/switch_ir_camera
rosservice call /camera/switch_ir_camera echo 64 > /sys/module/usbcore/parameters/usbfs_memory_mb"
W237,https://wiki.ros.org/swri_yaml_util,Wiki,swri_yaml_util,"Provides wrappers around the yaml-cpp library for various utility functions
    and to abstract out the API changes made to yaml-cpp between ubuntu:precise
    and ubuntu:trusty."
W238,https://wiki.ros.org/wireless_msgs,Wiki,wireless_msgs,"Messages for describing a wireless network such as bitrate, essid, and link quality."
W239,https://wiki.ros.org/mavros,Wiki,mavros,"MAVROS -- MAVLink extendable communication node for ROS
    with proxy for Ground Control Station.







 only. 





Main node can be extended by plugins (see ). See also  package. If you unsure what firmware your FCU runs start apm.launch and see . Starting from 0.11 mavros knows string representation for autopilot mavlink enum. For older you shall manually find autopilot type value in mavlink documentation.  All utilities provides  and  information. Supported custom modes listed at . Standard set of communication plugins loaded by . Note: this list for  version. Older versions: , , , , , , . mavlink/tomavlink/fromdiagnostics~system_idint~component_idint~target_system_idint~target_component_idint~startup_px4_usb_quirkbool~plugin_blackliststring[]~plugin_whiteliststring[]~fcu_urlstring~fcu_protocolstring~gcs_urlstringros_udpmavlink/frommavlink/to~gcs_urlstringmavros/state<trigger_event>~<event_name>/servicestring~<event_handler>/eventstring[]~<event_handler>/actionstring[]~<event_handler>/shellstring~<event_handler>/logfilestring/path/to/serial/device[:baudrate]serial:///path/to/serial/device[:baudrate][/?ids=sysid,compid]serial-hwfc:///path/to/serial/device[:baudrate][?ids=sysid,compid]udp://[bind_host][:port]@[remote_host][:port][/?ids=sysid,compid]udp-b://[bind_host][:port]@[:port][/?ids=sysid,compid]tcp://[server_host][:port][/?ids=sysid,compid]tcp-l://[bind_host][:port][/?ids=sysid,compid]~system_id~component_idbaudratebind_hostremote_hostserver_hostport<util> --help<util> <command> --help~radio_status~actuator_control~hil_controls/hil_controls~frame_idstring~cmd/command~cmd/command_int~cmd/arming~cmd/set_home~cmd/takeoff~cmd/land~cmd/trigger_control~cmd/use_comp_id_system_controlboolSYSTEM_CONTROL~ftp/open~ftp/close~ftp/read~ftp/write~ftp/list~ftp/truncate~ftp/remove~ftp/rename~ftp/mkdir~ftp/rmdir~ftp/checksum~ftp/reset~global_position/global~global_position/local~global_position/gp_vel~global_position/rel_alt~global_position/compass_hdg~global_position/raw/fix~global_position/raw/gps_vel~global_position/frame_idstring~global_position/tf/sendbool~global_position/tf/frame_idstring~global_position/tf/child_frame_idstring~imu/data~imu/data_raw~imu/mag~imu/temperature~imu/atm_pressure~imu/frame_idstring~imu/linear_acceleration_stdevdouble~imu/angular_velocity_stdevdouble~imu/orientation_stdevdouble~imu/magnetic_stdevdouble~local_position/pose~local_position/velocity~local_position/frame_idstring~local_position/tf/sendbool~local_position/tf/frame_idstring~local_position/tf/child_frame_idstring~manual_control/send~manual_control/control~param/~param/pull~param/push~param/get~param/set~rc/overrideSYSID_MYGCS~rc/in~rc/out~safety_area/set~safety_area/p1/xdouble~safety_area/p1/ydouble~safety_area/p1/zdouble~safety_area/p2/xdouble~safety_area/p2/ydouble~safety_area/p2/zdouble~setpoint_accel/accel~setpoint_accel/send_forcebool~setpoint_attitude/cmd_vel~setpoint_attitude/attitude~setpoint_attitude/thrust~setpoint_attitude/reverse_throttlebool~setpoint_attitude/use_quaternionbool~setpoint_attitude/tf/listenbool~setpoint_attutude/tf/frame_idstring~setpoint_attitude/tf/child_frame_idstring~setpoint_attitude/tf/rate_limitdouble~setpoint_position/global~setpoint_position/local~setpoint_position/tf/listenbool~setpoint_position/tf/frame_idstring~setpoint_position/tf/child_frame_idstring~setpoint_position/tf/rate_limitdouble~setpoint_raw/local~setpoint_raw/global~setpoint_raw/attitude~setpoint_raw/target_local~setpoint_raw/target_global~setpoint_raw/target_attitude~setpoint_velocity/cmd_vel_unstamped~state~battery~battery~extended_state~set_stream_rate~set_mode~conn/timeoutdouble~conn/heartbeat_ratedouble~sys/min_voltagedouble~sys/disable_diagbool~time_reference~conn/system_time_ratedoubleSYSTEM_TIME~conn/timesync_ratedouble~time/time_ref_sourcestring~time/timesync_avg_alphadouble~vfr_hud~wind_estimation~mission/reached~mission/waypoints~mission/pull~mission/push~mission/clear~mission/set_current~mission/pull_after_gcsbooltf/roslaunch mavros px4.launchroslaunch mavros apm.launchusage: mavcmd [-h] [-n MAVROS_NS] [-v] [--wait]
              {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}
              ...

Commad line tool for sending commands to MAVLink device.

positional arguments:
  {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}
    long                Send any command (COMMAND_LONG)
    int                 Send any command (COMMAND_INT)
    sethome             Request change home position
    takeoff             Request takeoff
    land                Request land
    takeoffcur          Request takeoff from current GPS coordinates
    landcur             Request land on current GPS coordinates
    trigger_control     Control onboard camera trigerring system (PX4)

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose output
  --wait                Wait for establishing FCU connectionusage: mavftp [-h] [-n MAVROS_NS] [-v]
              {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}
              ...

File manipulation tool for MAVLink-FTP.

positional arguments:
  {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}
    cd                  change directory
    list                list files and dirs
    cat                 cat file
    remove              remove file
    mkdir               create direcotory
    rmdir               remove directory
    download            download file
    upload              upload file
    verify              verify files
    reset               reset

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose outputusage: mavparam [-h] [-n MAVROS_NS] [-v] {load,dump,get,set} ...

Commad line tool for getting, setting, parameters from MAVLink device.

positional arguments:
  {load,dump,get,set}
    load                load parameters from file
    dump                dump parameters to file
    get                 get parameter
    set                 set parameter

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose outputusage: mavsafety [-h] [-n MAVROS_NS] [-v] {arm,disarm,safetyarea} ...

Commad line tool for manipulating safty on MAVLink device.

positional arguments:
  {arm,disarm,safetyarea}
    arm                 Arm motors
    disarm              Disarm motors
    safetyarea          Send safety area

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose outputusage: mavsetp [-h] [-n MAVROS_NS] [-V] {local} ...

Commad line tool for control the device by setpoints.

positional arguments:
  {local}
    local               Send local setpoint

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -V, --verbose         verbose outputusage: mavsys [-h] [-n MAVROS_NS] [-v] [--wait] {mode,rate} ...

Change mode and rate on MAVLink device.

positional arguments:
  {mode,rate}
    mode                Set mode
    rate                Set stream rate

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose output
  --wait                Wait for establishing FCU connectionusage: mavwp [-h] [-n MAVROS_NS] [-v]
             {show,load,pull,dump,clear,setcur,goto} ...

Commad line tool for manipulating mission on MAVLink device.

positional arguments:
  {show,load,pull,dump,clear,setcur,goto}
    show                Show waypoints
    load                load waypoints from file
    pull                pull waypoints from FCU
    dump                dump waypoints to file
    clear               clear waypoints on device
    setcur              set current waypoints on device
    goto                send goto waypoint (APM only)

optional arguments:
  -h, --help            show this help message and exit
  -n MAVROS_NS, --mavros-ns MAVROS_NS
                        ROS node namespace
  -v, --verbose         verbose output"
W240,https://wiki.ros.org/jackal_control,Wiki,jackal_control,"Controllers for Jackal
's mobility is controlled by . "
W241,https://wiki.ros.org/joint_qualification_controllers,Wiki,joint_qualification_controllers,"Controllers used in PR2 hardware testing. For testing counterbalance of PR2, and for internal WG use.
"
W242,https://wiki.ros.org/velocity_controllers,Wiki,velocity_controllers,"velocity_controllers
See the  page for more information. "
W243,https://wiki.ros.org/moveit,Wiki,moveit,"Meta package that contains all essential package of MoveIt!. Until Summer 2016 MoveIt! had been developed over multiple repositories, where developers' usability and maintenance effort was non-trivial. See .All documentation for MoveIt! is on the . "
W244,https://wiki.ros.org/jackal_navigation,Wiki,jackal_navigation,"Launch files and code for autonomous navigation of the Jackal
The jackal_navigation package contains configuration and launch files for running  on . For usage, please see .  "
W245,https://wiki.ros.org/perception_pcl,Wiki,perception_pcl,"PCL (Point Cloud Library) ROS interface stack. PCL-ROS is the preferred
  bridge for 3D applications involving n-D Point Clouds and 3D geometry
  processing in ROS.


Use GitHub to . []
 Please see  for documentation and tutorials on using PCL with ROS. "
W246,https://wiki.ros.org/jsk_baxter_startup,Wiki,jsk_baxter_startup,The jsk_baxter_startup package
W247,https://wiki.ros.org/velodyne_driver,Wiki,velodyne_driver,"ROS device driver for Velodyne 3D LIDARs.

: the  parameter now expects an exact name: ""VLP16"", ""32C"", ""32E"", ""64E"", ""64E_S2"", ""64E_S2.1"", or ""64E_S3"", and generates the correct packet rates for them.
 : The VLP-16 (""Puck"") model is now supported.
 : The VLP-32C (""Ultra Puck"") model is now supported.
 : The HDL-64E S3 model is now supported. 



 



This package provides basic device handling for Velodyne 3D LIDARs. For a list of all supported models refer to the  section. The driver publishes device-dependent  data. The  package provides nodes and nodelets to convert those data into more-convenient  messages. The  describes the evolution of these interfaces. Read the Velodyne HDL-64E (default) input socket as fast as possible. Publish each complete revolution to . Read the Velodyne Velodyne HDL-32E input socket as fast as possible. Publish each complete revolution to . Read previously captured Velodyne packets from dump.pcap file. Publish messages to  at approximately 10 Hz rate. Dump files can be grabbed by , Velodyne's DSR software, , , , or the  command. The  command dumps raw data from the Velodyne LIDAR in PCAP format. It is a shell script wrapper providing some obscure options for the powerful  command. Other methods of acquiring PCAP data include using  directly, , Velodyne's DSR software, and programming with . Dump Velodyne packets from the  interface to a series of files named , , etc. Each file will be about 100MB. The time span that a single 100MB file covers depends on packet size and sampling rate of a particular model (for VLP-16 that is about 100 seconds worth of packets). Type  when finished. Start a  process running the driver nodelet. Other nodelets using the same nodelet manager process will have zero-copy access to the raw data messages the driver publishes. Start a  process for a Velodyne HDL-32E. Start a driver nodelet with input from , in the current directory. The  provides a full path name, as required for . model/velodynetf_prefixvelodyne_packetsvelodyne_packetsvelodyne_packetslibpcapetherealwiresharktcpdumpvdumptcpdumptcpdumpwiresharklibpcapeth1pcap-000pcap-001^Cvelodyne_nodelet_managervelodyne_nodelet_managertcpdump.pcappwdroslaunch$ rosrun velodyne_driver velodyne_node $ rosrun velodyne_driver velodyne_node _model:=32E$ rosrun velodyne_driver velodyne_node _pcap:=dump.pcap  rosrun velodyne_driver vdump <file_prefix> [ <interface> ]

        <file_prefix>   file name to dump (with 3-digit number suffix)
        <interface>     interface to read from (default: ""eth0"")$ rosrun velodyne_driver vdump pcap- eth1 $ roslaunch velodyne_driver nodelet_manager.launch $ roslaunch velodyne_driver nodelet_manager.launch model:=32E $ roslaunch velodyne_driver nodelet_manager.launch pcap:=$(pwd)/tcpdump.pcap"
W248,https://wiki.ros.org/ypspur_ros,Wiki,ypspur_ros,ROS wrapper for the mobile robot control platform YP-Spur
W249,https://wiki.ros.org/rqt_runtime_monitor,Wiki,rqt_runtime_monitor,"rqt_runtime_monitor provides a GUI plugin viewing DiagnosticsArray messages.
rosrun rqt_runtime_monitor rqt_runtime_monitor"
W250,https://wiki.ros.org/seed_r7_ros_pkg,Wiki,seed_r7_ros_pkg,The seed_r7_ros_pkg package
W251,https://wiki.ros.org/mrpt_navigation,Wiki,mrpt_navigation,"Tools related to the Mobile Robot Programming Toolkit (MRPT).
    Refer to http://wiki.ros.org/mrpt_navigation for further documentation.



 
 


Use GitHub to . []
 See also: . rosbag playrosbag record# This will install all packages in the mrpt_navigation metapackage
# Alternatively, install individual packages only as you need them
sudo apt-get install ros-$ROS_DISTRO-mrpt-navigation"
W252,https://wiki.ros.org/yujin_maps,Wiki,yujin_maps,The yujin_maps package
W253,https://wiki.ros.org/rqt_controller_manager,Wiki,rqt_controller_manager,The rqt_controller_manager package
W254,https://wiki.ros.org/diff_drive_controller,Wiki,diff_drive_controller,"Controller for a differential drive mobile base.













 The controller works with wheel joints through a  interface. The controller main input is a  topic in the namespace of the controller. The current implementation allows you to register multiple wheels per side and will average those wheel positions in its odometry calculations. For more info read the code and . cmd_velodom/tfpublish_cmdleft_wheelstring | string[...]right_wheelstring | string[...]pose_covariance_diagonaldouble[6]twist_covariance_diagonaldouble[6]publish_ratedoublewheel_separation_multiplierdoublewheel_radius_multiplierdoublecmd_vel_timeoutdoublebase_frame_idstringlinear/x/has_velocity_limitsboollinear/x/max_velocitydoublelinear/x/min_velocitydoublelinear/x/has_acceleration_limitsboollinear/x/max_accelerationdoublelinear/x/min_accelerationdoublelinear/x/has_jerk_limitsboollinear/x/max_jerkdoubleangular/z/has_velocity_limitsboolangular/z/max_velocitydoubleangular/z/min_velocitydoubleangular/z/has_acceleration_limitsboolangular/z/max_accelerationdoubleangular/z/min_accelerationdoubleangular/z/has_jerk_limitsboolangular/z/max_jerkdoubleenable_odom_tfboolwheel_separationdoublewheel_radiusdoubleodom_frame_idstringpublish_cmdboolallow_multiple_cmd_vel_publishersboolmobile_base_controller:
  type: ""diff_drive_controller/DiffDriveController""
  left_wheel: 'wheel_left_joint'
  right_wheel: 'wheel_right_joint'
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]mobile_base_controller:
  type        : ""diff_drive_controller/DiffDriveController""
  left_wheel  : 'wheel_left_joint'
  right_wheel : 'wheel_right_joint'
  publish_rate: 50.0               # default: 50
  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]

  # Wheel separation and diameter. These are both optional.
  # diff_drive_controller will attempt to read either one or both from the
  # URDF if not specified as a parameter
  wheel_separation : 1.0
  wheel_radius : 0.3

  # Wheel separation and radius multipliers
  wheel_separation_multiplier: 1.0 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0

  # Velocity commands timeout [s], default 0.5
  cmd_vel_timeout: 0.25

  # Base frame_id
  base_frame_id: base_footprint #default: base_link

  # Velocity and acceleration limits
  # Whenever a min_* is unspecified, default to -max_*
  linear:
    x:
      has_velocity_limits    : true
      max_velocity           : 1.0  # m/s
      min_velocity           : -0.5 # m/s
      has_acceleration_limits: true
      max_acceleration       : 0.8  # m/s^2
      min_acceleration       : -0.4 # m/s^2
      has_jerk_limits        : true
      max_jerk               : 5.0  # m/s^3
  angular:
    z:
      has_velocity_limits    : true
      max_velocity           : 1.7  # rad/s
      has_acceleration_limits: true
      max_acceleration       : 1.5  # rad/s^2
      has_jerk_limits        : true
      max_jerk               : 2.5  # rad/s^3jackal_velocity_controller:
  type: ""diff_drive_controller/DiffDriveController""
  left_wheel: ['front_left_wheel', 'rear_left_wheel']
  right_wheel: ['front_right_wheel', 'rear_right_wheel']
  publish_rate: 50
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 0.03]
  twist_covariance_diagonal: [0.001, 0.001, 0.001, 1000000.0, 1000000.0, 0.03]
  cmd_vel_timeout: 0.25

  # Odometry fused with IMU is published by robot_localization, so
  # no need to publish a TF based on encoders alone.
  enable_odom_tf: false

  # Wheel separation and radius multipliers
  wheel_separation_multiplier: 1.5 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0

  # Velocity and acceleration limits
  # Whenever a min_* is unspecified, default to -max_*
  linear:
    x:
      has_velocity_limits    : true
      max_velocity           : 2.0   # m/s
      has_acceleration_limits: true
      max_acceleration       : 20.0   # m/s^2
  angular:
    z:
      has_velocity_limits    : true
      max_velocity           : 4.0   # rad/s
      has_acceleration_limits: true
      max_acceleration       : 25.0   # rad/s^2"
W255,https://wiki.ros.org/serial,Wiki,serial,"Serial is a cross-platform, simple to use library for using serial ports on computers.
    This library provides a C++, object oriented interface for interacting with RS-232
    like devices on Linux and Windows.The serial package is documented on its website:  "
W256,https://wiki.ros.org/jackal_robot,Wiki,jackal_robot,"Metapackage of software to install on Jackal.
Metapackage capturing software to be installed on . "
W257,https://wiki.ros.org/librviz_tutorial,Wiki,librviz_tutorial,Tutorial showing how to compile your own C++ program with RViz displays and features. Please see the  page. 
W258,https://wiki.ros.org/yocs_ar_marker_tracking,Wiki,yocs_ar_marker_tracking,"Collecting, tracking and generating statistics for ar markers from ar_track_alvar."
W259,https://wiki.ros.org/hrpsys_tools,Wiki,hrpsys_tools,The hrpsys_tools package
W260,https://wiki.ros.org/stomp_plugins,Wiki,stomp_plugins,This package provides additional plugins that can be used by the STOMP MoveIt planner
W261,https://wiki.ros.org/mrpt_reactivenav2d,Wiki,mrpt_reactivenav2d,"Reactive navigation for 2D robots using MRPT navigation algorithms (TP-Space)



After installing  and , run: roslaunch mrpt_reactivenav2d reactive_nav_demo_with_mvsim.launch"
W262,https://wiki.ros.org/ff,Wiki,ff,ff: pddl planner. see http://www.loria.fr/~hoffmanj/ff.html
W263,https://wiki.ros.org/yumi_moveit_config,Wiki,yumi_moveit_config,An automatically generated package with all the configuration and launch files for using the yumi with the MoveIt Motion Planning Framework
W264,https://wiki.ros.org/xv_11_laser_driver,Wiki,xv_11_laser_driver,"Neato XV-11 Laser Driver. This driver works with the laser when it is removed from the XV-11 Robot as opposed to reading scans from the Neato's USB port.



 is a C++ library for reading the data from the XV11's laser and packing that data into a . As a standalone library, it has no ROS API. neato_laser_publisherxv11_laser_driverscan~portstring~baud_rateint~firmware_versionint~frame_idstringxv11_laser_driver"
W265,https://wiki.ros.org/plotjuggler,Wiki,plotjuggler,PlotJuggler: juggle with data  Find out more here:  
W266,https://wiki.ros.org/controller_manager_tests,Wiki,controller_manager_tests,controller_manager_tests
W267,https://wiki.ros.org/single_joint_position_action,Wiki,single_joint_position_action,"The single joint position action is a node that provides an action
  interface for commanding a trajectory to move a joint to a particular
  position. The action reports success when the joint reaches the desired
  position. 







See also , which is used by this action. You can find an example of using the single joint position action on the PR2 in the . The joint trajectory action provides an action server (see ) that takes in goals of the type . ~jointstring~goal_thresholddouble~position_joint_action/goal~position_joint_action/cancel~position_joint_action/feedback~position_joint_action/status~position_joint_action/result~state~command"
W268,https://wiki.ros.org/web_video_server,Wiki,web_video_server,"HTTP Streaming of ROS Image Topics in Multiple Formats




 (, default: original width) 
 (, default: 95) 
 (, default: mjpeg) 
 (, default: 95) 
 (, default: 100000) 





 Several parameters can be configure via the video stream URL - Example:  More information on the quality and profile parameter of the VP8 codec can be found here:  Rate at which  subscribes a image topic depends on the publisher's publish rate. With a fast publish rate, a client host may unintentionally get busy. As of version 0.2.1,  does not come with a feature to control the rate at which the frontend subscribes to an image topic. You can work this around on your client. One way is to republish the image topic with a lower rate. You can use . View compressed stream at:  Source code is available at . Please send bug reports to the . Feel free to contact us at any point with questions and comments. ~portinteger~addressstring~server_threadsinteger~ros_threadsintegerhttp://localhost:8080/http://localhost:8080/stream_viewer?topic={ROS_TOPIC}http://localhost:8080/stream?topic={ROS_TOPIC}http://localhost:8080/snapshot?topic={ROS_TOPIC}widthintegerheightintegerqualityintegerinvertnonedefault_transportstringqualityintegertypestringqualityintegerbitrateintegerqminintegerqmaxintegergopintegerqualitystringweb_video_serverweb_video_serverhttp://localhost:8080/stream?topic=/usb_cam/image_raw&type=ros_compressed$ rostopic list
/usb_cam/camera_info
/usb_cam/image_raw/compressed"
W269,https://wiki.ros.org/moveit_ros_planning_interface,Wiki,moveit_ros_planning_interface,Components of MoveIt! that offer simpler interfaces to planning and execution
W270,https://wiki.ros.org/xpp_examples,Wiki,xpp_examples,"Examples of how to use the xpp framework.
  
$ sudo apt-get update
$ sudo apt-get install ros-[distro-name]-xpp
$ roslaunch xpp_examples hyq_ex.launch
$ roslaunch xpp_examples biped_ex.launch
$ roslaunch xpp_examples quadrotor_ex.launch
$ roslaunch xpp_examples monoped_ex_bag.launch
$ roslaunch xpp_examples monoped_ex_generate.launch"
W271,https://wiki.ros.org/leap_motion,Wiki,leap_motion,"ROS driver for the Leap Motion gesture sensor
 is a ROS wrapper for interfacing with the Leap Motion 3D gesture sensor API (). For the most up to date information you can check our Github repository . "
W272,https://wiki.ros.org/laser_proc,Wiki,laser_proc,laser_proc
W273,https://wiki.ros.org/nao_meshes,Wiki,nao_meshes,meshes for the Aldebaran Robotics NAO
W274,https://wiki.ros.org/pr2_head_action,Wiki,pr2_head_action,"The PR2 head action is a node that provides an action interface for
  pointing the head of the PR2.  It passes trajectory goals to the
  controller, and reports success when they have finished executing. 







See  for information on the controller that the head action communicates with. An example of using the head action on the PR2 can be found in the . The joint trajectory action provides an action server (see ) that takes in goals of the type .  It reports success when the head is pointed at the target. ~pan_linkstring~tilt_linkstring~success_angle_thresholddouble~point_head_action/goal~point_head_action/cancel~point_head_action/feedback~point_head_action/status~point_head_action/result~state~command"
W275,https://wiki.ros.org/jackal_description,Wiki,jackal_description,"URDF robot description for Jackal
 

 This package provides a  model of . For an example launchfile to use in visualizing this model, see . Jackal has a suite of optional payloads called accessories. These payloads can be enabled and placed on Jackal using environment variables specified at the time the  is rendered to URDF. Available accessory vars are: As an alternative to individually specifying each accessory, some fixed configurations are provided in the package. These can be specified using the  arg to , and are intended especially as a convenience for simulation launch. Please see  for more information on simulating Jackal. JACKAL_LASER0JACKAL_LASER_MOUNTfrontJACKAL_LASER_OFFSET""0 0 0""JACKAL_LASER_RPY""0 0 0""JACKAL_LASER_HOST192.168.1.14JACKAL_NAVSAT0JACKAL_NAVSAT_MOUNTrearJACKAL_NAVSAT_HEIGHT0.1JACKAL_NAVSAT0JACKAL_NAVSAT_MOUNTrearJACKAL_NAVSAT_HEIGHT0.1JACKAL_FLEA30JACKAL_FLEA3_MOUNTfrontJACKAL_FLEA3_OFFSET""0 0 0""JACKAL_FLEA3_RPY""0 0 0""JACKAL_FLEA3_TILT""0.5236""JACKAL_BB20JACKAL_BB2_MOUNTfrontJACKAL_BB2_OFFSET""0 0 0""JACKAL_BB2_RPY""0 0 0""JACKAL_BB2_TILT0JACKAL_BB2_CALIBRATION0JACKAL_BB2_SERIAL0configdescription.launchbasefront_laserfront_bumblebee2front_flea3"
W276,https://wiki.ros.org/youbot_gazebo_control,Wiki,youbot_gazebo_control,Controller
W277,https://wiki.ros.org/qwt_dependency,Wiki,qwt_dependency,This encapsulates the Qwt dependency for a specific ROS distribution and its Qt version
W278,https://wiki.ros.org/um7,Wiki,um7,"The um7 package provides a C++ implementation of the CH Robotics serial protocol, and a
    corresponding ROS node for publishing standard ROS orientation topics from a UM7.

 
 the ""port"" assignment actually defaults to ""/dev/ttyUSB0"", so if your sensor is on that port, the parameter setting shown above is unnecessary.   if you get a ""Couldn't find executable named um7_driver below /opt/ros/$ROS_DISTRO/share/um7"" message, try restarting linux.  I don't know why; but it has happened to me a couple times.  It should only happen on the first attempt to run. 





 To clarify data polarities, I will describe them in terms of aircraft motion.  NU/ND is aircraft nose up (as in climbing or nose down as in descent.   RWD/LWD is right wing down as in an aircraft turning to the right in flight; left wing down to turn to the left.  NR/NL is nose right as if the aircraft is turning right on the ground, and nose left for turn to the left. 

 sudo apt-get install ros-$ROS_DISTRO-um7rosrun um7 um7_driver _port:=/dev/ttyUSB0"
W279,https://wiki.ros.org/libuvc_ros,Wiki,libuvc_ros,libuvc_ros metapackage
W280,https://wiki.ros.org/marker_rviz_plugin,Wiki,marker_rviz_plugin,The marker_rviz_plugin package contains RViz plugins to visualize messages of the marker_msgs package using RViz.
W281,https://wiki.ros.org/downward,Wiki,downward,fast downward: PDDL Planner (http://www.fast-downward.org)
W282,https://wiki.ros.org/mrpt_graphslam_2d,Wiki,mrpt_graphslam_2d,"Implement graphSLAM using the mrpt-graphslam library, in an online fashion
  	by directly reading measurements off ROS Topics.











 mrpt_graphslam_2d provides support for running either single-robot or multi-robot pose-only graphSLAM, using simulated data (e.g. from Gazebo) or in a real-time setup. Algorithm practically utilises the  to execute graphSLAM, using the ROS communication mechanisms and the  stack. Information on how to use the algorithm for either simulation or real-time usage is provided in the Appendix of  Additional support for running real-time graphSLAM with either one or with multiple agents is provided in the  ROS package. The latter provides launchfiles and generic scripts for setting up common tasks in real robot agents (setting up sensor data acquisition processes, processes for starting robot motors etc.) Package is specialized for the robots and equipment of the  of the  but can be easily extended to suppport different platforms, sensors etc. Additional support for running simulations in Gazebo is provided in the  ROS package See  Package also contains sample datasets, along with the corresponding roslaunch files for easy execution, for both the single- and multi-robot SLAM cases. For more on this see the . Use the  tool to generate the complete API of this package: *  *  *  rosdoc_lite"
W283,https://wiki.ros.org/velodyne,Wiki,velodyne,"Basic ROS support for the Velodyne 3D LIDARs.
: the  parameter now expects an exact name: ""VLP16"", ""32C"", ""32E"", ""64E"", ""64E_S2"", ""64E_S2.1"", or ""64E_S3"" and generates the correct packet rates for them.
 : The VLP-16 (""Puck"") model is now supported.
 : The VLP-32C (""Ultra Puck"") model is now supported. 

ROS packages for . modelvelodyne"
W284,https://wiki.ros.org/mrpt_ekf_slam_3d,Wiki,mrpt_ekf_slam_3d,"This package is a wrapper for the implementation of EKF-based SLAM with range-bearing sensors, odometry, a full 6D robot pose, and 3D landmarks.





 The ROS node mrpt_ekf_slam_3d is a wrapper for the C++ class , part of MRPT. Thus, check out the documentation of that class for further details. For the convention on coordinate frames see . In order to use mrpt_ekf_slam_3d package it is necessary to install the last  build and the(see also the ) . mrpt_ekf_slam_3dtflandmarkstate_vizdata_association_viz~global_frame_idstring""map""~base_frame_idstring""base_link""~odom_frame_idstring""odom""~sensor_sourcestring""scan""""scan""""beacon""~ini_filenamestring~rawlog_filenamestring~rawlog_play_delayfloat~ellipse_scalefloat<the frame attached to incoming scans>base_linktfbase_linkodommapodomroslaunch mrpt_ekf_slam_3d ekf_slam_3d.launchroslaunch mrpt_ekf_slam_3d ekf_slam_3d_rawlog.launch"
W285,https://wiki.ros.org/youbot_gazebo_robot,Wiki,youbot_gazebo_robot,Launch the KUKA youBot in the Gazebo simulation
W286,https://wiki.ros.org/warehouse_ros,Wiki,warehouse_ros,"Persistent storage of ROS messages


 "
W287,https://wiki.ros.org/roseus,Wiki,roseus,"EusLisp client for ROS Robot Operating System.

See  for tutorials, also you may look at  packages for example codes. Please send bug report to . "
W288,https://wiki.ros.org/moveit_ros_manipulation,Wiki,moveit_ros_manipulation,Components of MoveIt! used for manipulation
W289,https://wiki.ros.org/sick_safetyscanners,Wiki,sick_safetyscanners,"Provides an Interface to read the sensor output of a SICK
  Safety Scanner
 











 In the following instructions, replace  with the name of your ROS distro (e.g., ). In case of technical support please open a new issue. Under  <rosdistro>kineticsudo apt-get install ros-<rosdistro>-sick-safetyscannerssource /opt/ros/<rosdistro>/setup.bash
mkdir -p ~/catkin_ws/src/
cd ~/catkin_ws/src/
git clone https://github.com/SICKAG/sick_safetyscanners.git
cd ..
catkin_make install
source ~/catkin_ws/install/setup.bashroslaunch sick_safetyscanners sick_safetyscanners.launch sensor_ip:=192.168.1.10 host_ip:=192.168.1.9rosrun rviz rviz/scan (type: sensor_msgs/LaserScan)/extended_laser_scan (type sick_safetyscanners/ExtendedLaserScanMsg)/output_paths (type sick_safetyscanners/OutputPathMsg)/raw_data (type: sick_safetyscanners/RawMicroScanDataMsg)/field_data"
W290,https://wiki.ros.org/pilz_robot_programming,Wiki,pilz_robot_programming,"An Easy to use API to execute standard industrial robot commands like Ptp, Lin, Circ and Sequence using Moveit.

For package documentation please see the . "
W291,https://wiki.ros.org/yocs_diff_drive_pose_controller,Wiki,yocs_diff_drive_pose_controller,"A controller for driving a differential drive base to a pose goal or along a path specified by multiple poses.
    A pose consists of a 2D position (x,y) and a 1D orientation (theta). "
W292,https://wiki.ros.org/moveit_setup_assistant,Wiki,moveit_setup_assistant,Generates a configuration package that makes it easy to use MoveIt!
W293,https://wiki.ros.org/ros_base,Wiki,ros_base,"A metapackage which extends ros_core and includes other basic non-robot tools like actionlib, dynamic reconfigure, nodelets, and pluginlib."
W294,https://wiki.ros.org/rqt_image_view,Wiki,rqt_image_view,"rqt_image_view provides a GUI plugin for displaying images using image_transport. is an  version of  (however, as of Mar 2015, they are separately implemented and there's no dependency in-between each package. See  for more info).   allows you to open multiple  windows and dock into a single window like this.  rqt_image_viewrqtrqt_image_view"
W295,https://wiki.ros.org/jsk_topic_tools,Wiki,jsk_topic_tools,"jsk_topic_tools









topic_buffer_server<topic_name><topic_type>~update<topic_name>_update<topic_type>~list~updatetopic_buffer_client<topic_name>_update<topic_type><topic_name>_buffered<topic_type>transform_mergertftf_merged~loop_hzdouble, default: 1.0specific_transform_publishertfspecific_transform~parent_framestring~child_framestringspecific_transform_subscriberspecific_transform rosrun jsk_topic_tools topic_buffer_server IN_TOPIC1 [IN_TOPIC2 [...]] rosrun jsk_topic_tools topic_buffer_client /list:=<topic_buffer_server_name>/list  /update:=<topic_buffer_server_name>/update rosrun jsk_topic_tools transform_mergerroslaunch jsk_topic_tools topic_buffer_server_sample.launch  roslaunch jsk_topic_tools topic_buffer_client_sample.launch  roslaunch jsk_topic_tools tf_buffer_server_sample.launch  roslaunch jsk_topic_tools tf_buffer_client_sample.launch  roslaunch jsk_topic_tools specific_transform_publisher_sample.launch roslaunch jsk_topic_tools specific_transform_subscriber_sample.launch "
W296,https://wiki.ros.org/qt_gui_app,Wiki,qt_gui_app,qt_gui_app provides the main to start an instance of the integrated graphical user interface provided by qt_gui.
W297,https://wiki.ros.org/visualization_marker_tutorials,Wiki,visualization_marker_tutorials,The visulalization_marker_tutorials package
W298,https://wiki.ros.org/laser_filters,Wiki,laser_filters,"Assorted filters designed to operate on 2D planar laser scanners,
    which use the sensor_msgs/LaserScan type.

 are configured from the parameter server.  They expect a parameter which is a list made up of repeating blocks of filter configurations.  These should almost always  be specified in a  file to be pushed to the parameter server.  Each filter specified in the chain will be applied in order.  that the  should be specified as  as the  is , if only the  is used. : 
 
 
 (list)  (string) 
 () 
 () 
: :  
 
 (list)  (list)  (string)  (bool, default: false) 
 () 
 () 
: : :  


 ()  ()  


 ()  ()  ()  () 





 ()  ()  () 


 ()  ()  ()  ()  () 


 ()  () 


 ()  () 


 ()  ()  ()  ()  ()  ()  () 
The primary content of the  package is a number of general purpose filters for processing  messages.  These filters are exported as plugins designed to work with with the .  At the moment all of these filters run directly on , but filters may be added in the future which process  instead.  Please review the  for an overview of how filters and filter chains are intended to work. This package provides two nodes that can run multiple filters internally. Using these nodes to run your filters is considered best practice, since it allows multiple nodes to consume the output while only performing the filtering computation once.  The nodes are minimal wrappers around filter chains of the given type.  The  applies a series of filters to a .  The  first applies a series of filters to a , transforms it into a , and then applies a series of filters to the . Each  is a separate plugin exported by the laser_filters package.  This allows them to be specified in a configuration file which can be loaded into an arbitrary filter_chain templated on a . You can instantiate a laser filter into a filter_chain in C++ (), or you can use the  and  nodes which contain appropriate filter chains internally (). The individual filters configurations contain a  which is used for debugging purposes, a  which is used to locate the plugin, and a  which is a dictionary of additional variables.  Consult the documentation for the particular filter plugin to see what variables may be set in the params field. For example, in a package, , to launch a  with two filters:  and , you could use the file: You could then push this configuration to the parameter server using  by running: And then launching the : The scan_to_scan_filter_chain is a very minimal node which wraps an instance of a .  This node can be used to run any filter in this package on an incoming laser scan.  If the  parameter is set, it will wait for the transform between the laser and the target_frame to be available before running the filter chain. The scan_to_cloud_filter_chain is a very minimal node which wraps an instances of  and .  This node can be used to run any filter in this package on an incoming laser scan.  After performing the laser filtering, it will use the  from  to transform each scan into a point cloud.  It will then run any cloud-based filtering, and finally publish the resultant cloud. This filter internally makes use of the the  implementation of float-array filters.  It extracts the range and intensity values and treats each as an independent float array passed through an internal filter chain. This filter removes laser readings that are most likely caused by the veiling effect when the edge of an object is being scanned.  For any two points  and , we do this by computing the perpendicular angle.  That is, assuming the origin of the laser is , the angle formed .  If the perpendicular angle is less than a particular min or greater than a particular max, we remove all neighbors further away than that point. This filter removes all measurements from the  which have an intensity greater than  or less than .  These points are ""removed"" by setting the corresponding range value to  + 1, which is assumed to be an error case. This filter removes all measurements from the  which are greater than  or less than .  These points are ""removed"" by setting the corresponding range value to , which is assumed to be an error case or /. If  is true, the range within the laserscan message is used. This filter removes points in a  outside of certain angular bounds by changing the minimum and maximum angle. This filter removes points in a  inside of certain angular bounds. These points are ""removed"" by setting the corresponding range value to  + 1, which is assumed to be an error case. This filter removes points in a  inside of a cartesian box. These points are ""removed"" by setting the corresponding range value to NaN which is assumed to be an error case. laser_filters.yamlnametypeparamstypepkg_name/FilterClassFilterClassmypkgLaserFilterClass1LaserFilterClass2my_laser_config.yamlscan_to_scan_filter_chainfilters::FilterChain<sensor_msgs::LaserScan>~tf_message_filter_target_frame~scan_filter_chain~tf_message_filter_target_frametf::MessageFilterscanscan_filteredmy_laser_filter.launchmy_laser_config.yamlfilters::FilterChain<sensor_msgs::LaserScan>filters::FilterChain<sensor_msgs::PointCloud>LaserProjection~scan_filter_chain~cloud_filter_chain~target_frame~high_fidelityscancloud_filteredmy_laser_cloud_filter.launchmy_laser_config.yamlmy_cloud_config.yamlrange_filter_chainFilterChainMultiChannelMedianFilterFloatintensity_filter_chainFilterChainMultiChannelMedianFilterFloatmin_angledoublemax_angledoublewindowintneighborsintupper_thresholdlower_thresholdrange_maxlower_thresholddoubleupper_thresholddoubledisp_histogramintupper_thresholdlower_thresholdNaNlower_replacement_valueupper_replacement_valueuse_message_range_limitslower_thresholddoubleupper_thresholddoubleuse_message_range_limitsboolrange_minrange_maxfalselower_replacement_valuedoublelower_thresholdNaNupper_replacement_valuedoubleupper_thresholdNaNlower_angledoubleupper_angledoublerange_maxlower_angledoubleupper_angledoublebox_framestringmin_xdoublemax_xdoublemin_ydoublemax_ydoublemin_zdoublemax_zdoublescan_filter_chain:
- name: unique_name1
  type: mypkg/LaserFilterClass1
  params:
    param1: a
    param2: b
- name: unique_name2
  type: mypkg/LaserFilterClass2
  params:
    param1: a
    param2: b$ rosparam load my_laser_config.yaml scan_to_scan_filter_chain$ rosrun laser_filters scan_to_scan_filter_chain<launch>
  <node pkg=""laser_filters"" type=""scan_to_scan_filter_chain""
      name=""laser_filter"">
    <rosparam command=""load"" file=""$(find mypkg)/my_laser_config.yaml"" />
    <remap from=""scan"" to=""base_scan"" />
  </node>
</launch>scan_filter_chain:
- name: shadows
  type: laser_filters/ScanShadowsFilter
  params:
    min_angle: 10
    max_angle: 170
    neighbors: 20
    window: 1
- name: dark_shadows
  type: laser_filters/LaserScanIntensityFilter
  params:
    lower_threshold: 100
    upper_threshold: 10000
    disp_histogram: 0<launch>
  <node pkg=""laser_filters"" type=""scan_to_cloud_filter_chain""
      name=""tilt_shadow_filter"">
    <rosparam command=""load"" file=""$(find mypkg)/my_laser_config.yaml"" />
    <rosparam command=""load"" file=""$(find mypkg)/my_cloud_config.yaml"" />
    <param name=""high_fidelity"" value=""true"" />
    <param name=""target_frame"" type=""string"" value=""base_link"" />
    <remap from=""scan"" to=""tilt_scan"" />
    <remap from=""cloud_filtered"" to=""tilt_scan_cloud_filtered"" />
  </node>
</launch>scan_filter_chain:
- name: shadows
  type: laser_filters/ScanShadowsFilter
  params:
    min_angle: 10
    max_angle: 170
    neighbors: 20
    window: 1
- name: dark_shadows
  type: laser_filters/LaserScanIntensityFilter
  params:
    lower_threshold: 100
    upper_threshold: 10000
    disp_histogram: 0cloud_filter_chain:
- type: PR2PointCloudFootprintFilter
  name: footprint_filter
  params:
    inscribed_radius: 0.325scan_filter_chain:
- type: laser_filters/LaserArrayFilter
  name: laser_median_filter
  params:
    range_filter_chain:
      - name: median_5
        type: filters/MultiChannelMedianFilterFloat
        params:
          number_of_observations: 5
          unused: 10
    intensity_filter_chain:
      - name: median_5
        type: filters/MultiChannelMedianFilterFloat
        params:
          number_of_observations: 5
          unused: 10scan_filter_chain:
- name: shadows
  type: laser_filters/ScanShadowsFilter
  params:
    min_angle: 10
    max_angle: 170
    neighbors: 20
    window: 1scan_filter_chain:
- name: interpolation
  type: laser_filters/InterpolationFilterscan_filter_chain:
- name: intensity
  type: laser_filters/LaserScanIntensityFilter
  params:
    lower_threshold: 8000
    upper_threshold: 100000
    disp_histogram: 0scan_filter_chain:
- name: range
  type: laser_filters/LaserScanRangeFilter
  params:
    use_message_range_limits: false
    lower_threshold: 0.3
    upper_threshold: .inf
    lower_replacement_value: -.inf
    upper_replacement_value: .infscan_filter_chain:
- name: angle
  type: laser_filters/LaserScanAngularBoundsFilter
  params:
    lower_angle: -1.57
    upper_angle: 1.57scan_filter_chain:
- name: angle
  type: laser_filters/LaserScanAngularBoundsFilterInPlace
  params:
    lower_angle: 0.685398163
    upper_angle: 0.885398163scan_filter_chain:
- name: box
  type: laser_filters/LaserScanBoxFilter
  params:
    box_frame: scan_link
    min_x: -1.0
    max_x: 1.0
    min_y: -1.0
    max_y: 1.0
    min_z: -1.0
    max_z: 1.0"
W299,https://wiki.ros.org/rosdoc_lite,Wiki,rosdoc_lite,"This ROS package wraps documentation tools like doxygen, sphinx,
    and epydoc, making it convenient to generate ROS package
    documentation.

    It also generates online documentation for the ROS wiki.
 is a simple program that runs an external documentation tool, like , , or , on a single ROS . It was built as a light-weight replacement to the  tool and uses the same  file format to assist in porting. We recommend trying  instead of attempting to setup those tools manually, as it provides shortcuts for configuring those tools and can also import additional ROS information. Configuring your package to be documented by  also has the additional benefit of allowing your package to be indexed for inclusion on the ROS wiki.  makes a best effort at providing good default settings to these tools, and in some cases allows these settings to be customized further.  is used as part of an automated process for updating documentation on ros.org. It is frequently run on repositories that have  files listed in the  repository, with the resulting documentation linked to in the ""Code API"" link of many packages' on .  contains some additional functionality for generating machine-readable documentation files, as well as / documentation, that are used by the ros.org wiki system and elsewhere. This functionality is mainly only of use to those maintaining documentation Web sites. 


: 




: Epydoc's ""introspection"" capability currently breaks when trying to process some ros python modules, so this feature should not be enabled in a custom epydoc config file. 


 provides support for cross-referencing with external  documentation using tag files. For more information on using tag files with  to link to external documentation, see this . 

 can be passed a yaml file containing a list of tagfiles with the  option. This yaml file should contain a list of dictionaries, where each dictionary has the following standard keys: 

 is automatically run for packages in repositories that have rosinstall files listed in the  repository. The resulting documentation is uploaded to  and is linked in the ""Code API"" links that you see on various package pages, like . 
 See also: , , and  By default,  will use  to generate the documentation for a package. If you wish to use another tool, like  or , you must use a rosdoc configuration file. This is described below.  For C/C++, only Doxygen is advised. The documentation that is generated will depend on which tool is used, as each tool behaves differently.  For example, Doxygen will extract API details from all source files found in the package (see  for more). You can use  to generate local copies of documentation. When you run the  command, it will generate documentation into the 'doc' folder of the local directory. In order to enable the rosdoc configuration file, simply have a  file in the root of your package. If you wish to name it something else, you must place the following tag in the  section of the , but this behavior is old: Here is an example from the  package, which performs both C++ and Python API documentation: The ""doxygen"" builder will enable running  on a package. As Doxygen is the default builder for any package, it is only necessary to configure this option if: The ""epydoc"" builder will enable running  on a package. The ""sphinx"" builder will enable running  on a package. The ""external"" builder specifies that you wish to link to externally generated documentation.  will generate a landing page with the link to the specified URL. To generate a tag file during a documentation run, simply pass the  option to rosdoc lite with a path to the desired location of the tagfile. For example: Running  with this file to get cross references might look something like this: Even if  is automatically generated for your package, we recommend regularly running  on your own computer to verify what your documentation looks like before checking it in. It is also used to generate the data for the ,  and  wiki macros that you see on many of the ros.org wiki pages. The  tool itself is stable, though it has many internal features and functionality that are changed to support the documentation needs of . In the future, the  tool will hopefully be evolved to better support the configuration requirements of the documentation tools it invokes (i.e. Doxygen). The code API of  should  be used as it is an internal library that is frequently changed. rosdoc_literosdoc.yamlrosdoc_literosdoc_literosdoc_literosdoc_literosdoc_litewiki.ros.orgrosdoc_litemsgsrvrosdoc_literosdoc_litedocdoc/html/index.htmldoxygensudo apt-get install doxygenrosdoc.yaml<export>...</export>package.xmldoxygenepydocsphinxFILE_PATTERNSEXCLUDEEXCLUDE_PATTERNSJAVADOC_AUTOBRIEFNOMULTILINE_CPP_IS_BRIEFNOTAB_SIZE8ALIASESEXAMPLE_PATTERNSIMAGE_PATHEXCLUDE_SYMBOLSPREDEFINED--exclude--configindex.rstconf.pyindex.rstrosdoc_literosdoc_lite-grosdoc_lite-trosdoc_literosdoc_literos.orgrosdoc_literosdoc_litePackageHeaderStackHeaderMsgSrvDocrosdoc_literos.orgrosdoc_literosdoc_liteapt-get install ros-$ROS_DISTRO-rosdoc-liteUsage: rosdoc_lite [options] [package_path]

Options:
  -h, --help            show this help message and exit
  -q, --quiet           Suppress doxygen errors.
  -o OUTPUT_DIRECTORY   The directory to write documentation to.
  -t TAGFILE, --tagfile=TAGFILE
                        Path to tag configuration file for Doxygen cross
                        referencing support. Ex: /home/user/tagfiles_list.yaml
  -g GENERATE_TAGFILE, --generate_tagfile=GENERATE_TAGFILE
                        If specified, will generate a doxygen tagfile in this
                        location. Ex: /home/user/tags/package.tagrosdoc_lite <path_of_package><export>
  <rosdoc config=""rosdoc.yaml"" />
</export> - builder: epydoc
   output_dir: python
 - builder: doxygen
   name: C++ API
   output_dir: c++
   file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox'- builder: doxygen
  name: C++ API
  output_dir: c++
  file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox'
  exclude_patterns: '*/ARDroneLib/*'- builder: doxygen
  file_patterns: '*.c *.cpp *.h *.cc *.hh *.dox *.md'
  use_mdfile_as_mainpage: README.md- builder: epydoc
  config: epydoc.config- builder: sphinx           # specify document generator. e.g) doxygen, epidoc, sphinx
  sphinx_root_dir: doc      # document directoryrosdoc_lite -o doc -g doc/tags/my_package.tag /path/to/my/package - docs_url: http://www.ros.org/doc/api/package_name/html
   location: file:///path/to/package_name/doc/tags/package_name.tag
 - docs_url: http://www.ros.org/doc/api/package_name2/html
   location: http://www.ros.org/doc/api/package_name2/tags/package_name2.tagrosdoc_lite -o doc -t /path/to/example_tags.yaml<export>
  <doxymaker external=""http://link.to.external/page.html""/>
</export>"
W300,https://wiki.ros.org/controller_interface,Wiki,controller_interface,"Interface base class for controllers
See the  page and the  for more information. "
W301,https://wiki.ros.org/slic,Wiki,slic,"SLIC-Superpizel ROS Wrapper
  This file contains the class elements of the class Slic. This class is an
  implementation of the SLIC Superpixel algorithm by Achanta et al. [PAMI'12,
  vol. 34, num. 11, pp. 2274-2282].

  This implementation is created for the specific purpose of creating
  over-segmentations in an OpenCV-based environment."
W302,https://wiki.ros.org/jsk_apc,Wiki,jsk_apc,Metapackage for Amazon Picking Challenge
W303,https://wiki.ros.org/urdf_geometry_parser,Wiki,urdf_geometry_parser,Extract geometry value of a vehicle from urdf.
W304,https://wiki.ros.org/pilz_msgs,Wiki,pilz_msgs,The pilz_msgs package
W305,https://wiki.ros.org/pr2_controllers,Wiki,pr2_controllers,"Contains the controllers that run in realtime on the PR2 and supporting packages.


The  stack has the components which must run in the realtime loop of the PR2, components which communicate with the realtime controllers, and a few supporting packages.  Realtime controllers run in the  at a guaranteed update rate and are used for moving the mechanism and triggering sensing components.  The supporting nodes provide a more user-friendly interface to the realtime components, often providing notification on success or failure of commands. A full set of controllers and supporting nodes has been configured to come up on the PR2 by default.  See  for instruction on how to use them. Report new issues on  pr2_controllers"
W306,https://wiki.ros.org/dwb_critics,Wiki,dwb_critics,Implementations for dwb_local_planner TrajectoryCritic interface 
W307,https://wiki.ros.org/jsk_visualization,Wiki,jsk_visualization,Metapackage that contains visualization package for jsk-ros-pkgDocument:  
W308,https://wiki.ros.org/rqt_msg,Wiki,rqt_msg,"A Python GUI plugin for introspecting available ROS message types.
  Note that the msgs available through this plugin is the ones that are stored
  on your machine, not on the ROS core your rqt instance connects to."
W309,https://wiki.ros.org/rqt_shell,Wiki,rqt_shell,rqt_shell is a Python GUI plugin providing an interactive shell. 
W310,https://wiki.ros.org/staro_moveit_config,Wiki,staro_moveit_config,An automatically generated package with all the configuration and launch files for using the STARO with the MoveIt Motion Planning Framework
W311,https://wiki.ros.org/ros_environment,Wiki,ros_environment,"The package provides the environment variables `ROS_VERSION`, `ROS_DISTRO`, `ROS_PACKAGE_PATH`, and `ROS_ETC_DIR`."
W312,https://wiki.ros.org/velodyne_pointcloud,Wiki,velodyne_pointcloud,"Point cloud conversions for Velodyne 3D LIDARs.
: the default  value is now 0.9 meters. : a new pair of parameters  and  may be used to reduce the output point cloud to a subset of angular directions. By default, every angle is included in the point cloud. Setting  to  radians will limit the output to 90 degrees around the forward direction of the device (from -45 degrees to +45). Also setting  to  would return output only from the device's rear facing, instead. Similarly, setting  to  would limit output to 90 degrees around the right facing in the XY plane of the device frame of reference. 













This package provides point cloud conversions for Velodyne 3D LIDARs. For a list of all supported models refer to the  section. The  describes the evolution of these interfaces.  Continuously convert raw Velodyne packets into  messages.  This launch file runs the cloud nodelet in the same process with the device driver.  The full path name of the calibration file  be provided. This example uses one of the package test files for calibration. Continuously convert raw Velodyne packets into  messages. Transform raw Velodyne packets into  messages into the  frame.  This launch file runs the transform nodelet in the same process with the device driver.  The full path name of the calibration file  be provided. This example uses one of the package test files. Transform raw Velodyne packets into  messages into the  frame. Transform raw Velodyne packets into  messages into the  frame. In two separate terminal windows, start a  process running the driver nodelet and the cloud nodelet, which will have zero-copy access to the raw data messages the driver publishes. Start a driver nodelet with input from , in the current directory. The  provides a full path name, as required for . In another terminal, start the transform nodelet, to publish the data points transformed into the /odom frame of reference. Start a  process for a Velodyne HDL-32E. This script runs both the driver and the point cloud conversion, providing the standard HDL-32E calibration. Start another  for the Velodyne HDL-32E, but provide a PCAP dump file as input. This script generates a YAML calibration file for use by this package from the  file that was provided by Velodyne with the device. Read  from the current directory, writing the required calibration data to . Save generated 32E calibration data in . ~min_range~view_direction~view_width~view_width~view_directionview_directionvelodyne_packetsvelodyne_points/velodynevelodyne_packetsvelodyne_points~modelstring~max_rangedouble~min_rangedouble~calibrationstring~view_directiondouble~view_widthdoubleCloudNodeletvelodyne_packetsvelodyne_points/odomvelodyne_packetsvelodyne_pointsframe_id~frame_idstrtf_prefix~modelstring~max_rangedouble~min_rangedouble~calibrationstring~view_directiondouble~view_widthdouble/odomTransformNodelet/odom/mapvelodyne_nodelet_managertcpdump.pcappwdroslaunchvelodyne_nodelet_managervelodyne_nodelet_managerdb.xmldb.xmldb.yamlmy_calibration.yamlvelodyne_pointcloud::PointXYZIRpcl::PointXYZI$ rosrun nodelet nodelet standalone velodyne_pointcloud/CloudNodelet<launch>
  <!-- start nodelet manager and driver nodelets -->
  <include file=""$(find velodyne_driver)/launch/nodelet_manager.launch"" />

  <!-- start cloud nodelet -->
  <include file=""$(find velodyne_pointcloud)/launch/cloud_nodelet.launch"">
    <arg name=""calibration""
         value=""$(find velodyne_pointcloud)/params/64e_utexas.yaml""/>
  </include>

</launch>$ rosrun velodyne_pointcloud cloud_node _calibration:=calibration.yaml$ rosrun nodelet nodelet standalone velodyne_pointcloud/TransformNodelet<launch>
  <!-- start nodelet manager and driver nodelets -->
  <include file=""$(find velodyne_driver)/launch/nodelet_manager.launch"" />

  <!-- start transform nodelet -->
  <include file=""$(find velodyne_pointcloud)/launch/transform_nodelet.launch"">
    <arg name=""calibration""
         value=""$(find velodyne_pointcloud)/params/64e_utexas.yaml""/>
  </include>
</launch>$ rosrun velodyne_pointcloud transform_node _calibration:=calibration.yaml$ rosrun velodyne_pointcloud transform_node _frame_id:=/map $ roslaunch velodyne_driver nodelet_manager.launch  $ roslaunch velodyne_pointcloud cloud_nodelet.launch calibration:=~/mydata.yaml $ roslaunch velodyne_driver nodelet_manager.launch pcap:=$(pwd)/tcpdump.pcap  $ roslaunch velodyne_pointcloud transform_nodelet.launch calibration:=~/mydata.yaml $ roslaunch velodyne_pointcloud 32e_points.launch $ roslaunch velodyne_pointcloud 32e_points.launch pcap:=$(pwd)/tcpdump.pcap $ rosrun velodyne_pointcloud gen_calibration.py db.xml $ rosrun velodyne_pointcloud gen_calibration.py 32db.xml my_calibration.yaml "
W313,https://wiki.ros.org/robot_mechanism_controllers,Wiki,robot_mechanism_controllers,"Generic Mechanism Controller Library

The controllers in this package should not be used directly.  The controllers should instead by used via their  interfaces, e.g., , , , and . "
W314,https://wiki.ros.org/teleop_twist_keyboard,Wiki,teleop_twist_keyboard,"Generic keyboard teleop for twist robots.


sudo apt-get install ros-$ROS_DISTRO-teleop-twist-keyboardrosrun teleop_twist_keyboard teleop_twist_keyboard.pyReading from the keyboard  and Publishing to Twist!
---------------------------
Moving around:
   u    i    o
   j    k    l
   m    ,    .

q/z : increase/decrease max speeds by 10%
w/x : increase/decrease only linear speed by 10%
e/c : increase/decrease only angular speed by 10%
anything else : stop

CTRL-C to quit"
W315,https://wiki.ros.org/mapviz,Wiki,mapviz,"mapviz
 
Mapviz is a ROS-based visualization tool with a plug-in system similar to  focused on visualization 2D data. See  for a list of existing plugins. "
W316,https://wiki.ros.org/yoctopuce_altimeter,Wiki,yoctopuce_altimeter,"ROS publisher for the Yoctopuce altimeter

   



  This package provides a publisher that interfaces with the yoctopuce altimeter: . To use, you must have the following dependencies: , , , , . ros_cppros_pystd_msgsnav_msgssensor_msgsexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/yocto/cpp/api/Binaries/linux/64bitsrosrun yoctopuce_altimeter yoctopuce_altimeter/yocto/rawyocto_msg/yocto/odomnav_msgs/odom"
W317,https://wiki.ros.org/prbt_ikfast_manipulator_plugin,Wiki,prbt_ikfast_manipulator_plugin,The prbt_ikfast_manipulator_plugin package
W318,https://wiki.ros.org/youbot_driver,Wiki,youbot_driver,"driver for the KUKA youBot robot







This package contains the drivers for the Kuka youBot. This is required for . It is recommended to use  instead of this package for any real application. Install the debian package using : This will install the code, set the permissions of the binaries, copy the config files to a set location, and install the  rules for the Hokuyo sensor. You must set the environment variable YOUBOT_CONFIG_FOLDER_LOCATION to point to the config folder before running the package. The debian install will have put it at /opt/ros/groovy/etc/youbot_driver/config/, so set the variable to that. If you do not wish to do this every time you start a new terminal, you can put that line in  in the home directory, . That way, the variable will be defined for every terminal you start. 
To install from source, get the package from the git repository in the typical way. First, create a folder for the package within the  folder of your catkin workspace.  to the folder, then do The binaries need to have the proper capabilites to run. If they do not have the right permissions, they will be unable to communicate over Ethercat, and the drivers will not run. To set the capabilities to their proper values, use  on each binary: If you do not wish to do this every time you start a new terminal, you can put that line in  in the home directory, . That way, the variable will be defined for every terminal you start. 
Finally, you should also install the  rules for the Hokuyo sensor. These are important for any other youBot packages which use the Hokuyo, such as . These rules do two things whenever you plug in the Hokuyo: To install the rules, copy the  file from the udev_rules folder included in the source to /etc/udev/rules.d/ If you wish to confirm that the rules work, run  and plug in the Hokuyo. The output should reflect the fact that the port has been given read and write access and a symbolic link in  was created. You may also do It is recommended to use  instead of this package for any actual application. You can test the base, arm, and gripper motors by running the base_arm_gripper_test. Be sure to have the robot off the ground because it will move around some while testing the base. If this fails with the message that there was no socket connection on  or , go into the  config file and change  to  or . apt-getudev.bashrc~/.bashrcsrccdsetcap.bashrc~/.bashrcudev/dev/sensors/hokuyo/dev/ttyACM0/dev/ttyACM147-hokuyo.rulesudevadm monitor/dev/sensors/hokuyoeth1eth0youbot-ethercat.cfgEthernetDeviceeth0eth1sudo apt-get install ros-groovy-youbot-driverexport YOUBOT_CONFIG_FOLDER_LOCATION=/opt/ros/groovy/etc/youbot_driver/config/git init
git pull http://github.com/WPI-RAIL/youbot_driver.gitcatkin_makesudo setcap cap_net_raw+ep [your_catkin_workspace]/devel/lib/youbot_driver/base_arm_gripper_test
sudo setcap cap_net_raw+ep [your_catkin_workspace]/devel/lib/youbot_driver/displayIpAddressexport YOUBOT_CONFIG_FOLDER_LOCATION=[your_catkin_workspace]/src/youbot_driver/configsudo cp [your_catkin_workspace]/src/youbot_driver/udev_rules/47-hokuyo.rules /etc/udev/rules.d/ls -all /dev/sensors/hokuyolrwxrw-rw- 1 root root 11 Jun 11 11:11 /dev/sensors/hokuyo -> ../ttyACM0rosrun youbot_driver base_arm_gripper_testrosrun youbot_driver displayIpAddress /dev/ttyACM0 eth1 wlan0"
W319,https://wiki.ros.org/summit_xl_gazebo,Wiki,summit_xl_gazebo,"Launch files and world files to start the models in gazebo
"
W320,https://wiki.ros.org/vision_msgs,Wiki,vision_msgs,"Messages for interfacing with various computer vision pipelines, such as
    object detectors."
W321,https://wiki.ros.org/mav_comm,Wiki,mav_comm,"Contains messages and services for MAV communication
Use GitHub to . []
  ROS communication meta-package for Micro Aerial Vehicles (MAV) containing . 
"
W322,https://wiki.ros.org/message_filters,Wiki,message_filters,"A set of message filters which take in messages and may output those messages at a later time, based on the conditions that filter needs met.
 is a utility library for use with  and . It collects commonly used message ""filtering"" algorithms into a common space.  A message filter is defined as something which a message arrives into and may or may not be spit back out of at a later point in time. 

 

  



  


 
  


   
  
  
   
    
 is most useful for cases where you want to determine which filters to apply at runtime rather than compile-time. 
  
    All message filters follow the same pattern for connecting inputs and outputs.  Inputs are connected either through the filter's constructor or through the  method.  Outputs are connected through the  method. For example, given two filters  and  where 's output is compatible with 's input, connecting foo to bar could be (in C++): The signature of  is dependent on the definition of . You can register multiple callbacks with the  method.  They will get called in the order they are registered. See also:   The  filter is simply a wrapper around a ROS subscription that provides a source for other filters.  The  filter cannot connect to another filter's output, instead it uses a ROS topic as its input. See also: ,  The  filter synchronizes incoming channels by the timestamps contained in their headers, and outputs them in the form of a single callback that takes the same number of channels.  The C++ implementation can synchronize up to 9 channels. (Note: In this particular case you could use the  class from , which essentially wraps the filtering code above.) See also:  The  filter guarantees that messages will be called in temporal order according to their header's timestamp.  The  is constructed with a specific delay which specifies how long to queue up messages before passing them through.  A callback for a message is never invoked until the messages' time stamp is out of date by at least delay. However, for all messages which are out of date by at least the delay, their callback are invoked and guaranteed to be in temporal order. If a message arrives from a time prior to a message which has already had its callback invoked, it is thrown away. See also:   Given a stream of messages, the most recent N messages are cached in a ring buffer, from which time intervals of the cache can then be retrieved by the client. The timestamp of a message is determined from its  field. In this example, the  stores the last 100 messages received on , and  is called on the addition of every new message. The user can then make calls like  to extract part of the cache. The  filter synchronizes incoming channels by the timestamps contained in their headers, and outputs them in the form of a single callback that takes the same number of channels.  The C++ implementation can synchronize up to 9 channels. The  filter is templated on a policy that determines how to synchronize the channels.  There are currently two policies:  and . The  policy requires messages to have exactly the same timestamp in order to match.  Your callback is only called if a message has been received on all specified channels with the same exact timestamp. The timestamp is read from the  field of all messages (which is required for this policy). The  policy uses  to match messages based on their timestamp. See also:  The  filter allows you to dynamically chain together multiple single-input/single-output (simple) filters.  As filters are added to it they are automatically connected together in the order they were added.  It also allows you to retrieve added filters by index. It is possible to pass bare pointers in.  These will  be automatically deleted when Chain is destructed. message_filtersconnectInput()registerCallback()FooFilterBarFilterFooFilterBarFiltermyCallbackBarFilterregisterCallbacks()registerCallback()disconnect()SubscriberSubscribervoid callback(const boost::shared_ptr<M const>&)callback(msg)TimeSynchronizervoid callback(const boost::shared_ptr<M const>&)callback(msg)M0M8void callback(const boost::shared_ptr<M0 const>&, ..., const boost::shared_ptr<M8 const>&)callback(msg0.. msgN)TimeSequencerTimeSequencerTimeSequencervoid callback(const boost::shared_ptr<M const>&)void callback(const boost::shared_ptr<M const>&)headerheadervoid callback(const boost::shared_ptr<M const>&)callback(msg)void callback(const boost::shared_ptr<M const>&)callback(msg)Cachemy_topicmyCallbackcache.getInterval(start, end)headerCacheallow_headerless=TrueSynchronizerSynchronizerExactTimeApproximateTimemessage_filters/synchronizer.hvoid callback(const boost::shared_ptr<M const>&)callback(msg)M0M8void callback(const boost::shared_ptr<M0 const>&, ..., const boost::shared_ptr<M8 const>&)callback(msg0.. msgN)message_filters::sync_policies::ExactTimeheadermessage_filters/sync_policies/exact_time.hmessage_filters::sync_policies::ApproximateTimeheadermessage_filters/sync_policies/approximate_time.hheaderApproximateTimeSynchronizerallow_headerless=Trueheader.stampChainChainvoid callback(const boost::shared_ptr<M const>&)void callback(const boost::shared_ptr<M const>&)
























































































































































"
W323,https://wiki.ros.org/rqt_gui,Wiki,rqt_gui,"rqt_gui provides the main to start an instance of the ROS integrated graphical user interface provided by qt_gui.
 upon using multiple  plugins has following advantages: rqt_guirqtrqtrqt_gui"
W324,https://wiki.ros.org/chomp_motion_planner,Wiki,chomp_motion_planner,"chomp_motion_planner


This package implements the motion planner interface that the move_arm package requires. This interface is described in detail in the . To use CHOMP, simply launch the pr2_arm_navigation_planning/launch/chomp_planning.launch file instead of any of the other planners. To check out tutorials for this package, just follow the general set of Tutorials on the  page. Replace the launch file for OMPL with the launch file for CHOMP (the launch file for CHOMP can be found in pr2_arm_navigation_planning/launch). "
W325,https://wiki.ros.org/octomap,Wiki,octomap,"The OctoMap library implements a 3D occupancy grid mapping approach, providing data structures and mapping algorithms in C++. The map implementation is based on an octree. See
  http://octomap.github.io for details.

General information about OctoMap is available at  and in the publication  by A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard (Autonomous Robots Journal, 2013). Please cite our paper if you use OctoMap in your research. Doxygen documentation based on the latest OctoMap release is available at . If you want to use OctoMap in ROS,  and  provide messages, wrappers and conversion methods.  provides map building and serving capabilities. A visualization tool is available at . Report bugs or request features . For questions and discussions, use the mailing list at  find_package()link_directories(${OCTOMAP_LIBRARY_DIRS})package.xml<rosdep name=""octomap"" /> stack.xml@ARTICLE{hornung13auro,
  author = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill
  Stachniss and Wolfram Burgard},
  title = {{OctoMap}: An Efficient Probabilistic {3D} Mapping Framework Based
  on Octrees},
  journal = {Autonomous Robots},
  year = 2013,
  url = {http://octomap.github.com},
  doi = {10.1007/s10514-012-9321-0},
  note = {Software available at \url{http://octomap.github.com}}
}sudo apt-get install ros-$ROS_DISTRO-octomapfind_package(octomap REQUIRED)
include_directories(${OCTOMAP_INCLUDE_DIRS})
target_link_libraries(${OCTOMAP_LIBRARIES})<build_depend>octomap</build_depend>
<run_depend>octomap</run_depend>"
W326,https://wiki.ros.org/slam_toolbox,Wiki,slam_toolbox,"This package provides a sped up improved slam karto with updated SDK and visualization and modification toolsets
The Slam Toolbox package incorporates information from laser scanners in the form of a  message and TF transforms from odom->base link, and creates a map 2D map of a space. This package will allow you to fully serialize the data and pose-graph of the SLAM map to be reloaded to continue mapping, localize, merge, or otherwise manipulate. We allow for SLAM Toolbox to be run in synchronous (process all valid sensor measurements, regardless of lag) and asynchronous (process valid sensors measurements on an as-possible basis) modes. More information, ROS API, demos, and resources are given in the  page. "
W327,https://wiki.ros.org/industrial_ci,Wiki,industrial_ci,"This package contains CI (Continuous Integration) configuration that any ROS-powered packages can commonly use. Some notable feature:
    See . "
W328,https://wiki.ros.org/ximea_camera,Wiki,ximea_camera,"ROS drivers for the ximea xiQ USB 3.0 Cameras



, which is of ROS message type . This message carries all of the camera specific calibration information. , which of of ROS message type . This message carries the image data. This software requires the Ximea Linux Software Package. See  for details. serial_nocam_nameyaml_urlexposure_timerect_left, rect_top, rect_height, rect_widthimage_data_formatframe_ratecamera_param_file_pathscamera_param_file_paths/camera_infosensor_msgs/CameraInfo/image_raw/sensor_msgs/Imageserial_no: 32301951
cam_name: ""camera1""
yaml_url: ""package://mcptam/calibrations/camera1.yaml""
exposure_time: 30000
rect_left: 200
rect_top: 200
rect_height: 600
rect_width: 900
image_data_format: ""XI_MONO8""










"
W329,https://wiki.ros.org/swri_console,Wiki,swri_console,"A rosout GUI viewer developed at Southwest Research Insititute as an
     alternative to rqt_console."
W330,https://wiki.ros.org/amcl,Wiki,amcl,"
            amcl is a probabilistic localization system for a robot moving in
            2D. It implements the adaptive (or KLD-sampling) Monte Carlo
            localization approach (as described by Dieter Fox), which uses a
            particle filter to track the pose of a robot against a known map.
        
            This node is derived, with thanks, from Andrew Howard's excellent
            'amcl' Player driver.
        





 (, default: 100) 
 (, default: -1.0) 
 (, default: ) 
 transforms incoming laser scans to the odometry frame ().  So there must exist a path through the  tree from the frame in which the laser scans are published to the odometry frame.    To localize using laser data on the  topic: There are three categories of ROS  that can be used to configure the  node: overall filter, laser model, and odometery model. If  is  then we use the  from Probabilistic Robotics, p136; this model uses the noise parameters  through , as defined in the book. If  is  then we use a custom model for an omni-directional base, which uses  through . The meaning of the first four parameters is similar to that for the  model. The fifth parameter capture the tendency of the robot to translate (without rotating) perpendicular to the observed direction of travel. A  was found and fixed. But fixing the old models would have changed or broken the localisation of already tuned robot systems, so the new fixed odometry models were added as new types  and . The default settings of the  parameters only fit the old models, for the new model these values probably need to be a lot smaller, see . Also, another  was found but only fixed after Navigation 1.16, while the current release for Kinetic is Navigation 1.14.1. This bug only affects robot with type  and , where  and  are actually reversed. I.e.  is for the translation odometry noise from robot translation-al motion, and  represents the odometry rotation noise from robot's rotation motion. An implementation detail: on receipt of the first laser scan,  looks up the transform between the laser's frame and the base frame (~base_frame_id), and latches it forever.  So  cannot handle a laser that moves with respect to the base. The drawing below shows the difference between localization using odometry and . During operation  estimates the transformation of the base frame (~base_frame_id) in respect to the global frame () but it only publishes the transform between the global frame and the odometry frame (). Essentially, this transform accounts for the drift that occurs using Dead Reckoning. The published transforms are . sample_motion_model_odometrybeam_range_finder_modellikelihood_field_range_finder_modelAugmented_MCLKLD_Sampling_MCLbase_scanamclamclscantfinitialposemapuse_map_topicamcl_poseparticlecloudtfodommapglobal_localizationrequest_nomotion_updateset_mapstatic_mapamcl~min_particlesint~max_particlesint~kld_errdouble~kld_zdoublekld_err~update_min_ddouble~update_min_adouble~resample_intervalint~transform_tolerancedouble~recovery_alpha_slowdoubledisabled~recovery_alpha_fastdoubledisabled~initial_pose_xdouble~initial_pose_ydouble~initial_pose_adouble~initial_cov_xxdouble~initial_cov_yydouble~initial_cov_aadouble~gui_publish_ratedouble~save_pose_ratedouble~use_map_topicboolmap~first_map_onlybool~laser_min_rangedouble~laser_max_rangedouble~laser_max_beamsint~laser_z_hitdouble~laser_z_shortdouble~laser_z_maxdouble~laser_z_randdouble~laser_sigma_hitdouble~laser_lambda_shortdouble~laser_likelihood_max_distdouble~laser_model_typestring""likelihood_field""beamlikelihood_fieldlikelihood_field_problikelihood_field~odom_model_type""diff""sample_motion_model_odometry algorithmodom_alpha1odom_alpha4~odom_model_type""omni""odom_alpha1odom_alpha5""diff""""diff-corrected""""omni-corrected""odom_alpha""omni""""omni-corrected""odom_alpha1odom_alpha4odom_alpha1odom_alpha4~odom_model_typestring""diff""""diff""""omni""""diff-corrected""""omni-corrected""~odom_alpha1double~odom_alpha2double~odom_alpha3double~odom_alpha4double~odom_alpha5double""omni""~odom_frame_idstring""odom""~base_frame_idstring""base_link""~global_frame_idstring""map""~tf_broadcastboolfalseamcl~odom_frame_idamclamclamclamcl~global_frame_id~odom_frame_idamcl scan:=base_scan"
W331,https://wiki.ros.org/safe_teleop_stage,Wiki,safe_teleop_stage,Launch files for running safe_teleop_base on pr2
W332,https://wiki.ros.org/joy_listener,Wiki,joy_listener,Translates joy msgs
W333,https://wiki.ros.org/ros_numpy,Wiki,ros_numpy,A collection of conversion function for extracting numpy arrays from messagesSee the  on github for a quick usage summary. 
W334,https://wiki.ros.org/turtlebot3_navigation,Wiki,turtlebot3_navigation,"The turtlebot3_navigation provides roslaunch scripts for starting the navigation. 






This package provides parameters from  in  directory. <arg name=""scan_topic""     default=""scan""/>     # topic name for the sensor values from 
                                                  the distance sensor
<arg name=""initial_pose_x"" default=""0.0""/>      # initial x-coordinate value
<arg name=""initial_pose_y"" default=""0.0""/>      # initial y-coordinate value
<arg name=""initial_pose_a"" default=""0.0""/>      # initial yaw coordinate value

#---- execute the amcl node by referring to the parameter settings below. ----#

<node pkg=""amcl"" type=""amcl"" name=""amcl"">

<param name=""min_particles"" value=""500""/>         # min number of particles allowed
<param name=""max_particles"" value=""3000""/>        # max number of particles allowed
<param name=""kld_err""       value=""0.02""/>        # max error between the actual distribution 
                                                    and the estimated distribution
<param name=""update_min_d"" value=""0.2""/>          # translational motion required for filter 
                                                    update (meter)
<param name=""update_min_a"" value=""0.2""/>          # rotational motion required for filter 
                                                    update (radian) 
<param name=""resample_interval"" value=""1""/>       # resampling interval 
<param name=""transform_tolerance"" value=""0.5""/>   # conversion allowed time (by sec) 
<param name=""recovery_alpha_slow"" value=""0.0""/>   # index drop rate(slow average weight 
                                                    filter), deactivated if 0.0 
<param name=""recovery_alpha_fast"" value=""0.0""/>   # index drop rate(fast average weight 
                                                    filter), deactivated if 0.0 
<param name=""initial_pose_x"" value=""$(arg initial_pose_x)""/>  # refer to above initial_pose_x 
<param name=""initial_pose_y"" value=""$(arg initial_pose_y)""/>  # refer to above initial_pose_y 
<param name=""initial_pose_a"" value=""$(arg initial_pose_a)""/>  # refer to above initial_pose_a 
<param name=""gui_publish_rate"" value=""50.0""/>     # max period to visually displaying scan and                                                    path info 
<param name=""use_map_topic"" value=""$(arg use_map_topic)""/>    # same as the explanation for                                                                   use_map_topic 

#---------------------- distance sensor parameter --------------------------#

<remap from=""scan"" to=""$(arg scan_topic)""/>       # change the sensor topic name 
<param name=""laser_max_range"" value=""3.5""/>       # max distance of laser sensing distance 
<param name=""laser_max_beams"" value=""180""/>       # max number of laser beams used during 
                                                    filter update 
<param name=""laser_z_hit"" value=""0.5""/>           # z_hit mixed weight of sensor model   
<param name=""laser_z_short"" value=""0.05""/>        # z_short mixed weight of sensor model   
<param name=""laser_z_max"" value=""0.05""/>          # z_max mixed weight of sensor model  
<param name=""laser_z_rand"" value=""0.5""/>          # x_rand mixed weight of sensor model   
<param name=""laser_sigma_hit"" value=""0.2""/>       # standard deviation of Gaussian model 
                                                    using z_hit of sensor
<param name=""laser_lambda_short"" value=""0.1""/>    # index drop rate parameter for z_short 
                                                    of sensor 
<param name=""laser_likelihood_max_dist"" value=""2.0""/>     # max distance and obstacle for 
                                                            likelihood_field method sensor 
<param name=""laser_model_type"" value=""likelihood_field""/> # select likelihood_field or beam 

#---------------------- parameter related to odometry --------------------------#

<param name=""odom_model_type""value=""diff""/>       # robot driving methods. ""diff"" or ""omni"" can be selected
<param name=""odom_alpha1"" value=""0.1""/>           # estimated rotational motion noise of 
                                                    the odometry during rotational motion
<param name=""odom_alpha2"" value=""0.1""/>           # estimated rotational motion noise of 
                                                    the odometry during translation motion
<param name=""odom_alpha3"" value=""0.1""/>           # estimated translation motion noise of 
                                                    the odometry during translation motion 
<param name=""odom_alpha4"" value=""0.1""/>           # estimated translation motion noise of 
                                                    the odometry during rotational motion  
<param name=""odom_frame_id"" value=""odom""/>             # odometry frame 
<param name=""base_frame_id"" value=""base_footprint""/>   # robot base frame base_local_planner_params.yaml              # The parameter of the speed command to the robot
costmap_common_params_burger.yaml           # The parameter of costmap configuration consists
costmap_common_params_waffle.yaml           # The parameter of costmap configuration consists
costmap_common_params_waffle_pi.yaml        # The parameter of costmap configuration consists
dwa_local_planner_params.yaml               # The parameter of the speed command to the robot
global_costmap_params.yaml                  # The parameter of the global area motion planning
local_costmap_params.yaml                   # The parameter of the local area motion planning
move_base_params.yaml                       # parameter setting file of move_base that 
                                              supervises the motion planning."
W335,https://wiki.ros.org/xpp_quadrotor,Wiki,xpp_quadrotor,"The URDF file for a quadrotor to be used with the xpp packages and a 
    simple rviz publisher of quadrotor tfs.
     
    Adapted from Daniel Mellinger, Nathan Michael, Vijay Kumar, 
    ""Trajectory Generation and Control for Precise Aggressive Maneuvers
    with Quadrotors"".
  "
W336,https://wiki.ros.org/rqt_plot,Wiki,rqt_plot,"rqt_plot provides a GUI plugin visualizing numeric values in a 2D plot using different plotting backends.













.  curve is not supported either.  Also if you're on Ubuntu and like to know the most recommended plotting result, simply get a  file of  , which is not available via . And run it by something like: There are two ways to give the topic names to  as explained in following sections. In both ways, topics that are set in previous run is resumed (as far as the program was shut down without error). Type in the ""Topic"" input field the full path of the topic name, and press ""+"" button.  The input value should be the full path to the value, not only the topic name. E.g., in above case the topic  is a member ""x"" in a published topic ""/turtle1/pose"", which is defined as . New short example to show this; say you want to plot a topic called position  of  topic, which is a type of  message. This can be plotted by . Possiblly you can figure out this plot name by following steps like this: Currently  has three plotting backend options () which can be configured using the setting dialog available via the gear icon in the window title bar: By default, backend option is chosen in the order above; the first one found on your system gets used (eg. if your system has  but not , your  runs with the ). See . .debpyqtgraphrosdeprqt_plot/turtle1/pose/xx/your_robot/pose/your_robot/pose/position/xpositiongeometry_msgs/Pointxgeometry_msgs/Pointrqt_plotpyqtgraphUbuntuqwt plotmatplotlibpyqtgraphrqt_plotmatplotlibtopic$ sudo apt-get install ros-$ROS_DISTRO-rqt
$ sudo apt-get install ros-$ROS_DISTRO-rqt-common-plugins$ rosdep install rqt_plot$ dpkg -i %NAME_OF_DOT_DEB_FILE%.deb$ rqt_plot$ rostopic list
/rosout         #  these are only example topics.
/rosout_agg
/turtle1/cmd_vel
/turtle1/color_sensor
/turtle1/pose$ rqt_plot /turtle1/pose/x:y:z
$ rqt_plot /turtle1/pose/x /turtle1/pose/y /turtle1/pose/z"
W337,https://wiki.ros.org/rosabridge,Wiki,rosabridge,"Metapackage for core of rosabridge.
  "
W338,https://wiki.ros.org/yocs_keyop,Wiki,yocs_keyop,Keyboard teleoperation for your robot
W339,https://wiki.ros.org/rqt_gui_cpp,Wiki,rqt_gui_cpp,rqt_gui_cpp enables GUI plugins to use the C++ client library for ROS.
W340,https://wiki.ros.org/rqt_graph,Wiki,rqt_graph,"rqt_graph provides a GUI plugin for visualizing the ROS
      computation graph.
      Its components are made generic so that other packages
      where you want to achieve graph representation can depend upon this pkg
      (use  to find out
      the pkgs that depend. rqt_dep itself depends on rqt_graph too).
  is the successor of . 
  and  can measure certain statistics for every topic connection (see  for more details. This has to be enabled beforehand through: 
 Note: rqt_graph currently does not automatically update the statistics annotations. You have to hit the  button to update them. rqt_graphRefresh$ rosparam set enable_statistics true"
W341,https://wiki.ros.org/mrpt_rbpf_slam,Wiki,mrpt_rbpf_slam,"This package is used for gridmap SLAM. The interface is similar to gmapping (http://wiki.ros.org/gmapping) but the package supports different particle-filter algorithms, range-only SLAM, can work with several grid maps simultaneously and more.





 The sections below describe the API of the package. The interface is similar to gmapping () but the package supports different particle filter algorithms, range-only SLAM and can work with several grid maps simultaneously. This package supports the following Particle Filter SLAM algorithms (more details at ): These algorithms allow building . The ROS node  is a wrapper for the C++ class, part of MRPT. Check out the documentation of this class for further details. This node has been designed to provide an interface similar to that of  for the convenience of users who already know this package. The coordinate frames are implemented according to the convention . In order to use mrpt_rbpf_slam package it is necessary to install the latest  build and the  (see also the ). Additionally, it is possible to install  simulator which allows to make simulations with RBPF SLAM. mrpt_rbpf_slammrpt_rbpf_slamtfscanbeaconparticlecloud_beaconsmapparticlecloudbeacon_viz~global_frame_idstring""map""~base_frame_idstring""base_link""~odom_frame_idstring""odom""~sensor_sourcestring""scan""""scan""""beacon""~ini_filenamestring~rawlog_filenamestring~rawlog_play_delayfloat<the frame attached to incoming scans>base_linktfbase_linkodommapodomroslaunch mrpt_rbpf_slam rbpf_slam.launchroslaunch mrpt_rbpf_slam rbpf_slam_rawlog.launchroslaunch mrpt_rbpf_slam rbpf_slam_rawlog.launch example:=2roslaunch mrpt_rbpf_slam ro_slam.launchroslaunch mrpt_rbpf_slam ro_slam_rawlog.launchroslaunch mrpt_rbpf_slam mvsim_slam.launch"
W342,https://wiki.ros.org/ros_control,Wiki,ros_control,"A set of packages that include controller interfaces, controller managers, transmissions and hardware_interfaces.
  














The ros_control packages are a rewrite of the  packages to make controllers generic to all robots beyond just the PR2. A high-level overview of the project can be found in the ROScon 2014 talk entitled  (, ). A short summary of CombinedRobotHW can be found in  ROScon 2016 talk. Additional documentation is available at the  A list of available controller plugins, contained in , as of this writing. You can of course create your own and are not limited to the below list. All controllers use the  to send commands to a hardware interface. Take a look at the  to understand how the joint_trajectory_controller is namespaced with the position_controller, velocity_controller, etc. Also refer to the  of the hardware_interface and the . From the above it can be seen that power remains constant between input and output. Complementary  (first part will do). See . Transmission-specific code (not robot-specific) implementing bidirectional (actuator <-> joint) effort and flow maps under a uniform interface shared across transmission types. This is hardware-interface-agnostic. A list of available transmission types as of this writing: See  The  contains data structures for representing joint limits, methods for populating them from common formats such as URDF and rosparam, and methods for enforcing limits on different kinds of joint commands. The joint_limits_interface is not used by controllers themselves (it does not implement a ) but instead operates after the controllers have updated, in the  method (or equivalent) of the robot abstraction. Enforcing limits will  the commands set by the controllers, it does not operate on a separate raw data buffer. See  Or on Ubuntu and other platforms from source. To ease installing from source a  file is provided: Not exactly a roadmap, but this  contains discussion and proposed solutions to allow ros_control to better accommodate more complex control setups and address shortcomings in the current implementation. A  exists with a mailing list for discussing ros_control issues and features. You are encouraged to join and help with ros_control's development! @article{ros_control,
author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\""u}dtke, Mathias and Fern{\'a}ndez Perdomo, Enrique},
title = {ros\_control: A generic and simple control framework for ROS},
journal = {The Journal of Open Source Software},
year = {2017},
doi = {10.21105/joss.00456},
URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}
}P_in        = P_out

F_in x V_in = F_out x V_outeffort map: F_joint = F_actuator * n

flow map:   V_joint = V_actuator / nsudo apt-get install ros-$ROS_DISTRO-ros-control ros-$ROS_DISTRO-ros-controllerscd CATKIN_WORKSPACE/src
wstool init
wstool merge https://raw.github.com/ros-controls/ros_control/$ROS_DISTRO-devel/ros_control.rosinstall
wstool update
cd ..
rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO -y
catkin_make"
W343,https://wiki.ros.org/rosflight_sim,Wiki,rosflight_sim,"Software-in-the-loop (SIL) simulator for the ROSflight firmware
This package provides a Gazebo plugin for software-in-the-loop (SIL) simulations with the . "
W344,https://wiki.ros.org/mrpt_local_obstacles,Wiki,mrpt_local_obstacles,"Maintains a local obstacle map (point cloud,
   voxels or occupancy grid) from recent sensor readings within a
   configurable time window.



 This demo requires . It simulates one robot with 2 laser scanners and builds and publish the local obstacle maps to : local_map_pointcloudodom~frameid_referencestring""odom""~frameid_robotstring""base_link""~source_topics_2dscanstring""scan,laser1""~topic_local_map_pointcloudstring""local_map_pointcloud""~time_windowdouble~publish_perioddouble~show_guibool<value of ~frameid_robot> (typ: )<each sensor frameid> (typ: , etc)<value of ~frameid_reference> (typ: )<value of ~frameid_robot> (typ: )/local_map_pointcloudroslaunch mrpt_local_obstacles demo_with_mvsim.launch"
W345,https://wiki.ros.org/rqt_common_plugins,Wiki,rqt_common_plugins,"rqt_common_plugins metapackage provides ROS backend graphical tools suite that can be used on/off of robot runtime.
    
    To run any rqt plugins, just type in a single command ""rqt"", then select any plugins you want from the GUI that launches afterwards.
    
    rqt consists of three following metapackages:
    . 

See . "
W346,https://wiki.ros.org/kinesis_video_streamer,Wiki,kinesis_video_streamer,"Kinesis Video Streams producer node
: Amazon Kinesis Video Streams makes it easy to securely stream video from connected devices to AWS for analytics, machine learning (ML), playback, and other processing. Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions of devices. It also durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. Kinesis Video Streams enables you to playback video for live and on-demand viewing, and quickly build applications that take advantage of computer vision and video analytics through integration with Amazon Recognition Video, and libraries for ML frameworks such as Apache MxNet, TensorFlow, and OpenCV. : The easy-to-use Rekognition API allows you to automatically identify objects, people, text, scenes, and activities, as well as detect any inappropriate content. Developers can quickly build a searchable content library to optimize media workflows, enrich recommendation engines by extracting text in images, or integrate secondary authentication into existing applications to enhance end-user security. With a wide variety of use cases, Amazon Rekognition enables you to easily add the benefits of computer vision to your business. : ROS, AWS, Kinesis Video Streams 

The Amazon Kinesis Video Streams ROS package enables robots to stream video to the cloud for analytics, playback, and archival use. Out of the box, the nodes provided make it possible to encode & stream image data (e.g. video feeds and LIDAR scans) from a ROS “Image” topic to the cloud, enabling you to view the live video feed through the Kinesis Video Console, consume the stream via other applications, or perform intelligent analysis, face detection and face recognition using Amazon Rekognition. The node will transmit standard  data from ROS topics to Kinesis Video streams, optionally encoding the images as h264 video frames along the way (using the included h264_video_encoder), and optionally fetches Amazon Rekognition results from corresponding Kinesis Data Streams and publishing them to local ROS topics. The source code is released under . sensor_msgs/ImagecodecKeywords"
W347,https://wiki.ros.org/octovis,Wiki,octovis,"octovis is visualization tool for the OctoMap library based on Qt and libQGLViewer. See
  http://octomap.github.io for details.octovis provides visualization for  based on Qt and libQGLViewer. octovis is available in the  debian package. As an alternative, you can download the package yourself from  and compile it with the library stand-alone or against a locally installed  library. This will install OctoMap and octovis as stand-alone libraries with no ROS dependencies, so they can be also used in a non-ROS setting. Use GitHub to . For questions and discussions, check the . ros-$ROS_DISTRO-octomapsudo apt-get install ros-$ROS_DISTRO-octovis"
W348,https://wiki.ros.org/jackal_base,Wiki,jackal_base,"Jackal's mobility and sensor base.

This package contains the primary binary which runs on , providing the -based comms to the MCU, as well as diagnostic support, and other basic services. Jackal includes a built-in magnetometer, which is used by  to estimate orientation. To calibrate the magnetometer using scripts provided by this package, see . "
W349,https://wiki.ros.org/mavros_msgs,Wiki,mavros_msgs,"mavros_msgs defines messages for .
"
W350,https://wiki.ros.org/pgm_learner,Wiki,pgm_learner,Parameter/Structure Estimation and Inference for Bayesian Belief Network
W351,https://wiki.ros.org/multisense_ros,Wiki,multisense_ros,multisense_ros
W352,https://wiki.ros.org/rosbaglive,Wiki,rosbaglive,"Plays rosbags as though they were happening NOW.

"
W353,https://wiki.ros.org/rqt_launchtree,Wiki,rqt_launchtree,"An RQT plugin for hierarchical launchfile configuration introspection.
  





Use GitHub to . []
  In case you want to make sure that you get the latest updates and fixes, the source repository is available on  and can be checked out by running (in the /src folder of your workspace): If you are using ROS Kinetic, you will need to switch the branch first. This is required because  has been replaced by , which has a few different bindings. sudo apt-get install ros-indigo-rqt-launchtreegit clone https://github.com/pschillinger/rqt_launchtree.git 
cd ..
catkin_makegit checkout kinetic"
W354,https://wiki.ros.org/laser_geometry,Wiki,laser_geometry,"This package contains a class for converting from a 2D laser scan as defined by
    sensor_msgs/LaserScan into a point cloud as defined by sensor_msgs/PointCloud
    or sensor_msgs/PointCloud2. In particular, it contains functionality to account
    for the skew resulting from moving robots or tilting laser scanners.


 To convert a  to a  
 To convert a  to a  in the base_link frame, using a high fidelity transform: 


The laser_geometry package contains a single C++ class: .  There is no ROS API. This class has two relevant functions for transforming from  to  or . Both of these functions have a final optional argument that augments the  which is created to include extra channels.  These channels may include intensities, distances, timestamps, the index or thew viewpoint from the original laser array. There is a simple Python implementation here (). The method  does the simplest possible projection of the laser.  Each ray is simply projected out along the appropriate angle according to: The appropriate sine and cosine values are cached, making this a very efficient operation.  However, the generated  is in the same frame as the original . While this has the advantage that it does not require an instance of a  or message notifier, it does not hold up in situations where the laser is moving and skew needs to be accounted for. Please consult the  for full usage details. The  method does a more advanced projection, but requires that you have set up a  transform listener. (If you are unfamiliar with , it is recommended you go through the  first.) Because the stamp of a  is the time of the  measurement, one cannot simply wait for a transform to target_frame at this stamp. Instead one also has to wait for a transform at the  measurement of the scan. Please consult the  for full usage details.  The method  projects a single laser scan from a linear array into a 3D . The generated cloud will be in the same frame as the original laser scan. projectLaser()transformLaserScanToPointCloud()projectLaser()tf::transformertransformLaserScanToPointCloud()projectLaser()









































































"
W355,https://wiki.ros.org/mbf_abstract_core,Wiki,mbf_abstract_core,"This package provides common interfaces for navigation specific robot actions. It contains the AbstractPlanner, AbstractController and AbstractRecovery plugin interfaces. This interfaces have to be implemented by the plugins to make the plugin available for Move Base Flex. The abstract classes provides a meaningful interface enabling the planners, controllers and recovery behaviors to return information, e.g. why something went wrong. Derivided interfaces can, for example, provide methods to initialize the planner, controller or recovery with map representations like costmap_2d, grid_map or other representations."
W356,https://wiki.ros.org/xpp_vis,Wiki,xpp_vis,"Visualization for the XPP Motion Framework.
  "
W357,https://wiki.ros.org/xpp,Wiki,xpp,"Visualization of motion-plans for legged robots. It draws support areas, 
    contact forces and motion trajectories in RVIZ and displays URDFs for 
    specific robots, including a one-legged, a two-legged hopper and
    . 
    Example motions were generated by
    .
  
 

  




Also you can always clone the repo into your catkin workspace and build from source, as described . The more involved example trajectories shown have been generated with , an optimizer for legged robot motions. However, simple motion plans can also be generated by hand as shown below. This example is taken from . Run it using  Then simply right-click on  and  -> . Or load the rosbag in  To visualize your own URDF is very easy to setup. A minimal example to follow can be seen here:. We would be happy to see a  to add your robot. Apart from benefitting the open-source community, this also adds publicity and visibility to you / your lab. The ROS page you can then design for your robot could look similar to this: . This software has been used in the following : Please post any questions you have at  using the tag . xpp/state_desViewPlotxpp$ sudo apt-get install ros-kinetic-xpp
$ roslaunch xpp_examples hyq_bag.launch$ roslaunch xpp_examples monoped_ex_generate.launch 


































$ roscd xpp_examples/bags/
$ rqt_bag hyq.bag 

@misc{xpp_ros,
  author = {Alexander W. Winkler},
  title  = {{Xpp - A collection of ROS packages for the visualization of legged robots}},
  year   = {2017},
  doi    = {10.5281/zenodo.1037901},
  url    = {https://doi.org/10.5281/zenodo.1037901}
}"
W358,https://wiki.ros.org/pose_cov_ops,Wiki,pose_cov_ops,"C++ library for SE(2/3) pose and 2D/3D point
    composition operations with uncertainty


See the C++ API documentation for the namespace . This module provides implementations for the  between poses (,,) and points (), which are the following (using the ""o plus"" and ""o minus"" notation): 















"
W359,https://wiki.ros.org/naoqi_driver,Wiki,naoqi_driver,"Driver module between Aldebaran's NAOqiOS and ROS. It publishes all sensor and actuator data as well as basic diagnostic for battery, temperature. It subscribes also to RVIZ simple goal and cmd_vel for teleop.
This package provides a bridge between ROS and . It is the officially supported by  Aldebaran. The package is based on C++ implementation of the former python edition .  All documentation can be found on . "
W360,https://wiki.ros.org/cl_transforms,Wiki,cl_transforms,Homogeneous transform library for Common Lisp.
W361,https://wiki.ros.org/zeroconf_jmdns_suite,Wiki,zeroconf_jmdns_suite,"An implementation of zeroconf in pure java.







This package compiles the  sources and includes a convenience class for interfacing jmdns with ros. Jmdns is a 100% java implementation of the  standard. It is currently being used and tested for android devices, however it is perfectly ok to use (and we may extend it more fully later) for pc implementations. Jmdns has a multi-homed interface (JmmDNS) which could almost be used directly, but it is still experimental - there are a few catches, broken api and a bit of black magic. To make the library easier to use and to interface it with ros, it also provides  class. This package also includes three demo programs in , to help quickly experiment with this package. sudo apt-get install avahi-utils> avahi-browse _ros-master._tcp./build/install/jmdns_tutorials/bin/jmdns_tutorials --publisher> avahi-publish -s DudeMaster _ros-master._tcp 8882./build/install/jmdns_tutorials/bin/jmdns_tutorials --polling./build/install/jmdns_tutorials/bin/jmdns_tutorials --discovery"
W362,https://wiki.ros.org/yocs_safety_controller,Wiki,yocs_safety_controller,"A controller ensuring the safe operation of your robot.

    The SafetyController listens to ranger readings in order to stop (and move back), if obstacles get to close.

    This controller can be enabled/disabled."
W363,https://wiki.ros.org/dwb_plugins,Wiki,dwb_plugins,"Standard implementations of the GoalChecker
      and TrajectoryGenerators for dwb_local_planner "
W364,https://wiki.ros.org/joint_state_publisher,Wiki,joint_state_publisher,"This package contains a tool for setting and publishing joint state values for a given URDF.


 




 This package publishes  messages for a robot.  The package reads the  parameter from the , finds all of the non-fixed joints and publishes a JointState message with all those joints defined. This package can be used in conjunction with the  node to also publish transforms for all joint states. There are four possible sources for the value of each JointState: Set the  parameter, see below. This is can be specified through the  parameter or the  tag in the . The default value is zero. If zero is not a permissible value  is used. To override the default value for some joints, use the  parameter. An example YAML file is seen below. The following YAML snippets show examples of how to set the  and the  parameters using YAML syntax. These can be loaded to the parameter server using the  in a launch file. groovy-develrobot_descriptionjoint_state_publisherjoint_state_publisher_guiuse_guijoint_state_publisherjoint_state_publisher_guijoint_state_publisher_gui<exec_depend>joint_state_publisher_guijoint_state_publisheruse_guisource_listdependent_jointsmimiczerosdependent_jointszerosdependent_joints:
  joint_D: {parent: joint_A, factor: 3 }
  joint_E: {parent: joint_B }
  joint_F: {parent: joint_C, factor: -1 }zeros:
  joint_A: 1.57
  joint_B: 0.785"
W365,https://wiki.ros.org/qt_gui_py_common,Wiki,qt_gui_py_common,qt_gui_py_common provides common functionality for GUI plugins written in Python.
W366,https://wiki.ros.org/openrtm_ros_bridge,Wiki,openrtm_ros_bridge,"openrtm_ros_bridge package provides basic functionalities to bind
    two robotics framework:  and ROS.
    By using this package, you can write your ROS packages that communicate with your
    non-ROS robots that run on OpenRTM.
  		
    For communicating with the robots that run on hrpsys, you can use
     package.Documentation is available . "
W367,https://wiki.ros.org/pr2_counterbalance_check,Wiki,pr2_counterbalance_check,"pr2_counterbalance_check
The  package contains utilities for checking the counterbalance of the PR2. It is used by the production testing systems, and can be run onboard a PR2. pr2_counterbalance_check"
W368,https://wiki.ros.org/marker_msgs,Wiki,marker_msgs,"The marker_msgs package contains messages usable to setup a marker/fiducial system. 
    The package distinguishes between two types of messages. 
    First messages to describe the properties of a marker/fiducial detection system and the detected markers. 
    Secondly messages used to represent a map of markers/features with covariances as it would be produced by a SLAM system or published by a map server for self-localization.
 
 With the help of the  the msgs can be visualized in rviz. "
W369,https://wiki.ros.org/jsk_interactive_marker,Wiki,jsk_interactive_marker,jsk interactive markers
W370,https://wiki.ros.org/visualization_tutorials,Wiki,visualization_tutorials,"Metapackage referencing tutorials related to rviz and visualization.

  This is the stack that provides the code for the  "
W371,https://wiki.ros.org/pmb2_description,Wiki,pmb2_description,"Mechanical, kinematic, visual, etc. description of the PMB2 robot.
      The files in this package are parsed and used by
      a variety of other components.  Most users will not interact directly
      with this package."
W372,https://wiki.ros.org/video_stream_opencv,Wiki,video_stream_opencv,"The video_stream_opencv package contains a node to publish a video stream (the protocols that
    opencv supports are supported, including rtsp, webcams on /dev/video and video files) in ROS image topics, it supports camera info and basic image flipping (horizontal, vertical or both) capabilities, also adjusting publishing rate.
 



A package to view video streams based on the , easy way to publish on a ROS Image topic (including camera info) usb cams, ethernet cameras, video streams or video files. It also supports flipping of images and fps throttling. Example usages in launch folder (only the argument  is mandatory): So if you want the very latest image published from a camera, set  to 1,  to the max the camera allows and  to that same max. If you want to publish all images (don't drop any and you don't mind some possible delay from real time), set  big enough for your case (1000?),  and  to whatever FPS it has. If you want to test quickly if your desired input may work with this node you can use a simple python script called  which just tries to open the video resource (no ROS involved, just copy the file to your computer and try). Just do any of those: video_stream_provider/dev/videoX/dev/video0rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.movmyvideo.aviset_camera_fpsCV_CAP_PROP_FPSbuffer_queue_sizefpsbuffer_queue_sizeset_camera_fpsfpsbuffer_queue_sizeset_camera_fpsfpsvideo_stream_providercamera_nameframe_idcamera_info_urlflip_horizontalflip_verticalloop_videofileloop_videofiletruewidthheight<launch>
   <!-- launch video stream -->
   <include file=""$(find video_stream_opencv)/launch/camera.launch"" >
        <!-- node name and ros graph name -->
        <arg name=""camera_name"" value=""webcam"" />
        <!-- means video device 0, /dev/video0 -->
        <arg name=""video_stream_provider"" value=""0"" />
        <!-- set camera fps to (if the device allows) -->
        <arg name=""set_camera_fps"" value=""30""/>
        <!-- set buffer queue size of frame capturing to -->
        <arg name=""buffer_queue_size"" value=""100"" />
        <!-- throttling the querying of frames to -->
        <arg name=""fps"" value=""30"" />
        <!-- setting frame_id -->
        <arg name=""frame_id"" value=""webcam"" />
        <!-- camera info loading, take care as it needs the ""file:///"" at the start , e.g.:
        ""file:///$(find your_camera_package)/config/your_camera.yaml"" -->
        <arg name=""camera_info_url"" value="""" />
        <!-- flip the image horizontally (mirror it) -->
        <arg name=""flip_horizontal"" value=""false"" />
        <!-- flip the image vertically -->
        <arg name=""flip_vertical"" value=""false"" />
        <!-- visualize on an image_view window the stream generated -->
        <arg name=""visualize"" value=""true"" />
   </include>
</launch>rosrun video_stream_opencv test_video_resource.py 0
rosrun video_stream_opencv test_video_resource.py rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov
rosrun video_stream_opencv /home/youruser/myvideo.mkvTrying to open resource: /dev/video0
Correctly opened resource, starting to show feed."
W373,https://wiki.ros.org/xmlrpcpp,Wiki,xmlrpcpp,"XmlRpc++ is a C++ implementation of the XML-RPC protocol. This version is
    heavily modified from the package available on SourceForge in order to
    support roscpp's threading model. As such, we are maintaining our
    own fork."
W374,https://wiki.ros.org/pmb2_simulation,Wiki,pmb2_simulation,"PMB2-specific simulation components. These include plugins
               and launch scripts necessary for running PMB2 in simulation."
W375,https://wiki.ros.org/pr2_calibration_controllers,Wiki,pr2_calibration_controllers,"The pr2_calibration_controllers package contains the controllers
     used to bring all the joints in the PR2 to a calibrated state. "
W376,https://wiki.ros.org/jsk_rviz_plugins,Wiki,jsk_rviz_plugins,The jsk_rviz_plugins packageDocument:  
W377,https://wiki.ros.org/mavlink,Wiki,mavlink,"MAVLink message marshaling library.
  This package provides C-headers and C++11 library
  for both 1.0 and 2.0 versions of protocol.

  For pymavlink use separate install via rosdep (python-pymavlink).

"
W378,https://wiki.ros.org/rosflight,Wiki,rosflight,"Package for interfacing to the ROSflight autopilot firmware over MAVLink


 
 ROSflight provides a simple, low-latency interface between a flight controller running the ROSflight firmware and ROS. ROSflight can stream both sensor data and motor commands at high speed. ROSflight is written to work with a variety of airframes, including multirotor and fixed-wing aircraft. The ROSflight package provided the interface for autopilots, but does not include any control code. For examples of autopilots using ROSflight, see  or . For documentation on the firmware, see . commandmodeignoreaux_commandtype_arrayvaluesexternal_attitudeexternal_attitudeattitudeairspeedattitudeattitude/eulerbarobatterygnssgnss_rawimu/dataimu/temperaturemagnetometernavsat_compat/fixnavsat_compat/time_referencetimenavsat_compat/vellinearoutput_rawrc_rawrosflight_errorssonarstatusunsaved_paramsversionnamed_value/int/<name>named_value/float/<name>param_getparam_setparam_writeparam_save_to_fileparam_load_from_filecalibrate_imucalibrate_rc_trimcalibrate_barocalibrate_airspeedrebootreboot_to_bootloader~portstring~baud_rateint~frame_idstring~udpbool~bind_hoststring~bind_portint~remote_hoststring~remote_portint$ rosrun rosflight rosflight_io _port:=/dev/ttyUSB0"
W379,https://wiki.ros.org/multi_object_tracking_lidar,Wiki,multi_object_tracking_lidar,"ROS package for Multiple objects detection, tracking and classification from LIDAR scans/point-clouds
  




 ()  PCL based ROS package to Detect/Cluster --> Track --> Classify static and dynamic objects in real-time from LIDAR scans implemented in C++. Follow the steps below to use this () package: If all went well, the ROS node should be up and running! As long as you have the point clouds published on to the  rostopic, you should see outputs from this node published onto the , , , …,  topics along with the markers on  topic which you can visualize using RViz. 1.  multi_object_tracking_lidarsrccd ~/catkin_ws/srcgit clone https://github.com/praveen-palanisamy/multiple-object-tracking-lidar.gitcd ~/catkin_ws && catkin_makesource ~/catkin_ws/devel/setup.bashkf_trackerrosrun multi_object_tracking_lidar kf_trackerfiltered_cloudobj_idcluster_0cluster_1cluster_5viz@software{praveen_palanisamy_2019_3559187,
  author       = {Praveen Palanisamy},
  title        = {{praveen-palanisamy/multiple-object-tracking-lidar:
                   Multiple-Object-Tracking-from-Point-Clouds_v1.0.2}},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {1.0.2},
  doi          = {10.5281/zenodo.3559187},
  url          = {https://doi.org/10.5281/zenodo.3559186}
}"
W380,https://wiki.ros.org/jsk_pepper_startup,Wiki,jsk_pepper_startup,The jsk_pepper_startup package
W381,https://wiki.ros.org/rqt_robot_monitor,Wiki,rqt_robot_monitor,"rqt_robot_monitor displays diagnostics_agg topics messages that
   are published by .
   rqt_robot_monitor is a direct port to rqt of
   . All
   diagnostics are fall into one of three tree panes depending on the status of
   diagnostics (normal, warning, error/stale). Status are shown in trees to
   represent their hierarchy. Worse status dominates the higher level status.
   "
W382,https://wiki.ros.org/pepper_meshes,Wiki,pepper_meshes,meshes for the Aldebaran Robotics Pepper
W383,https://wiki.ros.org/joystick_drivers,Wiki,joystick_drivers,"This metapackage depends on packages for interfacing common
    joysticks and human input devices with ROS.

 "
W384,https://wiki.ros.org/sbg_driver,Wiki,sbg_driver,"ROS driver package for communication with the SBG navigation systems.




















  sudo apt-get install ros-$ROS_DISTRO-sbg-driverroslaunch sbg_driver sbg_device.launchroslaunch sbg_driver sbg_device_mag_calibration.launch# Configuration of the device with ROS.
confWithRos: truesudo adduser $USER dialout$ roslaunch sbg_driver sbg_device_mag_calibration.launch
$ rosservice call /sbg/mag_calibration
// Proceed rotations on the IMU
$ rosservice call /sbg/mag_calibration
// If the magnetic calibration results are satisfaying, it could be uploaded
$ rosserive call /sbg/mag_calibration_save"
W385,https://wiki.ros.org/mbf_abstract_nav,Wiki,mbf_abstract_nav,"The mbf_abstract_nav package contains the abstract navigation server implementation of Move Base Flex (MBF). The abstract navigation server is not bound to any map representation. It provides the actions for planning, controlling and recovering. MBF loads all defined plugins at the program start. Therefor, it loads all plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions."
W386,https://wiki.ros.org/rqt_console,Wiki,rqt_console,"rqt_console provides a GUI plugin for displaying and filtering ROS messages. 
 is a viewer in the  package that displays messages being published to .  It collects messages over time, and lets you view them in more detail, as well as allowing you to filter messages by various means. 











Sending messages to  is done differently in each client library: ,  Assuming you have ROS installed, you can invoke  by just typing: The list view shows all of the messages, updating in real time as they arrive.  The list displays all the information in the  message broadcast on : There are two operations you can use on the items in the list.  A  will bring up all the information about that message in a separate box. A  will pop up a menu allowing you to filter the list based on some aspect of the selected message  See the  page. It will help you use  to publish error, info and debug messages and view them in rqt_console. rqt_consolerqt_consolerqt_console/u/jfaust/ros/base/pkgs/ros_tutorials/roscpp_tutorials/talker/talker.cpp:main:92rqt_console"
W387,https://wiki.ros.org/json_transport,Wiki,json_transport,JSON transport for ROS
W388,https://wiki.ros.org/pr2_gripper_action,Wiki,pr2_gripper_action,"The pr2_gripper_action provides an action interface for using the
  gripper. Users can specify what position to move to (while limiting the
  force) and the action will report success when the position is reached or
  failure when the gripper cannot move any longer. 







Users interested in grasping more delicate objects may want to checkout the alternative  package. You can see an example of using the pr2 gripper action on the PR2 in the . The  provides more context on how the  and how . ~goal_thresholddouble~stall_timeoutdouble~stall_velocity_thresholddouble~gripper_action/goal~gripper_action/cancel~gripper_action/statusaction~gripper_action/result~state~command"
W389,https://wiki.ros.org/novatel_gps_driver,Wiki,novatel_gps_driver,Driver for NovAtel receivers
W390,https://wiki.ros.org/pcl_ros,Wiki,pcl_ros,"PCL (Point Cloud Library) ROS interface stack. PCL-ROS is the preferred
  bridge for 3D applications involving n-D Point Clouds and 3D geometry
  processing in ROS.

 includes several  packaged as ROS nodelets. These links provide details for using those interfaces: 
 extends the ROS  to support message passing with  native data types. Simply add the following include to your ROS node source code: 


 


 

 

 


 


This header allows you to publish and subscribe  objects as ROS messages. These appear to ROS as  messages, offering seamless interoperability with non-PCL-using ROS nodes. For example, you may publish a  in one of your nodes and visualize it in  using a . It works by hooking into the  infrastructure. The old format  is not supported in PCL. You may publish PCL point clouds using the standard : You may likewise subscribe to PCL point clouds using the standard : Read messages from the  topic in , saving a PCD file for each message into the  subdirectory. Read the point cloud in <cloud.pcd> and publish it in ROS image messages at 5Hz. Subscribe to the  topic and republish each message on the  topic. To view the images created by the previous command, use . Publish the contents of  once in the  frame of reference. Publish the contents of  approximately ten times a second in the  frame of reference. Subscribe to the  topic and save each message in the current directory. File names look like , the exact names depending on the message time stamps. Set the  parameter in the current namespace, save messages to files with names like . We have more examples on  page pcl_rospcl_rospcl::PointCloud<T>ros::Publisherros::Subscriber/laser_tilt_clouddata.bag./pointcloudsoutputinputoutput/my_cloud/my_imagecloud_pcd~frame_idstrpoint_cloud_file.pcd/base_linkcloud_file.pcd/odomprefix.pcdinput~prefixstr~fixed_framestr~binarybool~compressedbool/velodyne/pointcloud21285627014.833100319.pcdprefix/tmp/pcd/vel_1285627015.132700443.pcd#include <pcl_ros/point_cloud.h>















































 $ rosrun pcl_ros bag_to_pcd <input_file.bag> <topic> <output_directory> $ rosrun pcl_ros bag_to_pcd data.bag /laser_tilt_cloud ./pointclouds $ rosrun pcl_ros convert_pcd_to_image <cloud.pcd> $ rosrun pcl_ros convert_pointcloud_to_image input:=/my_cloud output:=/my_image $ rosrun image_view image_view image:=/my_image $ rosrun pcl_ros pcd_to_pointcloud <file.pcd> [ <interval> ] $ rosrun pcl_ros pcd_to_pointcloud point_cloud_file.pcd $ rosrun pcl_ros pcd_to_pointcloud cloud_file.pcd 0.1 _frame_id:=/odom $ rosrun pcl_ros pointcloud_to_pcd input:=/velodyne/pointcloud2 $ rosrun pcl_ros pointcloud_to_pcd input:=/my_cloud _prefix:=/tmp/pcd/vel_"
W391,https://wiki.ros.org/joint_limits_interface,Wiki,joint_limits_interface,"Interface for enforcing joint limits.
See the  page and the  for more information. "
W392,https://wiki.ros.org/zivid_camera,Wiki,zivid_camera,"Driver for using the Zivid 3D cameras in ROS.
For more information about the zivid_camera ROS driver, read the . "
W393,https://wiki.ros.org/xpp_states,Wiki,xpp_states,"Common definitions (positions, velocities, angular angles,
    angular rates) and robot definitions in Cartesian and joint state
    used in the Xpp Motion Framework, as well as conversions to/from
    xpp_msgs.
  



This package provides two ways to describe an articulated robot state, one in cartesian (=task) space, the other in joint (=configuration) space. Each of these states has a corresponding ROS message , where conversion function are provided in .  
In this representation (), the robot is described by the position, velocity and acceleration of it's endeffectors and the Cartesian force they exert. In this representation () the endeffector state is only indirectly given through the joint values. Instead of forces acting on the endeffectors, this state equivalently represents this as torques acting on the joints. The core difference between the above representations is how the articulated limbs and the force they exert are described (task or joint space). In order to make these states most interchangeable, we create a class () that parameterizes each endeffector. This can be done in two ways: convert.h















"
W394,https://wiki.ros.org/jackal_bringup,Wiki,jackal_bringup,"Scripts for installing Jackal's robot software.
See  for information on Jackal configurations. "
W395,https://wiki.ros.org/libuvc_camera,Wiki,libuvc_camera,"USB Video Class camera driver




 
 
  This package provides a ROS interface for digital cameras meeting the USB Video Class standard (UVC) using . Most webcams are UVC-compliant. Under Linux, the user that runs camera_node must have write permissions to the  device that corresponds to the camera. You may run the node as root: However, use of  rules is recommended. In , to give every user camera access: Alternatively, set  to grant access for any user in that group. You may need to disable your operating system's builtin USB video or audio drivers. On Linux, the  and  modules conflict with libuvc. Try unloading them with  and consider blacklisting them -- e.g., add the lines  and  to an  file. (Applications that don't use libuvc will be unable to stream from the camera.) /dev/bus/usb/.../etc/udev/rules.d/99-uvc.rulesGROUP=""mygroup""snd-usb-audiouvcvideosudo rmmod snd-usb-audio; sudo rmmod uvcvideoblacklist uvcvideoblacklist snd-usb-audio/etc/modprobe.d/uvc.conf$ sudo -E rosrun libuvc_camera camera_node vendor:=...   lsusb -v# UVC cameras
SUBSYSTEMS==""usb"", ENV{DEVTYPE}==""usb_device"", ATTRS{idVendor}==""046d"", ATTRS{idProduct}==""08cc"", MODE=""0666""
# ^ Change the vendor and product IDs to match your camera.# UVC cameras
SUBSYSTEMS==""usb"", ENV{DEVTYPE}==""usb_device"", ATTRS{idVendor}==""046d"", ATTRS{idProduct}==""08cc"", OWNER=""myuser""
# ^ Change the owner and the vendor and product IDs to match your camera.#UVC cameras
SUBSYSTEMS==""usb"", ATTRS{idVendor}==""046d"", MODE=""0666""sudo chmod o+w /dev/bus/usb/001/024 <-- where 024 is port# from the error code   v4l2-ctl --list-formats-ext<launch>
  <group ns=""camera"">
    <node pkg=""libuvc_camera"" type=""camera_node"" name=""mycam"">
      <!-- Parameters used to find the camera -->
      <param name=""vendor"" value=""0x0""/>
      <param name=""product"" value=""0x0""/>
      <param name=""serial"" value=""""/>
      <!-- If the above parameters aren't unique, choose the first match: -->
      <param name=""index"" value=""0""/>

      <!-- Image size and type -->
      <param name=""width"" value=""640""/>
      <param name=""height"" value=""480""/>
      <!-- choose whichever uncompressed format the camera supports: -->
      <param name=""video_mode"" value=""uncompressed""/> <!-- or yuyv/nv12/mjpeg -->
      <param name=""frame_rate"" value=""15""/>

      <param name=""timestamp_method"" value=""start""/> <!-- start of frame -->
      <param name=""camera_info_url"" value=""file:///tmp/cam.yaml""/>

      <param name=""auto_exposure"" value=""3""/> <!-- use aperture_priority auto exposure -->
      <param name=""auto_white_balance"" value=""false""/>
    </node>
  </group>
</launch>"
W396,https://wiki.ros.org/virtual_force_publisher,Wiki,virtual_force_publisher,"publish end effector's force, which is estmated from joint torque value"
W397,https://wiki.ros.org/multi_map_server,Wiki,multi_map_server,multi_map_server provides themap_servermap_saver
W398,https://wiki.ros.org/mrpt_slam,Wiki,mrpt_slam,"mrpt_slam


  See also: ,  # This will install all packages in the mrpt_slam metapackage
# Alternatively, install individual packages only as you need them
sudo apt-get install ros-$ROS_DISTRO-mrpt-slam"
W399,https://wiki.ros.org/moveit_ros_perception,Wiki,moveit_ros_perception,Components of MoveIt! connecting to perception
W400,https://wiki.ros.org/cl_utils,Wiki,cl_utils,Common Lisp utility libraries
W401,https://wiki.ros.org/youbot_simulation,Wiki,youbot_simulation,Packages to run the KUKA youBot in the Gazebo simulation with ROS
W402,https://wiki.ros.org/imagesift,Wiki,imagesift,"For every image, computes its sift features and send a new message with the image, its intrinsic parameters, and the features.
    Parameters include:
    display - shows the image on the local computer"
W403,https://wiki.ros.org/joy_mouse,Wiki,joy_mouse,The joy_mouse package
W404,https://wiki.ros.org/moveit_planners,Wiki,moveit_planners,Metapacakge that installs all available planners for MoveIt
W405,https://wiki.ros.org/move_base_msgs,Wiki,move_base_msgs,"Holds the action description and relevant messages for the move_base package


This package contains the messages used to communicate with the  node. These messages are auto-generated from the  action specification. For more information on actions see , for more information on the  node see . The  is the goal that the navigation stack attempts to achieve. The  given as feedback is the current position of the base in the world as reported by . For the  node, the  is projected into the XY plane with the Z axis pointing up when attempting to achieve a goal. MoveBase.actiontarget_posebase_positiontarget_posegeometry_msgs/PoseStamped target_pose
---
---
geometry_msgs/PoseStamped base_position"
W406,https://wiki.ros.org/mbf_simple_nav,Wiki,mbf_simple_nav,"The mbf_simple_nav package contains a simple navigation server implementation of Move Base Flex (MBF). The simple navigation server is bound to no map representation. It provides actions for planning, controlling and recovering. MBF loads all defined plugins which are defined in the lists *planners*, *controllers* and *recovery_behaviors*. Each list holds a pair of a *name* and a *type*. The *type* defines which kind of plugin to load. The *name* defines under which name the plugin should be callable by the actions. 

        It tries to load the defined plugins which implements the defined interfaces in ."
W407,https://wiki.ros.org/py_trees,Wiki,py_trees,"Pythonic implementation of behaviour trees.
 Get started at the  for the project. If using this in ROS 1, see also , ,  "
W408,https://wiki.ros.org/vision_opencv,Wiki,vision_opencv,"Packages for interfacing ROS with OpenCV, a library of programming functions for real time computer vision.



 
The  stack provides packaging of the popular OpenCV library for ROS. For information about the OpenCV library, please see the OpenCV main page at  links to complete documentation for OpenCV, as well as other OpenCV resources (like the bug tracker on ) In order to use ROS with OpenCV, please see the  package. Since Indigo, there is a package for OpenCV3. Information about it is detailed at . vision_opencvvision_opencv   find_package(OpenCV)
   include_directories(${OpenCV_INCLUDE_DIRS})
   target_link_libraries(my_awesome_library ${OpenCV_LIBRARIES})   find_package(OpenCV 2 REQUIRED)"
W409,https://wiki.ros.org/pointgrey_camera_driver,Wiki,pointgrey_camera_driver,"Point Grey camera driver based on libflycapture2. 



When multiple Point Grey cameras are in use at a time, specify the serial number given by : Until better documentation is produced, please see the  file for the available parameters.  When using Point Grey's GigE cameras, you may experience an issue with dropped packets which results in  being thrown by the FlyCapture2 SDK. You can adjust the receive buffer settings in Linux using  to correct this. See  for more details. Similarly, multiple USB cameras may require raising the amount of memory allocated to the USB subsystem.  The usbcore variable  should be set suitably large.  describes two common ways of setting it, via the kernel command line (edit ), or module loading ( for current session, or adding  to an appropriate  file).  It should also be settable at runtime via  list_camerasIMAGE_CONSISTENCY_ERRORsysctlusbfs_memory_mb/boot/grub.confmodprobe usbcore usbfs_memory_mb=1024options usbcore usbfs_memory_mb=1000/etc/modprobe.d/sys/module/usbcore/parameters/usbfs_memory_mbsudo apt-get install ros-$ROS_DISTRO-pointgrey-camera-driverrosrun pointgrey_camera_driver list_camerasroslaunch pointgrey_camera_driver bumblebee.launch
roslaunch pointgrey_camera_driver camera.launchroslaunch pointgrey_camera_driver camera.launch camera_serial:=12345678"
W410,https://wiki.ros.org/xbot_safety_controller,Wiki,xbot_safety_controller,"A controller ensuring the safe operation of Xbot.

    The SafetyController keeps track of bumper, cliff and wheel drop events. In case of the first two,
    Xbot is commanded to move back. In the latter case, Xbot is stopped.
    
    This controller can be enabled/disabled.
    The safety states (bumper pressed etc.) can be reset. WARNING: Dangerous!"
W411,https://wiki.ros.org/roslint,Wiki,roslint,"CMake lint commands for ROS packages.

    The lint commands perform static checking of Python or C++ source
    code for errors and standards compliance.


You might also check  for checking package configuration. Add a  dependency on roslint to your package's :  In your package's  file, include roslint as one of your catkin component dependencies: Then, invoke the roslint functions from your , eg: To run roslint against your package you must invoke catkin_make with your package's roslint target. For example, for a package named  you would run: Each  function create a catkin build target called , which runs all specified lint operations for the package. Each additionally creates (if it does not yet exist) a master  target, which depends on all other  targets. To fix basic whitespace issues in C++, try using . Example invocation within your package: For similar fixes in Python, try . Example: package.xmlCMakeLists.txtCMakeLists.txtmy_fancy_packageroslint_*roslint_''pkgname''roslintroslint_*roslint_cpp([files ...])cpphroslint_python([files ...])pyroslint_custom(linter linter_opts file [...])roslint_add_test()<build_depend>roslint</build_depend>find_package(catkin REQUIRED COMPONENTS roslint ...)roslint_cpp()roslint_cpp(src/foo.cpp src/bar.cpp src/baz.cpp)catkin_make roslint_my_fancy_packagecatkin build my_fancy_package --make-args roslintcd ~/catkin_ws
catkin build
cd build/my_fancy_package
make roslintsudo apt-get install astyle
find -regextype egrep -regex '.*\.[ch](pp)?$' -exec astyle '{}' --style=allman --indent=spaces=2 --pad-oper --unpad-paren --pad-header --convert-tabs \;sudo pip install pep8ify
pep8ify -nw .set(ROSLINT_CPP_OPTS ""--filter=-runtime/references,-runtime/int"")
roslint_cpp()
set(ROSLINT_PYTHON_OPTS ""--max-line-length=180"")
roslint_python()// There's just no other way; I don't control the location of this header.
#include ""my_silly_header.h""  // NOLINT(build/include)"
W412,https://wiki.ros.org/easy_markers,Wiki,easy_markers,"Python library to assist in publishing markers easily
 
 









































"
W413,https://wiki.ros.org/image_geometry,Wiki,image_geometry,"`image_geometry` contains C++ and Python libraries for interpreting images
    geometrically. It interfaces the calibration parameters in sensor_msgs/CameraInfo
    messages with OpenCV functions such as image rectification, much as cv_bridge
    interfaces ROS sensor_msgs/Image with OpenCV data types.
 contains Python and C++ libraries that simplifies interpreting images geometrically using the parameters from . Although  contains all the information required to rectify a raw image and project points onto it, , since performing these operations correctly over the space of all camera options can be non-trivial. 


The camera parameters in  are for a full-resolution image; region-of-interest alone significantly complicates the creation of rectification maps and requires adjusting the projection matrix. Adding options such as subsampling (binning) to  would further complicate the correct interpretation of the corresponding Images. Using  simplifies and future-proofs imaging code. The  classes are written to be used in an / message callback similar to . In order to maintain invariance, the  classes offer read-only access to specific parameters and matrices. Setting a  can only be performed with full information using the  functions. Please see the  documentation. Please see the  documentation. CameraInfoCameraInfoCameraInfoimage_geometryimage_geometryImageCameraInfoCameraModelCameraModelfromCameraInfo()"
W414,https://wiki.ros.org/jsk_pcl_ros,Wiki,jsk_pcl_ros,"ROS nodelets for pointcloud perception.

Documentation is available . Use github issue to report  or .  "
W415,https://wiki.ros.org/peppereus,Wiki,peppereus,The pepper_bringup package
W416,https://wiki.ros.org/combined_robot_hw_tests,Wiki,combined_robot_hw_tests,The combined_robot_hw_tests package
W417,https://wiki.ros.org/jsk_baxter_desktop,Wiki,jsk_baxter_desktop,The jsk_baxter_desktop package
W418,https://wiki.ros.org/qt_create,Wiki,qt_create,"Provides templates and scripts for creating qt-ros packages
     (similar to roscreate-pkg).Currently we're installing a simple script,  to the global bin directory. In the future we may move this to a rosdistro independant python package. Refer to the  tutorials for an example on how to use it and details on the kind of package template it generates.  roscreate-pkg/usr/local/binROSQt Creatorqt_rosQt CreatorQtqt_rospkgQt CreatorROS pkgQt CreatorROSprojectQt CreatorROSQtQt CreatorCMakeLists.txtQt CreatorQtMakefilecmakerosmakecmakeQt CreatorMakefile%PKG_TOP%/resources/images.qrc%PKG_TOP%/resources/Qtimages.qrccatkin_create_qt_pkg> rosrun qt_create roscreate-qt-pkg my_package_foo> roscd qt_create
# The following will ask for your password (sudo)
> make install
# To remove
> make uninstall"
W419,https://wiki.ros.org/key_teleop,Wiki,key_teleop,"A text-based interface to send a robot movement commands 
 

key_vel"
W420,https://wiki.ros.org/apriltag_ros,Wiki,apriltag_ros,"A ROS wrapper of the AprilTag 3 visual fiducial detection
    algorithm. Provides full access to the core AprilTag 3 algorithm's
    customizations and makes the tag detection image and detected tags' poses
    available over ROS topics (including tf). The core AprilTag 3 algorithm is
    extended to allow the detection of tag bundles and a bundle calibration
    script is provided (bundle detection is more accurate than single tag
    detection). Continuous (camera image stream) and single image detector nodes
    are available.
 



 The behavior of the ROS wrapper is fully defined by the two configuration files  (which defines the tags and tag bundles to look for) and  (which configures the core AprilTag 2 algorithm itself). Then, the following topics are output: The  teach you how to operate the wrapper. The main idea is to fill out  with the standalone tags and tag bundles which you would like to detect (bundles potentially require a calibration process) and  with the wrapper and AprilTag 2 core parameters. Then, you simply run the continuous or single image detector. The tutorials walk you through how to do this. While this ROS wrapper is original code originating from the author's master thesis, the core AprilTag 2 algorithm in  is wholly the work of the  at The University of Michigan. If you use this package, please kindly cite: /camera/image_rect/camera/camera_info/camera/camera_info/KKconfig/tags.yamlconfig/settings.yaml/tftags.yamlpublish_tf: trueconfig/settings.yaml/tag_detections/tf/tag_detections_image/camera/image_rectpublish_tag_detections_image==truelaunch/continuous_detection.launchconfig/tags.yamlconfig/settings.yamlapriltags2/image_rectcamera_infoKtag_detectionstag_detections_imageimage_recttag_familystringtag36h11tag36h11tag36h10tag25h9tag25h7tag16h5tag_borderinttag_threadsinttag_decimatedoubletag_blurdoubletag_refine_edgesinttag_decimate==1.0tag_refine_decodeinttag_refine_poseinttag_refine_decodepublish_tfbool/tfcamera_framestringpublish_tag_detections_imagebool/tag_detections_imagetagcameraconfig/tags.yamltag_IDbundle_COUNTconfig/tags.yaml/tag_detections_imagecamera_framepublish_tag_detections_imagesingle_image_tag_detectionKcamera_framepublish_tag_detections_imagesingle_image_tag_detectionsingle_image_tag_detectionimage_load_pathstringimage_save_pathstringfxdoublefydoublecxdoublecydouble@mastersthesis{malyuta:2017mt,
  author = {Danylo Malyuta},
  title = {{Guidance, Navigation, Control and Mission Logic for Quadrotor Full-cycle Autonomy}},
  language = {english},
  type = {Master thesis},
  school = {Jet Propulsion Laboratory},
  address = {4800 Oak Grove Drive, Pasadena, CA 91109, USA},
  month = dec,
  year = {2017}
}
@inproceedings{Wang2016,
  author = {Wang, John and Olson, Edwin},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  doi = {10.1109/IROS.2016.7759617},
  isbn = {978-1-5090-3762-9},
  month = {oct},
  pages = {4193--4198},
  publisher = {IEEE},
  title = {{AprilTag 2: Efficient and robust fiducial detection}},
  year = {2016}
}"
W421,https://wiki.ros.org/turtlebot_stdr,Wiki,turtlebot_stdr,"Stdr version of turtlebot simulation. Convenient to test 2D-navigation related stuffs
]] 

 This package contains launchers, maps and world descriptions for the  simulation with . Refer to the  for help on how to run. "
W422,https://wiki.ros.org/effort_controllers,Wiki,effort_controllers,"effort_controllers
See the  page for more information. "
W423,https://wiki.ros.org/wu_ros_tools,Wiki,wu_ros_tools,A collection of tools for making a variety of generic ROS-related tasks easier.
W424,https://wiki.ros.org/xpp_hyq,Wiki,xpp_hyq,"HyQ-robot specific functions for visualization in the  XPP Motion Framework.
    
    These include inverse kinematics as well as urdf files for a one-legged,
    two-legged and four legged robot with 
    legs.
        
    The dynamic model can be found 
    .  
    
    See also .
  The Robot ""HyQ"" from the . (Picture credit to Agnese Abrusci) "
W425,https://wiki.ros.org/opencv_tests,Wiki,opencv_tests,"Tests the enumerants of the ROS Image message, and functionally tests the Python and C++ implementations of CvBridge.Package opencv_test tests the enumerants of the ROS Image message, and functionally tests the Python and C++ implementations of CvBridge. "
W426,https://wiki.ros.org/rqt_dep,Wiki,rqt_dep,"rqt_dep provides a GUI plugin for visualizing the ROS dependency graph. 


As of version 0.4.1, only the packages in  can be inquired on . ROS_PACKAGE_PATHrqt_dep"
W427,https://wiki.ros.org/turtlebot_stage,Wiki,turtlebot_stage,"Stage version of turtlebot simulation. Convenient to test 2D-navigation related stuffs

Tutorial link for now:  Install the turtlebot package as described in the turtlebot  and source the setup.bash to your needs. How to change things you can find in the . $ source ~/turtlebot/devel/setup.bash$ roslaunch turtlebot_stage turtlebot_in_stage.launch "
W428,https://wiki.ros.org/dwb_msgs,Wiki,dwb_msgs,Message/Service definitions specifically for the dwb_local_planner
W429,https://wiki.ros.org/rqt_action,Wiki,rqt_action,"rqt_action provides a feature to introspect all available ROS
  action (from actionlib) types. By utilizing rqt_msg, the output format is
  unified with it and rqt_srv. Note that the actions shown on this plugin
  is the ones that are stored on your machine, not on the ROS core your rqt
  instance connects to."
W430,https://wiki.ros.org/swri_nodelet,Wiki,swri_nodelet,"This package provides a simple script to write simple launch files
    that can easily switch between running nodelets together or as
    standalone nodes."
W431,https://wiki.ros.org/prbt_moveit_config,Wiki,prbt_moveit_config,An automatically generated package with all the configuration and launch files for using the prbt with the MoveIt! Motion Planning Framework
W432,https://wiki.ros.org/rqt_robot_steering,Wiki,rqt_robot_steering,"rqt_robot_steering provides a GUI plugin for steering a robot using Twist messages.
 This tool starts publishing  message as soon as it's launched. 
As noted,  publishes  as a name of  by default. This name may vary per robot/application; e.g.  also publishes  but as  (see . So, type that name into the topic field at the top of  GUI and it gets applied immediately. To verify, use also  (or run from commandline ) to see if the topics  are actually published. rqt_robot_steeringgeometry_msgs/Twist/cmd_velgeometry_msgs/Twistbase_controller/commandrqt_robot_steeringrostopic echobase_controller/command"
W433,https://wiki.ros.org/teleop_tools,Wiki,teleop_tools,A set of generic teleoperation tools for any robot.
W434,https://wiki.ros.org/yocs_msgs,Wiki,yocs_msgs,"Yujin's Open Control System messages, services and actions "
W435,https://wiki.ros.org/swri_rospy,Wiki,swri_rospy,"This package provides added functionaliy on top of rospy, including a
  single-threaded callback queue."
W436,https://wiki.ros.org/cv_bridge,Wiki,cv_bridge,"This contains CvBridge, which converts between ROS
    Image messages and OpenCV images. To learn how to interface OpenCV with ROS using CvBridge, please see the  . "
W437,https://wiki.ros.org/youbot_description,Wiki,youbot_description,Robot descriptions in form of URDF files and meshes
W438,https://wiki.ros.org/wireless_watcher,Wiki,wireless_watcher,A Python-based which publishes connection information about a linux wireless interface.
W439,https://wiki.ros.org/phidgets_api,Wiki,phidgets_api,"A C++ Wrapper for the Phidgets C API


 The  package contains a C++ API built on top of the  package. The package provides a base  class, from which all other Phidgets inherit. Currently, we have implemented classes for the following devices: * IMU sensor ()  * IR sensor ()  We first define the Imu class, which is inherited from the base  class: The  class has a , which is a special handle for the Phidget Spatial device. Different devices will have different handle types. The  and  functions implement sepcific calls to the IMU device using the C API. The data handler function receives spatial data events.  The  is a static callback function which forwards the data to the correct  class instance.  Finally, the virtual  function is the one which is called back when Spatial data arrives. In this example, the function just prints out a message. However, you can create a class which inherits from the  class and overwrites this behavior. Please submit your tickets through  (requires github account) or by emailing the maintainers. PhidgetPhidgetImuCPhidgetSpatialHandlezero()setDataRateSpatialDataHandlerImudataHandlerImu





















































"
W440,https://wiki.ros.org/zeroconf_avahi_suite,Wiki,zeroconf_avahi_suite,"Suite of packages supporing the avahi implementation of zeroconf for ros.


For more detailed notes, refer to the relevant . <d DOT stonier AT gmail DOT com>> sudo apt-get install ros-xxx-zeroconf-avahi-suite"
W441,https://wiki.ros.org/rosnode_rtc,Wiki,rosnode_rtc,"This package gives transparency between RTM and ROS.

     rtmros-data-bridge.py is a RT-Component for dataport/topic.
     This automatically convert ROS/topic into RTM/dataport.Documentation is available . "
W442,https://wiki.ros.org/assimp_devel,Wiki,assimp_devel,assimp library
W443,https://wiki.ros.org/teleop_twist_joy,Wiki,teleop_twist_joy,"Generic joystick teleop for twist robots.



The purpose of this package is to provide a generic facility for tele-operating Twist-based ROS robots with a standard joystick. Examples of such platforms include , , and . This node provides no rate limiting or autorepeat functionality. It is expected that you take advantage of the features built into  for this. The teleop translation functionality is embeddable, if you'd like to compile it into a larger ""base"" node for your robot. See the  class for details or  for an example. joycmd_vel~enable_buttonint~enable_turbo_buttonint~axis_linearint~scale_lineardouble~scale_linear_turbodouble~axis_angularint~scale_angulardouble"
W444,https://wiki.ros.org/joint_state_controller,Wiki,joint_state_controller,"Controller to publish joint state
See the  page for more information. "
W445,https://wiki.ros.org/turtlebot3_bringup,Wiki,turtlebot3_bringup,"roslaunch scripts for starting the TurtleBot3 




cmd_velmotor_powerresetsoundbattery_statecmd_vel_rc100diagnosticsimujoint_statesmagnetic_fieldodomsensor_statetfversion_info~baudint~portstringimuscansensor_stateversion_infodiagnosticsrpmsscan~frame_idstring~portstring"
W446,https://wiki.ros.org/moveit_ros_robot_interaction,Wiki,moveit_ros_robot_interaction,Components of MoveIt! that offer interaction via interactive markers
W447,https://wiki.ros.org/controller_manager,Wiki,controller_manager,"The controller manager.
 




  allows developers to switch controllers at run time, but it is not so convenient when you want to switch from a group of controllers to another for some special purposes. The  script makes this easy if such groups are defined in ROS parameter . It knows all controllers involved, and then controllers that need to be stopped and started when it switches from one group to another. Therefore, different groups can share some controllers. 



The  provides a -compatible loop to control a robot mechanism, which is represented by a  instance (see the  package).  The  provides the infrastructure to load, unload, start and stop controllers. When loading a controller, the  will use the controller name as the root for all controller specific parameters, most importantly,  which identifies which plugin to load. You can interact with the  from the command line, using the  script. To interact with a specific controller, use: To automatically load and start a set of controllers at once, and automatically stop and unload those same controllers at once, use the  tool: To automatically stop a set of controllers, and restart them later, you can use the  tool: The listed controllers will be , but not unloaded. Once spawner is shut down, the controllers will be restarted. An example of  parameter: To run the  script:: You could run  to start controllers from within a launch file. However, the controller would then stay up even after the launch file is taken down. Instead, use the tool to automatically load, start, stop and unload a controller from within a launch file. When you start , it will load and start the controller. When you stop  (when the launch file is taken down) it will stop and unload the controller. Your launch file would look something like this: The  is a rqt plugin that allows to graphically load, unload, start and stop controllers, as well as to display information about loaded controllers. controller_managerhardware_interface::RobotHWcontroller_managercontroller_managertypecontroller_managercontroller_managerloadunloadstartstopspawnkilllistlist-typesreload-librariesreload-libraries --restorespawnerunspawnercontroller_managercontroller_groupcontroller_groupscontroller_groupscontroller_grouplistcontroller_groupsspawn <group><group>switch <group><group>controller_managerspawner spawnerspawnercontroller_manager/load_controllercontroller_manager/unload_controllercontroller_manager/switch_controllerBEST_EFFORTSTRICTSTRICTBEST_EFFORTcontroller_manager/list_controllerscontroller_manager/list_controller_typescontroller_manager/reload_controller_libraries $ rosrun controller_manager controller_manager <command> <name1> <name2> ... $ rosrun controller_manager controller_manager <command>  $ rosrun controller_manager spawner [--stopped] <name1> <name2> ...  $ rosrun controller_manager unspawner <name1> <name2> ...    controller_groups:
      production:
        - prod_controller_1
        - prod_controller_2
      development:
        - devel_controller_1
        - devel_controller_2
        - shared_controller_3
      diagnostics:
        - diag_controller_1
        - diag_controller_2
        - shared_controller_3 $ rosrun controller_manager controller_group <command> <args> <launch>
   <node pkg=""controller_manager""
         type=""spawner""
         args=""controller_name1 controller_name2"" />
 </launch> <launch>
   <node pkg=""controller_manager""
         type=""spawner""
         args=""--stopped controller_name1 controller_name2"" />
 </launch>rosrun rqt_controller_manager rqt_controller_manager"
W448,https://wiki.ros.org/spacenav_node,Wiki,spacenav_node,"ROS interface to the 3Dconnexion SpaceNavigator 6DOF joystick.





This package should support any hardware that is supported by the upstream  package. spacenav_nodespacenav/offsetspacenav/rot_offsetspacenav/twistoffsetrot_offsetspacenav/joy$ sudo apt install spacenavd
$ sudo apt install ros-indigo-spacenav-node$ roslaunch spacenav_node classic.launch "
W449,https://wiki.ros.org/rosflight_msgs,Wiki,rosflight_msgs,"Message and service definitions for the ROSflight ROS stack
"
W450,https://wiki.ros.org/ffha,Wiki,ffha,ffha: PDDL Planner (http://ipc.informatik.uni-freiburg.de)
W451,https://wiki.ros.org/forward_command_controller,Wiki,forward_command_controller,"forward_command_controller
See the  page for more information. "
W452,https://wiki.ros.org/libmavconn,Wiki,libmavconn,"MAVLink communication library.
    This library provide unified connection handling classes
    and URL to connection object mapper.

    This library can be used in standalone programs.
It is  connection and communication library used in . "
W453,https://wiki.ros.org/rqt_multiplot,Wiki,rqt_multiplot,"rqt_multiplot provides a GUI plugin for visualizing numeric values in multiple 2D plots using the Qwt plotting backend.
 
 
 
  "
W454,https://wiki.ros.org/lgsvl_msgs,Wiki,lgsvl_msgs,The lgsvl_msgs package for ground truth data.
W455,https://wiki.ros.org/nmea_navsat_driver,Wiki,nmea_navsat_driver,"Package to parse NMEA strings and publish a very simple GPS message. Does not 
    require or use the GPSD deamon.






Use GitHub to . []
 This package provides a ROS interface for GPS devices that output compatible NMEA sentences. See the  for details on the raw format. Of the thousands of NMEA-compatible GPS devices, we are compiling a list of . This package is compatible with the  project as well as any other nodes that support  and/or .  This package replaces the  package present in Fuerte and Groovy. To get up and running quickly, you can use the following command to start outputting your GPS data onto ROS topics. This assumes your GPS is outputting GGA NMEA sentences, is connected to  and is communicating at 38400 baud. If you are using this package for the first time and encountering problems you should first check that the package installed correctly and in the right location. Then consult ,  and  to see if a solution has already been identified for your problem. If you are having trouble with nmea_serial_driver and connecting to a serial port, ensure that the user has permission to access the port by checking to see if the user is part of the ""dialout"" group. See  for more information.  /dev/ttyUSB0nmea_sentencefixveltime_referencetime_ref~time_ref_sourcestring~useRMCboolTrueFalsefixveltime_referencetime_ref~portstring~baudint~frame_idstringframe_idtf_prefix~time_ref_sourcestring~useRMCboolTrueFalsenmea_sentence~portstring~baudint~frame_idstringframe_idtf_prefix$ rosrun nmea_navsat_driver nmea_serial_driver _port:=/dev/ttyUSB0 _baud:=38400"
W456,https://wiki.ros.org/kobuki_driver,Wiki,kobuki_driver,"C++ driver library for Kobuki:
    Pure C++ driver library for Kobuki. This is for those who do not wish to use ROS on their systems.src/toolsversion_infosrc/toolsversion_infosrc/toolsversion_info$ rosrun kobuki_driver version_info
Version Info:
 * Hardware Version: 1.0.4
 * Firmware Version: 1.1.4
 * Software Version: 0.3.4
 * Unique Device ID: 736034612-892621875-1125147971$ rosrun kobuki_driver version_info
Version Info:
 * Hardware Version: 1.0.4
 * Firmware Version: 1.2.0
 * Software Version: 0.5.3
 * Unique Device ID: 736034612-892621875-1125147971$ rosrun kobuki_driver version_info
Version Info:
 * Hardware Version: 1.0.4
 * Firmware Version: 1.2.0
 * Software Version: 0.5.3
 * Unique Device ID: 736034612-892621875-1125147971"
W457,https://wiki.ros.org/rviz_plugin_tutorials,Wiki,rviz_plugin_tutorials,Tutorials showing how to write plugins for RViz.Please see the  page for your distribution. Follow the link and replace  with your preferred ROS distribution (i.e. ) in the URL. 
W458,https://wiki.ros.org/moveit_commander,Wiki,moveit_commander,Python interfaces to MoveIt
W459,https://wiki.ros.org/yocs_rapps,Wiki,yocs_rapps,Yujin open control system rapps for use with the app manager and rocon concert
W460,https://wiki.ros.org/pilz_robots,Wiki,pilz_robots,"The metapackage



 
 contains Moveit  plugins for Linear, Circular and Point-To-Point movements. You can plan industrial motion commands respecting the joint limits with trapezoidal velocity profiles.  is an easy to use API to execute standard industrial robot commands like Ptp, Lin, Circ and Sequence in a python script. 
 contains additional description and launch files to use the Manipulator PRBT combined with a gripper. 
 provide a launch file for your custom application package. If you want to use all configuration options, download this repository and use the files as template. 
Use GitHub to . []
  
We created a set of  that walk you through using the Pilz Manipulator Module PRBT, step by step. For example you can learn how to model your own machine layout and how to test if the manipulator can reach your machine. For package documentation please see the .  PlannerManager"
W461,https://wiki.ros.org/moveit_python,Wiki,moveit_python,A pure-python interaface to the MoveIt! ROS API.
W462,https://wiki.ros.org/mav_msgs,Wiki,mav_msgs,"Package containing messages for communicating with rotary wing MAVs
"
W463,https://wiki.ros.org/hrpsys_ros_bridge,Wiki,hrpsys_ros_bridge,"hrpsys_ros_bridge package provides basic functionalities to bind
  	, a 
  	-based controller, and ROS. 
    By using this package, you can write your ROS packages that communicate with your
    non-ROS robots that run on hrpsys.
  		
    For communicating with the robots that run on OpenRTM without hrpsys,
  	you can use 
  	package.



Other than API documentation being available , this package is missing document and your contribution is appreciated. Please contact through . In its downstream package, you might see a folder for conf files (e.g. ) where only template files with suffix  are stored. Once you build the package the concrete files are generated into the same folder. There are 3 types of conf files of which the distinction may not be very clear (): While in current design the package depends on  that's catkinized from  onward and not available in , some hacks allow the package not to separate  (regardless it's good or not, doing so is the decision as of March 2014). This requires another hack during release process using  as follows: .in_nosim_real_realrobotbranchesbloom$ bloom-release --rosdistro groovy --track groovy rtmros_commonbloompackage.xmlpr2-controllerspackage.xmlgit add$ git am --skipgit commitexit 0bloom$ bloom-release --rosdistro groovy --track groovy rtmros_common
:
>>> Resolve any conflicts and when you have resolved this problem run 'git am --resolved' and then exit the shell using 'exit 0'. <<<
    To abort use 'exit 1'
(bloom)emacs package.xml :  
<!-- <build_depend>pr2_controllers</build_depend> -->
:
<!-- <run_depend>pr2_controllers</run_depend> -->
:(bloom)git add package.xml
(bloom)git am --skip
Resolve operation not in progress, we are not resuming.
(bloom)git commit -m ""3rd trial commentout pr2 pkg"" -a
[release/groovy/hrpsys_ros_bridge 1c05bbc] 3rd trial commentout pr2 pkg
 1 file changed, 1 insertion(+), 1 deletion(-)
(bloom)git status
# On branch release/groovy/hrpsys_ros_bridge
# Your branch is ahead of 'origin/release/groovy/hrpsys_ros_bridge' by 8 commits.
#
nothing to commit (working directory clean)
(bloom)exit 0
exit
 [git-bloom-patch import]: User reports that conflicts have been resolved, continuing.
 [git-bloom-patch import]: Applied 2 patches
:
(bloom continues)"
W464,https://wiki.ros.org/moveit_kinematics,Wiki,moveit_kinematics,Package for all inverse kinematics solvers in MoveIt!
W465,https://wiki.ros.org/prbt_hardware_support,Wiki,prbt_hardware_support,Control hardware functions of the PRBT manipulator like RUN_PERMITTED for Stop1 functionality.
W466,https://wiki.ros.org/rtmros_common,Wiki,rtmros_common,"A package suite that provides all the capabilities for
    the ROS users to connect to the robots that run on
    
    or RTM-based controllers.



: TBD 
: Wait and re-trigger , as recommended (). 
: Wait and re-trigger , or improve test code 
: This has been fixed in 1.0.21, please report error to  
For discussions, updates, announcements, please subscribe to the . Here are some common errors and workarounds (if found any) on either of your local machine /  (buildfarm at ROS infra) / . This is failure in the test, in the test, happens in for example . hironx_ros_bridge/test_LArm and hironx_ros_bridge/test_RArm report errors () When  fails no matter what value you use in launch files, look at Environment Variables , which might be most likely set as  ( default). In that case re-define it as you want: jenkinstravistravistravisrostestRTCTREE_NAMESERVERS15005:
Executing command 'make run_tests'
Scanning dependencies of target clean_test_results
Built target clean_test_results
Built target tests
Scanning dependencies of target _run_tests_hironx_ros_bridge_rostest_test_test-hironx-ros-bridge.test
IDL:omg.org/CORBA/TRANSIENT:1.0
IDL:omg.org/CORBA/TRANSIENT:1.0
:
IDL:omg.org/CORBA/TRANSIENT:1.0
[ERROR] Connection Failed with the Nameserver (hostname=localhost port=2809).
Make sure the hostname is correct and the Nameserver is running.
CORBA.TRANSIENT(omniORB.TRANSIENT_ConnectFailed, CORBA.COMPLETED_NO)
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
IDL:omg.org/CORBA/TRANSIENT:1.0
[sensor_ros_bridge_connect.py]  start
configuration ORB with  localhost : 2809
[ERROR] Connection Failed with the Nameserver (hostname=localhost port=2809).
Make sure the hostname is correct and the Nameserver is running.
CORBA.TRANSIENT(omniORB.TRANSIENT_ConnectFailed, CORBA.COMPLETED_NO)
IDL:omg.org/CORBA/TRANSIENT:1.0
[rtmlaunch] starting...  /opt/ros/hydro/share/hrpsys_ros_bridge/launch/hrpsys_ros_bridge.launch
[rtmlaunch] RTCTREE_NAMESERVERS localhost:2809 localhost:2809
[rtmlaunch] SIMULATOR_NAME HiroNX(Robot)0
[rtmlaunch] check connection/activation
[31m[rtmlaunch] [ERROR] Could not Connect ( /localhost:2809/HiroNX(Robot)0.rtc:q , /localhost:2809/HrpsysSeqStateROSBridge0.rtc:rsangle ):  Invalid CORBA naming service: localhost:2809 [0m
[31m[rtmlaunch] Could not Activate ( localhost:2809/HrpsysSeqStateROSBridge0.rtc ) :  Invalid CORBA naming service: localhost:2809 [0m
IDL:omg.org/CORBA/TRANSIENT:1.0[0m[ 79%] Building CXX object rtc/VirtualCamera/CMakeFiles/VirtualCameraComp.dir/GLscene.o
[0m[ 79%] Building CXX object rtc/VirtualCamera/CMakeFiles/VirtualCamera.dir/GLscene.o
[0mg++: internal compiler error: Killed (program cc1plus)
[0mPlease submit a full bug report,
[0mwith preprocessed source if appropriate.
[0mSee <file:///usr/share/doc/gcc-4.6/README.Bugs> for instructions.
[0mmake[3]: *** [rtc/VirtualCamera/CMakeFiles/VirtualCameraComp.dir/VirtualCamera.o] Error 4
[0mmake[3]: *** Waiting for unfinished jobs....
[0mg++: internal compiler error: Killed (program cc1plus)
[0mPlease submit a full bug report,
[0mwith preprocessed source if appropriate.
[0mSee <file:///usr/share/doc/gcc-4.6/README.Bugs> for instructions.
[0mmake[3]: *** [rtc/VirtualCamera/CMakeFiles/VirtualCamera.dir/Virtself.check_log_data(data, 6, 9, -135, -100.0)[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAnglesOfGroup_Override_Acceleration][FAILURE]
File ""/usr/lib/python2.7/unittest/case.py"", line 327, in run
    testMethod()
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 494, in test_rarm_setJointAnglesOfGroup_Override_Acceleration
    self.check_log_data(data, 6, 9, -135, -100.0)
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 132, in check_log_data
    self.assertTrue(abs(_tm_data - tm_data) < tm_data*_tm_thre)
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 358, in assertTrue
    assert(a)
--------------------------------------------------------------------------------

[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAnglesOfGroup_minus][passed]
[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_Clear][passed]
[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_NoWait][passed]
[hironx_ros_bridge.rosunit-test_hironx/test_rarm_setJointAngles_Wait][passed]
[hironx_ros_bridge.rosunit-test_hironx_ik/test_ik_left][passed]
[hironx_ros_bridge.rosunit-test_hironx_ik/test_ik_right][passed]
[hironx_ros_bridge.rosunit-test_hironx_ik/test_set_target_pose][passed]

SUMMARY
[1;31m * RESULT: FAIL[0m
 * TESTS: 14
 * ERRORS: 0
[1;31m * FAILURES: 1[0m</testsuite>
=== /home/travis/.ros/test_results/hironx_ros_bridge/rosunit-test_hironx.xml ===
<?xml version=""1.0"" encoding=""utf-8""?>
<testsuite errors=""0"" failures=""1"" name=""unittest.suite.TestSuite"" tests=""11"" time=""152.451"">
  <testcase classname=""__main__.TestHiro"" name=""testSetTargetPoseBothArm"" time=""8.2143""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_fullbody_setJointAngles_Clear"" time=""34.9962""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_fullbody_setJointAngles_NoWait"" time=""27.1437""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_fullbody_setJointAngles_Wait"" time=""5.4608""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_fullbody_setJointAngles_minus"" time=""5.1352""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_goInitial"" time=""2.4177""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_rarm_setJointAnglesOfGroup_Override_Acceleration"" time=""5.8956"">
    <failure type=""AssertionError"">
  File ""/usr/lib/python2.7/unittest/case.py"", line 327, in run
    testMethod()
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 494, in test_rarm_setJointAnglesOfGroup_Override_Acceleration
    self.check_log_data(data, 6, 9, -135, -100.0)
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 132, in check_log_data
    self.assertTrue(abs(_tm_data - tm_data) &lt; tm_data*_tm_thre)
  File ""/home/travis/ros/ws_rtmros_hironx/install/share/hironx_ros_bridge/test/test_hironx.py"", line 358, in assertTrue
    assert(a)
    </failure>
  </testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_rarm_setJointAnglesOfGroup_minus"" time=""2.6168""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_rarm_setJointAngles_Clear"" time=""28.5729""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_rarm_setJointAngles_NoWait"" time=""22.7938""></testcase>
  <testcase classname=""__main__.TestHiro"" name=""test_rarm_setJointAngles_Wait"" time=""6.7109""></testcase>
  <system-out><![CDATA[configuration ORB with  localhost : 2809[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_LArm][FAILURE]-----------
Arrays are not almost equal to 3 decimals

(mismatch 22.2222222222%)
 x: array([[  2.49888699e-03,   1.23574328e-03,  -9.99996114e-01],
       [  2.31512602e-04,   9.99999209e-01,   1.23632563e-03],
       [  9.99996851e-01,  -2.34601140e-04,   2.49859893e-03]])
 y: array([[ 0,  0, -1],
       [ 0,  1,  0],
       [ 1,  0,  0]])
  File ""/usr/lib/python2.7/unittest/case.py"", line 327, in run
    testMethod()
  File ""/opt/ros/hydro/share/hironx_ros_bridge/test/test_hironx_ros_bridge.py"", line 185, in test_LArm
    [ 1, 0, 0]]), decimal=3)
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 800, in assert_array_almost_equal
    header=('Arrays are not almost equal to %d decimals' % decimal))
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 636, in assert_array_compare
    raise AssertionError(msg)
--------------------------------------------------------------------------------

[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_LArmIK][passed]
[hironx_ros_bridge.rosunit-test_hironx_ros_bridge/test_RArm][FAILURE]-----------
Arrays are not almost equal to 3 decimals

(mismatch 22.2222222222%)
 x: array([[  2.49888699e-03,  -1.23574328e-03,  -9.99996114e-01],
       [ -2.31512602e-04,   9.99999209e-01,  -1.23632563e-03],
       [  9.99996851e-01,   2.34601140e-04,   2.49859893e-03]])
 y: array([[ 0,  0, -1],
       [ 0,  1,  0],
       [ 1,  0,  0]])
  File ""/usr/lib/python2.7/unittest/case.py"", line 327, in run
    testMethod()
  File ""/opt/ros/hydro/share/hironx_ros_bridge/test/test_hironx_ros_bridge.py"", line 202, in test_RArm
    [ 1, 0, 0]]), decimal=3)
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 800, in assert_array_almost_equal
    header=('Arrays are not almost equal to %d decimals' % decimal))
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 636, in assert_array_compare
    raise AssertionError(msg)
--------------------------------------------------------------------------------$ unset RTCTREE_NAMESERVERS
$ export RTCTREE_NAMESERVERS=localhost:2809"
W467,https://wiki.ros.org/qt_tutorials,Wiki,qt_tutorials,"Example qt programs, generated from code similar to that used by the 
     roscreate-qt-pkg script and styled on roscpp_tutorials.

Simple package to test/demo the  tools. Demo features: Compile in place with the usual  to generate native linux binaries or  use rosbuild2 to build windows binaries with the mingw cross compiler (refer to  the  and   tutorials). make"
W468,https://wiki.ros.org/pcl_conversions,Wiki,pcl_conversions,Provides conversions from PCL data types and ROS message types
W469,https://wiki.ros.org/novatel_span_driver,Wiki,novatel_span_driver,"Python driver for NovAtel SPAN devices. 
  







This is a driver for , especially the . This driver publishes GNSS data as a , and inertial navigation system (INS) data as . You can plot this using , as well as monitoring your overall system using : This driver assumes that your unit has been configured with the ethernet port enabled for TCP. There are various ways this can be set up, but the easiest is to connect to your receiver with  (), using the serial or USB interface. Then, using the device's console: From the  menu, select , which will take you through the position and orientation of the IMU relative to your vehicle's base_link, and the relative position of the GNSS antenna(s). Note that if you only need the console and won't need to run the SPAN setup wizard, you may bypass Novatel Connect and just use an ordinary serial console at 9600 baud. If you are configuring multiple units, you can run the SPAN wizard only once, and enter the supplied SPAN setup commands into the other devices using the console or the  rosparam. You should see topics come up for , , , , etc. These will publish data once the system has acquired an initial GNSS fix. The source repository includes example captures from a  mounted on a . To create your own captures, use : The following documents from NovAtel are helpful in understanding what this driver is about and how it works: If you'd like more information about  or would like a quote for Husky equipped with SPAN, please use . configuration/commandnavsat/fixnavsat/odomimu/data/diagnosticsodomtcpdumpwificonfig state disabled
ethconfig etha auto auto auto auto
icomconfig icom1 tcp :3001
ipconfig etha static [address] 255.255.255.0 [gateway]
saveconfig
saveethernetdata ethalog wificonfig once
log ethconfig once
log icomconfig once
log ipconfig onceroslaunch novatel_span_driver example.launch ip:=[address] --screensudo tcpdump -i br0 port 3001 -w capture.pcap
gzip capture.pcap"
W470,https://wiki.ros.org/turtlebot3_teleop,Wiki,turtlebot3_teleop,"Provides teleoperation using keyboard for TurtleBot3. 


cmd_vel"
W471,https://wiki.ros.org/urdf,Wiki,urdf,"This package contains a C++ parser for the Unified Robot Description
    Format (URDF), which is an XML format for representing a robot model.
    The code API of the parser has been through our review process and will remain
    backwards compatible in future releases.

 A number of different packages and components make up urdf. The following diagram attempts to explain the relationship between these components:  




  
 In Indigo, the  tool has moved to the  package. You may need to run  if you can't use     
This package contains a number of  for robot models, sensors, scenes, etc. Each XML specification has a corresponding parser in one or more languages. There is large set of  on how to build up your own robot models using the URDF specification. Check out the  page.  We also developed a macro language called  to make it easier to maintain the robot description files, increase their readability, and to avoid duplication in the robot description files. See  for a list of robots described by a URDF model.  A command line tool check_urdf attempts to parse a file as a URDF description, and either prints a description of the resulting kinematic chain, or an error message. Note: You may need to run . sudo apt-get install liburdfdom-toolsurdf_to_graphizliburdfdom-toolssudo apt-get install liburdfdom-toolsurdf_to_graphizrosrun xacro xacro.py `rospack find pr2_description`/robots/pr2.urdf.xacro -o /tmp/pr2.urdfcheck_urdf pr2.urdfrosrun urdfdom check_urdf /tmp/pr2.urdfrobot name is: pr2
---------- Successfully Parsed XML ---------------
root Link: base_footprint has 1 child(ren)
    child(1):  base_link
        child(1):  base_laser_link
        child(2):  bl_caster_rotation_link
            child(1):  bl_caster_l_wheel_link
            child(2):  bl_caster_r_wheel_link
        child(3):  br_caster_rotation_link
            child(1):  br_caster_l_wheel_link
            child(2):  br_caster_r_wheel_link
        child(4):  fl_caster_rotation_link
            child(1):  fl_caster_l_wheel_link
            child(2):  fl_caster_r_wheel_link
        child(5):  fr_caster_rotation_link
            child(1):  fr_caster_l_wheel_link
            child(2):  fr_caster_r_wheel_link
        child(6):  torso_lift_link
            child(1):  head_pan_link
                child(1):  head_tilt_link
                    child(1):  head_plate_frame
                        child(1):  sensor_mount_link
                            child(1):  double_stereo_link
                                child(1):  narrow_stereo_link
 ...urdf_to_graphiz pr2.urdfurdf_to_graphiz pr2.urdf"
W472,https://wiki.ros.org/joy,Wiki,joy,"ROS driver for a generic Linux joystick.
    The joy package contains joy_node, a node that interfaces a
    generic Linux joystick to ROS. This node publishes a ""Joy""
    message, which contains the current state of each one of the
    joystick's buttons and axes.

 







For an example of using  to control a teleoperation node with a joystick, see the . In some cases, multiple joysticks may control a single robot. For example, a user may use the default joystick to drive a robot, but a second user may wish to use a different kind. Since the button mappings on each joystick may be different, it will be necessary to remap buttons on one joystick so they can match. See the   package for details. Table of index number of : Table of index number of : Table of index number of : Table of index number of : Table of index number of : Table of index number of : Table of index number of : joy~devstr~deadzonedouble~autorepeat_ratedouble~coalesce_intervaldouble/joy.buttons/joy.buttons/joy.axes/joy.buttons/joy.axes/joy.buttons/joy.axes"
W473,https://wiki.ros.org/mrpt_ekf_slam_2d,Wiki,mrpt_ekf_slam_2d,"This package is a wrapper for the implementation of EKF-based SLAM with range-bearing sensors, odometry, and a 2D (+heading) robot pose, and 2D landmarks.





 The ROS node mrpt_ekf_slam_2d is a wrapper for the C++ class, part of MRPT. Thus, check out the documentation of that class for further details. For the convention on coordinate frames see . In order to use mrpt_ekf_slam_2d package it is necessary to install the last  build and the (see also the ) . mrpt_ekf_slam_2dtflandmarkstate_vizdata_association_viz~global_frame_idstring""map""~base_frame_idstring""base_link""~odom_frame_idstring""odom""~sensor_sourcestring""scan""""scan""""beacon""~ini_filenamestring~rawlog_filenamestring~rawlog_play_delayfloat~ellipse_scalefloat<the frame attached to incoming scans>base_linktfbase_linkodommapodomroslaunch mrpt_ekf_slam_2d ekf_slam_2d.launchroslaunch mrpt_ekf_slam_2d ekf_slam_2d_rawlog.launch"
W474,https://wiki.ros.org/webots_ros,Wiki,webots_ros,"The ROS package containing examples for interfacing ROS with the standard ROS controller of Webots








Use GitHub to . []
 
webots_ros is a package that provides the necessary interfaces to simulate a robot in the  open-source 3D rigid body simulator for robots. It integrates with ROS using ROS messages and services. Webots is a prerequisite to use the webots_ros package. It can be downloaded from the . The installation is straightforward, but if need the installation instructions can be found . The following instructions assume that a  is already available: Refer to the  for more information on building catkin workspaces. See the  page for an overview of the available tutorials. For questions about this package or Webots in general, get in touch with the developers on . sudo apt-get install ros-$ROS_DISTRO-webots-ros















"
W475,https://wiki.ros.org/trajectory_tracker,Wiki,trajectory_tracker,Path following control package for wheeled mobile robot
W476,https://wiki.ros.org/moveit_experimental,Wiki,moveit_experimental,Experimental packages for moveit.See  for the detail. 
W477,https://wiki.ros.org/youbot_driver_ros_interface,Wiki,youbot_driver_ros_interface,ROS wrapper for the youBot driver
W478,https://wiki.ros.org/move_base_flex,Wiki,move_base_flex,"Move Base Flex (MBF) is a backwards-compatible replacement for move_base. MBF can use existing plugins for move_base, and provides an enhanced version of the planner, controller and recovery plugin ROS interfaces. It exposes action servers for planning, controlling and recovering, providing detailed information of the current state and the plugin’s feedback. An external executive logic can use MBF and its actions to perform smart and flexible navigation strategies. Furthermore, MBF enables the use of other map representations, e.g. meshes or grid_map
       
       This package is a meta package and refers to the Move Base Flex stack packages.The abstract core of MBF – without any binding to a map representation – is represented by the  and the . For navigation on costmaps see  and .


 













Use GitHub to . []
 Move Base Flex (MBF) is a backwards-compatible replacement for move_base. MBF can use existing plugins for move_base, and provides an enhanced version of the same ROS interface. It exposes action servers for planning, controlling and recovering, providing detailed information of the current state and the plugin's feedback. An external executive logic can use MBF and its actions to perform smart and flexible navigation strategies. For example,  has successfully deployed MBF at customer facilities to control TORU robots in highly dynamical environments. Furthermore, MBF enables the use of other map representations, e.g. meshes. The core features are: We have created Move Base Flex for a larger target group besides the standard developers and users of move_base and 2D navigation based on costmaps, as well as addressed move_base's limitations. Since robot navigation can be separated into planning and controlling in many cases, even for outdoor scenarios without the benefits of flat terrain, we designed MBF based on abstract planner-, controller- and recovery behavior-execution classes. To accomplish this goal, we created abstract base classes for the nav core ,  and  plugin interfaces, extending the API to provide a richer and more expressive interface without breaking the current move_base plugin API. The new abstract interfaces allow plugins to return valuable information in each execution cycle, e.g. why a valid plan or a velocity command could not be computed. This information is then passed to the external executive logic through MBF planning, navigation or recovering actions’ feedback and result. The planner, controller and recovery behavior execution is implemented in the abstract execution classes without binding the software implementation to 2D costmaps. In our framework,  is just a particular implementation of a navigation system: its execution classes implement the abstract ones, bind the system to the costmaps. Thereby, the system can easily be used for other approaches, e.g. navigation on meshes or 3D occupancy grid maps. However, we provide a  class without a binding to costmaps. Move Base Flex provides four actions which can be used by external executives to perform various navigation tasks and embed these into high-level applications. In the following the four actions get_path, exe_path, recovery and move_base are described in detail. The action definition files are stores here in the  package. 
See  See  See  
See  See  for details. See  for details. See  for details. See  for details. See  for details. See . @inproceedings{puetz18mbf,
  author = {Sebastian Pütz and Jorge Santos Simón and Joachim Hertzberg},
  title = {{Move Base Flex}: A Highly Flexible Navigation Framework for Mobile Robots},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 2018,
  month = {October},
  url = {https://github.com/magazino/move_base_flex},
  note = {Software available at \url{https://github.com/magazino/move_base_flex}}
}"
W479,https://wiki.ros.org/swri_transform_util,Wiki,swri_transform_util,"The swri_transform_util package contains utility functions and classes for
     transforming between coordinate frames."
W480,https://wiki.ros.org/four_wheel_steering_controller,Wiki,four_wheel_steering_controller,Controller for a four wheel steering mobile base.
W481,https://wiki.ros.org/pr2_motor_diagnostic_tool,Wiki,pr2_motor_diagnostic_tool,pr2_motor_diagnostic_tool on Willow Garage blog. 
W482,https://wiki.ros.org/moveit_ros_move_group,Wiki,moveit_ros_move_group,The move_group node for MoveIt
W483,https://wiki.ros.org/rviz_visual_tools,Wiki,rviz_visual_tools,"Utility functions for displaying and debugging data in Rviz via published markers
See  for full documentation. "
W484,https://wiki.ros.org/pointcloud_to_laserscan,Wiki,pointcloud_to_laserscan,"Converts a 3D Point Cloud into a 2D laser scan. This is useful for making devices like the Kinect appear like a laser scanner for 2D-based algorithms (e.g. laser-based SLAM).


If you're trying to create a virtual laserscan from your RGBD device, and your sensor is forward-facing, you'll find  will be much more straightforward and efficient since it operates on image data instead of bulky pointclouds. However, if your sensor is angled, or you have some other esoteric use case, you may find this node to be very helpful! Please check the  for common problems, or open an  if still unsolved. Same API as node, available as . pointcloud_to_laserscan_nodecloud_inscan~min_heightdouble~max_heightdouble~angle_mindouble~angle_maxdouble~angle_incrementdouble~scan_timedouble~range_mindouble~range_maxdouble~target_framestr~concurrency_levelint~use_infbooleanrange_max + 1+infinf_is_validpointcloud_to_laserscan/pointcloud_to_laserscan_nodelet"
W485,https://wiki.ros.org/xpp_msgs,Wiki,xpp_msgs,"ROS messages used in the XPP framework.
  
Each of the messages has a corresponding C++ class and conversion from/to it defined in . "
W486,https://wiki.ros.org/fanuc_post_processor,Wiki,fanuc_post_processor,"Fanuc post-processor
Documentation is here:  "
W487,https://wiki.ros.org/yujin_ocs,Wiki,yujin_ocs,Yujin Robot's open-source control software 
W488,https://wiki.ros.org/moveit_ros,Wiki,moveit_ros,Components of MoveIt! that use ROS
W489,https://wiki.ros.org/ypspur,Wiki,ypspur,YP-Spur is a mobile robot motion control software with coordinate frame based commands.
W490,https://wiki.ros.org/swri_serial_util,Wiki,swri_serial_util,swri_serial_util
W491,https://wiki.ros.org/jsk_interactive,Wiki,jsk_interactive,jsk_interactive
W492,https://wiki.ros.org/wiimote,Wiki,wiimote,"The wiimote package allows ROS nodes to communicate with a Nintendo Wiimote
    and its related peripherals, including the Nunchuk, Motion Plus, and
    (experimentally) the Classic. The package implements a ROS node that uses
    Bluetooth to communicate with the Wiimote device, obtaining accelerometer
    and gyro data, the state of LEDs, the IR camera, rumble (vibrator),
    buttons, joystick, and battery state. The node additionally enables ROS
    nodes to control the Wiimote's LEDs and vibration for feedback to the human
    Wiimote operator. LEDs and vibration may be switched on and off, or made to
    operate according to a timed pattern. 

 The cwiid library currently only recognizes Wiimotes which report the name as ""Nintendo RVL-CNT-01""; the latest Wiimotes will not be discovered. See . 


 
 The  array shows which buttons are currently depressed on the Wiimtoe device. The position mapping is as follows: This package should be considered as  except for support of the Classic controller, which requires additional testing. Check out the wiimote package, and  to ready the package for operation. Plug the Bluetooth dongle into your machine's USB port. The  message communicates all data that is available from your Wiimote device. Samples are taken and broadcast at 100Hz. Here are comments on some of the fields: The message header's time  is set to reflect the time when the respective message's sample was taken from the Wiimote device. The  shows the Motion+ gyroscope reading. These values are valid only if the Motion+ attachment is plugged into the Wiimote. Else they are held at constant zero, and matrix entry [0,0] in message field angular_velocity_covariance is set to -1. The  are four sets of x/y/[z], and size measures, for the four infrared light sources that the Wiimote device can track. When no lights are detected, the respective values are set to -1. The z axis is always -1, as it is not measured. The  array are four intensity measures of the lights that the camera observes. The meaning of these measures are unclear to the author. The  entry is the battery charge reading. The unit of this number is unclear. Field  returns the remaining charge as a percentage of full charge. The  is the time of the most recent device calibration. The  field is currently not used. cwiidrosmakewiimote_node.pyset_feedbackjoyimu/datawiimote/statewiimote/nunchukwiimote/classicimu/is_calibratedimu/calibrateStatestampangular_velocity_zeroedangular_velocity_rawbuttonsir_trackingir_sizesraw_batterypercent_batteryzeroing_timeerrorsPosition   Button Name
0         1
1         2
2         A
3         B (toggle button on back of device)
4         Plus
5         Minus
6         Rocker Left
7         Rocker Right
8         Rocker Up
9         Rocker Down
10        HOME"
W493,https://wiki.ros.org/python_qt_binding,Wiki,python_qt_binding,"This stack provides Python bindings for Qt.
    There are two providers: pyside and pyqt.  PySide is released under
    the LGPL.  PyQt is released under the GPL.

    Both the bindings and tools to build bindings are included from each
    available provider.  For PySide, it is called ""Shiboken"".  For PyQt,
    this is called ""SIP"".

    Also provided is adapter code to make the user's Python code
    independent of which binding provider was actually used which makes
    it very easy to switch between these.

This  pkg is planned to become standalone (= separated from ROS). See . It is already available via . python_qt_bindingpython_qt_binding"
W494,https://wiki.ros.org/teb_local_planner,Wiki,teb_local_planner,"The teb_local_planner package implements a plugin
    to the base_local_planner of the 2D navigation stack.
    The underlying method called Timed Elastic Band locally optimizes
    the robot's trajectory with respect to trajectory execution time,
    separation from obstacles and compliance with kinodynamic constraints at runtime.
 Use GitHub to . []
 






 (, default: 0.5)  (, default: 0.0)  (, default: ""point"") 
 (, default: 0.2) 
 (, default: 0.3) 
 (, default: 0.5)  (, default: """") 
 (, default: 5) 
 (, default: true) 
 (, default: ""odom"") 
This package implements an online optimal local trajectory planner for navigation and control of mobile robots as a plugin for the ROS  package. The initial trajectory generated by a global planner is optimized during runtime w.r.t. minimizing the trajectory execution time (time-optimal objective), separation from obstacles and compliance with kinodynamic constraints such as satisfying maximum velocities and accelerations. Get started by completing the tutorials in the  section. Features introduced in  are presented in the following video (supporting car-like robots and costmap conversion). The teb_local_planner package allows the user to set  in order to customize the behavior. These parameters are grouped into several categories: robot configuration, goal tolerance, trajectory configuration, obstacles, optimization, planning in distinctive topologies and miscellaneous parameters. Some of them are chosen to be compliant with the . Many (but not all) parameters can be modified at runtime using . The following parameters are relevant for the footprint model used for optimization (see ).  The following parameters are relevant only if  plugins are desired (see tutorial): ~<name>/global_plan~<name>/local_plan~<name>/teb_poses~<name>/teb_markers~<name>/teb_feedback~<name>/publish_feedback~<name>/odom~<name>/odom_topic~<name>/obstacles~<name>/via_points~<name>/global_plan_viapoint_sep~<name>/acc_lim_xdouble~<name>/acc_lim_thetadouble~<name>/max_vel_xdouble~<name>/max_vel_x_backwardsdoubleweight_kinematics_forward_drive~<name>/max_vel_thetadouble~<name>/min_turning_radiusdouble~<name>/wheelbasedouble~<name>/cmd_angle_instead_rotveltrue~<name>/cmd_angle_instead_rotvelbool~<name>/weight_kinematics_nh~<name>/max_vel_ydouble~<name>/acc_lim_ydouble~<name>/footprint_model/typestring~<name>/footprint_model/radiusdouble~<name>/footprint_model/line_startdouble[2]~<name>/footprint_model/line_enddouble[2]~<name>/footprint_model/front_offsetdouble~<name>/footprint_model/front_radiusdouble~<name>/footprint_model/rear_offsetdouble~<name>/footprint_model/rear_radiusdouble~<name>/footprint_model/verticesdouble[]~<name>/is_footprint_dynamicbool~<name>/xy_goal_tolerancedouble~<name>/yaw_goal_tolerancedouble~<name>/free_goal_velbool~<name>/dt_refdoubledt_ref~<name>/dt_hysteresisdoubledt_ref~<name>/min_samplesint~<name>/global_plan_overwrite_orientationbool~<name>/global_plan_viapoint_sepdoubleweight_viapoint~<name>/max_global_plan_lookahead_distdouble~<name>/force_reinit_new_goal_distdouble~<name>/feasibility_check_no_posesint~<name>/publish_feedbackbool~<name>/shrink_horizon_backupboolshrink_horizon_min_duration~<name>/allow_init_with_backwards_motionbool~<name>/exact_arc_lengthbool~<name>/shrink_horizon_min_durationdoubleshrink_horizon_backup~<name>/min_obstacle_distdouble~<name>/include_costmap_obstaclesbool~<name>/costmap_obstacles_behind_robot_distdouble~<name>/obstacle_poses_affectedintlegacy_obstacle_association~<name>/inflation_distdoublemin_obstacle_distweight_inflation~<name>/include_dynamic_obstaclesbool~/obstacles~<name>/legacy_obstacle_associationbooltrue~<name>/obstacle_association_force_inclusion_factordoublemin_obstacle_distenforce the consideration obstacles within a radius of 2.0*legacy_obstacle_associationfalse~<name>/obstacle_association_cutoff_factordoubleobstacle_association_force_inclusion_factormin_obstacle_distobstacle_association_force_inclusion_factorlegacy_obstacle_associationfalse~<name>/costmap_converter_pluginstring~<name>/costmap_converter_spin_threadbool~<name>/costmap_converter_ratedouble~<name>/no_inner_iterationsintno_outer_iterations~<name>/no_outer_iterationsintdt_refno_inner_iterations~<name>/penalty_epsilondouble~<name>/weight_max_vel_xdouble~<name>/weight_max_vel_thetadouble~<name>/weight_acc_lim_xdouble~<name>/weight_acc_lim_thetadouble~<name>/weight_kinematics_nhdouble~<name>/weight_kinematics_forward_drivedouble~<name>/weight_kinematics_turning_radiusdouble~<name>/weight_optimaltimedouble~<name>/weight_obstacledouble~<name>/weight_viapointdouble~<name>/weight_inflationdouble~<name>/weight_adapt_factordoubleweight_obstacle~<name>/enable_homotopy_class_planningbool~<name>/enable_multithreadingbool~<name>/max_number_classesint~<name>/selection_cost_hysteresisdouble~<name>/selection_obst_cost_scaledouble~<name>/selection_viapoint_cost_scaledouble~<name>/selection_alternative_time_costbool~<name>/roadmap_graph_no_samplesint~<name>/roadmap_graph_area_widthdouble~<name>/h_signature_prescalerdouble~<name>/h_signature_thresholddouble~<name>/obstacle_heading_thresholddouble~<name>/visualize_hc_graphbool~<name>/viapoints_all_candidatesbool~<name>/switching_blocking_perioddouble~<name>/odom_topicstring~<name>/map_framestring"
W495,https://wiki.ros.org/urdfdom,Wiki,urdfdom,A library to access URDFs using the DOM model.This is now an upstream package. Source can be found here:  
W496,https://wiki.ros.org/pr2eus,Wiki,pr2eus,pr2eus
W497,https://wiki.ros.org/stomp_moveit,Wiki,stomp_moveit,This package wraps the STOMP planner functionality in stomp_core so that it can be used within the MoveIt Motion Planning Framework
W498,https://wiki.ros.org/cl_tf,Wiki,cl_tf,Client implementation to use TF from Common LispImplementation of  for  nodes. 
W499,https://wiki.ros.org/rqt_py_common,Wiki,rqt_py_common,"rqt_py_common provides common functionality for rqt plugins written in Python.
    Despite no plugin is provided, this package is part of the rqt_common_plugins
    repository to keep refactoring generic functionality from these common plugins
    into this package as easy as possible.

    Functionality included in this package should cover generic ROS concepts and
    should not introduce any special dependencies beside ""ros_base""."
W500,https://wiki.ros.org/rosbridge_suite,Wiki,rosbridge_suite,"Rosbridge provides a JSON API to ROS functionality for non-ROS programs.
    There are a variety of front ends that interface with rosbridge, including
    a WebSocket server for web browsers to interact with.

    Rosbridge_suite is a meta-package containing rosbridge, various front end
    packages for rosbridge like a WebSocket package, and helper packages.








The  is a specification for sending JSON based commands to ROS (and in theory, any other robot middleware). An example of the protocol for subscribing to a topic: The rosbridge_suite package is a collection of packages that implement the rosbridge protocol and provides a  transport layer. Source code is available at . Please file issues and pull requests there. Rosbridge is a community project and involvement is encouraged! In addition to the  repository, check out the  and . { ""op"": ""subscribe"",
  ""topic"": ""/cmd_vel"",
  ""type"": ""geometry_msgs/Twist""
}sudo apt-get install ros-<rosdistro>-rosbridge-server"
W501,https://wiki.ros.org/rosflight_utils,Wiki,rosflight_utils,"Supporting utilities for ROSflight packages
"
W502,https://wiki.ros.org/summit_xl_sim,Wiki,summit_xl_sim,"The summit_xl_sim metapackage
 





This package contains the different controllers and launch files for the  simulation.  This package contains the launch and configuration files to spawn the joint controllers with the ROS controller_manager. It allows to launch the joint controllers for the Summit XL (4 axes skid steering + 2 axes ptz), Summit XL OMNI (4 axes skid steering, 4 axes swerve drive), Summit X-WAM (4 axes skid steering, 4 axes swerve drive, 1 linear axis for scissor mechanism). The Summit XL simulation stack follows the gazebo_ros controller manager scheme described in  Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "
W503,https://wiki.ros.org/lanelet2_maps,Wiki,lanelet2_maps,Example maps in the lanelet2-format
W504,https://wiki.ros.org/ublox,Wiki,ublox,"Provides a ublox_gps node for u-blox GPS receivers, messages, and serialization packages for the binary UBX protocol.


Launch the  node. Since there are many parameters, load the parameters from a  file. For example: An example parameter file is shown below. Note that if the baudrate, rate, nav_rate or GNSS are not configured correctly for your device, the launch may fail. 

The driver publishes  and  messages. The ublox_gps package provides a node to subscribe to various u-blox messages. ~<node_name>/fixgps~<node_name>/fix_velocitygps~<node_name>/diagnostics~<node_name>/frame_idstringtf_prefix~<node_name>/devicestring~<node_name>/uart1/baudrateuint16~<node_name>/uart1/inuint32~<node_name>/uart1/outuint16~<node_name>/ratefloat~<node_name>/nav_rateuint16~<node_name>/enable_pppbool~<node_name>/gnss/sbasbool~<node_name>/sbas/usageuint8~<node_name>/dynamic_modelstringportablestationarypedestrianautomotiveseaairborne1airborne2airborne4wristwatch~<node_name>/fix_modestring~<node_name>/dr_limituint8~<node_name>/save_on_shutdownbool~<node_name>/clear_bbrboolraw_databool~<node_name>/save/maskuint32~<node_name>/save/deviceuint8~<node_name>/load/maskuint32~<node_name>/load/deviceuint8~<node_name>/dat/set_datbool~<node_name>/dat/majAfloat64~<node_name>/dat/flatfloat64~<node_name>/dat/shift[float32, float32, float32]~<node_name>/dat/rot[float32, float32, float32]~<node_name>/dat/scalefloat32~<node_name>/gnss/gpsbool~<node_name>/gnss/glonassbool~<node_name>/gnss/beidoubool~<node_name>/gnss/qzssbool~<node_name>/gnss/qzss_sig_cfguint32~<node_name>/gnss/galileobool~<node_name>/gnss/imesbool~<node_name>/nmea/setbool~<node_name>/nmea/versionuint8nmea/set~<node_name>/nmea/num_svuint8nmea/set~<node_name>/nmea/sv_numberinguint8nmea/set~<node_name>/nmea/compatboolnmea/set~<node_name>/nmea/considerboolnmea/set~<node_name>/nmea/limit82bool~<node_name>/nmea/high_precbool~<node_name>/nmea/filter/posbool~<node_name>/nmea/filter/msk_posbool~<node_name>/nmea/filter/timebool~<node_name>/nmea/filter/datebool~<node_name>/nmea/filter/gps_onlybool~<node_name>/nmea/filter/trackbool~<node_name>/nmea/gnssToFilt/gpsbool~<node_name>/nmea/gnssToFilt/sbasbool~<node_name>/nmea/gnssToFilt/qzssbool~<node_name>/nmea/gnssToFilt/glonassbool~<node_name>/nmea/gnssToFilt/beidoubool~<node_name>/nmea/main_talker_iduint8~<node_name>/nmea/gsv_talker_iduint8~<node_name>/nmea/bds_talker_id[0, 0]~<node_name>/nmea/setbool~<node_name>/nmea/versionuint8nmea/set~<node_name>/nmea/num_svuint8nmea/set~<node_name>/nmea/compatboolnmea/set~<node_name>/nmea/considerboolnmea/set~<node_name>/nmea/filter/posbool~<node_name>/nmea/filter/msk_posbool~<node_name>/nmea/filter/timebool~<node_name>/nmea/filter/datebool~<node_name>/nmea/filter/sbasbool~<node_name>/nmea/filter/trackbool~<node_name>/use_adrbool~<node_name>/nav_rate (~<node_name>/tmode3uint8~<node_name>/arp/lla_flagbooltmode3~<node_name>/arp/positionfloat32[3]tmode3~<node_name>/arp/position_hpint8[3]tmode3~<node_name>/arp/accfloat32tmode3~<node_name>/sv_in/resetbool~<node_name>/sv_in/min_duruint8tmode3~<node_name>/sv_in/acc_limfloat32tmode3~<node_name>/dgnss_modeuint8INF~<node_name>/inf/allboolINF~<node_name>/inf/debugboolINF-DebugROS_DEBUG~<node_name>/inf/errorboolINF-ErrorROS_ERROR~<node_name>/inf/noticeboolINF-NoticeROS_INFO~<node_name>/inf/testboolINF-TestROS_INFO~<node_name>/inf/warningboolINF-WarningROS_WARN~<node_name>/publish/allboolRXMAIDMONpublish/<class>/all~<node_name>/publish/aid/allboolAIDAID~<node_name>/publish/aid/almbool~aidalm~<node_name>/publish/aid/ephbool~aideph~<node_name>/publish/aid/huibool~aidhui~<node_name>/publish/rxm/allboolRXMRXM~<node_name>/publish/rxm/almbool~rxmalm~<node_name>/publish/rxm/rawbool~rxmraw~<node_name>/publish/rxm/rtcmbool~rxmrtcm~<node_name>/publish/rxm/sfrbbool~rxmsfrb~<node_name>/publish/rxm/ephbool~rxmeph~<node_name>/publish/mon/allboolMON~<node_name>/publish/mon/hwbool~monhw~<node_name>/publish/nav/attbool~navatt~<node_name>/publish/nav/clockbool~<node_name>/publish/nav~navclock~<node_name>/publish/nav/posecefboolNavPOSECEF~navposecef~<node_name>/publish/nav/posllhboolNavPOSLLH~navposllh~<node_name>/publish/nav/pvtbool~navpvt~<node_name>/publish/nav/relposnedboolNavRELPOSNED~navrelposned~<node_name>/publish/nav/satbool~navsat~<node_name>/publish/nav/solbool~navsol~<node_name>/publish/nav/statusbool~navstatus~<node_name>/publish/nav/svinbool~navsvin~<node_name>/publish/nav/svinfobool~navsvinfo~<node_name>/publish/nav/velnedboolublox_msgs/NavVELNED~navvelnedublox_msgs/NavPVT~<node_name>/publish/esf/allboolESF~<node_name>/publish/esf/insbool~esfins~<node_name>/publish/esf/measbool~esfmeas~<node_name>/publish/esf/rawbool~esfraw~<node_name>/publish/esf/statusbool~esfstatus~<node_name>/publish/hnr/pvtbool~hnrpvtublox_gps.yaml<?xml version=""1.0"" encoding=""UTF-8""?>

<launch>
  <arg name=""param_file_name"" doc=""name of param file, e.g. rover"" />
  <node pkg=""ublox_gps"" type=""ublox_gps"" name=""ublox_gps"">
    <rosparam command=""load"" file=""$(find ublox_gps)/config/$(arg param_file_name).yaml"" />
  </node>
</launch>debug: 1                    # Range 0-4 (0 means no debug statements will print)

device: /dev/ttyACM0
frame_id: gps
dynamic_model: portable
fix_mode: auto              # Switches between 2D/3D automatically
dr_limit: 0                 # Dead reckoning limit
enable_ppp: false           # Advanced setting not supported by all devices

rate: 4                     # Measurement rate in Hz
nav_rate: 4                 # in number of measurement cycles

uart1:
  baudrate: 19200           # baudrate is device specific, check the device manual
  in: 1                     # UBX
  out: 4                    # RTCM

# RTCM out config
rtcm:
  ids: [5, 87, 77, 230]     # RTCM Messages to configure
  rates: [1, 1, 1, 10]      # Rates of RTCM messages above,
                            # in number of navigation solutions
dat:
  set: false                # Do not set the user configured datum

# GNSS Config, verify which GNSS are supported by your device
gnss:
  gps: true                 # (not required since it defaults to true)
  glonass: true
  beidou: false
  qzss: false
  sbas: false

inf:
  all: true                   # Whether to display INF messages

# Message subscriptions
subscribe:
  all: true                 # Subscribe to all messages
  aid:
    all: false                # ... except AID messages"
W505,https://wiki.ros.org/pilz_trajectory_generation,Wiki,pilz_trajectory_generation,"The pilz_trajectory_generation package containing the MoveIt! plugin pilz_command_planner.

For package documentation please see the . "
W506,https://wiki.ros.org/map_server,Wiki,map_server,"map_server provides the  ROS , which offers map data as a ROS . It also provides the  command-line utility, which allows dynamically generated maps to be saved to file.













 retrieves map data and writes it out to  and .  Use the  option to provide a different base name for the output files. The  and  options take values between 0 and 100. To save different map topic set  to your costmap topic. 

Image data is read in via ; supported formats vary, depending on what SDL_Image provides on a specific platform.  Generally speaking, most popular image formats are widely supported.  A notable exception is that PNG is not supported on OS X. Given a pixel that has a COLOR value  in the range , how should we interpret this value when put into the ROS message? First we convert integer  to a floating point number  depending on the interpretation of the  flag from the yaml.  This will allow you to output a full gradient of values ranging from . To output , simply use the alpha channel of a png, where any transparency will be interpreted as unknown. This mode will output  for each pixel, so output values are .  map_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_savermap_servermap_saverx[0, 256)xpnegatenegatep = (255 - x) / 255.0negatep = x / 255.0p > occupied_thresh100p < free_thresh0-1255p > occupied_thresh100p < free_thresh099 * (p - free_thresh) / (occupied_thresh - free_thresh)[0, 100]-1x[0, 255]map_servermap_metadatamapstatic_map~frame_idstring""map""map_savermap_savermapimage: testmap.png
resolution: 0.1
origin: [0.0, 0.0, 0.0]
occupied_thresh: 0.65
free_thresh: 0.196
negate: 0map_server <map.yaml>rosrun map_server map_server mymap.yamlrosrun map_server map_saver [--occ <threshold_occupied>] [--free <threshold_free>] [-f <mapname>] map:=/your/costmap/topicrosrun map_server map_saver -f mymaprosrun map_server map_saver --occ 90 --free 10 -f mymap map:=/move_base/global_costmap/costmap"
W507,https://wiki.ros.org/tf2_eigen,Wiki,tf2_eigen,"tf2_eigen


   Please see the  for use. "
W508,https://wiki.ros.org/pocketsphinx,Wiki,pocketsphinx,"This package is a simple wrapper around the pocketsphinx speech recognizer, 
    using gstreamer and a Python-based interface.





This package provides access to the  speech recognizer. It uses gstreamer to automatically split the incoming audio into utterances to be recognized, and offers services to start and stop recognition.  Currently, the recognizer  a language model and dictionary file. These can be automatically built from a corpus of sentances using the . Example launch files, language models, and dictionary files can be found in the  directory of the package. The  example controls a mobile base using commands such as """" or """". The  example uses some of the standard items and names from the @Home contest, for instance, it should recognize """" or """".  ~output~start~stop~lmstr~dictstrsudo apt-get install ros-groovy-pocketsphinxsudo apt-get install ros-hydro-pocketsphinxsudo apt-get install ros-indigo-pocketsphinxsudo apt-get install ros-jade-pocketsphinxgit clone https://github.com/mikeferguson/pocketsphinx
sudo apt-get install gstreamer0.10-pocketsphinx"
W509,https://wiki.ros.org/katana_gazebo_plugins,Wiki,katana_gazebo_plugins,"This package provides Gazebo plugins to simulate the Katana arm.

Currently, there is only one plugin available that simulates the gripper. See packages  and  for usage examples and for information on the Gazebo parameters (not documented here). posture_action_name/goalposture_action_name/resultgripper_controller_stategrasp_query_name~gripper_object_presence_thresholddouble"
W510,https://wiki.ros.org/rsv_balance_msgs,Wiki,rsv_balance_msgs,RoboSavvy's balancing platform messages and services definitions.
W511,https://wiki.ros.org/state_exchanger,Wiki,state_exchanger,"A package that exchanges behavioral states between multiple cyber physical systems (CPSs) in a swarm.

 (, default: 1)  (, default: ) 


The communication between CPSs is based on the . The state that is exchanged is read from a  state machine. to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. state_exchangeridintegeroutputstringscreenscreenlogparamstate_exchanger.yamlstate_exchangerstate_exchangersmach_server/smach/container_statusbridge/events/statestateswarm_state~loop_ratereal~queue_sizeinteger~timeoutreal~sm_pathstringroslaunch state_exchanger state_exchanger.launch"
W512,https://wiki.ros.org/wifi_ddwrt,Wiki,wifi_ddwrt,"Access to the DD-WRT wifi








This package provides tools for logging statistics from a router using  OpenSource firmware and publishing them over ROS. The ddwrt  publishes information about the Access Point that the router is currently connected to as well as survey information about all the Access Points that the router can see. The monitor node publishes a visualization marker to  that displays between 1-5 bars over the robot's head according to the signal strength of the Access Point the robot is currently connected to. ddwrt/sitesurveyddwrt/accesspoint~routerstring~usernamestring~passwordstringddwrt/sitesurveyddwrt/accesspointvisualization_markerddwrt/sitesurveyddwrt/accesspointvisualization_marker"
W513,https://wiki.ros.org/turtlebot3_autorace_camera,Wiki,turtlebot3_autorace_camera,"TurtleBot3 AutoRace ROS package that controls Raspberry Pi Camera, and process the image 







Refer to parameters for  with picamera. This package is provided parameters from . files.  camera/image_input/compressedcamera/image_outputcamera/image_output/compressedcamera/image_outputcamera/image_input/compressedcamera/image_outputcamera/image_output/compressedcamera/image_outputcamera_infoimage/compressed#------------------------ parameter for image compensation ------------------------#
gen.add(""clip_hist_percent"", double_t, 0, 
        ""Percentage of Histogram Cut-Off"", 1.0, 0.0, 10.0)#-------------------------- parameter for image warping --------------------------# 
gen.add(""top_x"",        int_t,      0,      ""Top X Pos"",        60,  0, 120)
gen.add(""top_y"",        int_t,      0,      ""Top Y Pos"",        50,  0, 120)
gen.add(""bottom_x"",     int_t,      0,      ""Bottom X Pos"",     140,  0, 320)
gen.add(""bottom_y"",     int_t,      0,      ""Bottom Y Pos"",     120,  0, 320) camera.yaml                          # default configuration for camera
 compensation.yaml                    # parameters for image compensation
 projection.yaml                      # parameters for image warping
 camerav2_320x240_30fps.yaml          # default configuration for lense"
W514,https://wiki.ros.org/wheeled_robin_node,Wiki,wheeled_robin_node,"The wheeled_robin_node package


 To start the  driver node use the launch files in wheeled_robin_bringup. cmd_velodomjoint_states~sensor_statediagnostics~set_operation_mode~set_digital_outputs~update_ratedouble~drive_modestring~cmd_vel_timeoutdouble~odom_angular_scale_correctiondouble~odom_linear_scale_correctiondouble~min_abs_yaw_veldouble~max_abs_yaw_veldouble~portstring~publish_tfbool~odom_framestring~base_footprint_framestring~base_link_framestring~operation_modeintegerodombase_footprintbase_footprintbase_link"
W515,https://wiki.ros.org/rail_pick_and_place,Wiki,rail_pick_and_place,"Grasp Training and Pick and Place Methods Developed by the RAIL Lab

The  metapackage contains packages for object recognition, grasp selection, and placement.  Also included are packages for collecting demonstration grasps, generating models for recognition and manipulation, and training to determine the effectiveness of learned grasps. To install the  package, you can install from source with the following commands: rail_pick_and_placerail_pick_and_place



"
W516,https://wiki.ros.org/object_recognition_msgs,Wiki,object_recognition_msgs,Object_recognition_msgs contains the ROS message and the actionlib definition used in object_recognition_core
W517,https://wiki.ros.org/schunk_sdh,Wiki,schunk_sdh,"This package provides an interface for operating the schunk dexterous hand (SDH), including the tactile sensors.




To use this package you need a schunk dexterous hand  with . Other firmware versions may work, but are not officially supported. Alternatively you can use a simulated version without any hardware, see . The installation is tested for Ubuntu 10.04, 10.10, 11.04 and 11.10 using ROS . If you discover problems installing them on other platforms, please . The  package provides a configurable node for operating a schunk dexterous hand. 
This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g.  in the  stack. For using only the sdh use All hardware configuration is done in the  package. A sample parameter file for the sdh in ""schunk_hardware_config/sdh/config/sdh.yaml"" could look like this schunk_sdhfollow_joint_trajectory_action/goalfollow_joint_trajectory_action/resultfollow_joint_trajectory_action/feedbackcommand/joint_statesinitstoprecoverset_operation_mode~sdhdevicetypestring~sdhdevicestringstring~dsadevicestringstring~baudrateint~joint_nameslist of strings/robot_descriptionurdf modeldsa_onlytactile_data~dsadevicestringstring~pollingbool~publish_frequencyfloatroslaunch schunk_bringup sdh_solo.launch<include file=""$(find schunk_bringup)/components/sdh.launch"" />sdhdevicetype: PCAN
sdhdevicestring: /dev/pcan0
baudrate: 1000000
joint_names: ['sdh_knuckle_joint', 'sdh_thumb_2_joint', 'sdh_thumb_3_joint', 'sdh_finger_12_joint', 'sdh_finger_13_joint', 'sdh_finger_22_joint', 'sdh_finger_23_joint']
OperationMode: positiondsadevicestring: /dev/ttyS0
polling: false
use_rle: true
frequency: 30"
W518,https://wiki.ros.org/laser_scan_splitter,Wiki,laser_scan_splitter,"The laser_scan_splitter takes in a LaserScan message and splits it into a number of other LaserScan messages. Each of the resulting laser scans can be assigned an arbitrary coordinate frame, and is published on a separate topic. 




 The  takes in a  message and splits it into a number of other  messages. Each of the resulting laser scans can be assigned an arbitrary coordinate frame, and is published on a separate topic.  You can run the  on a pre-recorded bag file that comes with the package. First, make sure you have the  stack downloaded and installed by following the instructions . You should see a result similar to the video below. The 3 laser scan messages displayed in  are obtained by splitting the original scan. Two drivers are available:  and . Their parameters and topics are identical. Please submit your tickets through  (requires github account) or by emailing the maintainers. LaserScanlaser_scan_splitter_nodelaser_scan_splitter_nodeletlaser_scan_splitter_nodescan~scan_[n]LaserScan~scan_1~scan_2~sizesstring""256 256""~topicsstring""scan_1 scan_2""~framesstring""laser laser""

"
W519,https://wiki.ros.org/manifest_cleaner,Wiki,manifest_cleaner,"Examines package and stack manifests. Currently only can output statistics, doesn't actually clean.

 








If the  tag is not used, the summary will contain whether the URL tag is specified or not.  If the  tag is used, the summary will contain the HTTP response numbers obtained when the given URL is downloaded. Note that this option will take a bit longer to run.  A list of all the authors and the number and list of all the stacks/packages they maintain. Minor parsing is done to separate comma delineated lists and email addresses when they are of the form 'My name/'. -web-webrosrun manifest_cleaner stats.py (some/directory/containing/packages) [-web]name                     description brief    license url       review       author                     
======================== =========== ======== ======= ========= ============ ===========================
pr2_common               detailed    detailed BSD     specified Doc reviewed Maintained by John Hsu  name                     description brief    license url       review       author                     
======================== =========== ======== ======= ========= ============ ===========================
pr2_msgs                 detailed    detailed BSD     specified Doc reviewed Eric Berger and many others"
W520,https://wiki.ros.org/rtt_diagnostic_msgs,Wiki,rtt_diagnostic_msgs,"Provides an rtt typekit for ROS diagnostic_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/diagnostic_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W521,https://wiki.ros.org/rosmsg,Wiki,rosmsg,"rosmsg contains two command-line tools:  and
    .  is a command-line tool for
    displaying information about .  is a command-line tool for displaying
    information about .
 and  are handy command-line tools that provide reference information for developers and also serve as a powerful introspection tool for learning more about data being transmitted in ROS.  



 


 
 


 and  are stable tools. There is currently no plan to add new features to them. For example, if you are using a message in your code, you can type  at the command-line to look up its fields: For even quicker typing, you can omit """", and  will search all packages for a matching message. You can also use this in an online system with tools like . For example,  will tell you the message type of a topic: You can pass this to  to quickly see the fields of the message: Once you know more about the fields of a particular message, you can then listen them at the command-line, e.g. The  command-line tool displays information about ROS . The following sections describe the commands that are available. Note that messages in a subfolder may not be listed as of March 2017 (). The  command-line tool displays information about ROS services. It has the exact same usage as  (see what it offers when it runs without sub-command below): rosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsgrossrvrosmsg showmy_pkgrosmsgrostopic typerosmsgrosmsgshow <message type>rosmsg-r-b BAGFILElist.msgpackage <package-name>-spackages.msg-susers <message type>rosmsg usersmd5 <message type>rossrvrosmsgrosmsgrossrv$ rosmsg show sensor_msgs/CameraInfo
Header header
  uint32 seq
  time stamp
  string frame_id
uint32 height
uint32 width
RegionOfInterest roi
  uint32 x_offset
  uint32 y_offset
  uint32 height
  uint32 width
float64[5] D
float64[9] K
float64[9] R
float64[12] P$ rostopic type rosout
roslib/Logrostopic type rosout | rosmsg show
byte DEBUG=1
byte INFO=2
byte WARN=4
byte ERROR=8
byte FATAL=16
Header header
  uint32 seq
  time stamp
  string frame_id
byte level
string name
string msg
string file
string function
uint32 line
string[] topics$ rostopic echo rosout/msg$ rosmsg show std_msgs/String$ rosmsg show Pose$ rostopic type /topic_name | rosmsg show$ rosmsg show -r robot_msgs/Quaternion
# xyz - vector rotation axis, w - scalar term (cos(ang/2))
float64 x
float64 y
float64 z
float64 w$ rosmsg list
nav_msgs/GridCells
nav_msgs/MapMetaData
nav_msgs/OccupancyGrid
nav_msgs/Odometry
nav_msgs/Path
...$ rosmsg package nav_msgs
nav_msgs/OccupancyGrid
nav_msgs/Path
nav_msgs/MapMetaData
nav_msgs/Odometry
nav_msgs/GridCells$ rosmsg packages
std_msgs
roscpp
roslib
...$ rosmsg users sensor_msgs/CameraInfo
Files using sensor_msgs/CameraInfo:
Usages directly depended upon:sensor_msgs/CameraInfo
/home/user/ros-pkg/pr2_simulator/pr2_gazebo_plugins/include/pr2_gazebo_plugins/gazebo_ros_prosilica.h
...$ rossrv
rossrv is a command-line tool for displaying information about ROS Service types.

Commands:
        rossrv show     Show service description
        rossrv list     List all services
        rossrv md5      Display service md5sum
        rossrv package  List services in a package
        rossrv packages List packages that contain services

Type rossrv <command> -h for more detailed usage"
W522,https://wiki.ros.org/maxwell_calibration,Wiki,maxwell_calibration,"
    Launch and configuration files for calibrating Maxwell using the new generic 'calibration' stack.
  



"
W523,https://wiki.ros.org/camera_handler,Wiki,camera_handler,"The camera_handler package
 
In V-REP it is possible to simulate a vision sensor. Vision sensors are added to the scene with [menu bar --> Add --> Vision sensor]. After a double-click on a vision-sensor, we can set some parameters like the resolution and the field of view of the camera. In addition we added a GUI to set the frequency of acquisition and the type of color coding (RGB or grayscale) that should be used.  /vrep/Vision_sensor_0
 /vrep/Vision_sensor_0/Camerainfo
 /vrep/Vision_sensor_0/compressed
 /vrep/Vision_sensor_0/compressed/parameter_descriptions
 /vrep/Vision_sensor_0/compressed/parameter_updates
 /vrep/Vision_sensor_0/compressedDepth
 /vrep/Vision_sensor_0/compressedDepth/parameter_descriptions
 /vrep/Vision_sensor_0/compressedDepth/parameter_updates
 /vrep/Vision_sensor_0/theora
 /vrep/Vision_sensor_0/theora/parameter_descriptions
 /vrep/Vision_sensor_0/theora/parameter_updates"
W524,https://wiki.ros.org/jog_launch,Wiki,jog_launch,Collection of the launch files for jog_controller
W525,https://wiki.ros.org/ridgeback_description,Wiki,ridgeback_description,"URDF robot description for Ridgeback
 

This package provides a  model of . For an example launchfile to use in visualizing this model, see . Ridgeback has a suite of optional payloads called accessories. These payloads can be enabled and placed on Ridgeback using environment variables specified at the time the  is rendered to URDF. Available accessory vars are: As an alternative to individually specifying each accessory, some fixed configurations are provided in the package. These can be specified using the  arg to , and are intended especially as a convenience for simulation launch. RIDGEBACK_FRONT_LASER0RIDGEBACK_FRONT_LASER_MOUNTfrontRIDGEBACK_FRONT_LASER_OFFSET""0 0 0""RIDGEBACK_FRONT_LASER_RPY""0 0 0""RIDGEBACK_FRONT_LASER_HOST192.168.131.14RIDGEBACK_REAR_LASER0RIDGEBACK_REAR_LASER_MOUNTrearRIDGEBACK_REAR_LASER_OFFSET""0 0 0""RIDGEBACK_REAR_LASER_RPY""0 0 0""RIDGEBACK_REAR_LASER_HOST192.168.131.13configdescription.launchbasedual_laser"
W526,https://wiki.ros.org/rtt_std_msgs,Wiki,rtt_std_msgs,"Provides an rtt typekit for ROS std_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/std_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W527,https://wiki.ros.org/jog_control,Wiki,jog_control,"This metapackage depends on packages related to jog control.

Use GitHub to . []
  "
W528,https://wiki.ros.org/steer_bot_hardware_gazebo,Wiki,steer_bot_hardware_gazebo,"steer bot hardware for gazebo simulation
 inherits  so that the plugin is integrated to . 

 is designed to have two joint interfaces, one is velocity_joint_interface for the single rear wheel joint and the other is position_joint_interface for the single front steer joint. This concept keeps the controller's abstraction to be applied in various types of configuration by converting the joint interfaces in the controller to ones on an actual robot via  or . 
 
  



 () 
 () 
 has an example launch file to spawn  with  named . An example of usage of this plugin can be seen in , especially in . This package provides 4-wheel car-like robot model with steer mechanism for Gazebo simulation, by using  plugin. We developed this plugins assuming that  is selected as the driving controller. Now we need to do it for a Gazebo model too, which is the main role of this plugin. The following figure shows how a velocity command of  converted to a joint command to  via . Each type of joint interface on  is split into two interface for right and left. This is because  doesn't support closed links (e.g. parallel link or Ackermann link), which means we need to virtually imitate such links by software. In order to achieve the conversion mentioned above, you need to register joint interfaces for both  and  in . For , it's simple to just register two joint interface for a rear wheel and a front steer as mentioned previously. For , 4 more velocity joint interfaces for wheels and 2 more position joint interface for front steers (in total 2 + 4 + 2 = 8 joint interface are registered in this plugin).  An example of registering such joint interfaces can be seen in . In  in your robot, add the following tag to apply . An example of a xacro is  in . gazebo_ros_controlsteer_bot_hardware_gazebo::SteerBotHardwareGazebogazebo_ros_control::RobotHWSimGazeboRobotHWRobotHWSimgeometry_msgs::TwistGazeboURDFGazebosteer_bot_hardware_gazebosteer_drive_controllerGazeboGazeboURDFdescription.gazebo.xacrorear_wheelstringfront_steerstringvirtual_rear_wheelsstring [2]Gazebovirtual_front_wheelsstring [2]Gazebovirtual_front_steersstring [2]Gazeboenable_ackermann_linkboolwheel_separation_wdoublewheel_separation_hdoublecirkit_unit03_world.launch  <!-- Gazebo plugin for ROS Control -->
  <gazebo>
    <plugin name=""gazebo_ros_control"" filename=""libgazebo_ros_control.so"">
      <robotNamespace>/</robotNamespace>
      <robotSimType>steer_bot_hardware_gazebo/SteerBotHardwareGazebo</robotSimType>
    </plugin>
  </gazebo>gains:
  base_to_right_rear_wheel  :  {p: 100000.0, d: 10.0, i: 0.50, i_clamp: 3.0}
  base_to_left_rear_wheel   :  {p: 100000.0, d: 10.0, i: 0.50, i_clamp: 3.0}"
W529,https://wiki.ros.org/turtlebot_dashboard,Wiki,turtlebot_dashboard,Launchers for the base-specific dashboardsturtlebot_dashboardStaleStaleStaleStalerosrun turtlebot_dashboard turtlebot_dashboardexport ROS_MASTER_URI=http://MY_ROBOT:11311roslaunch turtlebot_dashboard turtlebot_dashboard.launchroslaunch turtlebot_dashboard turtlebot_dashboard.launchroslaunch turtlebot_dashboard turtlebot_dashboard.launch
W530,https://wiki.ros.org/perception_oru,Wiki,perception_oru,"Perception packages from the MRO lab at AASS, Orebro UniversityAll packages in this stack for fuerte can be downloaded from the project svn trunk. 

 For documentation, please check the package pages. Description of the NDT data structures and related papers can be found in . Usage of the NDT for registration is documented in the  package. Visualization tools can be found at . Finally, the truncated SDF tracking package is documented at . "
W531,https://wiki.ros.org/tra1_description,Wiki,tra1_description,"This package contains the description (mechanical, kinematic, visual,  etc.) of the TRA1 robot. The files in this package are parsed and used by a variety of other components.  Most users will not interact directly with this package.
 
 $ roslaunch tra1_description tra1.launch"
W532,https://wiki.ros.org/svenzva_msgs,Wiki,svenzva_msgs,"Svenzva arm and state related messages.   
  
  "
W533,https://wiki.ros.org/lockfree,Wiki,lockfree,"The lockfree package contains lock-free data structures for use in multithreaded programming.  These
     kinds of data structures are generally not as easy to use as single-threaded equivalents, and are not
     always faster.  If you don't know you need to use one, try another structure with a lock around it
     first.



The  package contains  generally meant to be used in realtime or high-performance multithreaded systems. Currently  contains 2 data structures,  and . The  class provides a fixed number of fixed-size blocks that you can allocate and free from multiple threads.   is lock-free but not wait-free. While the  class simply provides allocation of specific-sized blocks of memory, the  class builds on top of that to provide allocation of specific object types, initialized using a template object.  It also allows you to allocate either s or bare pointers, depending on your needs.   is lock-free but not wait-free. FreeListFreeListboost::shared_ptrObjectPool


































"
W534,https://wiki.ros.org/ridgeback_base,Wiki,ridgeback_base,"Ridgeback's mobility and sensor base.

This package contains the primary binary which runs on , providing the -based communication the MCU, as well as diagnostic support, and other basic services such as lighting and cooling.  In addition, it provides the CAN based communication to the . Ridgeback includes a built-in magnetometer, which is used by  to estimate orientation. To calibrate the magnetometer using scripts provided by this package, see . "
W535,https://wiki.ros.org/roscpp_core,Wiki,roscpp_core,Underlying data libraries for roscpp messages. 
W536,https://wiki.ros.org/realtime_tools,Wiki,realtime_tools,"Contains a set of tools that can be used from a hard
    realtime thread, without breaking the realtime behavior.  The
    tools currently only provides the realtime publisher, which makes
    it possible to publish messages to a ROS topic from a realtime
    thread. We plan to add a basic implementation of a realtime
    buffer, to make it possible to get data from a (non-realtime)
    topic callback into the realtime loop. Once the lockfree buffer is
    created, the realtime publisher will start using it, which will
    result in major API changes for the realtime publisher (removal of
    all lock methods).
The  allows users that write C++  to publish messages on a ROS topic from a hard realtime loop. The normal ROS publisher is not realtime safe, and should not be used from within the update loop of a realtime controller. The realtime publisher is a wrapper around the ROS publisher; the wrapper creates an extra non-realtime thread that publishes messages on a ROS topic. The example below shows a typical usage of the realtime publisher in the  and  methods of a realtime controller: realtime_tools::RealtimePublisherinit()update()





















"
W537,https://wiki.ros.org/turtlebot3_msgs,Wiki,turtlebot3_msgs,"Message and service types: custom messages and services for TurtleBot3 packages 

 
   
  
  
 
 
  
 "
W538,https://wiki.ros.org/people_msgs,Wiki,people_msgs,"Messages used by nodes in the people stack.
 - Generic message for detecting the location of a person. Includes a 3-D point estimate, reliability estimate and covariance matrix.  - An array of PositionMeasurements as well as a co-occurence array.  - A position estimate with an added velocity vector, as well as the ability to add tags to the person. Has no header, should only be used in conjunction with PersonStamped or People.  - A header + a person  - A header + an array of persons  "
W539,https://wiki.ros.org/spur_gazebo,Wiki,spur_gazebo,3D simulation package for SPUR omni-directional mobile manipulator robot made at Tamagawa University.
W540,https://wiki.ros.org/touch_skill_msgs,Wiki,touch_skill_msgs,"touch_skill messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""touch_skill_msgs"" in rosdoc: /home/rosbot/docs/api/touch_skill_msgs/manifest.yaml "
W541,https://wiki.ros.org/katana_tutorials,Wiki,katana_tutorials,This package contains test and demo programs for the katana_driver stack.
W542,https://wiki.ros.org/uavc_v4lctl,Wiki,uavc_v4lctl,"ROS wrapper for the v4lctl tool







   This ROS node is just a wrapper for the  tool. It provides two services, to set and to get particular  video device parameter. If a yaml file will be provided a save and restore capability will be enabled. Parameter are then loaded and set automatically in the capture device when starting the node. Changed parameter are stored to a yaml file when the program ends. Additionally a dynamic reconfigure rqt gui is available to manipulate v4l parameter. The below v4lctl list output is based on an Osprey 440 bttv capture card.  is optimized for this card (but the services provided by this ROS node are generic and can be used for any hardware related available v4l parameter). Your card may output other options. To support them as well feel free to adapt the files v4lctl_node.cpp and v4lctlNodeDyn.cfg in the repository to your needs. The sources can be found here:  v4lctlSetv4lctlGet~devicestring~yamlstring$ v4lctl list
  attribute  | type   | current | default | comment
  -----------+--------+---------+---------+-------------------------------------
  norm       | choice | PAL-I   | NTSC    | NTSC NTSC-M NTSC-M-JP NTSC-M-KR PAL PAL-BG PAL-H PAL-I PAL-DK PAL-M PAL-N PAL-Nc PAL-60 SECAM SECAM-B SECAM-G SECAM-H SECAM-DK SECAM-L SECAM-Lc
  input      | choice | Composi | Composi | Composite0 Composite1 Composite2 Composite3
  bright     | int    |   32768 |   32768 | range is 0 => 65280
  contrast   | int    |   32768 |   27648 | range is 0 => 65408
  color      | int    |   32768 |   32768 | range is 0 => 65408
  hue        | int    |   32768 |   32768 | range is 0 => 65280
  mute       | bool   | on      | off     |
  Chroma AGC | bool   | off     | off     |
  Color Kill | bool   | off     | off     |
  Comb Filte | bool   | off     | off     |
  Auto Mute  | bool   | on      | on      |
  Luma Decim | bool   | off     | off     |
  AGC Crush  | bool   | on      | on      |
  VCR Hack   | bool   | off     | off     |
  Whitecrush | int    |     127 |     127 | range is 0 => 255
  Whitecrush | int    |     207 |     207 | range is 0 => 255
  UV Ratio   | int    |      51 |      50 | range is 0 => 100
  Full Luma  | bool   | off     | off     |
  Coring     | int    |       0 |       0 | range is 0 => 3$ roslaunch uavc_v4lctl v4lctl.launch device:=/dev/video1$ rosservice call /v4lctlSet bright ""77%""
$ rosservice call /v4lctlGet bright

$ rosservice call /v4lctlSet hue '!!str 40000'
$ rosservice call /v4lctlGet hue

$ rosservice call /v4lctlSet 'setattr ""UV Ratio""' 30%
$ rosservice call /v4lctlGet ""UV Ratio""cd ~/catkin_ws/src
git clone https://github.com/meuchel/uavc_v4lctl
cd ~/catkin_ws
catkin build # depending on your workspace it could also be catkin_make"
W543,https://wiki.ros.org/turtlesim,Wiki,turtlesim,"turtlesim is a tool made for teaching ROS and ROS packages.

 As of  turtlesim uses the /Twist message instead of its own custom one ( in  and older). Also the topic has been changed to  (instead of  before). 



cmd_velcommand_velocityturtlesim_nodeturtleX/cmd_velturtleX/poseclearresetkillspawnturtleX/set_penturtleX/teleport_absoluteturtleX/teleport_relative~background_bint~background_gint~background_rintmimicinputmimicposeoutputmimiccmd_vel$ roscore$ sudo apt-get install ros-$(rosversion -d)-turtlesim$ rosrun turtlesim turtlesim_node"
W544,https://wiki.ros.org/acado,Wiki,acado,"ACADO Toolkit is a software environment and algorithm collection for automatic control and dynamic optimization. It provides a general framework for using a great variety of algorithms for direct optimal control, including model predictive control, state and parameter estimation and robust optimization. ACADO Toolkit is implemented as self-contained C++ code and comes along with user-friendly Matlab interfaces. The object-oriented design allows for convenient coupling of existing optimization packages and for extending it with user-written optimization routines. The ACADO Toolkit is made available in ROS Indigo by . You can install it on Ubuntu like so: sudo apt-get install ros-indigo-acado"
W545,https://wiki.ros.org/visp_tracker,Wiki,visp_tracker,"Wraps the ViSP moving edge tracker provided by the ViSP visual
    servoing library into a ROS package.

    This computer vision algorithm computes the pose (i.e. position
    and orientation) of an object in an image. It is fast enough to
    allow object online tracking using a camera.
 



 is part of  stack.  
 




 even if a nodelet is available for the client and viewer, one should avoid running them in the same process than the vision pipeline to avoid crashing the whole pipeline if something goes wrong. 

 The package is composed of one node called  that does the tracking and two additional nodes  (that allows to set the initial pose by user mouse click) and  that allows to visualize the result of the tracking. The  node tries to track the object as fast as possible but needs to be initialized using the client. The viewer can be used to monitor the tracking result. When the nodelet version is used, no-copy intraprocess publishing is used. See the  documentation for more information. Use GitHub to . trackerclientviewertracker~camera_prefix/camera_info~camera_prefix/image_rectobject_position_hintobject_positionobject_position_covariancemoving_edge_sitesklt_points_positionsinit_trackertracking_meta_data~camera_prefixstd_msgs/String~first_thresholdfloat64~lambdafloat64~mask_sizeint64~min_samplestepfloat64~model_namestd_msgs/String.wrl~model_pathstd_msgs/Stringpackage://http://~mu1float64~mu2float64~n_maskint64~n_total_sampleint64~rangeint64~sample_stepint64~stripint64~thresholdfloat64~aberrationfloat64~init_aberrationfloat64~compensate_robot_motionbool~world_frame_idstring~compensate_robot_motion~world_frame_id<camera frame>~compensate_robot_motion<camera frame>visp_tracker~camera_prefixstd_msgs/String~tracker_prefixstd_msgs/String~model_pathstd_msgs/String~model_namestd_msgs/String~tracker_prefixstd_msgs/String~image_transportstringvisp_tracker/Trackervisp_tracker/TrackerClientvisp_tracker/TrackerViewersudo apt-get install ros-$ROS_DISTRO-visp-trackersudo apt-get install ros-$ROS_DISTRO-vision-visproslaunch visp_tracker tutorial-nodelet.launch

































"
W546,https://wiki.ros.org/sr_edc_muscle_tools,Wiki,sr_edc_muscle_tools,"

     sr_edc_muscle_tools - Usefull commands and basic demo for the ethercat muscle hand.

  "
W547,https://wiki.ros.org/pr2_calibration_launch,Wiki,pr2_calibration_launch,"Launch files and configuration files needed to run the calibration pipeline on PR2. This package is
     still experimental. Expect large changes tp occur.
"
W548,https://wiki.ros.org/staubli_tx90_support,Wiki,staubli_tx90_support,"
      ROS-Industrial support for the Staubli TX90 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for Staubli TX90 manipulators. This includes the base model,
      as well as models with extended arm and forearm links.
    :
      Joint limits, torque limits, and maximum joint velocities are based on the
      information in the  version .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise (ie: no support for high speed joints, extended /
      limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      : Masses, center of mass and moments of inertia were calculated
      using Solidworks and the official Staubli CAD models, and may not be
      accurate.
    
      : In order to allow maximum torque on axis 6, effort limit on
      axis 5 was set to 29 Nm, rather than a feasible 58 Nm if torque on
      axis 6 = 0 Nm (see superscripts (1) and (2) from table in Section 2.6.2
      -Torque Limits- of the instruction manual for details).
    :
      This support package has received contributions from: Panagiotis 
      Sotiropoulos (Ocado Technology) (TX90/TX90L/TX90XL).
    "
W549,https://wiki.ros.org/basic_states_skill_msgs,Wiki,basic_states_skill_msgs,"basic_states_skill messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""basic_states_skill_msgs"" in rosdoc: /home/rosbot/docs/api/basic_states_skill_msgs/manifest.yaml "
W550,https://wiki.ros.org/nao_extras,Wiki,nao_extras,"
    This stack contains tools for the Nao robot (in addition to the nao_robot stack) to run
  remotely on the PC. It provides teleoperation with a gamepad and path following. Renamed
    from the nao_common stack.
  This stack replaces parts of the  stack since version 0.2. "
W551,https://wiki.ros.org/rtt_geometry_msgs,Wiki,rtt_geometry_msgs,"Provides an rtt typekit for ROS geometry_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/geometry_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W552,https://wiki.ros.org/linksys_access_point,Wiki,linksys_access_point,"
    A ROS node that controls a Linksys access point with
    a Linksys WRT610n-compatible web interface.
  




This package implements the  dynamic_reconfigure interface for controlling an access point for Linksys access points.  txpower_autoFalseManualWireless/Basic Wireless SettingsWi-Fi Protected Setupupdate_configuration()wmmabgnaa-onlyanmixedbb-onlybngg-onlygnmixedlinksys_apcontrol_node.py~interfacestringwl0wl0wl1~ipstring192.168.1.1~userstring~passwordstringadmin"
W553,https://wiki.ros.org/std_msgs,Wiki,std_msgs,"Standard ROS Messages including common message types representing primitive data types and other basic message constructs, such as multiarrays.
    For common, generic robot-specific message types, please see .
 contains wrappers for ROS primitive types, which are documented in the . It also contains the  type, which is useful for sending an empty signal. However, these types do not convey semantic meaning about their contents: every message simply has a field called """". Therefore, while the messages in this package can be useful for quick prototyping, they are . For ease of documentation and collaboration, we recommend that existing messages be used, or new messages created, that provide meaningful field name(s). 

Note that this package also contains the ""MultiArray"" types, which can be useful for storing sensor data. , the same caveat applies: it's usually ""better"" (in the sense of making the code easier to understand, etc.) when developers use or create non-generic message types (see  for more detail). There are currently no plans to add new data types to the  package.  std_msgsEmptydatastd_msgs"
W554,https://wiki.ros.org/ridgeback_bringup,Wiki,ridgeback_bringup,"Scripts for installing Ridgeback's robot software.
See  for information on Ridgeback configurations. "
W555,https://wiki.ros.org/asr_mild_calibration_tool,Wiki,asr_mild_calibration_tool,"A tool to calibrate the relative frames between the mild's laserscanner and the cameras 


  






    
  








This package provides a tool to collect transformation data between the mild's laserscanner sensor and it's camera head. This data can then used calibrate the mild's kinematic chain using the . The calibration object in the form of a could be recognized by a 2D laserscanner and, using its detected edges p, pand p as well as the priorly known proportions, the pose of its top point  can be calculated. All relevant specifications for the calibration object can be retrieved and even changed using the  file. Two  have been integrated into the calibration software: Both the  (left), which is used in the mild platform, as well as the  (right), which has been used for evaluation of the calibration tool, have been integrated into the package and can be selected by changing a single parameter ( The supported types of  units depend on the   package and are described there. All  supported by the  package can be used for calibration. roslaunch asr_mild_calibration_tool calibration_tool.launch"
W556,https://wiki.ros.org/turtlebot_2dnav,Wiki,turtlebot_2dnav,"The turtlebot_2dnav package





The  application can be run with the following command: The  stack that is the core of the turtlebot_2dnav application can be commanded via , , or through code. roslaunch turtlebot_2dnav turtlebot_2dnav.launch map_file:=/my_map.yamlroslaunch turtlebot_rviz_launchers view_navigation.launch --screenroslaunch rosbridge_server rosbridge_websocket.launch"
W557,https://wiki.ros.org/automotive_platform_msgs,Wiki,automotive_platform_msgs,Generic Messages for Communication with an Automotive Autonomous Platform
W558,https://wiki.ros.org/tedusar_box_detection_msgs,Wiki,tedusar_box_detection_msgs,Action definition for the tedusar_box_detection package.
W559,https://wiki.ros.org/spinnaker_sdk_camera_driver,Wiki,spinnaker_sdk_camera_driver,"Point Grey (FLIR) Spinnaker based camera driver (Blackfly S etc.)



  Modify the  file replacing the cam-ids and master cam serial number to match your camera's serial number. Then run the code as: params/test_params.yaml# after installing spinnaker verify that you can run your cameras with SpinView
# after installing ros, install other pre-requisites with:
sudo apt install libunwind-dev ros-kinetic-cv-bridge ros-kinetic-image-transportbash mkdir -p ~/spinnaker_ws/src cd spinnaker_ws/src
git clone https://github.com/neufieldrobotics/spinnaker_sdk_camera_driver.git
cd ~/spinnaker_ws/
catkin_make
source ~/spinnaker_ws/devel/setup.bash
# add this to ~/.bashrc to make this permanentroslaunch spinnaker_sdk_camera_driver acquisition.launch

# Test that the images are being published by running rqt_image_view"
W560,https://wiki.ros.org/staubli,Wiki,staubli,"ROS-Industrial support for Staubli manipulators (metapackage).





Use GitHub to . []
 This repository is part of the  program. It currently contains robot support packages for Staubli manipulators and associated  packages. See the  metapackage for additional packages. See  for a VAL 3 based driver for use with CS8 controllers and Staubli 6-axis manipulators. See the  and the  for more information. For the generic ROS-Industrial tutorials, please see the ROS-Industrial . For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. 





























"
W561,https://wiki.ros.org/termcolor,Wiki,termcolor,C++ library for printing colours in ansii consoles.
W562,https://wiki.ros.org/task_allocation,Wiki,task_allocation,"A package that offers action servers for assigning tasks between cyber physical system (CPS).

 (, default: 1)  (, default: ) 


The communication between CPSs is based on the . The following packages of the  are required: In the  subdirectory there is the parameter file  that allows to configure the behavior of the auction process. This work is supported by the European Commission through the  under grant no. 731946. idintegeroutputstringscreenscreenlogparamtask_allocation.yamlauction_actiontask_allocation_auctioncmd/task_allocation_auction/goalcmd/task_allocation_auction/resultbridge/events/cps_selectioncps_selected~loop_ratereal~queue_sizeinteger~timeoutrealbid_actiontask_allocation_bidcmd/task_allocation_bid/goalcmd/task_allocation_bid/resultpos_provider/posebridge/uuidbridge/events/cps_selectedcps_selection~loop_ratereal~queue_sizeintegerroslaunch task_allocation task_allocation.launch"
W563,https://wiki.ros.org/asr_halcon_bridge,Wiki,asr_halcon_bridge,"This package is used to convert between image-messages of the ROS environment and HALCON-images. 
 







This Package contains a library which is used to convert point clouds and images between ROS and  specific data structures. The structure of this library is mostly based on the -package, for more information you can check out the documentation for that. To be able to build this package and use it in your project you will need to have a version of the  image processing library installed. So far it was tested mainly with version 11 but in theory it should work with higher versions as well as the basic structure of the data types has not changed (build tests have been conducted with version 12 as well). The environment variables  and  need to be set correctly, otherwise cmake won't be able to find your HALCON installation. Usually this should be the case if you have followed the installation guide of HALCON. To convert a  to a  call one of the following functions: The return-value is a object, which contains a-Pointer as a member called . To convert a  to ROS again call one of the following member functions: to convert a  to a (the member in the returned  is called ). HalconImagePtr toHalconCopy(const sensor_msgs::ImageConstPtr& source)
HalconImagePtr toHalconCopy(const sensor_msgs::Image& source);sensor_msgs::ImagePtr toImageMsg() const;
void toImageMsg(sensor_msgs::Image& ros_image) const;HalconPointcloudPtr toHalconCopy(const sensor_msgs::PointCloud2ConstPtr& source);
HalconPointcloudPtr toHalconCopy(const sensor_msgs::PointCloud2& source);sensor_msgs::PointCloud2Ptr toPointcloudMsg() const;
void toPointcloudMsg(sensor_msgs::PointCloud2& ros_pointcloud) const;"
W564,https://wiki.ros.org/stdr_parser,Wiki,stdr_parser,"Provides a library to STDR Simulator, to parse yaml and xml description files.
 is a Yaml/XML parser created for . Its job is to parse resource files (robots and sensors) and create the according stdr_msgs. Also, provided a stdr_msgs message  can save it to a Yaml or XML file. The parser structure is such that it can be ""easily"" extended with more file types (such as JSON f.e.) by changing only specific source files (the filetype parser and writer). A brief overview of the parsing steps follow. 

 takes as input a Yaml or XML file and initially does a ""blind"" parsing of the file, meaning that no validation is performed. Of course if the file does not exist or is malformed, a  is thrown. This initial parsing creates a tree consisting of stdr_parser::Node objects and represents the initial file. As the following sections describe, for convenience reasons you can have  tags in your robot or sensor file, which are used for including  other resources (for example in a robot you can include laser and sonar sensors without writing them from the scratch). During the parsing the specific filenames are parsed also recursively. 























































When a  tag is found, during the parsing step, a stdr_parser::Node is created tagged as . For example a robot XML resource follows: and the  In addition, every  contains a level value that is increased when the recurrent file depth increases. After the first step, the tree will look like that (the levels in [ ]): The second step is to eliminate the  tags from the tree. To do so a sanity check is performed: the parent node and the child node of a  node must be the same. If the above holds, the  node is eliminated, as well as its child and the child's children are connected to 's parent. The result follows: The third step is the recursive node merging. In this step the  file under  is of crucial importance. There, the tags that can have multiple occurrences under a specific tag are placed. The current implementation allows multiple occurrences in these tags: This is the final parsing step where the validation is performed. Crucial role plays the  file under . There for every valid tag, the allowed and required children are specified. (Look at the end of the page for the file's contents). The validation step reads this file and performs  and  checks for all tree nodes.  After the tree is fully created,  can create the according . This is performed seamlessly by using templates. An example of creating a  follows: In a similar way a  message can be saved to a Yaml or XML file: If anything goes wrong an  is thrown. The way to use it in a source code file follows: The  exceptions hold a trail of the error for better debugging. Example: ParserExceptionhokuyo.xmlstdr_parser::Nodefilenamefilenamefilenamefilenamestdr_resources/resources/specificationsstdr_resources/resources/specificationsParserExceptionParserExceptionstdr_specifications.xml<robot>
  <robot_specifications>
    <footprint>
      <radius>0.3</radius>
    </footprint>
    <laser>
      <filename>hokuyo.xml</filename>
      <laser_specifications>
        <pose>
          <theta>1.57</theta>
        </pose>
      </laser_specifications>
    </laser>
  </robot_specifications>
<robot><laser>
  <laser_specifications>
    <max_range>4</max_range>
    <pose>
      <x>0</x>
      <y>0</y>
      <theta>0</theta>
    </pose>
    <noise>
      <filename>gauss_small.xml</filename>
    </noise>
  </laser_specifications>
</laser><noise>
  <noise_specifications>
    <noise_mean>0</noise_mean>
    <noise_std>0.03</noise_std>
  </noise_specifications>
</noise>├ robot [0]
│ ├ robot_specifications [0]
│ │ ├ footprint [0]
│ │ │ ├ radius [0]
│ │ │ │ ├ 0.3 [0]
│ │ ├ laser [0]
│ │ │ ├  filename [0]
│ │ │ │ ├ laser [1]
│ │ │ │ │ ├ laser_specifications [1]
│ │ │ │ │ │ ├ max_range [1]
│ │ │ │ │ │ │ ├ 4 [1]
│ │ │ │ │ │ ├ pose [1]
│ │ │ │ │ │ │ ├ x [1]
│ │ │ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ │ │ ├ y [1]
│ │ │ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ │ │ ├ theta [1]
│ │ │ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ │ ├ noise [1]
│ │ │ │ │ │ │ ├ filename [1]
│ │ │ │ │ │ │ │ ├ noise [2]
│ │ │ │ │ │ │ │ │ ├ noise_specifications [2]
│ │ │ │ │ │ │ │ │ │ ├ noise_mean [2]
│ │ │ │ │ │ │ │ │ │ │ ├ 0 [2]
│ │ │ │ │ │ │ │ │ │ ├ noise_std [2]
│ │ │ │ │ │ │ │ │ │ │ ├ 0.03 [2]
│ │ │ ├ laser_specifications [0]
│ │ │ │ ├ pose [0]
│ │ │ │ │ ├ theta [0]
│ │ │ │ │ │ ├ 1.57 [0]├ robot [0]
│ ├ robot_specifications [0]
│ │ ├ footprint [0]
│ │ │ ├ radius [0]
│ │ │ │ ├ 0.3 [0]
│ │ ├ laser [0]
│ │ │ ├ laser_specifications [1]
│ │ │ │ ├ max_range [1]
│ │ │ │ │ ├ 4 [1]
│ │ │ │ ├ pose [1]
│ │ │ │ │ ├ x [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ y [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ theta [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ ├ noise [1]
│ │ │ │ │ ├ noise_specifications [2]
│ │ │ │ │ │ ├ noise_mean [2]
│ │ │ │ │ │ │ ├ 0 [2]
│ │ │ │ │ │ ├ noise_std [2]
│ │ │ │ │ │ │ ├ 0.03 [2]
│ │ │ ├ laser_specifications [0]
│ │ │ │ ├ pose [0]
│ │ │ │ │ ├ theta [0]
│ │ │ │ │ │ ├ 1.57 [0]├ robot [0]
│ ├ robot_specifications [0]
│ │ ├ footprint [0]
│ │ │ ├ radius [0]
│ │ │ │ ├ 0.3 [0]
│ │ ├ laser [0]
│ │ │ ├ laser_specifications [1]
│ │ │ │ ├ max_range [1]
│ │ │ │ │ ├ 4 [1]
│ │ │ │ ├ pose [1]
│ │ │ │ │ ├ x [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ y [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ theta [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ │ ├ 1.57 [0]
│ │ │ │ ├ noise [1]
│ │ │ │ │ ├ noise_specifications [2]
│ │ │ │ │ │ ├ noise_mean [2]
│ │ │ │ │ │ │ ├ 0 [2]
│ │ │ │ │ │ ├ noise_std [2]
│ │ │ │ │ │ │ ├ 0.03 [2]├ robot [0]
│ ├ robot_specifications [0]
│ │ ├ footprint [0]
│ │ │ ├ radius [0]
│ │ │ │ ├ 0.3 [0]
│ │ ├ laser [0]
│ │ │ ├ laser_specifications [1]
│ │ │ │ ├ max_range [1]
│ │ │ │ │ ├ 4 [1]
│ │ │ │ ├ pose [1]
│ │ │ │ │ ├ x [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ y [1]
│ │ │ │ │ │ ├ 0 [1]
│ │ │ │ │ ├ theta [1]
│ │ │ │ │ │ ├ 1.57 [0]
│ │ │ │ ├ noise [1]
│ │ │ │ │ ├ noise_specifications [2]
│ │ │ │ │ │ ├ noise_mean [2]
│ │ │ │ │ │ │ ├ 0 [2]
│ │ │ │ │ │ ├ noise_std [2]
│ │ │ │ │ │ │ ├ 0.03 [2]stdr_msgs::RobotMsg msg = stdr_parser::Parser::createMessage<stdr_msgs::RobotMsg>(""simple_robot.yaml"");stdr_msgs::RobotMsg msg = stdr_parser::Parser::createMessage<stdr_msgs::RobotMsg>(""simple_robot.yaml"");
stdr_parser::Parser::saveMessage(msg,""test.xml"");  try
  {
    stdr_parser::Parser::saveMessage(
      stdr_parser::Parser::createMessage
      <stdr_msgs::RobotMsg>      //!< Type
      (""pandora_robot.yaml""),    //!< Input file
      ""test.xml""            //!< Output file
    );
  }
  catch(ParserException ex)
  {
    ROS_ERROR("" === STDR PARSER ERROR ===\n%s"",ex.what());
  }STDR parser : noidse_mean is not allowed in a noise_specifications tag
Trail: 
  [noidse_mean] Line 17 of file 'hokuyo_laser_4L.xml'
  [noise] Line 16 of file 'hokuyo_laser_4L.xml'
  [laser_specifications] Line 14 of file 'hokuyo_laser_4L.xml'
  [laser] Line 14 of file 'pandora_robot.xml'
  [robot_specifications] Line 52 of file 'pandora_robot.xml'
  [robot] Line 2 of file 'pandora_robot.xml'
  [STDR_Parser_Root_Node] Line 1 of file 'pandora_robot.xml'noise:
  noise_specifications:
    mean: 0.5
    std: 0.200000002980232footprint:
  footprint_specifications:
    radius: 0.5laser:
  laser_specifications:
    max_angle: 2.35619258880615
    min_angle: -2.35619258880615
    max_range: 4
    min_range: 0
    num_rays: 270
    noise:
      noise_specifications:
        mean: 0.5
        std: 0.200000002980232
    frequency: 10
    frame_id: laser_0
    pose:
      x: 0.100000001490116
      y: 0
      theta: 0sonar:
  sonar_specifications:
    max_range: 3
    min_range: 0.300000011920929
    cone_angle: 0.523598313331604
    noise:
      filename: noises/noise_gauss.yaml
    frequency: 10
    frame_id: sonar_0
    pose:
      x: 0.100000001490116
      y: 0
      theta: 0robot:  
  robot_specifications:
    - footprint:
        footprint_specifications:
          radius: 0.15
    - initial_pose:
        theta: 0
        x: 0
        y: 0
    - laser:
        filename: laser_sensors/hokuyo_laser_4L.yaml
        laser_specifications: 
          max_range: 10
    - sonar:
        filename: range_sensors/standard_sonar.yaml
        sonar_specifications:
          frame_id: sonar_0
          pose:
            x: 0.100000001490116
            y: 0
            theta: 0
    - sonar:
        filename: range_sensors/standard_sonar.yaml
        sonar_specifications:
          frame_id: sonar_1
          pose:
            x: 0
            y: 0.100000001490116
            theta: 1.570795
    - sonar:
        filename: range_sensors/standard_sonar.yaml
        sonar_specifications:
          frame_id: sonar_2
          pose:
            x: 0
            y: -0.100000001490116
            theta: -1.570795
    - sonar:
        filename: range_sensors/standard_sonar.yaml
        sonar_specifications:
          frame_id: sonar_3
          pose:
            x: -0.100000001490116
            y: -0.100000001490116
            theta: 2.79252444444444
    - sonar:
        filename: range_sensors/standard_sonar.yaml
        sonar_specifications:
          frame_id: sonar_4
          pose:
            x: -0.100000001490116
            y: 0.100000001490116
            theta: 3.49065555555556<noise>
  <noise_specifications>
    <noise_mean>0.1</noise_mean>
    <noise_std>0.01</noise_std>
  </noise_specifications>
</noise><footprint>
  <footprint_specifications>
    <radius>0.5</radius>
  </footprint_specifications>
</footprint><laser>
  <laser_specifications>
    <max_angle>1.570795</max_angle>
    <min_angle>-1.570795</min_angle>
    <max_range>4.0</max_range>
    <min_range>0.1</min_range>
    <num_rays>270</num_rays>
    <frequency>10</frequency>
    <pose>
      <x>0</x>
      <y>0</y>
      <theta>0</theta>
    </pose>
    <noise>
      <filename>noises/noise_gauss.xml</filename>
      <noise_specifications>
        <noise_mean>0.5</noise_mean>
        <noise_std>0.05</noise_std>
      </noise_specifications>
    </noise>
  </laser_specifications>
</laser><sonar>
  <sonar_specifications>
    <cone_angle>0.87</cone_angle>
    <max_range>3.0</max_range>
    <min_range>0.15</min_range>
    <frequency>10</frequency>
    <pose>
      <x>0.1</x>
      <y>0</y>
      <theta>0</theta>
    </pose>
    <noise>
      <filename>noises/noise_gauss.xml</filename>
    </noise>
  </sonar_specifications>
</sonar><robot>
  <robot_specifications>
    <footprint>
      <footprint_specifications>
        <radius>0.2</radius>
      </footprint_specifications>
    </footprint>
    <initial_pose>
      <x>0</x>
      <y>0</y>
      <theta>0</theta>
    </initial_pose>
    <laser>
      <filename>laser_sensors/hokuyo_laser_4L.xml</filename>
    </laser>
    <sonar>
      <filename>range_sensors/standard_sonar.xml</filename>
      <sonar_specifications>
        <pose>
          <x>0.1</x>
        </pose>
      </sonar_specifications>
    </sonar>
    <sonar>
      <filename>range_sensors/standard_sonar.xml</filename>
      <sonar_specifications>
        <pose>
          <y>0.1</y>
          <theta>1.570795</theta>
        </pose>
      </sonar_specifications>
    </sonar>
    <sonar>
      <filename>range_sensors/standard_sonar.xml</filename>
      <sonar_specifications>
        <pose>
          <y>-0.1</y>
          <theta>-1.570795</theta>
        </pose>
      </sonar_specifications>
    </sonar>
    <sonar>
      <filename>range_sensors/standard_sonar.xml</filename>
      <sonar_specifications>
        <pose>
          <x>-0.1</x>
          <y>-0.1</y>
          <theta>2.79252444444444</theta>
        </pose>
      </sonar_specifications>
    </sonar>
    <sonar>
      <filename>range_sensors/standard_sonar.xml</filename>
      <sonar_specifications>
        <pose>
          <x>-0.1</x>
          <y>0.1</y>
          <theta>3.49065555555556</theta>
        </pose>
      </sonar_specifications>
    </sonar>
  </robot_specifications>
</robot>"
W565,https://wiki.ros.org/sr_gui_grasp_controller,Wiki,sr_gui_grasp_controller,"

     sr_gui_grasp_controller - gui plugin for interpolating between grasps.

   You can also save a current hand pose (obtained either by interpolating between two grasps, or by moving then hand with the sliders) by clicking on the  button. "
W566,https://wiki.ros.org/teraranger_array,Wiki,teraranger_array,"This package provides ros nodes for multi-sensor arrays from Terabee 




 * * * * * /ranges/imu_euler/imu_quat_portnamestr, default: ""/dev/ttyACM0""_baudrateint, default: ""115200""~Rate_enumint~Sequence_mode_enumint~IMU_enumint~Sensor_typeint/ranges_portnamestr, default: ""/dev/ttyACM0""~Modeint/ranges_portnamestr, default: ""/dev/ttyACM0""~Sensor_Xboolrosrun teraranger_array <teraranger_one|teraranger_multiflex> [_portname:=<device_path>]"
W567,https://wiki.ros.org/rc_roi_manager_gui,Wiki,rc_roi_manager_gui,"The ros client for the region of interest manager of the itempick and boxpick modules




Use GitHub to . []
  
See  and  for more details. For the  module: For the  module: device02912345:02912345$ roslaunch rc_roi_manager_gui interactive_roi_selection.launch device:=:<serial_number> pick_module=rc_itempick$ roslaunch rc_roi_manager_gui interactive_roi_selection.launch device:=:<serial_number> pick_module=rc_boxpick"
W568,https://wiki.ros.org/asr_descriptor_surface_based_recognition,Wiki,asr_descriptor_surface_based_recognition,"This package contains a 6-DoF object localizer for textured household objects 













This package contains an object localization system that returns 6-DoF poses for textured objects in RGBD-data.  There are two types of parameters which can be set, static and dynamic ones. The static ones can be found in the .yaml file in the param-directory and the dynamic ones in the launch-file (or during runtime by using ). roslaunch asr_descriptor_surface_based_recognition descriptor_surface_based_recognition.launch"
W569,https://wiki.ros.org/tf_publisher_gui,Wiki,tf_publisher_gui,"This is a simple GUI for publishing a single TF transform.
 

~ratedouble~parent_framestring~child_framestring~parent_frame~child_framerosrun tf_publisher_gui tf_publisher_gui _parent_frame:=/odom_combined _child_frame:=/head_mount_kinect_link"
W570,https://wiki.ros.org/blort_msgs,Wiki,blort_msgs,This package defines messages used by BLORT ROS interface
W571,https://wiki.ros.org/automotive_navigation_msgs,Wiki,automotive_navigation_msgs,Generic Messages for Navigation Objectives in Automotive Automation Software
W572,https://wiki.ros.org/vrep_ros_bridge,Wiki,vrep_ros_bridge,"The main application of the plugin is to provide a communication interface between V-Rep and (ROS). The aim is to control the V-Rep simulation externally using ROS messages and ROS services.
   
 is a plugin for V-Rep developed by the Inria  team located at . , developed by , is an open-source state-of-the-art (and freely available for academic use) 3D physical simulation engine which is becoming more and more widespread in the robotics community thanks to its flexibility (possibility to simulate many different robotic platforms), dynamical engine (it supports ODE, Bullet and Vortex), and finally customizability (it offers many different possibilities to include one's own code or to interface it with the external world). 
 




 ROS V-Rep Bridge uses the  package. Pluginlib is a C++ library for loading and unloading plugins from within a ROS package. Plugins are dynamically loadable classes that are loaded from a runtime library (i.e. shared object, dynamically linked library). In this way our handlers are actually plugins with some dependencies. If we don't need a handler or we don't have installed its dependencies we are still able to build our bridge (that plugin will not be available). For example, the  needs . If we don't want to install Telekyb we can just add a file called CATKIN_IGNORE in the quadrotor_tk_handler folder and it will not be considered. In spite of this the other handlers will be available. We have an object in the scene (let's say a quadrotor) and we want that the plugin  manage it. To do it we will have to tag the object with a predefined string. If we don't do it the plugin will not act on the object. We will show how to tag a quadrotor but the procedure for the other objects will be similar. The function 'simExtSetFloatCustomDataFromHeader()' adds a custom data to the object related to 'sim_ext_ros_bridge_set_obj_twist_data_main'. As we can see, the function requires a third input. If requested, we can add a value to our custom data, setting the third input of the function. In our case, since we don't want to use this additional parameter we set it to zero (it will be ignored). We can add float and int values. If you want to add an int value you have to use the function 'simExtSetIntCustomDataFromHeader()'. You can find the list of the Custom Lua Variables in the description of each handler. Moreover you will find the complete list in the file  (From line 149). In certain case the third values will be important (for instance to set the frequency of the camera acquisition). You will find more information about these commands in each wiki.ros page dedicated to the packages. You will find a guide for the installation in the . You can find info about this demo . if (simGetScriptExecutionCount()==0) then
-- Put your Initialization code, executed only once (at the beginning of the simulation)
end

simHandleChildScript(sim_handle_all_except_explicit)

-- Put your main code here. It will act at each iteration of the simulation.

if (simGetSimulationState()==sim_simulation_advancing_lastbeforestop) then
-- Put some restoration code here
endquadrotor = simGetObjectAssociatedWithScript(sim_handle_self)
simExtSetFloatCustomDataFromHeader(quadrotor, sim_ext_ros_bridge_quadrotor_data_main, 0.0) Add-on script 'vrepAddOnScript-addOnScriptDemo.lua' was loaded.
 Simulator launched.
 (...)
 Plugin 'RosBridge': loading...
 Plugin 'RosBridge': load succeeded.
 (...) rqt_graph rostopic list /command/quadrotor_0
 /rosout
 /rosout_agg
 /tf
 /vrep/IMU/quadrotor_0
 /vrep/Vision_sensor_0
 /vrep/Vision_sensor_0/Camerainfo
 /vrep/Vision_sensor_0/compressed
 /vrep/Vision_sensor_0/compressed/parameter_descriptions
 /vrep/Vision_sensor_0/compressed/parameter_updates
 /vrep/Vision_sensor_0/compressedDepth
 /vrep/Vision_sensor_0/compressedDepth/parameter_descriptions
 /vrep/Vision_sensor_0/compressedDepth/parameter_updates
 /vrep/Vision_sensor_0/theora
 /vrep/Vision_sensor_0/theora/parameter_descriptions
 /vrep/Vision_sensor_0/theora/parameter_updates
 /vrep/base/pose
 /vrep/camera_info
 /vrep/end_eff/pose
 /vrep/info
 /vrep/pose/quadrotor_0
 /vrep/twist/quadrotor_0
 /vrep/viper_0/jointCommand
 /vrep/viper_0/jointStatus"
W573,https://wiki.ros.org/tuw_marker_server,Wiki,tuw_marker_server,"The tuw_marker_server package contains a map server for saving and providing marker maps based on MarkerWithCovarianceArray messages from the marker_msgs package.








mapmapfilestring""map.yaml""tuw_marker_servermapmapfilestringframe_idstring""map""rosrun tuw_marker_server tuw_marker_saver.pyroslaunch tuw_marker_server saver.launchrosrun tuw_marker_server tuw_marker_server.pyroslaunch tuw_marker_server server.launch"
W574,https://wiki.ros.org/rosserial_embeddedlinux,Wiki,rosserial_embeddedlinux,"rosserial for embedded Linux enviroments
 



There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the  support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  Using the  package, you can use ROS directly with the these systems.  provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. The  package supports the following major connection types and capabilities: This package contains embedded-linux-specific extensions required to run  on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  Go to the  to learn how to install and use the package to connect your embedded linux system to ROS. Please file new bugs on the project's . The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "
W575,https://wiki.ros.org/tuw_ellipses,Wiki,tuw_ellipses,"The tuw_ellipses package contains a computer vision library which is able to detect ellipses within images.  
    The package is able to estimate the pose of the circle related to the ellipse the circle diameter as well as the camera parameter are known.
    A dynamic reconfigure interface allows the user to tune the parameter of the system to ones needs.
    But be aware that the pose of a projected circle within a image (ellipse) has two solutions and only one is published as TF.


This package detects ellipses in camera images and computes the 3D pose of the related circle if the radius of the circle is given. The current 3D pose estimation is based on the [Chen2004] and the successor of the   package. Various Parameter and algorithm used to find ellipses can be tuned via ROS shared parameters or by using the dynamic reconfigure interface. Chen2004) Chen, Q.; Wu, H. & Wada, T. Pajdla, T. & Matas, J. (Eds.) Camera Calibration with Two Arbitrary Coplanar Circles Computer Vision - ECCV 2004, Springer Berlin Heidelberg, 2004, 3023, 521-532,   rosrun tuw_ellipses tuw_ellipses_node image:=/camera/image_raw camera_info:=/camera/camera_inforosrun rqt_reconfigure rqt_reconfigure"
W576,https://wiki.ros.org/graspdb,Wiki,graspdb,"Grasp Training SQL Database Client Library









"
W577,https://wiki.ros.org/svenzva_moveit,Wiki,svenzva_moveit,An automatically generated package with all the configuration and launch files for using the revel with the MoveIt! Motion Planning Framework
W578,https://wiki.ros.org/sr_hand,Wiki,sr_hand,"

     This is a ROS interface to the Shadow Robot's robotic hand. It
     contains both an interface to the real hand (communicating via
     a CAN interface) and a simulated version of the hand. It also
     contains an interface to Shadow Robot's muscle arm.

  
This package provides a ROS interface to the . Its aim is not only to provide a complete ROS integration to our hardware, but also to provide the user with a simulated and a dummy interface (the dummy interface is a really simple simulated interface, without any physics computation). Changing between those 3 interfaces is transparent for the end user, thus allowing you to test your algorithm in simulation, and then run them on the real hardware without changing any code. This package also provides a (deprecated) compatibility interface for the . For more information, you can have a look at this . 
Here is an overview of the ROS system:  As you can see, the topics are similar on the arm and hand.  
: The sendupdate message is defined in . It is used to send one or a vector of new targets to the robot. For an example on how to publish on this topic, please refer to the  tutorial. : The contrlr message is defined in . This topic is used to set new controller parameters when you use our real hardware. To see how to publish on this topic, go to the  tutorial.  
: Publish a /joint_states message containing the current positions of the robot. A  subscribes to this topic, in order to publish to the  topic, with a  prefix.  : Publish a /joint_states message containing the current targets for the robot. This is not so important, but it can be used to  in rviz. A  subscribes to this topic, in order to publish to the  topic, with a  prefix.  : This topic publishes more information than the  topics. It's based on the /joints_data. There is a duplication of the information sent on those topics, but we can't really get rid of any of them as they may be needed in different situations. : Diagnostics data (motor status, etc...) are published on this topic, and then aggregated by a . You can look at the diagnostics using the . 
You can specify the following parameters for the Hand or for the Arm: : You can change the publishing frequency of the main robot data ( and ). Default is 20Hz. : You can change the rate at which diagnostics are being published for the robot. Default is 1Hz. : If using gazebo, what's the prefix of the joint_states published by gazebo. 
Please refer to the  page. 
We always welcome contributions. If you want to contribute, please refer to the  stack. "
W579,https://wiki.ros.org/people_tracking_filter,Wiki,people_tracking_filter,"A collection of filtering tools for tracking people's locations
"
W580,https://wiki.ros.org/pr2_calibration,Wiki,pr2_calibration,"The pr2_calibration package




 The following aspects of the PR2 are  calibrated by the pr2_calibration stack Follow instructions in the  Tutorial. The algorithm implemented in this stack is described in the following paper: 
  "
W581,https://wiki.ros.org/xbot_node,Wiki,xbot_node,"ROS nodelet for Xbot: ROS wrapper for the Xbot driver.

xbot_node功能包为提供ROS API。 /commands/motor_disable/commands/velocity/commands/yaw_platform/commands/pitch_platform/commands/sound_enable/commands/led/commands/lift/commands/reset_odometry/joint_states/sensors/core/sensors/extra/sensors/yaw_platform_degree/sensors/pitch_platform_degree/sensors/motor_disabled/sensors/sound_enabled/sensors/battery/sensors/echo/sensors/infrared/sensors/imu_data/sensors/raw_imu_data/xbot/state/commands/velocity/xbot/chat~base_pathstring""$(find xbot_talker)"""
W582,https://wiki.ros.org/rsv_balance,Wiki,rsv_balance,Common packages for RoboSavvy's balancing platform's  common package.  Tutorials . 
W583,https://wiki.ros.org/pysdf,Wiki,pysdf,"Python library to parse SDF into class hierarchy and export URDF
check_urdf"
W584,https://wiki.ros.org/ndt_map,Wiki,ndt_map,"

     Contains the definitions of the 3D Normal Distributions Transform data structures, 
     used for mapping, registration, etc.

  




NDT maps can be created either using a regular grid data structure () or using an irregular grid (). The recommended mode is to use , as most of the subsequent algorithms have been optimized for that data structure.  

















"
W585,https://wiki.ros.org/srv_tools,Wiki,srv_tools,"Stack with interesting ROS tools



  cd catkin_ws/src
mkdir srv_tools
cd srv_tools
git clone https://github.com/srv/srv_tools.git .
cd ../..
rosdep install --from-paths src --ignore-src --rosdistro kinetic # install dependencies
catkin_make"
W586,https://wiki.ros.org/wpi_jaco_msgs,Wiki,wpi_jaco_msgs,"Messages Used with the JACO ArmNewly proposed, mistyped, or obsolete package. Could not find package ""wpi_jaco_msgs"" in rosdoc: /home/rosbot/docs/api/wpi_jaco_msgs/manifest.yaml "
W587,https://wiki.ros.org/jsk_footstep_msgs,Wiki,jsk_footstep_msgs,jsk_footstep_msgs
W588,https://wiki.ros.org/canopen_master,Wiki,canopen_master,"CiA(r) CANopen 301 master implementation with support for interprocess master synchronisation.











canopen::SimpleMaster::Allocatorcanopen::ExternalMaster::Allocatorcanopen::SharedMaster::Allocatorcanopen::UnrestrictedMaster::Allocatorcanopen::LocalMaster::Allocator"
W589,https://wiki.ros.org/summit_xl_navigation,Wiki,summit_xl_navigation,"Navigation launch and config files for Summit XL robot.
"
W590,https://wiki.ros.org/canopen_402,Wiki,canopen_402,"This implements the CANopen device profile for drives and motion control. CiA(r) 402
 


  

 This package contains the implementation of the CiA 402 DSP protocol. It just communicates via objects (, no direct CAN communication is needed. "
W591,https://wiki.ros.org/asr_flir_ptu_driver,Wiki,asr_flir_ptu_driver,"asr_flir_ptu_driver is a package for controlling a flir ptu via (external) msg
     authors: Valerij Wittenbeck, Joachim Gehrung, Pascal Meissner, Patrick Schlosser 
 









 
  
                                       

 
Using the ptu_left.launch launchfile the topics shown below will be found under . Using the ptu_left.launch launchfile the topics shown below will be found under . Using the ptu_left.launch launchfile all parameters shown below will be found under . There are no external services needed. Nevertheless, if the GUI is used, it uses a few services offered by the driver, therefore always start  before  Using the ptu_left.launch launchfile the services shown below will be found under . needs to be invoked from the terminal to start the PTU. Make sure it is connected. Configure the forbidden areas in the as you need them (details on forbidden areas in Chapter 2). Then continue with the tutorials below: roslaunch asr_flir_ptu_driver ptu_gui.launchroslaunch asr_flir_ptu_driver ptu_gui.launch path_prediction:=trueroslaunch asr_flir_ptu_driver ptu_left_mock.launchroslaunch asr_flir_ptu_driver ptu_left.launchroslaunch asr_flir_ptu_driver ptu_left.launch"
W592,https://wiki.ros.org/segbot_gazebo,Wiki,segbot_gazebo,bwi_gazebo
W593,https://wiki.ros.org/turtlebot3_automatic_parking,Wiki,turtlebot3_automatic_parking,"Package for turtlebot3 automatic_parking. You need a reflective tape and real robots. You can see parking spot using this pacakge on rviz. 


scanodomcmd_velscan_spotreset"
W594,https://wiki.ros.org/tuw_marker_detection,Wiki,tuw_marker_detection,The tuw_marker_detection package
W595,https://wiki.ros.org/pr2_arm_ik_tests,Wiki,pr2_arm_ik_tests,"

     pr2_arm_ik_tests

  "
W596,https://wiki.ros.org/toposens_pointcloud,Wiki,toposens_pointcloud,"PCL integration for TS sensors mounted on Turtlebot3.



This package enables conversion of messages of type  into messages of type . Due to the specular reflection behavior of ultrasound, the surface normal of the detected object can be represented by a vector pointing from the detected point towards the sensor’s position while the point was recorded. This normal vector is added to the  representation. For a more detailed explanation of the physics behind Toposens sensors see . ts_scansts_cloudts_cloud_normals~scans_topicstd_msgs/String~target_framestd_msgs/String~pcd_save_intervalint~pcd_pathstd_msgs/String~lifetime_normals_visfloat"
W597,https://wiki.ros.org/nao_control,Wiki,nao_control,The nao_control packageIs used within  and  packages  
W598,https://wiki.ros.org/ros3djs_experimental,Wiki,ros3djs_experimental,The ros3djs_experimental package
W599,https://wiki.ros.org/rostopic,Wiki,rostopic,"rostopic contains the rostopic command-line tool for displaying
    debug information about
    ROS , including
    publishers, subscribers, publishing rate,
    and ROS . It also
    contains an experimental Python library for getting information about
    and interacting with topics dynamically. This library is for
    internal-use only as the code API may change, though it does provide
    examples of how to implement dynamic subscription and publication
    behaviors in ROS.
, like several other ROS tools, uses YAML-syntax at the command line for representing the contents of a message. For information on how to use this YAML syntax for commands like , please see the  guide. 









 is a stable command-line tool within the ROS core toolchain. The underlying code may undergo refactoring for easier library use, but the external API is expected to be fairly stable. The  command-line tool displays information about ROS topics. Currently, it can display a list of active topics, the publishers and subscribers of a specific topic, the publishing rate of a topic, the bandwidth of a topic, and messages published to a topic. The display of messages is configurable to output in a plotting-friendly format. or on Windows  Publish a geometry_msgs/Twist message with a rate of 10Hz.   One area in which  is expected to see development is with the output format of  and input format of . The planned feature is to make both compatible with YAML syntax, which will enable rostopicrostopicrostopic pubbw <topic-name>delay <topic-name>echo <topic-name>--offset--filtermframe_id-c-p-b-p-c-w NUM_WIDTH--nostr--noarr-n COUNTecho <topic-name/field>find <msg-type>hz <topic-name>-w-w WINDOW_SIZE--filter FILTER_EXPRinfo <topic-name>listlist <namespace>rostopic info-b-p-s-v--hostpub <topic-name> <topic-type> [data...]rostopic/topic_namerostopicctrl-Cctrl-Crostopicrostopic-r 10-l, --latch-r RATE-1--once-f FILErostopic echo-----latchtype <topic-name>rostopicrostopicrostopic echorostopic pubrostopic bw     display bandwidth used by topic
rostopic delay display delay for topic which has header
rostopic echo   print messages to screen
rostopic find   find topics by type
rostopic hz     display publishing rate of topic
rostopic info   print information about active topic
rostopic list   print information about active topics
rostopic pub    publish data to topic
rostopic type   print topic type$ rostopic bw /topic_name$ rostopic delay /topic_name$ rostopic echo /topic_name$ rostopic echo --offset /topic_name$ rostopic echo --filter ""m.data=='foo'""  /topic_name$ rostopic echo --filter ""m.transforms[0].child_frame_id == 'my_frame'"" /tf$ rostopic echo -c /topic_name$ rostopic echo -b log_file.bag /topic_name$ rostopic echo -p /topic_name$ rostopic echo -p --nostr --noarr /topic_name$ rostopic echo /my_topic/field_name$ rostopic find std_msg/String$ rostopic hz /topic_name$ rostopic info clock$ rostopic list$ rostopic list /namespace$ rostopic list -v$ rostopic pub /topic_name std_msgs/String hello$ rostopic pub my_topic std_msgs/String ""hello there""$ rostopic echo chatter | rostopic pub bar std_msgs/String$ rostopic echo chatter > chatter.bagy
Collect messages, then Ctrl-C
$ rostopic pub -f chatter.bagy bar std_msgs/String$ rostopic pub -r 10 /cmd_vel geometry_msgs/Twist  '{linear:  {x: 0.1, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0,z: 0.0}}'$ rostopic pub -r 10 /cmd_vel geometry_msgs/Twist  ""{linear:  {x: 0.1, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0, z: 0.0}}""$ rostopic type /topic_name$ rostopic type /topic_name | rosmsg show"
W600,https://wiki.ros.org/laser_pipeline,Wiki,laser_pipeline,"Meta-package of libraries for processing laser data, including converting laser data
      into 3D representations.

 

   The  stack is intended to do the necessary processing to get from the output of a scanning laser rangefinder to a more useful 3D representation of a point cloud.  This processing takes three distinct steps: For an end-user higher up the system, the  is actually capable of performing all 3 of these steps, implementing an arbitrary filter chain on its input, performing a high-fidelity transformation to a point cloud internally, and then making clouds available via a . Point clouds generated using the laser pipeline results in a  or ()  message.  This point cloud can have the following channels attached to it: The  assumes that you have a scanning laser rangefinger.  The most common examples of these are the Hokuyo UTM and the Sick LMS.  The  stack provides drivers for these particular models.  However, any driver which outputs the , including , can be used as the input to this pipeline. laser_pipeline""intensities""""index""""distances""""stamps""laser_pipeline"
W601,https://wiki.ros.org/katana,Wiki,katana,"This package provides ROS interfaces to the Neuronics Katana 450 arm.
    It wraps the  library for low-level communication
    with the Katana arm.

This package provides the  ROS node, which provides four sets of functionality at once: the , the , the  and the . They are combined into one single node for technical reasons (only one single process can access the Katana), but documented separately below for clarity. Also there is a second node in this package, called , documented at the end. katanajoint_state_publisherjoint_movement_controllerjoint_trajectory_action_controllergripper_grasp_controllerkatana_arm_kinematicsswitch_motors_offswitch_motors_ontest_speed~simulationboolfalsekatana_jointsArray of stringskatana_gripper_jointsArray of stringsrobot_descriptionString~use_serialboolfalsetrue~ipString~portint~serial_portint/dev/ttyUSB3~serial_port~config_file_pathStringkatana_typestringkatana_300_6m180katana_400_6m180katana_450_6m90akatana_450_6m90bjoint_stateskatana_arm_controller/joint_movement_action/goalkatana_arm_controller/joint_movement_action/resultkatana_arm_controller/joint_movement_action/feedbackcommandstatequery_statekatana_arm_controller/joint_trajectory_action/goalkatana_arm_controller/joint_trajectory_action/resultkatana_arm_controller/joint_trajectory_action/feedbackkatana_arm_controller/commandkatana_arm_controller/statequery_statejoint_trajectory_action_node/constraints/<joint>/goaldoublejoint_trajectory_action_node/constraints/stopped_velocity_tolerancedoubleposture_action_name/goalposture_action_name/resultgrasp_query_name~gripper_object_presence_thresholddoubleget_kinematic_solver_infoget_fkget_ik~config_file_pathStringrobot_descriptionStringkatana_jointsArray of strings"
W602,https://wiki.ros.org/puma_motor_driver,Wiki,puma_motor_driver,"A ROS driver for Puma single-channel motor control board.
"
W603,https://wiki.ros.org/turtlebot3_applications_msgs,Wiki,turtlebot3_applications_msgs,"Message and service types: custom messages and services for TurtleBot3 Applications packages 


"
W604,https://wiki.ros.org/rosh_core,Wiki,rosh_core,"
     Main ROSH scripting and interpreter environment.
  

  "
W605,https://wiki.ros.org/turtlebot_arm,Wiki,turtlebot_arm,"The turtlebot arm meta package.
 - Bill of materials and instructions on how to assemble the hardware for the  arm. 
 - Instructions for installing the  stack and dependencies.  - Instructions for numbering the Dynamixel servos correctly. 
 - A tutorial explaining how to calibrate the physical position of a kinect to the arm for more precise manipulation.  - controlling the arm through rviz.  - A tutorial for setting up a demo to move small blocks around a surface using the arm.   

Use GitHub to . []
 
The  arm is a low-cost arm that you can build and mount on the  to give it some basic manipulation capabilities. Kinetic release is pending on . "
W606,https://wiki.ros.org/pr2_delivery,Wiki,pr2_delivery,"This package contains scripts for making a PR2 deliver a small
  object from one place to another, and return to a home base.See:  "
W607,https://wiki.ros.org/rosserial_xbee,Wiki,rosserial_xbee,"Allows multipoint communication between rosserial
     nodes connected to an xbee. All nodes communicate back
     to a master xbee connected to a computer running ROS.

     This software currently only works with Series 1 Xbees.

     This pkg includes python code from the python-xbee project:
     http://code.google.com/p/python-xbee/ 

 ./setup_xbee.py [options] port my_adr

    port :    serial port of port of the xbee (/dev/ttyUSB0)
    my_adr:   MY address is the 16 bit address of this xbee in the
              network. This must be a unique address in the network.
              This address is always 0 for the coordinator.

Options:
  -h, --help            show this help message and exit
  -P PAN_ID, --pan_id=PAN_ID
                        Pan ID of the xbee network.  This ID must be the same
                        for all XBees in your network.
  -c CHANNEL, --channel=CHANNEL
                        Frequency channel for the xbee network. The channel
                        value must be the same for all XBees in your network.
  -C, --coordinator     Configures the XBee as Coordinator for the network.
                        Only make the XBee connected to the computer a
                        coordiantor./xbee_network.py <xbee_serial_port> ID1 [ ID2 ID3 ....]"
W608,https://wiki.ros.org/katana_arm_gazebo,Wiki,katana_arm_gazebo,This package starts a Neuronics Katana robot arm in the Gazebo simulation environment. It is modeled after the  package by John Hsu.
W609,https://wiki.ros.org/widowx_arm,Wiki,widowx_arm,"The widowx_arm package
 


This package contains the different controllers and description files for  "
W610,https://wiki.ros.org/widowx_arm_description,Wiki,widowx_arm_description,"The widowx_arm_description package
"
W611,https://wiki.ros.org/rtt_sensor_msgs,Wiki,rtt_sensor_msgs,"Provides an rtt typekit for ROS sensor_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/sensor_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W612,https://wiki.ros.org/staubli_rx160_gazebo,Wiki,staubli_rx160_gazebo,"
      ROS-Industrial Gazebo support package for the Staubli RX160 (and variants).
    
      This package contains the configuration data and launch files required
      to simulate the Staubli RX160 manipulator in Gazebo. This includes the base
      model and the RX160L.
    
      Before using any of the configuration files included in this package, be
      sure to check they are correct for the particular robot model and
      configuration you intend to use them with.
    "
W613,https://wiki.ros.org/sql_database,Wiki,sql_database,"
    Provides an easy way to use SQL databases from the ROS environment.
  





Note that an interface to a full-fledged database used for manipulation can be found in the  package, which does not live in this stack. Report bugs on the . "
W614,https://wiki.ros.org/summit_x_sim,Wiki,summit_x_sim,"The summit_x_sim metapackage
 



This package contains the different controllers and launch files for the  simulation.  Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "
W615,https://wiki.ros.org/srdf,Wiki,srdf,"

    SRDF (Semantic Robot Description Format) is a representation of
    semantic information about robots.

  




Proposer:  This format is intended to represent information about the robot that is not in the URDF file, but it is useful for a variety of applications. The intention is to include information that has a semantic aspect to it.  A review of this format is available . <?xml version=""1.0""?>

 <!-- This does not replace URDF, and is not an extension of URDF.
      This is a format for representing semantic information about the robot structure.
      A URDF file must exist for this robot as well, where the joints and the links that are referenced are defined -->
 <robot name=""some robot"">

   <group name=""group1"">
      <!-- when a link is specified, the parent joint of that link (if it exists) is automatically included -->
      <link name=""...""/>
      <link name=""...""/>

      <!-- when a joint is specified, the child link of that joint (which will always exist) is automatically included -->
      <joint name=""..."" />

      <!-- when a chain is specified, all the links along the chain (including endpoints) are included in the group. Additionally, all the joints that are parents to included links are also included. This means that joints along the chain and the parent joint of the base link are included in the group -->
      <chain base_link=""l_shoulder_pan_link"" tip_link=""l_wrist_roll_link""/>
      <chain base_link=""r_shoulder_pan_link"" tip_link=""r_wrist_roll_link""/>
   </group>

   <!-- groups can also be formed by referencing to already defined group names -->
   <group name=""arms"">
      <group name=""left_arm""/>
      <group name=""right_arm""/>
      <link name=""..."" />
   </group>

   <!-- define a named state/configuration of a group -->
   <group_state name=""name of this state"" group=""name of group the state is for"">
      <joint name=""name of joint in group"" value="""" />
      <!-- all joints must be specified for the state to be valid -->
   </group_state>

   <!-- Define how the robot moves in its environment, i.e., connection to robot's root link -->
   <virtual_joint name=""world_joint"" type=""planar"" parent_frame=""some fixed frame"" child_link=""robot's root link name""/> <!-- type can be planar, floating or fixed -->

   <!-- We can then include the virtual joint in groups -->
   <group name=""whole_body"">
      <group name=""arms""/>
      <joint name=""world_joint""/>
   </group>


   <!-- define end effectors -->
   <end_effector name=""some diff name"" parent_link=""..."" group=""group_name""/>

   <!-- By default it is assumed that any link of the robot could potentially come into collision with any other link in the robot. This tag disables collision checking between a specified pair of links. There can be many such tags in this file.-->
   <disable_collisions link1=""link1"" link2=""link2"" />

</robot><?xml version=""1.0""?>

<robot name=""pr2"">

   <virtual_joint name=""world_joint"" type=""planar"" parent_frame=""odom"" child_link=""base_footprint""/>

   <group name=""right_arm"">
      <chain base_link=""torso_lift_link"" tip_link=""r_wrist_roll_link""/>
   </group>

   <group name=""left_arm"">
      <chain base_link=""torso_lift_link"" tip_link=""l_wrist_roll_link""/>
   </group>

   <group name=""arms"">
      <group name=""left_arm""/>
      <group name=""right_arm""/>
   </group>

   <group_state name=""tuck_arms"" group=""arms"">
      <joint name=""l_shoulder_pan_joint"" value=""0.2"" />
      <!-- ... the rest of the joint values... -->
   </group_state>

   <group name=""base"">
      <joint name=""world_joint""/>
   </group>

   <group name=""whole_body"">
      <group name=""arms""/>
      <group name=""base""/>
      <joint name=""torso_lift_joint""/>
   </group>

   <group name=""l_end_effector"">
      <joint name=""l_gripper_palm_joint"" />
      <joint name=""l_gripper_l_finger_joint"" />
      <joint name=""l_gripper_l_finger_tip_joint"" />
      <joint name=""l_gripper_led_joint"" />
      <joint name=""l_gripper_motor_accelerometer_joint"" />
      <joint name=""l_gripper_motor_slider_joint"" />
      <joint name=""l_gripper_motor_screw_joint"" />
      <joint name=""l_gripper_r_finger_joint"" />
      <joint name=""l_gripper_r_finger_tip_joint"" />
      <joint name=""l_gripper_joint"" />
      <joint name=""l_gripper_tool_joint"" />
   </group>

   <group name=""r_end_effector"">
      <joint name=""r_gripper_palm_joint"" />
      <joint name=""r_gripper_l_finger_joint"" />
      <joint name=""r_gripper_l_finger_tip_joint"" />
      <joint name=""r_gripper_led_joint"" />
      <joint name=""r_gripper_motor_accelerometer_joint"" />
      <joint name=""r_gripper_motor_slider_joint"" />
      <joint name=""r_gripper_motor_screw_joint"" />
      <joint name=""r_gripper_r_finger_joint"" />
      <joint name=""r_gripper_r_finger_tip_joint"" />
      <joint name=""r_gripper_joint"" />
      <joint name=""r_gripper_tool_joint"" />
   </group>

   <end_effector name=""r_end_effector"" parent_link=""r_wrist_roll_link"" group=""r_end_effector""/>
   <end_effector name=""l_end_effector"" parent_link=""l_wrist_roll_link"" group=""l_end_effector""/>

   <disable_collisions link1=""r_shoulder_pan_link"" link2=""r_shoulder_lift_link"" />
   <!-- and many more disable_collisions tags -->

</robot>"
W616,https://wiki.ros.org/maggie_devices_msgs,Wiki,maggie_devices_msgs,"maggie_devices_msgs metapackage


Newly proposed, mistyped, or obsolete package. Could not find package ""maggie_eyelids_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_eyelids_msgs/manifest.yaml 
Newly proposed, mistyped, or obsolete package. Could not find package ""maggie_ir_controller_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_ir_controller_msgs/manifest.yaml 
Newly proposed, mistyped, or obsolete package. Could not find package ""maggie_motor_controller_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_motor_controller_msgs/manifest.yaml 
Newly proposed, mistyped, or obsolete package. Could not find package ""maggie_rfid_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_rfid_msgs/manifest.yaml This package defines -specific message and service types for the devices. Most users will not use these types directly, but rather through Maggie-specific visualizations and utilities. "
W617,https://wiki.ros.org/rtt_rospack,Wiki,rtt_rospack,rtt_rospack provides an RTT plugin to use rospack to find packages in your ROS_PACKAGE_PATH
W618,https://wiki.ros.org/rtt_rosnode,Wiki,rtt_rosnode,This package provides an RTT plugin to add a ROS node to the RTT process.
W619,https://wiki.ros.org/moveit_pr2,Wiki,moveit_pr2,All PR2-specific packages for MoveIt
W620,https://wiki.ros.org/kdl_typekit,Wiki,kdl_typekit,This package contains the KDL RTT bindings
W621,https://wiki.ros.org/svenzva_joy,Wiki,svenzva_joy,"The svenzva_joy package
 
joy/joyjoyXbox 360Svenzva 6-Axis Joystick/joyjoy/revel/gripper_action/joyjoy/revel/eef_velocity"
W622,https://wiki.ros.org/pr2_moveit_config,Wiki,pr2_moveit_config,An automatically generated package with all the configuration and launch files for using the pr2 with the MoveIt Motion Planning Framework
W623,https://wiki.ros.org/underwater_sensor_msgs,Wiki,underwater_sensor_msgs,Common messages for underwater robotics
W624,https://wiki.ros.org/pr2_navigation_self_filter,Wiki,pr2_navigation_self_filter,"Filters the robot's body out of point clouds.


 The pr2_navigation_self_filter package provides a node that filters hits on the robot's body out of  messages and republishes them. Due to the fact that  messages will soon be deprecated, the pr2_navigation_self_filter has no stable API. A new version of the node will be written and supported long term with the new PointCloud structure, but until the  stack moves to support the new PointCloud's this package will remain in . Overall, you can use this package, but its at your own risk. The pr2_navigation_self_filter package has been moved to the robot_self_filter package as it is no longer PR2 specific. It is hosted at . This change will not fully go into affect until ROS Jade which the pr2_navigation_self_filter package will then be removed from the pr2_navigation metapackage. This means in Indigo, we will support both packages. In Hydro, there will be no relaese of robot_self_filter. Please see  for discussion on the matter. "
W625,https://wiki.ros.org/ur_bringup,Wiki,ur_bringup,"The ur_bringup package
This package is part of the  program.  "
W626,https://wiki.ros.org/turtlebot_arm_kinect_calibration,Wiki,turtlebot_arm_kinect_calibration,"turtlebot_arm_kinect_calibration allows calibration of a kinect to a TurtleBot arm,
    including a kinect on-board and off-board the TurtleBot for more precise manipulation.


 

Refer to the  for instructions on how to calibrate a Kinect to the .   calibrate.launch/camera/rgb/image_mono/camera/rgb/camera_info~calibration_pattern_out~detector_cloud~physical_points~fixed_framestring~camera_framestring~target_framestring~tip_framestring~checkerboard_widthint~checkerboard_heightint~checkerboard_griddouble~gripper_tip_xdouble~gripper_tip_ydouble~gripper_tip_zdouble<fixed_frame><tip_frame><camera_frame><target_frame>"
W627,https://wiki.ros.org/rosserial,Wiki,rosserial,"Metapackage for core of rosserial.
 is a  for wrapping standard ROS serialized messages and multiplexing multiple topics and services over a character device such as a serial port or network socket. 











Client libraries allow users to easily get ROS nodes up and running on various systems. These clients are ports of the general ANSI C++  library.  Currently, these packages include: Refer to  for details on how to add a new hardware platform. Devices running  code require a node on the host machine to bridge the connection from the serial protocol to the more general ROS network: The number of Publishers and Subscribers are limited at 25, and the size of serialization and deserialization buffers are limited at 512 bytes by default for . However, those numbers and sizes are too big for microcontroller with limited . The buffer sizes, and numbers of Publisher/Subscriber for  now vary depending on the chip used: You can change these numbers and sizes, refer to tutorial  for more informaiton. To conserve precious AVR memory, strings are not stored inside a message instance, instead an  is stored. This has two impacts: Therefore, to send an array message, we have to set the length and pointer. When deserializing, we cannot deserialize in-place like the string (since the bytes of the message are actually packed, unlike a string which is passed in plain form). Therefore, the deserialization function will automatically allocate enough storage using , attempting to reuse the memory location whenever possible and only expanding it when the new message received is larger than the largest previous message. The  protocol is aimed at point-to-point ROS communications over a serial transmission line. We use the same serialization/de-serialization as standard ROS messages, simply adding a packet header and tail which allows multiple topics to share a common serial link. This page describes the low-level details of the packet header and tail, and several special topics used for synchronization. The Protocol version byte was  on ROS Groovy,  on ROS Hydro, Indigo, and Jade. Topics ID 0-100 are reserved for system functions, as defined in the  message. Report bugs, ask questions in the issues list on  rosserialunsigned char *realloc()0xff0xfetypedef NodeHandle_<HardwareType, MAX_PUBLISHERS, MAX_SUBSCRIBERS, IN_BUFFER_SIZE, OUT_BUFFER_SIZE> NodeHandle;



Header header
geometry_msgs/Pose[] poses





  1st Byte - Sync Flag (Value: 0xff)
  2nd Byte - Sync Flag / Protocol version
  3rd Byte - Message Length (N) - Low Byte
  4th Byte - Message Length (N) - High Byte
  5th Byte - Checksum over message length
  6th Byte - Topic ID - Low Byte
  7th Byte - Topic ID - High Byte
  x Bytes  - Serialized Message Data
  Byte x+1 - Checksum over Topic ID and Message DataMessage Length Checksum = 255 - ((Message Length High Byte + 
                                   Message Length Low Byte) % 256 )Message Data Checksum = 255 - ((Topic ID Low Byte +
                                Topic ID High Byte + 
                                Data byte values) % 256)  0xff 0xfe 0x00 0x00 0xff 0x00 0x00 0xff  uint16 topic_id
  string topic_name
  string message_type
  string md5sum
  int32 buffer_size"
W628,https://wiki.ros.org/target_monitor,Wiki,target_monitor,"A package that manages information about targets in a swarm of cyber physical systems (CPSs).

 (, default: 1)  (, default: ) 


The communication between CPSs is based on the . The following packages of the  are required: The following packages of the  are required: to launch the  node. In the  subdirectory there are two parameter files  and  that allows to configure the behavior of the  node. The  contains the coordinates of the simulated targets. It is only used when the parameter  is set to . They are given as two list parameters where the list index is the ID of the target. This work is supported by the European Commission through the  under grant no. 731946. target_monitoridintegeroutputstringscreenscreenlogparamtarget_monitor.yamltargets.yamltarget_monitortargets.yamlsimulationtruetarget_monitortarget_trackingsimulationtruetargets.yamlcmd/target_done/goalpos_provider/posetarget_trackingcps_selectedtarget_donebridge/events/target_foundbridge/events/target_updatebridge/events/cps_selectedbridge/events/target_lostbridge/events/target_donebridge/uuidtarget_trackingsimulationtruefovtarget_foundtarget_updatetarget_losttarget_done~loop_ratereal~queue_sizeinteger~tracking_timeoutreal~target_tolerancereal~fovreal~simulationboolean~targets_xreal list~targets_yreal listroslaunch target_monitor target_monitor.launch"
W629,https://wiki.ros.org/rosservice,Wiki,rosservice,"rosservice contains the rosservice command-line tool for listing
    and querying ROS . It also
    contains a Python library for retrieving information about
    Services and dynamically invoking them. The Python library is
    experimental and is for internal-use only.












 is a stable command-line tool within the ROS core toolchain. It's currently feature set is not expected expand much. Currently, the only major feature planned is the ability to use YAML text files as well as piped YAML input with the  command. This feature is currently not scheduled. The  tool provides information about  files. The  command implements a variety of commands that let you discover which services are currently online from which nodes and further drill down to get specific information about a service, such as its type, URI, and arguments. You can also call a service directly from the command line. Please see  for a detailed description and examples of how to specify service arguments to . Please see  for a detailed description and examples of how to call  with negative-number arguments. rosserviceargs <service-name>call <service-name> [service-args]--waitcallrosservicefind <service-type>listlist <namespace>-ninfo <service-name>node <service-name>type <service-name>uri <service-name>rosservicerosservice callrosservice call call the service with the provided args
rosservice find find services by service type
rosservice info print information about service
rosservice list list active services
rosservice type print service type
rosservice uri  print service ROSRPC uri$ rosservice args /service_name $ rosservice call /service_name service-args$ rosservice call /add_two_ints 1 2$ rosservice find rospy_tutorials/AddTwoInts$ rosservice list$ rosservice list /rosout$ rosservice list -n$ rosservice info /rosout$ rosservice node /service_name$ rosservice type /service_name $ rossrv show `rosservice type /service_name`$ rosservice type add_two_ints | rossrv show
int64 a
int64 b
---
int64 sum$ rosservice uri /service_name "
W630,https://wiki.ros.org/asr_lib_pose_prediction_ism,Wiki,asr_lib_pose_prediction_ism,"This package contains classes and algorithms to predict poses of searched objects by the help of a tree of ISMs. It is organized as a library and contains only a small program to evaluate the performance of different algorithms. 

   



#include <asr_msgs/AsrObject.h> #include <pose_prediction_ism/pose_predictor.h> #include <pose_prediction_ism/shortest_path.h> pose_prediction_ism::PosePredictor* pose_predictor; //use shortest path pose prediction. You can also use BestPath, RandomPath, PaperPredictionNormalized or PaperPredictionNonNormalized pose_predictor = new pose_prediction_ism::ShortestPath(db_filename); //enables the random functionallity to simulate some noise (in mm, deg) //pose_predictor_->enableRandom(random_position, random_orientation); //Buffer for already found objects in scene pose_prediction_ism::FoundObjects fos; //add all already found objects to buffer for(std::size_t i = 0; i < BUFFERED_OBJECTS.size(); i++) { asr_msgs::AsrObject asr_o; asr_o.type = BUFFERED_OBJECTS[i]->type; asr_o.identifier = BUFFERED_OBJECTS[i]->observedId; fos.push_back(asr_o); } //add buffter to predictor pose_predictor_->setFoundObjects(fos); //ISM::PosePtr of ISM reference ISM::PosePtr referencePosePtr = MY_REFERENCE; //name of pattern representing ISM std::string = ""MyPattern""; //call actually prediction here with parameters: pose_predictor_->predictUnfoundPoses(referencePosePtr, pattern_name, samplefactor); //get the resulting attributed point cloud (which contains the prediction-results as labed points) pose_prediction_ism::AttributedPointCloud current_point_cloud = pose_predictor_->getAttributedPointCloud(); //disables the random functionallity //pose_predictor_->disableRandom(); "
W631,https://wiki.ros.org/nextage_description,Wiki,nextage_description,"As a part of rtmros_nextage package that is a ROS interface for  dual-armed robot from Kawada Robotics Inc, this package provides its 3D model that can be used in simulation and -based motion planning tasks."
W632,https://wiki.ros.org/turtle_actionlib,Wiki,turtle_actionlib,"turtle_actionlib demonstrates how to write an action server and client with the turtlesim. The shape_server provides and action interface for drawing regular polygons with the turtlesim.

This tutorial package provides a  and example  for drawing regular polygons with the . The default client will draw a pentagon in .  The  is defined below:  Then in separate terminals  the following nodes: shape_servershape_clientturtlesim_nodeturtlesimShape.actionrosrun#goal definition
int32 edges
float32 radius
---
#result definition
float32 interior_angle
float32 apothem
---
#feedback$ rosdep install turtle_actionlib
$ rosmake turtle_actionlib $ rosrun turtlesim turtlesim_node
$ rosrun turtle_actionlib shape_server
$ rosrun turtle_actionlib shape_client"
W633,https://wiki.ros.org/m4atx_battery_monitor,Wiki,m4atx_battery_monitor,"Battery Monitor for the M4-ATX Power Module








The  package will read the information from a m4atx battery supply and publish it as a ros message. Locate the bus and device number of the device called "" Technology, Inc."". To install the  package, you can choose to either install from source, or from the Ubuntu package: The  package contains a  file. This file launches an instance of the . To launch these nodes the following command can be used: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  m4atx_battery_monitorm4atx_battery_monitor_nodebattery_status_m4atx~diag_frequency~input_nominal~battery_dead_voltagem4atx_battery_monitorros_ethernet_rmpm4atx-battery-monitor.launchm4atx_battery_monitor_nodelsusb sudo chmod a+rw /dev/bus/usb/<bus_num>/<device_num>




sudo apt-get install ros-indigo-m4atx-battery-monitorroslaunch m4atx_battery_monitor_node m4atx_battery_monitor_node.launch "
W634,https://wiki.ros.org/wheeled_robin_teleop,Wiki,wheeled_robin_teleop,"The wheeled_robin_teleop package provides nodes and launch files for teleoperating WheeledRobin

 This package contains a launch file for the node in   to teleoperate a robot with a Thrustmaster T-Wireless gamepad. The launch file also includes the  file. A node from  is also loaded. turtlebot_teleop_joy turtlebot_teleop/launch/includes/velocity_smoother.launch.xmljoy_node roslaunch wheeled_robin_teleop thrustmaster_teleop.launch"
W635,https://wiki.ros.org/turtlebot_navigation,Wiki,turtlebot_navigation,"turtlebot_navigation

"
W636,https://wiki.ros.org/constrained_ik,Wiki,constrained_ik,Constraint-based IK solver.  Good for high-DOF robots or underconstrained tasks.
W637,https://wiki.ros.org/schunk_grippers,Wiki,schunk_grippers,"Schunk_grippers stack contains packages for PG70 and EZN64 grippers



Use GitHub to . []
 This stack contains packages to control EZN64 and PG70 Schunk grippers from ROS. It is a basic implementation of Schunk Motion protocol in combination with  and  library, which allows user to interface grippers through standard ROS services. Xacro models of EZN64 and PG70 grippers are included as well. Schunk EZN64 (libusb1.0 implementation) -  Schunk  PG70  (serial implementation)                  -  "
W638,https://wiki.ros.org/sr_description,Wiki,sr_description,"

     sr_description contains the description for Shadow Robot's Hand and Arm, as well as some additional models used in our robot (kinect, etc...).

  "
W639,https://wiki.ros.org/ur3_moveit_config,Wiki,ur3_moveit_config,"An automatically generated package with all the configuration and launch files for using the ur3 with the MoveIt Motion Planning Framework


This package is part of the  program. It is the ! configuration for the UR3 arm, generated automatically by the  Setup Assistant. Install the package from package management, and run the MoveIt! planning demo: This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR3, see the  package. See also the relevant sections in the  on Github. moveit_simple_controller_manager$ sudo apt-get install ros-$ROS_DISTRO-ur3-moveit-config

$ roslaunch ur3_moveit_config demo.launch"
W640,https://wiki.ros.org/waypoint_touring,Wiki,waypoint_touring,Tours around the waypoints
W641,https://wiki.ros.org/roscpp_traits,Wiki,roscpp_traits,"roscpp_traits contains the message traits code as described in
    .

    This package is a component of . Please see . roscpp_traits is an internal library used in  and should not be used directly.  "
W642,https://wiki.ros.org/python_ethernet_rmp,Wiki,python_ethernet_rmp,"Segway RMP Ethernet Python Driver





The  package contains the drivers for interfacing to a Segway RMP via an Ethernet connection. To install the  package, you can choose to either install from source, or from the Ubuntu package: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  python_ethernet_rmppython_ethernet_rmp




sudo apt-get install ros-indigo-python-ethernet-rmp"
W643,https://wiki.ros.org/moveit_ros_benchmarks_gui,Wiki,moveit_ros_benchmarks_gui,MoveIt GUI tools for benchmarking
W644,https://wiki.ros.org/staubli_tx90_gazebo,Wiki,staubli_tx90_gazebo,"
      ROS-Industrial Gazebo support package for the Staubli TX90 (and variants).
    
      This package contains the configuration data and launch files required
      to simulate the Staubli TX90 manipulator in Gazebo. This includes the base
      model, the TX90L and the TX90XL.
    
      Before using any of the configuration files included in this package, be
      sure to check they are correct for the particular robot model and
      configuration you intend to use them with.
    "
W645,https://wiki.ros.org/roscpp_serialization,Wiki,roscpp_serialization,"roscpp_serialization contains the code for serialization as described in
    .

    This package is a component of . 
Please see . roscpp_serialization provides the  API used in  and should not be used directly.   ros::serialization"
W646,https://wiki.ros.org/sr_gui_motor_resetter,Wiki,sr_gui_motor_resetter,"

     sr_gui_motor_resetter - gui plugin for resetting motors on the shadow hand.

   "
W647,https://wiki.ros.org/wheeled_robin_core_apps,Wiki,wheeled_robin_core_apps,"The core set of wheeled_robin 'app manager' apps are defined in this package.


 This package contains various robot apps (rapps) that can be used by WheeledRobin or any  compatible robot. Rapps are used by the appmanager started by 'minimal_with_appmanager' or 'bringup.concert' in  package. Control the  with a Thrustmaster Joystick. Rapp Platform: linux.ros.turtlebot "
W648,https://wiki.ros.org/tra1_bringup,Wiki,tra1_bringup,"Package contains bringup scripts/config/tools for tra1 robto
 
 Now you can see ! rviz interface to control the robot. $ roslaunch tra1_bringup tra1_bringup.launch simulation:=true$ roslaunch tra1_bringup tra1_moveit.launch"
W649,https://wiki.ros.org/pr2_navigation_config,Wiki,pr2_navigation_config,"This package holds common configuration files for running the

This package holds a number of common configuration files for the  node on the PR2 robot. In particular, it holds parameter settings for the , , and  components of the  node that are shared between many different configurations of the  stack run on the PR2. move_base/base_local_planner_params.yamlmove_base/costmap_common_params.yamlmove_base/move_base_params.yaml"
W650,https://wiki.ros.org/pr2_mechanism_model,Wiki,pr2_mechanism_model,"
        This package contains the robot model that is used by the realtime
        controllers
        inside . This robot model focuses on controlling the robot
        mechanism in a realtime control loop, and therefore it only contains
        the components of a robot that are relevant in realtime: the robot
        joints (with encoders, transmisisons and actuators) and the
        kinematic/dynamic model of the robot.
     
        The pr2_mechanism_model package is well tested and is released with a stable API.
     
 

 is the main class in this package.  When a controller gets initialized, the  passes the controller a pointer to the  (see the ). The robot state describes both the kinematic/dynamic model of the robot and the current state of the robot. The state of the robot is defined by the position/velocity/effort of the joints in the robot. The model of the robot is a  object, as defined in the . Additionally, the  provides access to the 'controller time', the time at which a controller cycle is started. To see an example on how to use the , check out the . 






The  package contains the  C++ class, which is an interface to the robot joints and a description of the robot model. The  gives easy access to individual joints. To work with a kinematic chain that contains multiple joints,  contains a  tool that represents a full kinematic chain and interfaces with the . The  provides access by name to all the s it contains. To get access to a , use the following method: From a  you can extract joint position, effort, velocity, and command the desired joint effort: To get e.g. the measured joint position from the , use: or, to set the commanded effort on , use: The  give more examples on how to use the . The  also gives access to the joint model, which contains things like the joint type, axis, reference position, etc. To e.g. get the joint type, use: The  API documentation provides all details. For reference documentation, check out the  . From a  you can read the measured position, measured velocity and measured effort effort, and write the commanded effort. Class member  The  also provides access to the transmissions between the motors and the joints. Typically you should not need the transmissions, unless you are using some advanced dynamic model, or you are calibrating the joints. To get access to a , use the following method: See the  for more details. For details on the transmission description format, check out the  page. Every time a controller cycle is started, the  records the time. This time can be accessed by all controllers through the . When a controller e.g. needs to compute the duration between two consecutive update loops, it should . In contrast to the system time, the controller time is not affected by the time other controllers consume in their update loop. Moreover, the controller time is the best measure of when the communication with the hardware actually occurs. To get access to the controller time, use: The  contains a  robot description object. There is lots of  on the urdf model, and there are even a number of  you could look at. To get access to the urdf model use: The  class provides an easy way to work with a kinematic chain that consists of multiple joints. Instead of finding all the joints by iterating through the , the  will pull out all the joints between a given root and tip link: From a  you can get the positions/velocities/efforts of all the joints, and set the efforts of all joints: From a chain you can also extract a : See the  for more details. The  is used when writing a realtime controller. For example code on how to use the  and the  classes, check out . To see an example on how to use the  object for Cartesian control, check out . pr2_mechanism_modelpr2_mechanism_model::RobotStateRobotStatepr2_mechanism_modelpr2_mechanism_model::ChainRobotStatepr2_mechanism_model::RobotStateRobotStateRobotStateRobotStatepr2_mechanism_model::RobotStatepr2_mechanism_model::JointStateJointStateJointStateJointStateJointStateJointStateJointStateJointStateurdf::Joint::safetypr2_mechanism_model::RobotStateJointStatepr2_mechanism_model::RobotStatepr2_mechanism_model::RobotStatepr2_mechanism_model::ChainRobotStateChainChainKDL::Chainpr2_mechanism_modelpr2_mechanism_model::RobotStatepr2_mechanism_model::JointStatepr2_mechanism_model::ChainJointState* js = robot_state_->getJointState(name);double position = js->position_;js->commanded_effort_ = my_command;if (js->joint_->type == urdf::Joint::Continuous)
ROS_INFO(""This is a continuous joint"");js->joint_->safetyTransmission* tr = robot_state_->getTransmission(name);ros::Time time = robot_state_->getTime();urdf::Model m = robot_state_->robot_->robot_model_;pr2_mechanism_model::Chain chain;
chain.init(robot_state, root_name, tip_name);KDL::JointArray jnt_pos;
chain.getPositions(jnt_pos);

KDL::JointArrayVel jnt_pos_vel;
chain.getVelocities(jnt_pos_vel);

KDL::JointArray jnt_eff;
chain.getEfforts(jnt_eff);

KDL::JointArray jnt_eff;
chain.setEfforts(jnt_eff);KDL::Chain kdl_chain;
chain.toKDK(kdl_chain);"
W651,https://wiki.ros.org/turtlebot3_simulations,Wiki,turtlebot3_simulations,"ROS packages for the turtlebot3 simulation (meta package) 
  is a new generation mobile robot that is modular, compact and customizable. Let’s explore ROS and create exciting applications for education, research and product development. The goal of  is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and  can be customized in various ways.  is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. 



TurtleBot3TurtleBot3TurtleBot3"
W652,https://wiki.ros.org/rc_visard_driver,Wiki,rc_visard_driver,"The rc_visard_driver provides data from a Roboception rc_visard 3D sensor on several ROS topics.
  











Use GitHub to . []
  
 Official ROS driver for  rc_visard 3D sensor. See  and  for more details. The  is the world’s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. The  is the official ROS driver for the  which provides ROS parameters (configuration), ROS services (control of rc_visards dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF).  If the connected rc_visard has an  license, then the following topics are additionally provided for images where the GPIO out1 is either low or high. These topics only useful if  is set to the special mode . For color sensors with an  license, the following topics are additionally available: If the parameter  is set to true, the node subscribes to the rc_visard's pose stream (same data published on  topic) and publishes them on tf. The trajectory constructed and stored by the  node can be retrieved by The onboard map of the  node can be saved on the rc_visard for loading it after a SLAM restart or power cycle: The onboard  node can be ""reset"" (clears the internal state of the SLAM component, including the trajectory) to free the memory with device02912345:02912345gev_accesscontrolexclusiveoffmax_reconnectsenable_tfenable_visualization_markers/dynamics_visualization_markersautostart_dynamicsautostart_dynamics_with_slamautostop_dynamicsautopublish_trajectory/trajectoryptp_enabledcamera_fpscamera_exp_autocamera_exp_maxcamera_exp_valuecamera_gain_valuecamera_exp_widthcamera_exp_heightcamera_exp_offset_xcamera_exp_offset_ydepth_acquisition_modeSingleFrameContinuousSCdepth_qualityLowMediumHighStaticHighLMHSStaticHighHighMediumLowHighdepth_static_scenedepth_disprangedepth_filldepth_segdepth_smoothdepth_mediandepth_minconfdepth_mindepthdepth_maxdepthdepth_maxdeptherrout1_modeLowHighExposureActiveExposureAlternateActiveIO ControlExposureActiveout2_modeout1_modeLowcamera_wb_autocamera_wb_ratio_redcamera_wb_autocamera_wb_ratio_bluecamera_wb_autoIO Controlout1_modeExposureAlternateActiveIO Controlenable_tfenable_tf/posecameraworldcameraimumy_visardmy_visard_worldmy_visard_cameradynamics_startdynamics_restartdynamics_stopdynamics_start_slamdynamics_restart_slamdynamics_stop_slamrc_slamslam_get_trajectoryrc_slamslam_save_mapslam_load_mapslam_remove_maprc_slamslam_resetmy_visardmy_visard_cameramy_visard_worldmy_visard_imurosrun rc_visard_driver rc_visard_driver _device:=:02912345 _enable_tf:=True _autostart_dynamics:=True _autostop_dynamics:=TrueROS_NAMESPACE=my_visard rosrun nodelet nodelet standalone rc_visard_driver _device:=:02912345"
W653,https://wiki.ros.org/rosh_common,Wiki,rosh_common,"

     ROSH plugin for packages in the common stack

  

 provides an index of all  actions in a running ROS graph. The API is currently very simple right now and only supports display action goal arguments and synchronous invocation.   
 provides an index of cameras that support the general ROS camera interface, which is commonly used in . With the  object, you can easily inspect which cameras are available, retrieve their camera info, and show camera images.  

 camerasactionsactionsactions.action_nameactions.action_name(args)camerascamerasshow(cameras.camera)rviz/image_viewrosh_common.PLUGIN_CAMERA_SHOWshow()cameras"
W654,https://wiki.ros.org/test_nodelet,Wiki,test_nodelet,A package for nodelet unit tests
W655,https://wiki.ros.org/turtlebot3_follow_filter,Wiki,turtlebot3_follow_filter,"turtlebot3_follow_filter package using laser_filters for turtlebot3_follower package 



This package provides parameters from  in  directory. scanscan_filteredscan_filter_chain:

- name: Remove over 0.35 meters on the right
  type: laser_filters/LaserScanBoxFilter
  params:
    box_frame: odom
    min_x: -3.5
    max_x: 3.5
    min_y: -3.5
    max_y: -0.35
    min_z: -0.1
    max_z: 0.1

- name: Remove over 0.35 meters on the left
  type: laser_filters/LaserScanBoxFilter
  params:
    box_frame: odom
    min_x: -3.5
    max_x: 3.5
    min_y: 0.35
    max_y: 3.5
    min_z: -0.1
    max_z: 0.1

- name: Remove 90 to 270 degree
  type: laser_filters/LaserScanAngularBoundsFilterInPlace
  params:
    lower_angle: 1.57
    upper_angle: 4.71

- name: exist range 0.12 to 0.7 meter
  type: laser_filters/LaserScanRangeFilter
  params:
    lower_threshold: 0.12
    upper_threshold: 0.7

- name: exist intensity 500 to 4000
  type: laser_filters/LaserScanIntensityFilter
  params:
    lower_threshold: 500
    upper_threshold: 4000
    disp_histogram: 0

- name: interpolation
  type: laser_filters/InterpolationFilter"
W656,https://wiki.ros.org/sr_gui_joint_slider,Wiki,sr_gui_joint_slider,"

     sr_gui_joint_slider is a rosgui plugin to change the position of the different joints.

   "
W657,https://wiki.ros.org/pr2_hardware_interface,Wiki,pr2_hardware_interface,"This package contains the C++ interfaces to the PR2 hardware
  components that are controlled over EtherCAT. This includes the
  motors and encoders needed to control the PR2 mechanism, as well as
  components like the pressure sensors in the fingertips, camera
  triggers, etc... All of the hardware components in this interface are
  directly available to the controllers inside the hard realtime
  control loop.
The PR2 hardware interface provides a C++ abstraction layer for the PR2 hardware that is controlled over the  that runs through the robot. Most users should not have to deal directly with this interface. If you are only interested in controlling the robot joints, you should directly interact with . Only very advanced users that need direct access to the hardware should be using the PR2 hardware interface.  HardwareInterface"
W658,https://wiki.ros.org/staubli_experimental,Wiki,staubli_experimental,"Experimental packages for Staubli manipulators within ROS-Industrial (metapackage).





Use GitHub to . []
 This repository is part of the  program. It contains experimental packages that will be moved to the  package once they've received sufficient testing and review. Due to the experimental nature of these packages, they have not been released and are not part of any ROS distribution. In order to use this stack, it has to be checked out into a catkin workspace and has to be build manually. Refer to the  for more information. See the  page for more information. For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. "
W659,https://wiki.ros.org/jog_msgs,Wiki,jog_msgs,The jog_msgs package
W660,https://wiki.ros.org/turtlebot3_autorace,Wiki,turtlebot3_autorace,"AutoRace ROS packages for AutoRace with TurtleBot3 (meta package) 
  is a new generation mobile robot that is modular, compact and customizable. Let’s explore ROS and create exciting applications for education, research and product development. The goal of  is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and  can be customized in various ways.  is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. 



TurtleBot3TurtleBot3TurtleBot3"
W661,https://wiki.ros.org/turtlebot_teleop,Wiki,turtlebot_teleop,"Provides teleoperation using joysticks or keyboard.


The  package provides launch files for teleoperation with different input devices. turtlebot_teleopturtlebot_teleop_keyturtlebot_telop_keyboard/cmd_vel~scale_lineardouble~scale_angulardoubleturtlebot_teleop_joyjoyturtlebot_telop_joystick/cmd_vel~scale_lineardouble~scale_angulardouble~axis_deadmanint~axis_linearint~axis_angularintroslaunch turtlebot_teleop keyboard_teleop.launchroslaunch turtlebot_teleop ps3_teleop.launchroslaunch turtlebot_teleop xbox360_teleop.launch"
W662,https://wiki.ros.org/allocators,Wiki,allocators,"Contains aligned allocation functions, as well as an STL-compatible AlignedAllocator class.
General aligned allocation is done through the  and  functions.  For example: alignedMalloc()alignedFree()










"
W663,https://wiki.ros.org/pr2_mechanism,Wiki,pr2_mechanism,"The pr2_mechanism stack contains the infrastructure to control the PR2 robot in a hard realtime control loop.

The  stack contains useful libraries if you want to write a realtime controller to interact with the PR2 (or similar) robot. These libraries are contained in the following ROS packages: Report new issues on  pr2_mechanismpr2_mechanismpr2_mechanismpr2_mechanism"
W664,https://wiki.ros.org/turtlebot_capabilities,Wiki,turtlebot_capabilities,Capabilities for the TurtleBot
W665,https://wiki.ros.org/sync_params,Wiki,sync_params,"Synchronises parameters across multiple masters.
 provides a means to synchronize parameter servers between multiple ROS masters. The parameter server is polled, and new parameters are published as a topic. The topic is then synchronized across masters using . The topic is received and written to the parameter server on the other ROS master. 


By default, all parameters will be synchronized. The  excludes parameters based on their name. The  parameters are exempt from the . These can both be regular expressions. For example: Would only synchronize . The parameter  is designed for spawning robots in Gazebo. Gazebo pauses the ROS clock when loading a robot, and waits for the  parameter. But that parameter might not get synchronized if  uses the ROS clock. Examples can be found in the . sync_paramsblacklistwhitelistblacklistmy_parameteruse_wall_timerobot_descriptionsync_params/params/params~debugboolean~ratedouble~death_timerdouble~use_wall_timebooleandeath_timer~blacklistarray~whitelistarrayblacklistblacklist = [""/*""]
whitelist = [/my_parameter]"
W666,https://wiki.ros.org/ncd_parser,Wiki,ncd_parser,"The ncd_parser package reads in .alog data files from the New College Dataset and broadcasts scan and odometry messages to ROS. 




 used with the permission of Dr. Paul Newman, Oxford University. 
 The  package reads in .alog data files from the New College Dataset and broadcasts the data in ROS. The messages are broadcast in real time. Currently, the data extracted includes the odometry of the robot and the readings from the left and right SICK laser scanners. Additional transforms are provided between the odometric frame and the two lasers, as described in the NCD paper. To use the , you need to obtain an .alog file from the New College Dataset . You can run the  on a small .alog file included in the package for demo purposes. First, make sure you have the  stack downloaded and installed by following the instructions . Please submit your tickets through  (requires github account) or by emailing the maintainers. ncd_parserscan_leftscan_rightstartdouble0.0enddouble-1.0-1ratedouble1.01.0mapodomodomlaser_leftodomlaser_rightQuadTree_Alog.alog

"
W667,https://wiki.ros.org/swarm_functions,Wiki,swarm_functions,"The swarm functions library provides simple functionalities that enable swarm algorithms to work. It is part of the swarm library.
 
Use GitHub to . []
 
The swarm functions library provides simple functionalities that enable swarm algorithms to work. It is part of the . This work is supported by the European Commission through the  under grant no. 731946. "
W668,https://wiki.ros.org/librms,Wiki,librms,"Client libraries for the RMS API.




To install the  stack, you can choose to either install from source, or from the Ubuntu package: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  librmslibrms




sudo apt-get install ros-fuerte-librms"
W669,https://wiki.ros.org/sr_robot_lib,Wiki,sr_robot_lib,"

     sr_robot_lib contains the robot library used in the sr_edc_ethercat_drivers. The
     library is used to store the incoming etherCAT messages in an easy to access format,
     and prepare the messages to be send through etherCAT.

  

This package also contains a class which builds the etherCAT command we want to send to the hand, based on the configuration file , the data is updated at different rates. The  folder contains most of the configuration for the hand driver (except the controller configuration): "
W670,https://wiki.ros.org/ur_kinematics,Wiki,ur_kinematics,"Provides forward and inverse kinematics for Universal Robots designs.
     See http://hdl.handle.net/1853/50782 for details.
This package is part of the  program.  "
W671,https://wiki.ros.org/tf_tools,Wiki,tf_tools,"ROS tools and scripts relates to tf


tf_logger will record the changes of frames published through  each with respect to a given reference frame. E.g. if you want to log both the transforms /world -> /odom and /odom -> /base_link at a frequency of 5 Hz, run     $ rosrun tf_tools tf_logger FREQUENCY REF_FRAME LOG_FRAME [REF_FRAME LOG_FRAME ...]    $ rosrun tf_tools tf_logger 5 /world /odom /odom /base_link"
W672,https://wiki.ros.org/rc_hand_eye_calibration_client,Wiki,rc_hand_eye_calibration_client,"The rc_hand_eye_calibration_client package



 


 
Use GitHub to . []
  
See  and  for more details. The default behavior is to request the existing calibration of the rc_visard once on startup, broadcast it (latched) on  and only broadcast again if the advertised ROS services  or  are called. After the calibration transform is calculated and tested, it should be saved to the rc_visard (). For detailed instructions on the calibration routine consult the rc_visard manual: . /tf/tf_static/tf_staticcalibrateget_calibrationset_posecalibratesave_calibrationhostrc_visard_frame_idend_effector_frame_idrobot_mountedbase_frame_idrobot_mounted == falsecalibration_request_periodcalibrateget_calibrationcalibration_publication_period/tf/tf_static/tf_staticdevice02912345:02912345grid_widthgrid_heightrobot_mountedreset_calibrationset_posecalibrateset_pose/tf/tf_staticget_calibration/tf/tf_staticsave_calibrationget_calibrationremove_calibrationget_calibration/tfrosrun rc_hand_eye_calibration_client rc_hand_eye_calibration_client_node _host:=<sensor_ip>rosrun rc_hand_eye_calibration_client rc_hand_eye_calibration_client_node _device:=:<serial_number>"
W673,https://wiki.ros.org/laser_scan_matcher,Wiki,laser_scan_matcher,"
     An incremental laser scan matcher, using Andrea Censi's Canonical Scan Matcher (CSM) implementation. See  for more about CSM. NOTE the CSM library is licensed under the GNU Lesser General Public License v3, whereas the rest of the code is released under the BSD license.
     



 








 (, default: ) 
 (, default: ) 
 (, default: ) 
 (, default: 0.10) 
 (, default: ) 
 (, default: 10) 
 (, default: 0.010) 

 The  package is an incremental laser scan registration tool.  The package allows to scan match between consecutive  messages, and publish the estimated position of the laser as a  or a  transform. The  can operate using  messages or  messages. When using , make sure they have no  values.  While the  can operate by just using scan data, we can speed up the scan registration process by providing a guess for the current position of the sensor every time a new scan message arrives. When no guess is available, a reasonable (and widely-used) assumption is that the sensor didn't move (zero-velocity model). Below is a list of inputs that  accepts: We can use combinations of the above such as IMU together with wheel odometry or IMU together with alpha beta tracking. When several prediction modes are enabled, the priority is IMU > Odometry > Constant Velocity > Zero Velocity. Setting the tolerance for updating the keyframe can be achieved via the  and  parameters. Their default values give a more robust performance, both while standing still and moving. You can run the  on a pre-recorded bag file that comes with the package. First, make sure you have the  stack downloaded and installed by following the . Two drivers are available:  and . Their parameters and topics are identical. Parameters when using  instead of  messages. Please submit your tickets through  (requires github account) or by emailing the maintainers. nandelta-thetayawimu/dataodomvelkf_dist_linearkf_dist_angularlaser_scan_matcher_nodeletlaser_scan_matcher_nodescancloudimu/datause_imutrueodomuse_odomtruepose2Dbase_linklaserworldbase_linkpublish_tf~fixed_framestring""world""~base_framestring""base_link""~use_imubooltrue/imu/data~use_odombooltrueodom~use_velboolfalsevel~use_cloud_inputboolfalse/cloud/scan~cloud_range_mindouble~cloud_range_maxdouble~kf_dist_lineardouble~kf_dist_angulardouble~publish_tfbooltrue~publish_posebooltrue~publish_pose_stampedboolfalse~max_iterationsint~max_correspondence_distdouble~max_angular_correction_degdouble~max_linear_correctiondouble~epsilon_xydouble~epsilon_thetadouble~outliers_maxPercdouble~sigmadouble~use_corr_tricksint~restartint~restart_threshold_mean_errordouble~restart_dtdouble~restart_dthetadouble~clustering_thresholddouble~orientation_neighbourhoodint~use_point_to_line_distanceint~do_alpha_testint~do_alpha_test_thresholdDegdouble~outliers_adaptive_orderdoubleoutliers_adaptive_orderoutliers_adaptive_mult~outliers_adaptive_muldoubleoutliers_adaptive_orderoutliers_adaptive_mult~do_visibility_testint~outliers_remove_doublesint~do_compute_covarianceint~debug_verify_trickint~use_ml_weightsint~use_sigma_weightsint
"
W674,https://wiki.ros.org/summit_xl_description,Wiki,summit_xl_description,"URDF description of the Summit XL and Summit XL HL and omni versions
"
W675,https://wiki.ros.org/turtlebot,Wiki,turtlebot,The turtlebot meta package provides all the basic drivers for running and using a TurtleBot.
W676,https://wiki.ros.org/acc_finder,Wiki,acc_finder,This package contains two small tools to help configure the navigation pipeline. The node min_max_finder.py prints the minimum and maximum linear and angular speed of the robot; the node acc_finder.py prints the time needed to achieve maximum speed.
W677,https://wiki.ros.org/quadrotor_handler,Wiki,quadrotor_handler,"The quadrotor_handler package
 "
W678,https://wiki.ros.org/ros_type_introspection,Wiki,ros_type_introspection,"The ros_type_introspection package allows the user to parse and deserialize
  ROS messages which type is unknown at compilation time.



 The ROS Message Types can be described as a . This approach is very well known and commonly used on the web and in distributed systems in general. A  is defined by the user; an ""IDL compiler"", i.e. , reads this schema and generates a header file that contains the source code that the user shall include in his/her applications. The inclusion of this header file is needed on both the publisher  the subscriber sides. The only ""problem"" is that in very few use cases (for instance if you want to build a plugin to ) you don't know in advance which ROS Messages you will need to read. Therefore, you won't be able to include the necessary header files. 1. : a type used to subscribe to any topic, regardless of the original type. 2. : the generic type commonly used to read data from a ROS bag. Please refer to . ros::message_traits::Definition"
W679,https://wiki.ros.org/batteries_skill_msgs,Wiki,batteries_skill_msgs,"batteries_skill messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""batteries_skill_msgs"" in rosdoc: /home/rosbot/docs/api/batteries_skill_msgs/manifest.yaml "
W680,https://wiki.ros.org/launch_tools,Wiki,launch_tools,"ROS tools and scripts related to launchfiles

     $ rosrun srv_tools launchViz     $ rosrun srv_tools launchViz -pkg PKG_A [PKG_B ...]"
W681,https://wiki.ros.org/wsg_32_description,Wiki,wsg_32_description,URDF and Xacro description files for the Weiss WSG 32 gripper with force sensing fingers. 
W682,https://wiki.ros.org/visp_camera_calibration,Wiki,visp_camera_calibration,"visp_camera_calibration allows easy calibration of
     cameras using a customizable pattern and ViSP library.


 is part of  stack.  




 



visp_camera_calibration is a ROS package that allows a highly customisable camera calibration using calibration tools from the ViSP library avalaible from . The image feed used for calibration is a set of clearly distinguishible points. The planar disposition of the points is of no importance. This package uses ViSP's camera model described in  and camera calibration capabilities described in . The output camera parameters are given in the  format. visp_camera_calibration will work with any camera driver node satisfying the standard ROS camera interface. See the . imagepoint_correspondencegray_level_precisiondoublesize_precisiondoublepause_at_each_frameboolmodel_points_xarraymodel_points_yarraymodel_points_zarrayselected_points_xarrayselected_points_yarrayselected_points_zarraycalibration_pathstringpoint_correspondencepoint_correspondenceset_camera_infoimagecalibratesudo apt-get install ros-$ROS_DISTRO-visp-camera_calibrationsudo apt-get install ros-$ROS_DISTRO-vision-visp




















"
W683,https://wiki.ros.org/spur,Wiki,spur,Meta package for SPUR omni-directional mobile manipulator robot made at Tamagawa University.Document is available in . 
W684,https://wiki.ros.org/multirobot_map_merge,Wiki,multirobot_map_merge,"Merging multiple maps without knowledge of initial
  positions of robots.Use GitHub to . []
 
  does not depend on any particular communication between robots. 
 finds robot maps dynamically and new robots can be added to system at any time.  





This package provides global map for multiple robots. It can merge maps from arbitrary number of robots. It expects maps from individual robots as ROS topics. If your run multiple robots under the same ROS master then  will probably work for you out-of-the-box. It is also very easy to setup an simulation experiment. To make this dynamic behaviour possible there are some constrains placed on robots. First all robots must publish map under , where topic name () is configurable, but must be same for all robots. For each robot  will be of cause different. Two merging modes are currently supported as orthogonal options. If you know initial positions of robots you may preferably use the first mode and get exact results (rigid transformation will be computed according to initial positions). If you don't know robot's starting points you are still able to use the second mode where transformation between grids will be determined using heuristic algorithm. You can choose between these two modes using the  parameter. This is preferred mode whenever you are able to determine exact starting point for each robot. You need to provide initial position for each robot. You need to provide set of  parameters. These positions should be in . See . Estimating transforms between grids is cpu-intesive so you might want to tune  parameter to run re-estimation less often if it causes any troubles. This package was developed as part of my bachelor thesis at  in Prague. Idea for dynamic robot discovery is from  package from Zhi Yan. Merging algorithm and configuration are different. multirobot_map_mergemultirobot_map_mergemultirobot_map_merge<robot_namespace>/mapmap<robot_namespace>known_init_poses<robot_namespace>/map_merge/init_poseworld_frameestimation_rate<robot_namespace>/map<robot_namespace>/map_updatesmapknown_init_posestrue<robot_namespace>/map_merge/init_pose_xdouble<no_default>xworld_frame<robot_namespace>/map_merge/init_pose_ydouble<no_default>yworld_frame<robot_namespace>/map_merge/init_pose_zdouble<no_default>zworld_frame<robot_namespace>/map_merge/init_pose_yawdouble<no_default>yawworld_frame~robot_map_topicstringmap~robot_map_updates_topicstringmap_updatesrobot_map_topicrobot_map_topic~robot_namespacestring<empty string>robot_map_topicrobot_namespace~known_init_posesbooltruetrue~merged_map_topicstringmap~world_framestringworld~merging_ratedouble4.0~discovery_ratedouble0.05~estimation_ratedouble0.5~estimation_confidencedouble1.0@masterthesis{Hörner2016,
  author = {Jiří Hörner},
  title = {Map-merging for multi-robot system},
  address = {Prague},
  year = {2016},
  school = {Charles University in Prague, Faculty of Mathematics and Physics},
  type = {Bachelor's thesis},
  URL = {https://is.cuni.cz/webapps/zzp/detail/174125/},
}"
W685,https://wiki.ros.org/network_control_tests,Wiki,network_control_tests,"
    Test suite for the packages that are part of the ""WiFi Test Setup"" project:
    network_monitor_udp, network_traffic_control, hostapd_access_point, linksys_access_point,
    ddwrt_access_point.
  "
W686,https://wiki.ros.org/turtlebot_interactions,Wiki,turtlebot_interactions,"Catkin meta-package for turtlebot_interactions

Use GitHub to . []
  "
W687,https://wiki.ros.org/wifi_drivers,Wiki,wifi_drivers,"
   This stack contains WiFi drivers
  "
W688,https://wiki.ros.org/toposens_driver,Wiki,toposens_driver,"ROS device driver for communication with TS sensors.


This package functions as a device driver for a Toposens 3D ultrasonic sensor. It can be used to setup a serial connection to the sensor, parse the received data string and publish it as a . Most of the parameters are used by the sensors firmware and are therefore sent to the sensor via the serial port. For a more detailed description of these parameters see .  ts_scans~portstd_msgs/String~frame_idstd_msgs/String~echo_rejection_thresholdint~noise_indicator_thresholdint~num_pulsesint~peak_detection_windowint~external_temperaturedouble~use_external_temperaturebool"
W689,https://wiki.ros.org/tra1_moveit_config,Wiki,tra1_moveit_config,"An automatically generated package with all the configuration and launch files for using the tra1 with the MoveIt! Motion Planning Framework
  To try ! with this package, type below command: You can see the  rviz screen and make it move with GUI. $ roslaunch tra1_moveit_config demo.launch"
W690,https://wiki.ros.org/wire_msgs,Wiki,wire_msgs,"wire_msgs
 contains all message types used in the  stack. Newly proposed, mistyped, or obsolete package. Could not find package ""wire_msgs"" in rosdoc: /home/rosbot/docs/api/wire_msgs/manifest.yaml wire_msgs"
W691,https://wiki.ros.org/roswiki_node,Wiki,roswiki_node,"Creates CS/NodeAPI clearsilver documentation from source code files. Typical usage: rosrun roswiki_node roswiki src/*



Using the source code of your packages, this package applies a set of regular expressions and parses out the basic node information, particularly the type of information used by the  template, ().  Are you a regular expression whiz? Tickets and patches are welcome for adding new patterns.  or contact  rosrun roswiki_node roswiki [source code files]"
W692,https://wiki.ros.org/turtlebot_apps,Wiki,turtlebot_apps,"turtlebot_apps is a group of simple demos and exmaples to run on your TurtleBot to help you get started with ROS and TurtleBot.
This stack is a supporting stack for the  providing example applications.   "
W693,https://wiki.ros.org/pr2_navigation_perception,Wiki,pr2_navigation_perception,"This package holds navigation-specific sensor configuration options and launch files for the PR2.


lasers_and_filters.xmlground_plane.xmlconfig/base_self_filter.yamlconfig/point_cloud_footprint_filter.yamlconfig/tilt_self_filter.yamlconfig/tilt_laser_filters.yamlconfig/shadow_filter.yaml"
W694,https://wiki.ros.org/rosh_desktop,Wiki,rosh_desktop,"

     ROSH meta-plugin for the ROS 'desktop' variant.

  
rosh_desktop is a meta-plugin that makes it easy to automatically load all desktop-related  plugins.  See the  documentation on how to automatically load rosh_desktop when you start rosh. Please see the  documentation to find out more about rosh. "
W695,https://wiki.ros.org/rail_recognition,Wiki,rail_recognition,"Construction and Use of a Recognition Database for Grasping Purposes



   



 The  package contains nodes for object recognition and demonstration grasp selection using models from a grasp database, handled by .  The package also contains a node used for generating object models from grasp demonstrations collected with the  package.  The recognizer has support for a 2D image recognizer to run first in the full recognition pipeline, significantly increasing the runtime of the point cloud recognizer by limiting the number of candidate classes to test with point cloud registration.  This package also contains nodes for data collection, training, and testing of the 2D recognizer. The full recognition pipeline takes in a list of unrecognized segmented objects, such as what the  package provides.  Each unrecognized object will first be classified by the 2D image classifier to determine a set of candidate object classes of high probability.  These candidate classes will then be retrieved from the object model database, handled by , which are then used by the point cloud recognizer to provide a final object label and set of example grasps for picking up the now-recognized object. The 2D image recognizer can be trained in a few steps.  First, an image set representative of the objects in the environment must be collected.  This can be accomplished by running a segmentation node, such as the one found in , and the collect_images node as follows: See the tutorials section of  for details on how to set up an object model database, provide grasp demonstrations, train new object models, and refine existing object models. To install the  package, you can install from source with the following commands: The  package contains a launch file for launching the object_recognition_listener node with the various database, segmentation, and recognition parameters set, executed with: Model generation can be run with an rviz plugin for visualization found in . rail_recognitionmodel_generator/generate_modelsmodel_generator/generate_modelsmodel_generator/debug_pcmodel_generator/debug_poses/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringdebugboolrail_recognition/recognize_object/goalrail_recognition/recognize_object/result/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringrail_recognition/recognizerail_recognition/recognize_allrail_recognition/recognizerail_recognition/recognize_allobject_topic paramobject_recognition_listener/recognized_objectsobject_recognition_listener/debug/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringobject_topicstringdebugbooluse_image_recognitionboolrail_grasp_model_retriever/retrieve_grasp_model/goalrail_grasp_model_retriever/retrieve_grasp_model/resultrail_grasp_model_retriever/point_cloudrail_grasp_model_retriever/poses/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringmetric_trainer/train_metrics/goalmetric_trainer/train_metrics/resultmetric_trainer/get_yes_no_feedbackmetric_trainer/base_pcmetric_trainer/aligned_pc/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringrail_segmentation/segmented_objectscollect_images/saved_data_dirstringcollect_images/images_dirstringcollect_images/test_images_dirstringcollect_images/new_images_dirstringcollect_images/save_new_imagesboolcollect_images/segmented_objects_topicstringrail_segmentation/segmented_objectssave_image_recognizer_features/saved_data_dirstringsave_image_recognizer_features/images_dirstringsave_image_recognizer_features/test_images_dirstringsave_image_recognizer_features/new_images_dirstringsave_image_recognizer_features/save_new_imagesboolsave_image_recognizer_features/segmented_objects_topicstringrail_segmentation/segmented_objectstrain_image_recognizer/saved_data_dirstringtrain_image_recognizer/images_dirstringtrain_image_recognizer/test_images_dirstringtrain_image_recognizer/new_images_dirstringtrain_image_recognizer/save_new_imagesbooltrain_image_recognizer/segmented_objects_topicstringrail_segmentation/segmented_objectstest_image_recognizer/saved_data_dirstringtest_image_recognizer/images_dirstringtest_image_recognizer/test_images_dirstringtest_image_recognizer/new_images_dirstringtest_image_recognizer/save_new_imagesbooltest_image_recognizer/segmented_objects_topicstringrail_pick_and_placerail_recognitionroslaunch rail_recognition collect_images.launchrosrun rail_recognition save_image_recognizer_featuresrosrun rail_recognition train_image_recognizerrosrun rail_recognition test_image_recognizer




roslaunch rail_recognition object_recognition_listener.launchroslaunch rail_recognition collect_images.launchroslaunch rail_recognition metric_trainer.launchroslaunch rail_recognition model_generator.launchroslaunch object_recognizer.launchroslaunch rail_recognition rail_grasp_model_retriever.launchrosrun rail_recognition save_image_recognizer_features
rosrun rail_recognition train_image_recognizer
rosrun rail_recognition test_image_recognizer"
W696,https://wiki.ros.org/swarm_behaviors,Wiki,swarm_behaviors,"The swarm behaviors library contains implementations of swarm algorithms. It is part of the swarm library.
 
Use GitHub to . []
 
The swarm behaviors library contains implementations of swarm algorithms. It is part of the . This work is supported by the European Commission through the  under grant no. 731946. "
W697,https://wiki.ros.org/summit_xl_pad,Wiki,summit_xl_pad,"The summit_xl_pad package allows to control the summit_xl product range (summit_xl, summit_xl_omni, x_wam) teleoperation
This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux () so that the final command to the robot can be set by different components (move_base, etc.) "
W698,https://wiki.ros.org/topological_tools,Wiki,topological_tools,"The topological_tools package contains utilities to ease the deployment
               of the MDM Library in topological navigation problems."
W699,https://wiki.ros.org/turtlebot_description,Wiki,turtlebot_description,"turtlebot_description provides a complete 3D model of the TurtleBot for simulation and visualization. The files in this package are parsed and used by a variety of other components. Most users will not interact directly with this package.
 This package contains robot description files for , organized into subdirectories as follows: urdf/meshes/.stl.dae.3ds"
W700,https://wiki.ros.org/asr_ivt,Wiki,asr_ivt,"Ros wrapper for the Integrated Vision Toolkit (IVT) library (version 1.3.22) 




This package contains a ROS-wrapper for the  library (version 1.3.22). "
W701,https://wiki.ros.org/visualization_osg,Wiki,visualization_osg,"visualization_osg is a metapackage providing support for visualization of geometry using the OpenSceneGraph rendering engine.

  "
W702,https://wiki.ros.org/web_interface,Wiki,web_interface,"The web_interface package

  (where  is the name of computer 1 on your robot) 

 If you want to install the web interface on a new computer or non-PR2 robot, there are experimental instructions on the  page. http://c1:9090c1"
W703,https://wiki.ros.org/teraranger_array_converter,Wiki,teraranger_array_converter,"Package that handle conversion from RangeArray messsages 
: This package depends on URDF description of the sensor setup. Please use the  package for this disponible here:  


 /ranges/scan/point_cloud/rangesconverter_modestringsensor_maskbool[]rosrun teraranger_array_converter teraranger_array_converter _converter_mode:=<laser_scan>|<point_cloud>|<individual_ranges>|<sequential_ranges>"
W704,https://wiki.ros.org/asr_flir_ptu_controller,Wiki,asr_flir_ptu_controller,"asr_flir_ptu_controller is a package to control a flir ptu unit from a action server 

 








   
   
      
 

The asr_flir_ptu_controller is closely connected to the  as it grants access to the PTU just as the mentioned package. The difference between both packages is that asr_flir_ptu_controller uses  to make the PTU accessible for actionservers by offering an action client that takes new position commands for the pan and tilt values of the pan and executes them with the help of . The package supports the taking of new position goals, constant feedback of the movement and a check if the movement ended successfully. Not fulfillabe goals get filtered out from the beginning - they get rejected. The asr_flir_ptu_controller serves a single purpose: It makes the movement of a Flir pan-tilt-unit accessable by a . The functionality by asr_flir_ptu_controller will be shown below in a sequence diagram. For knowledge of the invoked functions check out . Basic knowledge of the PTU movement (e.g. orientation of axis, movement area, etc.) can be obtained from the documentation of asr_flir_ptu_driver. A lot of functionalities, especially the configuration of forbidden areas, are only available in the asr_flir_ptu_driver and cannot be accessed from here. asr_flir_ptu_controller extends the basic functionalities of movement and forbidden area checking by wrapping them them inside an Action offered by an ActionServer, making invocations easy and offering the opportunity to use the ActionServer in context of a more complex control logic. However, the controller restricts the opportunities of the asr_flir_ptu_driver somehow as it forces the check for forbidden areas and does not allow path_prediction. Being mounted upon the  it is necessary that you have a running instance of asr_flir_ptu_driver, so start it . After starting the asr_flir_ptu_driver, start the asr_flir_ptu_controller. Interaction is then done over the  launched by asr_flir_ptu_controller. As the  has no simulation mode itself, launching it real is the only option you have. Little to no configuration needs to be done before launch if you did not change the topic names used by asr_flir_ptu_driver. Otherwise you need to adjust the corrsponding topic names found in the ptu_controller_settings.yaml file in the param folder. Most of the values there should be fine, nevertheless two should be reconsidered:  and The first one describes the maximum amount of steps that will be done before a movement is considered a failure. A step means hereby a spin of ROS (to be totally fair, it means a publishing from the asr_flir_ptu_driver about his current position, what happens each spin). The second one describes the margin parameter known from asr_flir_ptu_driver. You can set this parameter freely, it is limited by the minimum of the width/height of the pan/tilt movement area divided by 2. From that point on you can use the ActionServer offered by asr_flir_ptu_controller. All topics below are subscribed by the ActionServer of asr_flir_ptu_controller by default. They use a custom defined message which can be found inside the action folder of the package. All published topics by the asr_flir_ptu_controller are related to the ActionServer and should not be invoked from the command line. Use an ActionClient or some tool design for interacting with ActionServers. Most of them are based on a custom ActionServer message that can be found inside the action folder of the package. Nevertheless there exists a very long code example on how to use the Goal/....-callbacks offered by the asr_flir_ptu_controller. Move to the src folder of the package and have a look at the PTUControllerClient.cpp. It is a piece of code that was used to test the behaviour of the ActionServer provided during development and remained here as an example for the usage. Be aware that some of the expected reactions of this program depend on the configuration of the  and the PTU you are using - executing it without adapting it to your data is not recommended. Just use it as an example for usage. If you do not know how to use a ActionServer check out the . "
W705,https://wiki.ros.org/scan_tools,Wiki,scan_tools,"Laser scan processing tools.

 
This stack contains tools for manipulating  and  messages. See  on the development repository. Please submit your tickets through  (requires github account) or by emailing the maintainers. "
W706,https://wiki.ros.org/cpp_common,Wiki,cpp_common,"cpp_common contains C++ code for doing things that are not necessarily ROS
    related, but are useful for multiple packages. This includes things like
    the ROS_DEPRECATED and ROS_FORCE_INLINE macros, as well as code for getting
    backtraces.

    This package is a component of . "
W707,https://wiki.ros.org/rostest,Wiki,rostest,"Integration test suite based on roslaunch that is compatible with xUnit frameworks.
rostest is an extension to  that enables  files to be used as test fixtures. As a fully running system has more complex behaviors than an individual ROS , this allows you to do full integration testing across multiple nodes.  roslaunch"
W708,https://wiki.ros.org/sr_gui_muscle_driver_bootloader,Wiki,sr_gui_muscle_driver_bootloader,A GUI plugin for bootloading the muscle drivers on the etherCAT muscle shadow hand. This is similar to  but is used for the version of the hand that employs air pressure actuated muscles instead of electric motors. Select one or more muscle driver(s) and a hex file and the click Bootload Motors. 
W709,https://wiki.ros.org/teb_local_planner_tutorials,Wiki,teb_local_planner_tutorials,"The teb_local_planner_tutorials package

This package contains supplementary material and examples for the  package.  Refer to the  wiki page for more information and the  section. cd ~/catkin-ws/src
git clone https://github.com/rst-tu-dortmund/teb_local_planner_tutorials.git
# install dependencies, e.g.
sudo apt-get install ros-$ROS_DISTRO-stage-rossudo apt-get install ros-$ROS_DISTRO-teb-local-planner-tutorials"
W710,https://wiki.ros.org/tf2_ros,Wiki,tf2_ros,"This package contains the ROS bindings for the tf2 library, for both Python and C++.






   is designed both as a command-line tool for manual use, as well as for use within  files for setting static transforms. For example:  Please refer to the  or  Please refer to the  or  For most purposes using tf2_ros will be done using . It's main public API is defined by . Typically it will be populated using a  which subscribes to the appropriate topics.  Please refer to the  or  Please refer to the  or  For more information see  or  tf2_ros::TransformBroadcaster()tf2_ros::TransformBroadcaster::sendTransformtf2_ros::StaticTransformBroadcaster()tf2_ros::StaticTransformBroadcaster::sendTransformtf2_ros::Buffertf2_ros::BufferInterfacetf2_ros::TransformListenertf2_ros::Buffer::transformcanTransformlookupTransformgetFramestf2_ros::MessageFilter()connectInput()setTargetFrame()setTargetFrames()setTolerance()clearsetQueueSize()tf2::ConnectivityExceptiontf2::LookupExceptiontf2::ExtrapolationExceptiontf2::InvalidArgumentExceptiontf2::TimeoutExceptiontf2::TransformExceptionstatic_transform_publisher x y z yaw pitch roll frame_id child_frame_idstatic_transform_publisher x y z qx qy qz qw frame_id child_frame_idstatic_transform_publisher


"
W711,https://wiki.ros.org/sr_tactile_sensors,Wiki,sr_tactile_sensors,"

    An interface to the tactile sensors used in the Shadow Dextrous Hand. Also Contains a virtual set of sensors.

  




To ensure the same versatile use as the  package, the sr_tactile_sensors come in three flavours: dummy sensors, simulated sensors and real sensors.  There's a good example on how to use the data coming from the tactile sensors in the  When you start the interface, two topics per sensors will be published (10 topics in all). Each sensor publishes a pressure value. Each of the topic is publishing a /float64 value. By default, when you run , the tactiles are compiled as a set of dummy sensors.  To compile the interface to the real tactile sensors, run: .  If you want to compile the Gazebo tactile sensors: . "
W712,https://wiki.ros.org/staubli_rx160_support,Wiki,staubli_rx160_support,"
      ROS-Industrial support for the Staubli RX160 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for Staubli RX160 manipulators. This includes the base model and the
      RX160L.
    :
      Joint limits, torque limits, and maximum joint velocities are based on the
      information in the  version .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise (ie: no support for high speed joints, extended /
      limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      : Masses, center of mass and moments of inertia were calculated
      using Solidworks and the official Staubli CAD models, and may not be
      accurate.
    
      : In order to allow maximum torque on axis 6, effort limit on
      axis 5 was set to 29 Nm, rather than a feasible 58 Nm if torque on
      axis 6 = 0 Nm (see superscripts (1) and (2) from table in Section 2.6.2
      -Torque Limits- of the instruction manual for details).
    :
      This support package has received contributions from: S. van Elderen
      (RX160) and Murilo Martins (Ocado Technology) (RX160/RX160L).
    "
W713,https://wiki.ros.org/osg_utils,Wiki,osg_utils,osg_utils is a library that contains some classes that may be useful in ROS-OSG applications.
W714,https://wiki.ros.org/win_pyyaml,Wiki,win_pyyaml,"

Build script for python yaml parser.

  "
W715,https://wiki.ros.org/plot_tools,Wiki,plot_tools,plot_tools
W716,https://wiki.ros.org/jsk_hark_msgs,Wiki,jsk_hark_msgs,jsk_hark_msgs
W717,https://wiki.ros.org/stdr_resources,Wiki,stdr_resources,"Provides robot and sensor descripiton files for STDR Simulator.
 package is the container for the resources needed by  to operate. The resources are divided in two main groups:  and . 

In the maps section six indicative maps are provided. Note that each  is actually a pair of files: In this section the files under the  folder are described. These are Yaml or XML files that describe robots and sensors. The available folders, each holding some sample resource files, are: For more information about the use of resource files please visit  or the following tutorial :   "
W718,https://wiki.ros.org/pr2_surrogate,Wiki,pr2_surrogate,"
    The pr2_surrogate package allows you to use a PR2
    as a surrogate for your physical body using the Oculus RIFT
    virtual reality headset and the Razer Hydra controller.







The button assignment is similar to one used for the PS3 joystick in . ntpdaterobot startroslaunch pr2_surrogate robot.launchroslaunch pr2_surrogate desktop.launch"
W719,https://wiki.ros.org/stepback_and_steerturn_recovery,Wiki,stepback_and_steerturn_recovery,"This package provides a recovery behavior for the navigation stack which
        steps back and proceed with a specified steer angle

 


 (, default: false) 

The  is designed for a robot with a car-like steering mechanism. It adheres to the  interface found in the  package and can be used as a recovery behavior  for the  node. The C++  class adheres to the  interface found in the  package. For detailed documentation, please see . stepback_and_steerturn_recovery::StepbackAndSteerturnRecoverynav_core::RecoveryBehaviorrecover_run~<name>/only_single_steeringbool~<name>/trial_timesint~<name>/obstacle_patiencedouble~<name>/obstacle_check_frequencydouble~<name>/sim_angle_resolutiondouble~<name>/simulation_frequencyint~<name>/linear_vel_backdouble~<name>/step_back_lengthdouble~<name>/step_back_timeoutdouble~<name>/linear_vel_steerdouble~<name>/angular_speed_steerdouble~<name>/steering_timeoutdouble~<name>/linear_vel_forwarddouble~<name>/step_forward_timeoutdoublerotate_recovery::RotateRecoverynav_core::RecoveryBehavior"
W720,https://wiki.ros.org/world_canvas_utils,Wiki,world_canvas_utils,C++/Python utilities library for the world canvas framework.
W721,https://wiki.ros.org/laser_ortho_projector,Wiki,laser_ortho_projector,"The laser_ortho_projector package calculates orthogonal projections of LaserScan messages. 




 The package is intended as an intermediary step to transform laser data, before passing it to another node that performs scan-matching (for example,  or ). It works under the assumption that the environment is rectilinear in the z-dimension, meaning that obstacles look the same, regardless of the height where they are observed. This assumption typically holds for indoor spaces. We also calculate a transformation between the world frame and a orthogonally-projected base frame of the robot (labeled  in the figure above), and publish it as a  transform. Note that projecting the scan from an arbitrary roll and pitch results in points that are no longer equal angles apart. Thus, we pubish the projected scan as a . The point cloud is published in the base_ortho frame of reference. You can run the  on a pre-recorded bag file that comes with the package. First, make sure you have the  stack downloaded and installed by following the instructions . You should see the input laser scan and the orthogonally projected scan displayed in , similar to the video below: Two drivers are available:  and . Their parameters and topics are identical. Please submit your tickets through  (requires github account) or by emailing the maintainers. /base_ortholaser_ortho_projector_nodelaser_ortho_projector_nodeletlaser_ortho_projector_nodescanimubase_linkbase_linktf~cloud_orthobase_orthobase_link~fixed_framestring""/world""~base_framestring""base_link""~publish_tfboolfalsefixed_framebase_orthotf~use_imubooltruebase_linkfalsebase_linktfbase_linklaserworldbase_linkworldbase_ortho

"
W722,https://wiki.ros.org/octomap_rviz_plugins,Wiki,octomap_rviz_plugins,A set of plugins for displaying occupancy information decoded from binary octomap messages.
W723,https://wiki.ros.org/katana_description,Wiki,katana_description,This package contains an URDF description of the Katana arm and all supporting mesh files. 
W724,https://wiki.ros.org/win_empy,Wiki,win_empy,"

Build script for python expressions module.

  "
W725,https://wiki.ros.org/katana_teleop,Wiki,katana_teleop,"This package provides tele-operation nodes to control the Neuronics Katana 450 arm via keyboard commands or with a playstation 3 controller.


 This package provides the  ROS node, which provides a keyboard-based teleoperation for the Neuronics Katana 450 arm. katana_teleop_keyjoint_statesincrementdoubleincrement_stepsizedoubleincrement_step_scalingdouble"
W726,https://wiki.ros.org/wheeled_robin,Wiki,wheeled_robin,"The wheeled_robin stack provides all the basic drivers for running and using a WheeledRobin robot.

Use GitHub to . []
 Please refer main  page. "
W727,https://wiki.ros.org/twist_mux,Wiki,twist_mux,"Twist multiplexer, which multiplex several velocity commands (topics) and allows to priorize or disable them (locks).

 






When there are more than a single source to move a robot with a  message, it is important to multiplex all those input sources into a single one that goes to the controller (e.g. ). This package provides a node that subscribes to a list of topics publishing  messages and multiplexes them using a priority-based scheme. It also supports timeouts for each input and locking by means of topics that publish  messages. The main node of this package is , which provides a multiplexer for  messages. It takes N input twist topics and outputs the messages from a single one. For selecting the topic they are prioritized based on their priority, the messages timeout and M input lock topics that can inhibit one input twist topic. This is illustrated in the diagram below. In the  folder there are example yaml files with configuration parameters. The  subscribes to the N input twist topics and M input lock topics specified in the parameters  and  described below. The  parameter contains a list of structs with the following fields that specify each input twist topics: Example configuration to multiplex the autonomous navigation from , a joystick from , a keyboard from  and a tablet: The  parameter contains a list of structs with the following fields that specify each input lock topics: The next plot shows one input twist topic vs. the output one. The delay is usually 0, and always .  In order to make it easier to use a joystick input from  with , the package comes with a joystick relay. See . twist_muxtwist_muxtopicslockstimeout == 0.0timeout == 0.00255< 1msroslaunch twist_mux twist_mux.launchtopics:
-
  name    : navigation
  topic   : nav_vel
  timeout : 0.5
  priority: 10
-
  name    : joystick
  topic   : joy_vel
  timeout : 0.5
  priority: 100
-
  name    : keyboard
  topic   : key_vel
  timeout : 0.5
  priority: 90
-
  name    : tablet
  topic   : tab_vel
  timeout : 0.5
  priority: 100locks:
-
  name    : pause
  topic   : pause_navigation
  timeout : 0.0
  # Same priority as joystick control, so it'll not block it.
  priority: 100
-
  name    : joystick 
  topic   : joy_priority
  timeout : 0.0
  priority: 100"
W728,https://wiki.ros.org/libcreate,Wiki,libcreate,"C++ library for interfacing with iRobot's Create 1 and Create 2
 is a C++ library for interfacing with iRobot Create and Roomba platforms. For ROS bindings, see . 

Use GitHub to . []
 "
W729,https://wiki.ros.org/uos_rotunit,Wiki,uos_rotunit,"A driver for the uos-rotunit.

Use GitHub to . []
  For installation instructions, see . "
W730,https://wiki.ros.org/manipulation_msgs,Wiki,manipulation_msgs,The manipulation_msgs package This package is . You probably want to use  where some have been moved to. See also . 
W731,https://wiki.ros.org/swiftnav,Wiki,swiftnav,"ROS release of swiftnav library

This package is a ROS release of 's libswiftnav. It offers a variety of functionality related to linear algebra and spacial processing. All libswiftnav releases are here:  Note that because libswiftnav is a plain CMake project and not a  one, you can't use it in a regular catkin workspace— you must build and install using , and then overlay the resulting workspace with a regular catkin one. catkin_make_isolated"
W732,https://wiki.ros.org/rosrt,Wiki,rosrt,"rosrt provides classes for interfacing with ROS from within realtime systems, such as realtime-safe Publisher and Subscriber classes.

 starts three threads, one for publishing, one for subscribing and one for garbage collection.  The publisher thread uses a lock-free multi-writer single-reader queue with a fixed limit on the # of messages specified by . 

 will never return the same message twice.  This means: 
rosrt is a package that contains realtime-safe tools for interacting with ROS.  It is currently  and , so use at your own risk. Used together with a Xenomai Kernel the ROS processes get guaranteed CPU time and are not affected by other processes. rosrt can also slightly improve performance by avoiding memory allocations by preallocating. Those speed-ups should probably be helpful even if not running a real time system if small margins are important. There is an optional  argument to . See also:  Using the  is very similar to the standard  but with some realtime-specific requirements.  First, it provides you with a fixed-size buffer of messages (10 in the example below).  To be realtime safe you must allocate your messages out of this  you're publishing it with.  Second, you must initialize each of those messages with a template message when you initialize the .  Anything that needs to be preallocated should be preallocated in this template. Deallocation of the 's pool of memory is done by a separate garbage collection thread, and will not happen until all messages allocated out of the  have been freed (or on program exit). See also:  Using the  is a bit different from the standard , mainly because it's polling based instead of callback based: As with the , you must specify a message pool size.  If you are not going to be storing off received messages the optimal size for this is 3 (1 for the ROS-side subscription queue, 1 waiting in the Subscriber, 1 in use by realtime). Deallocation of the 's pool of memory is done by a separate garbage collection thread, and will not happen until all messages allocated out of the  have been freed (or on program exit). rosrt also provides a way of tracking allocations and frees per thread.  See the , ,  functions in , as well as the . rosrt::init()rosrt::init()InitOptions::pubmanager_queue_sizerosrt::Publisherros::Publisherrosrt::Publisherrosrt::PublisherPublisherPublisherrosrt::Subscriberros::Subscriberrosrt::Publisherpoll()SubscriberSubscribergetThreadAllocInfo()resetThreadAllocInfo()setThreadBreakOnAllocOrFree()













<message received>
sub.poll()  <---  returns a message
sub.poll()  <---  returns NULL
<message received>
sub.poll()  <---  returns a message
..."
W733,https://wiki.ros.org/laser_joint_projector,Wiki,laser_joint_projector,"Projects laser readings into a point cloud, based on a set of recorded joint angles
     This package is experimental and unstable.
     Expect its APIs to change.
"
W734,https://wiki.ros.org/summit_xl_localization,Wiki,summit_xl_localization,"The summit_xl_localization package
"
W735,https://wiki.ros.org/schunk_powercube_chain,Wiki,schunk_powercube_chain,"This packages provides a configurable driver of a chain
  of Schunk powercubes. The powercube chain is configured
  through parameters. Most users will not directly interact
  with this package but with the corresponding launch files
  in other packages, e.g. schunk_bringup, cob_bringup, ...



To use this package you need one or more powercubes . Alternatively you can use a simulated version without any hardware, see . The installation is tested for Ubuntu 14.04 using ROS . If you discover problems installing them on other platforms, please . The  package provides a configurable node for operating a chain of powercube modules. 
This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g.  in the  stack. For starting only the lwa use All hardware configuration is done in the  package. A sample parameter file in ""schunk_hardware_config/lwa/config/lwa.yaml"" could look like this schunk_powercube_chainjoint_group_velocity_controller/commandjoint_group_position_controller/command/joint_statesjoint_trajectory_controller/statedriver/current_operationmode/diagnosticsdriver/initdriver/stopdriver/recoverdriver/set_operation_modecan_modulestringcan_devicestringcan_baudrateintmodule_idslist of intsforce_use_movevelbooljoint_nameslist of stringsmax_accelerationslist of doubleshorizondoublefrequencydoublemin_publish_durationdouble/robot_descriptionurdf modelroslaunch schunk_bringup lwa_solo.launch<include file=""$(find schunk_bringup)/components/lwa.launch"" />can_module: PCAN
can_device: /dev/pcan1
can_baudrate: 1000
modul_ids: [1,2,3,4,5,6,7]
joint_names: [arm_1_joint, arm_2_joint, arm_3_joint, arm_4_joint, arm_5_joint, arm_6_joint, arm_7_joint]
max_accelerations: [0.8,0.8,0.8,0.8,0.8,0.8,0.8]
frequency: 68
OperationMode: position
ptp_vel: 0.4 # rad/sec
ptp_acc: 0.1 # rad/sec^2
max_error: 0.2 # rad"
W736,https://wiki.ros.org/tuw_checkerboard,Wiki,tuw_checkerboard,"The tuw_checkerboard package is designed to detect one 
    checkerboard and to estimate the pose of the checkerboard relative to the camera.
    The detection itself is based on the opencv functions for checkerboards.


 This package detects one checkerboard in camera images and computes the 3D pose. The current 3D pose estimation is based on the OpenCV  function. Various Parameter and algorithm used to detect the checkerboard can be tuned via ROS shared parameters or by using the dynamic reconfigure interface. This package allows you to publish the checkerboard pose as tf, marker msg, or pose. rosrun tuw_checkerboard tuw_checkerboard_node image:=/camera/image_raw camera_info:=/camera/camera_inforosrun rqt_reconfigure rqt_reconfigure"
W737,https://wiki.ros.org/pr2_common,Wiki,pr2_common,"URDF description of the robot kinematics and dynamics, 3D models of robot components, information required for gazebo to simulate the PR2, and messages specific to the PR2 such as detailed information about its power board and fingertip pressure sensors.


  This stack is not intended for user consumption. Check the  documentation for how to interpret this data, or  look at the examples in  "
W738,https://wiki.ros.org/kobuki_gazebo_plugins,Wiki,kobuki_gazebo_plugins,"Kobuki-specific ROS plugins for Gazebo 



The plugin is configured throught the parameters given in the URDF description. See the  for details. Have a look at the  package to find out how to use this plugin. "
W739,https://wiki.ros.org/staubli_rx160_moveit_plugins,Wiki,staubli_rx160_moveit_plugins,"
      MoveIt plugins for the Staubli RX160 (and variants).
    
      This package contains plugins for use with MoveIt and Staubli RX160
      manipulators. Plugins included support the base model. See the Staubli
      RX160 support package for information on used joint angle and velocity
      limits.
    
      Before using any of the plugins included in this package, be sure to 
      check they are correct for the particular robot model and configuration 
      you intend to use them with.
    

This package is part of the  program.  See the  metapackage page. "
W740,https://wiki.ros.org/can_msgs,Wiki,can_msgs,CAN related message types.
W741,https://wiki.ros.org/asr_gazebo_models,Wiki,asr_gazebo_models,"This package provides our gazebo_models 

  



  To use these models with gazebo, copy the according folder to ""~/.gazebo/models"" following . One need  to use the models. To use these models with gazebo, copy the according folder to ""~/.gazebo/models"" following . "
W742,https://wiki.ros.org/pr2_map_navigation_app,Wiki,pr2_map_navigation_app,"
    Map nav for the PR2.
  
"
W743,https://wiki.ros.org/semantic_point_annotator,Wiki,semantic_point_annotator,"A node which annotates 3D point cloud data with semantic labels.

This package provides a node that the  package uses for removing hits on the ground from  messages. Since the  message will be deprecated in the near future, and the code in this package will be replaced with code using the new PointCloud format, there are no guarantees about the stability of this package. After the  stack switches to the new PointCloud structure, this package will likely be removed. You should feel free to use the code in this package, but it will not be supported and is at your own risk. "
W744,https://wiki.ros.org/maggie_rfid_msgs,Wiki,maggie_rfid_msgs,"rfid messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""maggie_rfid_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_rfid_msgs/manifest.yaml "
W745,https://wiki.ros.org/tuw_aruco,Wiki,tuw_aruco,"This is a wrapper around the marker detection library ArUco.


  


 live demo using the  (uvc camera driver) package as a video source. Default settings (marker_dictonary=ARTOOLKITPLUSBCH, marker_size=0.06) are used. The  plugin  provides visualization for the  message. imagemarkerfiducialsshow_debug_imagebooleantruemarker_dictonarystringmarker_sizedouble0.06publish_tfbooleantruepublish_markersbooleantruepublish_fiducialsbooleanfalsepose_estimation_enabledbooleantruecamerat#idrosrun tuw_aruco aruco_noderoslaunch tuw_aruco demo_single_marker_live.launch"
W746,https://wiki.ros.org/rtt_stereo_msgs,Wiki,rtt_stereo_msgs,"Provides an rtt typekit for ROS stereo_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/stereo_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W747,https://wiki.ros.org/robot,Wiki,robot,A metapackage which extends ros_base and includes ROS libaries for any robot hardware. It may not contain any GUI dependencies.
W748,https://wiki.ros.org/turtlebot_actions,Wiki,turtlebot_actions,"turtlebot_actions provides several basic actionlib actions for the TurtleBot.
 This package is still experimental.  




~cmd_vel~base_framestring~odom_framestring~turn_ratedouble~forward_ratedoubleodom_framebase_frame#goal definition
float32 turn_distance     # in radians, ccw = +, cw = -
float32 forward_distance  # in meters, forward = +, backward = -
---
#result definition
float32 turn_distance
float32 forward_distance
---
#feedback
float32 turn_distance
float32 forward_distance#goal definition
uint8   CHESSBOARD = 1
uint8   CIRCLES_GRID = 2
uint8   ASYMMETRIC_CIRCLES_GRID =3

string    camera_name       # name of the camera 
uint8     pattern_width     # number of objects across
uint8     pattern_height    # number of objects down
float32   pattern_size      # size the object pattern (square size or circle size)
uint8     pattern_type      # type of pattern (CHESSBOARD, CIRCLES_GRID, ASYMMETRIC_CIRCLES_GRID)
---
#result definition
geometry_msgs/PoseStamped pose
---
#feedback"
W749,https://wiki.ros.org/tf2_py,Wiki,tf2_py,"The tf2_py package
This package allows to convert tf2 and geometry_msgs data to . Also binds the tf2 functions and exceptions to python. This is an implementation package, please refer to  for more information. "
W750,https://wiki.ros.org/posedetection_msgs,Wiki,posedetection_msgs,posedetection_msgs provides messages and services to facilitate passing pose detection results and features.
W751,https://wiki.ros.org/pr2_msgs,Wiki,pr2_msgs,"Messages for representing PR2 state, such as battery information and the PR2 fingertip sensors.
: Added  Where two versions of a message or service are defined, the version defined with a suffix of  is preferred; the non-suffix version is deprecated (e.g., we use  instead of ). 2"
W752,https://wiki.ros.org/power_msgs,Wiki,power_msgs,ROS messages for power measurement and breaker control. 
W753,https://wiki.ros.org/schunk_pg70,Wiki,schunk_pg70,"Xacro model and RS232 control node for basic communication with Schunk PG70 gripper





 






  This package is part of   stack. It allows user to control Schunk PG70 gripper over RS232 link using standard ROS services and  provides Xacro model for easier integration with various robots. This package depends on  library by William Woodall, git clone and catkin_make if not already in your workspace. Then you can proceed to clone and build of schunk_pg70. The right to access a serial port is determined by the permissions of the device file (e.g. /dev/ttyS0). Serial ports are usualy owned by root and group dialout, so to access the serial device as non-root user it is convenient to add yourself to  group: These services are ROS user interface to Schunk PG70 gripper. Except ""set_position"" all of them use  requests, so you don't need to specify any values, just ""rosservice call"" as in the example below. To test the driver start by calling the  service (  request): To get actual gripper position, call  service (  request): Service respond with actual position value is in  format: To move the gripper to target position, call  service ( request): where """" is within a range of <0 - 69> mm, velocity <0-83>mm/s and acceleration <0-320>mm/s2. The gripper should respond with goal_position being accepted or not and move to goal position: To reference gripper, call   service (empty request). Referencing may also help in cases when you are not  able to move the gripper although everything else looks okay: joint_statesschunk_pg70/referenceschunk_pg70/get_errorschunk_pg70/acknowledge_errorschunk_pg70/get_positionschunk_pg70/set_positionschunk_pg70/stopgripper_idstd_msgs/UInt8portnamestd_msgs/Stringbaudratestd_msgs/Int16robot_end_linkschunk_pg70_base_linkschunk_pg70_base_linkschunk_pg70_finger_1_linkschunk_pg70_base_linkschunk_pg70_finger_2_link$ usermod -a -G dialout USER_NAME$ roslaunch schunk_pg70 pg70_rs232_control.launch$ rostopic echo /joint_statesheader:
  seq: 21
  stamp:
    secs: 1443075477
    nsecs: 409227511
  frame_id: ''
name: ['pg70_finger1_joint', 'pg70_finger2_joint']
position: [0.010000248908996583, 0.010000248908996583]
velocity: []
effort: []
---
header:
  seq: 22
  stamp:
    secs: 1443075477
    nsecs: 511969796
  frame_id: ''
name: ['pg70_finger1_joint', 'pg70_finger2_joint']
position: [0.010000248908996583, 0.010000248908996583]
velocity: []
effort: []$ rosservice listschunk_pg70/reference
schunk_pg70/get_error
schunk_pg70/acknowledge_error
schunk_pg70/get_position
schunk_pg70/set_position
schunk_pg70/stop$ rosservice call /schunk_pg70/get_errorerror_code: 0$ rosservice call /schunk_pg70/get_positionactual_position: 20.000497818$ rosservice call /schunk_pg70/set_position position velocity accelerationgoal position accepted: True$ rosservice call schunk_pg70/reference$ roslaunch schunk_pg70 pg70_visualize_standalone.launch"
W754,https://wiki.ros.org/tedusar_manipulation,Wiki,tedusar_manipulation,"A set of packages related to semi-autonomous manipulation of objects using an arm with a simple gripper.

Use GitHub to . []
  "
W755,https://wiki.ros.org/maxwell,Wiki,maxwell,"
    Maxwell is a custom mobile manipulator. The Maxwell stack contains configuration, launch, and demo applications for the Maxwell robot.
   

The development of Maxwell has been covered on my blog (). "
W756,https://wiki.ros.org/wire_tutorials,Wiki,wire_tutorials,wire_tutorialsPackage containing data for  stack tutorials. The tutorials can be found  
W757,https://wiki.ros.org/ridgeback_msgs,Wiki,ridgeback_msgs,"Messages exclusive to Ridgeback, especially for representing low-level motor commands and sensors.

These messages are the low-level interface between 's ARM MCU and integrated PC. Most users of Ridgeback should be able to use standard ROS interfaces (eg. , ) to command and monitor the robot. A possible exception is to programmatically monitor system state such as voltage, current, battery, faults, etc. "
W758,https://wiki.ros.org/sr_external_dependencies,Wiki,sr_external_dependencies,"

     sr_external_dependencies package is a ""dummy"" package used to synchronize the includes for the protocol communication between the host and the PIC for Shadow's EtherCAT hardware. It contains a script that automatically downloads the latest h file from our pic32 svn.

  

' When you run make in this package, it simply copies the files from the released directory to the include and compiled_firmware directories. The protocol headers are then used in the  and  to interpret the incoming packets. The compiled firmware can be used in the bootloader plugin of the  to update the firmware of the motors.  If you set the  environment variable to 1, then we'll download the latest version of the protocol and also the latest compiled firmware from our internal svn (this is only possible if you're working for Shadow).  "
W759,https://wiki.ros.org/sr_gui_change_controllers,Wiki,sr_gui_change_controllers,"

     sr_gui_change_controllers is a rosgui plugin for loading the different controllers.

   "
W760,https://wiki.ros.org/visp_hand2eye_calibration,Wiki,visp_hand2eye_calibration,"visp_hand2eye_calibration estimates the camera position with respect
     to its effector using the ViSP library.
 visp_hand2eye_calibration is a ROS package that computes extrinsic camera parameters : the constant transformation from the hand to the camera coordinates.  
 is part of  stack.  

 An example client is shipped with this package. It feeds different transformations (camera->object and world->hand) to the calibrator which computes the relative transformation between the the camera and the hand. 
 
To do so, two sets of transformations are fed to the  node. The package consists of a  node and an experimental client doing a sample calibration from a few poses.  To run the  node: calibratorcalibratorcalibratorworld_effectorcamera_objectcompute_effector_cameracompute_effector_camera_quickresetsudo apt-get install ros-$ROS_DISTRO-visp-hand2eye-calibrationsudo apt-get install ros-$ROS_DISTRO-vision-visprosrun visp_hand2eye_calibration visp_hand2eye_calibration_calibratorroscorerosrun visp_hand2eye_calibration visp_hand2eye_calibration_clientrosrun visp_hand2eye_calibration visp_hand2eye_calibration_calibrator[ INFO] [1329226083.184531090]: Waiting for topics...
[ INFO] [1329226084.186233704]: 1) GROUND TRUTH:
[ INFO] [1329226084.186327570]: hand to eye transformation: 
translation: 
  x: 0.1
  y: 0.2
  z: 0.3
rotation: 
  x: 0.96875
  y: 0.0863555
  z: -0.0863555
  w: 0.215889


[ INFO] [1329226085.186682976]: 2) QUICK SERVICE:
[ INFO] [1329226085.188853282]: hand_camera: 
translation: 
  x: 0.1
  y: 0.2
  z: 0.3
rotation: 
  x: 0.96875
  y: 0.0863555
  z: -0.0863555
  w: 0.215889

[ INFO] [1329226085.188915366]: 3) TOPIC STREAM:
[ INFO] [1329226085.190303537]: hand_camera: 
translation: 
  x: 0.1
  y: 0.2
  z: 0.3
rotation: 
  x: 0.96875
  y: 0.0863555
  z: -0.0863555
  w: 0.215889"
W761,https://wiki.ros.org/win_roscpp_tutorials,Wiki,win_roscpp_tutorials,"
    This package attempts to show the features of ROS step-by-step,
    including using messages, servers, parameters, etc.
    It is a copy of the roscpp_tutorials (because catkin
    won't handle turtlesim in the same package).
  "
W762,https://wiki.ros.org/maggie_eyelids_msgs,Wiki,maggie_eyelids_msgs,"eyelids messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""maggie_eyelids_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_eyelids_msgs/manifest.yaml "
W763,https://wiki.ros.org/svenzva_description,Wiki,svenzva_description,Svenzva robot description files
W764,https://wiki.ros.org/face_detector,Wiki,face_detector,"Face detection in images.
  


 and  together consists the namespace prefix, and  makes the body of the topic to subscribe. In the example above, you're looking for: 

  See  to see how to run the face detector continuously, or  to run it as an action.  files above are stored . Possible pitfall may be the argument names (in  for example): See   for the name of the topics you need to correct. No doubt  works on the robots on simulator. Examples below show how you can run this package using stereo camera on  and . Additionally, using some other useful packages, you can visualize face detection result on . face_positions<camera>/left/<image><camera>/disparity<camera>/left/camera_info<camera>/right/camera_info<camera>/rgb/<image><camera>/depth_registered/<image><camera>/rgb/camera_info<camera>/depth_registered/camera_infoface_detector/people_tracker_measurementsposfixed_frameface_detector/faces_cloud~classifier_namestring~classifier_filenamestring~classifier_reliabilitydouble (0-1)~do_continuousbool~do_publish_faces_of_unknown_sizebool~do_displaybool~face_size_min_mdouble~face_size_max_mdouble~max_face_z_mdouble~face_separation_dist_mdouble~use_rgbdbool~approx_syncboolface_detector/launch/face_detector.<camera>.launchface_detector/launch/face_detector_action.<camera>.launchlaunchcameradepth_ns*_topicface_detectorface_detectorRVizPR2Turtlebotstanding personInsertStanding personImageRViz/head_mount_kinect/rgb/image_rawImage Topic  <arg name=""camera"" default=""camera"" />
  <arg name=""depth_ns"" default=""depth_registered"" />
  <arg name=""image_topic"" default=""image_rect_color"" />
  <arg name=""depth_topic"" default=""image_rect_raw"" />
  <arg name=""fixed_frame"" default=""camera_rgb_optical_frame"" /><launch>
  <arg name=""camera"" default=""camera"" />
  <arg name=""image_topic"" default=""image_raw"" />
  <arg name=""depth_topic"" default=""image_raw"" />
  <arg name=""fixed_frame"" default=""camera_rgb_optical_frame"" />
  <arg name=""depth_ns"" default=""depth_registered"" />
:
</launch>apt-get install jsk_pr2_startup roslaunch pr2_gazebo pr2_empty_world.launch
roslaunch face_detector facedetector_rgb_pr2.launch  (*a)roslaunch turtlebot_gazebo turtlebot_world.launch
roslaunch turtlebot_miscsample_cpp facedetector_rgb.launch (*b)roslaunch jsk_pr2_startup rviz.launch"
W765,https://wiki.ros.org/pr2_controller_manager,Wiki,pr2_controller_manager,"The controller manager (CM) package provides the infrastructure to run controllers in a hard realtime loop.




 






The  provides a  loop to control the robot mechanism. The robot mechanism is represented by a set of effort controlled joints (see  for details).  For the PR2 robot, we run the control loop at 1000 Hz. The controller manager provides the infrastructure to load your own realtime controller into its control loop. Every controller that is loaded into the controller manager will get triggered once every mili-second. To find out how to write your own hard realtime controller, take a look at . The controller manager ensures that none of the loaded controllers can command a joint past its . If necessary, the controller manager reduces the commanded joint effort, or even applies an effort in the opposite direction. For more details, take a look at the  page. The controller manager publishes the state of all joints over ROS, as  messages. These messages appear on the  topic, at 100 Hz. You can change this publishing frequency by setting the  parameter. To interact with controllers from the command line, use the  tool. To interact with a specific controller, use: To automatically load and start a set of controllers at once, and automatically stop and unload those same controllers at once, use the  tool: To automatically stop a set of controllers, and restart them later, you can use the  tool: The listed controllers will be , but not unloaded. Once spawner is shut down, the controllers will be restarted. You could run  to start controllers from within a launch file. However, the controller would then stay up even after the launch file is taken down. Instead, use the tool to automatically load, start, stop and unload a controller from within a launch file. When you start , it will load and start the controller. When you stop  (when the launch file is taken down) it will stop and unload the controller. Your launch file would look something like this: pr2_controller_managerjoint_statejoint_state_publish_ratepr2_controller_managerloadunloadstartstopspawnkilllistlist-typeslist-jointsreload-librariesreload-libraries --restorespawnerunspawnerpr2_controller_managerspawner spawnerspawnerjoint_statesmechanism_statisticspr2_controller_manager/load_controllerpr2_controller_manager/unload_controllerpr2_controller_manager/switch_controllerBEST_EFFORTSTRICTSTRICTBEST_EFFORTpr2_controller_manager/list_controllerspr2_controller_manager/list_controller_typespr2_controller_manager/reload_controller_librariespr2_controller_manager/joint_state_publish_ratedoublepr2_controller_manager/mechanism_statistics_publish_ratedouble $ rosrun pr2_controller_manager pr2_controller_manager <command> <controller_name> $ rosrun pr2_controller_manager pr2_controller_manager <command>  $ rosrun pr2_controller_manager spawner [--stopped] name1 name2 name3   $ rosrun pr2_controller_manager unspawner name1 name2 name3 <launch>
   <node pkg=""pr2_controller_manager"" 
         type=""spawner"" 
         args=""controller_name1 controller_name2"" />
 </launch> <launch>
   <node pkg=""pr2_controller_manager"" 
         type=""spawner"" 
         args=""--stopped controller_name1 controller_name2"" />
 </launch>"
W766,https://wiki.ros.org/sr_gui_self_test,Wiki,sr_gui_self_test,A GUI plugin for running self diagnostics of a robot. You can select one of the available self tests of the hand to be executed. Follow the on screen instructions. This will take some time! This is the front-end of  package. 
W767,https://wiki.ros.org/turtlebot_msgs,Wiki,turtlebot_msgs,"Turtlebot messages, services and actions 

Newly proposed, mistyped, or obsolete package. Could not find package ""turtlebot_msgs"" in rosdoc: /home/rosbot/docs/api/turtlebot_msgs/manifest.yaml $ sudo apt-get install ros-hydro-turtlebot-msgs$ sudo apt-get install ros-indigo-turtlebot-msgs"
W768,https://wiki.ros.org/sr_mechanism_model,Wiki,sr_mechanism_model,"

    sr_mechanism_model contains the transmissions used in the robot model. We needed specific
    transmission as we're using our own actuator. We also needed to take care of the joint 0s
    which combine the distal and middle phalanges.

  
We needed to redefine the  used in the , to be able to combine the distal and middle phalanges of the fingers into joint 0s. The new transmissions are defined in this package. They're using the actuators which are defined in .  "
W769,https://wiki.ros.org/sr_gui_hand_calibration,Wiki,sr_gui_hand_calibration,"

     This is a rosgui plugin for calibrating the Shadow EtherCAT Hand.

   "
W770,https://wiki.ros.org/win_ros,Wiki,win_ros,"
    Setup and utilities for ros on windows.
  Contents  
ROS Fuerte is EOL, and these instructions for getting it to work on Windows are severely outdated. They are only kept here for historical reasons. Please do not expect these steps to work, or try to follow them. For future Windows support, see the relevant . We now have enough functionality and enough to be useful in some situations. The mingw cross compiles are fairly stable and the msvc is now native thanks to a 100% cmake build environment codenamed . To be practical, we are not targeting the windows environment as a full blown replacement for linux-ros as windows doesn't have the mechanisms to handle the scaling of complexity (e.g. rosdeps), but it needs to be useful in some simple use case scenarios. For example, 
 to the  page to keep track of progress by email.  - Windows on Ros slides. 

This is for native windows development with the . Currently supporting either windows sdk 7.1 (cl/nmake) or visual studio 10.0.  - what's working and what's not.  - installing, configuring and verifying a pre-built sdk.  - developing projects with visual studio and the sdk.  - developing new ros msg types with the sdk.  - rosmaster, roslaunch'ers, rosparam and ros logging with the sdk. For more advanced usage:  - compiling the sdk/building your packages catkin style!  - how to hack an existing catkin stack for winros.  - how to create msvc packages and stacks, ros style.  - debugging msvc with win_ros. 
This is for the control roboticists who love working in linux and get flustered when asked to build windows apps for the rest of the world (namely users/test engineers) there is the . There is also qt support here - write the code once and compile your qt app for both windows and linux without any changes.  - setting up the mingw-cross build environment.  - how to create mingw packages and stacks, ros style.  - how to create mingw qt packages in ros. 
/  - if you're interested in helping, either with the infrastructure or porting stacks, start here.   "
W771,https://wiki.ros.org/summit_x_description,Wiki,summit_x_description,"The summit_x_description package
"
W772,https://wiki.ros.org/uwsim,Wiki,uwsim,"UWSim is an UnderWater SIMulator for marine robotics research and development. UWSim visualizes an underwater virtual scenario that can be configured using standard modeling software. Controllable underwater vehicles, surface vessels and robotic manipulators, as well as simulated sensors, can be added to the scene and accessed externally through ROS interfaces. This allows to easily integrate the visualization tool with existing control architectures. 
 







You will need a decent PC, with a good graphics card. It should work well on recent NVidia and ATI cards with good driver support in GNU/Linux. Have a look to the  list of cards that are known to be working]. If you see strange visualization effects, or it just crashes before beginning, it probably means your card does not meet the requirements (if this is the case, try with the <tt>--disableShaders</tt> option). As an example, it runs fluently on a  Pro 2.26 Ghz Intel Core 2 Duo, 4 GB DDR3 with an NVIDIA  9400M, running Ubuntu 11.04. and subscribe/publish to them with rostopic and rospub, or with your custom ros control nodes. The are some example ROS interface nodes in the <tt>interface_examples</tt> folder. For example, the following command should update the vehicle position in the default scenario (2 meters along positive X axis): Create a  and place a .rosinstall file inside it with the following contents: apt-get install ros-groovy-uwsimroscorerosrun uwsim uwsimrostopic listrosrun uwsim setVehiclePosition /dataNavigator 2 0 0 0 0 0git clone https://github.com/uji-ros-pkg/underwater_simulation.gitrosdep install UWSimrosmake UWSim- other: {local-name: /opt/ros/groovy/share/ros}
- other: {local-name: /opt/ros/groovy/share}
- other: {local-name: /opt/ros/groovy/stacks}
- setup-file: {local-name: /opt/ros/groovy/setup.sh}
- git: {local-name: src/uwsim_osgocean, 
        uri: 'https://github.com/uji-ros-pkg/uwsim_osgocean.git', 
        version: groovy-devel}
- git: {local-name: src/uwsim_osgworks, 
        uri: 'https://github.com/uji-ros-pkg/uwsim_osgworks.git', 
        version: groovy-devel}
- git: {local-name: src/uwsim_bullet, 
        uri: 'https://github.com/uji-ros-pkg/uwsim_bullet.git', 
        version: groovy-devel}
- git: {local-name: src/uwsim_osgbullet, 
        uri: 'https://github.com/uji-ros-pkg/uwsim_osgbullet.git', 
        version: groovy-devel}
- git: {local-name: src/underwater_simulation, 
        uri: 'https://github.com/uji-ros-pkg/underwater_simulation.git', 
        version: groovy-devel}rosws update rosdep install --from-paths src --ignore-src --rosdistro groovy -y
 catkin_make_isolated --install"
W773,https://wiki.ros.org/pr2_mechanism_diagnostics,Wiki,pr2_mechanism_diagnostics,"The `pr2_mechanism_diagnostics` node subscribes to `mechanism_statistics` and publishes diagnostics data for joints and controllers on `/diagnostics`. 


The  package publishes data from the  topic onto diagnostics. This data is published by . The joints and controllers diagnostics come from this package. The  topic contains statistics and information from the joints, actuators and controllers. pr2_mechanism_diagnosticsmechanism_statisticsmechanism_statisticsmechanism_statistics/diagnostics~disable_controller_warningsbool/use_sim_timebool"
W774,https://wiki.ros.org/pheeno_ros_sim,Wiki,pheeno_ros_sim,"Gazebo simulation ROS package for Pheeno system!
Documentation for our package can be found . We will also be adding documentation to this ROS page in the coming weeks. "
W775,https://wiki.ros.org/pr2_dense_laser_snapshotter,Wiki,pr2_dense_laser_snapshotter,"Stores the data from a series of laser scan messages in a dense representation, allowing
     users to easily perform image-like operations on intensity or range data. This package is
     experimental. Expect APIs to change.
"
W776,https://wiki.ros.org/maxwell_defs,Wiki,maxwell_defs,"
    Maxwell is a custom mobile manipulator, this package contains his configuration and launch files. 
  





The base uses a standard  message on the  topic to set desired velocity. See  and . Use of  is not recommended as most of our demos will use the topics in the  namespace.  "
W777,https://wiki.ros.org/rosjava_core,Wiki,rosjava_core,"An implementation of ROS in pure-Java with Android support.
 

For core library and example documentation, refer to the . For more general documentation on all things rosjava-android, refer to the  and  wiki pages. Some outdated tutorials can be found in the . "
W778,https://wiki.ros.org/wheeled_robin_bringup,Wiki,wheeled_robin_bringup,"wheeled_robin_bringup provides roslaunch scripts for starting the WheeledRobin base functionality.


 This package starts the . There are several launch files for different applications. "
W779,https://wiki.ros.org/asr_ism,Wiki,asr_ism,"This package contains nodes which make up the Passive-Scene-Recognition interface to Implicit Shape Model (ISM) trees. The Active-Scene-Recognition interface to ISM trees is located in asr_recognizer_prediction_ism, instead. A short outline of the functionalities provided by the nodes are:
      1. Recording of scenes
      2. Training of an ISM tree (Implicit shape model tree)
      3. Recognition of scenes
      4. Visualization of ISM (tree) data 
	  etc. 
 


: Visualize recorded data of a given pattern as a path for each object on which these objects moved while recording. : Expand the  visualization with vectors from positions of an object on its path at a certain point in time to its reference path at the same point in time. This visualization can help the user to understand how the model was created from each record data point. : Provide two different vote visualizations, the first just visualizes all votes from a fixed pose for a selected object in a selected subpattern and the second visualizes a given configuration with each object's votes that the model of a selected pattern provides. 
: This class can be used for custom nodes to convert ros messages () to data-types used by the  library. This class is implemented in the  file. : This class expands a node with the functionality to configure an object configuration interactively. Main features of this class are the multi-threaded processing of incoming messages (number of threads set by the user) and the processing of keyboard input (polling on its own dedicated thread). With this approach the actual node runs on its own thread(s) and decouples the  logically and computationally from the node. : This node republishes recorded data from a given database as ros messages (). : This node generates an object configuration by editing object data from a given database or XML-file and writes it to an XML-file. 






               
    
: This service is only called by the ObjectConverter class and provides it with additional information about recognizable objects from the . 
        
 Missing object estimations when using a SceneConfigurator -Node and the _driver GUI.  Make sure to uncheck the “update current angle immediately” option if you want to work with the current view. This package serves as the Passive-Scene-Recognition interface to the functionality provided by the  library in the ROS environment. The Active-Scene-Recognition interface to ISM trees is located in , instead. The core functions of this package are the training and recognition of scenes which consist of various objects using Implicit Shape Model (ISM) trees. In addition to the implementation of the tools provided by  there are several visualization (based on ) and utility tools to make the usage of the scene recognition system more convenient. There are two training approaches implemented, one simply being called , the other . They are interchangeable but as they use different algorithms the trained models result in a difference in recognition quality mostly in terms of speed as the latter has a shorter computation time. The input of both trainers is a recording of a scene consisting of multiple objects which is stored in a sqlite database and can be created using the ""Recorder"" tool. The ""Recognizer"" tool uses the trained models and tries to find the most likely match given a set of objects. In general the steps required are the recording of a scene, training a model from this recording and then using the recognizer to get the most likely scene match from a new object configuration. Below you can see a list of all tools this package provides including the mentioned ones and tutorials on how to use them. For more information about the functionality see the  package. The nodes in this list wrap tools from  to provide them in the ROS environment: Although many nodes of this package publish some kind of visualization, the purpose of these nodes is solely to visualize ism data in . If you are using the  from  and you checked the option “update current angle immediately”, it may happen that the SceneConfigurator clears the object estimations in the current view, because the ptu toggles its “reached_desired_position” parameter. "
W780,https://wiki.ros.org/rosserial_python,Wiki,rosserial_python,"A Python-based implementation of the rosserial protocol.



The  package contains a Python implementation of the host-side rosserial connection. It automatically handles setup, publishing, and subscribing for a connected rosserial-enabled device.  To run the node with a different port and baud rate, for example on /dev/ttyACM1, you must specify the  and  parameters on the command line: ~portstr~baudint~port~baudrosrun rosserial_python serial_node.py _port:=/dev/ttyACM1 _baud:=115200<launch>
  <node pkg=""rosserial_python"" type=""serial_node.py"" name=""serial_node"">
    <param name=""port"" value=""/dev/ttyACM1""/>
    <param name=""baud"" value=""115200""/>
  </node>
</launch>"
W781,https://wiki.ros.org/tedusar_box_detection,Wiki,tedusar_box_detection,Node for detecting boxes with square base in point clouds by detecting their top plane. Detection is started via an action interface.
W782,https://wiki.ros.org/pr2_machine,Wiki,pr2_machine,"This package contains the xxx.machine files that describe the different hosts a node can be spawned on. Currently there is one machine file for the pr2 robot, and one for the simulated pr2 robot.
These files are intended to be included by  files.  The intended usage is: The user sets the  environment variable to  when working with a physical PR2, and  when working in simulation.  In this way,  files that refer to machines  and  will distribute computation appropriately on the robot, but still work on a single machine in simulation (assuming that the single machine can support the processing requirements). pr2.machinec1c2c1c2sim.machinec1c2localhostROBOTpr2simc1c2  <include file=""$(find pr2_machine)/$(env ROBOT).machine"" />"
W783,https://wiki.ros.org/tum_ardrone,Wiki,tum_ardrone,"The tum_ardrone package



 














The code works for both the AR.Drone 1.0 and 2.0, the default-parameters however are optimized for the AR.Drone 2.0 by now. You can find more details on my research on my . This Package builds on the well known monocular SLAM framework  presented by Klein & Murray in their  at ISMAR07.  Please study the original  and the corresponding  for more information on this part of the software. Also, be aware of the  that comes with it. 1. Install the  package:  To do this, run: The major part of this software package - that is everything except PTAM - is licensed under the GNU General Public License Version 3 (GPLv3), see .  PTAM (comprised of all files in /src/stateestimation/PTAM) has it's own licence, see . This licence in particular prohibits commercial use of the software. rosrun joy joy_nodeaggressivenessKp_rp# cd into ros root dir
roscd

# clone repository
git clone git://github.com/tum-vision/ardrone_autonomy.git ardrone_autonomy

# add to ros path (if required)
export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/ardrone_autonomy

# build SDK (might require your confirmation to install some system libraries)
cd ardrone_autonomy
./build_sdk.sh

# build package
rosmake# cd into ros root dir
roscd

# clone repository
git clone git://github.com/tum-vision/tum_ardrone.git tum_ardrone

# add to ros path (if required)
export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/tum_ardrone

# build package (may take up to 10 minutes)
rosmake tum_ardrone# run driver
rosrun ardrone_autonomy ardrone_driver

# run stateestimation node
rosrun tum_ardrone drone_stateestimation

# run autopilot node
rosrun tum_ardrone drone_autopilot

# run gui node
rosrun tum_ardrone drone_gui"
W784,https://wiki.ros.org/segbot_simulation_apps,Wiki,segbot_simulation_apps,"Applications designed specifically to be used in a
    simulation environment, such as opening and closing doors inside the
    building simulation."
W785,https://wiki.ros.org/pyros_config,Wiki,pyros_config,Configuration package for Pyros
W786,https://wiki.ros.org/smart_battery_msgs,Wiki,smart_battery_msgs,"Smart Battery MessagesNewly proposed, mistyped, or obsolete package. Could not find package ""smart_battery_msgs"" in rosdoc: /home/rosbot/docs/api/smart_battery_msgs/manifest.yaml "
W787,https://wiki.ros.org/uos_rotunit_driver,Wiki,uos_rotunit_driver,driver for the uos-rotunit
W788,https://wiki.ros.org/srdfdom,Wiki,srdfdom,Parser for Semantic Robot Description Format (SRDF).
W789,https://wiki.ros.org/wpi_jaco,Wiki,wpi_jaco,"Metapackage for the ROS Packages for the JACO Arm Developed at WPI




 Not all of the functionality of the meta-package is implemented yet for the JACO2.  There's no jaco2_description package yet, providing a urdf for the arm.  Similarly, there is no sample ! configuration either, which is waiting on the urdf before configuration is possible.  As such, the motion planning functionality found in the two moveit packages have not yet been extended to the JACO2.  All of the other functionality should work as intended for the new arm. To install the  package, you can install from source with the following commands: The  package contains a launch file, , to start all of the nodes required to communicate with the JACO arm.  Once these nodes are launched, further launch files can be run from the other packages, all of which are documented in their respective wiki pages. Please send bug reports to the . wpi_jacowpi_jacoarm.launch




"
W790,https://wiki.ros.org/rtmros_nextage,Wiki,rtmros_nextage,"The rtmros_nextage package is a ROS interface for  dual-armed robot from Kawada Robotics Inc.  
 



  The content of this DVD has become obsolete. Please refer to  tutorial page and get the software.  might ask you this password:   See . Please read the . When you insert the DVD into your Ubuntu computer,  package, which is a basis of , and its dependency will be installed. Once installation is done, you can try it by following  (which is ogirinally made for the robot from the same manufacturor called ). Since installation should be done by this point, you can skip installation section and move forward to . (New 2013/11/07) Now  is installable from ROS repository. See . rtmros_nextageHirortmros_nextageUbuntuopensource"
W791,https://wiki.ros.org/phidgets_imu,Wiki,phidgets_imu,"Driver for the Phidgets Spatial 3/3/3 devices
 

 The  package contains a  ROS driver for the  IMU sensor. The driver publishes the following data: You can use this driver in conjunction with  or a similar IMU filter to get an estimate for the orientation of the sensor from the fused sensor readings. An example  for using the driver together with a filter is included in the package. phidgets_imu_node_nodeimu/data_rawimu/magimu/is_calibratedimu/calibrateimu/is_calibratedimu/calibrate~frame_idstring""imu""~perioddouble~angular_velocity_stdevdouble~linear_acceleration_stdevdouble~magnetic_field_stdevdouble"
W792,https://wiki.ros.org/rosserial_arduino,Wiki,rosserial_arduino,"rosserial for Arduino/AVR platforms.

This package contains Arduino-specific extensions required to run  on an Arduino. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors into your ROS project using an Arduino. The Tutorials of this package will walk you through setting up your Arduino environment, creating a few example sketches and explain where to purchase the additional hardware. Some features can be enabled depending of  statements added before including  in the sketch. For example, to use the  define, see the  example. #defineros.h#defineUSE_USBCONROSSERIAL_ARDUINO_TCPUSE_TEENSY_HW_SERIALUSE_STM32_HW_SERIALSTM32ETHERNETROSSERIAL_ARDUINO_TCP"
W793,https://wiki.ros.org/sr_gui_change_muscle_controllers,Wiki,sr_gui_change_muscle_controllers,A GUI plugin for loading the different muscle controllers. This is similar to  but is used for the version of the hand that uses air pressure actuated muscles instead of electric motors. You may select Valve or position control mode. 
W794,https://wiki.ros.org/linux_peripheral_interfaces,Wiki,linux_peripheral_interfaces,"Simple scripts which help utilise, monitor, interact with computer
     hardware abstracted by a linux OS.

Use GitHub to . []
  "
W795,https://wiki.ros.org/turtlebot_rapps,Wiki,turtlebot_rapps,"The core set of turtlebot 'app manager' apps are defined in this package.
"
W796,https://wiki.ros.org/spur_controller,Wiki,spur_controller,A package for mobile base control for SPUR omni-directional mobile manipulator robot made at Tamagawa University.
W797,https://wiki.ros.org/pr2_navigation,Wiki,pr2_navigation,"The pr2_navigation stack holds common configuration options for running the


  "
W798,https://wiki.ros.org/rosserial_msgs,Wiki,rosserial_msgs,"Messages for automatic topic configuration using rosserial.
"
W799,https://wiki.ros.org/wheeled_robin_description,Wiki,wheeled_robin_description,"The wheeled_robin_description package
 This package contains the robot description file for  as URDF file (compare ). The file can be loaded by the  and the . "
W800,https://wiki.ros.org/turtlebot_bringup,Wiki,turtlebot_bringup,"turtlebot_bringup provides roslaunch scripts for starting the TurtleBot base functionality.

Follow the  to start your TurtleBot. "
W801,https://wiki.ros.org/tedusar_cartesian_arm_teleop,Wiki,tedusar_cartesian_arm_teleop,Node for teleoperating an arm and gripper in a cartesian coordinate frame using a joystick.
W802,https://wiki.ros.org/hironx_ros_bridge,Wiki,hironx_ros_bridge,"ROS-OpenRTM interfacing package for the opensource version of Kawada's Hiro/NEXTAGE dual-arm robot.

  NOTE: This package is multi-license -- pay attention to file header in each file where license is declared. For Creative Commons nc 4.0 applied, see .

  This package also contains some sensor driver software (as of April 2016 they are the following force sensors such as  and ) for QNX. These drivers are stored in this robot-specific package for not many reasons than they are slightly customized for the robot. So if you can separate those as a standalone, generic package that'll be appreciated (please just let us know if you will).

 is supported by the opensource community per best-effort basis. If you find anything wrong, or would like to add more documentation, please consider opening a ticket and providing patches . 

Dependency graph (that's yielded by ) of .  Tutorial for  is integrated into 's page. User can get a the most control of the  robot through the Python class , where the large part of methods are derived from . Some of their methods are overridden specifically for Hironx at  (that is a derived class of ). For some of those methods derived from , unit test cases are available in . Download it and run: As of today (Jan 31, 2014), you might want to modify the file to adjust to your environment. Open the file with the editor, replace  with the QNX hostname of your robot. hironx_ros_bridgeHironxhironx_ros_bridgeHironxhironx_ros_bridge.hironx_client.HIRONXhrpsys.HrpsysConfigurator$ mv test_hironx_derivedmethods_rostest.py `rospack find nextage_ros_bridge`/test
$ chmod 755 test_hironx_derivedmethods_rostest.py
$ rosrun nextage_ros_bridge test_hironx_derivedmethods_rostest.py "
W803,https://wiki.ros.org/manipulator_handler,Wiki,manipulator_handler,"The manipulator_handler package
The manipulator handler looks for a manipulator tag and it finds all its joints. After it creates a ROS publisher of  messages: In addition it gives us the possibility to control the joints using commands from ROS in several ways (see  for more details): In the folder  you will find the model of a manipulator with the joints controlled in velocity:  . sim_ext_ros_bridge_manipulator_ctrl_mode_Passive_modesim_ext_ros_bridge_manipulator_ctrl_mode_MOT_velocitysim_ext_ros_bridge_manipulator_ctrl_mode_Passive_mode_velocitysim_ext_ros_bridge_manipulator_ctrl_mode_TF_positionsim_ext_ros_bridge_manipulator_ctrl_mode_TF_velocitysim_ext_ros_bridge_manipulator_ctrl_mode_TF_effort"
W804,https://wiki.ros.org/turtlebot_create_desktop,Wiki,turtlebot_create_desktop,Catkin meta-package for turtlebot_create_desktop 
W805,https://wiki.ros.org/tuw_marker_noise,Wiki,tuw_marker_noise,"The tuw_marker_noise package provides nodes
      for adding artificial noise to MarkerDetection messages from the marker_msgs package and
      for recording MarkerDetection messages in order to obtain a measurement noise model.








  






tuw_recordrecord.csvmarkersinputstringoutput_dirstringrecord.csvframe_id_odomstring""odom""variance.pyvariance.csvparameter.mparameter.csvrecordfilestringprecisiondoublevariance.csvparameter.csvfilestringmarkermarker_noisebeta_1/18doubleplot_databooleanfalserosrun tuw_marker_noise tuw_record.pyroslaunch tuw_marker_noise record.launch./variance.py -r ../output/record.csv -p 1.0octave> parameter('../output/variance.csv')rosrun tuw_marker_noise tuw_marker_noise.pyroslaunch tuw_marker_noise noise.launch"
W806,https://wiki.ros.org/sr_mechanism_controllers,Wiki,sr_mechanism_controllers,"

     The sr_mechanism_controllers package contains different types of
     controllers for the etherCAT hand:(fake) calibration controllers,
     position controllers, velocity controllers, force controllers, ...

  







The different controllers are implemented in this package. The controllers have access to an actuator which contains the hand data updated in real time by  and . The  package is used to record and interpolate the friction compensation map. Based on this map, we just add a value to the output of the controller as illustrated below (we have two different maps, one for each direction):  "
W807,https://wiki.ros.org/stdr_server,Wiki,stdr_server,"Implements synchronization and coordination functionalities of STDR Simulator.



 ()  ()  () 

 can run without any command-line arguments and simply waits until someone calls either  or  service. There is an option to run  passing an image file to load as the static map or you can include it to a launch file using the  option. 


The  node implements the synchronization and coordination functionalities of . It is used to serve the static map, which represents the simulated environment and keeps track of active robots. The  node provides several action server implementations used for robot handling and coordination. The  node uses 's  library to load an map image from a file, fill a  message, call  service and load it to the simulator. The loading functionality is also provided in  library and can be used by other packages.  For tutorials see . stdr_server_nodestdr_simulatorstdr_server_nodespawn_robotdelete_robotregister_robotstdr_robotmapmap_metadataactive_robotsload_static_mapload_static_map_externalrobot_manager/load_nodeletrobot_manager/unload_nodeletworldmapworldmap_staticstdr_server_nodeload_static_mapload_static_map_externalstdr_server_nodeargsmap_loader_nodeimage_loaderload_static_map_externalmap_loader$ rosrun stdr_server stdr_server_node <map_file.yaml>$ rosrun stdr_server load_map <map_file.yaml>"
W808,https://wiki.ros.org/vtec_ros,Wiki,vtec_ros,"The vtec_ros metapackage that installs VisioTec packages











Use GitHub to . []
 A  A technical report is available here: . It describes the tracker software and its working principles. If you use this software in an academic context, please cite the technical report, using: Download the dataset from here:  camera/imagetrack_cmdannotated_imagestabilized_imagereference_imagetrackingbbox_size_xintbbox_size_yintbbox_pos_xintbbox_pos_yintimage_topicstringmax_nb_iter_per_levelintmax_nb_pyr_levelintsampling_ratedoublehomography_typestringrobust_flagbool@TechReport{nogueira2019,
  author = {Lucas Nogueira and Ely de Paiva and Geraldo Silveira},
  title  = {Visio{T}ec robust intensity-based homography optimization software},
  number = {CTI-VTEC-TR-01-19},
  institution = {CTI},
  year = {2019},
  address = {Brazil}
}sudo apt-get install ros-[kinetic|melodic]-usb-cammkdir -p ~/catkin_ws/srccd ~/catkin_ws/src
git clone https://github.com/visiotec/vtec.git
cd vtec
mkdir build
cd build
cmake ..
makecd ~/catkin_ws/src
git clone https://github.com/visiotec/vtec_ros.git
cd ~/catkin_ws
catkin_make
source devel/setup.bashroslaunch vtec_tracker tracker.launchrosbag play vtec_test_tracker.bagroslaunch vtec_tracker tracker_live.launchroslaunch vtec_tracker tracker_live_occlusion.launch "
W809,https://wiki.ros.org/schunk_modular_robotics,Wiki,schunk_modular_robotics,"This stack includes packages that provide access to the Schunk hardware through ROS messages, services and actions.


For the Schunk Powercubes, see . For the Schunk SDH, see . Please consult  to see if your problem is already known. Please use the  for additional support or feature discussion. Use  to report bugs or request features.  "
W810,https://wiki.ros.org/trac_ik_python,Wiki,trac_ik_python,"The trac_ik_python package contains a python wrapper using SWIG
  for trac_ik_lib"
W811,https://wiki.ros.org/media_export,Wiki,media_export,Placeholder package enabling generic export of media paths.
W812,https://wiki.ros.org/kobuki_dashboard,Wiki,kobuki_dashboard,"The Kobuki dashboard is a RQT-based plug-in for visualising data from Kobuki and giving easy access
    to basic functionalities. 

The kobuki_dashboard is also part of the . In order to get the battery statuses, you need to launch the . $ roslaunch kobuki_node minimal.launch$ rosrun kobuki_dashboard kobuki_dashboard"
W813,https://wiki.ros.org/tf2_geometry_msgs,Wiki,tf2_geometry_msgs,"tf2_geometry_msgs



 "
W814,https://wiki.ros.org/ur_msgs,Wiki,ur_msgs,The ur_msgs package
W815,https://wiki.ros.org/twist_mux_msgs,Wiki,twist_mux_msgs,"The twist_mux msgs and actions package
  "
W816,https://wiki.ros.org/rosout,Wiki,rosout,"System-wide logging mechanism for messages sent to the /rosout topic.
 

 

 
 
 is an aggregated feed for subscribing to console logging messages. This aggregated topic is offered as a performance improvement: instead of connecting to individual ROS nodes to receive their console messages, the aggregated message feed can instead be received directly from the  node. 
 node by default logs all messages into  in the ROS log directory.  This can be disabled by setting environment variable  to  when launching .  This behavior can be changed by setting boolean ROS parameter  at any time. 
The   only provides the  node. Please see . The  node is part of  and has preferential startup order. ROS  are required to publish console logging messages to the  topic as a standard interface. By default,  prints  name for every message. No future development on  is currently planned. rosoutrosout/rosout/rosout/rosout_agg/rosout/rosout_agg/rosout/rosout/rosout_aggrosoutrosoutrosout.logROSOUT_DISABLE_FILE_LOGGINGTruerosout.logtopic/rosout/omit_topicsrosout"
W817,https://wiki.ros.org/stdr_samples,Wiki,stdr_samples,"Provides sample codes to demonstrate STDR simulator functionalities.

The  package provides code and launchers to demonstrate the  functionalities. The available samples follow. rosrun stdr_obstacle_avoidance robotX laser_Y"
W818,https://wiki.ros.org/rosh_visualization,Wiki,rosh_visualization,"

     ROSH plugin for the visualization stack.

  
 
:  show(cameras.camera)rviz/image_viewcameras"
W819,https://wiki.ros.org/rosnode,Wiki,rosnode,"rosnode is a command-line tool for displaying debug information
    about ROS ,
    including publications, subscriptions and connections. It also
    contains an experimental library for retrieving node
    information. This library is intended for internal use only.




 


 is a stable command-line tool within the ROS core toolchain. No major feature development is currently scheduled for this tool. The  command-line tool displays information about ROS . The currently supported commands are: IMPORTANT:  is not guaranteed to succeed. If a node is hung or set to ""respawn"" in , it may either fail to die or may quickly reappear. IMPORTANT:  was meant as a temporary solution and its use was not encouraged in normal operation. Its benefit is aesthetic and it has the downside of potentially unregistering functioning nodes. . rosnodeinfo <node-name>rosnode killkill <node-name>...killkill -akill --alllistlist <namespace>/namespacelist -ulist -alist --allmachine <machine-name>machineping <node-name>ping --all-c-aping -c COUNT--allrosnode cleanupcleanuprosnoderosnode info    print information about node
rosnode kill    kill a running node
rosnode list    list active nodes
rosnode machine list nodes running on a particular machine or list machines
rosnode ping    test connectivity to node
rosnode cleanup purge registration information of unreachable nodes$ rosnode info /node_name$ rosnode kill rosout add_two_ints_server$ rosnode kill
1. /rosout

Please enter the number of the node you wish to kill.
> $ rosnode list$ rosnode list /my_ns$ rosnode list -u$ rosnode list -a$ rosnode machine ninja.local
/talker-ninja.local-72266-1257921234733
/rosout
/listener-ninja.local-72615-1257921238320$ rosnode ping /node_name$ rosnode ping --all$ rosnode ping -c 4 rosout
rosnode: node is [/rosout]
pinging /rosout with a timeout of 3.0s
xmlrpc reply from http://ann:46635/     time=1.195908ms
xmlrpc reply from http://ann:46635/     time=1.123905ms
xmlrpc reply from http://ann:46635/     time=1.144886ms
xmlrpc reply from http://ann:46635/     time=1.137018ms
ping average: 1.150429ms$ rosnode cleanup"
W820,https://wiki.ros.org/sr_edc_launch,Wiki,sr_edc_launch,"

    Package with launch files to start the needed nodes for the Shadow Robot EtherCAT hand.

  
This package contains the main launch files used to start the etherCAT Hand ROS driver. For more information on how to start the interface, please go to the . "
W821,https://wiki.ros.org/nextage_ik_plugin,Wiki,nextage_ik_plugin,IKFast package for NEXTAGE OpenSee  tutorial for the usage of this package. 
W822,https://wiki.ros.org/asr_lib_ism,Wiki,asr_lib_ism,"This package contains the ROS-independent library which provides the actual scene-recognition functionality of Implicit Shape Model (ISM) trees. It is referred to both by asr_ism for Passive Scene Recognition and by asr_recognizer_prediction_ism for Active Scene Recognition. 


 Provides an interface to store sets of  objects to a sqlite database. Each set of objects represents a  configuration of objects for a certain scene. The Trainer and the CombinatorialTrainer  are interchangeable, both create a scene model represented by an ISM  from the object poses stored in the recorded database and write it into a  sqlite database. The ISM created by the CombinatorialTrainer should have a shorter computing time when it comes to recognizing a scene compared to the one created by the Trainer. Given a set of objects, the Recognizer calculates the  most likely scenes that those objects are part of. These calculations  use the scene models created by the Trainer/CombinatorialTrainer. 
Delete the recordings or the models or both from the database. Merge multiple databases into one.  Rotate the pose of objects which are determined by a marker e.g. .  Generates additional recording data  between objects by interpolating the pose of two objects between  consecutive recorded object sets.  Transform the absolute pose of an entire scene relative to a world coordinate frame.  Rotate Objects in the  database which are rotation invariant to the y-Axis around this y-Axis  to a given direction. As result these objects get distinct object poses. 


- Stores the representing name for a pattern.  - Stores a recorded object set at a point in time for a certain pattern.   - Stores the object estimation pose obtained from a object recognizer during the recording process.   - Stores the object estimation meta-data obtained from an object recognizer during the recording process. 
 - Stores trained patterns. - Store all objects which appeared while training the model.  - Stores the votes generated by the trainer. 








 Include   Create a new Recorder instance:  Insert objects of a recorded object configuration into the database: 
 Include   Create a new Trainer instance: Train ism for all patterns inside the database: Train ism only for the given pattern (patternName): Before using the trainPattern method, the training parameters  should be set. An example how to set those parameters can be found at asr_ism/src/trainer.cpp 
 Include   Create a new CombinatorialTrainer instance: Train ism for all patterns inside the database: 
 Include   Create a new  instance: Recognize most likely pattern for a given object configuration: 
This package contains the ROS-independent library which provides the actual scene-recognition functionality of Implicit Shape Model (ISM) trees. It is referred to both by  for Passive Scene Recognition and by  for Active Scene Recognition. XML is used to represent a scene, a pattern or just a set of objects for convenient use in simulation or to just store a certain configuration of objects for further use. E.g. use the XML to publish the contained object-set as recognized object estimations with the provided tool of the  package. This package only provides the library without any nodes, however the package  implements nodes for the actual usage of the recognition system.  <Objects>

  <Object type="""" id="""" mesh="""" angles=""quaternion""> x, y, z, qw, qx, qy, qz</Object>
  <Object type="""" id="""" mesh="""" angles=""euler""> x, y, z, alpha, beta, gamma</Object>

  ...

</Objects>Recorder(const std::string& dbfilename)void insert(const ObjectSetPtr& set, const std::string& patternName)Trainer(std::string dbfilename, bool dropOldModelTables)void trainPattern()void trainPattern(const std::string& patternName)CombinatorialTrainer(CombinatorialTrainerParameters params)std::map<std::string, std::pair<double, TreePtr> > learn()Recognizer(const std::string& dbfilename, double bin_size, double maxProjectionAngleDeviation, int raterType = 0)const std::vector<RecognitionResultPtr> recognizePattern(const ObjectSetPtr& _objectSet_, const double filterThreshold = 0.0, const int resultsPerPattern = -1, const std::string targetPatternName == """")"
W823,https://wiki.ros.org/ndt_registration,Wiki,ndt_registration,"

    Contains a new implementation of 3D NDT registration. 
    Used to find the relative positions of two point clouds.

  


This package implements point cloud registration, using the Normal Distributions Transform. Two basic classes are available - point to distributiuon registration (NDTMatcherP2D) and distribution to distribution registration (NDTMatcherD2D). The point to distribution algorithm is described  and the distribution to distribution . 













"
W824,https://wiki.ros.org/network_autoconfig,Wiki,network_autoconfig,ROS Networking Autoconfiguration
W825,https://wiki.ros.org/wire,Wiki,wire,"The wire meta package is implements a framework that 
     generates and maintains one consistent world state estimate based 
     on object detections. It solves the data association problem by 
     maintaining multiple hypotheses and facilitates tracking of various
     object attributes. The state estimators used for estimation and the
     probabilistic models used for association can be configured.






 J. Elfring, S. van den Dries, M.J.G. van de Molengraft, M. Steinbuch, Semantic world modeling using probabilistic multiple hypothesis anchoring, Robotics and Autonomous Systems, Volume 61, Issue 2, February 2013, Pages 95-105, () To install the  software, clone the source into your workspace: We have created a set of  explaining how to use, tune and interpret the world model and the resulting world state estimate. git clone https://github.com/tue-robotics/wire.gitcatkin_make"
W826,https://wiki.ros.org/maxwell_moveit_config,Wiki,maxwell_moveit_config,maxwell_moveit_config
W827,https://wiki.ros.org/maggie_ir_controller_msgs,Wiki,maggie_ir_controller_msgs,"ir_controller messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""maggie_ir_controller_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_ir_controller_msgs/manifest.yaml "
W828,https://wiki.ros.org/rail_ceiling,Wiki,rail_ceiling,"Overhead Camera System for Tracking AR Tags












 Rail_ceiling is an overhead camera system for tracking the positions of obstacles in a closed space and publishing maps containing those obstacles for use in robot navigation. Rail_ceiling supports multiple cameras and can publish multiple maps with different obstacle footprints. Obstacle tracking is accomplished using ar tags and the  ros package.  The  node will run an automatic calibration procedure where each camera will take sample poses of an associated marker of known position in the environment.  Once a sufficient number of samples have been taken for each camera, the transforms will be calculated and written to the  file in your home directory, and must then be copied into the  directory of the  package if you wish to use it. The  node provides a method of calibrating the camera transforms from a marker placed on a localized mobile robot, such as the CARL platform.  This calibration method is executed as follows: Next, the robot must be driven into the field of view of a camera to be calibrated.  Once the robot is in the camera's field of view and it is confirmed to be accurately localized, publishing to the  topic with the id number of the camera to be calibrated replacing [camera_id]: Once sufficient samples are collected for all of the cameras, the transforms will be calculated and written to the  file in your home directory, and must then be copied into the  directory of the  package if you wish to use it. The transforms can also be edited directly in the human-readable urdf file, .  This should only be done if the camera positions and orientations can be accurately measured. Furniture footprints and marker information can be configured in the  and  file in the  directory.  The  configuration file defines general pieces of furniture with convex polygon footprints for localization and navigation, and the  configuration file defines instances of furniture with attached markers and their associated poses. To add a new type of furniture, simply add a new entry to the  file.  Each entry must have a name (for identifying the type of furniture) a localization footprint (a set of convex polygons that a laser scanner will detect), and a navigation footprint (a set of convex polygons that represent the full area occupied by the piece of furniture that should be avoided during navigation).  The entry format is as follows: Points composing the polygons are defined with respect to the center of the piece of furniture, according to a coordinate system with x increasing right, y increasing forward, and z increasing up.  In practice, the reference frame's position does not have to be at the center of the furniture piece, as long as it is consistent with the reference frame defined for instances of the furniture type in the  file. Each piece of furniture in th eenvironment must have its own entry in the  file.  Each entry consists of a required type (corresponding with the furniture names defined in ), an optional initial_pose (an initial pose for the piece of furniture in the global coordinate frame), and a required set of markers.  Markers are defined with the unique id used to generate them, and the pose of the marker with respect to the furniture reference frame.  The entry format is as follows: The main functionality of the  package is furniture tracking.  This can be launched with: Please send bug reports to the . ceiling_cam_tracker_[i]/ar_pose_markerfixed_framestringcamera_frame_id_prefixstringnum_camerasintnum_samplesintceiling_cam_[i]_pos_xdoubleceiling_cam_[i]_pos_ydoubleceiling_cam_[i]_pos_zdoubleceiling_cam_[i]_rot_xdoubleceiling_cam_[i]_rot_ydoubleceiling_cam_[i]_rot_zdoubleceiling_cam_[i]_rot_wdoubleceiling_cam_tracker_[i]/ar_pose_markerstart_calibrationnum_camerasintcalibration_marker_idintceiling_cam_tracker_[i]/ar_pose_markerstart_calibrationfurniture_layer/update_obstaclesfurniture_tracker/get_all_posesnum_marker_topicsintread_initial_posesboolmarkers_configstringfurniture_footprints_configstringcalibrationceiling.urdf.xacrourdfrail_ceilingcalibration_from_carlstart_calibrationceiling.urdf.xacrourdfrail_ceilingurdf/ceiling.urdf.xacrofurniture_footprints.yamlmarkers.yamlconfigfurniture_footprints.yamlmarkers.yamlfurniture_footprints.yamlmarkers.yamlmarkers.yamlfurniture_footprints.yamlrail_ceilingcd /(your catkin workspace)/src
git clone https://github.com/WPI-RAIL/rail_ceiling.git
cd ..
catkin_makeroslaunch rail_ceiling calibration.launchroslaunch rail_ceiling view_calibration.launchroslaunch rail_ceiling cameras.launch
roslaunch rail_ceiling ar_trackers.launch marker_size:=12.0
roslaunch rail_ceiling calibration_from_carl.launchrostopic pub /start_calibration std_msgs::Int16 ""data: [camera_id]""- name: furniture_name
  localization_footprint:
    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]
    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]
    - ...
  navigation_footprint:
    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]
    - polygon: [[x1, y1], [x2, y2], [x3, y3], ..., [xn, yn]]
    - ...- type: furniture_name
  initial_pose: [x0, y0, theta0]
  markers:
    - id: 1
      x: x1
      y: y1
      theta: theta1
    - id: 2
      x: x2
      y: y2
      theta: theta2
    - ...roslaunch rail_ceiling ceiling_description.launchroslaunch rail_ceiling furniture_tracker.launchroslaunch rail_ceiling cameras.launch
roslaunch rail_ceiling ar_trackers.launch"
W829,https://wiki.ros.org/xbot_description,Wiki,xbot_description,"The urdf model description package for xbot robot.
roslaunch xbot_description display.launchroslaunch xbot_description gazebo.launch"
W830,https://wiki.ros.org/stop_base,Wiki,stop_base,"Stop base controller for any robot using the cmd_vel interface.
 "
W831,https://wiki.ros.org/rtt_trajectory_msgs,Wiki,rtt_trajectory_msgs,"Provides an rtt typekit for ROS trajectory_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/trajectory_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W832,https://wiki.ros.org/turtlebot3_panorama,Wiki,turtlebot3_panorama,"This app utilises pano_ros for taking snapshots and stitching them together to create panorama pictures. 




odomcamera/rgb/image_rawcmd_velpanoramacamera_infoimage/compressedimage/compressedcamera/rgb/image_raw"
W833,https://wiki.ros.org/teleop_twist_keyboard_cpp,Wiki,teleop_twist_keyboard_cpp,"Generic keyboard teleop for twist robots (in C++)! Based off of the teleop_twist_keyboard Python ROS node.



C++ Implementation of the Generic Keyboard Teleop for ROS:  $ git clone https://github.com/methylDragon/teleop_twist_keyboard_cpp.git
$ cd ..
$ catkin_make

$ source devel/setup.bash# In one terminal, run
$ roscore

# In another terminal, run
$ rosrun teleop_twist_keyboard_cpp teleop_twist_keyboard

# If you want to see the outputs, check the /cmd_vel topic
$ rostopic echo /cmd_velReading from the keyboard  and Publishing to Twist!
---------------------------
Moving around:
   u    i    o
   j    k    l
   m    ,    .

For Holonomic mode (strafing), hold down the shift key:
---------------------------
   U    I    O
   J    K    L
   M    <    >

t : up (+z)
b : down (-z)

anything else : stop

q/z : increase/decrease max speeds by 10%
w/x : increase/decrease only linear speed by 10%
e/c : increase/decrease only angular speed by 10%

CTRL-C to quit"
W834,https://wiki.ros.org/ros_canopen,Wiki,ros_canopen,"A generic canopen implementation for ROS
  "
W835,https://wiki.ros.org/pr2_make_a_map_app,Wiki,pr2_make_a_map_app,"
   Make maps using the PR2 robot.
  
"
W836,https://wiki.ros.org/steer_drive_controller,Wiki,steer_drive_controller,"Controller for a steer drive mobile base.










 () 
 () 
 (, default: 50.0) 
 (, default: base_link) 
 (, default: 1.0) 
 (, default: false) 
 () 





 An example of using the packages can be seen in . The controller inherits  to work with wheel joints through a  interface for a linear wheel and a  interface for a front steer wheel, which is the the most basic configuration for the steer driving mechanism. If you want  to show states of robot's actual joint interfaces'  through  and , you need to convert the two interfaces of  to your robot's specific ones via  or RobotHWSim (generally used for ). This is because the controller only update it's basic interfaces mentioned in the previous section. The controller main input is a  topic in the namespace of the controller. An example for usage of  with  can be grabbed from . We developped a general RobotHWSim plugin for usage of . You can get the plugin from  and also see an example of application on . We also provide a recovery behavior plugin of  specifically desigined for steer mechanism base robots in . Feel free to see  to learn how to use it. steer_drive_controllercmd_velodom/tfrear_wheelstringfront_steerstringpose_covariance_diagonaldouble[6]twist_covariance_diagonaldouble[6]publish_ratedoublecmd_vel_timeoutdoublebase_frame_idstringodom_frame_idstringenable_odom_tfboolwheel_separation_h_multiplierdoublewheel_radius_multiplierdoublesteer_pos_multiplierdoublelinear/x/has_velocity_limitsboollinear/x/max_velocitydoublelinear/x/min_velocitydoublelinear/x/has_acceleration_limitsboollinear/x/max_accelerationdoublelinear/x/min_accelerationdoublelinear/x/has_jerk_limitsboollinear/x/max_jerkdoubleangular/z/has_velocity_limitsboolangular/z/max_velocitydoubleangular/z/min_velocitydoubleangular/z/has_acceleration_limitsboolangular/z/max_accelerationdoubleangular/z/min_accelerationdoubleangular/z/has_jerk_limitsboolangular/z/max_jerkdoublewheel_separation_hdoublewheel_radiusdoublesteer_drive_controllermobile_base_controller:
  type: ""steer_drive_controller/SteerDriveController""
  rear_wheel: 'rear_wheel_joint'
  front_steer: 'front_steer_joint'
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]mobile_base_controller:
  type        : ""diff_drive_controller/DiffDriveController""
  rear_wheel: 'rear_wheel_joint'
  front_steer: 'front_steer_joint'
  publish_rate: 50.0               # default: 50
  pose_covariance_diagonal : [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]

  # Wheel separation between the rear and the front, and diameter of the rear. 
  # These are both optional.
  # steer_drive_controller will attempt to read either one or both from the
  # URDF if not specified as a parameter.
  wheel_separation_h : 1.0
  wheel_radius : 0.3

  # Wheel separation and radius multipliers for odometry calibration.
  wheel_separation_h_multiplier: 1.0 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0

  # Steer position angle multipliers for fine tuning.
  steer_pos_multiplier       : 1.0

  # Velocity commands timeout [s], default 0.5
  cmd_vel_timeout: 0.25

  # Base frame_id
  base_frame_id: base_footprint #default: base_link

  # Odom frame_id
  odom_frame_id: odom

  # Velocity and acceleration limits
  # Whenever a min_* is unspecified, default to -max_*
  linear:
    x:
      has_velocity_limits    : true
      max_velocity           : 1.0  # m/s
      min_velocity           : -0.5 # m/s
      has_acceleration_limits: true
      max_acceleration       : 0.8  # m/s^2
      min_acceleration       : -0.4 # m/s^2
      has_jerk_limits        : true
      max_jerk               : 5.0 # m/s^3

  angular:
    z:
      has_velocity_limits    : true
      max_velocity           : 1.7  # rad/s
      has_acceleration_limits: true
      max_acceleration       : 1.5  # rad/s^2
      has_jerk_limits        : true
      max_jerk               : 2.5 # rad/s^3"
W837,https://wiki.ros.org/sr_visualization,Wiki,sr_visualization,"This stack contains the different gui and gui plugins used with the shadow robot stacks.
 is a package with GUI plugins which can be used to control the different nodes of the  stack. The GUI plugins are programmed in Python and can be started from within rqt. A ROS master must be running before starting rqt. ROS master and rqt can be started by simply typing in linux command line:  
 $ roscore$ rqt"
W838,https://wiki.ros.org/turtlebot3_fake,Wiki,turtlebot3_fake,"Package for TurtleBot3 fake node. With this package, simple tests can be done without a robot.
    You can do simple tests using this package on rviz without real robots. 


cmd_veljoint_statesmagnetic_fieldtf"
W839,https://wiki.ros.org/lyap_control,Wiki,lyap_control,"A node to control nonlinear dynamic systems
 


The lyap_control package provides a sophisticated and relatively easy-to-use control node. It can handle regulation or tracking problems of any order and with any number of inputs... from simple first order dynamic systems where a PID controller would typically be used... up to complex, large, higher-order systems. There is also a  which can be used to visualize, tune, and simulate the control algorithm beforehand. The default example of the MATLAB toolbox shows the simultaneous tracking of seven motors. The theory behind the algorithm is explained . (You may have to do this every time you open a new terminal window, or add this line to your bashrc: ) This launches a simulation of a 2nd-order system with (1,-2) setpoints. The displayed  is the sum-of-squares of the error for all states (it should drop exponentially). You may wish to tune the controller at this point. You can adjust its 'aggressiveness', called , in controller.h. Generally a more negative value performs better, unless the time step is too small and it becomes unstable. The saturation limits on the control effort (maximum and minimum) and the controller's model of the system are also adjusted here. The time step for the simulation is adjusted as the variable  in second_order_plant_header.h. A smaller time step will perform better. To demonstrate how to switch to a different dynamic system, a first-order single-input example is included (). Here are the changes that must be made to control this other system: 1. In , change  and  to one-vectors since there is one input now. 2. Edit the model definition in  to update the controller's model of the system. Comment the second equation so there is just one state variable 3. Since there are fewer states and inputs, the messages that the nodes pass must be shorter. In , update  to a 1-vector. In , update  and  to 1-vectors. If you wish to change the initial conditions or the setpoints, or even make a time-varying setpoint, you can do so in . If you want more aggressive gain, again, change  in  In general, the best results are achieved with a very high control rate and a very large 'gain.' Set the loop rate of your plant and the controller as fast as the hardware will allow, then set the gain (a.k.a. ) as high as stability allows. These changes are made in  $ mkdir -p ~/Desktop/catkin_ws/src
$ cd ~/Desktop/catkin_ws/src
$ catkin_init_workspace$ git clone https://bitbucket.org/AndyZe/lyap_control.git
$ cd ..$ catkin_make$ source devel/setup.bash$ roslaunch lyap_control lyap_control.launch$ roscore
$ rosrun lyap_control controller (publishes data on the control_effort topic)
$ rosrun lyap_control second_order_plant (publishes data on the state topic)$ catkin_make$ roscore$ rosrun lyap_control controller$ rosrun lyap_control first_order_plant"
W840,https://wiki.ros.org/spatial_world_model,Wiki,spatial_world_model,"Spatial World Model for Object Tracking










 




 




 


 

As a basic example for the types of end-user interfaces that can be created with the Spatial World Model, we look at the Map annotation interface. Information on this interface can be found on the . Below is a video demonstrating its capabilities: The following steps are written for  but apply to most Linux systems. To begin, we must install  and the Python libraries that will talk to it. To do so, run the following command: Finally, we are able to install the database schema. This is provided in a script found in the  package. This script can be used to both install a new database and to update an existing one. In many cases, you will be installing the Spatial World Model database on a central server so that multiple clients (and robots) can talk to it. As of now, the ROS nodes communicate via SQL to the database; however, due to security risks this will eventually be changed. To allow remote connections, we must modify the configuration scripts on the system. Using your choice of editor, modify  with root privileges and add the following line: Next, modify  with root privileges and add the following line: At its core, the Spatial World Model is designed to be a persistent, multi-robot model to keep track of both the robot's working memory as well as keeping track of properties, affordances, and activities that can be associated with each object. To manage persistence, the world model is stored in a  database  At a high level, currently the Spatial World Model allows for two sets of entities: a  and a . A , defined in the  message, can be thought of as a robot's working memory. At a basic level, such an entity contains a relative pose in the world with associated tags and timestamps. These entities describe a particular, specific instance of an object in the world (e.g., the cup sitting on the desk in the conference room). Each instance is linked to a single  which contains a set of spatial descriptors for the object (e.g., mesh, bounding box, point-cloud cluster, etc...). Below is a detailed explanation of the fields in the . Note that some fields will be blank depending on the type of object or what you know about the world.  The second implemented entity is the . This entity, defined in the  message, contains spatial descriptors of objects in the world. These are shared models that are common between all instances of such an object (e.g., a 3D mesh of the object itself). Each descriptions contains a set of tags and an array of actual s. The genericness of the descriptor model allows for models to come from a variety of sources (point cloud segmentation, 3D model warehouses and databases) with few-to-no restrictions. The main idea is to associate an appropriate  and  field with each descriptor to determine how the data should be treated. In a sense, the  field can be thought up as a non-standard MIME type (PNG, Collada, but also  as a type). Future goals of the project set out to create a standard set of accepted type fields. Below is a detailed description of the fields associated with a . The first design decision was to use a  database for storage. Given the highly relational components associated with the world model (e.g.,  and ), it made sense to use such a database over other types of databases. For efficiency in searching and storage, the database schema itself is broken into finer grains than the APIs allow for. It is intended that developers make user of these higher-level APIs when dealing with the Spatial World Model as apposed to making raw SQL queries. The current implementation includes several layers of APIs. As mentioned previously, it is not intended for a developer to use the world model by directly making SQL queries. At the lowest level, the  Python API should be used. This level of the API is responsible for talking SQL to the world model database and is able to make basic insertion and search queries while maintaining the correct structure. This level of the API allows for non-ROS processes to make use of the world model (another future goal of the project). By using an SQL connection between this library and the database, remote connections can be made and a central database can be used (such as one hosted in the cloud). This, of course, requires your server to allow remote SQL connections which is not ideal. Therefore, future plans hope to create a server-side API to allow for remote queries (think REST as an example but this would require polling). With such an API in place, the interface between the robot or client and the database could be made with this new service. Furthermore, a  library is provided in  to allow remote web clients to interact with the world model. This API currently uses  and  to communicate with the world mode; however, as discussed above, the eventual goal is to have a standard server-side API to communicate with directly instead of using ROS. Within ROS, the intended use of the APIs into the world model was to create a series of what are being called listener nodes. Such nodes listen to a set of defined topics, make the appropriate inferences on the information, and update the world model accordingly. Below are three examples included in .  To allow for multiple robots, a notion of namespacing must be kept. To support this feature early on, this information is currently held inside of the  of the instance. It is up to the developer to maintain this namespace. For example, the above listeners take an optional argument to define the namespace. If no namespace is given, it will default to the hostname of the machine the node is running on. In most cases, this is good enough since the hostname of the robot is usually a good namepsace. Then, when searching for things like a particular robot, we can do a tag search for . Future improvements should be made to make this clearer and enforce unique namespacing.  One improvement to the current system would be to separate the  array into its own separate database. The idea behind properties is to define relationships such as  or  between entities in the world model. Current thoughts are to point to entries within a graph database. By doing so, powerful search queries to can written such as ""give me all the objects inside the bedroom?"" or ""is the book on my bookshelf?"" in an efficient way.  One large piece of the world model that is missing is the notice of affordances. The goal of the Spatial World Model is to not only keep track of particular instances of objects, but to also manage what types of actions can be taken on certain objects. For example, a door can be opened, a cup can be grasped, and a robot can grasp (assuming it has a gripper, of course). Furthermore, pre-conditions should also be stored here. For example, the cup must be on the table to be picked up (or any number of other conditions). This would rely on the implementation of the graph database described above. These types of attributes should be stored in a separate table in the database and linked to a particular .  In addition to the affordances, a notion of activities, must be stored as well. Such a structure would be used to figure out how to perform such an action on such an object. For example, if you wanted to use a  action on a coffee cup, the associated activity would be some action call to a grasping pipeline. Each activity can be thought of as a node with some kind of transition model incorporated to provide feedback and belief states. An updated diagram of the Spatial World Model would be the following: In addition to abstracting out the  as defined above, several improvements are needed with respect to the instances. For one, belief states should be associated with most attributes. While the current  does allow for this, beliefs about things just as timestamps are just as important.  A second major component is a cleanser process for the database. Currently, descriptions can be linked to multiple instances. This is the main idea behind the descriptions itself. Additionally, these descriptions can potentially contain massive amounts of data (Collada models for example). If there are no longer any instances linked to a given description, it should be removed not only from the database itself, but from the disk as well (since the large data portions are kept in . Care should be taken to ensure thread safety in the removal. Perhaps the largest piece needed in the project is a more robust, efficient, and flexible server-side API for the world model. Currently, the  Python API is used by the main ROS node and speaks SQL to the database. For many reasons, security being one, this is not ideal. Efforts should be made to create a server-side API that allows for multiple remote connections to interact with the world model. Not only would this still allow the robots to communicate with the world model, but clients could now directly connect to the world model instead of using  as a ""proxy"". While at first glance it may seem appropriate, this API should not be response-based such as a REST API. A more robust socket-level connection should be made to allow for bi-directional communication. By standardizing a server-side interface, we can also create a more powerful query system. The protocol between clients and the server could include things like searching descriptions or descriptors without having to return the data associated with them. This allows clients to subscribe to changes in the world model without the need of polling. A diagram of the updated API levels is shown below. Discussions and contributions are welcome! To get involved, check out the  for current feature requests and discussions.  Please send bug reports to the . Feel free to contact me at any point with questions and comments.  spatial_world_model/etc/postgresql/9.1/main/pg_hba.conf/etc/postgresql/9.1/main/postgresql.confWorldObjectInstanceWorldObjectDescriptionWorldObjectInstanceWorldObjectDescriptionWorldObjectInstanceinstance_idnamecreationupdateexpected_ttlperceived_endsourceorigincreatorposeframe_idinstance_iddescription_idWorldObjectDescriptionpropertieson(45)tagsWorldObjectDescriptionDiscriptortypereftypenav_msgs/OccupancyGridWorldObjectDescriptiondescription_idnamedescriptorstypedatareftagstagsWorldObjectInstanceWorldObjectDescriptionJavaScriptmap_listener/mapmaprobot_pose_listenerrobot_pose_listener/robot_pose/initposetags[""robot"", ""myRobotName""]propertiesoninWorldObjectDescriptionpickuppropertiesposesudo apt-get install git postgresql python-psycopg2sudo -u postgres createdb world_modelsudo -u postgres createuser -D -A -P <username>





host     world_model     <username>      0.0.0.0/0               md5listen_addresses = '*'sudo service postgresql restart"
W841,https://wiki.ros.org/imu_handler,Wiki,imu_handler,"The imu_handler package
"
W842,https://wiki.ros.org/stdr_msgs,Wiki,stdr_msgs,"Provides msgs, services and actions for STDR Simulator.
 package provides the essential ROS messages, services and actions for the  to operate. Newly proposed, mistyped, or obsolete package. Could not find package ""stdr_msgs"" in rosdoc: /home/rosbot/docs/api/stdr_msgs/manifest.yaml "
W843,https://wiki.ros.org/staubli_val3_driver,Wiki,staubli_val3_driver,"
     ROS-Industrial VAL3 driver for interfacing with Staubli CS8 robot controllers.
   
     This package is part of the ROS-Industrial program and contains a VAL3
     application and libraries that implement an industrial_robot_client
     compatible server program.
   
     See the readme and wiki for more information.
   




Use GitHub to . []
 This is a VAL 3 based driver for use with CS8 controllers and Staubli 6-axis manipulators. See the  for more information. For the generic ROS-Industrial tutorials, please see the ROS-Industrial . For questions related to the Staubli support or ROS-Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. "
W844,https://wiki.ros.org/turtlebot_exploration_3d,Wiki,turtlebot_exploration_3d,"Autonomous Exploration package for a Turtulebot equiped with RGBD Sensor(Kinect, Xtion) 












Please follow the turtlebot network  to setup network between turtlebot and remote PC. tf/camera/depth_registered/pointsoctomap_3d@inproceedings{bai2016information,
  title={Information-theoretic exploration with Bayesian optimization},
  author={Bai, Shi and Wang, Jinkun and Chen, Fanfei and Englot, Brendan},
  booktitle={Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},
  pages={1816--1822},
  year={2016},
  organization={IEEE}
}@inproceedings{bai2015inference,
  title={Inference-Enabled Information-Theoretic Exploration of Continuous Action Spaces},
  author={Bai, S. and Wang, J. and Doherty, K. and Englot, B.},
  booktitle={International Symposium of Robotics Research},
  year={2015}
}sudo apt-get install ros-indigo-octomap*git clone https://github.com/RobustFieldAutonomyLab/turtlebot_exploration_3d.gitcatkin_makesudo apt-get updatesudo apt-get install ros-indigo-turtlebot-exploration-3d$ roslaunch turtlebot_exploration_3d minimal_explo.launch
$ roslaunch turtlebot_exploration_3d turtlebot_gmapping.launch
$ rosrun turtlebot_exploration_3d turtlebot_exploration_3droslaunch turtlebot_exploration_3d exploration_rviz.launch"
W845,https://wiki.ros.org/tello_driver,Wiki,tello_driver,">This package provides a ROS interface for the TelloPy library. Development of this ROS package pursues not to modify the TelloPy library, instead apply any modification or addition to the ros_driver package in an encapsulated manner.Use GitHub to . []
  
























 Communicating with the Tello drone can be done either using official  or one of the unofficial libraries. The unofficial libraries originated from the reverse-engineering the raw packages broadcasted by the Tello. This ROS package is build on top of the unofficial  library. The  library is used at this moment since it offers more functionalities than the official  or any other unofficial library. Developing of the tello_driver ROS package is inspired by , which by now diverged considerately from the original work. Furthermore, development of this ROS package pursues not to modify the  library, but instead apply any modification or addition to the ros_driver package in an encapsulated manner. This prevents breaking functionalities when updating the  library. Main node running as interface for the  library Converting gamepad input controls from  to commands for  Receive input from gamepad controller and publish into  message TELLO_XXXXXX/tello/cmd_vel/tello/emergency/tello/fast_mode/tello/flattrim/tello/flip/tello/land/tello/palm_land/tello/takeoff/tello/throw_takeoff/tello/camera/camera_info/tello/image_raw/tello/imag/raw/h264/tello/odom/tello/imu/tello/status~/tello_driver_node/connect_timeout_sec~/tello_driver_node/fixed_video_rate~/tello_driver_node/local_cmd_client_port~/tello_driver_node/local_vid_server_port~/tello_driver_node/stream_h264_video~/tello_driver_node/tello_cmd_server_port~/tello_driver_node/tello_ip~/tello_driver_node/vel_cmd_scale~/tello_driver_node/video_req_sps_hz~/tello_driver_node/altitude_limit~/tello_driver_node/attitude_limit~/tello_driver_node/low_bat_thresholdjoy_nodetello_driver_node/joy/tello/agent_cmd_vel_in/tello/cmd_vel/tello/emergency/tello/fast_mode/tello/flattrim/tello/flip/tello/land/tello/palm_land/tello/takeoff/tello/throw_takeoffsensor_msgs/Joy/joy~/joy_node/deadzone~/joy_node/devtello_driver_node$ sudo apt install ros-kinetic-tello-driver$ cd <CATKIN_WS/SRC>$ git clone --recursive https://github.com/appie-17/tello_driver.git$ cd ..$ catkin_make$ source devel/setup.bash $ roslaunch tello_driver tello_node.launch$ pip install av --user$ sudo add-apt-repository ppa:jonathonf/ffmpeg-3   
$ sudo apt update && sudo apt install ffmpeg"
W846,https://wiki.ros.org/tf_conversions,Wiki,tf_conversions,"This package contains a set of conversion functions to convert
common tf datatypes (point, vector, pose, etc) into semantically
identical datatypes used by other libraries. The conversion functions
make it easier for users of the transform library (tf) to work with
the datatype of their choice. Currently this package has support for
the Kinematics and Dynamics Library (KDL) and the Eigen matrix
library. This package is stable, and will get integrated into tf in
the next major release cycle (see roadmap).

We plan to replace this package with a more advanced template-based data conversion package, as part of the redesign of the  API. See the  for more details. "
W847,https://wiki.ros.org/win_appupdater,Wiki,win_appupdater,"

     win_appupdater

  Some scripts to help out with setting up the  repositories, namely key signing. "
W848,https://wiki.ros.org/katana_driver,Wiki,katana_driver,"This stack contains all descriptions, drivers and bringup facilities for Neuronics Katana 450 arm.


: This will move the robot arm without any obstacle avoidance whatsoever, so if you run this on a physical arm, make sure the workspace of the robot is clear. 
 has to be configured individually for each robot. At Osnabrück University, we have Calvin, a robot that consists of a Volksbot base and a Katana arm. You can see instructions how to run the full  stack in Gazebo, including motion planning, inverse kinematics, collision environment etc. on the  wiki page. 
 
Use GitHub to . []
  You should set your Katana type as an environment variable, for example in your /. At the moment, only the Katana 450 6M90A and the Katana 300 6M180 (experimental) are supported. Include one of the following lines: .bashrc.zshrcsudo apt-get install ros-$ROS_DISTRO-katana-driverexport KATANA_TYPE=""katana_300_6m180""
export KATANA_TYPE=""katana_450_6m90a""roslaunch katana katana.launchroslaunch katana_arm_gazebo katana_arm.launchroslaunch katana_teleop katana_teleop_key.launchroslaunch katana_tutorials follow_joint_trajectory_client.launch"
W849,https://wiki.ros.org/win_boost,Wiki,win_boost,"

  Scripts to help download, patch and compile cmake boost.

  "
W850,https://wiki.ros.org/canopen_chain_node,Wiki,canopen_chain_node,"Base implementation for CANopen chains node with support for management services and diagnostics






 This packages contains the ROS interface for  and . It can be used as a stand-alone ROS node, but as well as a base class for profile specific ROS interfaces, e.g. . The bus settings consists of a CAN interface () and the shared bus settings for . Each node (or in the defaults) can be passed a publish parameter with a list of object names. The topic types correspond to the object types, e.g. UNSIGNED16 to . It is meant for debugging or for simple CANopen interfaces, since it blocks the control loop. Each entry can have an exclamation mark appended that forces the driver to reread the object form the node in each step. The  can be passed the diagnostic_period parameter in fractional seconds. This package provides a  class that implements a  interface and takes care of the parameter parsing and the life-cycle. It can be customized via its virtual interface, especially with  /diagnosticsdriver/initdriver/haltdriver/recoverdriver/shutdowndriver/get_objectdriver/set_object~diagnostic_perioddouble~busstruct~syncstruct~heartbeatstruct~defaultsstruct~nodesstruct/listcanopen::RosChaincanopen::LayerStackRosChain::nodeAdded














































"
W851,https://wiki.ros.org/turtlebot_viz,Wiki,turtlebot_viz,"turtlebot_viz
This stack contains visualization tools for TurtleBot.    - a display panel for monitoring the status of a running TurtleBot.   - tools for interacting with the TurtleBot in rviz.  
  "
W852,https://wiki.ros.org/tuw_marker_filter,Wiki,tuw_marker_filter,The tuw_marker_filter package
W853,https://wiki.ros.org/stereo_wall_detection,Wiki,stereo_wall_detection,"
    Detects planar structures (e.g., walls) from stereo cameras point clouds (usually generated using a texture projector).
  "
W854,https://wiki.ros.org/osg_markers,Wiki,osg_markers,osg_markers can be used to create Markers geometry in OSG.
W855,https://wiki.ros.org/turtlebot3_gazebo,Wiki,turtlebot3_gazebo,"Gazebo simulation package for the TurtleBot3 




scanjoint_statescmd_vel/modelString/cmd_velString/namestring"
W856,https://wiki.ros.org/vicon_bridge,Wiki,vicon_bridge,"

     This is a driver providing data from VICON motion capture systems. It is based on the vicon_mocap package from the starmac stacks. 
     Additionally, it can handle multiple subjects / segments and allows to calibrate an origin of the vehicle(s) as this is somehow tedious with the VICON Tracker.

  





All available subjects and segments are recognized automatically and are published as tf transform and  as .  Sometimes vicon data is too perfect  This motivated , which adds different types of noise, adds delay or reduces the framerate to test how robots work with bad data.  Then run  to set the parameters. This is work in progress, suggestions are welcome.  ~stream_modeSetStreamMode()ServerPushClientPullServerPushClientPullvicon/<subject_name>/<segment_name>tf_distortvicon/<subject_name>/<segment_name>vicon/markers~/calibrate_segment~/grab_vicon_pose~stream_modestring~datastream_hostportstring~tf_ref_frame_idstring~/<subject_name>/<segment_name>/zero_pose/orientation/wdouble~/<subject_name>/<segment_name>/zero_pose/orientation/xdouble~/<subject_name>/<segment_name>/zero_pose/orientation/ydouble~/<subject_name>/<segment_name>/zero_pose/orientation/zdouble~/<subject_name>/<segment_name>/zero_pose/position/xdouble~/<subject_name>/<segment_name>/zero_pose/position/ydouble~/<subject_name>/<segment_name>/zero_pose/position/zdouble~/<subject_name>/<segment_name>/zero_pose/orientation/wdouble~/<subject_name>/<segment_name>/zero_pose/orientation/xdouble~/<subject_name>/<segment_name>/zero_pose/orientation/ydouble~/<subject_name>/<segment_name>/zero_pose/orientation/zdouble~/<subject_name>/<segment_name>/zero_pose/position/xdouble~/<subject_name>/<segment_name>/zero_pose/position/ydouble~/<subject_name>/<segment_name>/zero_pose/position/zdoubleworldvicon/<subject_name>/<segment_name>from~tf_ref_frame_id~/calibrate_segmentroslaunch vicon_bridge vicon.launchrosrun vicon_bridge calibrate <subject name> <segment name> <z offset>rosrun vicon_bridge tf_distort"
W857,https://wiki.ros.org/world_canvas_msgs,Wiki,world_canvas_msgs,World canvas framework messages package
W858,https://wiki.ros.org/summit_xl_control,Wiki,summit_xl_control,"This package contains the launch files that load the required controller interfaces for simulation in Gazebo.
This package contains the launch and configuration files to spawn the joint controllers with the ROS controller_manager. It allows to launch the joint controllers for the Summit XL (4 axes skid steering + 2 axes ptz), Summit XL OMNI (4 axes skid steering, 4 axes swerve drive), Summit X-WAM (4 axes skid steering, 4 axes swerve drive, 1 linear axis for scissor mechanism). The Summit XL simulation stack follows the gazebo_ros controller manager scheme described in  "
W859,https://wiki.ros.org/rc_visard_description,Wiki,rc_visard_description,"Visualization package for rc_visard



"
W860,https://wiki.ros.org/rmp_msgs,Wiki,rmp_msgs,"The rmp_msgs package defines rmp specific messages such as motor status, audio command, ...
 contains message types for interacting with and receiving feedback from a Segway RMP. Newly proposed, mistyped, or obsolete package. Could not find package ""rmp_msgs"" in rosdoc: /home/rosbot/docs/api/rmp_msgs/manifest.yaml rmp_msgs"
W861,https://wiki.ros.org/asr_ism_visualizations,Wiki,asr_ism_visualizations,"This package provides visualization logic for ism data, e.g. visualization with marker in rviz. 
:  

   
   
   
   





The  package contains several classes for visualization of the ISM-datastructures. There are visualizations for the ISM itself, the pose prediction, the voting space, as well as for the reconstruction of the scene and basic visualizations of objects and object-overlays in RVIZ. It doesn't contain any nodes and its more like a library. Normally this package is used by another package like  and provides no independent components. Only topics of dynamic reconfigure are being subscribed to. (e. g. ) All generated markers of ISM-result-visualization, pose-prediction-visualization and voting-space-visualization are published (by default) on  (msg-Type: Markerarray) "
W862,https://wiki.ros.org/summit_xl_common,Wiki,summit_xl_common,"URDF description of the Summit XL and Summit XL HL, platform messages and other files for simulation.
 




This package contains the different controllers and launch files for the , shared for real robot and simulation.  This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux () so that the final command to the robot can be set by different components (move_base, etc.) "
W863,https://wiki.ros.org/siftgpu,Wiki,siftgpu,"

    The SiftGPU library is an implementation of SIFT for GPU.
     
  
     For more details go to the  "
W864,https://wiki.ros.org/tf_keyboard_cal,Wiki,tf_keyboard_cal,"Allows manual control of a TF through the keyboard
See  for full documentation. "
W865,https://wiki.ros.org/asr_direct_search_manager,Wiki,asr_direct_search_manager,"This package can be used to generate and manage poses for the direct mode of 3-D
    object search. The direct mode is used as an opening procedure for Active Scene Recognition.
    The poses will be generated so that they cover the current environment map.
    There are different modes to generate these poses. One is based on a grid and a
    second on a recording of the ""cropbox record"" mode in the asr_state_machine. 


 
 
 
: the  which are search at the moment 
: :  
     
  




 : the path to the config.xml generated by the , which contains of the grid : the path to the initialized grid, which contains  of the grid. Can be generated by the  of the asr_state_machine 
 : camera fiels of view angles (will be used in ) : camera fiels of view angles (will be used in ) : PTU angle free of vision obstacles (will be used in ) : can be 1 for , 2 for  and 3 for  : the distance function to use. 1 for the service call  of  (accurate, slow) or 2: the euclidean distance (approximative, fast) : enables the use of prior knwolege by reordering the poses by , so that poses which have a higher chance to detect an object will be taken first. The reordering takes place on the basis of the  from the current SQL-database : if the poses of the  should be reordered with TSP ( and ) : the threshold when two positions of  will be seen as approx equale. This will be used to filter poses depending on already seen viewports taken from other search modes () The threshold for orientation will be /nbv/mHypothesisUpdaterAngleThreshold : remove all  which have not at least this number of normals deleted while the poses were recorded : remove all  which the robot can not reach (this was need due a bug in asr_next_best_view). It could also be neccessary if the colThresh (asr_next_best_viewparam) has changed since the recording of the poses : concatenate  which are approx equale to one with multiple  As a result the robot will move less. : the threshold when two  of  will be seen as approx equale for concatenating two  
 : , , ,  : , ,  :  
The  is used to manage the views for the direct mode of Active Scene Recognition. The direct search is one of the implemented mode in the 3-D object search we interrelated with scene recognition. The main goal of the direct search is to generate views which should cover the search space, i.e., the robot's environment. It provides a possibility to search for objects without prior knowledge. The direct search can be started in the  with mode 1 or 3. One implementation is the grid mode. The grid can be generated with the . The idea is to devide the search space with a grid. The grid is made up of grid points which have an equidistant distance between each. On each grid point the asr_direct_search_manager generates a subset of views which are neccessary to cover the room around that grid point. The number of views depens on the size of the frustum. #goal definition : the command which should be executed: #result definition : the next  : the next  (belonging to the goalRobotPose) if present : the next pan to take : the next tilt to take : the PTU poses which are left for this goalRobotPose (just as information) : the  which are left (just as information) : the remaining distance for the remainingRobotPoses to take (just as information) : if goalRobotPose is the same as the one from the call before : if there are no poses left at all : if there are poses left after this one, which are sorted based on the prior knwoledge : the searchedObjectTypesAndIds which were filtered. It will be filtered, if at the goalCameraPose were already some objects searched or if it is more likely to find a subset of objects This package is part of the active_scene_recognition. When using the , this node will be started automatically. Generating the views for the gridMode:  Generating the views for the recordMode:  To execute the direct search:  "
W866,https://wiki.ros.org/rviz_backdrop,Wiki,rviz_backdrop,rviz_backdrop
W867,https://wiki.ros.org/kobuki_qtestsuite,Wiki,kobuki_qtestsuite,"An rqt plugin that provides a graphical, interactive testsuite for Kobuki.  > sudo apt-get install ros-$ROS_DISTRO-kobuki-qtestsuite> . /opt/ros/$ROS_DISTRO/setup.bash
> kobuki_qtestsuite"
W868,https://wiki.ros.org/static_transform_mux,Wiki,static_transform_mux,"A helper node that makes sure everybody knows about all static transforms, even if they are published by multiple publishers.





This ROS node subscribes to , collects all the transforms that are ever published there, and re-sends a message that contains not only the transforms from the last publisher, but all transforms ever encountered. This is a workaround for e.g. , or for anybody else who needs to have multiple static transform publishers in the system. /tf_static/tf_static/tf_statictf2_msgs/TFMessagereadystd_msgs/Bool/tf_static~update_only_with_newerboolFalse~forbidden_callerid_prefixstrNoneNone/tf_static/tf_staticcallerid"
W869,https://wiki.ros.org/pointcloud_tools,Wiki,pointcloud_tools,pointcloud_tools
W870,https://wiki.ros.org/kni,Wiki,kni,"This package provides the third-party KNI (Katana Native Interface) library for Katana
     robot arms.

     Instead of using the KNI library directly, the 
     package should be used for communication with the Katana arm."
W871,https://wiki.ros.org/stdr_gui,Wiki,stdr_gui,"A gui in Qt for visualizing purposes in STDR Simulator.
The  package provides a Graphical User Interface for  developed with QT4. A detailed description of  can be examined through the following tutorials: "
W872,https://wiki.ros.org/bag_tools,Wiki,bag_tools,"ROS tools and scripts related to bagfiles












Install this package by first cloning and building the srv_tools package, as described on the  page. Next, install this package to make it available to rosrun. Parses camera info yaml files and returns the content as sensor_msgs.msg.. catkin_make install --pkg bag_toolsrosrun bag_tools extract_stereo_images OUT_DIR FILETYPE STEREO_BASE_TOPIC BAGFILE [BAGFILE...]usage: bag_add_time_offset.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE
                              [INPUT_BAGFILE ...] -of OFFSET -t TOPIC
                              [TOPIC ...]

Shift the publishing time of given topics in input bagfile.

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT_BAGFILE     output bagfile
  -i INPUT_BAGFILE [INPUT_BAGFILE ...]
                        input bagfile(s)
  -of OFFSET            time offset to add in seconds
  -t TOPIC [TOPIC ...]  topic(s) to changeusage: change_camera_info.py [-h] inbag outbag replacement [replacement ...]

Change camera info messages in a bagfile.

positional arguments:
  inbag        input bagfile
  outbag       output bagfile
  replacement  replacement in form ""TOPIC=CAMERA_INFO_FILE"", e.g.
               /stereo/left/camera_info=my_new_info.yaml

optional arguments:
  -h, --help   show this help message and exitusage: check_delay.py [-h] inbag [inbag ...]

Checks the delay in a bagfile between publishing (recording) time and the time
stamp in the header (if exists). Prints out min, max and mean delays.

positional arguments:
  inbag       input bagfile(s)

optional arguments:
  -h, --help  show this help message and exitusage: cut.py [-h] --inbag INBAG [INBAG ...] --outbag OUTBAG --start START
              --duration DURATION

Cuts out a section from an input bagfile and writes it to an output bagfile

optional arguments:
  -h, --help            show this help message and exit
  --inbag INBAG [INBAG ...]
                        input bagfile(s)
  --outbag OUTBAG       output bagfile
  --start START         start time
  --duration DURATION   duration of the resulting partusage: replace_msg_time_with_hdr.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE

Create a new bagfile from an existing one replacing the message time for the
header time.

optional arguments:
  -h, --help         show this help message and exit
  -o OUTPUT_BAGFILE  output bagfile
  -i INPUT_BAGFILE   input bagfileusage: add_header_time_offset.py [-h] -o OFFSET -i BAGFILE [BAGFILE ...] -t
                                 TOPIC [TOPIC ...]

Changes header timestamps using given offset, can change /tf as well.

optional arguments:
  -h, --help            show this help message and exit
  -o OFFSET             time offset to add in seconds
  -i BAGFILE [BAGFILE ...]
                        input bagfile(s)
  -t TOPIC [TOPIC ...]  topics to changeusage: change_frame_id.py [-h] -o OUTPUT_BAGFILE -i INPUT_BAGFILE -f FRAME_ID
                          -t TOPIC [TOPIC ...]

reate a new bagfile from an existing one replacing the frame id of requested
topics.

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT_BAGFILE     output bagfile
  -i INPUT_BAGFILE      input bagfile
  -f FRAME_ID           desired frame_id name in the topics
  -t TOPIC [TOPIC ...]  topic(s) to change<launch>
  <node name=""img_pub"" pkg=""bag_tools"" type=""image_sequence_publisher.py"" output=""screen"">
    <param name=""image_dir"" value=""/tmp/seq""/>
    <param name=""file_pattern"" value=""*.png""/>
    <param name=""camera_info_file"" value=""/tmp/seq/camera_info.yaml""/>
    <param name=""frequency"" value=""10""/>
  </node>
</launch>usage: make_video.py [-h] [--output OUTPUT] [--fps FPS]
                     topic inbag [inbag ...]

Creates a video from sensor_msgs/Image messages from a bagfile. This script
uses the extract_images binary to extract color images from bagfiles and calls
ffmpeg afterwards to combine them together to form a video. Note that ffmpeg
must be installed on your system.

positional arguments:
  topic            topic of the images to use
  inbag            input bagfile(s)

optional arguments:
  -h, --help       show this help message and exit
  --output OUTPUT  name of the output video. Note that the file ending defines
                   the codec to use.
  --fps FPS        frames per second in the output video, as long as codec
                   supports this"
W873,https://wiki.ros.org/rail_pick_and_place_tools,Wiki,rail_pick_and_place_tools,"RViz Plugins for Collecting Grasps and Generating Models



 The  package contains rviz plugins to aid in the grasp demonstration collection and model generation process.  This package also contains launch files for easier running of this process. To install the  package, you can install from source with the following commands: The  package contains a launch file for starting up the backend necessary for grasp demonstration collection and object model generation, as well as a frontend that launches rviz with the relevant panels and topics shown: rail_pick_and_place_toolsrail_pick_and_placerail_pick_and_place_tools




roslaunch rail_pick_and_place_tools model_generation_backend.launchroslaunch rail_pick_and_place_tools model_generation_frontend.launch"
W874,https://wiki.ros.org/turtlebot_arm_moveit_config,Wiki,turtlebot_arm_moveit_config,An automatically generated package with all the configuration and launch files for using the turtlebot_arm with the MoveIt! Motion Planning FrameworkThe package contains some tweaks and addition to the automatically generated one. Refer to  if you want to generate the ! configuration by yourself. 
W875,https://wiki.ros.org/wge100_camera,Wiki,wge100_camera,"A ROS node and assorted tools to provide access to the WGE100
    camera used in the forearms and the stereo cameras of the PR2
    robot.








 
 
 
 
 
 





The Willow Garage 100 Mbps Ethernet (WGE100) camera is a 752x480 Ethernet camera developed for the PR2 robot. The PR2's narrow stereo camera is a monochrome WGE100, while its wide stereo camera and forearm cameras are in color. This package contains the , a ROS driver for a monocular WGE100 camera, the  node, which allows two cameras in a stereo pair to be configured from one centralized location, and a suite of  to manage the camera. Except for the  and  tools, which can be used at any time, the WGE100 tools are not designed for concurrent access to the camera. The timestamps returned by the  are with respect to the end of the exposure. The timestamps can be produced in one of two ways: When working with a WGE100 camera, the user needs to identify the camera she wishes to work with.  Cameras are identified using URLs, which can refer either to the camera's serial number or to its descriptive name (set using ). If there is only one camera present, a URL can indicate that whatever camera is found should be used.  If a URL matches more than one camera, none of them will be selected, and an error will be reported. This situation cannot happen with a  URL as camera serial numbers are unique. When an IP address is specified, WGE100 camera tools will configure the camera to use that address before they try to work with it. The IP address that is specified using @ will get reset each time a new tool is used. To set a camera's IP address permanently, use the  tool. In some cases, a single camera may be visible on multiple interfaces, or cameras with the same name may be visible on different network interfaces. In this case, an interface name can be included in the camera URL to force a particular interface to be used for communication. An interface name is introduced with the  sign. For example, on the PR2, only the  interface is searched to avoid potential conflicts with identically named cameras on the wan0 interface:  The  tool uses a broadcast packet to find cameras on the network. It can be run on a single network interface: The IP address that is reported by the  tool is the currently configured address for the camera. This may be different from the IP address stored in the camera's flash, and to which the camera defaults when it is reset. This IP may or may not be valid for the interface on which the camera is located, and it is quite possible that you will not be able to communicate with the camera at this particular IP address. Sometimes a camera can be seen from multiple interfaces. The  tool only reports the first interface on which a response is seen. The camera can nevertheless be configured to run from an interface other than the one on which it was reported. The camera name and IP address that are stored in the camera's flash can be accessed using the  tool. With a single camera URL argument, set_name reports the current settings. The camera intrinsics that are stored in the camera's flash can be accessed using the  tool. With a single camera URL argument, set_name reports the current settings. In general, calibration of the camera and uploading of the parameters should be done through the  package.  These programs will perform the calibration, and make the service call to flash the intrinsics back onto the camera. The camera can be reset using the  command, which takes a single camera_url argument. Note: The  tool currently has the same effect as . In future firmware versions  will always cause the camera FPGA to reconfigure itself, whereas  may do a softer reset that resets all components without reconfiguring the FPGA. For information on contents of the WGE100 flash memory, you may consult . wge100_camera_nodefirst_packet_offsetname://wide_stereo_lserial://2701025any://@name://my_camera@192.168.1.2#lan0name://wide_stereo_l#lan0any://serial://15#eth2name://left_forearm@10.68.0.210wge100_camera_nodewge100_camera_node<~trig_timestamp_topic>wge100_camera_nodecamera/image_rawcamera/camera_infocamera_alternate/image_rawcamera_alternate/camera_info/diagnostics~self_testcamera/set_camera_info~board_configwge100_camera_node~camera_urlstr~frame_idstr~register_setint~packet_debugboolcamera_infowidthheight~widthint~heightint~imager_ratedouble~horizontal_binningint~vertical_binningint~horizontal_offsetint~vertical_offsetint~mirror_xbool~mirror_ybool~rotate_180bool~ext_trigbool~rising_edge_trigbool~trig_timestamp_topicstr~trig_ratedouble~first_packet_offsetdouble~brightnessint~black_levelint~max_exposuredouble~auto_exposurebool~exposuredouble~auto_gainbool~gainint~compandingbool~auto_exposure_alternatebool~exposure_alternatedouble~auto_gain_alternatebool~gain_alternateint~companding_alternateboolwge100_multi_configuratorwge100_camera_nodewge100_camera_nodewge100_camera_node~camera_nodesstr~<any wge100_camera_node parameter except camera_url>samename://camera_name[@camera_ip][#local_interface]
serial://serial_number[@camera_ip][#local_interface]
any://[@camera_ip][#local_interface]$ rosrun wge100_camera discover eth1
Found camera serial://13 name://test MAC: 00:24:cd:00:00:83 iface: eth2:avahi current IP: 169.254.8.124, PCB rev: C HDL rev: 400 FW rev: 118$ rosrun wge100_camera discover
Found camera serial://13 name://test MAC: 00:24:cd:00:00:83 iface: eth2:avahi current IP: 169.254.8.124, PCB rev: C HDL rev: 400 FW rev: 118$ rosrun wge100_camera set_name serial://15@169.254.8.200
Previous camera name was: test.
Previous camera IP: 169.254.8.124.$ rosrun wge100_camera set_name serial://15@169.254.8.200 new_name 169.254.8.200
Previous camera name was: test
Previous camera IP: 169.254.8.124
Success! Restarting camera, should take about 10 seconds to come back up after this.
$ rosrun wge100_camera set_name serial://15
Previous camera name was: new_name
Previous camera IP: 169.254.8.200$ rosrun wge100_camera set_calibration name://wide_stereo_l
Unable to create ARP entry (are you root?), continuing anyway
Reading old calibration...
[image]
...$ rosrun wge100_camera set_calibration serial://15@169.254.8.200 intrinsics.ini$ rosrun wge100_camera reset_cam any://"
W876,https://wiki.ros.org/realsense_camera,Wiki,realsense_camera,"RealSense Camera package allowing access to Intel 3D cameras and advanced modules

















 This package provides ROS node(s) for using the Intel® ™ R200, F200 and SR300 cameras. This package requires the  package as the underlying camera drivers for all Intel® ™ cameras.  installing the realsense-camera package, follow the . This will also install the required ros-<*distro*>-librealsense library on your system. If a user needs to debug this package or contribute changes/bug fixes to the package, only then should the package need to be built from source. Please closely follow the directions provided on the  page. To ensure you camera has the most current, supported firmware, please review the . If the camera requires a firmware upgrade, please refer to the  page. : Currently there is no native Linux tool for FW updates; all updates require a system with Microsoft Windows. Please  concerning this package to the realsense_camera  Issues. See the  for a complete list. color/camera_infocolor/image_rawdepth/camera_infodepth/image_rawuint16depth/pointsir/camera_infoir/image_rawuint16ir/camera_infoir/image_rawuint16fisheye/camera_infoir/image_rawuint16imu/data_rawget_settingsset_powertruefalsefalseforce_powertruefalsefalseis_poweredget_imu_infomodestringpresetserial_nostringblankusb_port_idstringblankcamera_typestringblankenable_irboolenable_depthbooldepth_widthintdepth_heightintdepth_fpsintenable_colorboolcolor_widthintcolor_heightintcolor_fpsintenable_fisheyeboolfisheye_widthintfisheye_heightintfisheye_fpsintenable_imuboolenable_pointcloudboolenable_tfboolenable_tf_dynamic ('''Added in 1.7.0''')boolbase_frame_idstringdepth_frame_idstringdepth_optical_frame_idstringcolor_frame_idstringcolor_optical_frame_idstringir_frame_idstringir_optical_frame_idstringir2_frame_idstringir2_optical_frame_idstringfisheye_frame_idstringfisheye_optical_frame_idstringimu_frame_idstringimu_optical_frame_idstring~enable_depthbool~color_backlight_compensationint~color_brightnessint~color_contrastint~color_gainint~color_gammaint~color_hueint~color_saturationint~color_sharpnessint~color_white_balanceint~color_exposureint~r200_lr_gainint~r200_lr_exposureint~color_enable_auto_white_balanceint~color_enable_auto_exposureint~r200_lr_auto_exposure_enabledint~r200_auto_exposure_top_edgeint~r200_auto_exposure_bottom_edgeint~r200_auto_exposure_left_edgeint~r200_auto_exposure_right_edgeint~r200_emitter_enabledint~r200_dc_presetint~r200_dc_estimate_median_decrementint~r200_dc_estimate_median_incrementint~r200_dc_median_thresholdint~r200_dc_score_minimum_thresholdint~r200_dc_score_maximum_thresholdint~r200_dc_texture_count_thresholdint~r200_dc_texture_difference_thresholdint~r200_dc_second_peak_thresholdint~r200_dc_neighbor_thresholdint~r200_dc_lr_thresholdint~enable_depthbool~color_backlight_compensationint~color_brightnessint~color_contrastint~color_gainint~color_gammaint~color_hueint~color_saturationint~color_sharpnessint~color_white_balanceint~color_exposureint~color_enable_auto_white_balanceint~color_enable_auto_exposureint~f200_laser_powerint~f200_accuracyint~f200_motion_rangeint~f200_filter_optionint~f200_confidence_thresholdint~enable_depthbool~color_backlight_compensationint~color_brightnessint~color_contrastint~color_gainint~color_gammaint~color_hueint~color_saturationint~color_sharpnessint~color_white_balanceint~color_enable_auto_white_balanceint~color_exposureint~color_enable_auto_exposureint~f200_laser_powerint~f200_accuracyint~f200_motion_rangeint~f200_filter_optionint~f200_confidence_thresholdint~sr300_auto_range_enable_motion_versus_rangeint~sr300_auto_range_enable_laserint~sr300_auto_range_min_motion_versus_rangeint~sr300_auto_range_max_motion_versus_rangeint~sr300_auto_range_start_motion_versus_rangeint~sr300_auto_range_min_laserint~sr300_auto_range_max_laserint~sr300_auto_range_start_laserint~sr300_auto_range_upper_thresholdint~sr300_auto_range_lower_thresholdint~enable_depthbool~color_backlight_compensationint~color_brightnessint~color_contrastint~color_exposureint~color_gainint~color_gammaint~color_hueint~color_saturationint~color_sharpnessint~color_white_balanceint~r200_lr_gainint~r200_lr_exposureint~color_enable_auto_exposureint~color_enable_auto_white_balanceint~r200_lr_auto_exposure_enabledint~r200_emitter_enabledint~r200_depth_clamp_minint~r200_depth_clamp_maxint~fisheye_exposureint~fisheye_gainint~fisheye_enable_auto_exposureint~fisheye_auto_exposure_modeint~fisheye_auto_exposure_antiflicker_rateint~fisheye_auto_exposure_pixel_sample_rateint~fisheye_auto_exposure_skip_framesint~frames_queue_sizeint~hardware_logger_enabledint~r200_dc_presetint~r200_dc_estimate_median_decrementint~r200_dc_estimate_median_incrementint~r200_dc_median_thresholdint~r200_dc_score_minimum_thresholdint~r200_dc_score_maximum_thresholdint~r200_dc_texture_count_thresholdint~r200_dc_texture_difference_thresholdint~r200_dc_second_peak_thresholdint~r200_dc_neighbor_thresholdint~r200_dc_lr_thresholdintcamera_linkcamera_rgb_framecamera_rgb_framecamera_rgb_optical_framecamera_linkcamera_depth_framecamera_depth_framecamera_depth_optical_framecamera_linkcamera_ir_framecamera_ir_framecamera_ir_optical_framecamera_linkcamera_ir2_framecamera_ir2_framecamera_ir2_optical_framecamera_linkcamera_fisheye_framecamera_fisheye_framecamera_fisheye_optical_framecamera_linkcamera_imu_framecamera_imu_framecamera_imu_optical_framesudo apt-get install 'ros-*-realsense-camera'$ roslaunch realsense_camera r200_nodelet_default.launch$ roslaunch realsense_camera f200_nodelet_default.launch$ roslaunch realsense_camera sr300_nodelet_default.launch$ roslaunch realsense_camera zr300_nodelet_default.launch/camera/depth_registered/hw_registered/image_rect_raw
/camera/depth_registered/hw_registered/image_rect
/camera/depth_registered/image
/camera/depth/disparity
/camera/depth_registered/disparity"
W877,https://wiki.ros.org/turtlebot_arm_block_manipulation,Wiki,turtlebot_arm_block_manipulation,"turtlebot_arm_block_manipulation contains a demo allowing the TurtleBot arm
    to manipulate small blocks on a level surface using interactive markers.



   







This  will walk you through running this demo on your own TurtleBot.   This package requires almost all the others on  stack. In particular,  from the  package and  and  from  have to be running. See the  launch file for more details. Additionally, it requires an external kinect to be running and calibrated to the robot. Refer to  package to learn how to calibrate your camera. arm.launchplanning_context.launchmove_group.launchblock_manipulation_moveit.launchdemo/block_manipulation_moveit.launchdemo/block_manipulation_demo.launchlaunch/block_manipulation.launch/turtlebot_blocks/pick_and_place~bump_sizedouble/camera/depth_registered/points/turtlebot_blocksblock_outputpointcloud framearm_link (from goal)#goal definition
string frame
float32 table_height
float32 block_size
---
#result definition
geometry_msgs/PoseArray blocks
---
#feedback#goal definition
string frame
float32 block_size
---
#result definition
geometry_msgs/Pose pickup_pose
geometry_msgs/Pose place_pose
---
#feedback#goal definition
string frame
float32 z_up
float32 gripper_open
float32 gripper_closed
geometry_msgs/Pose pickup_pose
geometry_msgs/Pose place_pose
string topic
---
#result definition
---
#feedback"
W878,https://wiki.ros.org/leg_detector,Wiki,leg_detector,"Leg Detector using a machine learning approach to find leg-like patterns of laser scanner readings.


This leg detector package takes s as input and uses a machine-learning-trained classifier to detect groups of laser readings as possible legs. Sadly, the training dataset has been lost to Willow Garage history (it wasn't even available before they closed). The code is in the repository for retraining, but is unsupported at this time.  This node will publish s for the individual legs, and it can also attempt to pair the legs together and publish their average as an estimate of where the center of one person is as a . The node will also optionally publish visualization Marker messages to indicate where detections happened.  In the seeded mode, the algorithm will use another source of PositionMeasurement messages to guide the algorithm to possible locations for people. Historically, this has been used with a face detection algorithm that alerts the leg_detector that there is probably a pair of legs underneath. This mode is enabled using the  parameter.  use_seedsscanpeople_tracker_filterleg_tracker_measurementspeople_tracker_measurementsvisualization_markeruse_seedsbooleanconnection_thresholddoublemin_points_per_groupintleg_reliability_limitdoublepublish_legsbooleanpublish_peoplebooleanpublish_leg_markersbooleanpublish_people_markersbooleanno_observation_timeoutdoublemax_second_leg_agedoublemax_track_jumpdoublemax_meas_jumpdoubleleg_pair_separationdoublefixed_framestringkalman_pdoublekalman_qdoublekalman_rdouble"
W879,https://wiki.ros.org/uos_diffdrive_teleop,Wiki,uos_diffdrive_teleop,uos_diffdrive_teleop
W880,https://wiki.ros.org/sr_kinematics,Wiki,sr_kinematics,"
    A specific shadowhand package derived from arm_kinematics, for computing both forward and backward kinematics for the fingers except thumb.
    Solution is analytic. Developed as an alternative to arm_kinematics that cannot solve coupled joints.
  





 sr_kinematics currently contains a specific analytical inverse kinematics for the  hand. Currently, only the 4 fingers have an IK solution, the thumb will come later. The solution takes care of the coupled joint J1/J2 (assuming it is 1:1) and accepts 3D requests (instead of 6D). There is an approximation in this solution. The node proposes the same services and parameters as the  NOTE that  parameter is used to detect singularities for J4 joint. "
W881,https://wiki.ros.org/turtlebot_panorama,Wiki,turtlebot_panorama,"

     This app utilises pano_ros for taking snapshots and stitching them together to create panorama pictures.

  To be documented.  


To learn how to use this package, take a look to the  pano_app/take_panopano_app/stop_panopano_app/odompano_server/stitchpano_app/logpano_app/panoramapano_app/cmd_velpano_server/snappano_server/stoppano_app/take_pano~default_modeString~default_pano_angledouble~default_snap_intervalString~default_rotation_velocitydouble~camera_nameString~bag_locationString"
W882,https://wiki.ros.org/turtlesim_dash_tutorial,Wiki,turtlesim_dash_tutorial,"The turtlesim_dash_tutorial package
  
 

 This package is designed to provide a quick and dirty tutorial on how to quickly create a Web UI for a ROS environment with . As backbone for this tutorial, we'll use ROS's . The default launch file included in this package,  brings up a  environment and starts 's  node. As mentioned in the documentation for , the node is designed to control the simulated turtlebot so that it traces out a polygon of a specified radius with the desired number of edges. The launch file also starts a . On navigating to that URL, you should see a web page like so: Here is an example of the page as the turtlebot is executing a : Creates a  server on the port 8080; navigate to  in order to view it. tutorial.launchturtlesimturtle_actionlibshape_serverturtle_actionlibTrace Shapeshape_serveractionlibShapeGoalturtle_actionlibsudo apt install ros-melodic-turtle-actionlibpip install -r requirements.txt roslaunch turtlesim_dash_tutorial tutorial.launch dash/turtle_shape/turtle1/pose"
W883,https://wiki.ros.org/linux_networking,Wiki,linux_networking,"
    
      Tools to work with linux networking. 
    

  "
W884,https://wiki.ros.org/ridgeback_navigation,Wiki,ridgeback_navigation,"Launch files and code for autonomous navigation of the Ridgeback
The ridgeback_navigation package contains configuration and launch files for running  on . "
W885,https://wiki.ros.org/sr_movements,Wiki,sr_movements,"

    Contains a node which can be used to take the hand through a series of movements (perfect for tuning
    controllers for example).

  





It also receives an input topic and calculates the MSE for each cycle of the bitmap plot. The MSE is output to ROS_INFO and published in the topic . For example, using this png file  will send targets between the specified  and  values on a (very) rough sinusoid. The black dot on each row represents the percentage between  and . The top of the graph is 100% (=max), the bottom is 0% (=min). Publishes  with the targets values. Publishes  with the calculated MSE values. Subscribe to  to receive the data to calculate MSE. rosrun sr_movements sr_movements /sr_movements/targets:=/sh_ffj3_mixed_position_velocity_controller/command /sr_movements/inputs:=/sh_ffj3_mixed_position_velocity_controller/state _image_path:=""`rospack find sr_movements`/movements/test.png"" _min:=.1 _max:=1.4 _publish_rate:=100 _repetition:=5 _nb_step:=1000 _msg_type:=""sr"""
W886,https://wiki.ros.org/turtlebot_concert,Wiki,turtlebot_concert,"A solution for multi TurtleBot teloperation and navigation which can be used in a lab.
  how to start the turtlebot concert how to start the turtlebot concert how to teleoperate turtlebot in concert  "
W887,https://wiki.ros.org/tf,Wiki,tf,"tf is a package that lets the user keep track of multiple coordinate
frames over time. tf maintains the relationship between coordinate
frames in a tree structure buffered in time, and lets the user
transform points, vectors, etc between any two coordinate frames at
any desired point in time.

    : Since ROS Hydro, tf has been ""deprecated"" in favor of . tf2 is an iteration on tf providing generally the same feature set more efficiently. As well as adding a few new features.
    As tf2 is a major change the tf API has been maintained in its current form. Since tf2 has a superset of the tf features with a subset of the dependencies the tf implementation has been removed and replaced with calls to tf2 under the hood. This will mean that all users will be compatible with tf2. It is recommended for new work to use tf2 directly as it has a cleaner interface. However tf will continue to be supported for through at least J Turtle.
     





 
   
  
   is designed both as a command-line tool for manual use, as well as for use within  files for setting static transforms. For example:  
 is a graphical debugging tool that creates a PDF graph of your current transform tree. 
 tf comes with a plugin for  that automatically runs whenever you run . This plugin will analyze your current tf configuration and attempt to find common problems. To run, just invoke  normally: 
 
 
 You want to  what tf can do instead of just reading about it? Check out the . A robotic system typically has many 3D  that change over , such as a world frame, base frame, gripper frame, head frame, etc. tf keeps track of all these frames over time, and allows you to ask questions like: tf can operate in a . This means all the information about the coordinate frames of a robot is available to all ROS components on any computer in the system.  There is  of transform information. For more information on the design see  There is a paper on tf presented at TePRA 2013  We created a set of  that walk you through using tf, step by step. You can get started on the  tutorial. For a complete list of all tf and tf-related tutorials check out the  page. Once you are finished with the basic tutorials, you can move on to learn about tf and time. The tf and time tutorial   teaches the basic principles of tf and time. The advanced tutorial about tf and time   teaches the principles of time traveling with tf. Although tf is mainly a code library meant to be used within ROS , it comes with a large set of command-line tools that assist in the debugging and creation of tf coordinate frames. These tools include: You may also wish to use the  node, which is a utility node for remapping coordinate transforms. Therefore an helpful shortcut to add in your  is: NOTE: See also  that allows dynamic introspection of the frames. tfwtftf_monitortf_monitor <source_frame> <target_target>/base_footprint/odomtf_echo <source_frame> <target_frame>source_frametarget_frame/map/odomstatic_transform_publisher x y z yaw pitch roll frame_id child_frame_id period_in_msstatic_transform_publisher x y z qx qy qz qw frame_id child_frame_id  period_in_msstatic_transform_publisherview_frames.bashrcroswtfroswtfroswtf/tf_old/tf/tf:=/tf_oldtf_remap~mappings/tf_old/tf/tf~mappings[ {str: str} ]change_notifier/tf/tf_changes/tf/tf_changes~polling_frequencyfloat~translational_update_distancefloat~angular_update_distancefloat$ rosrun tf tf_monitor
RESULTS: for all Frames

Frames:
Frame: /base_footprint published by /robot_pose_ekf Average Delay: 0.0469324 Max Delay: 0.0501503
Frame: /base_laser_link published by /robot_state_publisher Average Delay: 0.00891066 Max Delay: 0.009591
Frame: /base_link published by /robot_state_publisher Average Delay: 0.00891147 Max Delay: 0.009592
0.00891431 Max Delay: 0.009595

... editing for the sake of brevity ...

Broadcasters:
Node: /realtime_loop 94.7371 Hz, Average Delay: 0.000599916 Max Delay: 0.001337
Node: /robot_pose_ekf 30.8259 Hz, Average Delay: 0.0469324 Max Delay: 0.0501503
Node: /robot_state_publisher 25.8099 Hz, Average Delay: 0.0089224 Max Delay: 0.00960276$ rosrun tf tf_monitor /base_footprint /odom
RESULTS: for /base_footprint to /odom
Chain currently is: /base_footprint -> /odom
Net delay     avg = 0.00371811: max = 0.012472

Frames:
Frame: /base_footprint published by /robot_pose_ekf Average Delay: 0.0465218 Max Delay: 0.051754
Frame: /odom published by /realtime_loop Average Delay: 0.00062444 Max Delay: 0.001553

Broadcasters:
Node: /realtime_loop 95.3222 Hz, Average Delay: 0.00062444 Max Delay: 0.001553
Node: /robot_pose_ekf 30.9654 Hz, Average Delay: 0.0465218 Max Delay: 0.051754
Node: /robot_state_publisher 25.9839 Hz, Average Delay: 0.00903061 Max Delay: 0.00939562$ rosrun tf tf_echo /map /odom
At time 1263248513.809
- Translation: [2.398, 6.783, 0.000]
- Rotation: in Quaternion [0.000, 0.000, -0.707, 0.707]
in RPY [0.000, -0.000, -1.570]


$ rosrun tf view_frames$ rosrun tf view_frames
$ evince frames.pdfalias tf='cd /var/tmp && rosrun tf view_frames && evince frames.pdf &'$ roswtf"
W888,https://wiki.ros.org/xbot_bringup,Wiki,xbot_bringup,"The xbot_bringup package





roslaunch xbot_bringup xbot.launchroslaunch xbot_bringup rplidar.launchroslaunch xbot_bringup realsense.launchroslaunch xbot_bringup xbot-u.launch"
W889,https://wiki.ros.org/xbot_msgs,Wiki,xbot_msgs,"
      Xbot message and service types: custom messages and services for Xbot packages.
    "
W890,https://wiki.ros.org/stereo_msgs,Wiki,stereo_msgs,"stereo_msgs contains messages specific to stereo processing, such as disparity images.
: this package is now part of .  In previous releases, it was part of . 
"
W891,https://wiki.ros.org/topic_proxy,Wiki,topic_proxy,"topic_proxy implements a ROS service server and client to pull single messages from one master and optionally republish them locally.
Use GitHub to . []
 "
W892,https://wiki.ros.org/rtabmap_ros,Wiki,rtabmap_ros,"RTAB-Map's ros-pkg. RTAB-Map is a RGB-D SLAM approach with real-time constraints.














 










: It is recommend to use directly  or  published topics from  node instead of using this node. 














: this node will use a lot of CPU ressources if the raw point clouds are fed to it directly. A  can be used to downsample the raw point cloud (e.g. like 5 cm voxel) or  nodelet can be used to generate a downsampled cloud from a depth image (e.g. decimating the depth image by 4 before creating a cloud). That filtered point cloud would be fed to .  


 

This package is a ROS wrapper of  (Real-Time Appearance-Based Mapping), a RGB-D SLAM approach based on a global loop closure detector with real-time constraints. This package can be used to generate a 3D point clouds of the environment and/or to create a 2D occupancy grid map for navigation. The  and  show some examples of mapping with RTAB-Map. For this demo, you will need the ROS bag  (295 MB, , ). Launch:  For this demo, you will need the ROS bag  (295 MB, , ). Launch:  Detailed results are shown on the  page on RTAB-Map's wiki. For the first launch, you can do ""Edit->Delete memory"" to make sure that you start from a clean memory. You may need to do this after starting the first bag with ""--pause"" so that rtabmap node is initialized to avoid a ""service /reset cannot be called"" error. Launch:  Find-Object's ros-pkg  should be installed. ROS Bag:  (416 MB) Launch:  There is no bag recorded for this demo but how to reproduce this setup is described on the page  of the RTAB-Map's wiki. Visit the tutorial  for detailed information. It is also shown how to create 2D occupancy grid map for navigation. Launch :  There is no bag recorded for this demo but how to reproduce this setup is described in the tutorial . Launch:  For  and information about the loop closure detection approach used in RTAB-Map, visit . All  topics use . 
This is the main node of this package. It is a wrapper of the RTAB-Map Core library. This is where the graph of the map is incrementally built and optimized when a loop closure is detected. The online output of the node is the local graph with the latest added data to the map. The default location of the RTAB-Map database is ""~/.ros/rtabmap.db"" and the workspace is also set to ""~/.ros"". To get a 3D point cloud or a 2D occupancy grid of the environment, subscribe to ,  or  topics. This node starts the visualization interface of RTAB-Map. It is a wrapper of the RTAB-Map GUI library. It has the same purpose as  but with specific options for RTAB-Map. Common odometry stuff for ,  and  nodes. These nodes wrap the various odometry approaches of RTAB-Map. When a transformation cannot be computed, a null transformation is sent to notify the receiver that odometry is not updated or lost. See also  for common odometry stuff used by this node. 
See also  for common odometry stuff used by this node. 
See also  for common odometry stuff used by this node. 
A node for image acquisition from an USB camera (OpenCV is used). A special option for this node is that it can be configured to read images from a directory or a video file. Parameters can be changed with the  GUI from ROS. For dynamic parameters, see  This node subscribes to  output topic  and assembles the 3D map incrementally, then publishes the same maps than . See all  related topics and parameters of  node. This node is for  as it is preferred to use graph optimization already inside  node (which is the default). See related parameters in : This node subscribes to  output topic  and optimize the graph, then republishes the optimized . This rviz plugin subscribes to /mapData () topic. A 3D map cloud will be created incrementally in RVIZ. When the graph is changed, all point clouds added in RVIZ will be transformed to new poses. It has the same properties as  display but with these new ones: This rviz plugin subscribes to /mapGraph () topic. It will show the RTAB-Map's graph with different colors depending on the links' type. It has the same properties as  display. This rviz plugin subscribes to /info () topic. Information about loop closures detected are shown in the ""Status"". video_or_images_pathcloud_mapgrid_mapproj_map""--delete_db_on_start""""--delete_db_on_start""""-d""""--udebug""""--uinfo""""--params""odomsubscribe_depthsubscribe_stereoodom_frame_idrgb/imagesubscribe_depthsubscribe_stereoleft/image_rectrgb/camera_infosubscribe_stereoleft/camera_infodepth/imagesubscribe_depthscansubscribe_scanscan_cloudsubscribe_scan_cloudleft/image_rectsubscribe_stereoleft/camera_infosubscribe_stereoright/image_rectsubscribe_stereoright/camera_infosubscribe_stereogoalRGBD/LocalRadiusset_goalrgbd_imagesubscribe_rgbdtrueinfomapDatamapGraphgrid_mapmap_grid_proj_mapmap_grid_proj_cloud_mapmap_cloud_scan_mapmap_scan_labelsglobal_pathlocal_pathgoal_reachedgoal_outmove_base_simple/goaloctomap_fulloctomap_binaryoctomap_occupied_spaceoctomap_obstaclesoctomap_groundoctomap_empty_spaceoctomap_gridget_mapget_map_datapublish_maplist_labelsupdate_parametersresetpauseresumetrigger_new_mapbackupdatabase_path~/.ros/rtabmap.db.backset_mode_localizationset_mode_mappingset_labelset_goaloctomap_fulloctomap_binary~subscribe_depthbool""true""~subscribe_scanbool""false""~subscribe_scan_cloudbool""false""~subscribe_stereobool""false""~subscribe_rgbdbool""false""rgbd_image~frame_idstring""base_link""~map_frame_idstring""map""~odom_frame_idstring""""odom~queue_sizeint~publish_tfbool""true""~tf_delaydouble~tf_prefixstring""""~wait_for_transformbool""true""wait_for_transform_duration~wait_for_transform_durationdoublewait_for_transform~config_pathstring""""~database_pathstring""~/.ros/rtabmap.db""~gen_scanbool""false""subscribe_scansubscribe_scan_cloud~gen_scan_max_depthdouble~approx_syncbool""false""~rgbd_camerasintsubscribe_rgbdtruergbd_image0rgbd_image1~use_action_for_goalbool""false""goal_outmove_base_simple/goal~map_filter_radiusdoublemap_filter_angle~map_filter_angledoublemap_filter_radius~map_cleanupbool""true""cloud_mapgrid_mapproj_map~latchbool""true""~cloud_decimationintcloud_map~cloud_max_depthdoublecloud_map~cloud_voxel_sizedoublecloud_map~cloud_floor_culling_heightdoublecloud_map~cloud_output_voxelizedbool""false""cloud_map~cloud_frustum_cullingbool""false""cloud_map~cloud_noise_filtering_radiusdoublecloud_noise_filtering_min_neighborscloud_noise_filtering_radiuscloud_map~cloud_noise_filtering_min_neighborsdoublecloud_noise_filtering_min_neighborscloud_noise_filtering_radiuscloud_map~scan_voxel_sizedoublescan_map~scan_output_voxelizedbool""false""scan_map~grid_cell_sizedoublegrid_mapproj_map~grid_sizedoublegrid_mapproj_map~grid_erodedbool""false""grid_mapproj_map~grid_unknown_space_filledbool""false""grid_map~proj_max_ground_angledoubleproj_map~proj_min_cluster_sizeintgrid_cell_sizeproj_map~proj_max_heightdoubleproj_mapbase_link<the frame attached to sensors of incoming data>tfodombase_linkmapodom-d ""config.ini""""/.ros/rtabmapGUI.ini""odomsubscribe_depthsubscribe_stereoodom_frame_idrgb/imagesubscribe_depthsubscribe_stereoleft/image_rectrgb/camera_infosubscribe_stereoleft/camera_infodepth/imagesubscribe_depthscansubscribe_scanscan_cloudsubscribe_scan_cloudleft/image_rectsubscribe_stereoleft/camera_infosubscribe_stereoright/image_rectsubscribe_stereoright/camera_infosubscribe_stereoodom_infosubscribe_odom_infoinfomapDatargbd_imagesubscribe_rgbdtrue~subscribe_depthbool""false""~subscribe_scanbool""false""~subscribe_scan_cloudbool""false""~subscribe_stereobool""false""~subscribe_odom_infobool""false""~subscribe_rgbdbool""false""rgbd_image~frame_idstring""base_link""~odom_frame_idstring""""odom~tf_prefixstring""""~wait_for_transformbool""false""~queue_sizeint~rgbd_camerasintsubscribe_rgbdtruergbd_image0rgbd_image1base_link<the frame attached to sensors of incoming data>tfodombase_linkmapodom""--params""odomodom_infoOdom/FillInfoDatatrueodom_last_frameodom_local_mapOdom/Strategy=0reset_odomreset_odom_to_pose""x y z roll pitch yaw""pause_odomresume_odom~frame_idstring""base_link""~odom_frame_idstring""odom""~publish_tfbool""true""~tf_prefixbool""""~wait_for_transformbool""false""~initial_posestring""""""x y z roll pitch yaw""~queue_sizeint~publish_null_when_lostbool~ground_truth_frame_idstring""""~ground_truth_base_frame_idstring""""ground_truth_frame_id~guess_frame_idstring""""tfguess_frame_idodom_combinedodom_frame_idodomframe_idbase_footprintodomodom_combinedtf/odom -> /odom_combined -> /base_link~guess_min_translationfloat0.0guess_frame_id~guess_min_rotationfloat0.0guess_frame_id~config_pathstring""""base_link<the frame attached to sensors of incoming data>tfodombase_linkrgb/imagergb/camera_infodepth/imagergbd_imagesubscribe_rgbdtrue~approx_syncbool""true""~rgbd_camerasintsubscribe_rgbdtruergbd_image0rgbd_image1~subscribe_rgbdbool""false""rgbd_imageleft/image_rectleft/camera_inforight/image_rectright/camera_inforgbd_imagesubscribe_rgbdtrue~approx_syncbool""false""~subscribe_rgbdbool""false""rgbd_imagescanscanscan_cloudscan_cloudscanscan_cloud~scan_cloud_max_pointsint00~scan_downsampling_stepint1<=1~scan_voxel_sizefloat0.00.0~scan_normal_kint0Icp/Point2Plane0~scan_normal_radiusfloat0.0Icp/Point2Plane0.0imagestop_camerastart_camera~frame_idstring""camera""cloud_mapproj_map""mapData""mapData~reset""mapData""""mapData""mapData_optimizedposesRGBD/OptimizeStrategyRGBD/OptimizeIterations0RGBD/OptimizeMaxError0publish_tffalsemapData[mapData]_optimized[mapData]Graph_optimized~map_frame_idstring""map""~odom_frame_idstring""odom""~strategyint~slam_2dbool""false""~robustbool""true""strategy~global_optimizationbool""true""~iterationsint~epsilondoubleepsilon~ignore_variancebool""false""~optimize_from_last_nodebool""false""~publish_tfbool""true""~tf_delaydoublesubscribe_rgbdrtabmaprgb/imagedepth/imagergb/camera_inforgbd_imagergbd_image/compressed~queue_sizeint~approx_syncbool""True""~compressed_ratedoublergbd_image/compressedsubscribe_rgbdrtabmapleft/image_rectright/image_rectleft/camera_inforight/camera_inforgbd_imagergbd_image/compressed~queue_sizeint~approx_syncbool""False""~compressed_ratedoublergbd_image/compressedrgbd_image[rgbd_image]_relay~queue_sizeint~compressbool""False""~uncompressbool""False""odom_inrgb/image_indepth/image_inrgb/camera_info_inodom_outrgb/image_outdepth/image_outrgb/camera_info_out~queue_sizeintrgb/image_indepth/image_inrgb/camera_info_inrgb/image_outdepth/image_outrgb/camera_info_out~queue_sizeint~ratedouble~approx_syncbool""True""~decimationdoublecamera_info_outleft/image_rectleft/camera_inforight/image_rectright/camera_info[left/image_rect]_throttle[left/camera_info]_throttle[right/image_rect]_throttle[right/camera_info]_throttle~queue_sizeint~ratedouble~approx_syncbool""false""~decimationdoublergb/imagedepth/imagergb/camera_infoleft/imageleft/camera_inforight/imageright/camera_infocloud~queue_sizeint~approx_syncbool""true""""false""~decimationint~voxel_sizedouble0.0~min_depthdouble~max_depthdouble0.0~noise_filter_radiusdouble0.0~noise_filter_min_neighborsintdepth/imagedepth/camera_infodisparity/imagedisparity/camera_infocloud~queue_sizeint~approx_syncbool""true""~decimationint~voxel_sizedouble0.0~min_depthdouble~max_depthdouble0.0~noise_filter_radiusdouble0.0~noise_filter_min_neighborsintdisparitydepthdepth_rawfixed_frame_idcamera_infocloudimageimage_raw~queue_sizeint~fixed_frame_idstringapproxtrue~approxbool""true""~wait_for_transformdouble~decimationint~fill_holes_sizeint~fill_holes_errordouble~fill_iterationsintobstacles_detectioncloudgroundobstacles~frame_idstring""base_link""~queue_sizeint~normal_estimation_radiusdouble~ground_normal_angledouble~min_cluster_sizeint~max_obstacles_heightdoublebase_link<the frame attached to sensors of incoming data>tf$ roslaunch rtabmap_ros demo_robot_mapping.launch
$ rosbag play --clock demo_mapping.bag$ roslaunch rtabmap_ros demo_robot_mapping.launch localization:=true
$ rosbag play --clock demo_mapping.bag$ roslaunch rtabmap_ros demo_robot_mapping.launch rviz:=true rtabmapviz:=false
$ rosbag play --clock demo_mapping.bag$ roslaunch rtabmap_ros demo_multi-session_mapping.launch
$ rosbag play --clock --pause map1.bag
$ (...)
$ rosbag play --clock map2.bag
$ (...)
$ rosbag play --clock map3.bag
$ (...)
$ rosbag play --clock map4.bag
$ (...)
$ rosbag play --clock map5.bag$ roslaunch rtabmap_ros demo_find_object.launch
$ rosbag play --clock demo_find_object.bag$ roslaunch rtabmap_ros demo_stereo_outdoor.launch
$ rosbag play --clock stereo_outdoorA.bag
[...]
$ rosbag play --clock stereo_outdoorB.bag$ roslaunch rtabmap_ros demo_appearance_mapping.launch$ rostopic echo /rtabmap/info/loopClosureId
6
---
0
---
7
---$ roslaunch rtabmap_ros demo_appearance_mapping.launch localization:=true<launch>
<node name=""rtabmap"" pkg=""rtabmap_ros"" type=""rtabmap"">
   <param name=""Optimizer/Iterations"" type=""int"" value=""50""/>
</node>
</launch>$ rosrun rtabmap_ros rtabmap --params<launch>
<node name=""rtabmap"" pkg=""rtabmap_ros"" type=""rtabmap"" args="""">
   <!-- LOCALIZATION MODE -->
   <param name=""Mem/IncrementalMemory"" type=""string"" value=""false""/>
</node>
</launch>$ rosrun rtabmap_ros rgbd_odometry --params
or
$ rosrun rtabmap_ros stereo_odometry --params
or
$ rosrun rtabmap_ros icp_odometry --params$rosrun rtabmap_ros rtabmap --params | grep Optimize"
W893,https://wiki.ros.org/turtlebot_follower,Wiki,turtlebot_follower,"Follower for the turtlebot. Follows humans and robots around by following the centroid of a box points in front of the turtlebot.

Before running the follower, make sure your TurtleBot is setup: To start the follower, open an SSH terminal on the TurtleBot laptop, and run the following command: The follower should now be running. To initiate following, walk in front of the TurtleBot. Then, slowly walk away from the TurtleBot. The robot should move forward. Moving close to the TurtleBot will cause it to back away. Moving slowly to the left or right will cause the TurtleBot to turn. To stop the robot from following, walk quickly away from the robot. To get more details about running TurtleBot follower, please take a look to the  roslaunch turtlebot_follower follower.launch"
W894,https://wiki.ros.org/blort,Wiki,blort,"
    BLORT - The Blocks World Robotic Vision Toolbox 
    Ported and refactored version of the library.
    

"
W895,https://wiki.ros.org/kurt3d,Wiki,kurt3d,"

     kurt3d

  

Use GitHub to . []
  For installation instructions, see . "
W896,https://wiki.ros.org/rosatomic,Wiki,rosatomic,"rosatomic provides the C++11-style atomic operations by pulling symbols from the proposed Boost.Atomic
     package into the ros namespace.  Once C++11-style atomics (std::atomic) are available from compilers, rosatomic will
     conditionally use those instead."
W897,https://wiki.ros.org/naoqi_bridge_msgs,Wiki,naoqi_bridge_msgs,The naoqi_bridge_msgs package provides custom messages for running Aldebaran's robot such as NAO and Pepper. See the packages nao_robot and pepper_robot for details.
W898,https://wiki.ros.org/kobuki_gazebo,Wiki,kobuki_gazebo,"Kobuki simulation for Gazebo 

Refer to the Kobuki's  tutorial. "
W899,https://wiki.ros.org/turtlebot_arm_ikfast_plugin,Wiki,turtlebot_arm_ikfast_plugin,The turtlebot_arm_ikfast_plugin package
W900,https://wiki.ros.org/tf2,Wiki,tf2,"tf2 is the second generation of the transform library, which lets
    the user keep track of multiple coordinate frames over time. tf2
    maintains the relationship between coordinate frames in a tree
    structure buffered in time, and lets the user transform points,
    vectors, etc between any two coordinate frames at any desired
    point in time. 




 is the core of a group of packages which form the 2nd generation of .  There are three types of packages. 
 implements templated datatype support. This allows the core packages to have minimal dependencies and there be packages which add support for converting to and from different datatypes as well as transforming those data types. Please see  overview, and  for how to use tf2 with different datatypes.  does have an internal datatypes which are based on 's LinearMath library. However it's recommended to use a fully supported math datatype which best supports your application.  conversion methods also support converting between and transforming between multiple different datatypes too. 


 In previous versions there was a concept of a  which would be prepended to the frame name using a  separator. A leading slash used to indicate that it had already been prefixed. For backwards compatibility tf2 will strip any leading  character.   

 provides basic geometry data types, such as , , , . These data types support linear algebra operations between each other. 



 You want to  what tf can do instead of just reading about it? Check out the . A robotic system typically has many 3D  that change over , such as a world frame, base frame, gripper frame, head frame, etc. tf2 keeps track of all these frames over time, and allows you to ask questions like: tf2 can operate in a . This means all the information about the coordinate frames of a robot is available to all ROS components on any computer in the system.  Tf2 can operate with a central server that contains all transform information, or you can have every component in your distributed system build its own transform information database. For more information on the design see  There is a paper on tf presented at TePRA 2013  We created a set of  that walk you through using tf2, step by step. You can get started on the  tutorial. For a complete list of all tf2 and tf2-related tutorials check out the  page. Once you are finished with the basic tutorials, you can move on to learn about tf2 and time. The tf2 and time tutorial   teaches the basic principles of tf2 and time. The advanced tutorial about tf2 and time   teaches the principles of time traveling with tf2. If you are looking for an easy tool to manually tweak tf transforms, such as for quick calibration-by-eye tuning, try  The  described the high level design of the tf2 library. At it's core  relies on the  which can be conveniently correlated to ROS messages which have a . Coordinate frames in ROS are identified by a string  in the format lower case underscore separated. This string has to be unique in the system. All data produced can simply identify it's  to state where it is in the world. The concept of   is not scoped in the same way as . In particular, namespacing a specific subpart of a computation graph does not change the physical layout which the  tree represents. Because of this s do not follow namespace remapping rules. It is common to support a  to allow changing s used in algorithms. For use cases with multiple robots it is generally recommended to use multiple masters and forward specific tf information between the robots. There are several different methods of implementing bridges between masters. For more information please see the . These packages provide the primary interface for developers using . For more information about migrating from  see  tf2tf2tf2bullettf2tf2frame_idframe_idtf_prefixtf_prefix//tfframe_idstfframe_idframe_idtf2BufferListenerBufferBroadcasterBufferServerBufferClientBufferListenerBufferBroadcasterBufferClient"
W901,https://wiki.ros.org/xbot,Wiki,xbot,"Software for xbot, Droid Robot's mobile research base.

Introduction:  Tutorial:  "
W902,https://wiki.ros.org/ar_track_alvar,Wiki,ar_track_alvar,"This package is a ROS wrapper for Alvar, an open source AR tag tracking library.visualization_markerar_pose_markerCamera frame (from Camera info topic param)AR tag framevisualization_markerar_pose_markerCamera frame (from Camera info topic param)AR tag framemarker_sizemax_new_marker_errormax_track_errorcamera_imagecamera_infooutput_frame./bundlesmarker_sizemax_new_marker_errormax_track_errorcamera_imagecamera_infooutput_framebundle_files(e.g.) /kinect_head/rgb/camera_info(any topic in an image format)visualization_markerar_pose_markerCamera frame (from Camera info topic param)AR tag framevisualization_markerar_pose_markerCamera frame (from Camera info topic param)AR tag frame$ git clone https://github.com/sniekum/ar_track_alvar.git
$ git checkout f093668$ sudo apt-get install ros-fuerte-ar-track-alvar


$ sudo apt-get install ros-indigo-ar-track-alvar


"
W903,https://wiki.ros.org/asmach,Wiki,asmach,"
    SMACH, which stands for 'state machine', is a task-level
    architecture for rapidly creating complex robot behavior. At its
    core, SMACH is a ROS-independent Python library to build
    hierarchical state machines.  SMACH is a new library that takes
    advantage of very old concepts in order to quickly create robust
    robot behavior with maintainable and modular code.
  "
W904,https://wiki.ros.org/trac_ik_examples,Wiki,trac_ik_examples,This package contains the source code for testing and comparing trac_ik
W905,https://wiki.ros.org/sr_example,Wiki,sr_example,"

    sr_example is an example of a real package interfaced with our robot. Please refer to the tutorial Creating a package to interact with our robots.

  
Please refer to  for more information. "
W906,https://wiki.ros.org/turtlebot_core_apps,Wiki,turtlebot_core_apps,"

    The core set of turtlebot 'app manager' apps are defined in this package.

  "
W907,https://wiki.ros.org/hostapd_access_point,Wiki,hostapd_access_point,"
    A ROS node that controls a hostapd-based access
    point. It is mainly intended for use with a wireless 
    network adapter running in master mode. It implements 
    the dynamic_reconfigure interface defined
    in the [[access_point_control]] package.
  




   



:  
A ROS node for starting and controlling a hostapd-based access point. This node works with wifi adapters that have -compatible drivers which support master mode (see  for more information). This is an example that shows how to set up an access point and control its parameters using the  interface. The following launch file starts an AP node on the  interface and the : The desired configuration is selected: mode , channel 44, WPA security with the chosen password, a TX power level of 8 dBm and a TX bitrate of 24Mbit/s. Next the  checkbox is checked at the AP is started: This script is useful for setting up a -based setup. mac80211_hwsim is a 802.11 radio simulator. The script takes two parameters: If the mac80211_hwsim is not loaded or if the number of radios it has currently spawned is smaller than  then it is re-loaded with the proper radio count. The script prints to its output the name of the -th interface. For example (this is taken from a real setup), suppose that the system has a real wireless interface with name  and we need to spawn three virtual interfaces. Their names will be ,  and .  Using : The script can be used to launch nodes on the  with roslaunch. The following example, launches two nodes on the first and second mac80211_hwsim interfaces while ensuring that there are at least three total interfaces: ap_hostapd_node.py~interfacestringwlan0wlan1~ipstring~netmaskstring~hostapd_pathstringhostapd~enabledboolTrueFalse~ssidstrtest~wmmbool~modestrbabg~freqdoublea~ieee80211nbool~encryption_modestringopenwepwpawpa2wpa_wpa2~encryption_passstring~txpower_autobool~txpowerinttxpower_autoFalse~bitrateint1000000b24000000ga~statusstringOKFAILerrmsg~errmsgstringreconfigure_guiwlan0reconfigure_guiaenabledmac80211_hwsimradio indextotal number of radiostotal number of radiosradio indexwlan1wlan0wlan1wlan2find_hwsim_iface.pywlan0hwsim_nat_setup.shnetwork_traffic_controlap_hostapd_node.py<launch>
    <node name=""ap_wlan0"" pkg=""hostapd_access_point"" type=""ap_hostapd_node.py"">
        <param name=""interface"" value=""wlan0""/>
        <param name=""ip"" value=""192.168.68.1""/>
        <param name=""netmask"" value=""255.255.255.0""/>
    </node>
    <node name=""reconfigure_node"" pkg=""dynamic_reconfigure"" type=""reconfigure_gui""/>
</launch>import dynamic_reconfigure.client

ap = dynamic_reconfigure.client.Client(""ap_wlan0"")

freq = IEEE80211_Channels.get_freq(44, IEEE80211_Channels.BAND_5000_MHz)
config = ap.update_configuration({""enabled"": True, ""mode"": 'a', ""freq"": freq, ""encryption_mode"": ""wpa"", ""encryption_pass"": ""sample_password"", ""txpower_auto"": False, ""txpower"": 8, ""bitrate"": 24*10**6})

if config['status'] != ""OK"":
    raise Exception(""AP failed to start: "" + config['errmsg'])

freq = IEEE80211_Channels.get_freq(1, IEEE80211_Channels.BAND_2400_MHz)
config = ap.update_configuration({""freq"": freq})

if config['status'] != ""OK"":
    raise Exception(""AP failed to start: "" + config['errmsg'])$ echo `rosrun hostapd_access_point find_hwsim_iface.py 1 3`
wlan0
$ echo `rosrun hostapd_access_point find_hwsim_iface.py 2 3`
wlan1
$ echo `rosrun hostapd_access_point find_hwsim_iface.py 3 3`
wlan1<launch>
    <node name=""ap1"" pkg=""hostapd_access_point"" type=""ap_hostapd_node.py"">
        <param name=""interface"" command=""$(find hostapd_access_point)/scripts/find_hwsim_iface.py 1 3""/>
    </node>

    <node name=""ap2"" pkg=""hostapd_access_point"" type=""ap_hostapd_node.py"">
        <param name=""interface"" command=""$(find hostapd_access_point)/scripts/find_hwsim_iface.py 2 3""/>
    </node>
</launch># rosrun hostapd_access_point hwsim_nat_setup.sh wlan0 192.168.68.1 192.168.69.1 wlan1 192.168.69.2 192.168.68.2

# ifconfig wlan0
wlan0     Link encap:Ethernet  HWaddr 02:00:00:00:00:00  
          inet addr:192.168.68.1  Bcast:192.168.68.255  Mask:255.255.255.0

# ifconfig wlan1
wlan1     Link encap:Ethernet  HWaddr 02:00:00:00:01:00  
          inet addr:192.168.69.2  Bcast:192.168.69.255  Mask:255.255.255.0"
W908,https://wiki.ros.org/willow_maps,Wiki,willow_maps,"Holds maps of Willow Garage that can be used for a number of different applications.
"
W909,https://wiki.ros.org/pr2_navigation_global,Wiki,pr2_navigation_global,"This package holds XML files for running the



This package contains configuration files for the  and  nodes meant to be run in an application that requires global navigation with a pre-specified static map. This package also includes launch files that bring up  and  with global navigation specific configurations. rviz/rviz_move_base.launchnav_view/nav_view_move_base.launchmove_base.xmlamcl_node.xmlconfig/base_local_planner_params.yamlconfig/global_costmap_params.yamlmove_base.xmlconfig/local_costmap_params.yamlmove_base.xml"
W910,https://wiki.ros.org/jog_controller,Wiki,jog_controller,The jog_controller package
W911,https://wiki.ros.org/pcl_msgs,Wiki,pcl_msgs,Package containing PCL (Point Cloud Library)-related ROS messages.
W912,https://wiki.ros.org/tensorflow_ros_cpp,Wiki,tensorflow_ros_cpp,"Catkin-friendly C++ bindings for the tensorflow package. 
 are available for each of the options. 

 See the usage example at  . A comprehensive list of compatible options for various OSes and ROS distros is available . Ubuntu systems starting with 16.04 (Xenial) are using the new C++11 ABI for all system libraries. Until   gets resolved (if ever!), the pip-distributed Tensorflow is built  againts an older C++ ABI, which is incompatible with the C++11 ABI. This  means linking to the Tensorflow library will fail on such systems and  there's no way around it. An example of this approach can be found at . <run_depend>python-tensorflow-pip</run_depend>find_package(catkin REQUIRED COMPONENTS
  ... your other packages ...
  tensorflow_ros_cpp
)rosdep install ... --skip-keys=tensorflow_catkin --skip-keys=python-tensorflow-pip"
W913,https://wiki.ros.org/laser_scan_sparsifier,Wiki,laser_scan_sparsifier,"The laser_scan_sparsifier takes in a LaserScan message and sparsifies it.



 The  package is used to downsample  messages. Two drivers are available:  and . Their parameters and topics are identical. Please submit your tickets through  (requires github account) or by emailing the maintainers. laser_scan_sparsifier_nodeletlaser_scan_sparsifier_nodelaser_scan_sparsifierscanscan_sparse~stepint"
W914,https://wiki.ros.org/wheeled_robin_rviz_launchers,Wiki,wheeled_robin_rviz_launchers,"Launchers for visualizing WheeledRobin



 This package provides several launch files for  to visualize . First launch the robot either in real or faked mode and start the Kinect drivers (see Getting Started section in ). roslaunch wheeled_robin_rviz_launchers view_robot.launch"
W915,https://wiki.ros.org/ntpd_driver,Wiki,ntpd_driver,"ntpd_driver sends TimeReference message time to ntpd server





Just add to : Add this to : /etc/ntp.conf/etc/chrony/chrony.conf~time_ref~shm_unitint### GPS SHM driver (unit 2)
server 127.127.28.2 minpoll 4 maxpoll 4
fudge 127.127.28.2 time1 0.5 stratum 12 refid ROS### SHM driver (unit 2)
refclock SHM 2 delay 0.5 refid ROS"
W916,https://wiki.ros.org/waypoint_generator,Wiki,waypoint_generator,Generates waypoint yaml file
W917,https://wiki.ros.org/turtlebot3_follower,Wiki,turtlebot3_follower,"The follower demo was implemented using a 360 Laser Distance Sensor LDS-01. The classification algorithm is used based on previous fitting with samples of person and obstacles positions to take actions. It follows someone in front of the robot within a 50 centimeter range and 140 degrees. 


scan_filteredcmd_vel"
W918,https://wiki.ros.org/toposens_description,Wiki,toposens_description,"3D models of the sensor for visualization.
"
W919,https://wiki.ros.org/schunk_libm5api,Wiki,schunk_libm5api,This package wraps the libm5api to use it as a ros dependency. Original sources from http://www.schunk-modular-robotics.com/fileadmin/user_upload/software/schunk_libm5api_source.zip.
W920,https://wiki.ros.org/ridgeback_control,Wiki,ridgeback_control,"Controllers for Ridgeback
's mobility is controlled by mecanum_drive_controller. "
W921,https://wiki.ros.org/jsk_gui_msgs,Wiki,jsk_gui_msgs,jsk_gui_msgs
W922,https://wiki.ros.org/turtlebot3_autorace_detect,Wiki,turtlebot3_autorace_detect,"AutoRace ROS packages for feature detection with TurtleBot3 Auto










detect/image_input/compresseddetect/image_inputdetect/image_output/compresseddetect/image_output_sub1/compresseddetect/image_output_sub2/compresseddetect/image_outputdetect/image_output_sub1detect/image_output_sub2detect/yellow_line_reliabilitydetect/white_line_reliabilitydetect/image_input/compresseddetect/image_inputdetect/level_crossing_ordercontrol/level_crossing_finisheddetect/image_output/compresseddetect/image_output_sub1/compresseddetect/image_outputdetect/image_output_sub1detect/level_crossing_stampedcontrol/level_crossing_startcontrol/max_veldetect/parking_lot_orderdetect/scancontrol/parking_finisheddetect/image_input/compresseddetect/image_inputdetect/image_output/compresseddetect/image_outputdetect/parking_lot_stampedcontrol/parking_startcontrol/max_veldetect/image_input/compresseddetect/image_inputdetect/image_output/compresseddetect/image_outputdetect/traffic_signdetect/image_input/compresseddetect/image_inputcontrol/traffic_light_finisheddetect/image_output/compresseddetect/image_outputdetect/image_output_sub1/compresseddetect/image_output_sub2/compresseddetect/image_output_sub3/compresseddetect/image_output_sub1detect/image_output_sub2detect/image_output_sub3detect/traffic_light_stampedcontrol/traffic_light_startcontrol/max_veldetect/tunnel_ordermove_base/resultodomdetect/tunnel_stampedmove_base_simple/goalcontrol/cmd_velcontrol/max_vel#------------------ parameter for HSL detection of withe lane ------------------#
gen.add(""hue_white_l"",         int_t,   0,   ""hue_white_l"",         0,   0, 179)
gen.add(""hue_white_h"",         int_t,   0,   ""hue_white_h"",         179, 0, 179)
gen.add(""saturation_white_l"",  int_t,   0,   ""saturation_white_l"",  0,   0, 255)
gen.add(""saturation_white_h"",  int_t,   0,   ""saturation_white_h"",  255, 0, 255)
gen.add(""lightness_white_l"",   int_t,   0,   ""lightness_white_l"",   0,   0, 255)
gen.add(""lightness_white_h"",   int_t,   0,   ""lightness_white_h"",   255, 0, 255)

 ------------------ parameter for HSL detection of yellow lane -----------------#
gen.add(""hue_yellow_l"",        int_t,   0,   ""hue_yellow_l"",        0,   0, 179)
gen.add(""hue_yellow_h"",        int_t,   0,   ""hue_yellow_h"",        179, 0, 179)
gen.add(""saturation_yellow_l"", int_t,   0,   ""saturation_yellow_l"", 0,   0, 255)
gen.add(""saturation_yellow_h"", int_t,   0,   ""saturation_yellow_h"", 255, 0, 255)
gen.add(""lightness_yellow_l"",  int_t,   0,   ""lightness_yellow_l"",  0,   0, 255)
gen.add(""lightness_yellow_h"",  int_t,   0,   ""lightness_yellow_h"",  255, 0, 255)#------------------ parameter for HSL detection of red color ------------------#
gen.add(""hue_red_l"",           int_t,   0,   ""hue_red_l"",           0,   0, 179)
gen.add(""hue_red_h"",           int_t,   0,   ""hue_red_h"",           179, 0, 179)
gen.add(""saturation_red_l"",    int_t,   0,   ""saturation_red_l"",    0,   0, 255)
gen.add(""saturation_red_h"",    int_t,   0,   ""saturation_red_h"",    255, 0, 255)
gen.add(""lightness_red_l"",     int_t,   0,   ""lightness_red_l"",     0,   0, 255)
gen.add(""lightness_red_h"",     int_t,   0,   ""lightness_red_h"",     255, 0, 255)#------------- parameter for HSL detection of traffic red light ---------------#
gen.add(""hue_red_l"",           int_t,   0,   ""hue_red_l"",           0,   0, 179)
gen.add(""hue_red_h"",           int_t,   0,   ""hue_red_h"",           179, 0, 179)
gen.add(""saturation_red_l"",    int_t,   0,   ""saturation_red_l"",    0,   0, 255)
gen.add(""saturation_red_h"",    int_t,   0,   ""saturation_red_h"",    255, 0, 255)
gen.add(""lightness_red_l"",     int_t,   0,   ""lightness_red_l"",     0,   0, 255)
gen.add(""lightness_red_h"",     int_t,   0,   ""lightness_red_h"",     255, 0, 255)

#------------ parameter for HSL detection of traffic yellow light -------------#
gen.add(""hue_yellow_l"",        int_t,   0,   ""hue_yellow_l"",        0,   0, 179)
gen.add(""hue_yellow_h"",        int_t,   0,   ""hue_yellow_h"",        179, 0, 179)
gen.add(""saturation_yellow_l"", int_t,   0,   ""saturation_yellow_l"", 0,   0, 255)
gen.add(""saturation_yellow_h"", int_t,   0,   ""saturation_yellow_h"", 255, 0, 255)
gen.add(""lightness_yellow_l"",  int_t,   0,   ""lightness_yellow_l"",  0,   0, 255)
gen.add(""lightness_yellow_h"",  int_t,   0,   ""lightness_yellow_h"",  255, 0, 255)

#------------ parameter for HSL detection of traffic green light --------------#
gen.add(""hue_green_l"",         int_t,   0,   ""hue_green_l"",         0,   0, 179)
gen.add(""hue_green_h"",         int_t,   0,   ""hue_green_h"",         179, 0, 179)
gen.add(""saturation_green_l"",  int_t,   0,   ""saturation_green_l"",  0,   0, 255)
gen.add(""saturation_green_h"",  int_t,   0,   ""saturation_green_h"",  255, 0, 255)
gen.add(""lightness_green_l"",   int_t,   0,   ""lightness_green_l"",   0,   0, 255)
gen.add(""lightness_green_h"",   int_t,   0,   ""lightness_green_h"",   255, 0, 255)"
W923,https://wiki.ros.org/pheeno_ros,Wiki,pheeno_ros,"The pheeno_ros package contains necessary files for run and control an individual Pheeno unit with ROS.
Documentation for our package can be found . We will also be adding documentation to this ROS page in the coming weeks. "
W924,https://wiki.ros.org/rtctree,Wiki,rtctree,API for interacting with running RT-Components and managing RTM-based systems using OpenRTM-aist.
W925,https://wiki.ros.org/octomap_msgs,Wiki,octomap_msgs,"This package provides messages and serializations / conversion for the . 
 "
W926,https://wiki.ros.org/graph_rviz_plugin,Wiki,graph_rviz_plugin,An RViz plugin to draw graphs from topics valuesDocumentation is here:  
W927,https://wiki.ros.org/vigir_pluginlib_msgs,Wiki,vigir_pluginlib_msgs,"The vigir_pluginlib_msgs package
The  package provides basic message definition needed for inter-process communication via ROS. See . "
W928,https://wiki.ros.org/pr2_2dnav,Wiki,pr2_2dnav,"This application allows the PR2 robot to navigate autonomously with a pre-specified static map.









As with all PR2 applications, you must . This application assumes that a map is provided. Please see documentation on the  for information on providing a map over ROS. Tuck the arms of the PR2 using the . The  application can be run with the following command: The  stack that is the heart of the pr2_2dnav application can be commanded via , , or through code. roslaunch pr2_2dnav pr2_2dnav.launchroslaunch pr2_navigation_global rviz_move_base.launchroslaunch pr2_navigation_global nav_view_move_base.launch"
W929,https://wiki.ros.org/costmap_2d,Wiki,costmap_2d,"This package provides an implementation of a 2D costmap that takes in sensor
        data from the world, builds a 2D or 3D occupancy grid of the data (depending
        on whether a voxel based implementation is used), and inflates costs in a
        2D costmap based on the occupancy grid and a user specified inflation radius.
        This package also provides support for map_server based initialization of a
        costmap, rolling window based costmaps, and parameter based subscription to
        and configuration of sensor topics.
  




 

The  package provides a configurable structure that maintains information about where the robot should navigate in the form of an occupancy grid. The costmap uses sensor data and information from the static map to store and update information about obstacles in the world through the  object. The  object provides a purely two dimensional interface to its users, meaning that queries about obstacles can only be made in columns. For example, a table and a shoe in the same position in the XY plane, but with different Z positions would result in the corresponding cell in the  object's costmap having an identical cost value. This is designed to help planning in planar spaces. As of the Hydro release, the underlying methods used to write data to the costmap is fully configurable. Each bit of functionality exists in a layer. For instance, the static map is one layer, and the obstacles are another layer. By default, the obstacle layer maintains information three dimensionally (see ). Maintaining 3D obstacle data allows the layer to deal with marking and clearing more intelligently. The main interface is  which maintains much of the ROS related functionality. It contains a  which is used to keep track of each of the layers. Each layer is instantiated in the  using  and is added to the . The layers themselves may be compiled individually, allowing arbitrary changes to the costmap to be made through the C++ interface. The  class implements the basic data structure for storing and accessing the two dimensional costmap. While each cell in the costmap can have one of 255 different cost values (see the  section), the underlying structure that it uses is capable of representing only three. Specifically, each cell in this structure can be either free, occupied, or unknown. Each status has a special cost value assigned to it upon projection into the costmap. Columns that have a certain number of occupied cells (see  parameter) are assigned a  cost, columns that have a certain number of unknown cells (see  parameter) are assigned a  cost, and other columns are assigned a  cost. The costmap performs map update cycles at the rate specified by the  parameter. Each cycle, sensor data comes in, marking and clearing operations are perfomed in the underlying occupancy structure of the costmap, and this structure is projected into the costmap where the appropriate cost values are assigned as described . After this, each obstacle inflation is performed on each cell with a  cost. This consists of propagating cost values outwards from each occupied cell out to a user-specified inflation radius. The details of this inflation process are outlined . In order to insert data from sensor sources into the costmap, the  object makes extensive use of . Specifically, it assumes that all transforms between the coordinate frames specified by the  parameter, the  parameter, and sensor sources are connected and up-to-date. The  parameter sets the maximum amount of latency allowed between these transforms. If the  tree is not updated at this expected rate, the  stops the robot. There are two main ways to initialize a  object. The first is to seed it with a user-generated static map (see the  package for documentation on building a map). In this case, the costmap is initialized to match the width, height, and obstacle information provided by the static map. This configuration is normally used in conjunction with a localization system, like , that allows the robot to register obstacles in the map frame and update its costmap from sensor data as it drives through its environment. The second way to initialize a  object is to give it a width and height and to set the  parameter to be true.  The  parameter keeps the robot in the center of the costmap as it moves throughout the world, dropping obstacle information from the map as the robot moves too far from a given area. This type of configuration is most often used in an odometric coordinate frame where the robot only cares about obstacles within a local area. costmap_2dcostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::LayeredCostmapCostmap2DROSLayeredCostmapcostmap_2d::Costmap2Dcostmap_2d::LETHAL_OBSTACLEcostmap_2d::NO_INFORMATIONcostmap_2d::FREE_SPACEcostmap_2d::LETHAL_OBSTACLEcostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::Costmap2DROScostmap_2d::Costmap2Dcostmap_2d::Costmap2DROS~<name>/obstacles~<name>/inflated_obstacles~<name>/unknown_space~<name>/voxel_grid<point_cloud_topic>""PointCloud""observation_sources<point_cloud2_topic>""PointCloud2""observation_sources<laser_scan_topic>""LaserScan""observation_sources""map""costmap_2d::Costmap2DROS~<name>/global_framestring""/map""~<name>/robot_base_framestring""base_link""~<name>/transform_tolerancedoubleglobal_framerobot_base_frametransform_toleranceros::Time::now()~<name>/update_frequencydouble~<name>/publish_frequencydouble~<name>/max_obstacle_heightdouble~<name>/obstacle_rangedouble~<name>/raytrace_rangedouble~<name>/cost_scaling_factordoubleexp(-1.0 * cost_scaling_factor * (distance_from_obstacle - inscribed_radius)) * (costmap_2d::INSCRIBED_INFLATED_OBSTACLE - 1)~<name>/inflation_radiusdouble~<name>/footprintlist~<name>/robot_radiusdouble~<name>/observation_sourcesstring""""<source_name>source_nameobservation_sources~<name>/<source_name>/topicstringsource_name~<name>/<source_name>/sensor_framestring""""sensor_msgs/LaserScansensor_msgs/PointCloudsensor_msgs/PointCloud2~<name>/<source_name>/observation_persistencedouble~<name>/<source_name>/expected_update_ratedouble~<name>/<source_name>/data_typestring""PointCloud""""PointCloud""""PointCloud2""""LaserScan""~<name>/<source_name>/clearingboolfalse~<name>/<source_name>/markingbooltrue~<name>/<source_name>/max_obstacle_heightdoublemax_obstacle_heightmax_obstacle_height~<name>/<source_name>/min_obstacle_heightdouble~<name>/<source_name>/obstacle_rangedouble~<name>/<source_name>/raytrace_rangedouble~<name>/static_mapbooltruerolling_window~<name>/rolling_windowboolfalsestatic_map~<name>/unknown_cost_valueint~<name>/publish_voxel_mapboolfalse~<name>/lethal_cost_thresholdint~<name>/map_topicstring~<name>/widthint~<name>/heightint~<name>/resolutiondouble~<name>/origin_xdouble~<name>/origin_ydouble~<name>/map_typestring""voxel""""voxel""""costmap""map_type""voxel""~<name>/origin_zdouble~<name>/z_resolutiondouble~<name>/z_voxelsint~<name>/unknown_thresholdint~<name>/mark_thresholdint~<name>/track_unknown_spaceboolfalse(value of global_frame parameter)(value of robot_base_frame parameter)costmap_2d::Costmap2DROScostmap_2d::Costmap2DPublisherraw_obstaclesinflated_obstaclesunknown_spaceCostmap2DPublishercostmap_2d::Costmap2Dcostmap_2d::Costmap2Dcostmap_2d::Costmap2DROScosmtap_2d::Costmap2Dcostmap_2d::VoxelCostmap2DCostmap2Dcostmap_2d::VoxelCostmap2Dcostmap_2d::VoxelCostmap2Dcostmap_2d::Costmap2DROScostmap_2d::VoxelCostmap2Dcostmap_2d::ObservationBuffercostmap_2d::ObservationBuffercostmap_2d::Costmap2DROScostmap_2d::ObservationBuffercostmap_2d::Costmap2DROScostmap_2d::Costmap2Dcostmap_2d::Costmap2DROSrosrunroslaunchcostmap_2dcostmapmove_base~<name>/footprint~<name>/costmap~<name>/costmap_updates~<name>/voxel_gridcostmap_2dpluginsstatic_layerobstacle_layerinflation_layerplugins~<name>/pluginssequence~<name>/global_framestring""/map""~<name>/robot_base_framestring""base_link""~<name>/transform_tolerancedoubleglobal_framerobot_base_frametransform_toleranceros::Time::now()~<name>/update_frequencydouble~<name>/publish_frequencydouble~<name>/rolling_windowboolfalsestatic_map~<name>/always_send_full_costmapboolfalse~<name>/widthint~<name>/heightint~<name>/resolutiondouble~<name>/origin_xdouble~<name>/origin_ydouble(value of global_frame parameter)(value of robot_base_frame parameter)costmap_2d::Costmap2DROSObstacleCostmapPlugin













"
W930,https://wiki.ros.org/naoqi_tools,Wiki,naoqi_tools,"Set of tools provided by Aldebaran to convert Aldebaran files (URDF, blender...)"
W931,https://wiki.ros.org/base_local_planner,Wiki,base_local_planner,"This package provides implementations of the Trajectory Rollout and Dynamic Window approaches to local robot navigation on a plane. Given a plan to follow and a costmap, the controller produces velocity commands to send to a mobile base. This package supports both holonomic and non-holonomic robots, any robot footprint that can be represented as a convex polygon or circle, and exposes its configuration as ROS parameters that can be set in a launch file. This package's ROS wrapper adheres to the BaseLocalPlanner interface specified in the  package.
 


 











 





 (, default: 2.5)  (, default: [-0.3, -0.1, 0.1, 0.3]) 
 (, default: 0.05) 
 (, default: 1.0) 
 (, default: ) 
 (, default: 0.05) 
 (, default: ) 

The  package provides a controller that drives a mobile base in the plane.  This controller serves to connect the path planner to the robot.  Using a map, the planner creates a kinematic trajectory for the robot to get from a start to a goal location. Along the way, the planner creates, at least locally around the robot, a value function, represented as a grid map.  This value function encodes the costs of traversing through the grid cells.  The controller's job is to use this value function to determine dx,dy,dtheta velocities to send to the robot. The groovy release of ROS includes a new implementation of the  package. The implementation attempts to be more modular, to allow easier creation of custom local planners while reusing a lot of code. The code base of base_local_planner has been extended with several new headers and classes. The interfaces and classes below capture the generic local planning principles allowing many instantiations. It should be possible to create custom local planners using the  as template and just adding own cost functions or trajectory generators. This interface describes a Generator which may generate a finite or infinte number of trajectories, returning a new one on each invocation of .  The  class can generate trajectories described in the overview, using either the trajectory rollout or the DWA principle. This interface contains most importantly , which takes a trajectory and returns a score. A negative score means the trajectory is invalid. For positive value, the semantics are that a trajectory with a lower score is preferrable to one with a higher score with respect to this cost function. The  package ships with some cost functions used on the PR2, described below. This is a simple implementation of a trajectory search, taking a  and a list of . It will invoke  until the generator stops generating trajectories. For each, trajectory, it will loop over the list of cost functions, adding up their positive values or aborting the scoring if one cost function returns a negative value. The  is a Controller that can be used as soon as the robot is close enough to the goal. The Controller will then just perform a full stop and a rotation on the spot towards the goal orientation, regardless of whether the robot position after the full stop leads the robot outside the goal position tolerance. The  object is a  for a  object that exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: There are a large number of ROS  that can be set to customize the behavior of the  wrapper. These parameters are grouped into several categories: robot configuration, goal tolerance, forward simulation, trajectory scoring, oscillation prevention, and global plan. The following parameters are only used if  is set to true: The  provides implementations of the DWA and Trajectory Rollout algorithms described earlier. In order to use the  with ROS, please use the . It is not recommended to use the  on its own. The C++ API is stable. However, it is recommended that you use the  instead of using the  on its own. base_local_plannerdwa_local_plannernextTrajectory()SimpleTrajectoryGeneratorscoreTrajectory(Trajectory &traj)base_local_plannerTrajectorySampleGeneratorTrajectoryCostFunctionnextTrajectory()base_local_planner::TrajectoryPlannerROSbase_local_planner::TrajectoryPlannernav_core::BaseLocalPlannerbase_local_planner::TrajectoryPlannerROS~<name>/global_plan~<name>/local_plan~<name>/cost_cloudpublish_cost_grid_pcodomrobot_base_frameTrajectoryPlannerROS objectrobot_base_framebase_local_planner::TrajectoryPlannerROS~<name>/acc_lim_xdouble~<name>/acc_lim_ydouble~<name>/acc_lim_thetadouble~<name>/max_vel_xdouble~<name>/min_vel_xdouble~<name>/max_vel_thetadouble~<name>/min_vel_thetadouble~<name>/min_in_place_vel_thetadouble~<name>/backup_veldouble~<name>/escape_veldouble~<name>/holonomic_robotboolholonomic_robot~<name>/y_velslist~<name>/yaw_goal_tolerancedouble~<name>/xy_goal_tolerancedouble~<name>/latch_xy_goal_tolerancebool~<name>/sim_timedouble~<name>/sim_granularitydouble~<name>/angular_sim_granularitydouble~<name>/vx_samplesinteger~<name>/vtheta_samplesinteger~<name>/controller_frequencydouble~<name>/meter_scoringboolfalsegdist_scalepdist_scalegoal_distancepath_distance~<name>/pdist_scaledouble~<name>/gdist_scaledouble~<name>/occdist_scaledouble~<name>/heading_lookaheaddouble~<name>/heading_scoringboolfalse~<name>/heading_scoring_timestepdouble~<name>/dwabooltrue~<name>/publish_cost_grid_pcboolfalsesensor_msgs/PointCloud2~<name>/cost_cloud~<name>/global_frame_idstringodomcost_cloud~<name>/oscillation_reset_distdouble~<name>/prune_planbooltruebase_local_planner::TrajectoryPlannerbase_local_planner::TrajectoryPlannerbase_local_planner::TrajectoryPlannerbase_local_planner::TrajectoryPlanner










cost = 
  pdist_scale * (distance to path from the endpoint of the trajectory in map cells or meters depending on the meter_scoring parameter) 
  + gdist_scale * (distance to local goal from the endpoint of the trajectory in map cells or meters depending on the meter_scoring parameter) 
  + occdist_scale * (maximum obstacle cost along the trajectory in obstacle cost (0-254))"
W932,https://wiki.ros.org/kdl_parser_py,Wiki,kdl_parser_py,"The Kinematics and Dynamics Library (KDL) defines a tree structure
   to represent the kinematic and dynamic parameters of a robot
   mechanism.  provides Python tools to construct a KDL
   tree from an XML robot representation in URDF.kdl_parser_pykdl_parser_pykdl_parser_pykdl_parser_pykdl_parser_py"
W933,https://wiki.ros.org/rosmon,Wiki,rosmon,"Node launcher and monitor for ROS. rosmon is a replacement
		for the roslaunch tool, focused on performance, remote
		monitoring, and usability. 







rosmon is a drop-in replacement for the venerable  tool. It offers some interesting features both for monitoring and debugging: The  specification is complex and a bit vague, so you can expect some differences. Bug reports are welcome! Known differences include: For additional information and rosmon extensions not supported by roslaunch see . rosmon can also be controlled remotely using an  plugin, which uses rosmon's ROS interface. The context menu offers starting and stopping control. Additionally collected statistics (CPU and memory usage) are displayed. <machine>~state~start_stopsudo apt install ros-${ROS_DISTRO}-rosmon

source /opt/ros/${ROS_DISTRO}/setup.bash # Needed to use the 'mon launch' shortcutmon launch <package> <launch file> [arguments]mon launch <path to launch file> [arguments]Usage:
  rosmon [actions] [options] some_package test.launch [arg1:=value1 ...]
  rosmon [actions] [options] path/to/test.launch [arg1:=value1 ...]

Actions (default is to launch the launch file):
  --benchmark    Exit after loading the launch file
  --list-args    List launch file arguments

Options:
  --disable-ui   Disable fancy terminal UI
  --help         This help screen
  --log=FILE     Write log file to FILE
  --name=NAME    Use NAME as ROS node name. By default, an anonymous
                 name is chosen.

rosmon also obeys some environment variables:
  ROSMON_COLOR_MODE   Can be set to 'truecolor', '256colors', 'ansi'
                      to force a specific color mode
                      If unset, rosmon tries to detect the best
                      available color mode."
W934,https://wiki.ros.org/adhoc_communication,Wiki,adhoc_communication,"The adhoc_communication package allows to exchange data over an ad-hoc network setup by robots running the corresponding node. The package allows you to exchange data over serveral roscores by wrapping transmitting the data to the destination and publishing the data on a predefined topic at the destination host. Routing is accomplished using the hostname of the robots.






 


 

 
:      srv :        sendQuaternion.srv : 
: ad_hoc_communication.cpp 

: ad_hoc_communication.cpp : publishPacket   The node  allows you to exchange data over an ad-hoc network protocol via dynamic source routing. The package allows you to exchange data over serveral roscores. The node will send the data to the destination robot and publish the message on the destination on a given topic. The routing is done with the hostname of the robots. One-to-Many communication. Every robot has its own multicast group, which will be created when the  node is starting. The name of the group will be """" plus the hostname. If a robots hostname is """", its multicast group is called """". All other robots can join a group with the service . All members of a group can send data within this group. You may obtain the paper from  or search in  . It's  that the node always runs with root rights because the protocol is implement using raw sockets requiring root. 

Mark node to automatically run as root by setting the SUID bit:
  
  
 To send custom messages you just need to serialize a message to a string and then send it with the service . To serialize any type of ROS message you can use this function: Include the service in  Function:  Service name is .  Adapt the function  that the new payload type will be published. To deserialize the message, the function from Step 4 is used.  @InProceedings{Andre2014,
  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},
  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},
  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},
  Year                     = {2014},
  Month                    = dec,
}template <class t>
std::string getSerializedMessage(t message)
{
    /* Description:
     * returns a serialized ROS message as string to send it over network.
     */
    uint32_t serial_size = ros::serialization::serializationLength(message);
    boost::shared_array<uint8_t> buffer(new uint8_t[serial_size]);
    ros::serialization::OStream streamOut(buffer.get(), serial_size);
    ros::serialization::serialize(streamOut, message);

    std::string serialized_map = """";
    serialized_map.append((const char*) buffer.get(), serial_size);

    return serialized_map;
}template <class t>
void desializeObject(unsigned char* serialized_message, uint32_t length, t * obj)
{
    /* Description:
     * de-serialize a ROS message from a buffer.
     */

    try
    {
        ros::serialization::IStream stream(serialized_message, length);
        ros::serialization::deserialize(stream, *obj);
    } catch (ros::serialization::StreamOverrunException e)
    {
        ROS_ERROR(""IN desializeObject: NODE THROWS EXCEPTION: %s "", e.what());
        ROS_ERROR(""PARAMETERS: length=[%u] object type=[%s]"", length, typeid (*obj).name());
    }
}string topic
geometry_msgs/Quaternion Quaternion
string destinationHost
---
uint8 successfullySend#include ""mapExchange/sendQuaternion.h"""
W935,https://wiki.ros.org/tuw_multi_robot_router,Wiki,tuw_multi_robot_router,"This package contains a MultiRobotRouter using Prioritized Planning in Combination with a collision resolution algorithm to find a routing tabel for a large number of robots.
      


 ()   ()  ()  ()  () 
  ()  ()   () 
 ( default: """") 
 ( default: ""true"")  ( default: ""true"")  ( default: ""true"")  ( default: ""10.0"")  ( default: ""10.0"")  ( default: ""false"")  ( default: ""Avoidance"")  ( default: ""use_voronoi_goal"")  ( default: ""standard_router"")  ( default: ""1"") 
Use GitHub to . []
 The Multi Robot Mode is the default mode. The planner listens to  see how many robots are online and available for planning. A list of goals can be send to   Since the results generated for these scenarios are interdependent, the given routes have to be executed in a synchronized fashion. Therefore, the Router publishes a tuw_multi_robot_msgs/Route containing preconditions, when a robot is allowed to enter a segment. Additionally a unsynchronized version via nav_msgs/Path is published for every robot. /robot_infogoalpath_endpoint_optimizationrobot_name/robot_infotuw_multi_robot_msgs/RobotInfo/robot_info. mapnav_msgs/OccupancyGridsegmentstuw_multi_robot_msgs/Graphtuw_multi_robot_msgs/Vertexgoalstuw_multi_robot_msgs/RobotGoalArray/goalgeometry_msgs/PoseStampedplanner_statustuw_multi_robot_msgs/PlannerStatus[robot_name]/pathnav_msgs/Path[robot_name] /robot_info[robot_name]/routetuw_multi_robot_msgs/Routerobot_namestringvoronoi_graphboolpriority_reschedulingboolspeed_reschedulingboolrouter_time_limit_sfloattopic_timeout_sfloatpath_endpoint_optimizationboolcollision_resolverenumgoal_modeenumrouter_typeenumnr_threadsint"
W936,https://wiki.ros.org/rb1_base_description,Wiki,rb1_base_description,The rb1_base_description package
W937,https://wiki.ros.org/octomap_server,Wiki,octomap_server,"octomap_server loads a 3D map (as Octree-based OctoMap) and distributes it to other nodes in a compact binary format. It also allows to incrementally build 3D OctoMaps, and provides map saving in the node octomap_saver.


 and  offer a dynamic_reconfigure interface to change the displayed map resolution on the fly (since version 0.3.8). Note that this will not change the resolution of the underlying , but only of the published marker / collision topics (e.g. for visualization). 

General information about OctoMap is available at  and in the publication  by A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard (Autonomous Robots Journal, 2013). Please cite our paper if you use OctoMap in your research. Use the alufr-ros-pkg  to report bugs or request features. For questions (and FAQ), check . cloud_inoctomap_binaryoctomap_fulloccupied_cells_vis_arrayoctomap_point_cloud_centersoctomap_collision_objectcollision_map_outmap (up to fuerte) / projected_map (since fuerte)projected_mapoctomap_binary~clear_bbx~reset~frame_idstring~resolutionfloat~base_frame_idstring~height_mapbool~color/[r/g/b/a]float~sensor_model/max_rangefloat~sensor_model/[hit|miss]float~sensor_model/[min|max]float~latchbool~filter_groundbool~ground_filter/distancefloat~ground_filter/anglefloat~ground_filter/plane_distancefloat~pointcloud_[min|max]_zfloat~occupancy_[min|max]_zfloatsensor data frame/map (static world frame, changeable with parameter frame_id)@ARTICLE{hornung13auro,
  author = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill
  Stachniss and Wolfram Burgard},
  title = {{OctoMap}: An Efficient Probabilistic {3D} Mapping Framework Based
  on Octrees},
  journal = {Autonomous Robots},
  year = 2013,
  url = {http://octomap.github.com},
  doi = {10.1007/s10514-012-9321-0},
  note = {Software available at \url{http://octomap.github.com}}
}"
W938,https://wiki.ros.org/force_sensor_handler,Wiki,force_sensor_handler,The force_sensor_handler package
W939,https://wiki.ros.org/ur5_moveit_config,Wiki,ur5_moveit_config,"An automatically generated package with all the configuration and launch files for using the ur5 with the MoveIt Motion Planning Framework


This package is part of the  program. It is the ! configuration for the UR5 arm, generated automatically by the  Setup Assistant. Install the package from package management, and run the MoveIt! planning demo: This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR5, see the  package. See also the relevant sections in the  on Github. moveit_simple_controller_manager$ sudo apt-get install ros-$ROS_DISTRO-ur5-moveit-config

$ roslaunch ur5_moveit_config demo.launch"
W940,https://wiki.ros.org/euscollada,Wiki,euscollada,"euscollada

 and  Documentation is available . Use trac to report  or .  "
W941,https://wiki.ros.org/stage,Wiki,stage,"Mobile robot simulator http://rtv.github.com/Stage
For detailed documentation on the Stage .world file format, consult the  ,  or  . stageros.worldworldstagerobot_<i>/robot_0/cmd_velcmd_velrobot_<i>/robot_0/cmd_velodombase_scanbase_pose_ground_truthodombase_pose_ground_truthbase_pose_ground_truth~base_watchdog_timeoutcmd_velbase_linkbase_laserbase_footprintbase_linkodombase_footprintstageros [-g runs headless] <world> [standard ROS args]"
W942,https://wiki.ros.org/std_srvs,Wiki,std_srvs,"Common service definitions.
 contains two service types called  and , which are common service patterns for sending a signal to a ROS node. For the  service, no actual data is exchanged between the service and the client. The  service adds the possibility to check if triggering was successful or not.  For common message definitions, please see the  package. std_srvsEmptyTriggerEmptyTrigger"
W943,https://wiki.ros.org/win_pymercurial,Wiki,win_pymercurial,"

Build script for python (only) mercurial module.

  "
W944,https://wiki.ros.org/canopen_motor_node,Wiki,canopen_motor_node,"canopen_chain_node specialization for handling of canopen_402 motor devices. It facilitates interface abstraction with ros_control.





The objects used in the conversion functions and the drive modes should be mapped to PDOs for best performance. 

 The canopen_motor_node package provides a  interface to [canopen_402]] compliant motors. It is based on  and inherits all its interfaces, so this site just focuses on the additional interfaces. The node includes a  instance that can be used to spawn  compliant controllers. Depending on the motor device different interfaces are support. For each joint a  is registered with the position, velocity and effort of the specific drive. The actual value is determined by the conversion functions. The output from the controller is limited by  and not passed directly to the motor. The limits can be read from URDF or the : . The driver features  based conversion functions. In addition to the predefined  and , the following functions are available: Further two constants are defined for convenience:  and . The conversion functions from ROS the device units can read the commands from the respective , and  variables. The conversion functions from device to ROS supports an extended notion with obj prefixes: E.g.  will read the actual position and  will read  the gear ration nominator. The basic configuration is described in . For the canopen_motor_node to work each node is given a  parameter that defaults to the CANopen node name and is used as joint name in the  interfaces. For each motor node a  can be specified which is used to load a motor plugin with , it defaults to the  implementation. All settings contained in the 'motor_layer' parameter will be passed to the motor layer instance. In summary the following parameters are supported in  section and per node: The canopen_motor_node exposes the ROS interfaces of . In addition the interfaces of  are available after initialization. However, the controller_manager is stopped when shutdown service ist called. The  will read its limits from the URDF and from the ParameterServer. The latter takes precedence but does not support soft limits. The current implementation does not expose a C++ API, but it is planned for the future:  hardware_interface::JointStateHandlehardware_interface::PositionJointInterfacehardware_interface::VelocityJointInterfacehardware_interface::EffortJointInterfacepinanposveleffobj6064obj6091sub1jointmotor_allocatordefaultsinit










"
W945,https://wiki.ros.org/asr_ftc_local_planner,Wiki,asr_ftc_local_planner,"A local planner which based on the ""follow the carrot"" algorithm. Drives accurate along the global plan 

 

 
 




    


    




 () 
 () 
  This package provides an implementation of the """" algorithm to local robot navigation on a flat plane. Given a global plan to follow and a costmap, the local planner produces velocity commands to send to a mobile base. The parameters for this planner are also dynamically reconfigurable. This package implements the asr_nav_core interface for a local planner. For this to work the standard  and  must be adapted (look at kapitel 3.1 Needed Packages). In this pictures you can see the function graph of the slow down factor. The first one depicts braking without a slow down factor -> the robot rotates a long time with minimal rotation velocity. With the slow down factor in the second picture the robot rotates not as long with a minimal rotation velocity. You can also look at this  with a point by point description on how to setup the navigation to use the ftc_local_planner. Manually adapt the two packages  and : You can use the launch files in : ~<name>/local_plan~max_x_veldouble~max_rotation_veldouble~min_rotation_veldouble~acceleration_xdouble~acceleration_zdouble~position_accuracydouble~rotation_accuracydouble~slow_down_factordouble~sim_timedouble~local_planner_frequenceint~join_obstaclebooltc_->setGlobalCostmap(planner_costmap_ros_);void setGlobalCostmap(costmap_2d::Costmap2DROS* global_costmap_ros){
     global_costmap_ros_ = global_costmap_ros;
}costmap_2d::Costmap2DROS* global_costmap_ros_;<node name=""move_base"" pkg=""asr_move_base"" type=""move_base"" respawn=""false"" output=""screen"">

<param name=""controller_frequency"" value=""5.0""/> <param   name=""planner_frequency"" value=""10""/> <param name=""base_local_planner"" value=""ftc_local_planner/FTCPlanner"" />

... yaml files ....

</node>global_costmap/obstacle_layer:
    enabled: truejoin_obstacle: trueroslaunch asr_mild_navigation simulation_manual_rearranged.launchroslaunch asr_mild_navigation navigation.launch"
W946,https://wiki.ros.org/sr_hardware_interface,Wiki,sr_hardware_interface,"

    This package contains the actuator used in the hand model.

  
"
W947,https://wiki.ros.org/pr2_dashboard_aggregator,Wiki,pr2_dashboard_aggregator,"A simple script that aggregates all of the topics that a ""pr2_dashboard"" app might be interested in.

pr2_dashboard_aggregatorpr2.launchpr2_dashboard_aggregatorpower_board/statepower_stateddwrt/accesspointpr2_etherCAT/motors_halteddashboard_agg"
W948,https://wiki.ros.org/summit_x_control,Wiki,summit_x_control,"This package contains the launch files that load the required controller interfaces for simulation in Gazebo.
"
W949,https://wiki.ros.org/message_runtime,Wiki,message_runtime,Package modeling the run-time dependencies for language bindings of messages.
W950,https://wiki.ros.org/turtlebot_android,Wiki,turtlebot_android,"
    This stack contains android applications for turtlebot.
  
Thanks to the great job of Kazuto Murase, we have the the old Android ROS apps updated and improved. See  for more details. On this stack we add some extra apps specific for . If you just want to use them, install the  (Groovy) or  (Hydro) and connect to the turtlebot. It will download the follower for you from the app list. But if you want to make your own apps, or try to compile the apps by yourself, proceed with the . "
W951,https://wiki.ros.org/win_python_build_tools,Wiki,win_python_build_tools,"Collects all the ros python build tools packages together in 
    one installer.
Currently bundles in a single msi installer: 
The rosinstall installation is based around a 32 bit version of python (x86). This must be the case even for win64 as many python modules do not yet have 64 bit versions. This is not a big issue, so don't worry.  If upgrading from win_ros for fuerte, first uninstall vcstools, rosinstall and rospkg. :         - select '' /  Finally, add  and  to your  variable if not already present. :  - catkin-pkg, rospkg, vcstools, wstool, win_ros 
 You shouldn't need to use these directly as they are support modules only.  Options are identical to that for . An example one liner: An example of repeated use:  Note that we don't make use of  anymore.  The win_ros module provides a few convenience scripts, currently ,  and . They are mostly just simple wrappers around cmake and catkin functionality tailored for windows. If you want to know more in detail about the build process, the  are fairly self explanatory. Run git and unix tools from windows command promptC:\Python27\C:\Python27\ScriptsPATHroswswinros_init_workspacewinros_init_buildwinros_make> wstool init src https://raw.github.com/ros-windows/win_ros/groovy-devel/msvc_unstable.rosinstall> mkdir src
> cd src
> wstool init .
> wstool set catkin --git https://github.com/yujinrobot/catkin.git
> wstool set genmsg --git git://github.com/ros/genmsg.git
> wstool set gencpp --git git://github.com/ros/gencpp.git
> wstool set genpy --git git://github.com/ros/genpy.git
> wstool update catkin
> wstool update genmsg
> wstool update gencpp
> wstool update genpy"
W952,https://wiki.ros.org/xbot_driver,Wiki,xbot_driver,"C++ driver library for xbot:
    Pure C++ driver library for xbot. This is for those who do not wish to use ROS on their systems.
"
W953,https://wiki.ros.org/rtabmap,Wiki,rtabmap,"RTAB-Map's standalone library. RTAB-Map is a RGB-D SLAM approach with real-time constraints.

Visit  to know how to use RTAB-Map under ROS. The  package is only for convenient release of the RTAB-Map libraries and standalone application. Visit  to know how to use the standalone application and  that come with this package: If you use  in academic context, please cite the appropriate publication from  $ rtabmap"
W954,https://wiki.ros.org/scan_to_cloud_converter,Wiki,scan_to_cloud_converter,"Converts LaserScan to PointCloud messages.



 The  converts  to   messages. The ouput cloud message has the  attribute set to . Ranges in the scan message which are outside  are represented by  values in the output cloud. Please submit your tickets through  (requires github account) or by emailing the maintainers. is_densefalse(min_range, max range)nanscan_to_cloud_converterscancloud"
W955,https://wiki.ros.org/wpi_jaco_wrapper,Wiki,wpi_jaco_wrapper,"ROS Wrapper for the JACO Arm Developed at WPI











The  package contains nodes to interface ROS with the JACO API.  It includes publishing angular and Cartesian commands to the arm, generating and following trajectories from input such as !, rotational representation conversions between ROS and the JACO API, and forward kinematics. The  package uses a configuration file to set most of the parameters for its nodes.  This allows for support of different types of arms, such as the Jaco, Jaco2, or the Mico.  The configuration files are located within the  directory, which includes a  file,  file, and  file that define default parameter values for the Jaco, Jaco2, and Mico arms respectively.  The parameters include: The  provides three different options for trajectory execution, each of which has its own action server and its own set of advantages and disadvantages.  The specifics of each trajectory follower, how they compare to eachother, and situations where each one may be applicable are detailed below. The  action server provides the simplest trajectory execution method.  This method sends each point to the JACO arm using the Kinova API, which will then execute the trajectory using its PID controller to move the arm from point to point.  This is the most accurate and precise trajectory follower for point-to-point motion, but for complex trajectories with many points, the point-to-point motion causes the arm to stop at each point resulting in a jerky, uneven overally motion.  As such, this trajectory follower is recommended only for simple trajectories that are comprised of a small number of points spaced far apart, such as pre-defined trajectories for basic motions. The  action server works similarly to the point-to-point trajectory follower provided by , with the addition of the Kinova API's trajectory smoothing.  This is accomplished through first converting the trajectory points from joint position points to Cartesian end effector points.  The Kinova API then smooths the trajectory of the end effector.  This has the disadvantage of requiring the full trajectory to avoid the singularity protection zones defined internally, so this trajectory follower should only be used for trajectories generated from planners that are aware of these protection zones, or for pre-defined trajectories. The  action server provides an alternative to the previous two methods (which rely on trajectory execution through the Kinova API) by using its own trajectory controller and trajectory follower based on velocity control.  The trajectory points are used to generate a linear interpolated trajectory with smoothed corners using the  package.  The trajectory is then followed using a velocity controller, defined in the  file, that sends its control inputs as joint velocity commands through the Kinova API.  This controller is the recommended trajectory follower for execution of complex trajectories with many points, such as those generated by !'s motion planners, as it uses joint control and is therefore not subject to the singularity constraints of the smoothed point-to-point trajectory follower. This package is designed to work with the 2- or 3-fingered gripper included with the JACO, JACO2, and MICO.  With it's default behavior, the wrapper node will publish joint states for the fingers, and includes gripper control action servers.  If you are using an alternative end-effector for your arm, setting the kinova_gripper argument in the  file will disable the finger joint state publishing and the gripper action servers.  This package has been updated to work with the new JACO2.  There is one important difference to note when using this package with the JACO2 instead of the JACO or the MICO.  For the JACO and MICO, the joint state names are published as .  The JACO2 publishes joint state names under a different set of names for compatibility with a new arm urdf.  The joint names, in order from the base to the end-effector, are: [, , , , , ] See the metapackage, , for any other limitations of using this package with the JACO2. To install the  package, you can install from source with the following commands: The  package contains the launch file  which will launch all of the nodes required to send trajectories and manipulation commands to the JACO arm.  Note that the launch file will remap some of the topic names for the trajectory execution actions (this is done for easier ! integration), but these can be changed if desired by editing the launch file.  This can be launched with the following command: wpi_jaco_wrapperjaco_arm/arm_controller/trajectory/goaljaco_arm/smooth_arm_controller/trajectory/goaljaco_arm/joint_velocity_controller/trajectory/goaljaco_arm/fingers_controller/gripper/goaljaco_arm/fingers_controller_radian/gripper/goaljaco_arm/home_arm/goaljaco_arm/arm_controller/trajectory/resultjaco_arm/smooth_arm_controller/trajectory/resultjaco_arm/joint_velocity_controller/trajectory/resultjaco_arm/fingers_controller/gripper/resultjaco_arm/fingers_controller_radian/gripper/resultjaco_arm/home_arm/resultjaco_arm/angular_cmdjaco_arm/cartesian_cmdjaco_arm/joint_statesjaco_arm/angular_cmdjaco_arm/cartesian_cmdjaco_arm/arm_homedjaco_arm/get_angular_positionjaco_arm/get_cartesian_positionjaco_arm/software_estopjaco_arm/erase_trajectoriesjaco_arm/kinematics/fkjaco_conversions/quaternion_to_eulerjaco_arm/erase_trajectorieswpi_jaco/arm_namestringwpi_jaco/finger_scalefloatwpi_jaco/finger_error_thresholdfloatwpi_jaco/gripper_openfloatwpi_jaco/gripper_closedfloatwpi_jaco/max_curvaturedoublewpi_jaco/max_speed_fingerfloatwpi_jaco/num_fingersinthome_arm_on_initboolkinova_gripperbooljaco_arm/manipulation/gripper/goaljaco_arm/manipulation/lift/goaljaco_arm/manipulation/gripper/resultjaco_arm/manipulation/pickup/resultjaco_arm/joint_statesjaco_arm/angular_cmdjaco_arm/cartesian_cmdjaco_arm/get_cartesian_positionwpi_jaco/arm_namestringwpi_jaco/gripper_openfloatwpi_jaco/gripper_closedfloatwpi_jaco/num_fingersintkinova_gripperbooljaco_conversions/euler_to_quaternionjaco_conversions/quaternion_to_eulerwpi_jaco/arm_namestringjaco_arm/kinematics/fkwpi_jaco/arm_namestringwpi_jaco_wrapperconfigjaco.yamljaco2.yamlmico.yamljaco_arm_trajectory_nodejaco_arm/arm_controllerjaco_arm/smooth_arm_controllerjaco_arm/arm_controllerjaco_arm/joint_velocity_controllerjaco_arm_trajectory_node.cpparm.launch[arm_name]_joint_[joint_number]jaco_shoulder_pan_jointjaco_shoulder_lift_jointjaco_elbow_jointjaco_wrist_1_jointjaco_wrist_2_jointjaco_wrist_3_jointwpi_jacowpi_jaco_wrapperarm.launch




roslaunch wpi_jaco_wrapper arm.launch"
W956,https://wiki.ros.org/theora_image_transport,Wiki,theora_image_transport,"Theora_image_transport provides a plugin to image_transport for
    transparently sending an image stream encoded with the Theora codec.
 is a plugin package for . It enables any node using  classes to publish and subscribe to image topics compressed over the wire using the Theora video codec.  only works with 8-bit color or grayscale images.  





See  for general instruction on using . theora_image_transportimage_transporttheora_image_transportimage_transport<base topic>/theora<base topic>/theora/optimize_forintQuality~theora/target_bitrate~theora/qualityBitrateQuality<base topic>/theora/target_bitrateintoptimize_forBitrate<base topic>/theora/qualityintoptimize_forQuality<base topic>/theora/keyframe_frequencyint<base topic>/theora~theora/post_processing_levelintogg_saver<image>/theoraimagestream$ rosrun theora_image_transport ogg_saver image:=<base_topic> [output_file.ogv]"
W957,https://wiki.ros.org/rostime,Wiki,rostime,"Time and Duration implementations for C++ libraries, including roscpp. 
Please see . "
W958,https://wiki.ros.org/sr_robot_msgs,Wiki,sr_robot_msgs,"

     sr_robot_msgs contains some messages used in the shadow_robot stack.

  
This package contains messages specific to our packages. They are defined in a separate package to minimize the dependencies between packages. If you develop a node to interact with ours, most of the time, you only need to depend on this package (and not on ). "
W959,https://wiki.ros.org/naoqi_pose,Wiki,naoqi_pose,"
          This package contains nodes for managing Nao's poses.
    

body_posejoint_trajectory~xapstring~poseslistjoint_angles_action/goaljoint_trajectory/goaljoint_stiffness_trajectory/goalbody_pose_naoqi/goaljoint_anglesjoint_stiffnessbody_stiffness/disablebody_stiffness/enablerestwakeup~poll_ratefloat~init_stiffness"
W960,https://wiki.ros.org/kurt_bringup,Wiki,kurt_bringup,"

     kurt_bringup

  "
W961,https://wiki.ros.org/clear_costmap_recovery,Wiki,clear_costmap_recovery,"This package provides a recovery behavior for the navigation stack that attempts to clear space by reverting the costmaps used by the navigation stack to the static map outside of a given area.



 (, default: 3.0) 
The  is a simple recovery behavior that clears out space in the navigation stack's  by reverting to the static map outside of a given radius away from the robot. It adheres to the  interface found in the  package and can be used as a recovery behavior  for the  node. The  object exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: The C++  class adheres to the  interface found in the  package. For detailed documentation, please see . clear_costmap_recovery::ClearCostmapRecoverynav_core::RecoveryBehaviorclear_costmap_recovery::ClearCostmapRecoverynav_core::RecoveryBehaviorclear_costmap_recovery::ClearCostmapRecovery~<name>/reset_distancedoubleclear_costmap_recovery::ClearCostmapRecoverynav_core::RecoveryBehavior












"
W962,https://wiki.ros.org/qb_chain,Wiki,qb_chain,This package contains the ROS interface to control multiple qbrobotics® devices simultaneously.
W963,https://wiki.ros.org/rosmaster,Wiki,rosmaster,"ROS  implementation.

The  package implements the ROS . Most programs will not need to interact with this package directly. The  is run automatically whenever  is run and all communication with the Master happens over XMLRPC APIs. The XMLRPC API of the ROS Master is documented on the  page.  This API is for advanced users only and backwards compatibility is not guaranteed. rosmasterrosmaster"
W964,https://wiki.ros.org/rotors_gazebo,Wiki,rotors_gazebo,The rotors_gazebo package
W965,https://wiki.ros.org/ros_realtime,Wiki,ros_realtime,"The ros_realtime package

  "
W966,https://wiki.ros.org/rigid_body_handler,Wiki,rigid_body_handler,"The rigid_body_handler package


pose_handl = simGetObjectAssociatedWithScript(sim_handle_self)
simExtSetFloatCustomDataFromHeader(pose_handl, sim_ext_ros_bridge_obj_pose_data_main, 0.0)twist_handl = simGetObjectAssociatedWithScript(sim_handle_self)
simExtSetIntCustomDataFromHeader(twist_handl, sim_ext_ros_bridge_set_obj_twist_data_main, 0)"
W967,https://wiki.ros.org/nao_gazebo_plugin,Wiki,nao_gazebo_plugin,The nao_gazebo_plugin packageSee the doc is on the github  
W968,https://wiki.ros.org/ivcon,Wiki,ivcon,"Mesh Conversion Utility Used to generate '.iv' files from '.stl' files. This package has not been changed since 2001 and appears to be very stable. We plan on keeping this package in this revision for mesh conversions. This package is only available as a single source file for download. There are no local modifications to this package.

This is a thirdparty package with . rosrun ivcon ivcon `rospack find gazebo_worlds`/meshes/000.580.67.obj 000.580.67.stlb"
W969,https://wiki.ros.org/eus_assimp,Wiki,eus_assimp,eus_assimp
W970,https://wiki.ros.org/visp_bridge,Wiki,visp_bridge,"Converts between ROS structures and ViSP structures.
 is a small interface between ViSP library and ROS. For instance it converts between the different data types used by each library. To date, the supported functionnality sums up to: 
 is part of  stack.  For usage, see the . sudo apt-get install ros-$ROS_DISTRO-visp-bridgesudo apt-get install ros-$ROS_DISTRO-vision-visp"
W971,https://wiki.ros.org/widowx_arm_controller,Wiki,widowx_arm_controller,"The widowx_arm_controller package
"
W972,https://wiki.ros.org/trac_ik_lib,Wiki,trac_ik_lib,"TRAC-IK is a faster, significantly more reliable drop-in replacement for
    KDL's pseudoinverse Jacobian solver.

    The TRAC-IK library has a very similar API to KDL's IK solver calls,
    except that the user passes a maximum time instead of a maximum number of
    search iterations.  Additionally, TRAC-IK allows for error tolerances to
    be set independently for each Cartesian dimension (x,y,z,roll,pitch.yaw)."
W973,https://wiki.ros.org/schunk_description,Wiki,schunk_description,"This package contains the description (mechanical, kinematic, visual,
  etc.) of different schunk components. The files in this package are parsed and used by
  a variety of other components. Most users will not interact directly
  with this package.






Further information  Further information  Further information  Further information  Further information  "
W974,https://wiki.ros.org/sr_self_test,Wiki,sr_self_test,"

     sr_self_test

  "
W975,https://wiki.ros.org/rosbag_migration_rule,Wiki,rosbag_migration_rule,This empty package allows to export rosbag migration rule files without depending on rosbag.
W976,https://wiki.ros.org/pr2_ft_moveit_config,Wiki,pr2_ft_moveit_config,"Configuration and launch files for using the PR2 robot with force-torque sensors with the MoveIt Motion Planning Framework
 Configuration and launch files for using the PR2 robot with force-torque sensors with the  Motion Planning Framework "
W977,https://wiki.ros.org/sr_cyberglove_config,Wiki,sr_cyberglove_config,"

    sr_cyberglove_config contains configuration files for the cyberglove (calibration, mapping) for the Shadow Robot hand

  "
W978,https://wiki.ros.org/arbotix_msgs,Wiki,arbotix_msgs,Messages and Services definitions for the ArbotiX.
W979,https://wiki.ros.org/vigir_step_control,Wiki,vigir_step_control,"The vigir_step_control package


 
 If you would like to see the system running with a real robot, then you can get in touch with it using the THORMANG3 in simulation. The full install instruction can be found . 
 


The  provides a step queue management system and a state machine to keep track of current step plan execution. It is able to feed the low-level motion layer with the proper number of steps required for seamless execution while continuously merging incoming step plans provided by the . This allows even for continuous walking using our  stack. This package provides following features: For detailed information about the system please take a look at the . The  packages can be downloaded from GitHub: In order to run this example. you will need to install the  stack as well. An install instruction can be found . In the  you have first to select a footstep planner parameter set. Afterwards the direction commands become available which allows to generate simple pattern of footsteps. As soon a footstep plan has been generated the  button becomes active as well. When you click on this button the previously generated footsteps will be executed virtually by the  which fakes an footstep execution. During the fake execution, you will be able to follow the fake execution in the  by the progress bar. The THORMANG3 provides a nice real world example how to migrate the software into an exisiting setup . During the Humanoids@RoboCup Demo 2016 at Leipzig, the step controller was used. If you would like to try it out in simulation by yourself, then just follow the instructions . StepControllerTestPluginroscore
roslaunch vigir_footstep_planning footstep_planner_test.launch
roslaunch vigir_step_control step_controller_test.launch
roslaunch vigir_footstep_planning step_interface_rqt.launch"
W980,https://wiki.ros.org/pr2_2dnav_slam,Wiki,pr2_2dnav_slam,"This application allows the PR2 to navigate autonomously while also building a map of its environment as it drives along.








As with all PR2 applications, you must . Tuck the arms of the PR2 using the . The  stack that is the heart of the pr2_2dnav_slam application can be commanded via , , or through code. roslaunch pr2_2dnav_slam pr2_2dnav.launchroslaunch pr2_navigation_slam rviz_move_base_slam.launchroslaunch pr2_navigation_slam nav_view_move_base_slam.launch"
W981,https://wiki.ros.org/pr2_2dnav_local,Wiki,pr2_2dnav_local,"This application allows the PR2 to navigate autonomously in an odometric frame.








As with all PR2 applications, you must . Tuck the arms of the PR2 using the . The  stack that is the heart of the pr2_2dnav_local application can be commanded via , , or through code. roslaunch pr2_2dnav_local pr2_2dnav.launchroslaunch pr2_navigation_local rviz_move_base_local.launchroslaunch pr2_navigation_local nav_view_move_base_local.launch"
W982,https://wiki.ros.org/ueye_cam,Wiki,ueye_cam,"A ROS nodelet and node that wraps the driver API for UEye cameras
    by IDS Imaging Development Systems GMBH. git clone  --branch fuerte 

 



 







 


This package provides a ROS interface for the . This ROS interface exposes many of the features of the underlying , and is compatible with , , and . This package has been tested with the , on , operating with  cameras. (side-note: it is technically possible to ; see video caption for outline of instructions) This implementation makes use of certain C++11 features (such as std::thread, std::to_string, etc), although the CMakeLists.txt is configured for GCC >= 4.6 (and hence uses the  flag). The IDS camera API allows users to have fine-grain control over the camera on-board processor's clock rate, which determines the range of values for frame rates, exposures, and other camera settings. This can be adjusted at runtime alongside other parameters, via . It is however not recommended to operate the camera at a fast clock rate for extended periods of time, as the onboard processor may get excessively hot. Thus, ideally one should adjust the clock rate to match a target frame rate and exposure setting. You may choose to use the underlying IDS camera API to perform bayer decoding and publish images as 'rgb8' or 'mono8', or alternatively choose to publish images as 'bayer_rggb8' and rely on the standard ROS  package for decoding. Currently, this ROS interface does not expose fine-grain control over the bayer decoding engine from the underlying IDS camera API. A common mistake is to interpret the 'image_width' and 'image_height' ROS parameters as the width and height of the resulting ROS image. Unfortunately, these names were chosen to be consistent with official camera interfaces provided by IDS, and they refer to the width and height of the camera sensor's Area of Interest (AOI). Therefore, values for 'image_width' and 'image_height' that are smaller than your camera's maximum values will result in  (a.k.a. reduced AOI). 1. Install the IDS Software Suite 4.xx for Linux from  2. create catkin workspace . 4. Run  under . Returns raw Bayer-encoded (RGGB encoding) images from the UEye camera, and uses  to convert to RGB images. Also publishes on /camera/image_raw. Same as rgb8.launch, but spawns the nodelet (manager) in gdb on a separate screen.  The ueye_cam wrapper fully supports . You can refer to  for info on calibrating your own UEye cameras. All calibration files are stored by default under:  We have connected multiple cameras in hardware to an Arduino-compatible device (a ), which allows any camera to act as master and any number of other cameras to act as slaves, and achieve synchronization seamlessly with unified hardware add-on required. Please see  for further documentation and instructions. A video demonstration of UEye camera synchronization can be seen . Historically speaking, ueye_cam was based on an earlier ROS package for interfacing with  cameras. Given that the initial work on ueye_cam was done prior to the release of other similar ROS wrappers like  and , the original intention was to keep this code internal so as to avoid contention. Nevertheless, this code has since been released as result of a number of recent requests, with the sole hope that it may benefit the ROS community. Please check out the other packages to see which one will best suite your needs. <camera_name>/<camera_topic><camera_name>/camera_info<~camera_name>/<~camera_topic><~camera_name>/set_camera_info~camera_namestring~camera_topicstring~camera_idint~camera_parameters_filestring~camera_intrinsics_filestring~image_widthint~image_heightint~image_leftint~image_topint~color_modestr~subsamplingint~binningint~sensor_scalingdouble~auto_gainbool~master_gainint~red_gainint~green_gainint~blue_gainint~gain_boostbool~auto_exposurebool~exposuredouble~auto_white_balancebool~white_balance_red_offsetint~white_balance_blue_offsetint~flash_delayint~flash_durationint~ext_trigger_modebool~auto_frame_ratebool~frame_ratedouble~pixel_clockint"
W983,https://wiki.ros.org/node_manager_fkie,Wiki,node_manager_fkie,"Graphical interface, written in PySide, to manage the running and 
     configured ROS nodes on different hosts. For discovering 
     the running ROS master master_discovery node will be used.  
 



This package offers a graphical user interface (GUI) to manage ROS nodes, topics, services, parameters, and launch files in a ROS network. Combined with other tools of the  it is possible to operate a network with multiple masters. Although the node is written in Python we need to run  to generate message and service types: The services of  and  are detected automatically by whose names. 1. Error while launch a node on remote host:  2. The  crashes on load a launch file with error:  ROS NetworkStartROS NetworkStartroscoremaster_discoverystatic hostsRefreshhost description panelROS_MASTER_URInode_manager_fkie/images/robot_iconscreenrqt_consolerqt_graph/use_sim_timeTrueNodesmaster_discoverylaunchshutdownSIGKILLscreenTopicsPublisherSubscriberServicesParameterget parameterLaunch DockrootROS_PACKAGE_PATH*.launchDeleteLaunch EditorDescription DockNode Managercapability_groupcapability_groupcapabilitiesgroup namegroup typeimagedescriptionimagenode_manager_fkiedescriptionnode_manager_fkie\nnamespacerobotshost namerobot typedisplayed nameimagedescriptionNode Managerlist_nodesdefault_cfgCfgsCapability ViewrosmakechangeslinkstatsXML EditorSCREENrxconsolerxgraphrosoutnode_managermaster_discoverymaster_syncdefault_cfgSIGKILLrosoutnode_managermaster_discoverymaster_syncdefault_cfgrosoutnode_managermaster_discoverymaster_syncdefault_cfgSIGKILLSCREENSCREEN'sNodesNodesNodesROS NetworkStartROS NetworkStart:roscoreRefreshhost description panelROS_MASTER_URInode_manager_fkie/imagesscreenrxconsolerxgraphNodesmaster_discoverymaster_discovery/empty_world_serverlaunchshutdownSIGKILLscreenTopicsPublisherSubscriberServicesParameterget parameterLaunch DockrootROS_PACKAGE_PATH*.launchLaunch EditorDescription DockNode Managercapability_groupcapability_groupcapabilitiesgroup namegroup typeimagedescriptionimagenode_manager_fkiedescriptionnode_manager_fkie\nnamespacerobotshost namerobot typedisplayed nameimagedescriptionNode Managerlist_nodesdefault_cfgCfgsCapability ViewrosmakechangeslinkstatsXML EditorSCREENrxconsolerxgraphrosoutnode_managermaster_discoverymaster_syncdefault_cfgSIGKILLrosoutnode_managermaster_discoverymaster_syncdefault_cfgrosoutnode_managermaster_discoverymaster_syncdefault_cfgSIGKILLSCREENSCREEN'sNodesNodesNodescatkin_makechangeslinkstatsNode Manager  <node name=""node_manager"" pkg=""node_manager_fkie"" type=""nm"" >
    <param name=""capability_group"" value=""Management""/>
  </node>  <node name=""node_manager"" pkg=""node_manager_fkie"" type=""nm"" >
    <param name=""capability_group"" value=""Management""/>
    <param name=""1.capability_group"" value=""Node Manager""/>
  </node>   <rosparam param=""capabilities"">
      [
        [""Management"",
         ""core"",
         ""images/crystal_clear_app_network2.png"",
         ""The ``management`` group provides nodes needed to detect and synchronize
          other robots in the ROS network. These are:\n\n- Node Manager\n- Master
          Discovery\n- Master Synchronization""
        ]
      ]

    </rosparam>  <rosparam param=""robots"">
    [
      [""tiderko"",
       ""Workstation"",
       ""tiderko"",
       ""images/veryicon_devcom_workstation.png"",
       ""Workstation\n\n|ws|\n\n.. |ws| image::
        images/veryicon_devcom_workstation.png\n""
      ]
    ]
  </rosparam>rosmake master_discovery_fkie default_cfg_fkierosrun node_manager_fkie nm  <node name=""node_manager"" pkg=""node_manager_fkie"" type=""nm"" >
    <param name=""capability_group"" value=""Management""/>
  </node>  <node name=""node_manager"" pkg=""node_manager_fkie"" type=""nm"" >
    <param name=""capability_group"" value=""Management""/>
    <param name=""1.capability_group"" value=""Node Manager""/>
  </node>   <rosparam param=""capabilities"">
      [
        [""Management"",
         ""core"",
         ""images/crystal_clear_app_network2.png"",
         ""The ``management`` group provides nodes needed to detect and synchronize
          other robots in the ROS network. These are:\n\n- Node Manager\n- Master
          Discovery\n- Master Synchronization""
        ]
      ]

    </rosparam>  <rosparam param=""robots"">
    [
      [""tiderko"",
       ""Workstation"",
       ""tiderko"",
       ""images/veryicon_devcom_workstation.png"",
       ""Workstation\n\n|ws|\n\n.. |ws| image::
        images/veryicon_devcom_workstation.png\n""
      ]
    ]
  </rosparam>rosmake master_discovery_fkie default_cfg_fkierosrun node_manager_fkie nmcatkin_makerosrun node_manager_fkie node_managernode_manager#[ -z ""$PS1"" ] && returnsudo update-alternatives --config x-terminal-emulator'''"
W984,https://wiki.ros.org/ros_emacs_utils,Wiki,ros_emacs_utils,"A metapackage of Emacs utils for ROS.
    Only there for simplifying the release process."
W985,https://wiki.ros.org/interactive_marker_twist_server,Wiki,interactive_marker_twist_server,"Interactive control for generic Twist-based robots using interactive markers


The purpose of this package is to provide a basic generic marker server for teleoperation of twist-based robots, particularly simple differential drive bases. Examples of such platforms include , , and . Package is . Please see the feature tracker for planned enhancements. ~cmd_vel~link_namestrbase_linkbase_footprint~robot_namestr~marker_size_scaledoublecmd_vel~link_namestrbase_linkbase_footprint~robot_namestr~marker_size_scaledouble"
W986,https://wiki.ros.org/roslz4,Wiki,roslz4,"A Python and C++ implementation of the LZ4 streaming format.  Large data
    streams are split into blocks which are compressed using the very fast LZ4
    compression algorithm."
W987,https://wiki.ros.org/navfn,Wiki,navfn,"navfn provides a fast interpolated navigation function that can be used to create plans for
        a mobile base. The planner assumes a circular robot and operates on a costmap to find a
        minimum cost plan from a start point to an end point in a grid. The navigation function is
        computed with Dijkstra's algorithm, but support for an A* heuristic may also be added in the
        near future. navfn also provides a ROS wrapper for the navfn planner that adheres to the
        nav_core::BaseGlobalPlanner interface specified in .





 adheres to the  interface found in the  package. For detailed documentation, please see . 



This package provides an implementation of a fast, interpolated navigation function used to create plans for a mobile base through the  class. It also provides a  for this class via the  object that adheres to the  interface specified in the  package. The  object is also used as a global planner plugin for the  node. The  object is a  for a  object that exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: The  object provides an implementation of the navigation function described above. Feel free to use it, but beware that we make no guarantees about the stability of its public API. navfn::NavFnnavfn::NavfnROSnav_core::BaseGlobalPlannernavfn::NavfnROSnavfn::NavfnROSnavfn::NavFnnav_core::BaseGlobalPlannernavfn::NavfnROS~<name>/plannavfn~<name>/allow_unknownbooltrue~<name>/planner_window_xdouble~<name>/planner_window_ydouble~<name>/default_tolerancedoubledefault_tolerance~<name>/visualize_potentialboolfalsenavfn::NavfnROSnav_core::BaseGlobalPlannernavfn::NavFnnavfn::NavFn










"
W988,https://wiki.ros.org/timestamp_tools,Wiki,timestamp_tools,"This package is currently for internal use only. Its API may change
    without warning in the future.  This package is deprecated.
timestamp_toolsTriggerMatchertimestamp_toolsTriggerMatchertimestamp_toolsTriggerMatcher"
W989,https://wiki.ros.org/turtlebot_rviz_launchers,Wiki,turtlebot_rviz_launchers,Launchers for visualizing TurtleBot
W990,https://wiki.ros.org/pr2_navigation_slam,Wiki,pr2_navigation_slam,"This package holds launch files for running the



This package contains configuration files for the  and  nodes meant to be run in an application that requires SLAM-based global navigation. This package also includes launch files that bring up  and  with global navigation specific configuration options. rviz/rviz_move_base_slam.launchnav_view/nav_view_move_base_slam.launchmove_base.xmlslam_gmapping.xmlconfig/base_local_planner_params.yamlconfig/global_costmap_params.yamlmove_base.xmlconfig/local_costmap_params.yamlmove_base.xmlconfig/move_base_params.yaml"
W991,https://wiki.ros.org/rtt_nav_msgs,Wiki,rtt_nav_msgs,"Provides an rtt typekit for ROS nav_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/nav_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W992,https://wiki.ros.org/summit_x_robot_control,Wiki,summit_x_robot_control,"Control the robot joints in all kinematic configurations, publishes odom topic and, 
	  if configured, also tf odom to base_link. Usually takes as input joystick commands 
	  and generates as outputs references for the gazebo controllers defined in summit_xl_control.
Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "
W993,https://wiki.ros.org/summit_x_gazebo,Wiki,summit_x_gazebo,"Launch files and world files to start the models in gazebo
"
W994,https://wiki.ros.org/minas,Wiki,minas,"Meta package for minas for PANASONIC MINAS EtherCAT Motor Driver Control System



 package wiki page shows how to run robots virtually. 
 The minas pacakges contains basic control tools for MINAS-A5B EtherCAT communication driver for indusdtrial robots Tra1 and  its simulator with the ! Motion Planning Framework. On your  machine where   is installed: UbuntuROSminasminastra1$ sudo apt-get install ros-indigo-minas"
W995,https://wiki.ros.org/multi_level_map_utils,Wiki,multi_level_map_utils,multi_level_map_utils
W996,https://wiki.ros.org/sbpl,Wiki,sbpl,"Search-based planning library (SBPL). 





The API documentation for this package can be found . A good resource for technical information on the planners in the SBPL package is Maxim Likhachev's presentation (,) at the ROS Cotesys School at TUM, Germany in November 2010. "
W997,https://wiki.ros.org/teleop_keyboard_omni3,Wiki,teleop_keyboard_omni3,"Generic keyboard teleop for 3 wheeled omnidirectional robots.


 Motion Analysis of 3 wheeled omnidirectional robot:  cd ~/catkin_ws/src
git clone https://github.com/YugAjmera/teleop_keyboard_omni3
cd ~/catkin_ws
catkin_make
source ~/catkin_ws/devel/setup.bash
source ~/.bashrcrosrun teleop_keyboard_omni3 teleop_keyboard_omni3.pyReading from the keyboard !
---------------------------
Moving around:
   u    i    o
   j    k    l
   m    ,    .

For Holonomic mode (strafing), hold down the shift key:
---------------------------
   U    I    O
   J    K    L
   M    <    >


anything else : stop

q/z : increase/decrease max speeds by 10%

CTRL-C to quit"
W998,https://wiki.ros.org/libfreenect,Wiki,libfreenect,"Open source libraries that will enable the Kinect to be used with Windows, Linux, and Mac.
 is a library for accessing the Microsoft Kinect USB camera. This package downloads revision  from the . 
The tarball is currently hosted . Bugs should be reported on the relevant github issues page:  If you would like to submit a patch for the ROS wrapper, please open an issue here:  "
W999,https://wiki.ros.org/telegram_ros,Wiki,telegram_ros,The telegram_ros package
W1000,https://wiki.ros.org/pr2_description,Wiki,pr2_description,"This package contains the description (mechanical, kinematic, visual,
  etc.) of the PR2 robot.  The files in this package are parsed and used by
  a variety of other components.  Most users will not interact directly
  with this package.



 This package contains the description of the PR2 robot.  It supercedes the older  package which was written for the alpha hardware. Some notable changes from : To see the PR2 URDF graphically, you can A snapshot (r46956) is attached  for reference. In general, PR2 URDF contains a tree structured set of links and joints, with  as the root link of the tree. urdf/robots/urdf/gazebo/meshes/.stl.daeframe_idbase_laserbase_laser_linkframe_id{narrow,wide}_stereo_{l,r}_stereo_camera_optical_frameplug_holderbase_footprintrosrun xacro xacro.py `rospack find pr2_description`/robots/pr2.urdf.xacro > pr2.urdf
rosrun urdf urdf_to_graphiz pr2.urdf
evince pr2.pdfexport KINECT1=trueexport KINECT2=true"
W1001,https://wiki.ros.org/usv_gazebo_plugins,Wiki,usv_gazebo_plugins,"Gazebo plugins for simulating Unmanned Surface Vehicles
    Originaly copied from https://github.com/bsb808/usv_gazebo_plugins





The included  file sets all of the parameters for the plugin, intended as a example for customization. waterLeveldoublewaterDensitydoublexDotUdoublexDotVdoublenDotRdoublexUdoublexUUdoubleyVdoubleyVVdoublezWdoublekPdoublemQdoublenRdoublenRRdoublemaxCmddoublemaxForceFwddoublemaxForceRevdoubleboatAreadoubleboatWidthdoubleboatLengthdoublethrustOffsetZdoublemetacentricLengthdoublemetcentricWidthdoubleurdf/usv_gazebo_dynamics_plugin.xacro"
W1002,https://wiki.ros.org/libnabo,Wiki,libnabo,"

     Fetches libnabo through git submodule and makes it available to ROS

  "
W1003,https://wiki.ros.org/kvh_geo_fog_3d_driver,Wiki,kvh_geo_fog_3d_driver,"A ROS driver for the KVH Geo Fog 3D INS family of systems.
   




 latitude/longitude is measured in degrees (see message definition). This is different than the KVH messages, which report latitude/longitude in radians. 





 
      
 








 
 Link:  Link:  Developer Note: Notice that at the end we must run kvhDriver.(packet_id, bool)`. The driver has been implemented so that you must explicitly state when you have read its data. If you wish to keep track of when new data appears, the driver must be used this way. In any case, the driver will always store the most recent packet of a specific type that it receives and will set the update status to true. 1. Add packet information to each set/map currently in . 2. Add packet-specific decoding function to  function in  3. Add packet to initialization mapping in the  function of  4. Add to the  that you are sending upon creation of the driver. ~<node_name>/kvh_system_state~<node_name>/kvh_satellites~<node_name>/kvh_detailed_satellites~<node_name>/kvh_local_magnetics~<node_name>/kvh_utm_position~<node_name>/kvh_ecef_pos~<node_name>/kvh_north_seeking_status~<node_name>/kvh_odometer_state~<node_name>/kvh_raw_sensors~<node_name>/kvh_raw_gnss~<node_name>/imu/data_raw_frd~<node_name>/imu/data_raw_flu~<node_name>/imu/data_ned~<node_name>/imu/data_enu~<node_name>/imu/rpy_ned~<node_name>/imu/rpy_ned_deg~<node_name>/imu/rpy_enu~<node_name>/imu/rpy_enu_deg~<node_name>/gps/fix~<node_name>/gps/raw_fix~<node_name>/gps/mag~<node_name>/gps/utm_ned~<node_name>/gps/utm_enu~<node_name>/odom/wheel_encoder~<node_name>imu/raw_sensor_frd~<node_name>/odom/raw_sensor_flu~<node_name>/port~<node_name>/baud~<node_name>/debug~<node_name>/filterVehicleType~<node_name>/atmosphericAltitudeEnabled~<node_name>/velocityHeadingEnabled~<node_name>/reversingDetectionEnabled~<node_name>/motionAnalysisEnabled~<node_name>/odomPulseToMeters~<node_name>/port$ sudo chmod a+rw <port>  # E.g., port may be /dev/ttyUSB0$ git clone <url> $ cd kvh_geo_fog_3d $ catkin build kvh_geo_fog_3d $ source .../devel/setup.bash # May be required after building$ rosmsg list | grep kvh $ roslaunch kvh_geo_fog_3d_driver kvh_geo_fog_3d_node.launch port:=<port> baud:=<baud> # E.g., port=""/dev/ttyUSB0"" baud=""921600"" $ roslaunch kvh_geo_fog_3d_driver determine_baud.launch starting_baud:=<baud_rate> src/kvh_driver/kvh_global_vars.cppsrc/kvh_driver/decode_packets.cppsrc/kvh_driver/packet_storage.cppKvhPacketRequest"
W1004,https://wiki.ros.org/rosjava_messages,Wiki,rosjava_messages,"Message generation for rosjava.
Please see  for details about how this package generates code and artifacts for the officially released message package set. "
W1005,https://wiki.ros.org/rotors_description,Wiki,rotors_description,The rotors_description package provides URDF models of the AscTec multicopters.
W1006,https://wiki.ros.org/tuw_multi_robot_local_behavior_controller,Wiki,tuw_multi_robot_local_behavior_controller,"This package presents a node, which converts synchronized robot routes to path segments published sequentially to maintain synchronization

  ()  () 
 ()  () 
 ( default: ""[robot_0]"")  ( default: """")  ( default: ""[]"")  ( default: ""0.3"")  ( default: ""path"")  ( default: ""route"") 
Use GitHub to . []
  [robot_name]/routetuw_multi_robot_msgs/Routerobot_infotuw_multi_robot_msgs/RobotInfo[robot_name]/pathnav_msgs/Pathrobot_infotuw_multi_robot::RobotInfo~robot_namesstring[]~robot_names_strstring~robot_radiusfloat[]~robot_default_radiusfloat~path_topicstring~route_topicstring"
W1007,https://wiki.ros.org/visp,Wiki,visp,"ViSP standing for Visual Servoing Platform is a modular cross platform library that allows prototyping and developing applications using visual tracking and visual servoing technics at the heart of the researches done by Inria Lagadic team. ViSP is able to compute control laws that can be applied to robotic systems. It provides a set of visual features that can be tracked using real time image processing or computer vision algorithms. ViSP provides also simulation capabilities. ViSP can be useful in robotics, computer vision, augmented reality and computer animation.


This package provides packaging of the ViSP library for ROS. For information about the ViSP library, please see the ViSP main page at . The next video shows what can be done with  package that uses  package. The next video shows what can be done with  package that uses also  package. This other video shows how using  package that depends on  it may possible to control a Pioneer P3-DX mobile robot using visual servoing. ViSP is a library that is maintained by Inria Lagadic research team . 

  $ sudo apt-get install ros-$ROS_DISTRO-visp"
W1008,https://wiki.ros.org/ethercat_manager,Wiki,ethercat_manager,"ROS-Industrial support stack for facilitating communication with
EtherCAT networks. The code is mainly copied from https://github.com/ros-industrial/robotiq/blob/jade-devel/robotiq_ethercat/src/ethercat_manager.cpp"
W1009,https://wiki.ros.org/access_point_control,Wiki,access_point_control,"
    Defines an API for access point control based on 
    dynamic_reconfigure. Other packages must
    implement the API for various access-point models: 
    for example: hostapd_access_point for hostapd-based control or
    linksys_access_point for Linksys router web interface.
  

The following dynamic_reconfigure API must be implemented by packages specific to access point model such as , , . ~enabledboolTrueFalse~ssidstrtest~wmmbool~modestrbabg~freqdoublea~ieee80211nbool~encryption_modestringopenwepwpawpa2wpa_wpa2~encryption_passstring~txpower_autobool~txpowerinttxpower_autoFalse~bitrateint1000000b24000000ga~statusstringOKFAILerrmsg~errmsgstring"
W1010,https://wiki.ros.org/hironx_moveit_config,Wiki,hironx_moveit_config,An automatically generated package with all the configuration and launch files for using the HiroNX with the MoveIt Motion Planning Framework
W1011,https://wiki.ros.org/xbot_navi,Wiki,xbot_navi,"The xbot_navi package




The package has many functions such as mapping, positioning, navigation, path planning, and integrated services demo including navigation, face recognition, and voice conversations. The package relies on the xbot-u robot platform and other packages such as ,  and . See the , ,  and  package for more details to configure the mapping and navigation parameters. To make a map from xbot-u robot with  package: Or you can choose to use google open source  to make a map: Navigate via  and : Or use  to navigate: param/kp.json and param/greet.jsonroslaunch xbot_navi build_map.launchroslaunch xbot_navi rviz_build_map.launchroslaunch xbot_navi build_map_carto.launchroslaunch xbot_navi demo.launchroslaunch xbot_navi navi_carto.launchroslaunch xbot_navi demo.launch"
W1012,https://wiki.ros.org/uos_gazebo_worlds,Wiki,uos_gazebo_worlds,Gazebo world and model files for UOS.
W1013,https://wiki.ros.org/wge100_driver,Wiki,wge100_driver,"This stack contains the ROS driver and firmware for the WGE100 camera used on the PR2 robot. 


  ROS driver and firmware for the WGE100 Ethernet camera. See  for usage and tutorials. Prior to Fuerte, these packages resided in . A . WGE100 cameras are not available separately. "
W1014,https://wiki.ros.org/rtshell,Wiki,rtshell,Shell commands for managing RT-Middleware running on OpenRTM-aist.
W1015,https://wiki.ros.org/minas_control,Wiki,minas_control,This package contains ros_control based robot controller for PANASONIC MINAS EtherCAT Motor Driver Control System
W1016,https://wiki.ros.org/pr2_props_app,Wiki,pr2_props_app,"
    Application files for running PR2 props
  
"
W1017,https://wiki.ros.org/rospy,Wiki,rospy,"rospy is a pure Python client library for ROS. The rospy client
    API enables Python programmers to quickly interface with ROS , , and . The
    design of rospy favors implementation speed (i.e. developer
    time) over runtime performance so that algorithms can be quickly
    prototyped and tested within ROS. It is also ideal for
    non-critical-path code, such as configuration and initialization
    code. Many of the ROS tools are written in rospy to take
    advantage of the type introspection capabilities.

    Many of the ROS tools, such
    as 
    and , are
    built on top of rospy.




Please refer to the  package and to the  page. Please see the  for an introduction to the rospy API and its usage. For a more detailed reference, please consult the . Bug reports and feature requests can be filled and views in the . "
W1018,https://wiki.ros.org/moveit_visual_tools,Wiki,moveit_visual_tools,"Helper functions for displaying and debugging MoveIt! data in Rviz via published markers
See  for full documentation. "
W1019,https://wiki.ros.org/katana_msgs,Wiki,katana_msgs,This package contains messages specific to the Neuronics Katana arm.
W1020,https://wiki.ros.org/staubli_rx160_moveit_config,Wiki,staubli_rx160_moveit_config,"
      MoveIt package for the Staubli RX160.
    
      An automatically generated package with all the configuration and launch
      files for using the Staubli RX160 with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  metapackage page. "
W1021,https://wiki.ros.org/turtlebot_create,Wiki,turtlebot_create,"Catkin metapackage for the turtlebot_create stack
Please refer main  page "
W1022,https://wiki.ros.org/nextage_gazebo,Wiki,nextage_gazebo,Gazebo simulation for NEXTAGE Open
W1023,https://wiki.ros.org/svenzva_utils,Wiki,svenzva_utils,Svenzva Arm utilities that streamline arm-code interaction
W1024,https://wiki.ros.org/kvh_geo_fog_3d_rviz,Wiki,kvh_geo_fog_3d_rviz,The KVH GEO FOG 3D rviz plugin packageUtilizes the  message published by the . /diagnostics
W1025,https://wiki.ros.org/mongodb_store,Wiki,mongodb_store,"A package to support MongoDB-based storage and analysis for data from a ROS system, eg. saved messages, configurations etc













  Use GitHub to . []
 This package contains nodes and libraries for storing and retrieving ROS-related data in a  database using C++ and Python. It is intended to support data persistence and inspection, including in running systems (i.e. introspection). The main functions are the storage and retrieval of single message (this is the ); the rosbag-like logging of topics to the db (via ) and their playback (mongodb_play); and the storage and recreation of parameters. First set the host and port you want the datacentre to run on. We do this via  so that other nodes know where to find the server. If these are not set the server uses a generated port number and  then sets the above parameters to its chosen values. This runs the  server and also provides some utility functions around this. By default, the mongod database will be stored in . This can be overridden by setting the private parameter ~database_path for the node. If it is the first time that the database is used, be sure to first create the database path (e.g. ). To create "" record""-like logging of topics to the  use . This has been updated to store logged data in a format that can be easily recreated into ROS messages for replay. The  node reads logged messages from the store and replays them on their original topics. This provides a similar function to "" play"". Currently this node always creates its own  in order to play back the messages at the time they were originally recorded. will play back messages previously from the   and  topics which were previously stored in the default database ().  and  respect latched topics. 1. .  These should be ""working defaults"" - so all essential parameters at least have a default value. For example, if a robot application requires some calibration data then default values should be provided. Default parameters can be shared among sites and stored inside a shared ROS package. When the config manager is started, all .yaml files stored in a 'defaults' folder will be examined. Any new default parameters will automatically be inserted into the ""defaults"" collection within the configs database. The defaults folder should be supplied as a private parameter:  either set to a system path or in the form . 2. . These parameters override the same named  global default parameters, allowing site-specific parameter setting. They are stored within the database inside the ""local"" collection. At start up, the config manager places all parameters onto the ros parameter server to allow interoperability with existing software. Parameters can also be queried using the , or by directly connection to and querying the mongo database server. Likewise, local parameter overrides can be set using the  service or by directly editing the ""local"" collection in the configs database. The message store node provides services to allow clients to add, update and remove ROS messages in the mongo store via the  object in both Python and C++. This is best demonstrated by examples. With the mongodb server running, run the message store: If the constructor argument to the message store node  is set to true, replication of the message store parts of the store is done manually to allow different content to appear on different hosts. A list of hosts and ports where replications should be made can be set via the  ros parameter: If  is set (regardless of ), queries are performed on the main first, and if nothing found, the replicants are tried. You can test if this works by adding some things to the message store, deleting them from the master using  (not the message store as the deletes are replicated), then running queries. The  action and the corresponding action server: (which is included in ) allows you to bulk copy or move entries from message store collections to the mongod instances defined under . The client accepts a list of collection names and uses the  field of the message store entries to replicate or move all entries that were inserted before a particular time. If no time is provided then the default is 24 hours ago. There is an example client that does this for a list of collections specified on the command line. This *moves* entries inserted 24 hours ago or earlier. ***NOTE THAT this all makes  operations a bit uncertain, so please do not use this type of replication on collections you plan to use update on.*** rosparamlocalhostmongod/opt/ros/mongodb_storemkdir  -p /opt/strands/mongodb_storemongodb_storemongodb_play/map/tf/scanroslogmongodb_logmongodb_play~defaults_pathpkg://ros_package_name/inside/package/config_manager/get_param service/config_manager/set_paramMessageStoreProxyreplicate_on_writemongodb_store_extrasmongodb_store_extrasreplicate_on_writeMoveEntriesdatacentre.launchmongodb_store_extrasmeta[""inserted_at""]updateHOSTNAME=yourhost roslaunch mongodb_store mongodb_store.launch db_path:=/path/to/db db_port:=62345rosparam set mongodb_port 62345
rosparam set mongodb_host bobrosrun mongodb_store mongodb_server.pyUsage: mongodb_play.py [options] [TOPICs...]

Options:
  -h, --help           show this help message and exit
  --mongodb-name=NAME  Name of DB in which to store valuesrosrun mongodb_store mongodb_play.py  /map /tf /scanrosrun mongodb_store config_manager.py _defaults_path:=pkg://my_package/defaultsrosparam listrosparam get /my/parameterrosservice call /config_manager/get_param ""param_name: '/my/parameter'""rosservice call /config_manager/set_param ""param: '{\""path\"":\""/chris\"",\""value\"":43}'""rosservice call /config_manager/save_param name_of_the_parameter_to_be_savedrosrun mongodb_store message_store_node.py































































































































































mongodb_store_extras: [[""localhost"", 62344], [""localhost"", 62333]]rosrun mongodb_store mongodb_server.py _master:=false _database_path:=/opt/strands/strands_mongodb_62344 _host:=localhost _port:=62344
rosrun mongodb_store mongodb_server.py _master:=false _database_path:=/opt/strands/strands_mongodb_62333 _host:=localhost _port:=62333rosrun mongodb_store replicator_node.pyrosrun mongodb_store replicator_client.py message_store robblog scheduling_problems"
W1026,https://wiki.ros.org/nao_robot,Wiki,nao_robot,"The nao_robot metapackage contains some useful nodes to integrate the Nao humanoid robot into ROS.
    Check out the  for more functionality.
    The  contains some more general packages for humanoid/biped robots.

See  for installation instructions and the packages in this stack for more documentation, in particular  to start the nodes for Nao. For issues and questions, please use  or the  Use the  to report bugs or request features.  "
W1027,https://wiki.ros.org/roslaunch,Wiki,roslaunch,"roslaunch is a tool for easily launching multiple ROS  locally and remotely
    via SSH, as well as setting parameters on the . It includes options to automatically respawn processes
    that have already died. roslaunch takes in one or more XML
    configuration files (with the  extension) that
    specify the parameters to set and nodes to launch, as well as the
    machines that they should be run on.
 uses XML files that describe the nodes that should be run, parameters that should be set, and other attributes of launching a collection of ROS . For a specification of this XML format, please see:  was designed to fit the ROS architecture of complexity via composition. Understanding 's architecture will give you better insight in how to construct your  files and better debug remote vs. local launches. 
 is a specialization of the  tool for bringing up the ""core"" ROS system.  A roslaunch will automatically start roscore if it detects that it is not already running (unless the --wait argument is supplied).  For more information, please see the  documentation. Note: due to a , roslaunch should not be used to guarantee a singleton instance of roscore. 



 these *.launch file tests can also be initiated using console tool called  OR . 
 

The   contains the  tools, which reads the . It also contains a variety of other support tools to help you use these files.  Many ROS packages come with ""launch files"", which you can run with: To find out more about the main  tool and other command-line tools, please consult: The launch file syntax itself is , and every effort will be made to provide backwards compatibility with new features. The code API of  is  and should not be used directly. In order to support the new features that are being planned, it may be necessary to make major, incompatible changes to the programmatic API. There are many new features being planned for . These include new features within the launch file syntax, GUI tools for interacting with launch files more effectively, network API, better coordination between separate launch files, and more. Ref.  The  CMake macro can be used to check launch files for common errors such as missing arguments, dependencies, packages, or nodes. The following is how you would check all  files in a package's """" directory: NOTE:  takes only one directory at a time. The check runs during . So something like following is cleaner. Since you need to find  in  as above, you better explicitly add a dependency in your  as following: Pass an optional argument """" to  as the following example, if your package defines dependency for the tests (e.g. ). This avoids issues that happen during tests such as . A few graphical tools are available to support  functionalities of ROS. .launch.launch.launch.launch.launch.launch.launch.launch.launch.launchroslaunchroslaunchroslaunchroslaunchroslaunchroslaunch.launchroslaunchroslaunchroslaunchroslaunch_add_file_check*.launchlaunchroslaunch_add_file_checkroslaunchfind_packagepackage.xmlUSE_TEST_DEPENDENCIESroslaunch_add_file_checktest_dependlaunch$ roslaunch package_name file.launchfind_package(catkin REQUIRED COMPONENTS roslaunch)
roslaunch_add_file_check(launch)if (CATKIN_ENABLE_TESTING)
  find_package(roslaunch REQUIRED)
  roslaunch_add_file_check(launch)
endif()<build_depend>roslaunch</build_depend>find_package(catkin REQUIRED COMPONENTS roslaunch)
roslaunch_add_file_check(launch USE_TEST_DEPENDENCIES)"
W1028,https://wiki.ros.org/rotors_joy_interface,Wiki,rotors_joy_interface,The rotors_joy_interface package to control MAVs with a joystick
W1029,https://wiki.ros.org/fingertip_pressure,Wiki,fingertip_pressure,"This package provides access to the PR2 fingertip pressure sensors. This information includes:

: All nodes assume that  is either  or . 
 

 is a standalone demo of the package's capabilities. It runs all the package's nodes, and rviz (to view the visualization markers). This should demonstrate all the packages capabilities. Each pr2 gripper is equipped with two pressure-sensitive fingertips. Each pressure comprises 22 pressure sensing elements: one on the back, 6 around the edges and a 3x5 array on the front.  provides nodes to facilitate the visualization and interpretation of the fingertip pressure sensor data. Example of  GUI: Example: and in a separate shell: fingertip_pressure<gripper_motor_name>r_gripper_motorl_gripper_motor/pressure/<gripper_motor_name>_infoboard<board>_infoview_fingertip_pressure/pressure/<gripper_motor_name>/pressure/<gripper_motor_name>_info""/visualization_marker""sphere_viz/pressure/<gripper_motor_name>/pressure/<gripper_motor_name>_info""/visualization_marker""/pressure/<gripper_motor_name>launch/fingertip_demo.launch$ roslaunch launch/fingertip_demo.launch$ roscd pr2_gazebo
$ roslaunch pr2_empty.launch"
W1030,https://wiki.ros.org/rtsprofile,Wiki,rtsprofile,"Library to read, manipulate and write RT system profiles using the RTSProfile XML schema."
W1031,https://wiki.ros.org/rosserial_client,Wiki,rosserial_client,"Generalized client side source for rosserial. contains the generic client-side  implementation. It is designed for microcontrollers and it can run on any processor for which you have an ANSI C++ compiler and a serial port connection to a computer running ROS.   The serialization and deserialization code generated by the  module assumes that the client is a little-endian machine. If you have a bi-endian target such as ARM or MIPS, be sure that it has been placed in little-endian mode in order to use it with rosserial. For details on using rosserial_client with the Arduino, please see . For other platforms, please see the . make_libraries"
W1032,https://wiki.ros.org/uos_rotunit_teleop,Wiki,uos_rotunit_teleop,sends command to handle the rotunit speed and to start the snapshotter
W1033,https://wiki.ros.org/ur_driver,Wiki,ur_driver,"Driver for the UR5/10 arm based on the Polyscope control scheme.
3000250001pingjoint_states~max_velocitydouble~prefixstrJointState~prevent_programmingboolean~robot_descriptionstr300023000350001pingio_statesjoint_stateswrench~max_velocitydouble~min_payloaddoubleSetPayload~max_payloaddoubleSetPayload~prefixstrJointState~prevent_programmingboolean~robot_descriptionstr"
W1034,https://wiki.ros.org/sr_edc_ethercat_drivers,Wiki,sr_edc_ethercat_drivers,"

    A package implementing a ROS interface for the etherCAT Shadow Robot Dextrous Hand.

  

This package contains the driver for the etherCAT Hand. It uses the  which is running the main loop at 1kHz for sending and receiving packets to/from the etherCAT. We also load the  which will be used to load the controllers on demand. The driver sends different demands to the etherCAT hand and receives and formats correctly the incoming packets. The incoming data is stored in a vector of actuators (defined in the  package). Those actuators are then passed to the controllers for the 1kHz control loop. The controllers are publishing the relevant data (position / effort / velocity) at 100Hz on the  topic, and the hardware diagnostics on the  topic at 1Hz. The protocol used to interpret or build the etherCAT packets can be found in .  Please refer to the  to learn how to use the driver. You can look at the current status of the robot using the : $ rosrun robot_monitor robot_monitor"
W1035,https://wiki.ros.org/rsv_balance_description,Wiki,rsv_balance_description,"RoboSavvy's balancing platform URDF description and meshes.'s self-balance platform URDF model and meshes. 
  The platform macro is provided by the file:  and can be included in your URDF model as such: As an example you can look at , which puts on top a rod and a dummy weight of 5kg. <robot name=""you_awesome_robot"" xmlns:xacro=""http://www.ros.org/wiki/xacro"">
  <xacro:include filename=""$(find rsv_balance_description)/urdf/balance.urdf.xacro"" />
  <xacro:balance/> 

  ..
  .. <your_awesome_robot_here>
  ..

</robot>"
W1036,https://wiki.ros.org/simple_grasping,Wiki,simple_grasping,Basic grasping applications and demos.
W1037,https://wiki.ros.org/dataspeed_ulc,Wiki,dataspeed_ulc,CAN interface to the Universal Lat/Lon Controller (ULC) firmware
W1038,https://wiki.ros.org/tf2_sensor_msgs,Wiki,tf2_sensor_msgs,"Small lib to transform sensor_msgs with tf. Most notably, PointCloud2


 "
W1039,https://wiki.ros.org/win_bzip2,Wiki,win_bzip2,
W1040,https://wiki.ros.org/turtlebot_arm_bringup,Wiki,turtlebot_arm_bringup,"turtlebot_arm_bringup provides launch files for starting the drivers for the TurtleBot arm.
  
  launch/arm.launch  launch/fake-arm.launch  launch/simple_arm_server.launch  launch/constraint_aware_simple_arm_server.launch  config/arm.yaml  config/planning_environment.yaml "
W1041,https://wiki.ros.org/tango_ros_streamer,Wiki,tango_ros_streamer,"This package wraps Tango Ros Streamer application





Use GitHub to . []
 Note that all image topics are published via . Therefore, for each image topic, a compressed version of the image is available together with its compression parameters. Also note that the service  seems to not work properly on Tango Tablet Development Kit. android/imutango/camera/color_1/camera_infotango/camera/color_1/image_rawtango/camera/color_1/image_recttango/camera/fisheye_1/camera_infotango/camera/fisheye_1/image_rawtango/camera/fisheye_1/image_recttango/laser_scantango/point_cloudtango/reconstruction/mesh_markertango/reconstruction/occupancy_gridtango/static_occupancy_gridtango/load_occupancy_gridtango/statustango/transform/area_description_T_start_of_servicetango/transform/start_of_service_T_devicetango/connecttango/get_map_nametango/get_map_uuidstango/load_occupancy_gridtango/occupancy_grid_directory/tango/static_occupancy_grid/tango/localization_map_uuidtango/save_map/tango/create_new_maptango/occupancy_grid_directory/tango/localization_map_uuidtango/set_parameterstango/area_description_frame_idstringtango/create_new_mapbooltango/localization_modetango/enable_3dr_meshboolenable_color_cameraenable_depthtango/enable_3dr_occupancy_gridboolenable_color_cameraenable_depthtango/enable_color_camerabooltango/enable_depthbooltango/laser_scan_max_heightdoubletango/laser_scan_min_heightdoubletango/localization_map_uuidstringtango/localization_modetango/localization_modeinttango/occupancy_grid_directorystringtango/publish_pose_on_tfbooltango/reconstruction/floorplan_max_errordoubletango/reconstruction/max_voxel_weightinttango/reconstruction/min_num_verticesinttango/reconstruction/occupancy_grid_thresholdinttango/reconstruction/resolution_3ddoubletango/reconstruction/update_methodinttango/reconstruction/use_space_clearingbooltango/start_of_service_frame_idstringtango/use_tf_staticbooltango/android_api_levelintarea_descriptionstart_of_servicestart_of_servicedevicedevicecamera_depthcamera_depthlaserdevicecamera_fisheyedevicecamera_colordeviceimutango/connect"
W1042,https://wiki.ros.org/surface_perception,Wiki,surface_perception,"Simple library for segmentation of tabletop and shelf surfacesUse GitHub to . []
 
  is a simple tabletop/shelf perception pipeline.  is the main API. It takes in a point cloud, where the positive ""z"" direction points up. It also assumes that the point cloud has been cropped down to a tabletop/shelf scene. 
 visualizes the result: 
If  is not provided, the point cloud will be processed in . surface_perceptiontarget_point_cloud_framebase_linkcrop_min_xfloatcrop_min_yfloatcrop_min_zfloatcrop_max_xfloatcrop_max_yfloatcrop_max_zfloathorizontal_tolerance_degreesfloatmargin_above_surfacefloatcluster_distancefloatmin_cluster_sizeintegermax_cluster_sizeintegermin_surface_sizeintegermin_surface_exploration_iterationinteger































rosrun surface_perception demo target_point_cloud_frame cloud_in:=input_point_cloud_topic





"
W1043,https://wiki.ros.org/ros_ethernet_rmp,Wiki,ros_ethernet_rmp,"ROS Wrapper for the Segway RMP Ethernet Python Driver



 broadcasts the robot frame ('/base_footprint') with respect to the odometry frame (). 





The  package is used to bridge ROS and a Segway RMP. It will convert  topic messages to the RMPCommand format and then publish the feedback from the RMP. There is also a joint state publisher to read in the feedback and publish the changing joint states as necessary. To install the  package, you can choose to either install from source, or from the Ubuntu package: The  package contains a  file. This file launches an instance of the , 'rmp_pose_updater.py' and  nodes. 'battery_monitor_rmp.launch' from 'battery_monitor_rmp' will also be launched if the argument, include_batt_monitor, is true. It is defaulted to true. To launch these nodes,  the battery monitor the following command can be used: To launch these nodes  the battery monitor, the following command can be used: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  ros_ethernet_rmpcmd_velethernet_rmp.pycmd_velrmp_commandrmp_feedback~update_delay_sec~log_data~current_rmp_ip_addr~current_rmp_port_num~is_omni~my_velocity_limit_mps~my_accel_limit_mps2~my_decel_limit_mps2~my_dtz_rate_mps2~my_coastdown_accel_mps2~my_yaw_rate_limit_rps~my_yaw_accel_limit_rps2~my_tire_diameter_m~my_wheel_base_length_m~my_wheel_track_width_m~my_gear_ratio~my_config_bitmap~my_ip_address~my_port_num~my_subnet_mask~my_gateway~my_user_defined_feedback_bitmap_1~my_user_defined_feedback_bitmap_2~my_user_defined_feedback_bitmap_3~my_user_defined_feedback_bitmap_4rmp_pose_updater.pyrmp_feedbackodom~publish_tfrmp_pose_updater/odomrmp_joint_state.pyrmp_feedbackrmp_joint_states~has_two_wheels~link_left_front~link_right_front~link_left_rear~link_right_rearros_ethernet_rmpros_ethernet_rmpros_ethernet_rmp.launchethernet_rmp.pyrmp_joint_states.py




sudo apt-get install ros-indigo-ros-ethernet-rmproslaunch ros_ethernet_rmp ros_ethernet_rmp.launch roslaunch ros_etehrnet_rmp ros_ethernet_rmp.launch include_batt_monitor:=false"
W1044,https://wiki.ros.org/catkinize_this,Wiki,catkinize_this,Scripts for helping catkinize packages
W1045,https://wiki.ros.org/multi_interface_roam,Wiki,multi_interface_roam,"
    
    This package allows automatic configuration and switching between 
    multiple network interfaces. It can be used in combination with a VPN
    tunnel to achieve seamless wifi roaming, and near-instantaneous
    transitioning between multiple available network interfaces.
  
    Currently only wifi interfaces are supported.
  "
W1046,https://wiki.ros.org/turtlebot3_applications,Wiki,turtlebot3_applications,"ROS packages for the turtlebot3 applications (meta package) 
  is a new generation mobile robot that is modular, compact and customizable. Let’s explore ROS and create exciting applications for education, research and product development. The goal of  is to drastically reduce the size and lower the price of the platform without sacrificing capability, functionality, and quality. Optional parts such as chassis, computers and sensors are available, and  can be customized in various ways.  is willing to be in the center of the maker movement by applying the latest technical advances of the SBC(Single Board Computer), the Depth sensor and 3D printing technology. 



TurtleBot3TurtleBot3TurtleBot3"
W1047,https://wiki.ros.org/ndt_fuser,Wiki,ndt_fuser,"

     ndt_fuser

  


A tutorial describing how to set-up an NDT fuser node and use it with your robot is available - . ~/points~/laser_scan~/odometry/tf/ndt_map~/save_map"
W1048,https://wiki.ros.org/swri_profiler,Wiki,swri_profiler,"swri_profiler provides basic tools for real-time selective
    profiling of ROS C++ nodes.. "
W1049,https://wiki.ros.org/abb_driver,Wiki,abb_driver,"
     ROS-Industrial nodes for interfacing with ABB robot controllers.
   
     This package is part of the ROS-Industrial program and contains nodes 
     for interfacing with ABB industrial robot controllers.
   





RobotWare OS version 5.13 or later is required due to the use of certain socket options. Earlier versions may work, but will require modifications to the RAPID code. 


This package is part of the  program.  While it is possible to use this driver with YuMi, for now this is not recommended. There are many packages that target YuMi specifically, one of which is . As of now, users of an IRB 14000 are suggested to consider using that package. The package is usable as-is, but is not feature complete. However, no significant development is planned, as development focus has shifted to  and . Use the links on the  page for access to the tutorials. These explain how to install and set up the RAPID programs on the controller, as well as how to use them in conjunction with the ROS nodes in this package. 623-1672-1616-1feedback_statesjoint_statesrobot_ip_addressstr~portintegerrobot_descriptionstrcontroller_joint_names[str, str, str, ..]robot_descriptioncontroller_joint_namesjoint_statesjoint_path_commandjoint_path_commandstop_motionrobot_ip_addressstr~portintegerrobot_descriptionstrcontroller_joint_names[str, str, str, ..]robot_descriptioncontroller_joint_names"
W1050,https://wiki.ros.org/sbpl_recovery,Wiki,sbpl_recovery,"A recovery behavior that uses the sbpl lattice planner and the pose
    follower to try to plan in full 3D to get the robot out of really tricky
    situations."
W1051,https://wiki.ros.org/irb_6640_moveit_config,Wiki,irb_6640_moveit_config," This package has been deprecated in Hydro, and will be removed in Indigo. Please use the abb_irb6640_moveit_config package as a replacement.An automatically generated package with all the configuration and launch
     files for using the irb_6640 with the MoveIt Motion Planning Framework
     (deprecated).
This package is part of the  program. "
W1052,https://wiki.ros.org/uav_random_direction,Wiki,uav_random_direction,"A package that performs random direction coverage with an unmanned aerial vehicle (UAV).

 (, default: 1)  (, default: ) 


The following packages of the  are required: to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. single_target=trueuav_random_directionidintegeroutputstringscreenscreenlogparamuav_random_direction.yamluav_random_directionuav_random_directionsingle_targettrueuav_coverage/goaluav_coverage/resulttarget_foundsingle_targettruearea/get_areaobstacle_detection/get_clear_sector~loop_ratereal~queue_sizeinteger~single_targetboolean~marginreal/rng_seedintegerroslaunch uav_random_direction uav_random_direction.launch"
W1053,https://wiki.ros.org/radar_omnipresense,Wiki,radar_omnipresense,"This is the radar driver package developed for the omnipresense radar module.



 Please see the individual packages within this stack for documentation. OPS241/OPS242 radar sensors can be purchased from .  The full API documentation is available at . radar_omnipresense , a ROS module for the  radar sensor The radar_omipresense driver is built automatically by the ROS build farm.  Subsequently, the standard way of installing drivers works for the radar omnipresense driver.  Namely, apt install ros--radar-omnipresense.  So, for example, if you are running with ROS ""melodic"" and are not logged in as root, you could issue the command; You can also download the driver as source code and build it yourself.  All external dependencies have been removed, so a beginner should be able to accomplish it without too many complications. The instructions on the wiki are very thorough on walking a developer through the steps.  A good place to start is  For application support, please contact  . sudo apt install ros-melodic-radar-omnipresense"
W1054,https://wiki.ros.org/sick_tim,Wiki,sick_tim,"A ROS driver for the SICK TiM and the SICK MRS 1000 laser scanners. 


 TIM310-1030000S01  1056791   
 TIM310-1030000  1052627  . 
 TIM310-1130000M01  1062563  none 
 TIM551-2050001  1060445   
 MRS1104C-111011  1081208    4 x 12.5 Hz  0.25°  Horizontal: 275°; Vertical 7.5° (Over 4 measurement layer)  0.2m to 64m  ± 60 mm  ≤ 30 mm  LAN, TCP 




 
 
Use GitHub to . []
 This is the standard edition of the TIM310. It does  support ranging (only detection). There was a firmware bug in versions prior to V2.50 that allowed ranging output, and this node works with those firmware versions. All newer firmware versions . See the  file in the package directory. To reduce data rates, some scanners (e.g., the TiM 571) don't send RSSI data by default. It must first be enabled in the configuration software by downloading , connecting to the sensor using USB or Ethernet, logging in (UID: Authorized Client, PWD: client), and clicking the checkbox shown below: Now you can visualize the  topic using . Enjoy!  scandatagrampublish_datagram~min_angdouble~max_angdouble~intensitybool~skipint~frame_idstr~time_offsetdouble~auto_rebootbool~hostnamestringhostname~portstringhostname~publish_datagrambool/datagram~subscribe_datagrambooltrue/datagrampublish_datagramudev/README/scanpublish_datagram<!-- ... --><param name=""publish_datagram"" type=""bool"" value=""true"" />roslaunch sick_tim sick_tim551_2050001.launch"
W1055,https://wiki.ros.org/usb_cam,Wiki,usb_cam,"A ROS Driver for V4L USB Cameras


 - supports image capture from usb cameras using OpenCV usb_cam_node~<camera_name>/image_raw~video_devicestring""/dev/video0""~image_widthinteger640~image_heightinteger480~pixel_formatstring""mjpeg""~io_methodstring""mmap""~camera_frame_idstring""head_camera""~framerateinteger30~contrastinteger32~brightnessinteger32~saturationinteger32~sharpnessinteger22~autofocusbooleanfalse~focusinteger51~camera_info_urlstring~camera_namestringhead_camera"
W1056,https://wiki.ros.org/velodyne_height_map,Wiki,velodyne_height_map,"

    Obstacle detection for 3D point clouds using a height map algorithm.

  





Start the height map nodelet in a separate process.  This launch file runs the height map nodelet in the same process with the Velodyne device driver and a  nodelet which publishes the points transformed into the ""/odom"" frame.  velodyne_pointsvelodyne_obstaclesvelodyne_clearcell_sizedoublefull_cloudsbooltruegrid_dimensionsintheight_thresholddouble$ rosrun nodelet nodelet standalone velodyne_height_map/HeightMapNodelet<launch>

  <!-- start nodelet manager and driver nodelets -->
  <include file=""$(find velodyne_driver)/launch/nodelet_manager.launch"">
    <arg name=""pcap""
           value=""$(find velodyne_pointcloud)/tests/class.pcap""/>
  </include>

  <!-- start transform nodelet using test calibration file -->
  <include file=""$(find velodyne_pointcloud)/launch/transform_nodelet.launch"">
    <arg name=""calibration""
         value=""$(find velodyne_pointcloud)/tests/angles.config""/>
  </include>

  <!-- start heightmap nodelet -->
  <include file=""$(find velodyne_height_map)/launch/heightmap_nodelet.launch""/>

</launch>$ rosrun velodyne_height_map heightmap_node$ rosrun velodyne_height_map heightmap_node _grid_dimensions:=100 _cell_size:=0.1$ rosrun velodyne_height_map heightmap_node _height_threshold:=0.05"
W1057,https://wiki.ros.org/nav2d_operator,Wiki,nav2d_operator,"The operator is a lightweight, purely reactive obstacle-avoidance
    module for mobile robots moving in a planar environment. The operator node
    works by evaluating a set of predefined motion primitives based on a local
    costmap and a desired direction. The best evaluated motion command will be
    send to the mobile base.


See the  for an example how to setup the Operator in Stage and use a Joystick to simulate commands from a higher level node. operatorscantfcmdVelocityTurnModecmd_vel~desired~route~local_map/costmap~max_free_spacedouble~safety_decaydouble~max_velocitydouble~safety_weightint~distance_weightint~conformance_weightint~continue_weightint~publish_routebooldesiredroute"
W1058,https://wiki.ros.org/pr2_controller_interface,Wiki,pr2_controller_interface,"This package specifies the interface to a realtime controller. A
   controller that implements this interface can be executed by the
     in the real time control loop. The package basically
  contains the C++ controller base class that all controllers need to
  inherit from. 




To implement a real time controller, your controller needs to inherit from the  base class. The base class contains  The  method is executed in . The  method returns if the initialization was successful or not. If the initialization fails, the controller will get unloaded by . Make sure to always use  to inform the user why your controller failed to initialize. A controller can only be initialized once. If you want to re-initialize a controller, you first need to unload it, and then load it again.  The  method is executed in . The  method initializes the controller right before the first time update is called. The  is allowed to re-start a controller at a later time, without having to unload/load the controller. The  method is executed in . The  method is executed in . The  method does not return anything, it is not allowed to fail.  The  method is executed in . The  method takes three arguments: pr2_controller_interface::Controllerinitinitinitpr2_mechanism_model::RobotStateros::NodeHandleinitROS_ERROR(""explanation"");startingstartingupdateupdatestoppingstoppingstoppinggetControllergetControllergetControllerpr2_controller_interface:BEFORE_MEpr2_controller_interface::AFTER_MEgetController























"
W1059,https://wiki.ros.org/industrial_moveit,Wiki,industrial_moveit,"ROS Industrial MoveIt packages.


Use GitHub to . []
 This stack is part of the  program. It currently contains packages that are meant for use with the  packages. See the  page for an overview of the available tutorials. "
W1060,https://wiki.ros.org/asr_intermediate_object_generator,Wiki,asr_intermediate_object_generator,"The intermediate object generator generates intermediate objects for a domain composed from scenes. 
    It is used to restrain the amount of objects searched during the direct search phase by selecting appropriate objects to search. 

     

 



 : The path were the intermediate_object_weights xml file should be created. The XXX works analog here, too. 
 The intermediate object generator generates intermediate object for a domain composed from scenes. It is used to restrain the amount of object searched during the direct search () phase by selecting appropriate objects to search. This package needs a database of objects and their absolute positions during the time (can be set in the ). On basis of this information it will be determined which objects have a heigher chance to be found in a 3D-object-search. There will be two files saved. In one a subset of the current objects will be saved, to limit the search objects while the direct search of the . In the second the calculated weight for each object will be saved. This can be used in the  to prefer some objects about the others. The  will launch this package automatically if the generated files for the current database were not generated yet. There is an option in asr_world_model to activate this function. !: The path were the intermediate_objects xml file should be created. If there is an XXX in the name, the XXX will be replaced with the current database name. So the name has not to be changed manually after a database change. ! : 0 or 1, 0 is additive and 1 is multiplicative  : weight for the presence in scene criteria  : weight for the position variance criteria  : weight for the average distance between object criterias!   : gain threshold for the object filtering ! : name of the domain "
W1061,https://wiki.ros.org/md49_base_controller,Wiki,md49_base_controller,"The md49_base_controller packageUse GitHub to . []
 

/cmd_vel/md49_data/md49_encoders~serialport/namestd::string~serialport/bpsint~md49/modeint~md49/accelerationint~md49/regulatorboolean~md49/timeoutboolean~md49/speed_lint~md49/speed_rint"
W1062,https://wiki.ros.org/octomap_ros,Wiki,octomap_ros,"octomap_ros provides conversion functions between ROS and OctoMap's native types.
    This enables a convenvient use of the octomap package in ROS.

 See  for documentation.  helps you to convert between various ROS / PCL and OctoMap data types.  Messages, services and conversions of them (without ROS-dependencies) are available in . Since fuerte, this package is a unary stack and released separately. "
W1063,https://wiki.ros.org/trac_ik,Wiki,trac_ik,"The ROS packages in this repository were created to provide an improved
    alternative Inverse Kinematics solver to the popular inverse Jacobian
    methods in KDL.  TRAC-IK handles joint-limited chains better than KDL
    without increasing solve time.


Sources -- including a ! compatible IK plugin -- can be found at: . TRAC-IK has a very similar API to KDL's IK solver calls, except that the user passes a maximum time instead of a maximum number of search iterations.  Additionally, TRAC-IK allows for error tolerances to be set independently for each Cartesian dimension (x, y, z, roll, pitch & yaw). Detailed usage instructions can be found at  (or more specifically, ). KDL's joint-limited pseudoinverse Jacobian implementation is the solver used by various ROS packages and ! for generic manipulation chains. In our research with Atlas humanoids in the DARPA Robotics Challenge and with NASA's Robonaut 2 and Valkyrie humanoids, TRACLabs researchers experienced a high amount of solve errors when using KDL's inverse kinematics functions on robotic arms.  We tracked the issues down to the fact that theoretically-sound Newton methods fail in the face of joint limits.  As such, we have created TRAC-IK that concurrently runs two different IK methods: Details can be found here in our Humanoids 2015 paper . Image (from ): A few high-level results are shown in the attached (low-res) figure.  Use  to . . "
W1064,https://wiki.ros.org/social_navigation_layers,Wiki,social_navigation_layers,"Plugin-based layers for the navigation stack that 
  implement various social navigation contraints, like proxemic distance.






There are currently two social navigation layers. However, they both share functionality in that they both subscribe to where people are and alter the costmaps with a Gaussian distribution around those people. Both classes derive from the general SocialLayer class. They can be used in  with the following types: The proxemic layer adds gaussian costs all around the detected person, with the parameters specified above. If the person is stationary, the gaussian is perfectly round. However, if the person is moving, then the costs will be increased in the direction of their motion. How far in front of the person the costs are increased is proportional to the  parameter.  social_navigation_layers::ProxemicLayersocial_navigation_layers::PassingLayer/peopleenabledboolcutoffdoubleamplitudedoublecovariancedoublefactordoublekeep_timedoublefactor"
W1065,https://wiki.ros.org/webui,Wiki,webui,"A web interface to install and launch applications for the PR2.












Ergo, the easiest way to install the webui from the binary is to  the webui directory.  ... where <robot name> would usually be of the form prX and <robot type> would usually be pr2. Add the following line to /etc/apache2/sites-available/default just above <> near the end of the file: ros-RELEASE-web-interfacepython-clearsilverapache2-mpm-preforklibapache2-mod-pythonruby1.8-devchown/etc/ros/envROBOTROBOT_NAMEROS_ROOTROS_MASTER_URIROS_PACKAGE_PATHroscd webui
make -f setup.make
sudo ./install.py <robot name> <robot type> www-datasudo ./install_rootInclude /etc/ros/ros_webui_apache.cfgsudo cp varwww/index.html /var/www/index.htmlsudo apache2ctl restart    gPump.publish(""/hoge"",""std_msgs/String"",[""hoga""]);    gPump.service_call2(""/service/knowrob"",
                       {'str': command},
                       function(res){
                         document.getElementById('displaybox') , res.str);
                       }
                       );<div class=""nav_element"" objtype=PercentTextWidget topic=""/power_state"" num=""a"" div=""b""/></div>var PercentTextWidget = Class.create({
  initialize: function(domobj) {
    this.pump = null;
    this.domobj = domobj;
    this.topics = [domobj.getAttribute(""topic"")];
    this.numerator = domobj.getAttribute(""num"");
    this.denominator = domobj.getAttribute(""den"");
  }, 

  init: function() {
  }, 

  receive: function(topic, msg) {
    if(msg[this.numerator] != null) {
      var percent = parseFloat(msg[this.numerator]) / parseFloat(msg[this.denominator]);
      this.domobj.innerHTML = (100. * percent).toFixed(2) + ""%"";
    }
  } 
});

gRosClasses[""PercentTextWidget""] = function(dom){
  return new PercentTextWidget(dom);
}"
W1066,https://wiki.ros.org/pr2_navigation_local,Wiki,pr2_navigation_local,"This package holds xml files for running the



This package contains configuration files for the  node meant to be run in an application that requires navigation in an odometric frame. This package also includes launch files that bring up  and  with local navigation specific configurations. rviz/rviz_move_base_local.launchnav_view/nav_view_move_base_local.launchmove_base_local.xmlconfig/global_costmap_params.yamlmove_base_local.xmlconfig/base_local_planner_params.yamlconfig/local_costmap_params.yamlmove_base_local.xmlconfig/move_base_params.yaml"
W1067,https://wiki.ros.org/pr2_navigation_teleop,Wiki,pr2_navigation_teleop,"This package holds a special teleop configuration for the PR2 robot that
     should be used when running applications that use autonomous navigation.

This package provides an XML file for running  in a configuration that allows it to run in parallel with the  stack on the PR2 robot. teleop.xml"
W1068,https://wiki.ros.org/ieee80211_channels,Wiki,ieee80211_channels,"
    This package provides mapping from frequencies to
    IEEE802.11 channels and vice-versa.
  

"
W1069,https://wiki.ros.org/tuw_marker_slam,Wiki,tuw_marker_slam,"The tuw_marker_slam package provides a framework for feature based SLAM implementations in ROS.
      Meanwhile a variant of EKF-SLAM is implemented.






Start SLAM framework in EKF-SLAM mode with a predefined measurement noise model using the simulation environment Stage (): Start SLAM framework in EKF-SLAM mode with a predefined measurement noise model using the simulation environment Gazebo () and the tuw_aruco marker detection cmdmarkerxtmtmodeintxzplanebooleanfalseframe_id_mapstring""map""frame_id_odomstring""odom""frame_id_basestring""base_link""beta_1/18doublebaseodom<frame in which measurements are taken>basemapodomrosrun tuw_marker_slam tuw_marker_slam_noderoslaunch tuw_marker_slam slam.launchroslaunch tuw_marker_slam slam_demo_stage.launchroslaunch tuw_marker_slam slam_demo_gazebo.launch"
W1070,https://wiki.ros.org/shape_tools,Wiki,shape_tools,Tools for operating on shape messages.
W1071,https://wiki.ros.org/staubli_resources,Wiki,staubli_resources,"
      Shared configuration data, 3D models and launch files for Staubli
      manipulators.
    
      This package contains configuration data, 3D models and launch files
      that are shared between different Staubli robot support packages
      within the ROS-Industrial program.

      This package also contains common urdf / xacro resources used by
      other Staubli related packages.
    

This package is part of the  program.  See the  metapackage page. "
W1072,https://wiki.ros.org/xaxxon_openlidar,Wiki,xaxxon_openlidar,"ROS Drivers for the Xaxxon OpenLIDAR Sensor
is an open hardware rotational laser scanner, using the Garmin LIDAR-LiteV3 sensor. Full specs and complete documentation can be found at     





 Full specs and complete documentation can be found at  /scan/odomdropscan_turnrateminimum_rangemaximum_rangerpmmasksdropscan_turnrate/odompark_offsetforward_offsetread_frequency"
W1073,https://wiki.ros.org/stdr_simulator,Wiki,stdr_simulator,"A simple, flexible and scalable 2D multi-robot simulator.

 



  STDR Simulator implements a distributed, server-client based architecture. Each node can run in a different machine and communicate using ros interfaces. STDR Simulator, also provides a  developed in QT, for visualization purposes and more. The , is not necessary for the simulator to run and its functionalities can be performed using command-line tools provided with the package. The  available packages are: An overview of the  architecture is depicted in the following diagram: "
W1074,https://wiki.ros.org/rwt_plot,Wiki,rwt_plot,rwt_plotExample of  with .  rwt_plot
W1075,https://wiki.ros.org/moveit_object_handling,Wiki,moveit_object_handling,"Package which helps generate the MoveIt! moveit_msgs/CollisionObject
    messages for existing objects in the scene, described by object_msgs/Object.
    Also provides helper classes for MoveIt! in relation to objects."
W1076,https://wiki.ros.org/viso2_ros,Wiki,viso2_ros,"
    This is the ROS wrapper for libviso2, library for visual odometry (see package libviso2).
  

: The coordinate frame of the camera is expected to be the  frame, which means  is pointing right,  downwards and  from the camera into the scene. The origin is where the camera's principle axis hits the image plane (as given in ). 








This package contains two nodes that talk to  (which is included in the  package):  and . Both estimate camera motion based on incoming rectified images from calibrated cameras. To estimate the scale of the motion, the mono odometer uses the ground plane and therefore needs information about the camera's z-coordinate and its pitch. The stereo odometer needs no additional parameters and works - if provided with images of good quality - out of the box. The video below shows an online 3D reconstruction of a 3D scene shot by a Micro AUV using dense stereo point clouds coming from  concatenated in  using the stereo odometer of this package. In the repository, you can find a sample launch file, which uses a public bagfile available here: . Please read  for an explanation of odometry frame ids. Visual odometry algorithms generally calculate . To be able to calculate  based on , the transformation from the camera frame to the robot frame has to be known. Therefore this implementation needs to know the tf  →  to be able to publish  → . The name of the camera frame is taken from the incoming images, so be sure your camera driver publishes it correctly. If your camera driver does not set frame ids, you can use the fallback parameter  (see below). To learn how to publish the required tf  → , please refer to the . If the required tf is not available, the odometer assumes it as the identity matrix which means the robot frame and the camera frame are identical. In general, monocular odometry and SLAM systems cannot estimate motion or position on a metric scale. All estimates are relative to some unknown scaling factor. libviso2 overcomes this by assuming a fixed transformation from the ground plane to the camera (parameters  and ). To introduce these values, in each iteration the ground plane has to be estimated. That is why features on the ground as well as features above the ground are mandatory for the mono odometer to work. Please use the stack's issue tracker at Github to submit bug reports and feature requests regarding the ROS wrapper of libviso2: . mono_odometerstereo_odometerworldodombase_linkcamerabase_linkcameraodombase_linksensor_frame_idxyzbase_linkcameracamera_heightcamera_pitchcamera_heightcamera_pitch~pose~odometry~info~odom_frame_idstring/odom~base_link_frame_idstring/base_link~publish_tfbool~sensor_frame_idstring~max_featuresint~bucket_widthdouble~bucket_heightdouble~nms_nint~nms_tauint~match_binsizeint~match_radiusint~match_disp_toleranceint~outlier_disp_toleranceint~outlier_flow_toleranceint~multi_stageint~half_resolutionint~refinementint~base_link_frame_id<frame_id attached to image messages>base_link~odom_frame_id~base_link_frame_idodombase_linkimagecamera_infoimage_transport::CameraSubscriber~camera_heightdouble~camera_pitchdouble~ransac_itersint~inlier_thresholddouble~motion_thresholddouble<stereo>/left/<image><stereo>/right/<image><stereo>/left/camera_info<stereo>/right/camera_info~point_cloud~queue_sizeint~approximate_syncbool~ransac_itersint~inlier_thresholddouble~reweightingbool~ref_frame_change_methodint~ref_frame_motion_thresholddouble~ref_frame_inlier_thresholdint"
W1077,https://wiki.ros.org/uwb_hardware_driver,Wiki,uwb_hardware_driver,The uwb_hardware_driver package
W1078,https://wiki.ros.org/segbot_navigation,Wiki,segbot_navigation,"Contains launch files for running the ROS navigation stack on the segbot
    using the eband_local_planner approach, as well as launch files for amcl
    and gmapping."
W1079,https://wiki.ros.org/goal_passer,Wiki,goal_passer,"A global planner plugin for move_base that simply passes the target pose on
    as a global plan. Useful for debugging local planners."
W1080,https://wiki.ros.org/rwt_config_generator,Wiki,rwt_config_generator,The rwt_config_generator package
W1081,https://wiki.ros.org/katana_moveit_ikfast_plugin,Wiki,katana_moveit_ikfast_plugin,The katana_moveit_ikfast_plugin package
W1082,https://wiki.ros.org/hironx_calibration,Wiki,hironx_calibration,"Launch and configuration files for calibrating hironx using the generic  package.

   THIS FILE IS AUTOMATICALLY GENERATED BY:
   "
W1083,https://wiki.ros.org/rosh_geometry,Wiki,rosh_geometry,"

     ROSH plugin for the geometry stack, including tf.

  

 transformsPointQuaternionPointStampedPoseStampedQuaternionStampedVector3Stampedtransforms.transform_name('target_transform')transform_nametarget_transform"
W1084,https://wiki.ros.org/tuw_marker_pose_estimation,Wiki,tuw_marker_pose_estimation,This node does pose estimation for detected fiducials (marker_msgs/FiducialDetection.msg)
W1085,https://wiki.ros.org/warehouse_ros_mongo,Wiki,warehouse_ros_mongo,Implementation of warehouse_ros for MongoDB 
W1086,https://wiki.ros.org/summit_xl_robot_control,Wiki,summit_xl_robot_control,"Control the robot joints in all kinematic configurations, publishes odom topic and, 
	  if configured, also tf odom to base_link. Usually takes as input joystick commands 
	  and generates as outputs references for the gazebo controllers defined in summit_xl_control.
Control the robot joints in all kinematic configurations, publishes odom topic and, if configured, also tf odom to base_link. Usually takes as input joystick commands and generates as outputs references for the gazebo controllers defined in summit_xl_control. This package permits an alternative way to control the robot motion (4 motorwheels) that by default is carried on by the Gazebo plugin (skid-steer). In the default configuration this package only controls the pan-tilt camera joints. When used as main controller of the simulated robot, this node also computes the odometry of the robot using the joint movements and a IMU and publish this odometry to /odom. The node has a flag in the yaml files that forces the publication or not of the odom->base_footprint frames, needed by the localization and mapping algorithms.  "
W1087,https://wiki.ros.org/rc_pick_client,Wiki,rc_pick_client,"The ros client for roboception grasp generation modules


 



Use GitHub to . []
  
See  and  for more details. The components provide out-of-the-box perception solutions for robotic pick-and-place applications.  targets the detection of flat surfaces of unknown objects for picking with a suction gripper.  detects rectangular surfaces and determines their position, orientation and size for grasping. The interface of both components is very similar. Therefore both components are described together in this chapter. For detail description of the modules check the following link:  The following parameters are available for the  and  modules: For the  module, two additional parameters are available: The  node offers an additional service: For the  module: For the  module: hostdevice02912345:02912345load_carrier_crop_distanceload_carrier_model_tolerancecluster_max_curvatureclustering_max_surface_rmseclustering_discontinuity_factorcluster_max_dimensionclustering_patch_sizestartstopset_region_of_interestget_region_of_interestsdelete_regions_of_interestset_load_carrierget_load_carriersdelete_load_carriersdetect_load_carriercompute_graspsdetect_items$ rosrun rc_pick_client rc_itempick_client_node _host:=<sensor_ip>rosrun rc_pick_client rc_itempick_client_node _device:=:<serial_number>$ rosrun rc_pick_client rc_boxpick_client_node _host:=<sensor_ip>rosrun rc_pick_client rc_boxpick_client_node _device:=:<serial_number>"
W1088,https://wiki.ros.org/nav2d,Wiki,nav2d,"Meta-Package containing modules for 2D-Navigation
 





Use GitHub to . []
  This stack is developed using the catkin tool-chain. An older version is available that uses ROS Fuerte and rosbuild tool-chain, but has not been updated after the move to Hydro. To build the  package is required, which is included in ros-navigation. To check if all packages are working correctly, you can run the launch files located in the  package. This will use a joystick to semi-autonomous control a simulated robot in Stage. A more in-detail description can be found in the . To start the tests you need to have the following packages additionally installed: If you have a Question concerning any of the nav2d-packages, please post your question at  and add the tag ""nav2d"".     apt-get install ros-<release-name>-nav2d    ros-<release-name>-nav2d_operator
    ros-<release-name>-nav2d_navigator
    ros-<release-name>-nav2d_exploration
    ros-<release-name>-nav2d_karto
    ros-<release-name>-nav2d_remote
    ros-<release-name>-nav2d_msgs
    ros-<release-name>-nav2d_tutorials    source /opt/ros/<release-name>/setup.bash
    cd catkin_ws/src
    git clone https://github.com/skasperski/navigation_2d
    cd ..
    catkin_make -DCMAKE_BUILD_TYPE=Release
    source catkin_ws/devel/setup.bashroslaunch nav2d_tutorials tutorial1.launch"
W1089,https://wiki.ros.org/joint_trajectory_action_tools,Wiki,joint_trajectory_action_tools,joint_trajectory_action_tools
W1090,https://wiki.ros.org/sbpl_lattice_planner,Wiki,sbpl_lattice_planner,"The sbpl_lattice_planner is a global planner plugin for move_base and wraps
    the SBPL search-based planning library.







sbpl_lattice_planner is a ROS wrapper for the  lattice environment and  adheres to the nav_core:: interface specified in .  The lattice planner can therefore be used as the global planner for . The planner will generate a path from the robot's current position to a desired goal pose. Paths are generated by combining a series of ""motion primitives"" which are short, kinematically feasible motions. Planning is therefore done in x, y, and theta dimensions, resulting in smooth paths that take robot orientation into account, which is especially important if the robot is not assumed to be circular or has nonholonomic constraints. Plans can be found using the ARA* planner or AD* planner. Please refer to the  documentation for pre-made motion primitives for the PR2 (and other robots) as well as instructions on how to generate your own custom motions. ~/SBPLLatticePlanner/plan~/SBPLLatticePlanner/sbpl_lattice_planner_stats~/SBPLLatticePlanner/planner_typestring~/SBPLLatticePlanner/allocated_timedouble~/SBPLLatticePlanner/initial_epsilondouble~/SBPLLatticePlanner/environment_typestring~/SBPLLatticePlanner/forward_searchbool~/SBPLLatticePlanner/primitive_filenamestring~/SBPLLatticePlanner/force_scratch_limitint~/SBPLLatticePlanner/nominalvel_mpersecsdouble~/SBPLLatticePlanner/timetoturn45degsinplace_secsdouble~/SBPLLatticePlanner/lethal_obstacleunsigned charroslaunch sbpl_lattice_planner  move_base_sbpl_fake_localization_2.5cm.launch"
W1091,https://wiki.ros.org/agile_grasp,Wiki,agile_grasp,"The agile_grasp ROS package. AGILE stands for Antipodal Grasp Identification and LEarning. The package 
  finds antipodal grasps in point clouds.




 
  

: If you want to adjust the grasp parameters, you can do this from the launch file. For the available parameters, see . 
   
  When no handles or not enough antipodal grasps are found, please increase the  parameter. Another option is to modify the workspace limits in  (this requires recompiling the code).  


   
     

 This package localizes antipodal grasps in 3D point clouds.  stands for ntipodal rasp dentification and arning. The reference for this package is: . The package already comes with pre-trained machine learning classifiers and can be used (almost) out-of-the-box, in particular with an  range sensor. For a complete  on a Baxter robot, check out our  package. Two example ROS launch files,  and , are provided that illustrate  how to use the  ROS node to localize grasps in a point cloud obtained from one or two range sensors. The most important parameters to increase the number of grasps found are  and . A higher sample number means that a larger subset of points in the point cloud will be considered. A smaller workspace means that less samples are required to find grasps. Localize grasps in a point cloud stored in a  file: This localizes grasps in the point cloud file  using the SVM stored in the file . The last three parameters are optional.  sets the number of samples,  sets the number of CPU threads used, and  sets the minimum number of grasps required to have a cluster of grasps. To train the SVM to predict grasps, first create a directory that contains the  files used for training. If you like this package and use it in your own work, please cite our : Andreas ten Pas and Robert Platt.  International Symposium on Robotics Research (ISRR), Italy, September 2015. $ sudo apt-get install liblapack-dev$ cd location_of_workspace/src$ git clone https://github.com/atenpas/agile_grasp.git$ cd ..$ catkin_make$ git clone https://github.com/atenpas/agile_grasp.git -b hydro$ roslaunch agile_grasp single_camera_grasps.launch$ roscore$ roslaunch openni2_launch openni2.launch$ roslaunch agile_grasp single_camera_grasps.launch$ rosrun rviz rviz$ rosrun agile_grasp test_svm /home/userABC/data/input.pcd /home/userABC/ros_ws/src/agile_grasp/svm_032015_20_20_same$ rosrun agile_grasp test_svm pcd_filename svm_filename [num_samples] [num_threads] [min_handle_inliers]$ rosrun agile_grasp train_svm num_files pcd_directory/obj svm_filename [plots_hands] [num_samples] [num_threads]$ rosrun agile_grasp train_svm num_files pcd_directory svm_filename [plots_hands] [num_samples] [num_threads]file1
file2
...file1
file2
..."
W1092,https://wiki.ros.org/range_sensor_layer,Wiki,range_sensor_layer,"Navigation Layer for Range sensors like sonar and IR



 The range_sensor_layer is a plugin for the LayeredCostmap in , that uses the  message. It is intended for use with sonar and infrared data. ""topics""nsstringtopicsArray of stringsno_readings_timeoutdoubleclear_thresholddoublemark_thresholddoubleclear_on_max_readingbool      - {name: sonar,   type: ""range_sensor_layer::RangeSensorLayer""}"
W1093,https://wiki.ros.org/rotors_simulator,Wiki,rotors_simulator,"RotorS is a MAV gazebo simulator.

Use GitHub to . []
 RotorS is a MAV gazebo simulator. It provides some multi-rotor helicopter models such as the  Hummingbird, Pelican, and Firefly, but the simulator is not limited for the use with these multicopters. "
W1094,https://wiki.ros.org/tuw_multi_robot_demo,Wiki,tuw_multi_robot_demo,"Contains launch and config files to run a sample demo.




 default: ""cave""  default: ""true""  default: ""true""  default: ""true""  default: ""true""  default: ""true""  default: ""true""  default: ""default"" (2 robots)  default: ""false"" 
Use GitHub to . []
  To control the robots one can use a custom controller (e.g. the DWA from move_base) in combination with the local behavior controller which takes care of synchronization with other robots and provides an ordinary nav_msgs/Path message. For tests with a large number of robots the  is provided which directly uses synchronous tuw_multi_robot_msgs/Route messages and controls all robots simultaneously. This is advantageous for performance reasons. multi_segment_controller_noderoomuse_rvizuse_stageuse_map_serveruse_planneruse_controlleruse_graph_generatorcfguse_path_synchronizer"
W1095,https://wiki.ros.org/arbotix_firmware,Wiki,arbotix_firmware,"Firmware source code for ArbotiX ROS bindings.



You can then copy the files found in the  folder of this package into your sketchbook. You should then be able to open the  sketch, compile and upload.  "
W1096,https://wiki.ros.org/webrtc_ros,Wiki,webrtc_ros,"A collection of ROS utilities for using WebRTC with ROS



A ROS wrapper that allows for streaming of ROS video topics over  . webrtc_ros_server_node operates similar to . It provides a way of streaming ROS topics to a web browser. By default it provides a webpage at the root path of the web server that allows you to browse all video topics and stream any of them. A small Javascript library is also served to simplify the usage. See the topic stream web page source for a simple example of usage. A simple protocol that uses JSON over WebSockets is used as the WebRTC signaling channel. ~portstring~image_transportstring"
W1097,https://wiki.ros.org/rtt_actionlib_msgs,Wiki,rtt_actionlib_msgs,"Provides an rtt typekit for ROS actionlib_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/actionlib_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W1098,https://wiki.ros.org/rosserial_server,Wiki,rosserial_server,"A more performance- and stability-oriented server alternative implemented
    in C++ to rosserial_python.






The  package contains a C++ implementation of the host-side rosserial connection. It automatically handles setup, publishing, and subscribing for a connected rosserial-enabled device. It uses a python node in the rosserial_python package as an aid for handling subcriptions. These nodes use the /ShapeShifter meta message in order to republish messages from clients without having to know about them at compile time. The only caveat to this approach is that the servers do not have the full textual definition of messages (as it is not stored in clients or part of the rosserial protocol). There is a provided Python shim which the servers may optionally use to acquire this information. Example launch files for serial and socket usage are provided in the package. The  parameter to the server allows it to enforce that the client(s) must publish and subscribe to a certain set of topics. This is important because a serial connection provides no guarantee of delivery, and the rosserial protocol doesn't inherently contain any such checks. Use of the  parameter is completely optional, but may be of value to users needing to deploy ROS-connected microcontrollers into environments where the occasional failed initialization is not acceptable. At this time,  is experimental. It is missing key features of the -provided node, including parameters, logging, and services. If you require these features, please stick to the standard Python server for now. ~portstr~baudint~requireobj~portint~require~requireroslaunch rosserial_server serial.launch port:=/dev/ttyUSB0roslaunch rosserial_server socket.launchrosrun rosserial_server serial_node _port:=/dev/ttyUSB0<launch>
  <node pkg=""rosserial_server"" type=""serial_node"" name=""rosserial_server"">
    <rosparam>
      port: /dev/arduino
      require:
        publishers: [ status ]
        subscribers: [ cmd, lights ]
    </rosparam>
  </node>
  <node pkg=""rosserial_python"" type=""message_info_service.py""
        name=""rosserial_message_info"" />
</launch>"
W1099,https://wiki.ros.org/nav_pcontroller,Wiki,nav_pcontroller,Simple P-Controller for a holonomic robot base
W1100,https://wiki.ros.org/trac_ik_kinematics_plugin,Wiki,trac_ik_kinematics_plugin,A MoveIt! Kinematics plugin using TRAC-IK
W1101,https://wiki.ros.org/trajectory_msgs,Wiki,trajectory_msgs,"This package defines messages for defining robot trajectories. These messages are
    also the building blocks of most of the
     actions.
: this package is now part of .  In previous releases, it was part of . 
"
W1102,https://wiki.ros.org/wheeled_robin_apps,Wiki,wheeled_robin_apps,"The wheeled_robin_apps is a group of applications to run on the WheeledRobin Robot.

Use GitHub to . []
  Please refer main  page. "
W1103,https://wiki.ros.org/ackermann_msgs,Wiki,ackermann_msgs,"ROS messages for robots using Ackermann steering.

 This package provides ROS messages for vehicles using front-wheel Ackermann steering. It was defined by the. "
W1104,https://wiki.ros.org/people,Wiki,people,The people stack holds algorithms for perceiving people from a number of sensors.
W1105,https://wiki.ros.org/rail_maps,Wiki,rail_maps,"Maps generated by the RAIL group at WPI.To install the  package, you can choose to either install from source, or from the Ubuntu package: 
To install from source, execute the following:  
To install the Ubuntu package, execute the following:  










The  stack contains a set of maps in  format that have been generated by the  research group at . Maps can be used in the real world or in simulated worlds provided in the  package. Please send bug reports to the . Feel free to contact me at any point with questions and comments.  rail_maps*.pgm0.050.050.050.050.050.05rail_mapsrail_maps



sudo apt-get install ros-fuerte-rail-maps



sudo apt-get install ros-groovy-rail-maps"
W1106,https://wiki.ros.org/nao_path_follower,Wiki,nao_path_follower,"
	
  Enables a Nao humanoid to either walk to a target location (with localization feedback),
  or follow a planned 2D path closely. Sends nao_msgs to the nao_walker node in nao_driver.
  

foot_contactTruecmd_poseuse_vel_ctrlFalsecmd_veluse_vel_ctrlTruenao_path_follower/target_posewalk_path/goalwalk_target/goalbase_frame_idstringcontroller_frequencyfloattarget_distance_thresholdfloattarget_angle_thresholdfloatwaypoint_distance_thresholdfloatwaypoint_angle_thresholdfloatmax_vel_xfloatmax_vel_yfloatmax_vel_yawfloatstep_freqfloatuse_vel_ctrlbooleanTrueFalseuse_foot_contact_protectionbooleanTruepath_next_target_distancefloatpath_max_start_distancefloatthreshold_damp_xyfloatthreshold_damp_yawfloat"
W1107,https://wiki.ros.org/wheeled_robin_simulator,Wiki,wheeled_robin_simulator,"The wheeled_robin_simulator stack provides packages for simulating a WheeledRobin robot.
Use GitHub to . []
  Please refer main  page. 
"
W1108,https://wiki.ros.org/sr_common_drivers,Wiki,sr_common_drivers,"sr_common_drivers metapackage

"
W1109,https://wiki.ros.org/rosh,Wiki,rosh,"rosh is a Python-based scripting and runtime environment for ROS.  Through rosh and its various plugins, you can interact with ROS APIs in an introspectable and unified approach. 
 is a Python-based shell and runtime environment for ROS.  It leverages the IPython shell environment to provide tab-completion introspection across various ROS APIs, like topics, services, parameters, and nodes.  It is similar to using tools like  and , but with Pythonic semantics and the convenience of a Python interpreter.  You can also develop ROS nodes using rosh, which we call ""roshlets"". 







Please see the . See  See  In order customize your default  shell, you can write a . See . roshshow(cameras.camera)rosh_robotrosh_robotrosrun rosh rosh"
W1110,https://wiki.ros.org/spin_hokuyo,Wiki,spin_hokuyo,"This package enables a 2D Hokuyo laser, connected to a Dynamixel servo motor, to produce a 3D point cloud that can
    be visualized in rviz and used to make an octomap.





 Light Detection and Ranging, or LiDAR, depends on data from one or more laser range finders.  While some laser range finders are now available that create 3D scans, such as the Velodyne Puck, there are still gaps in the data, and 2D laser range finders provide even less data.  By connecting a 2D sensor to a servo, the amount of data acquired can be significantly increased and improve the robot's perception of its environment.  This package includes the code to operate such a setup and generates a point cloud that then be visualized in rviz or used to create an . The hardware used for developing this package were based on the setup detailed in this  from Glendale Community College. While this code is specifically designed to operate with the Hokuyo laser and Dynamixel servo, any laser range finder and servo that provide identical or similar data could be used with the proper modification of the code.  The part files for the gimbal and mount used in this project are currently unavailable, but the original gimbal used in the capstone report can be found . tilt_controller/statetilt_controller/commandtime/start_timetime/end_time~maximuminteger~minimuminteger~pausefloattilt_controller/stateperform_sweeptilt_controller/commandtime/start_timetime/end_time~maximuminteger~minimuminteger~pausefloattilt_controller/Stateservolaserscanhokuyo_filteredhokuyo_filteredhokuyo_pointstime/start_timetime/end_timeassembled_cloudassemble_scans2~assembled_cloud_modestring~scan_timedoublesudo apt-get install ros-indigo-spin-hokuyoroslaunch spin_hokuyo basic_motors.launchroslaunch spin_hokuyo tilting_lidar_continuous.launch"
W1111,https://wiki.ros.org/tf2_msgs,Wiki,tf2_msgs,"tf2_msgs
This is the package grouping the Transform and Error messages used by  and . "
W1112,https://wiki.ros.org/rtt_rosgraph_msgs,Wiki,rtt_rosgraph_msgs,"Provides an rtt typekit for ROS rosgraph_msgs messages.

    It allows you to use ROS messages transparently in
	RTT components and applications.

	This package was automatically generated by the
	create_rtt_msgs generator and should not be manually
	modified.

	See the http://ros.org/wiki/rosgraph_msgs documentation
	for the documentation of the ROS messages in this
	typekit."
W1113,https://wiki.ros.org/laptop_battery_monitor,Wiki,laptop_battery_monitor,Simple script to check battery status
W1114,https://wiki.ros.org/rtmros_hironx,Wiki,rtmros_hironx,"The rtmros_hironx package is an operating interface via ROS and OpenRTM, for Hiro and  dual-armed robots from Kawada Industries Inc.
  
  NOTE for Hiro users: Utilizing this opensource controller for Hiro requires installation both on Controller Box (QNX-based) and Vision PC (Ubuntu Linux), and the steps for it are not shared publicly in order to avoid any possible inconvenience that can easily be caused by slight mis-operation during installation. Please contact  for an advice.







Root of the frame tree is  (instead of  ) due to the fact that originally this robot wasn't made to work on . ROS news related to  twin-arm robot: Full-fledged user document incl. writing codes is found . For ! related feature, HiroNXO does no customization. So follow general .  ! has ""allow re-plan"" feature.  might be of your interest. QNXUbuntuHiro/NEXTAGE OPENROSWAISTbase_linkROSHiroMoveIt! way Can moveit plan a path and then change it during execution because a new obstacle
 appeared in the path? There are `move_group.plan()` and `move_group.go()` for static
 scenes. Do I need other commands for dynamic scenes?  At the moment I am working on the low level API, the joint trajectory action
 interface to control the robot. Is it true that the joint trajectory controller 
 directly control the joints (joint motors) of the robot? Because I thought that 
 the robot can only be accessed via CORBA and ROS does not know anything about CORBA. Another question is, if the hrpsys simulator can also simulate the correct physical
 behavior when we control the joints directly (with Joint Trajectory Aciton). 
 Let’s say my controller parameters are chosen wrong.. Will the robot arm overshoot? "
W1115,https://wiki.ros.org/sr_gui_bootloader,Wiki,sr_gui_bootloader,"

    A GUI plugin for bootloading the motors on the shadow etherCAT hand.

   "
W1116,https://wiki.ros.org/ohm_tsd_slam,Wiki,ohm_tsd_slam,"The ohm_tsd_slam package provides a 2D SLAM approach for laser scanners. RANSAC-aided registration   Multi-robot SLAM  


 Welcome to the ohm_tsd_slam ROS wiki page. Ohm_tsd_slam is the SLAM approach of the  Rescue  from the Technische Hochschule Nuremberg, Germany. The release includes a SLAM package using 2D LIDAR data only as input. Its localization module uses ICP-based registration. The mapping uses a grid map, which cells contain Truncated Signed Distances (tsd), similar to the well known  approach. This representation performs dynamic mapping, wherefore temporary objects are removed over time. The repository comes with an example launchfile, slam.launch. Its parameters are set to fit the typical  rescue scenario deploying a Hokuyo UTM30LX LIDAR or a sensor with similar parameters. This video shows a demo of the package. It uses public available recorded Lidar data, acquired from the University of Freiburg (). The ohm_tsd_slam package is based on our CPU version of the well known  approach,  and is available at . The multi-robot SLAM has been subject of a paper itself and can be downloaded at . If you like to install obviously externally it is recommended to use the master branch and follow the installation instructions provided in the  repository of . Finally, you can use the slam.launch launchfile to run the SLAM. If you play a bagfile that publishes sensor_msgs:: on the ""/scan"" topic you will receive a map on topic ""/map"" and the robot's pose on ""/pose"" 1.2.mapposemap_sizeintegercell_sizedoublex_offsetdoubley_offsetdoubleyaw_offsetdoublemin_rangedoublemax_rangedoublelow_reflectivity_rangedoubleocc_grid_time_intervaldoubleloop_ratedoublepose_topicstringtf_base_framestringtf_child_framestringtruncation_radiusdoublemap_topicstringget_map_topicstringfootprint_widthdoublefootprint_heightdoublefootprint_x_offsetdoubleregistration_modeintdist_filter_maxdoubledist_filter_mindoubleicp_iterationsintreg_trs_maxdoublereg_sin_rot_maxdoublenode_control_topicdoubleransac_trialsintransac_eps_treshdoubleransac_ctrlset_sizeintransac_phi_maxdoubleS. May, P. Koch, R. Koch, C. Merkl, C. Pfitzner and A. Nuechter.
A Generalized 2D and 3D Multi-Sensor Data Integration Approach based on Signed Distance Functions for Multi-Modal Robotic Mapping.
In Proceedings of the VMV 2014: Vision, Modeling & Visualization, Darmstadt, Germany, 2014.P. Koch, S. May, M. Schmidpeter, M. Kühn, J. Martin, C. Pfitzner, C. Merkl, M. Fees, R. Koch and A. Nüchter.
Multi-Robot Localization and Mapping based on Signed Distance Functions.
In Proceedings of the IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC '15), Vila Real, Portugal, April 2015.$ #In your catkin workspace
$ cd src
$ git clone https://github.com/autonohm/ohm_tsd_slam
$ cd ohm_tsd_slam
$ git checkout indigo-devel
$ cd ../..$ wstool update -t src/ohm_tsd_slam$ sudo rosdep init
$ rosdep update$ source devel/setup.bash #for example
$ rosdep install ohm_tsd_slam$ catkin_make --only-pkg-with-deps ohm_tsd_slam$ roslaunch ohm_tsd_slam slam.launch"
W1117,https://wiki.ros.org/segbot_simulator,Wiki,segbot_simulator,"segbot_simulator

Use GitHub to . []
  "
W1118,https://wiki.ros.org/rtt_visualization_msgs,Wiki,rtt_visualization_msgs,"Provides an rtt typekit for ROS visualization_msgs messages.

    It allows you to use ROS messages transparently in
    RTT components and applications.

    This package was automatically generated by the
    create_rtt_msgs generator and should not be manually
    modified.

    See the http://ros.org/wiki/visualization_msgs documentation
    for the documentation of the ROS messages in this
    typekit."
W1119,https://wiki.ros.org/multi_level_map_server,Wiki,multi_level_map_server,multi_level_map_server
W1120,https://wiki.ros.org/uav_optimal_coverage,Wiki,uav_optimal_coverage,"A package that performs optimal coverage with a swarm of unmanned aerial vehicles (UAVs). The UAVs optimally divide the area to be covered among each other.

 (, default: 1)  (, default: ) 


to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. single_target=trueuav_optimal_coverageidintegeroutputstringscreenscreenlogparamuav_optimal_coverage.yamluav_optimal_coverageuav_optimal_coveragesingle_targettrueuav_coverage/goaluav_coverage/resulttarget_foundsingle_targettruecoverage_path/waypoint~loop_ratereal~queue_sizeinteger~single_targetbooleanroslaunch uav_optimal_coverage uav_optimal_coverage.launch"
W1121,https://wiki.ros.org/moveit_controller_multidof,Wiki,moveit_controller_multidof,"A moveit_controller_manager implementation which supports execution
    of a MultiDOF-trajectory with a virtual joint.
    Transforms the moveit_msgs::RobotTrajectory into a path navigation action
    and/or a control_msgs/FollowJointTrajectoryAction
    to control (1) the virtual joint with the path navigation action (read from
    moveit_msgs/RobotTrajectory.multi_dof_joint_trajectory), and (2) the
    joints with a control_msgs/FollowJointTrajectoryAction."
W1122,https://wiki.ros.org/pr2_arm_move_ik,Wiki,pr2_arm_move_ik,"Move the pr2 arm using inverse kinematics 
pr2_arm_ik_action<~arm>_arm_ik/goal<~arm>_arm_ik/result<~arm>_arm_controller/<~joint_trajectory_action>~armstring~joint_trajectory_actionstring~free_angleint~search_discretizationdouble~ik_timeoutdouble<launch>
  <!-- ik action -->
  <node pkg=""pr2_arm_move_ik"" type=""arm_ik"" name=""r_arm_ik"" output=""screen"">
    <param name=""joint_trajectory_action"" value=""/r_arm_controller/joint_trajectory_generator"" />
    <param name=""arm"" value=""r"" />
    <param name=""free_angle"" value=""2"" />
    <param name=""search_discretization"" value=""0.01"" />
    <param name=""ik_timeout"" value=""5.0"" />
  </node>

  <!-- Trajectory generator -->
  <node pkg=""joint_trajectory_generator"" type=""joint_trajectory_generator"" output=""screen""
        name=""joint_trajectory_generator"" ns=""r_arm_controller"" >
    <param name=""max_acc"" value=""2.0"" />
    <param name=""max_vel"" value=""2.5"" />
  </node>
</launch>"
W1123,https://wiki.ros.org/rosserial_mbed,Wiki,rosserial_mbed,"rosserial for mbed platforms. This package contains Mbed-specific extensions required to run  on an . It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors into your ROS project using an . The Tutorials of this package will walk you through a setting up your Mbed environment, creating a few example programs and explain where to purchase the additional hardware. "
W1124,https://wiki.ros.org/slam_gmapping,Wiki,slam_gmapping,"slam_gmapping contains a wrapper around gmapping which provides SLAM capabilities.

  
See the  package for more details on mapping options. Also, see the  "
W1125,https://wiki.ros.org/typelib,Wiki,typelib,"
      This library offers an introspection mechanism for C/C++ value-types. I.e.
      it offers a way to represent types, and to manipulate in-memory values
      that are instances of those types.

      A Ruby binding is included, which gives a fast and transparent
      modification of C/C++ in-memory types from Ruby, and an associated
      interface to call C functions from shared libraries.
  "
W1126,https://wiki.ros.org/urdf2inventor,Wiki,urdf2inventor,A conversion from URDF 2 Inventor including a simple viewer.
W1127,https://wiki.ros.org/navigation,Wiki,navigation,"A 2D navigation stack that takes in information from odometry, sensor
        streams, and a goal pose and outputs safe velocity commands that are sent
        to a mobile base. 




 









Available Translations:  The Navigation Stack is fairly simple on a conceptual level. It takes in information from odometry and sensor streams and outputs velocity commands to send to a mobile base. Use of the Navigation Stack on an arbitrary robot, however, is a bit more complicated. As a pre-requisite for navigation stack use, the robot must be running ROS, have a  transform tree in place, and publish sensor data using the correct ROS . Also, the Navigation Stack needs to be configured for the shape and dynamics of a robot to perform at a high level. To help with this process, this manual is meant to serve as a guide to typical Navigation Stack set-up and configuration.  The following documentation assumes familiarity with the Robot Operating System. Documentation on ROS can be found here:  sensor_msgs/LaserScansensor_msgs/PointCloud"
W1128,https://wiki.ros.org/mrpt_msgs,Wiki,mrpt_msgs,"ROS messages for MRPT classes and objects
"
W1129,https://wiki.ros.org/industrial_core,Wiki,industrial_core,"ROS-Industrial core stack contains packages and libraries for supporing industrial systems


Use GitHub to . []
 This stack is part of the  program. It currently contains core packages that provide nodes and libraries for communication with industrial robot controllers.  It also includes utilities and tools that are useful for industrial robotics and automation applications. See the  page for an overview of the available tutorials. "
W1130,https://wiki.ros.org/rosgraph,Wiki,rosgraph,"rosgraph contains the rosgraph command-line tool, which prints
    information about the ROS Computation Graph. It also provides an
    internal library that can be used by graphical tools.

 is a console version of . It periodically displays information about your current graph in a text format. To use it, simply type: 
 
For a graphical version of , please see . The  package contains the  module, which implements a Python library for interacting with the low-level ROS Master API. For other Python libraries for interacting with the ROS graph, see , , , and . There are no plans to update the  tool at this time.  The Python API may expand as necessary to provide access to other ROS graph primitives, though those are currently covered by the , , and  libraries as well. rxgraphrxgraphrosgraphrosgraphrosgraphrosgraph.masterapirosgraph$ rosgraph"
W1131,https://wiki.ros.org/urdf_transform,Wiki,urdf_transform,"Provides a collection of functions which
      can be applied on a URDF traversed by urdf_traverser"
W1132,https://wiki.ros.org/nao_bringup,Wiki,nao_bringup,"Launch files and scripts needed to bring ROS interfaces for Nao up into a
      running state.


Before starting, please make sure you meet all the required dependencies especially the packages ,  and .  You can either install the official releases via your package manager or directly clone the necessary ros packages from github. Alternatively you can make use of the python SDK, which has to be installed and correctly setup in your PYTHONPATH environment variable. For more information on that, please refer to . $ roslaunch nao_bringup nao_full.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip>$ roslaunch nao_bringup nao_full_py.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip> "
W1133,https://wiki.ros.org/rosserial_tivac,Wiki,rosserial_tivac,"rosserial for TivaC Launchpad evaluation boards.
   

 will communicate either through UART0 or USB0: 
See also . This package contains all necessary extensions on  to bring two Tiva C Launchpad boards from  to ROS. All boards can use both debug USB and device USB to communicate with rosserial. Due to changes in USB library of TivaWare.  This package contains the prepares the required libraries for Energia's IDE and also prepares a build configuration for  packages based on  GNU compiler toolchain and TI's TivaWare libraries. The  page of this package will walk you through the steps for setting up your environment, and demonstrate how to develop applications, both for Energia and catkin. The SystemTick interrupt service must be available for  to use, so it can keep the execution time. After going through the  you should have understood that each project requires a  which calls the function  to prepare the build files. catkinarm-none-eabirosserial_tivacrosserial_tivacCMakeLists.txtgenerate_tivac_firmwareTIVA_WARE_PATHTIVA_FLASH_EXECUTABLETARGET_IS_TM4C123_RB1generate_tivac_firmware(
  USB
  STARTUP custom_startup.c
  SRCS buttons.cpp buttons.c
  INCS .
  BOARD tm4c123gxl
)"
W1134,https://wiki.ros.org/industrial_robot_simulator,Wiki,industrial_robot_simulator,"The industrial robot simulator is a stand in for industrial robot driver node(s).  It adheres to the driver specification for industrial robot controllers.




Use GitHub to . []
 This package simulates an industrial robot controller that adheres to the  driver specification.  Currently the simulator only supports the minimum .  The purpose of this node is to provide a simulated robot controller for development.  This simulator publishes standard topics that can be fed into  to create a realistic visualization of an actual robot cell.  Note that the simulation is at the ROS API level, the node does not accept Simple Message TCP/UDP connections. joint_path_commandjoint_statesfeedback_statescontroller_joint_namesstr[]initial_joint_statedouble[]motion_update_ratedoublepub_ratedoubleroslaunch industrial_robot_simulator robot_interface_simulator.launch "
W1135,https://wiki.ros.org/wheeled_robin_viz,Wiki,wheeled_robin_viz,"Catkin meta-package for wheeled_robin_viz

Use GitHub to . []
  Please refer main  page. "
W1136,https://wiki.ros.org/dataspeed_ulc_can,Wiki,dataspeed_ulc_can,Package to translate ROS messages to and from CAN messages to interact with the Universal Lat/Lon Controller (ULC) firmware
W1137,https://wiki.ros.org/blort_ros,Wiki,blort_ros,"

    BLORT - The Blocks World Robotic Vision Toolbox 
    ROS interface classes and nodes for the BLORT library.

      
 



 More information:  [] or you can also visit the . sudo apt-get install ros-hydro-perception-blortsudo apt-get install ros-hydro-pal-vision-segmentation"
W1138,https://wiki.ros.org/ur10_moveit_config,Wiki,ur10_moveit_config,"An automatically generated package with all the configuration and launch files for using the ur10 with the MoveIt Motion Planning Framework


This package is part of the  program. It is the ! configuration for the UR10 arm, generated automatically by the  Setup Assistant. Install the package from package management, and run the MoveIt! planning demo: This is not a real simulation, just a demonstration of the planning capability and the MoveIt! and RViz integration. For true simulation of a UR10, see the  package. See also the relevant sections in the  on Github. moveit_simple_controller_manager$ sudo apt-get install ros-$ROS_DISTRO-ur10-moveit-config

$ roslaunch ur10_moveit_config demo.launch"
W1139,https://wiki.ros.org/toposens_markers,Wiki,toposens_markers,"Rviz integration for TS sensor data.


ts_scansts_markers~frame_idstd_msgs/String~lifetimedouble~scaledouble"
W1140,https://wiki.ros.org/visp_auto_tracker,Wiki,visp_auto_tracker,"Online automated pattern-based object tracker relying on visual servoing.

    visp_auto_tracker wraps model-based trackers provided by ViSP visual
    servoing library into a ROS package. The tracked object should have a
    QRcode of Flash code pattern. Based on the pattern, the object is
    automaticaly detected. The detection allows then to initialise the
    model-based trackers. When lost of tracking achieves a new detection
    is performed that will be used to re-initialize the tracker.

    This computer vision algorithm computes the pose (i.e. position and
    orientation) of an object in an image. It is fast enough to allow
    object online tracking using a camera.



  
 is part of  stack.  



 centralises most of its parameters inside a configuration file following the  default format. 







 


 This package wraps an automated pattern barcode based tracker using  library. The tracker estimates the pattern position and orientation with respect to the camera. It requires the pattern 3d model and a configuration file. The package is composed of one node called .  This node tries to track the object as fast as possible. The viewer coming with  package can be used to monitor the tracking result. Currently the  package requires calibration information from a camera_info topic. To this end  package can be used. This is an example of a valid QR-code pattern that can be downloaded . This is an example of a valid flash-code pattern that can be downloaded . You can run  on a pre-recorded bag file that comes with the package, or on a live video from a camera. To run  on a pre-recorded image sequence, just run: The pattern used in this example can be downloaded . You have a ready-to-use roslaunch file in . This works with a firewire (1394) camera. If you have an usb camera (like a webcam) you can use  launch file. When set () this parameter activates the tracking lost detection and recovery using ,  and  point coordinates. When you track a model, you probably want a visual feedback. You can get one by connecting rviz to the outputed  topic.  does not have a dedicated viewer. It can use the viewer provided with  package, specifically  node. Without connecting another node, you can also open a debug graphical output directly from the  node by setting the  parameter. The following figure shows the debug output (left) next to the external /viewer (right) in the case of the hybrid model-based tracker with QR-code initialisation: Use GitHub to . visp_auto_trackerlaunch/tracklive_firewire.launchlaunch/tracklive_usb.launchdetector-type= zbardetector-type= dmtxtracker-type= 1flashcode-coordinatesinner-coordinatesouter-coordinates/object_positionvisp_tracker/visp_tracker_viewervisp_auto_trackerdebug_displayimage_rawcamera_infoobject_positionobject_position_covariancestatusmoving_edge_sitesklt_points_positionsmodel_pathstringmodel_namestringdebug_displaybooleansudo apt-get install ros-$ROS_DISTRO-visp-auto-trackersudo apt-get install ros-$ROS_DISTRO-vision-visproslaunch launch/tutorial.launchroslaunch launch/tracklive_firewire.launch#set the detector type: ""zbar"" to detect QR code, ""dmtx"" to detect flashcode
detector-type= zbar
#enable recovery mode when the tracker fails
ad-hoc-recovery= 1

#point 1
flashcode-coordinates= -0.024
flashcode-coordinates= -0.024
flashcode-coordinates= 0.000
#point 2
flashcode-coordinates= 0.024
flashcode-coordinates= -0.024
flashcode-coordinates= 0.000
#point 3
flashcode-coordinates= 0.024
flashcode-coordinates= 0.024
flashcode-coordinates= 0.000
#point 4
flashcode-coordinates= -0.024
flashcode-coordinates= 0.024
flashcode-coordinates= 0.000

#point 1
inner-coordinates= -0.038
inner-coordinates= -0.038
inner-coordinates= 0.000
#point 2
inner-coordinates= 0.038
inner-coordinates= -0.038
inner-coordinates= 0.000
#point 3
inner-coordinates= 0.038
inner-coordinates= 0.038
inner-coordinates= 0.000
#point 4
inner-coordinates= -0.038
inner-coordinates= 0.038
inner-coordinates= 0.000

#point 1
outer-coordinates= -0.0765
outer-coordinates= -0.0765
outer-coordinates= 0.000
#point 2
outer-coordinates= 0.0765
outer-coordinates= -0.0765
outer-coordinates= 0.000
#point 3
outer-coordinates= 0.0765
outer-coordinates= 0.0765
outer-coordinates= 0.000
#point 4
outer-coordinates= -0.0765
outer-coordinates= 0.0765
outer-coordinates= 0.000"
W1141,https://wiki.ros.org/maggie_motor_controller_msgs,Wiki,maggie_motor_controller_msgs,"motor_controller messages and servicesNewly proposed, mistyped, or obsolete package. Could not find package ""maggie_motor_controller_msgs"" in rosdoc: /home/rosbot/docs/api/maggie_motor_controller_msgs/manifest.yaml "
W1142,https://wiki.ros.org/stdr_robot,Wiki,stdr_robot,"Provides robot, sensor implementation, using nodelets for stdr_server to load them.

 



 () 
 ()  () 
 ()  () 





The  package implements a simulated robot, all simulated sensors and its simulated motion controller. Till now the following sensors are implemented: The robot class is available using the  interface, named . To load a new robot a  has to be running. New robots/nodelets can be loaded only from , using either  or command-line tools described below. A parser for YAML and XML files is also provided, to load or save robots, sensors etc. More details on how to use YAML and XML files with stdr_simulator .  A robot provides tf transforms for the pose of itself and its sensors. All transforms are relative to  frame. For more details about map tf frames see . An example with one spawned robot follows (using ): The  for each sensor is defined on loading a robot from GUI or when using a YAML/XML file to describe a sensor. Each sensor  has to have a unique name per robot. To avoid naming collisions with other robots it is also (automatically) prefixed with robot's name. Example: . Each robot provides a tf transform with its current pose. The  is automatically assigned and has the format . Example: . All topic names are prefixed with robot name. Example . All services are prefixed with the name . This is the name of the nodelet manager and should  change. With the  command-line tool you can add, delete and move a robot directly from the terminal. The following sections describe the available commands. For tutorials see . stdr_robotnodeletstdr_robot/Robotmap_staticrqt_tf_treeframe_idframe_idrobot0_laser_1frame_idrobot<ID>robot2robot1/cmd_velcmd_vel<laser_sensor_frame_id>robot0/laser_back<sonar_sensor_frame_id>robot0/sonar_2robot_managerload_nodeletunload_nodeletrobot_handleradd <description.yaml> <x> <y> <theta>robot_handlerdelete <robot_name>replace <robot_name> <new_x> <new_y> <new_theta>robot_handler$ rosrun stdr_robot robot_handler add resources/robots/khepera2.yaml 1.2 2 1.57$ rosrun stdr_robot robot_handler delete /robot2$ rosrun stdr_robot robot_handler replace /robot1 1.2 3 3.14"
W1143,https://wiki.ros.org/sdf_tracker,Wiki,sdf_tracker,"

     sdf_tracker

  


 
 

This package provides an implementation of the truncated Signed Distance Function tracking algorithm, proposed .  The initial starting point of the camera is at the center of the specified volume, looking along the z-axis. To change the initial camera pose, relative to the volume set the  parameter of the SDF_Parameter class and pass this to the constructor when initializing your SDFTracker, e.g.,  In the interactive mode, pressing  or  sets a flag to notify the node that it's time to shut down. Terminating the program with ctrl-C works, but will not output triangles.  export ROS_PACKAGE_PATH=/your_path/oru-ros-pkg/:$ROS_PACKAGE_PATHroscd sdf_tracker
rosmakeroslaunch openni_launch openni.launch &
rosrun sdf_tracker sdf_tracker_node _param1:=val1 _param2:=val2 ...etcrosrun sdf_tracker sdf_tracker_node _c_name:=""camera2"" _depth_registered:=""true"" _OutputTriangles:=""true"" _CellSize:=0.02 _GridSizeX:=300















"
W1144,https://wiki.ros.org/socketcan_interface,Wiki,socketcan_interface,"Generic CAN interface description with helpers for filtering and driver implementation. Further a socketcan implementation based on boost::asio is included.









 This packages provides a generic CAN interface class and a -based driver implementation. The listeners are based on   (since melodic) and use RAII-pointers. The SocketCAN driver interface is based on  and provides concurrent access to SocketCAN interfaces. It is the default CAN implementation used throughout ros_canopen and requires Linux kerner 2.6.25 or newer. The SocketCAN driver is exposed as ""can::SocketCANInterface"" with base class can::DriverInterface via . In addition the plugin library is announced to . Further options are availabe, please consult . For automatic set-up, the network can be configured in , e.g.: sudo modprobe peak_usb # kernel driver, since 3.11sudo modprobe peak_pci # kernel driversudo modprobe pcan # PEAK vendor driversudo modprobe esd_usb2 # kernel driversudo ip link set can0 up type can bitrate 500000 # adjust bitrate as neededallow-hotplug can0
iface can0 can static
    bitrate 500000
#    up ip link set $IFACE txqueuelen 20 # uncomment if more than 4 nodes are usedrosrun socketcan_interface socketcan_dump can0ip -details -statistics link show can0sudo apt-get install can-utils"
W1145,https://wiki.ros.org/nextage_moveit_config,Wiki,nextage_moveit_config,An automatically generated package with all the configuration and launch files for using the NextageOpen with the MoveIt Motion Planning Framework.
W1146,https://wiki.ros.org/rviz_fps_plugin,Wiki,rviz_fps_plugin,"The rviz_fps_plugin package contains an additional ViewController and a Tool Plugin to navigate RViz like an FPS-Shooter.

    To enable the tool press 'q' and enable the 'FPSMotion' ViewController. Use the 'wasd' keys for walking.
    By pressing 'f' one can switch between walk or fly mode. By pressing 'r' you can reset the view controller.
Use GitHub to . []
 "
W1147,https://wiki.ros.org/nextage_calibration,Wiki,nextage_calibration,"This package provides .launch files and other tools for
  calibrating the head-mount cameras to the NEXTAGE Open robot.
  As of version 0.7.15/March 2017, only Kinect/Xtion is capable (i.e. Ueye
  cameras, the ones the robot comes with on this head by default, are not yet
  handled).Some info on  about this package is available. "
W1148,https://wiki.ros.org/roshlaunch,Wiki,roshlaunch,"roshlaunch is a temporary package for redesigning roslaunch to have better programmatic APIs for libraries like rosh.
"
W1149,https://wiki.ros.org/svenzva_drivers,Wiki,svenzva_drivers,"The svenza_drivers package
 
 
/joint_statestfmoveit/revel/motor_state/svenzva_joint_action//revel/follow_joint_trajectory/revel/gripper_action//home_arm_service/revel/SetTorqueEnable/revel/gripper/insert_finger~data_frequencyint~modestruser_definedsvenzva_bringup.launchuser_definedvelocitygravitygravity/joint_statestfmoveit/revel/model_efforts"
W1150,https://wiki.ros.org/ros_tutorials,Wiki,ros_tutorials,"ros_tutorials contains packages that demonstrate various features of ROS,
    as well as support packages which help demonstrate those features.
 "
W1151,https://wiki.ros.org/moveit_ikfast,Wiki,moveit_ikfast,"Generates a IKFast kinematics plugin for MoveIt using OpenRave generated cpp files./!\:From ROS  onward, this package is renamed as . "
W1152,https://wiki.ros.org/rail_pick_and_place_msgs,Wiki,rail_pick_and_place_msgs,"Messages and Services for RAIL Pick and PlaceNewly proposed, mistyped, or obsolete package. Could not find package ""rail_pick_and_place_msgs"" in rosdoc: /home/rosbot/docs/api/rail_pick_and_place_msgs/manifest.yaml "
W1153,https://wiki.ros.org/wge100_camera_firmware,Wiki,wge100_camera_firmware,"Source for the WGE100 Ethernet camera: Verilog source for the
    FPGA, Forth source for the camera firmware.  Intended for camera
    developers.  Note that a built binary from this package is checked
    in under wge100_camera/firmware_images/

The Willow Garage 100 Mbps Ethernet (WGE100) camera is a 752x480 Ethernet camera developed for the PR2 robot.  This package contains the source code for the camera hardware and firmware.  If you want to develop or change the camera firmware, everything you need is in this package.  If you only want to use the WGE100 cameras, see package . The Verilog source for the camera firmware is under , with the main Makefile in .  You will need Xilinx ISE Webpack 11.1 or 11.3 to build the FPGA .bit file. The Forth source code for the  CPU is under , see  for build details.  You do not need the Xilinx tools to update the camera firmware. src/hardwaresrc/hardware/synth/Makefilesrc/firmwarereadme.txt"
W1154,https://wiki.ros.org/perception_blort,Wiki,perception_blort,"perception_blort
 Currently, BLORT makes use of GLSL (OpenGL Shading Language) and requires GPU in order to run the tracker node.  
  "
W1155,https://wiki.ros.org/rail_face_detector,Wiki,rail_face_detector,"This package provides face detection.










 This detector uses  to perform face detection. It publishes faces found in images from a subscribed image topic. The face detector itself can be found here: . This package contains a single ROS node -  - which serves as an interface between a ROS system and the trained face recognition network. Type:  Type:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  top_left_xtop_left_ybot_right_xbot_right_ynose_xnose_yleft_eye_xleft_eye_yright_eye_xright_eye_yleft_mouth_xleft_mouth_yright_mouth_xright_mouth_yface_detector_nodestring""/kinect/qhd/image_color_rect""boolfalsebooltrueboolfalse"
W1156,https://wiki.ros.org/rail_object_detection,Wiki,rail_object_detection,Object Detection methods used in the RAIL Lab
W1157,https://wiki.ros.org/vigir_pluginlib,Wiki,vigir_pluginlib,"The vigir_pluginlib package

 



 

 


: Ensure all above steps have been done right. Another very weird issue may arise if you try to load plugins from a package A which have been depended from another package B which exports plugins too. NEVER DO THAT!!! As the library from A may be linked into B, while loading library B the  may invoke all PLUGINLIB_EXPORT_CLASS macros from A too while being under the namespace of package B. This confuses the class_loaders as all plugins from A seems now to be part of package B. 
Use GitHub to . []
 The  is based on the exisiting  system. It extends the basic plugin system by a convenient plugin management tool which enables to gather specific plugins based on their provided functionality from a heterogeneous plugin database. Hereby the basic infrastructure remains identically to the original  system as the  is built on top. Using the  allows analogously to load classes from a runtime library (i.e. shared object, dynamically linked library) without the application having any prior awareness of the library or the header file containing the class definition (for details see the  documentation). The  uses the C++ RTTI mechanism to determine the functionality of each instantiated plugin based on implemented parent classes. This information helps the plugin manager to resolve any kind of plugin request done by the application during runtime and allows to manage a heterogeneous plugin database. For clarification, heterogeneous denotes indeed that you can load plugins of different type in one single manager and therefore have convenient centralized access to all your plugins no matter which interface they actually implement. If you need a plugin implementing a specific interface, then the plugin manager tries best effort to deliver them. Polymorphic plugins are indeed allowed, thus a single plugin may implement the interfaces of multiple interface plugins and still will be retrieved correctly. As an example use case for such kind of plugin system, please take a look at the  stack. The  class provides the low level basic functionality needed by the plugin manager. Therefore each new interface plugin must be derived from this class. See . See . Please take also a look at the . A Plugin Aggregator is a collector for a set of plugins implementing a specified interface and simplifies handling of such sets. It obtains automatically all plugins from the plugin manager and provides the option to update parameters of those plugins. The plain  class is ready for use, but may be extended as demonstrated  to perform accumulative operations using the plugins. The  comes with a  widget providing full access to all running plugin manager instance. The widget allows to  monitor the current state of all plugins and even to add and remove plugins during runtime. In  this widget is located in the  menu. Alternatively you can launch the standalone version: The  uses  under the hood where many magic is happening. This can cause many unforeseen issues. vigir_pluginlib::Pluginnamestringtype_class_packagestringtype_classstringbase_class_packagestringbase_classstringplugins->vigir_pluginlibMultiLibraryClassLoaderroslaunch vigir_pluginlib_manager plugin_mananger_rqt.launch[PluginManager] Plugin (thor_mang_step_plan_msg_plugin) of type_class 'thor_mang_footstep_planning::ThorMangStepPlanMsgPlugin' failed to load for some reason. Error: MultiLibraryClassLoader: Could not create object of class type thor_mang_footstep_planning::ThorMangStepPlanMsgPlugin as no factory exists for it. Make sure that the library exists and was explicitly loaded through MultiLibraryClassLoader::loadLibrary()"
W1158,https://wiki.ros.org/asr_fake_object_recognition,Wiki,asr_fake_object_recognition,"This package provides a 'perception algorithm'-independent simulation of 6-D object localization for 3D object search by a mobile robot: Based on the poses of the searched objects with respect to the current viewing frustum(s) of the robot, the detectability of the objects is estimated. 












This package offers two sets of parameters you can adjust, the static ones which you can set by adjusting the params.yaml file located in the param-directory of the package, and the dynamic ones which you can either set by adjusting the launch-file or during runtime by using . <Objects>
    <Object type=""Cup"" id=""011021054100"" mesh=""package://asr_object_database/rsc/databases/segmentable_objects/Cup/object.dae"" angles=""quaternion"">-1.2902,0.729374,0.755761,0.721985,-0.665815,-0.13442,0.131754 </Object>
    <Object type=""CoffeeBox"" id=""0"" mesh=""package://asr_object_database/rsc/databases/textured_objects/CoffeeBox/CoffeeBox.dae"" angles=""euler"">1.5,-0.5,1.5,90,0,0 </Object>
</Objects>roslaunch fake_object_recognition fake_object_recognition.launch"
W1159,https://wiki.ros.org/mqtt_bridge,Wiki,mqtt_bridge,"The mqtt_bridge package
 provides a functionality to bridge between ROS and MQTT in bidirectional.  uses ROS message as its protocol. Messages from ROS are serialized by json (or messagepack) for MQTT, and messages from MQTT are deserialized for ROS topic. So MQTT messages should be ROS message compatible. (We use  for message conversion.) 

mqtt_bridgemqtt_bridgerosbridge_library.internal.message_conversionmqtt_bridge_node"
W1160,https://wiki.ros.org/map_merger,Wiki,map_merger,"Map merger is a package to merge several maps on the fly to one global map, if possible
  




 


 
The map_merger node uses the  to distribute local maps, i.e., maps created by each robot, to other robots which attempt to merge other robots' local maps into their own to create a global map. The following picture shows a global map created by merging local maps of two robots.  Changes in local maps are detected by the map_merger node which then automatically distributes the changes in the network using the . Upon reception of map updates by other robots, the map_merger node integrates the update using an existing transformation. If no transformation is available, the remote map update is stored for later processing. Upon availability of a transformation, the remote map is merged into a robot's own map. The map_merger node regularly publishes the global map on a distinct topic (see below) to which other nodes are required to subscribe to in order to receive the global map. You may obtain the paper from  or search in  . mapodomcontrolmap_otherposition_other_robotsadhoc_communication/new_robotglobal_mapall_positionsmap_merger/logOutputmap_merger/transformPointadhoc_communication/get_neighborsadhoc_communication/send_controladhoc_communication/send_map_updateadhoc_communication/send_pointadhoc_communication/send_positionadhoc_communication/send_map~has_local_mapboolexchange_positionboolmax_size_map_partintseconds_pub_timerintseconds_send_timerintseconds_recompute_transformintmax_rotation_robotsdoublelocal_map_topicstringlocal_map_metadata_topicstringlocal_map_frame_idstringmap_topic_over_networkstringposition_local_robot_topicstringposition_other_robots_topicstringcontrol_topicstringrobot_prefixstringlog_pathstring@InProceedings{Andre2014,
  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},
  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},
  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},
  Year                     = {2014},
  Month                    = dec,
}"
W1161,https://wiki.ros.org/rail_manipulation_msgs,Wiki,rail_manipulation_msgs,Common Manipulation Messages and Services Used in RAIL Manipulation Packages
W1162,https://wiki.ros.org/rosjava_build_tools,Wiki,rosjava_build_tools,"Simple tools and catkin modules for rosjava development.package.xmlCMakeLists.txt> sudo apt-get install ros-hydro-rosjava-build-tools ros-hydro-rosjava-bootstrapcmake_minimum_required(VERSION 2.8.3)
project(rosjava_core)
find_package(catkin REQUIRED rosjava_build_tools)
# replace argument with another gradle target of your choice
catkin_rosjava_setup(publishMavenJavaPublicationToMavenRepository)
catkin_package()cmake_minimum_required(VERSION 2.8.3)
project(android_extras)
find_package(catkin REQUIRED rosjava_build_tools)
catkin_android_setup(assembleRelease uploadArchives)
catkin_package()> cd build
> make clean-gradle"
W1163,https://wiki.ros.org/myahrs_driver,Wiki,myahrs_driver,"myahrs_driver is a driver package for the WITHROBOT's myAHRS+. The myAHRS+ is a low cost high performance AHRS(Attitude Heading Reference System) with USB/UART/I2C interface. The myAHRS+ board contains a 3-axis 16-bit gyroscope, a 3-axis 16-bit accelerometer and a 3-axis 13-bit magnetometer. The driver should also work with USB port.

 
 






  This is a driver package for the WITHROBOT's  from  and  . The myAHRS+ is a low cost high performance AHRS(Attitude Heading Reference System) with USB/UART/I2C interface. The myAHRS+ board contains a 3-axis 16-bit gyroscope, a 3-axis 16-bit accelerometer and a 3-axis 13-bit magnetometer. The driver should also work with USB port. The myAHRS+ board used NED type. The myahrs_driver contained in this package converts to the frame conventions of ROS (use the east north up (ENU) convention and right hand rule) before publishing the msgs. The driver use the coordinate frame below. Please see  for more information. The myAHRS+ protocol can be found . The Forum for myAHRS+ user can be found . imu/data_rawimu/dataimu/magimu/temperature~portstring~baud_rateint~frame_idstring~parent_frame_id_string~linear_acceleration_stddevdouble~angular_velocity_stddevdouble~magnetic_field_stddevdouble~orientation_stddevdoublesudo apt-get install ros-indigo-myahrs-drivercd ~/catkin_ws/src
git clone https://github.com/robotpilot/myahrs_driver.git
cd ~/catkin_ws && catkin_makerosrun myahrs_driver myahrs_driver _port:=/dev/ttyACM0roslaunch myahrs_driver myahrs_driver.launch"
W1164,https://wiki.ros.org/ur_kin_py,Wiki,ur_kin_py,"Python wrappers for ur_kinematics
from ur_kin_py.kin import Kinematics
kin = Kinematics('ur5') # or ur10
print kin.forward([0.1]*6)"
W1165,https://wiki.ros.org/rail_segmentation,Wiki,rail_segmentation,"Segmentation Functionality from the RAIL Lab








The  package provides tabletop segmentation functionality given a point cloud.  It also allows for segmentation within a robot's coordinate frame, so that objects stored on a robot's platform can be segmented. To install the  package, you can install from source with the following commands: Segmentation zones can be defined in yaml config files, an example of which can be found in the config directory.  The  file defines a segmentation zone that will segment objects on horizontal surfaces anywhere above the level of the floor. Each resulting segmented object is represented by a   message, with the following data calculated and filled in: The  package can be launched by running the rail_segmentation node: rail_segmentationpoint_cloud_topic~/segmented_objectspoint_cloud_topic~point_cloud_topicrail_segmentation<~/point_cloud_topic parameter>~/segmented_objects~/segmented_table~/markers~/table_marker~/debug_pc~/debug_img~/segment~/segment_objects~/segment_objects_from_point_cloudpoint_cloud_topic~/clear~/remove_object~/calculate_features~/debugbool~/point_cloud_topicstring~/zones_configstring~/min_cluster_sizeint~/max_cluster_sizeint~/cluster_tolerancedouble~/use_colorbool~/crop_firstbool~/label_markersbool~/markers~/segmented_objectsrail_segmentationzones.yamlrail_segmentation




rosrun rail_segmentation rail_segmentation"
W1166,https://wiki.ros.org/uav_local_coverage,Wiki,uav_local_coverage,"A package that performs local coverage with an unmanned aerial vehicle (UAV).

 (, default: 1)  (, default: ) 


to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. single_target=trueuav_local_coverageidintegeroutputstringscreenscreenlogparamuav_local_coverage.yamluav_local_coverageuav_local_coveragesingle_targettrueuav_local_coverage/goaluav_local_coverage/resulttarget_foundsingle_targettrue~loop_ratereal~queue_sizeinteger~single_targetboolean~fov_horreal~fov_verreal~local_stepsintegerroslaunch uav_local_coverage uav_local_coverage.launch"
W1167,https://wiki.ros.org/carrot_planner,Wiki,carrot_planner,"This planner attempts to find a legal place to put a carrot for the robot to follow. It does this by moving back along the vector between the robot and the goal point.
 


 (, default: Resolution of the associated costmap) 
The  is a simple global planner that adheres to the  interface found in the  package and can be used as a global planner  for the  node. The planner takes a goal point from an external user, checks if the user-specified goal is in an obstacle, and if it is, it walks back along the vector between the user-specified goal and the robot until a goal point that is not in an obstacle is found. It then passes this goal point on as a plan to a local planner or controller. In this way, the carrot planner allows the robot to get as close to a user-specified goal point as possible. The  object exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: The C++  class adheres to the  interface found in the  package. For detailed documentation, please see . carrot_planner::CarrotPlannernav_core::BaseGlobalPlannercarrot_planner::CarrotPlannernav_core::BaseGlobalPlannercarrot_planner::CarrotPlanner~<name>/step_sizedouble~<name>/min_dist_from_robotdoublecarrot_planner::CarrotPlannernav_core::BaseGlobalPlanner









"
W1168,https://wiki.ros.org/shadow_robot_ethercat,Wiki,shadow_robot_ethercat,"
    This stack contains the drivers and the controllers for Shadow Robot's EtherCAT Hand.
  Our documentation can now be found on . "
W1169,https://wiki.ros.org/rwt_ros,Wiki,rwt_ros,The rwt_ros package
W1170,https://wiki.ros.org/spur_description,Wiki,spur_description,A package for storing 3D model of SPUR omni-directional mobile manipulator robot made at Tamagawa University.
W1171,https://wiki.ros.org/pr2_props,Wiki,pr2_props,"pr2_props is a package designed to be the first step towards replacing your real (or imaginary) friends with a robot. Robot gives you mad props yo. 





The goal of pr2_props, aside from just generally being awesome and making you feel good, is to demonstrate the PR2's ability to do dynamic human interaction. It has been designed to use low-latency real-time controller packages like  and  so that PR2 is capable of quickly and sensitively responding to a human slapping the robot's hand. Currently  supports 3 main behaviors: If you have not previously built the real-time controller libraries associated with the  package dependency it is important you build pr2_props prior to launching the robot. In the above commands the values inside () are optional. The robot is naturally right-handed if no hand is specified.  and  have the same effect.  explodeexplosionsudo apt-get install ros-<version>-pr2-props-stack svn co https://mediabox.grasp.upenn.edu/svn/penn-ros-pkgs/pr2_props_stack/trunk/pr2_props ~/ros/pr2_propsrosmake pr2_propsroslaunch pr2_props pr2_props.launchfor continuous repeating of different props:
rosrun  pr2_props run_all_props.sh 
or individually one-by-one:
rosrun pr2_props high_five (left/right/double)
rosrun pr2_props low_five (left/right)
rosrun pr2_props pound (left/right/double) (explode/explosion)
rosrun pr2_props repeat_high_five
rosrun pr2_props hug"
W1172,https://wiki.ros.org/ur_gazebo,Wiki,ur_gazebo,"Gazebo wrapper for the Universal UR5/10 robot arms.

 
 This package is part of the  program. See also the sections  and  in the  on Github. moveit_simple_controller_manager$ sudo apt-get install \
  ros-$ROS_DISTRO-ur-gazebo \
  ros-$ROS_DISTRO-ur5-moveit-config \
  ros-$ROS_DISTRO-ur-kinematics$ roslaunch ur_gazebo ur5.launch$ roslaunch ur5_moveit_config ur5_moveit_planning_execution.launch sim:=true$ roslaunch ur5_moveit_config moveit_rviz.launch config:=true"
W1173,https://wiki.ros.org/turtlebot3_automatic_parking_vision,Wiki,turtlebot3_automatic_parking_vision,"Package for TurtleBot3 automatic_parking which uses ar code. This example needs a printed ar code and a TurtleBot3. 


ar_pose_markercmd_vel"
W1174,https://wiki.ros.org/industrial_extrinsic_cal,Wiki,industrial_extrinsic_cal,"The industrial_extrinsic_cal package: This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status .



The  package provides a generic tool for calibrating sensors to a known reference frame.  It is relevant to anyone using a system in which the relative position(extrinsics) of multiple pieces of equipment must be determined. Common equipment examples include positioning systems(i.e. robots, cartesian gantries), measurement/sensor systems (i.e. camera(s), laser scanner/trackers, radio) and fixturing(accurately produced parts for referencing objects of interest). The industrial extrinsic calibration package depends on the google .  The steps below walk through a minimal installation of Ceres on Ubuntu 14.04 as required for this package, more detailed instructions or different Ubuntu versions can be found .  These instructions download and install dependencies from your home directory.  Once installed, these tarballs and directories can be deleted. Detailed design info can be found in this  presented at ROSCon 2014. industrial_extrinsic_calceresindustrial_extrinisc_calcd
wget https://github.com/gflags/gflags/archive/v2.1.2.zip
unzip v2.1.2.zip && rm v2.1.2.zip
cd gflags-2.1.2 && mkdir build && cd build
cmake .. -DBUILD_SHARED_LIBS=ON
make
sudo make installcd
wget https://github.com/google/glog/archive/v0.3.4.zip
unzip v0.3.4.zip && rm v0.3.4.zip
cd glog-0.3.4/
./configure --with-gflags=/usr/local/
make
sudo make installcd
wget https://github.com/ceres-solver/ceres-solver/archive/1.11.0.zip
unzip 1.11.0.zip && rm 1.11.0.zip
cd ceres-solver-1.11.0
mkdir build && cd build
cmake ..
make
sudo make install"
W1175,https://wiki.ros.org/turtlebot3_autorace_control,Wiki,turtlebot3_autorace_control,"TurtleBot3 AutoRace ROS package that controls TurtleBot3 Auto 



control/lanecontrol/max_velcmd_velodomcontrol/parking_startcontrol/cmd_velcontrol/parking_finished"
W1176,https://wiki.ros.org/explore_lite,Wiki,explore_lite,"Lightweight frontier-based exploration.Use GitHub to . []
 
 
 uses  for navigation. You need to run properly configured  node.   subscribes to a  and  messages to construct a map where it looks for frontiers. You can either use costmap published by  (ie. ) or you can use map constructed by mapping algorithm (SLAM). 



This package provides greedy frontier-based exploration. When node is running, robot will greedily explore its environment until no frontiers could be found. Movement commands will be send to . Unlike similar packages,  does not create its own costmap, which makes it easier to configure and more efficient (lighter on resources). Node simply subscribes to  messages. Commands for robot movement are send to  node. Depending on your environment you may achieve better results with either SLAM map or costmap published by . Advantage of  costmap is the inflation which helps to deal with some very small unexplorable frontiers. When you are using a raw map produced by SLAM you should set the  parameter to some reasonable number to deal with the small frontiers. For details on both setups check the  and  launch files. Before starting experimenting with  you need to have working  for navigation. You should be able to navigate with  manually through . Please refer to  for setting up  and the rest of the navigation stack with your robot. You should be also able to to navigate with  though unknown space in the map. If you set the goal to unknown place in the map, planning and navigating should work. With most planners this should work by default, refer to  if you need to setup this for  planner (but should be enabled by default). Navigation through unknown space is required for . If you want to use costmap provided by  you need to enable unknown space tracking by setting . If you have  configured correctly, you can start experimenting with . Provided  should work out-of-the box in most cases, but as always you might need to adjust topic names and frame names according to your setup. This package was developed as part of my bachelor thesis at  in Prague. This project was initially based on  package by Charles DuHadway. Most of the node has been rewritten since then. The current frontier search algorithm is based on  by Paul Bovbel. explore_liteexplore_liteexplore_lite<move_base>/global_costmap/costmapmove_basemove_basemin_frontier_sizeexplore.launchexplore_costmap.launchexplore_liteexplore_litetrack_unknown_space: trueexplore_liteexplore.launchmove_baseexplore_litecostmaptrack_unknown_space: truecostmap_updates~frontiers~robot_base_framestringbase_link~costmap_topicstringcostmap~costmap_updates_topicstringcostmap_updates~visualizeboolfalse~planner_frequencydouble1.0~progress_timeoutdouble30.0progress_timeout~potential_scaledouble1e-3~orientation_scaledouble0~gain_scaledouble1.0~transform_tolerancedouble0.3~min_frontier_sizedouble0.5global_framerobot_base_framemapbase_linkrobot_base_frameglobal_frameglobal_framecostmap_topic@masterthesis{Hörner2016,
  author = {Jiří Hörner},
  title = {Map-merging for multi-robot system},
  address = {Prague},
  year = {2016},
  school = {Charles University in Prague, Faculty of Mathematics and Physics},
  type = {Bachelor's thesis},
  URL = {https://is.cuni.cz/webapps/zzp/detail/174125/},
}"
W1177,https://wiki.ros.org/automotive_autonomy_msgs,Wiki,automotive_autonomy_msgs,"Messages for vehicle automation

Use GitHub to . []
  "
W1178,https://wiki.ros.org/sr_ronex_test,Wiki,sr_ronex_test,contains software tests that require RoNeX hardware.
W1179,https://wiki.ros.org/utexas_gdc,Wiki,utexas_gdc,"Simulation environment for the Gates Dell Complex of the
    University of Texas At Austin"
W1180,https://wiki.ros.org/dwa_local_planner,Wiki,dwa_local_planner,"This package provides an implementation of the Dynamic Window Approach to
        local robot navigation on a plane. Given a global plan to follow and a
        costmap, the local planner produces velocity commands to send to a mobile
        base. This package supports any robot who's footprint can be represented as
        a convex polygon or cicrle, and exposes its configuration as ROS parameters
        that can be set in a launch file. The parameters for this planner are also
        dynamically reconfigurable. This package's ROS wrapper adheres to the
        BaseLocalPlanner interface specified in the  package. 
  





 (, default: 2.5) 
 (, default: 0.05) 
 (, default: 1.7) 
 (, default: 32.0) 
 (, default: 0.05) 
 (, default: ) 



 The  package provides a controller that drives a mobile base in the plane.  This controller serves to connect the path planner to the robot.  Using a map, the planner creates a kinematic trajectory for the robot to get from a start to a goal location. Along the way, the planner creates, at least locally around the robot, a value function, represented as a grid map.  This value function encodes the costs of traversing through the grid cells.  The controller's job is to use this value function to determine dx,dy,dtheta velocities to send to the robot. The  object is a  for a  object that exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: There are a large number of ROS  that can be set to customize the behavior of the  wrapper. These parameters are grouped into several categories: robot configuration, goal tolerance, forward simulation, trajectory scoring, oscillation prevention, and global plan. Most of these parameters can also be changed using  to facilitate tuning the local planner in a running system. For C++ level API documentation on the  class, please see the following page:  The  provides implementations of the DWA and Trajectory Rollout algorithms described earlier. In order to use the  with ROS, please use the . It is not recommended to use the  on its own. For C++ level API documentation on the , please see the following page:  dwa_local_plannerdwa_local_planner::DWAPlannerROSdwa_local_planner::DWAPlannernav_core::BaseLocalPlannerdwa_local_planner::DWAPlannerROS~<name>/global_plan~<name>/local_planodomrobot_base_frameTrajectoryPlannerROS objectrobot_base_framedwa_local_planner::DWAPlannerROS~<name>/acc_lim_xdouble~<name>/acc_lim_ydouble~<name>/acc_lim_thdouble~<name>/max_trans_veldouble~<name>/min_trans_veldouble~<name>/max_vel_xdouble~<name>/min_vel_xdouble~<name>/max_vel_ydouble~<name>/min_vel_ydouble~<name>/max_rot_veldouble~<name>/min_rot_veldouble~<name>/yaw_goal_tolerancedouble~<name>/xy_goal_tolerancedouble~<name>/latch_xy_goal_tolerancebool~<name>/sim_timedouble~<name>/sim_granularitydouble~<name>/vx_samplesinteger~<name>/vy_samplesinteger~<name>/vth_samplesinteger~<name>/controller_frequencydouble~<name>/path_distance_biasdouble~<name>/goal_distance_biasdouble~<name>/occdist_scaledouble~<name>/forward_point_distancedouble~<name>/stop_time_bufferdouble~<name>/scaling_speeddouble~<name>/max_scaling_factordouble~<name>/publish_cost_gridbool~<name>/oscillation_reset_distdouble~<name>/prune_planbooltruebase_local_planner::TrajectoryPlannerROSdwa_local_planner::DWAPlannerdwa_local_planner::DWAPlannerdwa_local_planner::DWAPlannerdwa_local_planner::TrajectoryPlannerdwa_local_planner::DWAPlanner class










cost =
  path_distance_bias * (distance to path from the endpoint of the trajectory in meters)
  + goal_distance_bias * (distance to local goal from the endpoint of the trajectory in meters)
  + occdist_scale * (maximum obstacle cost along the trajectory in obstacle cost (0-254))"
W1181,https://wiki.ros.org/pose_base_controller,Wiki,pose_base_controller,"A node that provides the move_base action server interface, but instead of
    planning simply drives towards the target pose using a control-based
    approach."
W1182,https://wiki.ros.org/tuw_object_msgs,Wiki,tuw_object_msgs,"The tuw_object_msgs package. This pkg provides a set of messages used to detect, map and track objects of different types.

The  message is used to define the location and the quality of a detection. The msg also hold a shape field to define the real appearance of the object useful for debugging and visualization.  
Same a  with header information 
Same a  but with information about the pose uncertainty as covariance 
Same a   with header information 
The  message represents the result of a detector with the detector settings such as field of view, or noise model. 
The  message represents a map of objects and a result of filter (SLAM). It can also be used to publish a Feature map for a feature based self-localization.  "
W1183,https://wiki.ros.org/rosconsole,Wiki,rosconsole,"ROS console output library.  is a C++ package that supports console output and logging in . It provides a macro-based interface which allows both - and stream-style output. It also wraps , which supports hierarchical loggers, verbosity levels and configuration-files. 

 




 
 the default format (if the environment variable is not set) for Python is now the same as for C++. If you want to keep the previous format for backward compatibility you can set the following: 



 
  rosconsole also provides assertions, in : rosconsole will load a config file from  when it initializes. rosconsole also lets you define your own configuration file that will be used by log4cxx, defined by the ROSCONSOLE_CONFIG_FILE environment variable. Anything defined in this config file will  the default config file. ROS output is set to  and higher by default. For more detailed information on the config file, and log4cxx in general, please see the . If you want to include a custom configuration into a specific launch file, you can do so using the  of roslaunch. Rosconsole uses the ""ros"" logger as its root-level logger. All unnamed logging statements will be output to the ""ros.<package_name>"" logger. The named variations will output to ""ros.<package_name>.<name>"". There are a couple of defines that expose this: rosconsole provides a way to remove logging at compile time, though this should rarely be necessary. This is accomplished through the  define. Statements of a severity level lower than  will be compiled out. The options are: If you want to change the logger levels via a configuration file, please see the  section. To change the logger levels from C++, use . Example: If you change one of the 's verbosity levels after any logging statements using that logger, you  call . If you do not, logging statements that have already been hit once (and therefore initialized) may continue to print when they should not, and vice-versa. For examples of this behavior, please see the  file. rosconsole allows you to specify how you'd like its output to show up in the console output through the  environment variable.  The default is equivalent to: By invoking  in C++ the logging subsystem is shut down and therefore no more logging occurs. When  of a ROS application is fully buffered, for example in case when it is connected to a pipe, users may not see the output of the application until the buffer fills up. The user can force line buffering for ROS loggers that print to the console by setting the environment variable  to . Default value is . When set to  the flush is not triggered on every line and the default buffering scheme of  is used. rosconsoleprintfprintfROS_DEBUG(...)ROS_DEBUG_STREAM(args)ROS_DEBUG_NAMED(name, ...)ROS_DEBUG_STREAM_NAMED(name, args)ROS_DEBUG_COND(cond, ...)ROS_DEBUG_STREAM_COND(cond, args)ROS_DEBUG_COND_NAMED(cond, name, ...)ROS_DEBUG_STREAM_COND_NAMED(cond, name, args)ROS_DEBUG_ONCE(...)ROS_DEBUG_STREAM_ONCE(args)ROS_DEBUG_ONCE_NAMED(name, ...)ROS_DEBUG_STREAM_ONCE_NAMED(name, args)ROS_DEBUG_THROTTLE(period, ...)ROS_DEBUG_STREAM_THROTTLE(period, args)ROS_DEBUG_THROTTLE_NAMED(period, name, ...)ROS_DEBUG_STREAM_THROTTLE_NAMED(period, name, args)ROS_DEBUG_DELAYED_THROTTLE(period, ...)ROS_DEBUG_STREAM_DELAYED_THROTTLE(period, args)ROS_DEBUG_DELAYED_THROTTLE_NAMED(period, name, ...)ROS_DEBUG_STREAM_DELAYED_THROTTLE_NAMED(period, name, args)ROS_DEBUG_FILTER(filter, ...)ROS_DEBUG_STREAM_FILTER(filter, args)ROS_DEBUG_FILTER_NAMED(filter, name, ...)ROS_DEBUG_STREAM_FILTER_NAMED(filter, name, args)ros/assert.hROS_ASSERT(cond)ROS_ASSERT_MSG(cond, ...)ROS_BREAK()$ROS_ROOT/config/rosconsole.configROSCONSOLE_ROOT_LOGGER_NAMEROSCONSOLE_DEFAULT_NAMEROSCONSOLE_MIN_SEVERITYROSCONSOLE_MIN_SEVERITYROSCONSOLE_SEVERITY_DEBUGROSCONSOLE_SEVERITY_INFOROSCONSOLE_SEVERITY_WARNROSCONSOLE_SEVERITY_ERRORROSCONSOLE_SEVERITY_FATALROSCONSOLE_SEVERITY_NONEros::console::set_logger_level()Loggerros::console::notifyLoggerLevelsChanged()examples/example.cppROSCONSOLE_FORMATros_consoleros::console::shutdown();stdoutROSCONSOLE_STDOUT_LINE_BUFFERED100stdout




























# Set the default ros output to warning and higher
log4j.logger.ros=WARN
# Override my package to output everything
log4j.logger.ros.my_package_name=DEBUG<launch>
  <env name=""ROSCONSOLE_CONFIG_FILE""
       value=""$(find mypackage)/custom_rosconsole.conf""/>
  <node pkg=""mypackage"" type=""mynode"" name=""mynode"" output=""screen""/>
</launch>
#include <ros/console.h>
if( ros::console::set_logger_level(ROSCONSOLE_DEFAULT_NAME, ros::console::levels::Debug) ) {
   ros::console::notifyLoggerLevelsChanged();
}export ROSCONSOLE_FORMAT='[${severity}] [${time}]: ${message}'export ROSCONSOLE_FORMAT='[${severity}] [WallTime: ${time}]: ${message}'log4j.threshold=OFFexport ROSCONSOLE_STDOUT_LINE_BUFFERED=1"
W1184,https://wiki.ros.org/rosjava_bootstrap,Wiki,rosjava_bootstrap,"Bootstrap utilities for rosjava builds.
Please see . "
W1185,https://wiki.ros.org/moveit_msgs,Wiki,moveit_msgs,"Messages, services and actions used by MoveIt

"
W1186,https://wiki.ros.org/webrtc,Wiki,webrtc,"WebRTC Native API


A package that exports the  libraries for use by other packages. The  package does not export any include directories, libraries, or compiler options directly. This is because there are a substantial number of options and libraries that may cause issues with other libraries. Instead  exports a number of CMake variables that can be used. See  for example usage. webrtcwebrtc"
W1187,https://wiki.ros.org/turtlebot_arm_description,Wiki,turtlebot_arm_description,turtlebot_arm_description contains URDF files and meshes for the TurtleBot arm.
W1188,https://wiki.ros.org/stage_ros,Wiki,stage_ros,"This package provides ROS specific hooks for stage



  
 ()  ()  ()  ()  ()  () 

 (default: 0.2)  (default: true) 
 →   →   →   →  
The  node wraps the Stage 2-D multi-robot simulator, via libstage.  Stage simulates a world as defined in a  file.  This file tells stage everything about the world, from obstacles (usually represented via a bitmap to be used as a kind of background), to robots and other objects. The .world file syntax is documented in the  . stageros only exposes models created by a subset of the .world file syntax, specifically ,  and  models.  For examples, see the  directory in the  and  packages. If there is only one position model defined in the world file, all of these topics appear at the top namespace. However, if more than 1 position models exist, these topics are pushed down into their own namespaces, by prefixing the topics with  , e.g.,  etc. If there is only one position model defined in the world file, all of these topics appear at the top namespace. However, if more than 1 position models exist, these topics are pushed down into their own namespaces, by prefixing the topics with  , e.g.,  etc. The  topic gives simulated odometry, which is affected by settings in the .world file, which can change its origin and noise model (the transforms mentioned below use the same data); see the  for details on changing this behavior.  The   topic always provides a perfect, globally referenced pose for the robot in the simulation, independent of .world file settings.  The  data is intended for testing purposes; it should not be used in robot control loops (because it's unrealistic). Stage supports the use of ""controllers,"" which are chunks of code that control simulated robots from inside the simulator, instead of being on the other end of a ROS connection.  There are some situations in which it can be advantageous to use Stage controllers. For a discussion of when and how to use Stage controllers, see . stageros.worldworldstagestage_rosrobot_<i>/robot_0/cmd_velcmd_velrobot_<i>/robot_0/cmd_velodombase_scanbase_pose_ground_truthimagedepthcamera_infoodombase_pose_ground_truthbase_pose_ground_truth~base_watchdog_timeoutcmd_vel~is_depth_canonicalbase_linkbase_laserbase_footprintbase_linkodombase_footprintbase_linkcamerarosrun stage_ros stageros [-g runs headless] <world> [standard ROS args]"
W1189,https://wiki.ros.org/pr2_precise_trajectory,Wiki,pr2_precise_trajectory,"This does some precise trajectory stuff, I'm not really sure though. :D
"
W1190,https://wiki.ros.org/topic_tools,Wiki,topic_tools,"Tools for directing, throttling, selecting, and otherwise messing with
    ROS topics at a meta level. None of the programs in this package actually
    know about the topics whose streams they are altering; instead, these
    tools deal with messages as generic binary blobs. This means they can be
    applied to any ROS topic.
"
W1191,https://wiki.ros.org/aruco_mapping,Wiki,aruco_mapping,"This package allows user to create a map of Aruco markers in 2D or 3D space 
    and estimate full 6 DOF pose of the camera.









Use GitHub to . []
  Using  to estimate full 6 DOF position only by means of single calibrated camera is well known approach that has been utilized for quite a long time now. This package leverages basic  functionality and provides tools to create a map of detected markers in 2D/3D space. It is designed for scenarioand can be used for various navigation tasks for UAVs, UGVs, etc. In order to achieve successfull mapping, everytime when a new marker is detected, previous marker needs to be visible in the actual image to allow computing new marker's position. (See  for better understanding). Keep this principle in mind when placing markers in your environment and do not overdo their mutual distances. In order to to calibrate your camera and get results in INI format, we stongly suggest   package. Here is an example of launch file to run ,  driver and : In case you use other camera driver, remap  to your topic name. Do not forget to adopt ,  and other params to your setup. If everything is set and ready, launch the aruco_mapping by following command: If you are experiencing problems with basic aruco detector caused by lighting conditions (strong reflections, poor lighting, bad focus) try to include our  into your processing pipeline in order to improve the raw image. image_rawaruco_markersaruco_posescalibration_filestd_msgs/Stringnum_of_markersstd_msgs/UInt8marker_sizestd_msgs/Double64space_typestd_msgs/Stringroi_allowedstd_msgs/Boolroi_xstd_msgs/UInt8roi_ystd_msgs/UInt8roi_wstd_msgs/UInt8roi_hstd_msgs/UInt8worldcamera_pose# Prosilica camera intrinsics

[image]

width
2448

height
2050

[prosilica]

camera matrix
4827.93789 0.00000 1223.50000
0.00000 4835.62362 1024.50000
0.00000 0.00000 1.00000

distortion
-0.41527 0.31874 -0.00197 0.00071 0.00000

rectification
1.00000 0.00000 0.00000
0.00000 1.00000 0.00000
0.00000 0.00000 1.00000

projection
4827.93789 0.00000 1223.50000 0.00000
0.00000 4835.62362 1024.50000 0.00000
0.00000 0.00000 1.00000 0.00000<launch>

  <!-- RVIZ -->
  <node name=""rviz"" pkg=""rviz"" type=""rviz"" args=""-d $(find aruco_mapping)/launch/aruco_config.rviz"" />

   <!--   usb_cam node -->
  <node name=""usb_cam"" pkg=""usb_cam"" type=""usb_cam_node"" output=""screen"">
    <param name=""video_device"" value=""/dev/video0"" />
    <param name=""image_width"" value=""640"" />
    <param name=""image_height"" value=""480"" />
    <param name=""pixel_format"" value=""mjpeg"" />
    <param name=""camera_frame_id"" value=""usb_cam"" />
    <param name=""io_method"" value=""mmap""/>
  </node>

  <!-- ArUco mapping -->
  <node pkg=""aruco_mapping"" type=""aruco_mapping"" name=""aruco_mapping"" output=""screen"">
    <remap from=""/image_raw"" to=""/usb_cam/image_raw""/>

    <param name=""calibration_file"" type=""string"" value=""$(find aruco_mapping)/data/F100.ini""/>
    <param name=""num_of_markers"" type=""int"" value=""20"" />
    <param name=""marker_size"" type=""double"" value=""0.135""/>
    <param name=""space_type"" type=""string"" value=""plane"" />
    <param name=""roi_allowed"" type=""bool"" value=""false"" />
  </node>
</launch>roslaunch aruco_mapping aruco_mapping.launch"
W1192,https://wiki.ros.org/stereo_image_proc,Wiki,stereo_image_proc,"Stereo and single image rectification and disparity processing.stereo_image_procstereo_image_procstereo_image_procrostopic list | grep image_rawstereo_image_procstereo_image_procstereo_image_procstereoleftrightstereo/leftstereo/rightstereo/disparitystereo/points2leftrightleft/*right/*stereo_image_procimage_rawcamera_infoleft/image_rawleft/camera_inforight/image_rawright/camera_infoleft/image_monoleft/image_rectleft/image_colorleft/image_rect_colorright/image_monoright/image_rectright/image_colorright/image_rect_colordisparitypoints2pointspoints2~prefilter_sizeint~prefilter_capint~correlation_window_sizeint~min_disparityintmin_disparitymin_disparity~disparity_rangeintmin_disparity~uniqueness_ratiodoubleuniqueness_ratio > (best_match - next_match) / next_match~texture_thresholdint~speckle_sizeint~speckle_rangeint~approximate_syncbool~queue_sizeintstereo_image_procstereo_image_procstereo_image_procrostopic list | grep image_rawstereo_image_procstereo_image_procstereo_image_procstereoleftrightstereo/leftstereo/rightstereo/disparitystereo/points2leftrightleft/*right/*stereo_image_procimage_rawcamera_infoleft/image_rawleft/camera_inforight/image_rawright/camera_infoleft/image_monoleft/image_rectleft/image_colorleft/image_rect_colorright/image_monoright/image_rectright/image_colorright/image_rect_colordisparitypoints2pointspoints2~prefilter_sizeint~prefilter_capint~correlation_window_sizeint~min_disparityintmin_disparitymin_disparity~disparity_rangeintmin_disparity~uniqueness_ratiodoubleuniqueness_ratio > (best_match - next_match) / next_match~texture_thresholdint~speckle_sizeint~speckle_rangeint~approximate_syncbool~queue_sizeintstereo_image_procstereo_image_procleft/image_rectleft/camera_inforight/image_rectright/camera_infodisparity~approximate_syncbool~queue_sizeint~prefilter_sizeint~prefilter_capint~correlation_window_sizeint~min_disparityintmin_disparitymin_disparity~disparity_rangeintmin_disparity~uniqueness_ratiodoubleuniqueness_ratio > (best_match - next_match) / next_match~texture_thresholdint~speckle_sizeint~speckle_rangeint~approximate_syncbool~queue_sizeintleft/image_rect_colorleft/camera_inforight/camera_infodisparitypoints2~approximate_syncbool~queue_sizeintleft/image_rect_colorleft/camera_inforight/camera_infodisparitypoints~approximate_syncbool~queue_sizeintstereo_image_procstereo_image_procstereo_image_procrostopic list | grep image_rawstereo_image_procstereo_image_procstereo_image_procstereoleftrightstereo/leftstereo/rightstereo/disparitystereo/points2leftrightleft/*right/*stereo_image_procimage_rawcamera_infoleft/image_rawleft/camera_inforight/image_rawright/camera_infoleft/image_monoleft/image_rectleft/image_colorleft/image_rect_colorright/image_monoright/image_rectright/image_colorright/image_rect_colordisparitypoints2pointspoints2~prefilter_sizeint~prefilter_capint~correlation_window_sizeint~min_disparityintmin_disparitymin_disparity~disparity_rangeintmin_disparity~uniqueness_ratiodoubleuniqueness_ratio > (best_match - next_match) / next_match~texture_thresholdint~speckle_sizeint~speckle_rangeint~approximate_syncbool~queue_sizeintstereo_image_procstereo_image_procleft/image_rectleft/camera_inforight/image_rectright/camera_infodisparity~approximate_syncbool~queue_sizeint~prefilter_sizeint~prefilter_capint~correlation_window_sizeint~min_disparityintmin_disparitymin_disparity~disparity_rangeintmin_disparity~uniqueness_ratiodoubleuniqueness_ratio > (best_match - next_match) / next_match~texture_thresholdint~speckle_sizeint~speckle_rangeint~approximate_syncbool~queue_sizeintleft/image_rect_colorleft/camera_inforight/camera_infodisparitypoints2~approximate_syncbool~queue_sizeintleft/image_rect_colorleft/camera_inforight/camera_infodisparitypoints~approximate_syncbool~queue_sizeintimage_procstereo_image_procstereo_image_procstereo_image_procmanagerstring/my_managerrespawnboolleftstringrightstringstereo_image_proc/stereo/left/image_raw
/stereo/left/camera_info
/stereo/right/image_raw
/stereo/right/camera_info$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc$ rosrun image_view image_view image:=/stereo/left/image_rect_color$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color/stereo/left/image_raw
/stereo/left/camera_info
/stereo/right/image_raw
/stereo/right/camera_info$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc$ rosrun image_view image_view image:=/stereo/left/image_rect_color$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color/stereo/left/image_raw
/stereo/left/camera_info
/stereo/right/image_raw
/stereo/right/camera_info$ ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_image_proc$ rosrun image_view image_view image:=/stereo/left/image_rect_color$ rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color"
W1193,https://wiki.ros.org/polar_scan_matcher,Wiki,polar_scan_matcher,"
    A wrapper around Polar Scan Matcher by Albert Diosi and Lindsay Kleeman, used for laser scan registration.
     





 The  package is a wrapper around Polar Scan Matcher [1], courtesy of: Albert Diosi and Lindsay Kleeman 
 Intelligent Robotics Research Centre (IRRC) 
 Monash University 
  
 The package allows to scan match between consecutive  messages, and publish the estimated position of the laser as a  or a  transform. An estimation for theta can optionally be provided to improve accuracy, in the form of a . This message would typically be published by an IMU or other angular rate sensor. Alternatively, an estimation for x, y, and theta can optionally be provided to improve accuracy, in the form of a  transform. This transform would typically be published by an odometry system. This has not yet been tested. You can run the  on a pre-recorded bag file that comes with the package. First, make sure you have the  stack downloaded and installed by following the instructions . Please use our  to  or . psm_nodescanimuodometry_typeimupose2D~world_framestring""world""~base_framestring""base_link""~publish_tfbooltrue~publish_posebooltrue~odometry_typestringnonenoneimuimutfworldbase~min_valid_pointsint200~search_windowint40~max_errordouble0.20~max_iterationsint20~stop_conditiondouble0.01base_linklaseruse_odometryworldbase_linkpublish_tf

"
W1194,https://wiki.ros.org/vision_visp,Wiki,vision_visp,"Virtual package providing ViSP related packages.These packages depend on  package that corresponds to the  last stable release packaged for ROS. 











Get  stack: Use GitHub to . sudo apt-get install ros-$ROS_DISTRO-vision-vispmkdir -p ~/catkin_ws/src
cd ~/catkin_ws/src
catkin_init_workspace
cd ~/catkin_ws
catkin_makecd ~/catkin_ws/srcgit clone https://github.com/lagadic/vision_visp.gitcd vision_visp
git checkout $ROS_DISTROcd ~/catkin_ws
sudo rosdep init
rosdep update
rosdep install --from-paths src --ignore-src --rosdistro $ROS_DISTROcd ~/catkin_ws
catkin_make -j4 -DCMAKE_BUILD_TYPE=Releasecd ~/catkin_ws
catkin_make -j4 -DCMAKE_BUILD_TYPE=Release --pkg visp_trackerroslaunch visp_tracker tutorial.launch
roslaunch visp_auto_tracker tutorial.launch"
W1195,https://wiki.ros.org/thingmagic_usbpro,Wiki,thingmagic_usbpro,"ROS driver package for the thingmagic USB pro RFID reader.  The driver creates a node named /rfid_detector_node and 
publish all detected tags on the topic /RFID_detections as custom RFID_Detection messages.  The RFID_Detection messages have 4
fields: 
  epc:  A string containing the RFID tag identifier detected
  antenna:  8-bit integer containing the antenna number of the detection
  read_count:  8-bit integer containing the number of detections during the collection period
  rssi:  8-bit integer containing the RSSI value of the detection 

Uses the python wrapper for ThingMagic's Mercury API located here: https://github.com/gotthardp/python-mercuryapi"
W1196,https://wiki.ros.org/rc_tagdetect_client,Wiki,rc_tagdetect_client,"The ros client for roboception tag detection modules


 


 
Use GitHub to . []
  
See  and  for more details. This node provides ROS service calls and parameters for the  module. For detail description of the  module check the . hostdevice02912345:02912345use_cached_imagesforget_after_n_detectionsmax_corner_distancequalitydetect_inverted_tagspublish_visualizationdetectstart_continuous_detectionstop_continuous_detectionrosrun rc_tagdetect_client rc_april_node _host:=<sensor_ip>
rosrun rc_tagdetect_client rc_qr_node _host:=<sensor_ip>rosrun rc_tagdetect_client rc_april_node _device:=:<serial_number>
rosrun rc_tagdetect_client rc_qr_node _device:=:<serial_number>"
W1197,https://wiki.ros.org/roscpp_tutorials,Wiki,roscpp_tutorials,"This package attempts to show the features of ROS step-by-step,
    including using messages, servers, parameters, etc.
 contains a number of tutorial applications for programming with roscpp.  You can browse these tutorials by -ing to the  package, i.e. roscdroscpp_tutorialsNodeHandleNodeHandleroscd roscpp_tutorials"
W1198,https://wiki.ros.org/rosh_robot_plugins,Wiki,rosh_robot_plugins,"ROSH related packages. This is a temporary stack that is expected to go away after the Diamondback release. For C Turtle and Diamondback it provides a convenient way to install rosh until it is properly stabilized.
 is a Python-based shell and runtime environment for ROS.  It leverages the IPython shell environment to provide tab-completion introspection across various ROS APIs, like topics, services, parameters, and nodes.  It is similar to using tools like  and , but with Pythonic semantics and the convenience of a Python interpreter.  You can also develop ROS nodes using rosh, which we call ""roshlets"". 

 To get started, please see the  documentation. rosh_robot_plugins houses stacks related to the ""robot"" variant, which was introduced in . The robot variant focuses on on-robot capabilities, such as  and  libraries. "
W1199,https://wiki.ros.org/dataspeed_ulc_msgs,Wiki,dataspeed_ulc_msgs,ROS messages for interacting with the Universal Lat/Lon Controller (ULC)
W1200,https://wiki.ros.org/stereo_slam,Wiki,stereo_slam,"Stereo Slam stereo_slam is a ROS node to execute Simultaneous Localization And Mapping (SLAM) using only one stereo camera. The algorithm was designed and tested for underwater robotics. This node is based on the  library for graph optimization and uses the power of  to find loop closures between graph nodes. It uses a keyframe to multi-keyframe loop closing mechanism, based on keypoint clustering, to improve the SLAM corrections on feature-poor environments. See the documentation on . "
W1201,https://wiki.ros.org/turtlebot_interactive_markers,Wiki,turtlebot_interactive_markers,"Interactive control for the TurtleBot using RViz and interactive markers 



This  will walk you through using interactive markers to control the .  /turtlebot_node/cmd_vel~link_namestring~linear_scaledouble~angular_scaledouble"
W1202,https://wiki.ros.org/topics_rviz_plugin,Wiki,topics_rviz_plugin,Display topics values in a RViz pluginDocumentation is here:  
W1203,https://wiki.ros.org/nextage_ros_bridge,Wiki,nextage_ros_bridge,"A main ROS interface for developers and users of  dual-armed robot from Kawada Robotics Inc. Developers can build their own application that takes control over Nextage via this package. Interface for both ROS and  is provided.
 is a python class that functions as a programming interface for the robot users. As seen in the api document, it extends  class so that all the public methods are inherited from there on.   The reason  was created separately from  is because of the  design unique to  robot. NextageClientHIRONXDIO"
W1204,https://wiki.ros.org/explorer,Wiki,explorer,"The explorer package utilizes frontier based exploration for multi-robot systems. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration reducing exploration time.






 The  utilizes frontier based exploration to discover environments autonomously operating a distributed multi-robot system. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration which result in improvement of efficiency in terms of exploration time. The  comprises multiple functionalities to perform frontier based exploration. Frontier detection is utilized on local and global costmaps to further select navigation goals in the environment to proceed with exploration. The assignment of robots to goals is accomplished according to coordinated and uncoordinated exploration strategies being applied for the distributed multi-robot system. Auctioning thereby ensures negotiation among available goals to coordinate efficiently, distributing robots among the environment by minimizing the overall travel path. Additionally to frontier detection and selection, the  is concerned with navigation to goal points by incorporating a simple action client utilizing . You may obtain the paper from  or search in  . ~<name>/map_merger/global_map~<name>/base_scan~<name>/frontiers~<name>/visited_frontiers~<name>/negotiation_list~<name>/auction~<name>/all_positions~<name>/visitedfrontierPoints~<name>/goalPoint~<name>/frontierPoints~<name>/cluster_grid_~~<name>/adhoc_communication/send_frontier~<name>/adhoc_communication/send_auction~<name>/frontier_selectionint~<name>/local_costmap/widthint~<name>/number_unreachable_for_clusterint@InProceedings{Andre2014,
  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},
  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},
  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},
  Year                     = {2014},
  Month                    = dec,
}"
W1205,https://wiki.ros.org/nav2d_remote,Wiki,nav2d_remote,"This package is used to manually control a robot that uses the operator and
    navigator node from navigation_2d. Currently there is one node to control one
    robot with a joystick and one to control multiple robots in simulation.
    It can send commands directly to the operator or start and stop navigator actions."
W1206,https://wiki.ros.org/advanced_navigation_driver,Wiki,advanced_navigation_driver,"The Advanced Navigation driver package for ROS This example has been developed and tested using Ubuntu Linux v16.04 LTS and ROS Lunar. Installation instructions for ROS can be found here: . If you require any assistance using this code, please email  . "
W1207,https://wiki.ros.org/reemc_description,Wiki,reemc_description,"This package contains the description (mechanical, kinematic, visual,
      etc.) of the REEM-C robot.  The files in this package are parsed and used by
      a variety of other components.  Most users will not interact directly
      with this package."
W1208,https://wiki.ros.org/slam_karto,Wiki,slam_karto,"This package pulls in the Karto mapping library, and provides a ROS
     wrapper for using it. 



Part of the documentation is available in the previously maintained . Use github to . slam_kartotfscanmap_metadatamapvisualization_marker_arraydynamic_map~odom_framestring""odom""~map_framestring""map""~base_framestring""base_link""~throttle_scansint~map_update_intervalfloat~resolutionfloat~deltafloat~transform_publish_periodfloat0~use_scan_matchingbool~use_scan_barycenterbool~minimum_travel_distancedouble~minimum_travel_headingdouble~scan_buffer_sizeint~scan_buffer_maximum_scan_distancedouble~link_match_minimum_response_finedouble~link_scan_maximum_distancedouble~loop_search_maximum_distancedouble~do_loop_closingbool~loop_match_minimum_chain_sizeint~loop_match_maximum_variance_coarsedouble~loop_match_minimum_response_coarsedouble~loop_match_minimum_response_finedouble~correlation_search_space_dimensiondouble~correlation_search_space_resolutiondouble~correlation_search_space_smear_deviationdouble~loop_search_space_dimensiondouble~loop_search_space_resolutiondouble~loop_search_space_smear_deviationdouble~distance_variance_penaltydouble~angle_variance_penaltydouble~fine_search_angle_offsetdouble~coarse_search_angle_offsetdouble~coarse_angle_resolutiondouble~minimum_angle_penaltydouble~minimum_distance_penaltydouble~use_response_expansionbool<the frame_id of the incoming scans>base_linktfbase_linkodommapodom"
W1209,https://wiki.ros.org/ethercat_hardware,Wiki,ethercat_hardware,"Package for creating a hardware interface to the robot using the EtherCAT motor controller/driver




 

 
  will respond with: 
The  package's primary purpose is to provide a library for communicating with motor controller boards.  However, the package does provide the  command-line tool for configuring these boards.  In practice, this tool is used during robot assembly, and should not be needed after initial bring-up of the robot.   When running motorconf, you must specify the interface used to communicate with the EtherCAT devices.  Without any additional arguments,  will enumerate all of the EtherCAT devices it can find. In order to program an unconfigured device, or re-program a device, you must specify a name, motor type, and board type for this motor.  If the name given (using the  option) matches one of the names in the actuators configuration file (, by default), then the motor type and board type will be selected automatically.  The motor type can be specified explicitly with the  option, and the board type can be specified with the  option.  A list of valid actuator names and motor types can be found with the  option.  In addition to the name, motor, and board types,  needs to know which device in the EtherCAT chain to program.  The device number is specified with the  option.  Finally, the  option tells  to actually program the board.  The following example programs device #2 to be the : actuators.conf is an XML file that specifies the motor parameters and common motor names to be programmed into the motor controller boards.  The file consists of a single <configuration> section.  The <configuration> section contains two subsections: <motors> and <actuators>. The <motors> subsection contains a series of <motor> definitions.  Each motor requires a  attribute.  The <motor> also requires child elements <params> and <encoder>.  The <params> element contains the following attributes: The <encoder> element contains the following attributes: The <actuators> subsection contains a series of <actuator> definitions.  An <actuator> has the following attributes: For example, the following <actuator> definition states that the  should be configured with the motor parameters specified in the previous example: ethercat_hardwarediagnosticsaccelerometerpressuremotors_haltedethercat_hardwaremotorconfmotorconfmotorconf-nactuators.conf-m-b-hmotorconf-d-pmotorconfbr_caster_r_wheel_motormotorconfUsage: ./motorconf [options]
 -i, --interface <i>    Use the network interface <i>
 -a, --actuators <file> Get the actuator definitions from file (default: actuators.conf)
 -d, --device <d>       Select the device to program
 -b, --board <b>        Set the expected board type (wg005, wg006, wg021)
 -p, --program          Program a motor control board
 -n, --name <n>         Set the name of the motor control board to <n>
 -m, --motor <m>        Set the configuration for motor <m>
 -h, --help             Print this message and exit# ./motorconf -i ecat0

[DEBUG] 1263333387.377268000: Device #00: WG014 (0x67d616)
[DEBUG] 1263333387.419128000: Device #01: WG014 (0x67d616)
[DEBUG] 1263333387.462366000: Device #02: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1399
[DEBUG] 1263333387.463359000:             Serial #: 01399
[DEBUG] 1263333387.465986000:             Name: br_caster_r_wheel_motor
[DEBUG] 1263333387.509329000: Device #03: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1414
[DEBUG] 1263333387.510322000:             Serial #: 01414
[DEBUG] 1263333387.512832000:             Name: br_caster_l_wheel_motor
 .
 . 
 .
[DEBUG] 1263333388.293608000: Device #20: WG05 (0x67d60d) Firmware Revision 1.20, PCB Revision F.02, Serial #: 1695
[DEBUG] 1263333388.294604000:             Serial #: 01695
[DEBUG] 1263333388.297113000:             Name: laser_tilt_mount_motor./motorconf -i ecat0 -n br_caster_r_wheel_motor -d 2 -p[ INFO] 1263334127.577301000: Programming device 2, to be named: br_caster_r_wheel_motor  <!-- Elbow, shoulder, spine -->
  <!-- http://pr.willowgarage.com/wiki/HardwareComponents/Motors?action=AttachFile&do=get&target=maxonRE40.pdf -->
  <motor name=""148877"">
    <params make=""Maxon""
            model=""148877""
            max_current=""3.12""
            speed_constant=""158""
            resistance=""1.16""
            motor_torque_constant=""0.0603"" />
    <encoder pulses_per_revolution=""1200"" reduction=""-1""/>
  </motor>  <actuator name=""l_elbow_flex_motor"" motor=""148877"" board=""wg005""/>"
W1210,https://wiki.ros.org/move_slow_and_clear,Wiki,move_slow_and_clear,"move_slow_and_clear 



 (, default: 0.5) 
The  is a simple recovery behavior that clears information in the  and then limits the speed of the robot. Note, this recovery behavior is not truly safe, the robot may hit things, it'll just happen at a user-specified speed. Also, this recovery behavior is only compatible with local planners that allow maximum speeds to be set via  such as the . The  object exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. The C++  class adheres to the  interface found in the  package. For detailed documentation, please see . move_slow_and_clear::MoveSlowAndClearmove_slow_and_clear::MoveSlowAndClearnav_core::RecoveryBehavior~<name>/clearing_distancedouble~<name>/limited_trans_speeddouble~<name>/limited_rot_speeddouble~<name>/limited_distancedouble~<name>/planner_namespacestringmax_trans_velmax_rot_velmove_slow_and_clear::MoveSlowAndClearnav_core::RecoveryBehavior"
W1211,https://wiki.ros.org/v4r_ellipses,Wiki,v4r_ellipses,"The v4r_ellipses package contains a computer vision library which is able to detect ellipses within images.  
    The package is able to estimate the pose of the circle related to the ellipse the circle diameter as well as the camera parameter are known.
    A dynamic reconfigure interface allows the user to tune the parameter of the system to ones needs.
    But be aware that the pose of a projected circle within a image (ellipse) has two solutions and only one is published as TF.
    A costom message (v4r_msgs) publishes all the data as well as the pose ambiguity.

 Chen2004) Chen, Q.; Wu, H. & Wada, T. Pajdla, T. & Matas, J. (Eds.) Camera Calibration with Two Arbitrary Coplanar Circles Computer Vision - ECCV 2004, Springer Berlin Heidelberg, 2004, 3023, 521-532,   rosrun v4r_ellipses v4r_ellipses_node image:=/camera/image_raw camera_info:=/camera/camera_inforosrun rqt_reconfigure rqt_reconfigure"
W1212,https://wiki.ros.org/libsick_ldmrs,Wiki,libsick_ldmrs,"A library for communication with the SICK LD-MRS series of laser scanners.

Use GitHub to . []
  This package contains a library for communicating with the SICK LD-MRS line of laser scanners. For a ROS wrapper, see . "
W1213,https://wiki.ros.org/pr2_moveit_plugins,Wiki,pr2_moveit_plugins,PR2 specific plugins for MoveIt
W1214,https://wiki.ros.org/jsk_common_msgs,Wiki,jsk_common_msgs,Metapackage that contains commonly used messages for jsk-ros-pkg
W1215,https://wiki.ros.org/svenzva_simulation,Wiki,svenzva_simulation,"Files relating to running 3D simulations of Svenzva manipulators



 
 
This package contains relevant files for running Svenzva robots in 3D simulations. Currently supported simulations are through Gazebo, !, or both Gazebo and Moveit!.  For control of robot arms in simulation we use  plugins for Gazebo.  This provides software level controllers for each joint which likely will not translate 1-1 on the real robot.  Tips on tuning PID parameters for  can be found on Gazebo's  plugin page (located ) under the section ""Tuning PID Parameters"". The tutorial for 3D simulations using Gazebo and/or  can be found at  ros_controlros_controlros_controlros_control/revel/effort_joint_trajectory_controller/follow_joint_trajectory/goal/revel/effort_joint_trajectory_controller/gains/joint_1/parameter_descriptions/revel/effort_joint_trajectory_controller/gains/joint_2/parameter_descriptions/revel/effort_joint_trajectory_controller/gains/joint_3/parameter_descriptions/revel/effort_joint_trajectory_controller/gains/joint_4/parameter_descriptions/revel/effort_joint_trajectory_controller/gains/joint_5/parameter_descriptions/revel/effort_joint_trajectory_controller/gains/joint_6/parameter_descriptions/revel/effort_joint_trajectory_controller/follow_joint_trajectory/feedback/revel/effort_joint_trajectory_controller/follow_joint_trajectory/result/svenzva_controllers/joint_1/command/svenzva_controllers/joint_1/pid/parameter_descriptions/svenzva_controllers/joint_2/command/svenzva_controllers/joint_2/pid/parameter_descriptions/svenzva_controllers/joint_3/command/svenzva_controllers/joint_3/pid/parameter_descriptions/svenzva_controllers/joint_4/command/svenzva_controllers/joint_4/pid/parameter_descriptions/svenzva_controllers/joint_5/command/svenzva_controllers/joint_5/pid/parameter_descriptions/svenzva_controllers/joint_6/command/svenzva_controllers/joint_6/pid/parameter_descriptions/svenzva_controllers/joint_1/state/svenzva_controllers/joint_2/state/svenzva_controllers/joint_3/state/svenzva_controllers/joint_4/state/svenzva_controllers/joint_5/state/svenzva_controllers/joint_6/state"
W1216,https://wiki.ros.org/phidgets_ir,Wiki,phidgets_ir,"

     Driver for the Phidgets IR.

  
 
 The  package contains a  ROS driver for the  device. The driver does not publish any data in ROS, but can be used as an example or adapted. Please submit your tickets through  (requires github account) or by emailing the maintainers. "
W1217,https://wiki.ros.org/rc_visard,Wiki,rc_visard,"Roboception rc_visard support meta package
 is a meta package of the ROS interface for the   3D sensor.    contains the packages  and . 
The  is the world’s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. The  package contains xacro and urdf files for the two baseline versions of the  (, ). The  is the official ROS driver for the  which provides ROS parameters (configuration), ROS services (control of s dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF). Purchase one of the rc_visard variants available right now and continue with the : "
W1218,https://wiki.ros.org/sr_gazebo_plugins,Wiki,sr_gazebo_plugins,"
    Gazebo Plugins for various Shadow Robot-specific sensors and actuators on the robot.
  "
W1219,https://wiki.ros.org/rsv_balance_desktop,Wiki,rsv_balance_desktop,"Visualization and HMI packages for RoboSavvy's balancing platform
   roslaunch rsv_balance_viz view_model.launch  roslaunch rsv_balance_viz view_robot.launch"
W1220,https://wiki.ros.org/world_canvas_server,Wiki,world_canvas_server,"Storage manager and server for WCF semantic maps.


get_annotationsget_annotations_datapub_annotations_datadelete_annotationssave_annotations_datalist_worldsset_keywordset_relationshipreset_databaseyaml_importyaml_exportlist_mapspublish_mapdelete_maprename_mapsave_mapdynamic_map~start_map_manager~last_map_id~last_map_id~auto_save_map"
W1221,https://wiki.ros.org/summit_x_common,Wiki,summit_x_common,"The summit_x_common package
 

This package contains the different controllers and launch files for the , shared for real robot and simulation.  "
W1222,https://wiki.ros.org/svenzva_ros,Wiki,svenzva_ros,"The svenzva_ros meta-package


Source code is available on  which also contains instructions for installation and compilation. General tutorials, guides and discussions on implementation can be found on the svenzva_ros . "
W1223,https://wiki.ros.org/tf_remapper_cpp,Wiki,tf_remapper_cpp,"More efficient version of tf/tf_remap able to handle TFs at kHz with tens of subscribers.









This package is an alternative to official ROS node  with the following advantages: /tf_staticnew/tf_old/tf/tf/tf_old/map/ugv1/map/ugv2/map/global_maptftf_remapper_cpplibtf_remapper_cpp.somappingsarray of dicts[{""old"": ""b"", ""new"": ""d""}]oldnewrosrunrosparam set /tf_remapper/mappings '[{""old"": ""b"", ""new"": ""d""}]'static_tfboolnew_tf_topic_namenew_tf_topic_nametf_static/tf_staticstatic_tfTrueFalseold_tf_topic_namestring'/tf_old'new_tf_topic_namestring'/tf'is_bidirectionalboolFalseTrue/tf_oldold_tf_topic_nametf2_ros/TFMessage/tfnew_tf_topic_nameis_bidirectional == Truetf2_ros/TFMessage/tf_old/tfnew_tf_topic_nametf2_ros/TFMessage/tf_oldold_tf_topic_nameis_bidirectional == Truetf2_ros/TFMessage/tf<launch>
    <group>
        <remap from=""tf"" to=""tf_old"" />
        <!-- The tf(1) static_transform_publisher does not use /tf_static, but periodically publises to /tf -->
        <node name=""broadcaster_ab"" pkg=""tf"" type=""static_transform_publisher"" args=""1 2 3 4 5 6 a b 10""/>
        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->
    </group>

    <node name=""remapper"" pkg=""tf_remapper_cpp"" type=""tf_remap"">
        <rosparam param=""mappings"">[{old: b, new: c}]</rosparam>
    </node>

    <!-- This node will see transform a->c -->
    <node name=""my_node"" pkg=""my_pkg"" type=""node_type"" />
</launch><launch>
    <group>
        <remap from=""tf_static"" to=""tf_static_old"" />
        <!-- The tf2 static_transform_publisher uses /tf_static -->
        <node name=""broadcaster_ab"" pkg=""tf2_ros"" type=""static_transform_publisher"" args=""1 2 3 4 5 6 a b""/>
        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->
    </group>

    <node name=""remapper"" pkg=""tf_remapper_cpp"" type=""tf_remap"">
        <rosparam param=""mappings"">[{old: b, new: c}]</rosparam>
        <!--<param name=""static_tf"" value=""true"" />  - this is not needed, autodetection works in this case -->
    </node>

    <!-- This node will see static transform a->c -->
    <node name=""my_node"" pkg=""my_pkg"" type=""node_type"" />
</launch><launch>
    <group>
        <remap from=""tf"" to=""tf_old"" />
        <!-- The tf(1) static_transform_publisher does not use /tf_static, but periodically publises to /tf -->
        <node name=""broadcaster_ab"" pkg=""tf"" type=""static_transform_publisher"" args=""1 2 3 4 5 6 a b 10""/>
        <!-- Usually, there would be e.g. a rosbag play instead of the static tf publisher. -->
            
        <!-- This node will see transforms a->b and d->e -->
        <node name=""my_node2"" pkg=""my_pkg"" type=""node_type"" />
    </group>

    <node name=""remapper"" pkg=""tf_remapper_cpp"" type=""tf_remap"">
        <rosparam param=""mappings"">[{old: b, new: c}, {old: e, new: f}]</rosparam>
        <param name=""is_bidirectional"" value=""true"" />
    </node>

    <!-- This node will see transforms a->c and d->f -->
    <node name=""my_node"" pkg=""my_pkg"" type=""node_type"" />
        
    <node name=""broadcaster_df"" pkg=""tf"" type=""static_transform_publisher"" args=""1 2 3 4 5 6 d f 10""/>
</launch>"
W1224,https://wiki.ros.org/rotunit_snapshotter,Wiki,rotunit_snapshotter,"This modul can be used to assemble a point cloud from a rotating laserscanner.
 "
W1225,https://wiki.ros.org/toposens,Wiki,toposens,"ROS support for Toposens 3D Ultrasound sensors.
 
 


ROS packages for  These packages support the  ultrasonic sensor by Toposens. Use the ROS Answers forum for questions and tag with : Use the issue tracker in the  repository to report bugs or submit feature requests: toposens"
W1226,https://wiki.ros.org/rtt_geometry,Wiki,rtt_geometry,"This metapackage contains tools for integrating the Orocos Kinematics and
    Dynamics Library (KDL) with the Orocos Toolchain and Real-Time Toolkit
    (RTT). 




  sudo aptitude install ros-electric-rtt-geometrygit clone http://git.mech.kuleuven.be/robotics/rtt_geometry.git
rosmake rtt_geometry"
W1227,https://wiki.ros.org/rosparam,Wiki,rosparam,"rosparam contains the rosparam command-line tool for getting and
    setting ROS Parameters on the  using YAML-encoded files. It also contains an
    experimental library for using YAML with the Parameter
    Server. This library is intended for internal use only.

    rosparam can be invoked within a  file.
 uses a 1-to-1 correspondence between  types and YAML types. For example: 








 is a stable command-line tool within the ROS core toolchain. No major feature development is currently scheduled for this tool. 
YAML is a lightweight markup language that supports all parameter types. For more on YAML, see . For tips on entering YAML in at the command-line, please see the  guide. YAML dictionaries can occur as the argument to the  and  commands of .  Dictionaries in this context are interpreted differently from namespace dictionaries that are set as the value of a parameter (e.g. from a C++ or Python node). Instead of  a parameter namespace, dictionaries  are unpacked into individual parameters to be set on the Parameter Server. Thus,  dictionaries can be thought of as  new values to a parameter namespace. The  tag enables the use of the  tool for loading and dumping parameters encoded in YAML files.  The  tag can be put inside of a  tag, in which case the parameter is treated like a . The  tool enables command-line setting and getting of parameters as well as loading and dumping  state to a file. The currently supported commands are: Command-line arguments to rosparam obey the  environment variable (see ). Parameter names that are not globally specified are resolved with respect to . NOTE:  and  are essentially the same command, as are  and , with the only difference being whether or not a file is used. rosparamloadsetrosparamrosparamrosparampirosparamrosparamROS_NAMESPACEROS_NAMESPACEgetdumpsetloadlistlist <namespace>get <parameter-name>-p-vset <parameter-name> [parameter-value]parameter-value--textfile--binfile-v-t <text_file>, --textfile <text_file>-b <binary_file>, --binfile <binary_file>delete <parameter-name>-vdump <file>dump <file> <namespace>-vload <yaml-file> [namespace][namespace]/-vrosparamstring: 'foo'
integer: 1234
float: 1234.5
boolean: true
list: [1.0, mixed list]
dictionary: {a: b, c: d}angle1: rad(2*pi)
angle2: deg(180)angle1: !degrees 181.0
angle2: !radians 3.14169rosparam set    set parameter
rosparam get    get parameter
rosparam load   load parameters from file
rosparam dump   dump parameters to file
rosparam delete delete parameter
rosparam list   list parameter names$ rosparam list$ rosparam list /namespace$ rosparam get parameter_name$ rosparam set parameter_name value$ rosparam set /foo ""['1', 1, 1.0]""$ rosparam set /gains ""p: 1.0
i: 1.0
d: 1.0""$ rosparam delete parameter_name $ rosparam dump dump.yaml$ rosparam dump dump.yaml /namespace$ rosparam dump -v gains.yaml /gains
dumping namespace [/gains] to file [gains.yaml]
/gains/i=1.0
/gains/p=1.0
/gains/d=1.0$ rosparam load dump.yaml"
W1228,https://wiki.ros.org/tf2_kdl,Wiki,tf2_kdl,"KDL binding for tf2


 Please see the  for use. "
W1229,https://wiki.ros.org/ur_description,Wiki,ur_description,"URDF description for Universal UR5/10 robot arms

This package is part of the  program.  To view and manipulate the arm models in , install the package from package management and launch the following: You should see an rviz window showing the UR5 in a lying-down position, and a separate window where the joint values may be manually specified. Note that this is not a simulation, just a visualization of the arm model. To simulate UR5 or UR10, see . roslaunch ur_description ur5_upload.launch
roslaunch ur_description test.launch"
W1230,https://wiki.ros.org/multi_level_map_msgs,Wiki,multi_level_map_msgs,multi_level_map_msgs
W1231,https://wiki.ros.org/wheeled_robin_driver,Wiki,wheeled_robin_driver,"Driver for WheeledRobin
 This is a generic driver for . Port of pyrobot.py by Damon Kohler and  by OSRF. For ROS bindings, please see . "
W1232,https://wiki.ros.org/universal_teleop,Wiki,universal_teleop,"Allows keyboard/joystick control of any robot by means of geometry_msgs::Twist messages


joykeyboard/key_upkeyboard/key_downrobot/cmd_veleventscontrols"
W1233,https://wiki.ros.org/rqt_ez_publisher,Wiki,rqt_ez_publisher,"The rqt_ez_publisher package




  






 2. run as plugin of  Plugins -> Topics -> Easy Message Publisher Input topic name -> You got GUI A. Click ""config (gear) icon"" -> set repeat interval [ms] $ sudo apt-get install ros-indigo-rqt-ez-publisher$ sudo apt-get install ros-hydro-rqt-ez-publisher$ rosrun rqt_ez_publisher rqt_ez_publisher$ rqtqt_gui_main() found no plugin matching ""rqt_ez_publisher""$ rm ~/.config/ros.org/rqt_gui.ini"
W1234,https://wiki.ros.org/qb_device_srvs,Wiki,qb_device_srvs,"This package contains the device-independent custom ROS services for qbrobotics® devices.
Each  device-independent custom ROS service is documented directly in its  specification and it is designed to fit the Communication Handler requirements (cf. ). We recommend not to use these services for other purposes outside the  ecosystem. .srv"
W1235,https://wiki.ros.org/rsv_balance_gazebo,Wiki,rsv_balance_gazebo,"Gazebo's specific packages for RoboSavvy's balance platform.
 



 This package provides all the necessary URDF model extensions, worlds and launch files for successfully simulating 's self-balance platform. On  package we have available 3 worlds: rsv_balance_gazeboempty.worldramp.worldterrain.world/cmd_vel/tilt_equilibrium/odom/state/joint_states/tf/set_mode/set_input/reset_odom/reset_overriderobotNamespacestrcommandTopicstrpublishOdomTFboolbaseFrameIdstrodomFrameIdstrodomSourcestrodomTopicstrpublishWheelJointStateboolstartModestrpublishStateboolpublishStateRateintupdateRateint roslaunch rsv_balance_gazebo simulation_empty.launch roslaunch rsv_balance_gazebo simulation_ramp.launch roslaunch rsv_balance_gazebo simulation_terrain.launchroslaunch rsv_balance_gazebo view.launch





















"
W1236,https://wiki.ros.org/applanix_msgs,Wiki,applanix_msgs,"
    ROS messages which represent the serialized wire messages and groups of Applanix devices.
  "
W1237,https://wiki.ros.org/pr2_teleop,Wiki,pr2_teleop,"The pr2_teleop package


 

  







Note: before moving the robot base, you may want to . As with all applications, you must first . Before use, the PS3 controller must be ""paired"" with the robot. If your controller is not already paired, you can pair it by pressing the center button, shown in the image.  If you need to pair a new PS3 controller to the PR2 (i.e. not the controller that came with it), see . Note: The , , , and  buttons are all labeled on the controller.  Now you should be able to control the robot base with keyboard commands in the shell where you ran the above  command.   roslaunch pr2_teleop teleop_joystick.launchroslaunch pr2_teleop teleop_keyboard.launch"
W1238,https://wiki.ros.org/bwi_guidance_concert,Wiki,bwi_guidance_concert,"Wraps a Human-Robot Interaction Experiment conducted at the
    University of Texas At Austin to use the Robotics in Concert Framework. The
    results from this experiment were reported in the following symposium
    paper: Piyush Khandelwal and Peter Stone. Multi-robot Human Guidance using
    Topological Graphs. In AAAI Spring 2014 Symposium on Qualitative
    Representations for Robots (AAAI-SSS), March 2014.






The  package wraps this experiment to use the  framework. This package currently wraps preliminary work on this project, where a central positioner node teleports each robot to a desired location using Gazebo's  service. Additionally, each robot subscribes to an image stream which is displayed on its simulated robot screen (ex. '/robot1/image'), and these images are also published by the positioner. Apart from the positioner node, an experiment controller node decides which exact problem the user is facing, and a server node keeps track of which user is interfacing with the system. A user controls a human avatar inside the simulator using a web based GUI that talks to the rest of the system using . Once you get to the  page, follow the instructions to run through the experiment! bwi_guidance_concertset_model_state/var/wwwindex.htmlsudo apt-get install apache2- git: {local-name: segbot_rocon, uri: 'https://github.com/utexas-bwi/segbot_rocon.git', version: master}
- git: {local-name: bwi_guidance, uri: 'https://github.com/utexas-bwi/bwi_guidance.git', version: master}
- git: {local-name: rl_pursuit, uri: 'https://github.com/utexas-bwi/rl_pursuit.git', version: master}
- git: {local-name: rosbridge_suite, uri: 'https://github.com/piyushk/rosbridge_suite.git', version: patch-1}sudo ln -sf `rospack find bwi_guidance`/www /var/www/exp1roscd bwi_guidance_solver/data/exp2/cache
wget http://cs.utexas.edu/~piyushk/share/vi.tar.gz
tar xvzf vi.tar.gz
rm vi.tar.gzroslaunch bwi_guidance_solver server.launch --screenrocon_launch bwi_guidance_concert guidance.concert --screenhttp://localhost/exp1/index.htmlhttp://robot-devil.csres.utexas.edu/exp1/index.html?host=robot-devil.csres.utexas.eduhttp://robot-devil.csres.utexas.edu/exp1/index.html?host=robot-devil.csres.utexas.edu&concert=truehttp://robot-devil.csres.utexas.edu/exp1/link.html"
W1239,https://wiki.ros.org/fake_localization,Wiki,fake_localization,"A ROS node that simply forwards odometry information.

The  package provides a single node, , which substitutes for a localization system, providing a subset of the ROS API used by . This node is most frequently used during simulation as a method to provide perfect localization in a computationally inexpensive manner. Specifically,  converts odometry data into pose, particle cloud, and transform data of the form published by . fake_localizationfake_localizationfake_localizationfake_localizationbase_pose_ground_truthinitialposeamcl_poseparticlecloud~odom_frame_idstring""odom""~delta_xdoublefake_localization~delta_ydoublefake_localization~delta_yawdoublefake_localization~global_frame_idstringglobal_frame_idodom_frame_id~base_frame_idstring/map<value of odom_frame_id parameter>"
W1240,https://wiki.ros.org/tuw_msgs,Wiki,tuw_msgs,"The tuw_msgs meta package

Use GitHub to . []
  "
W1241,https://wiki.ros.org/rwt_image_view,Wiki,rwt_image_view,The rwt_image_view package
W1242,https://wiki.ros.org/multimaster_fkie,Wiki,multimaster_fkie,"The metapackage to combine the nodes required to establish and manage a multimaster network. 
    This requires no or minimal configuration. The changes are automatically detected and synchronized.  - Technical Report by Sergi Hernandez Juan and Fernando Herrero Cotarelo 
 "
W1243,https://wiki.ros.org/rosparam_handler,Wiki,rosparam_handler,An easy wrapper for using parameters in ROS.
W1244,https://wiki.ros.org/ddwrt_access_point,Wiki,ddwrt_access_point,"
    A ROS node that controls a Linksys WRT610Nv2 access point with
    a dd-wrt firmware. Other access points models/dd-wrt versions
    may be compatible as long as the web interface is identical.
  
Provides a node for controlling a Linksys WRT610Nv2 (or compatible) access point with the  firmware. It has been tested with the firwmare version . Other dd-wrt firmware versions and access point models may be compatible with this node provided the web interface is the same. See  and  for more details. "
W1245,https://wiki.ros.org/sr_communications,Wiki,sr_communications,"communications for the Social Robots robots

"
W1246,https://wiki.ros.org/libsensors_monitor,Wiki,libsensors_monitor,"A ROS node for using libsensors to provide diagnostics information about the sensors on a computer system.


/diagnostics~ignore_sensorsstring[]"
W1247,https://wiki.ros.org/rail_mesh_icp,Wiki,rail_mesh_icp,"Enables matching a mesh model file (e.g. STL) to a point cloud using ROS.






  
 The intended use for  is to allow RGBD sensing platforms using ROS to match a mesh model (e.g. an STL file) to point clouds. This is useful in cases where an accurate estimate of the model's 6-DoF pose in the point cloud is needed (e.g. grasping/manipulation). To install the  package, you can install from source with the following commands: can read the file format and convert it to a point cloud. In Ubuntu, [Mesh Lab]() allows  you to import many mesh model formats (e.g. STL, PLY, DAE) and convert them to PLY via the  and   options. [INPUT_MESH_MODEL].ply [OUTPUT_POINT_CLOUD].pcd-h`. rail_mesh_icptemplate_matcher_nodeicp_matcher_node<~/pcl_topic parameter>~/template_points~/target_points~/matched_template_points~/match_template~/debugbool~/matched_template_points~/visualizebool~/template_frame~/pcl_topicstring~/pre_processed_cloud~/pre_processed_cloudbooltarget_cloud~/match_template~/pcl_topic~/template_filestringcad_models~/matching_framestring~/initial_estimate_stringstring~/matching_framelatch_initial~/latch_initialbool~/initial_estimate_stringinitial_estimate~/match_template~/template_offset_stringstring~/template_framestring~/visualizeicp_matcher_node/icp_match_clouds/icp_matcher_node/iterationsint/icp_matcher_node/max_distancefloat/icp_matcher_node/trans_epsilonfloat/icp_matcher_node/fit_epsilonfloatmesh_sampler_node-hrail_mesh_icp.plyImport MeshExport Mesh. Optional arguments, like sampling density, are detailed using .pcdcad_modelscorner.pcdcad_modelstemplate_match_demo.launchroslaunch fetchit_challenge main.launchroslaunch fetch_navigation build_map.launchrosrun teleop_twist_keyboard teleop_twist_keyboard.py/head_camera/depth_registered/pointsroslaunch rail_mesh_icp template_match_demo.launchtemplate_matcher_nodecornericp_matcher_nodeinitial_estimatetemplate_matcher_nodeinitial_estimateinitial_estimatetemplate_match_demo.launchstatic_transform_publisherrosservice call /template_matcher_demo_node/match_templatetemplate_posetemplate posetemplate_offsetdebugtarget_pointstemplate_pointsmatched_template_pointstemplate_match_demo.launchinitial_estimatetemplate_offsetprovide_processed_cloudlatch_initial_estimatetemplate_filenameinitial_estimate~match_template



"
W1248,https://wiki.ros.org/rospy_tutorials,Wiki,rospy_tutorials,"This package attempts to show the features of ROS python API step-by-step,
    including using messages, servers, parameters, etc. These tutorials are compatible with the nodes in roscpp_tutorial.
rospy_tutorials is a series of tutorials for using the  client API. You can browse these tutorials by -ing to the  package, i.e. roscdrospy_tutorialsMakefileroscd rospy_tutorials"
W1249,https://wiki.ros.org/xbot_face,Wiki,xbot_face,"The xbot_face package

 
 
face_recog/xbot/camera/image/xbot/face_resultcamera_image_publisher/xbot/camera/image/xbot/camera/image"
W1250,https://wiki.ros.org/rtt_ros_comm,Wiki,rtt_ros_comm,"The rtt_ros_comm package 




  sudo aptitude install ros-electric-rtt-ros-commgit clone http://git.mech.kuleuven.be/robotics/rtt_ros_comm.git
rosmake rtt_ros_comm"
W1251,https://wiki.ros.org/tedusar_cartesian_controller,Wiki,tedusar_cartesian_controller,A controller for ros_control enabling moving an arm's tool frame in a cartesian coordinate frame.
W1252,https://wiki.ros.org/laser_joint_processor,Wiki,laser_joint_processor,"Computes joint angles associated with a specific set of detected checkerboard corners.
     This package is experimental and unstable.
     Expect its APIs to change.
"
W1253,https://wiki.ros.org/rtt_ros_integration,Wiki,rtt_ros_integration,"This stack contains all software necessary to build systems using both Orocos and ROS infrastructuresrosrun rtt_ros_integration create_rtt_msgs MyPkg  <depend package=""rtt_MyPkg""/>#include <MyPkg/typekit/MsgName.h>import(""OrocosPkg"")var ConnPolicy cp;
cp.transport = 3; // ROS == 3
cp.name_id = ""/topic_name""; // ros topicstream(""YourComponentName.YourRTTPortName"", cp ) <simple name=""Import"" type=""string""><value>rtt_ros_integration</value></simple>
<struct name=""ROSConMsg"" type=""ConnPolicy"">
  <simple name=""transport"" type=""short""><value>3</value></simple><!-- 3 means ROS --/>
  <simple name=""name_id"" type=""string""><value>topic_name</value></simple>
</struct><struct name=""Ports"" type=""PropertyBag"">
  <simple name=""YourRTTPortName"" type=""string""><value> RosConMsg </value></simple>
</struct>rosrun rtt_ros_integration create_rtt_msgs MyPkg  <depend package=""rtt_MyPkg""/>#include <MyPkg/typekit/MsgName.h>import(""OrocosPkg"")var ConnPolicy cp;
cp.transport = 3; // ROS == 3
cp.name_id = ""/topic_name""; // ros topicstream(""YourComponentName.YourRTTPortName"", cp ) <simple name=""Import"" type=""string""><value>rtt_ros_integration</value></simple>
<struct name=""ROSConMsg"" type=""ConnPolicy"">
  <simple name=""transport"" type=""short""><value>3</value></simple><!-- 3 means ROS --/>
  <simple name=""name_id"" type=""string""><value>topic_name</value></simple>
</struct><struct name=""Ports"" type=""PropertyBag"">
  <simple name=""YourRTTPortName"" type=""string""><value> RosConMsg </value></simple>
</struct>sudo aptitude install ros-electric-rtt-ros-integrationgit clone http://git.mech.kuleuven.be/robotics/rtt_ros_integration.git
rosmake rtt_ros_integrationrosrun rtt_rosnode rtt-upgrade-2.5 <package_dir>rosrun rtt_rosnode create_rtt_msgs MyPkg  <depend package=""rtt_MyPkg""/>#include <MyPkg/typekit/MsgName.h>rosrun ocl orocreate-pkg my_component_pkg component
cd my_component_pkg
rosmakerosrun ocl deployer-gnulinux [-s scriptname.ops]import(""rtt_rosnode"") // makes this process a ROS node
import(""my_component_pkg"")
loadComponent(""YourComponentName"",""My_component_pkg"")
// See DeploymentComponent Manual for creating a component using 'loadComponent'stream(""YourComponentName.YourRTTPortName"", ros.topic(""/topic_name"")) rosrun ocl deployer-gnulinux -s xmlfile.xml<simple name=""Import"" type=""string""><value>rtt_rosnode</value></simple>
<simple name=""Import"" type=""string""><value>my_component_pkg</value></simple>
<struct name=""ROSConMsg"" type=""ConnPolicy"">
  <simple name=""transport"" type=""short""><value>3</value></simple><!-- 3 means ROS --/>
  <simple name=""name_id"" type=""string""><value>topic_name</value></simple>
</struct><struct name=""Ports"" type=""PropertyBag"">
  <simple name=""YourRTTPortName"" type=""string""><value> RosConMsg </value></simple>
</struct>sudo apt-get install ros-fuerte-rtt-ros-integrationgit clone http://git.mech.kuleuven.be/robotics/rtt_ros_integration.git -b fuerte
rosmake rtt_ros_integrationrosrun rtt_rosnode create_rtt_msgs MyPkg  <depend package=""rtt_MyPkg""/>#include <MyPkg/typekit/MsgName.h>rosrun ocl orocreate-pkg my_component_pkg component
cd my_component_pkg
rosmakerosrun ocl deployer-gnulinux [-s scriptname.ops]import(""rtt_rosnode"") // makes this process a ROS node
import(""my_component_pkg"")
loadComponent(""YourComponentName"",""My_component_pkg"")
// See DeploymentComponent Manual for creating a component using 'loadComponent'stream(""YourComponentName.YourRTTPortName"", ros.topic(""/topic_name"")) rosrun ocl deployer-gnulinux -s xmlfile.xml<simple name=""Import"" type=""string""><value>rtt_rosnode</value></simple>
<simple name=""Import"" type=""string""><value>my_component_pkg</value></simple>
<struct name=""ROSConMsg"" type=""ConnPolicy"">
  <simple name=""transport"" type=""short""><value>3</value></simple><!-- 3 means ROS --/>
  <simple name=""name_id"" type=""string""><value>topic_name</value></simple>
</struct><struct name=""Ports"" type=""PropertyBag"">
  <simple name=""YourRTTPortName"" type=""string""><value> RosConMsg </value></simple>
</struct>"
W1254,https://wiki.ros.org/speech_recognition_msgs,Wiki,speech_recognition_msgs,speech_recognition_msgs
W1255,https://wiki.ros.org/toposens_sync,Wiki,toposens_sync,"Operational sync of multiple TS sensors.


This package enables simultaneous use of multiple TS3 devices in a sensor system. It administers the lifecycle and ultrasonic emission characteristics of each sensor to coordinate incoming datastreams. Is is designed as a thin layer handling multiple ::Sensor instances that individually encapsulate all the device communication and logic flow. ts_scans~portsXmlRpc::XmlRpcValue~frame_idsXmlRpc::XmlRpcValue"
W1256,https://wiki.ros.org/turtlebot_calibration,Wiki,turtlebot_calibration,"turtlebot_calibration


To use this package please follow the  "
W1257,https://wiki.ros.org/asr_grid_creator,Wiki,asr_grid_creator,"This package can generate a grid for the current map. Each grid_point
    defines a position where the robot has to move to. The grid can be used
    later on in the asr_direct_search_manager as a basis to generate poses to
    search the map. At each grid_point the robot will search around him. All
    gird_points together should cover the map. 

 




 (MarkerArray): Visualisation of the grid 

 The path to a file where the generated grid should be saved 
 the width of the grid  the hieght of the grid !: the shape of each  It can be Hex or Quad !: if the generated positions should make a  or not : start postition of the robot (for sorting the postitions) 

roslaunch asr_robot_model_services RobotModelServiceSim.launch !: the size of each cell or rather the half of the distance between two neighbors of  : horizontal translation offset applied to the grid : vertical translation offset applied to the grid : rotation offset applied to the grid The () defines the ranges in which the generation took place. The best one will be saved at the end. The best grid is the one with the most . asr_robot_model_services: , GetDistance The generation of the grid is part of the . "
W1258,https://wiki.ros.org/toposens_msgs,Wiki,toposens_msgs,"ROS message definitions for TS sensors.

"
W1259,https://wiki.ros.org/khi_robot_control,Wiki,khi_robot_control,ROS KHI robot controller package based on ros_control
W1260,https://wiki.ros.org/phantomx_reactor_arm,Wiki,phantomx_reactor_arm,"The phantomx_reactor_arm package
 


This package contains the different controllers and description files for  "
W1261,https://wiki.ros.org/pi_trees,Wiki,pi_trees,"Behavior Trees for ROS


Use GitHub to . []
  A Python implementation for using Behavior Trees and ROS for task management.  Please see the  or the book """". $ sudo apt-get install graphviz-dev libgraphviz-dev python-pygraph python-pygraphviz gv
$ cd ~/catkin_ws/src
$ git clone https://github.com/pirobot/pi_trees.git
$ cd ..
$ catkin_make"
W1262,https://wiki.ros.org/rcll_ros,Wiki,rcll_ros,"ROS packages related to RoboCup Logistics League (metapackage)This is a meta package covering the ROS packages related to the  and the . 
This metapackage pulls the  and  packages. 
You might also want to have a look at the simulation integration package . "
W1263,https://wiki.ros.org/ros_opcua_impl_freeopcua,Wiki,ros_opcua_impl_freeopcua,"The ros_opcua_impl_freeopcua package implements bindings for freeopcua - Open Source C++ OPC-UA Server and Client Library.





Use GitHub to . []
  This package provides communication interface between ROS and  communication standard using  written in C++. This package currently implements an OPC UA Client with basic functionality. For more details see the node description. Check the  page. connectdisconnectslist_nodecall_methodreadwritesubscribeunsubscriberoslaunch ros_opcua_impl_freeopcua clinet.launch"
W1264,https://wiki.ros.org/moveit_full,Wiki,moveit_full,All MoveIt components and plugins
W1265,https://wiki.ros.org/unique_id,Wiki,unique_id,"ROS Python and C++ interfaces for universally unique identifiers.
This package provides Python and C++ interfaces for , as described in . "
W1266,https://wiki.ros.org/abb_moveit_plugins,Wiki,abb_moveit_plugins,"
    ABB-specific plugins for MoveIt
  
This package is part of the  program.  "
W1267,https://wiki.ros.org/object_recognition_tabletop,Wiki,object_recognition_tabletop,A port of the old tabletop object recognition
W1268,https://wiki.ros.org/segbot_gui,Wiki,segbot_gui,"Displays a simple GUI to the user. The GUI is capable of displaying a simple
    message or image to the user, and ask a question. The message and question
    plugins are also written in this package."
W1269,https://wiki.ros.org/fawkes_msgs,Wiki,fawkes_msgs,"Messages used by Fawkes to interact with ROS.


This package contains the message types specific to the integration with the . It is used in several of the . It is used, for example, for the  for ROS. "
W1270,https://wiki.ros.org/vrpn_client_ros,Wiki,vrpn_client_ros,"ROS client nodes for the  library, compatible with VICON, OptiTrack, and other .

To debug connection issues, try to use 's CLI tools, such as , to verify that a connection to the Tracker object of interest can be established. If you cannot get this to work, note that debugging networking or VRPN issues is outside the scope of this ROS interface package, and see  for further guidance. Please check the  for common problems, or open an  if still unsolved. See sample configuration launch file . vrpnvrpn_print_devices <tracker_name>@<vrpn_server><tracker name>/pose<tracker name>/twist<tracker name>/accel~update_frequencydouble~refresh_tracker_frequencydouble~trackers~trackerslist~refresh_tracker_frequency~frame_idstring~use_server_timebool~broadcast_tfbool/tf"
W1271,https://wiki.ros.org/turtlebot_arm_moveit_demos,Wiki,turtlebot_arm_moveit_demos,The turtlebot_arm_moveit_demos package contains scripts to start playing with a turtlebot arm and MoveIt.
W1272,https://wiki.ros.org/socketcan_bridge,Wiki,socketcan_bridge,"Conversion nodes for messages from SocketCAN to a ROS Topic and vice versa.




The packages provides functionality to expose CAN frames from  to a ROS Topic. Internally it uses the  from the  package, as such it is capable of dealing with both normal and extended CAN frames. For more information and hardware related information see . The functionality is offered in the form of three nodes: ,  and . To receive frames from and sent frames to the same CAN device, the  needs to be used to prevent every sent message from being echoed to the receiving topic. socketcan_bridge_nodesocketcan_to_topic_nodetopic_to_socketcan_nodesocketcan_bridge_nodesent_messagesreceived_messages~can_devicestringreceived_messages~can_devicestringsent_messages~can_devicestringros::Time::now()"
W1273,https://wiki.ros.org/roslibjs_experimental,Wiki,roslibjs_experimental,The roslibjs_experimental package
W1274,https://wiki.ros.org/mjpegcanvas,Wiki,mjpegcanvas,The mjpegcanvas package
W1275,https://wiki.ros.org/sr_edc_controller_configuration,Wiki,sr_edc_controller_configuration,"

    contains the different launch files for Shadow Robot hand controllers. The actual configuration files are stored in the sr_config stack.

  


See  for more details on the actual implementation of the controllers. The Parameters are saved in the different  file:  The package also contains one launch file per controller type. You can change which controller is started by default by editing . Just make sure you only have one type of controllers started (otherwise one of them is going to be ignored by the controller manager). The controller manager is started by the  file (which is called from /sr_edc.launch file). "
W1276,https://wiki.ros.org/vigir_footstep_planning,Wiki,vigir_footstep_planning,"The vigir_footstep_planning package is a stack for the whole footstep planning system. It contains the top-level launch files and may be used to include all dependencies.
 
 



 

 
 
  Before the direction commands become activated you have to select a parameter set from the parameter selection section. 
 The terrain generator does only consider all point cloud data around the current robot pose to reduce computational cost. Therefore you should place a  (hotkey ""p"") in RViz in a feasible region of the input pointcloud (see below) to obtain a world model. 



  


 

Use GitHub to . []
 The  stack provides an integrated full 3D footstep planner. It was originally based on the search-based  (using A* from SBPL) and has been intensively extended/rewritten to enable the generation of feasible footstep placements based on perceived 3D data. It can cope with sloped terrain and uses overhanging steps to improve planning performance. The footstep planning system is designed to be easily deployable and adaptable to any humanoid bipedal robot. It can be either used as a 3D planner out of the box, as a research tool in bipedal search-based planning or for benchmarking walking controllers in difficult terrain. For improvement mission performance in real world scenarios, the footstep planner implements a comprehensive set of coactive footstep planning services. In this way, it enables human-in-the-loop planning to combine human intelligence and capable footstep placement algorithms to generate quickly a safe sequence of footstep placements through challenging terrain (examples see under ). This allows for adaptive code execution even during runtime which is superior to classic parameter-based systems. Although plugins can provide new code for the pipeline, already existing code is kept untouched which simplifies code maintenance and improves code stability. In order to achieve this kind of versatile code management, the  has been developed. See under . The  stack consists of multiple repositories located at GitHub: All generated step plan are published on . You can just place a start pose ( (hotkey ""p"")) and goal pose ( (hotkey ""g"")) to trigger planning. You should be able to follow the planning process and receive a result at the end. The planning system is also capable to provide manual step generation. For this purpose the  widget can be launched by: Using this widget allows to lay down patterns of step placements manually. Each parameter can be set individually in this widget. It also includes an interface for the  which manages step execution on the robot. For a quick demonstration of the 3D planning capabilities the  package can be used here. In order to use that package clone and compile from Create the  subfolder in the  package. Download and extract the example pointcloud files from  into this recently created directory. Afterwards you are able to launch the terrain generator test environment (while the footstep planning system is already running in the background): As already mentioned above, you need to set the fake robot pose by placing a  (hotkey ""p""). If you place it like illustrated in the image below, then you should get a nice world model of the pitch ramp scenario.  Please wait a few seconds until the world model is reasonable dense. Now you can request footstep plans over the pitch ramp by placing a  (hotkey ""g""). After a few seconds you should see results similar to that demonstrated on the picture below:  You can also use your own pointcloud data as the  can accumulate data from any arbitrary source. Just launch the standalone : Now you can just publish your pointcloud data as incremental updates at  in a common frame (e.g. ). If you wish to just generate the terrain model from a single pointcloud, the data must be published on . The  stack is accompanied by the  package which enables seamless integration to the low-level motion layer. In particular, this includes step queue management and step queue spooling. Using this package should simplify integration to other robot platforms while providing high-level functionality such as continuous walking (by continuous updating the step queue). The  stack takes heavy use of the  package due to heavy use of plugins (see ). In this step-by-step tutorial we do not discuss details about the  as we refer to the  documentation for details. We recommend to read through the basics of the  to understand how the footstep planning system can be customized easily. Please take note of the  which provides seamless low-level hardware integration and step queue management in order to simplify even more the migration process while providing a capable step queue management system that allows even for continuous walking. During the Humanoids@RoboCup Demo 2016 at Leipzig, the footstep planner was used as well. If you would like to try it out in simulation by yourself, then just follow the install instruction of the basic THORMANG software  which provides a fully working robot using Gazebo simulation. When Gazebo has started up, first unpause the simulator. Afterwards, you can bring the robot in  mode by using the . You have to proceed following states with the robot: From this point, you can work with the . After selecting a parameter set you can command simple step patterns and directly execute them afterwards. As long you do not push the limits too hard, the robot will execute the steps safely in simulation. As explained  you can use RViz to generate step plans. After a step plan has been generated you can hit the  button in the  which will then execute the recently generated plan. pclvigir_terrain_classifier/vigir/terrain_classifier/point_cloud_update/world/vigir/terrain_classifier/set_point_cloudwalkstand_prepstandwalk@INPROCEEDINGS{2016:Humanoids-Stumpf,
  author = {Stumpf, Alexander and Kohlbrecher, Stefan and Conner, David C and von Stryk, Oskar},
  title = {Open source integrated 3D footstep planning framework for humanoid robots},
  booktitle = {Humanoid Robots (Humanoids), 2016 IEEE-RAS 16th International Conference on},
  pages = {938--945},
  year = {2016},
  organization = {IEEE}
}@INPROCEEDINGS{2014:Humanoids-Stumpf,
  author = {Supervised Footstep Planning for Humanoid Robots in Rough Terrain Tasks using a Black Box Walking Controller},
  title = {Supervised Footstep Planning for Humanoid Robots in Rough Terrain Tasks using a Black Box Walking Controller},
  year = {2014},
  pages = {287-294},
  month = {Nov 18-20},
  address = {Madrid, Spain},
  booktitle = {Proc. IEEE-RAS Intl. Conf. Humanoid Robots},
}@ARTICLE{2016:FRAI-Kohlbrecher-etal,
  author = {Kohlbrecher, Stefan and Stumpf, Alexander and Romay, Alberto and Schillinger, Philipp and von Stryk, Oskar and C. Conner, David},
  title = {A comprehensive software framework for complex locomotion and manipulation tasks applicable to different types of humanoid robots},
  journal = {Frontiers in Robotics and AI},
  year = {2016},
  pages = {online},
  doi = {10.3389/frobt.2016.00031},
  url = {http://journal.frontiersin.org/article/10.3389/frobt.2016.00031},
}roslaunch vigir_footstep_planning footstep_planner_test.launchroslaunch vigir_footstep_planning rviz_footstep_planning.launchroslaunch vigir_footstep_planning step_interface_rqt.launchhttps://github.com/team-vigir/vigir_terrain_classifier.gitroslaunch vigir_terrain_classifier terrain_classifier_test.launchroslaunch vigir_terrain_classifier terrain_classifier.launchthor install footstep_planning uithor makeroscore
thor sim
roslaunch thor_mang_footstep_planner thor_mang_footstep_planner.launch
thor ui supervisor
thor ui step_interface_rqtthor ui rviz_thor_mang_default.launch"
W1277,https://wiki.ros.org/roswtf,Wiki,roswtf,"roswtf is a tool for diagnosing issues with a running ROS system. Think of it as a FAQ implemented in code.
 will examine your ROS setup, such as your , and look for configuration issues. If you have a ROS system online, it will look at it and check for any potential issues. 

:  performs those checks based on the directory you run it from. For example, if you run it in the  stack, it will perform it's filesystem checks based on files in the  stack and its dependencies.  

 accepts the following command-line options: 
 looks for many, many things, and the list is always growing. There are two categories of what it looks for: file-system issues and online/graph issues. 
 produces a report containing both warnings and errors based on the checks it performed. In general, warnings are something that seems odd, but may be just fine. Errors are known problems that you should probably address if you are experiencing problems. 

 will continue to evolve to try and diagnose more complex problems that may arise in large ROS systems. There are currently plans to do checks for multi-machine setups, as well as expand the range of its checks via the plugin API.  Recommendations for checks that can be performed are always welcome. Other than the general checks,  has two usages. Or you can also run  on a  file: For file-system issues,  looks at your environment variables, package configurations, stack configurations, and more. It can also take in a  file and attempt to find any potential configuration issues in it, such as packages that haven't been built properly. For online issues,  examines the state of your current graph and tries to find any potential issues. These issues might be unresponsive nodes, missing connections between nodes, or potential machine-configuration issues with . Please see . roswtfroswtfroswtfnavigationroswtfroswtf--allroswtfROS_PACKAGE_PATH--no-pluginsroswtf--offlineroswtfroswtfroswtfroswtfroswtf$ roswtf$ roswtf yourfile.launch"
W1278,https://wiki.ros.org/rplidar_ros,Wiki,rplidar_ros,"The rplidar ros package, support rplidar A2/A1 and A3/S1"
W1279,https://wiki.ros.org/kobuki_desktop,Wiki,kobuki_desktop,"Visualisation and simulation tools for Kobuki
"
W1280,https://wiki.ros.org/transform_graph,Wiki,transform_graph,"Library for computing transformations in arbitrary graph structures.Use GitHub to . []
 
 is a library for computing transformations between coordinate frames in an arbitrary graph structure. 
 maintains the graph of transformations and is the primary interface to transform_graph:  The library's generated documentation explains how to use  in detail. Below are a few quick examples illustrating how it can be used. Add frames to the graph using : Get points in different frames using . In this example, we want to know what a point 10 cm in front of the robot's wrist is, expressed in the base frame: transform_graphtransform_graphtransform_graphtransform_graphtransform_graphtransform_graphtransform_graph::Graphtransform_graph::Graph::Addtransform_graph::Graph::DescribePosition

















"
W1281,https://wiki.ros.org/osg_interactive_markers,Wiki,osg_interactive_markers,"This package is basically an OpenSceneGraph (OSG) adaptation of the Interactive Markers client writen for rviz/Ogre.

 
 does not currently offer all the potential of Interactive Markers. However, the most frequent use cases should be supported. This package is basically an  (OSG) adaptation of the  client writen for rviz/Ogre. Most of the code has been taken from the rviz sources, and adapted to use OSG data types and facilities when possible. It allows the creation of Interactive Markers in  applications. Let's have a look to the  example, inside the  package: The example above creates an  application that listens for Interactive Markers in the  topic. By running the above example and the  tutorial in different terminals you should see something like the following: Let's have a look to the code required for setting the Interactive Markers client. First you need to create a  instance and set the fixed frame where you expect the markers to be referenced to. After that,  is the main class you have to instantiate, giving as input the topic where to listen to Interactive Markers, a node in your OSG scene that will hold the geometry, and a TF client:  osg_interactive_markers_demo.cpposg_interactive_markersbasic_controls/updateosg_interactive_markers






















































$ rosrun osg_interactive_markers osg_interactive_markers_demo$ rosrun interactive_marker_tutorials basic_controls





"
W1282,https://wiki.ros.org/contact_handler,Wiki,contact_handler,"The contact_handler package. It reports the dynamic-engine-reported contacts between
      all scene objects on a topic called ""contacts"".

      This package uses gazebo_msgs/ContactsState message type to report body contacts.
      This is because ROS doesn't have any standardized contact reporting messages.
      However, to have gazebo_msgs, you don't need to install whole Gazebo, you just need to
      install the single package ros-indigo-gazebo-msgs."
W1283,https://wiki.ros.org/network_detector,Wiki,network_detector,"

     A ROS node that watches a given network interface and publishes
     whether it is both UP and RUNNING (indicating that a cable is
     plugged into it and communication is happening, for instance) or
     not.

  "
W1284,https://wiki.ros.org/win_dateutil,Wiki,win_dateutil,"Scripts to help download, patch and compile python dateutil."
W1285,https://wiki.ros.org/uos_tools,Wiki,uos_tools,"Various helper utilities not associated with a particular stack

Use GitHub to . []
  For installation instructions, see . "
W1286,https://wiki.ros.org/homer_robot_face,Wiki,homer_robot_face,An application to display a talking head on your robot for human robot interaction.
W1287,https://wiki.ros.org/mvsim,Wiki,mvsim,"Node for the ""multivehicle simulator"" framework.




  
 ()  ()  () 
 (default: 0.2) 
 →   →   →  The  node wraps Multi-Vehicle Simulator library (libmvsim). It loads a  file and exposes vehicles, sensors and wheel forces via ROS.  If there is only one vehicle defined in the world file, all of these topics appear at the top namespace. However, if more than one vehicle exist, topics are placed into their own namespaces like  , e.g.,  etc. If there is only one vehicle defined in the world file, all of these topics appear at the top namespace. However, if more than one vehicle exist, topics are placed into their own namespaces like  , e.g.,  etc. The  topic gives simulated odometry, while  always provides a perfect, globally referenced pose. mvsim_nodeworldveh<i>/veh0/cmd_velcmd_velveh<i>/veh0/odomodombase_pose_ground_truth<LASER_SENSOR_NAME>odombase_pose_ground_truth~base_watchdog_timeoutcmd_velbase_linkbase_<LASER_SENSOR_NAME>base_footprintbase_linkodombase_footprintsudo apt-get install ros-$ROS_DISTRO-mvsim    roslaunch mvsim mvsim_demo_2robots.launch"
W1288,https://wiki.ros.org/khi_rs080n_moveit_config,Wiki,khi_rs080n_moveit_config,An automatically generated package with all the configuration and launch files for using the khi_rs080n with the MoveIt! Motion Planning Framework
W1289,https://wiki.ros.org/kuka_rsi_simulator,Wiki,kuka_rsi_simulator,"Python node that implements a minimal RSI interface simulator.

This package is part of the  program. See the  page. "
W1290,https://wiki.ros.org/maggie_teleop,Wiki,maggie_teleop,"teleoperation

This package provides an launch file for running  in a configuration that allows it to run in parallel with the  stack on the . teleop_joy.launchteleop_keyboard.launch"
W1291,https://wiki.ros.org/ros_ethercat_model,Wiki,ros_ethercat_model,The mechanism model
W1292,https://wiki.ros.org/vrmagic_ros_bridge_server,Wiki,vrmagic_ros_bridge_server,"This Package contains a ROS-brige for the VRMagic Smartcameras. There is a
	ROS-node (vrmagic_ros_bridge_server), which is the Server for the ROS-brige,
  	and firmware for the VRMagic Smartcam. On the Smartcam the User have to implement a firmware and have	
	to use the Class VrMagicHandler_camhost for communication with the vrmagic_ros_bridge_server.
	Each Image which is transmitted to the vrmagic_ros_bridge_server by using the Class VrMagicHandler_camhost
  	will be published as Image via ROS. Multiple Images are also possible. 




 

  the following explanations are extracted from demo_app. 

 The demo application is written for a D3-Multisensor smart cam from VRMagic.  This package contains a ROS bridge for the VRMagic smart cameras. It includes a ROS server node named , and a firmware interface for VRMagic smart cams. The firmware interface is implemented as C++ class () and needs to be included in the user's application. Smart cam images are transmitted to the  via this interface. The camhost server provides a ROS multi-channel publisher for the multi-sensor devices. The node receives from the VRMagic smart cam an image via the  class. Each image must have an ID representing a specific channel. An individual publisher is instanciated for each ID. The node verifies for incoming images whether a publisher is already instanciated. New publishers are created during runtime with the following convention for the topic name: <base_topic> + ID, (e.g. base_topic:""topicname"", ID:1 -> ""topicname1""). Or use a launch file and roslaunch with the parameters described in  To use the ROS bridge you have to be familiar with the VRMagic camera user guide, which you can find on the . To use the ROS bridge in your applications, the folder  in  has to be copied in your application's source folder. You have to add all  files in  to your . In the first step a  - object must be instanciated. For that the header file from the class needs to be included. A connection to the ROS server can be established by calling the  method. This method blocks until a connection to the ROS server can be established. With the method  an image is transmitted to the ROS server. Create and fill an instance of  with information about the image format. Image data is passed via the pointer variable . After filling the -object, it must be transmitted to the ROS bridge with the method , see the following code: The example application is located in the folder . To build the demo application, copy the whole  folder to the location where the VRMagic SDK is installed (host PC or virtual machine).  Type To execute the demo application, copy the binary in  named  to your VRMagic smart cam. Now execute the demo application on the VRMagic smart cam: vrmagic_ros_bridge_serverVrMagicHandler_camhostvrmagic_ros_bridge_serverVrMagicHandler_camhostVrMagicHandler_camhostfirmware/src/.cppVrMagicHandler_camhostMakefileVrMagicHandler_camhostconnect()writeImage(ohm::ImageType& image)ohm::ImageTypeimage_ptrunsigned int channelsunsigned int channelsohm::ImageType.idohm::ImageType.dataSizeohm::ImageType.dataTypeohm::ImageType.compressionTypeohm::ImageType.widthohm::ImageType.heightohm::ImageType.channelsohm::ImageType.bytePerPixelohm::ImageType.dataImageTypeohm::ImageTypewriteImage(ohm::ImageType& image)VrMagicHandler_camhostMakefileVrMagicHandler_camhost/firmware/src/demp_appfirmwarefirmware/src/demo_appros_bridge_demo_app<your_base_topicname>1 $ cd ""Path_to_catkin_ws""/src/""
 $ git clone https://github.com/ohm-ros-pkg/vrmagic_drivers.git $ rosrun vrmagic_ros_bridge_server vrmagic_ros_bridge_server_node _pub_name:=<topicname> _ip_smartcam:=<ip> _port_smartcam:=<port> $ rosrun vrmagic_ros_bridge_server vrmagic_ros_bridge_server_node _pub_name:=vrmagic_image_ _ip_smartcam:=192.168.3.100 _port_smartcam:=1234















 $ cd firmware/
 $ make $ cd where_you_copied_the_binary/
 $ ./ros_bridge_demo_app $ rosrun image_view image_view image:=/<your_base_topicname>1



"
W1293,https://wiki.ros.org/shadow_robot,Wiki,shadow_robot,"

  This stack regroups the different ros interfaces developped for Shadow Robot's
  Hardware. It provides an interface to both simulated and real hardware.

  Our documentation can be found on . "
W1294,https://wiki.ros.org/maggie_create_map,Wiki,maggie_create_map,"create map for Social Robot Maggie.


 $ roslaunch maggie_create_map maggie_mapping.launch robot:=maggie $ roslaunch maggie_create_map save_map.launch robot:=maggie"
W1295,https://wiki.ros.org/default_cfg_fkie,Wiki,default_cfg_fkie,"The configuration node loads a given launch configuration and offers services to 
     list or start the contained nodes. It provides additional description 
     extracted from launch file. This is used by node_manager_fkie. 





The  node offers a list of nodes, which can be started by calling a service with name of the node. Thus the needed nodes can be launched on demand without knowing the details of the configuration to run those. To configure the list with nodes a ROS launch file is used. While loading a launch file by the  some addtional parameters are parsed to obtain a description of robots, nodes and capabilities configured by the launch file. This description is used in  to show additional information for nodes. The  shows the usage of additional description. You can run the node without parameter and use the  service to load a launch configuration. default_cfgdefault_cfg~load~list_nodes~run~description~list_nodes~run~description~reload~packageString''~launch_fileString''~argvlist[str]rosmake default_cfg_fkiecatkin_makerosrun default_cfg_fkie default_cfg _package:=@PACKAGE_NAME@ _launch_file:=@FILE_NAME@"
W1296,https://wiki.ros.org/nao_teleop,Wiki,nao_teleop,"

     Teleoperation (gamepad or joystick) for the Nao humanoid

  



Then start  either on your local machine or on the Nao (nao_walker and nao_controller are required by this node). By default, gamepad teleoperation starts paused. Just hit the ""toggle control button"" (#8 by default or #9 on PS3 controller) and start walking Nao around by setting the velocities for the OmniWalk engine with the two sticks on the gamepad (see below). You can teleoperate Nao using any joystick or gamepad configured in ROS with omnidirectional velocities, very similar to . The following commands are currently implemented (tested on a Logitech Cordless Rumblepad II, where the button numbering should be increased by one as it starts with ""1""): joycmd_velmotion_command_btnhead_anglesspeech~axis_*intaxis_axis_x~btn_*intbtn_~max_vxdouble~max_vydouble~max_vwdoubleroslaunch nao_teleop teleop_joy.launch"
W1297,https://wiki.ros.org/ros_control_boilerplate,Wiki,ros_control_boilerplate,"Simple simulation interface and template for setting up a hardware interface for ros_control
See  for full documentation. "
W1298,https://wiki.ros.org/sr_gui_controller_tuner,Wiki,sr_gui_controller_tuner,"

     sr_gui_controller_tuner is a rosgui plugin for tuning the sr_mechanism_controllers

    "
W1299,https://wiki.ros.org/asmach_tutorials,Wiki,asmach_tutorials,"
    This package containes numerous examples of how to use SMACH. See the examples directory.
  "
W1300,https://wiki.ros.org/odva_ethernetip,Wiki,odva_ethernetip,Library implementing ODVA EtherNet/IP (Industrial Protocol).
W1301,https://wiki.ros.org/turtlebot3_autorace_core,Wiki,turtlebot3_autorace_core,"TurtleBot3 AutoRace ROS package that TurtleBot3 Auto's core 



detect/traffic_signcore/returned_modecore/decided_modedetect/parking_lot_stampeddetect/level_crossing_stampeddetect/tunnel_stampeddetect/traffic_light_orderdetect/parking_lot_orderdetect/level_crossing_orderdetect/tunnel_ordercore/returned_mode"
W1302,https://wiki.ros.org/rosh_desktop_plugins,Wiki,rosh_desktop_plugins,"

    ROSH plugins related to the desktop variant. 

  

Please see the  documentation to get started. rosh_desktop_plugins is an  development stack for using  . As rosh has APIs that reach across many ROS libraries, such as , , and ROS itself, this stack is being used to unify the development.  This stack is expected to disappear as  and its related plugins mature. rosh_robot_plugins houses stacks related to the ""desktop"" variant, which was introduced in . The desktop plugins mainly focus on -based capabilities. "
W1303,https://wiki.ros.org/dense_laser_assembler,Wiki,dense_laser_assembler,"Stores streaming data from a laser sensor in a
    dense representation. This allows the user to do 'image-like'
    processing on the data, and can also be used for very fast approx
    neighborhood searches.  This package is still experimental and unstable.
    Expect its APIs to change.

 
 -  - A single range/intensity reading from a laser scanner. Takes approx 17 υs to acquire 
 -  - Data collected during a single revolution of a laser scanner. Takes approx 25 ms to acquire, and consists of 100's of rays 
 -  - Data collected during monotonic motion of the tilting_stage on the PR2. Usually takes 2-10 seconds to acquire, and consists of 100's of scans 
   
 A 'typical' LaserScan message will also be published, providing config information for each scan. This includes info like min-angle, max-angle, angle-increment, time-increment, etc. Currently, we assume that the config information is consistent across all scans in a dense laser scan. It is likely that the DensePointCloud could end up using  as the underlying data structure. "
W1304,https://wiki.ros.org/straf_recovery,Wiki,straf_recovery,"The straf_recovery package

 The  is a simple recovery behavior that attempts to move away from the nearest obstacle in the navigation stack's . It is designed only for omnidirectional robots. It adheres to the  interface found in the  package and can be used as a recovery behavior  for the  node. straf_recovery::StrafRecoverynav_core::RecoveryBehaviormove_base_simple/goal~/obstacle_direction~/cyclestimeoutdoubleminimum_translate_distancedoublemaximum_translate_distancedoublestraf_veldoublexy_goal_tolerancedoublefrequencydouble"
W1305,https://wiki.ros.org/interactive_marker_proxy,Wiki,interactive_marker_proxy,"A Proxy Server for Interactive Markers
~topic_ns~topic_ns/tunneled/update~topic_ns/tunneled/get_init~target_framestring~topic_nsstring~update_ratefloat"
W1306,https://wiki.ros.org/naoqi_dashboard,Wiki,naoqi_dashboard,"naoqi_dashboard is a GUI for monitoring the state of an ALdebaran robot.
    It is a port of pr2_dashboard and shows status information like
    battery status, joint temperatures, and joint stiffness, as well
    as integrating ROS tools like rqt_console and rqt_robot_monitor."
W1307,https://wiki.ros.org/people_velocity_tracker,Wiki,people_velocity_tracker,"Track the output of the leg_detector to indicate the velocity of person.


people_tracker_measurements/people/visualization_markertimeoutdouble/people"
W1308,https://wiki.ros.org/rospeex_audiomonitor,Wiki,rospeex_audiomonitor,"This package provides a stable waveform monitor of rospeex's (recommended).
    This package requires an external library: qtmobility-dev."
W1309,https://wiki.ros.org/sentis_tof_m100,Wiki,sentis_tof_m100,"The Sentis ToF M100 ROS package

.    














 Make sure your network is correctly configured. We recommend you to follow the API instructions to check whether the camera and your network are working without any problem.  Network parameters cannot be changed at runtime.  Following camera parameters and filtering methods can be accessed in runtime using the rqt_reconfigure. There is a new package () that uses the new  developed by Bluetechnix for interacting with their sensors. The ' works with ROS versions groovy and hydro. You can use catkin workspaces or the previous rosbuild to configure, compile and get ready ROS. ROS tutorial:  Be sure your libboost library version is >= 1.49. Previous versions as 1.46 generate error while compiling sentis_tof_m100_ros_pkg. Clone from repository:  to the src/ folder in your catkin workspace. Now compile it with: sentis_tof_m100_ros_pkgapt-get install ros-hydro-pcl-ros ros-hydro-pcl-conversions ros-hydro-perception-pclcd catkin_ws
source devel/setup.bash ## initialize search path to include local workspace
cd src/
git clone https://github.com/voxel-dot-at/sentis_tof_m100_pkg.git
cd ..
catkin_makeroslaunch sentis_tof_m100 start.launchcd catkin_ws
source devel/setup.bash
roscore &rosrun sentis_tof_m100 sentis_tof_m100_node #[options]Using help for sentis_tof_m100_ros_pkg
 You can set the configuration values for the camera. If any option is missing the value of the parameter server or the default value will be used:

 Usage:
 rosrun sentis_tof_m100 sentis_tof_m100_node <options>
-tcp_ip *TCP IP Addresss*
        Ip address for the control connection
        (string, i.e: 192.168.0.10)
-tcp_port *Port for tcp*
        Defines the port used for the control connection
        (unsigned short, i.e: 10001)
-udp_ip *UDP IP Addresss*
        Multicast ip address for the data connection
        (string, i.e: 224.0.0.1)
-udp_port *Port for udp*
        Defines the port used for the data connection
        (unsigned short, i.e: 10001)
-it *Integration_Time*
        Integration time(in usec) for the sensor
        (min: 50 | max: 7000 | default: 1500)
-mf  *Modulation_Frequency*
        Sets the modulation frequency(Hz) of the sensor
        (min: 5000 | max: 30000 | default: 20000)
-fr *Frame_Rate*
        Sets the frame rate of the camera
        (min: 1 | max: 45 | default: 40)
-mef *MedianFilter*
        Sets on or off the Median Filter.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-avf *AverageFilter*
        Sets on or off the Average Filter.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-gaf *GaussFilter*
        Sets on or off the Gauss Filter.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-sla *SlidingAverage*
        Sets on or off the Sliding Average.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-wic *WigglingCompensation*
        Sets on or off the Wiggling Compensation.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-fppnc *FPPNCompensation*
        Sets on or off the FPPN Compensation.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-mfs *ModFreqScaling*
        Sets on or off the ModFreq Scaling.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-smm *Scalingmm*
        Sets on or off the Scaling to [mm].
        (OFF: 0 | ON: any other integer value |  ON if not set )
-aos *AdditiveOffset*
        Sets on or off the Additive Offset.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-tmc *TemperatureCompensation*
        Sets on or off the Temperature Compensation.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-sdcg *ScalingDistCalibGradient*
        Sets on or off the Scaling via register DistCalibGradient.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-sdco *ScalingDistCalibOffset*
        Sets on or off the Scaling via register DistCalibOffset.
        (OFF: 0 | ON: any other integer value |  ON if not set )
-mefite *FilterMedian_Config*
        Sets the nº of iteration for the Media filter.
        (min: 1 | max: 255 | default: 1)
-avfpix *FilterAverage_Config_Pixels*
        Sets pixel matrix for the Average filter.
        (3x3: 0 | 5x5: 1 | Default: 3x3 )
-avfite *FilterAverage_Config_Iters*
        Sets the nº of iteration for the Average filter.
        (min: 1 | max: 255 | default: 1)
-gafpix *FilterGauss_Config_Pixels*
        Sets pixel matrix for the Gauss filter.
        (3x3: 0 | 5x5: 1 | Default: 3x3 )
-gafite *FilterGauss_Config_Iters*
        Sets the nº of iteration for the Gauss filter.
        (min: 1 | max: 255 | default: 1)
-slacw *FilterSLAF_config*
        Sets the SLAF filter windows size.
        (min: 1 | max: 255 | default: 1)
-af *Amplitude_Filter_On*
        Whether to apply amplitude filter or not. Image pixels with amplitude values less than the threshold will be filtered out
        (ON: if set | OFF: default)
-at *Amplitude_Threshold*
        What should be the amplitude filter threshold. Image pixels with smaller amplitude values will be filtered out. Amplitude Filter Status should be true to use this filter
        (min: 0 | max: 2500 | default: 0)

 Example:
rosrun sentis_tof_m100 sentis_tof_m100_node -tcp_ip 192.168.0.10 -tcp_port 10001 -it 1500 -mf 20000 -fr 20rosrun rviz rvizrosrun rqt_reconfigure rqt_reconfigure"
W1310,https://wiki.ros.org/motoman,Wiki,motoman,"ROS-Industrial support for Yaskawa Motoman manipulators (metapackage).





Use GitHub to . []
 This stack is part of the  program. It currently contains packages that provide nodes for communication with Motoman industrial robot controllers (DX100, FS100, DX200, and YRC1000), URDF models for various robot arms and associated  configuration packages. Please see the  page for more information. See the  metapackage for additional packages, such as robot support packages and  configuration packages. The packages in the main repository have been released into ROS Indigo on Ubuntu, making installation through  or synaptic possible. Other Linux distributions will have to build from source. This installs all the dependencies as well. The controller must be installed/configured to work with ROS-Industrial as well.  The relevant software can be found in the  package.  Installation instructions for the controller can be found in this . See the  page for an overview of the available tutorials. See the  page for details on alarms and errors when using the MotoROS driver. apt-getsudo apt-get install ros-indigo-motoman"
W1311,https://wiki.ros.org/kuka_kr210_support,Wiki,kuka_kr210_support,"
      ROS-Industrial support for the KUKA KR 210 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 210 manipulators. This currently includes the L150 only.
    :
      Joint limits and maximum joint velocities are based on the information
      found in the online .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      : this package currently uses non-valid inertia parameters.
    "
W1312,https://wiki.ros.org/schunk_svh_driver,Wiki,schunk_svh_driver,"SVH Driver wrapper to enable control of the Schunk five finger hand














 The urdf of the node makes use of the  tag which is currently only resolved by the robot joint state publisher. in order to generate TFs for the visualization and to get the angles of the coupled joints the node is used in conjunction with a joint state publisher and a robot state publisher. If you include the node without these nodes the TF tree will not be complete as the joints that use mimic are not working. See the URDF section for details on joints, their naming and relation. 
 
: The SVH uses relative encoders that need a hard stop to reset. Especially the finger spread however also contains springs that will lead to a slightly different pose than commanded in real execution. So please beware when you develop poses without the hardware in the loop. 

         
           



This package provides a way of controlling the . It provides the driver for the low level interface and enables an easy control of the hand via ROS . To use this package you will need a .  It communicates via RS485 protocol. Brainbox USB to Serial converter have proven to work well with the hand and are usually delivered in combination with the hand. this will copy the udev rules to  and restart your udev service. If you have the fzi_icl_core or fzi_icl_comm package in your workspace you'll have to build it with , as those packages are plain cmake packages. See the  for details. which will copy the udev rules into  and restart your udev service. 
When using the launch file  all parameters are read from yaml files residing in the folder . If you want to give custom parameters just edit the file  if you are using the source installation. In case of an installation from deb you should first copy the file under  to a folder with user write acces, make your changes and then use it by adding the argument  when launching the node.  If you want to go back to the original values (and have edited the file, residing in etc) you can simply delete the file and copy the  to the name  and start again. If no  file is present the values of the default file will be used. If both files are missing or the node use used without the launch file hardcoded default values that are safe will be used. In any case  as it sets up many variables, the parameter sets and some additional packages that are needed for correct operation and visualization. You can change the device used by adding the argument  to the launch calls, change it via dynamic reconfigure and then do a reconnect or change it permanently by replacing the argument in the launch file. By using the  argument the launchfile will start a joint state publisher for easy input. If you do not activate this as input you have to provide the target positions by another node or console input. The package folder comes with a file called ""quick_commands"" which gives you some examples how to controll the hand via rostopic. By default the node will await input from another node. To use the svh_controller with your project  like this: The node will automatically show the input sliders if started with the standalone argument. If you additionally provide the  argument as true an rqt gui will be opened when launching the node: The  gui opens always to its default configuration (which is usually the last one). The SVH comes with the plugin  which enables easy reset control of the hand. Additionally you can use dynamic_reconfigure to change some of the values and the RVIZ plugin to visualize the robot model of the SVH. A configuration file for rviz is provided with the package at ""urdf/svh.rviz"". Your configuration should look something like this to access all GUI functionalities: as with the real hardware you can choose to use the simulation (which is not really a simulation but just a visualisation) with convenient sliders or with the command line/ your own packages by using the  argument: As a test to see if the hardware is properly working the very simple test node  is provided. Make sure the hand can move freely and run the test with: In case you do not use the autostart feature of the controller you will have to connect and start the controller manually.  You should do this by using the  plugin provided with the package. When the hardware is ready press the connect button. Afterwards you can either reset all or individual fingers by pressing reset. The fingers will be disabled after start but are automatically enabled once a target position is set. If the troubleshooting did not answer your questions you can ask the community via  or contact the support offered by FZI on behalf of Schunk at svh-support AT fzi DOT de /etc/udev/rules.d/etc/udev/rules.dconnectserial_devicereset_channelenable_channelchannel_targetschannel_feedbackchannel_currentsparameter_descriptionsparameter_descriptionsparameter_updates~autostartbool~serial_devicestring~disable_flagsvector of bool~reset_timeoutint~finger_reset_speeddouble/robot_descriptionurdf model~logging_configstring~use_internal_loggingbool~CHANNEL_NAME/position_controllervector of floats~CHANNEL_NAME/current_controllervector of floats~CHANNEL_NAME/home_settingsvector of floats~VERSIONS_PARAMETERarraysvh_controllertoggle_runspeedloopchannel_targetssvh_controller.launchcontroller_config:=path_to_your/logging.xmlserial_devicestandalonemimicguirqtSVH_Resetstandalonesvh_sin_testSVH_Resetrqtrqt --clear-configapt-get install ros-indigo-schunk-svh-driverapt-get install ros-jade-schunk-svh-driverapt-get install ros-hydro-schunk-svh-driverapt-get install ros-indigo-schunk-svh-driverapt-get install ros-kinetic-schunk-svh-driverrosrun schunk_svh_driver create_udev_rules   catkin_make_isolated
   source devel_isolated/setup.bash   rosrun schunk_svh_driver create_udev_rulesls /devroslaunch schunk_svh_driver svh_controller.launch standalone:=trueroslaunch schunk_svh_driver svh_controller.launch standalone:=true autostart:=false  <include file=""$(find schunk_svh_driver)/launch/svh_controller.launch"">
        <arg name=""standalone"" value=""False"" />
        <arg name=""gui"" value=""False"" />
  </include><include file=""$(find schunk_svh_driver)/launch/svh_node.launch"">
            <arg name=""serial_device"" value=""$(arg serial_device)""/>
            <arg name=""autostart"" value=""$(arg autostart)"" />
</include>roslaunch schunk_svh_driver svh_controller.launch standalone:=true gui:=trueroslaunch schunk_svh_driver svh_controller.launch simulation:=true gui:=trueroslaunch schunk_svh_driver svh_controller.launch simulation:=true standalone:=true gui:=trueroslaunch schunk_svh_driver svh_sin_test.launchrostopic pub -1 /svh_sin_test/toggle_run std_msgs/Empty ""{}""<2014-09-29 14:40:56.004> DriverSVH(Warning) SVHFingerManager::setAllTargetPositions: Could not set target position vector: At least one channel is out of bounds!<2014-09-30 11:24:20.086> DriverSVH(Info) SVHFingerManager::connect: Successfully established connection to SCHUNK five finger hand.
<2014-09-30 11:24:20.086> DriverSVH(Info) SVHFingerManager::connect: Send packages = 28, received packages = 28<2014-09-30 13:23:54.741> DriverSVH(Error) SVHSerialInterface::connect: Could not open serial device: /dev/ttyUSB0
[ INFO] [1412076234.741596785]: SVH Driver Ready, you will need to connect and reset the fingers before you can use the hand."
W1313,https://wiki.ros.org/nodelet_core,Wiki,nodelet_core,"Nodelet Core Metapackage
: the nodelet packages are now part of nodelet_core.  In previous releases, they were part of . For documentation on using nodelets, please see the  package.  For nodelet libraries similar in function to the  package, see . "
W1314,https://wiki.ros.org/abb_irb5400_support,Wiki,abb_irb5400_support,"
      ROS-Industrial support for the ABB IRB 5400 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 5400 manipulators. This currently includes the base model.
    
      Joint limits and max joint velocities are based on the information in
      the ABB data sheets.  All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1315,https://wiki.ros.org/kobuki_ftdi,Wiki,kobuki_ftdi,"Utilities for flashing and enabling Kobuki's USB connection.
	    This package contains tools for flashing the Kobuki's FTDI chip (usually done at the factory).
	    The special firmware for the FTDI chip (USB to serial converter) enables it to appear as
	    /dev/kobuki on the user's PC.

kobuki/dev/kobuki> rosrun kobuki_ftdi create_udev_rules> make udev"
W1316,https://wiki.ros.org/rosbag,Wiki,rosbag,"This is a set of tools for recording from and playing back to ROS
    topics.  It is intended to be high performance and avoids
    deserialization and reserialization of the messages.

The  package provides a command-line tool for working with  as well as code APIs for reading/writing bags in  and . The rosbag command-line tool and code APIs are .  Every effort will be made to maintain backwards compatibility. The main new feature being planned for  is the addition of a ROS API for interacting with the playing and recording nodes via service calls. rosbagrosbagrosbagrosbagrosbag"
W1317,https://wiki.ros.org/viso2,Wiki,viso2,"
    A ROS-Wrapper for libviso2, a library for visual odometry, 
    maintained by the Systems, Robotics and Vision group of the 
    University of the Balearic Islands, Spain. http://srv.uib.es 
"
W1318,https://wiki.ros.org/nav_core,Wiki,nav_core,"This package provides common interfaces for navigation specific robot actions. Currently, this package provides the BaseGlobalPlanner, BaseLocalPlanner, and RecoveryBehavior interfaces, which can be used to build actions that can easily swap their planner, local controller, or recovery behavior for new versions adhering to the same interface.
 








The  package contains key interfaces for the navigation stack. All planners and recovery behaviors that wish to be used as  in the  node must adhere to these interfaces. The  provides an interface for global planners used in navigation. All global planners written as plugins for the  node must adhere to this interface. Current global planners using the  interface are: Documentation on the C++ API for the  can be found here: . The  provides an interface for local planners used in navigation. All local planners written as plugins for the  node must adhere to this interface. Current local planners using the  interface are: Documentation on the C++ API for the  can be found here: . The  provides an interface for recovery behaviors used in  navigation. All recovery behaviors written as plugins for the  node must adhere to this interface. Current recovery behaviors using the  interface are: Documentation on the C++ API for the  can be found here:  nav_corenav_core::BaseGlobalPlannernav_core::BaseGlobalPlannernav_core::BaseGlobalPlannernav_core::BaseLocalPlannernav_core::BaseLocalPlannernav_core::BaseLocalPlannernav_core::RecoveryBehaviornav_core::RecoveryBehaviornav_core::RecoveryBehavior"
W1319,https://wiki.ros.org/reemc_bringup,Wiki,reemc_bringup,Launch files and scripts needed to bring up the ROS nodes of a REEM-C robot.
W1320,https://wiki.ros.org/tuw_multi_robot,Wiki,tuw_multi_robot,"This repository includes ros packages to plan routes for multiple robots on a search graph. It creates a search graph out of a pixel map and tries to find a path for multiple robots using an extended approach for prioritized planning. The inputs are the tuw_multi_robot_msgs/RobotInfo messages which include the robots pose, the map and the desired goal poses. The output are multiple synchronized routes given to the individual robots.
 

 
Use GitHub to . []
 The following figure represents the current state and planed developments on the tuw_multi_robot framework.  The green boxes show already existing modules while the red boxes are not yet implmented/released.  The framework is designed to cover all tools needed for an automated delivery system with autonomous vehicles. The current implementation of the system allows one to set goals for multiple vehicles using RViz or by a configuration file. In the future we also want a order management integrated which is capable to assign vehicles for specific deliveries and to generate goals needed by the multi robot route planner. The system provides a simple local motion controller for all robots, which allows a high number (> 100) of vehicles to be controlled in real time using stage. Furthermore, the design allows the usage of existing individual controllers running on each vehicle such as DWA implemented in move_base. "
W1321,https://wiki.ros.org/pr2_common_actions,Wiki,pr2_common_actions,"Various actions which help in moving the arms of the PR2
    or getting data from its tilting laser.

  "
W1322,https://wiki.ros.org/rtt_tf,Wiki,rtt_tf,This package contains the components of the rtt_tf package
W1323,https://wiki.ros.org/ur_modern_driver,Wiki,ur_modern_driver," This package has been deprecated. Users of CB3 and e-Series controllers should migrate to ur_robot_driver.The new driver for Universal Robots UR3, UR5 and UR10 robots with CB2 and CB3 controllers.




Use GitHub to . []
 This package is part of the  program. It currently contains nodes that support communication with Universal Robots' industrial robot controllers. The following instructions assume that a  has been created at $HOME/catkin_ws and that the source space is at $HOME/catkin_ws/src. Update paths appropriately if they are different on the build machine. v3.xv5.x<= 1.8.xur_modern_driverv1.8.x















"
W1324,https://wiki.ros.org/vrep_ros_plugin,Wiki,vrep_ros_plugin,"The vrep_ros_plugin package
 contains all the objects in the scene to which we have added a custom data. The handlers are derived classes that redefines the functions of the  in order to handle the object.  Vrep_ros_plugin contains the main code of the bridge. We wrote Vrep_ros_plugin starting from a template called v_repExtPluginSkeleton, available in the V-REP folder ""/programming"" with the porpoise to create your own plugin. You can find more information about the plugins in V-REP . "
W1325,https://wiki.ros.org/universal_robots,Wiki,universal_robots,"ROS-Industrial support for Universal Robots manipulators (metapackage).




Use GitHub to . []
 This stack is part of the  program. It currently contains packages that provide nodes for communication with Universal's industrial robot controllers, URDF models for various robot arms and the associated  packages. On supported Linux distributions (Ubuntu, up to 16.04 (Xenial),  and ): The following instructions assume that a  has been created at $HOME/catkin_ws and that the source space is at $HOME/catkin_ws/src. Update paths appropriately if they are different on the build machine. Refer to the  for more information on building catkin workspaces. See the  page for an overview of the available tutorials. ur_driverv1.8.16941v1.8.xuniversal_roboti386amd64sudo apt-get install ros-$ROS_DISTRO-universal-robots















"
W1326,https://wiki.ros.org/sr_utilities,Wiki,sr_utilities,"

     sr_utilities contains different useful header libraries (math libraries, etc...).

  



Please note that the robot_state_publisher should soon implement this feature (with a cleaner implementation), as stated by Wim in the . The node subscribes to the two topics to merge:  and . These are hard coded for the time being. Publishes the merged joint state messages to . "
W1327,https://wiki.ros.org/rosserial_windows,Wiki,rosserial_windows,"rosserial for Windows platforms.






 This package contains Windows-specific extensions required to run  on an Windows. It will generate a package of headers and a few cpp files that you will need to add to your Visual Studios project in order to communicate with a ROS system, usually over a TCP socket. Please see the  for examples of using rosserial_windows Visual Studio 2013 defaults to indenting using tabs. The ROS guidelines are for 2 spaces. To keep things consistent, all of the examples are with 2 spaces. You're welcome to use your editor however you like, but please do not submit code with tabs. See the following page from MSDN for how to set up your Visual Studios environment correctly:  error C1010: unexpected end of file while looking for precompiled header. Did you forget to add '#include ""stdafx.h""' to your source?"
W1328,https://wiki.ros.org/rc_cloud_accumulator,Wiki,rc_cloud_accumulator,"A viewer for the SLAM component of roboception based on ROS and PCL

  



The rc_cloud_accumulator ROS node subscribes to the following topics of the  After starting the , execute The  provides the following services /stereo/points2/pose/trajectoryTruerosrun rc_cloud_accumulator rc_cloud_accumulatorrosrun rc_cloud_accumulator rc_cloud_accumulator _voxel_grid_size_display:=0.01/rc_cloud_accumulator/toggle_pause/rc_cloud_accumulator/save_cloudvoxel_grid_size_displayvoxel_grid_size_saveminimum_distancemaximum_distanceoutput_filenamestart_pausedkeep_high_resolution"
W1329,https://wiki.ros.org/rosparam_shortcuts,Wiki,rosparam_shortcuts,"Quickly load variables from rosparam with good command line error checking.
See  for full documentation. "
W1330,https://wiki.ros.org/rosh_robot,Wiki,rosh_robot,"

     ROSH meta-plugin for the ROS 'robot' variant.

  rosh_robot is a meta-plugin that makes it easy to automatically load all desktop-related  plugins.  See the  documentation on how to automatically load rosh_robot when you start rosh. Please see the  documentation to find out more about rosh. "
W1331,https://wiki.ros.org/teraranger,Wiki,teraranger,"This package provides ros nodes for single sensors from Terabee
  is the long range Time-of-Flight distance sensor of the  product family. It provides calibrated distance readings in millimetres and has a range up to 60m, whilst remaining lightweight and small! Instead of laser,  Evo uses LED technology. React faster and detect obstacles with greater assurance,   is perfect for high-speed collision avoidance and object detection solution! With its 10cm to 3m range, 100Hz fixed update rate and greater accuracy(+/-2cm), the  , is optimized for close-range distance measurement.   Monitor heat variations, detect movement and capture the unseen! In a compact and affordable design, ideal for OEM integration in Smart City, Smart building, Robotics and Industrial applications. For more information about  :   is a lightweight, high-performance multi-pixel sensor based on infrared Time-of-Flight (ToF) technology. For more information about  :   is a lightweight, high-performance distance measurement sensor based on infrared Time-of-Flight (ToF) technology.  



 Github: * This package works with  ,  ,  ,   ,   ,  ,   and  . You can find more information below. For more information about  : * * * * For more information about  : * * * * * * For more information about  : * * For more information about  : * * /teraranger_evo_portnamestr, default: ""/dev/ttyACM0""_sensor_typestr, default: ""Evo_60m""/teraranger_evo_mini/range/teraranger_evo_mini/ranges_portnamestr, default: ""/dev/ttyACM0""Pixel_modeintRange_modeint/teraranger_evo_thermal/raw_temp_array/teraranger_evo_thermal/rgb_image/teraranger_evo_thermal/ptat_portnamestr, default: ""/dev/ttyACM0""_baudrateint, default: ""115200""thermal_image_flip_hboolthermal_image_flip_vboolthermal_image_interpolateboolmanual_min_scalingdouble_tmanual_max_scalingdouble_tMapint_t/teraranger_evo_64px/point_cloud/teraranger_evo_64px/depth_image_portnamestr, default: ""/dev/ttyACM0""_baudrateint, default: ""115200""depth_image_invertbooldepth_image_interpolateboolmin_distance_mmintmax_distance_mmintModeint/teraranger_one_portnamestr, default: ""/dev/ttyACM0""/teraranger_duo_portnamestr, default: ""/dev/ttyACM0""rosrun teraranger name_of_the_sensor"
W1332,https://wiki.ros.org/network_monitor_udp,Wiki,network_monitor_udp,"
    Facilities to monitor a network connection by sending UDP packets from
    a client to a server, which bounces them back to the client. The client
    collects statistics on latency and loss. The server is a C standalone utility
    or a ROS node. The client can be a ROS node, a standalone utility or a python class.
  

 records packets receive times and sorts them into latency bins based on their travel time. These latency bins can be periodically retrieved and information such as packet loss, average latency and bandwidth can be therefrom determined. 
 is a node that implements an action server which receives link testing goals. It instantiates and collects statistics from multiple s. Each source (i.e. link test) is independent of all others and can be parametrized differently in terms of bandwidth, latency bin thresholds, update (i.e. stats collection) interval and so on. It sends periodical feedback to the action client.  also implements logic for adaptive bandwidth tests: link tests that strive to saturate a link in terms of bandwidth while maintaining latency and loss within specified thresholds. 



 can also be used stand-alone, independent of ROS with  as in the example below: 

The basic link measurements are implemented by the class  (defined in ) and the  node.  sends UDP packets at a specified rate to  which timestamps them and echoes them back either via UDP or via ROS topic message. Multiple stream support is built in so multiple s on the same ROS node can ping packets off the same . For a ROS independent setup,  can be used instead of . The former is not a ROS node, but rather a standalone UDP server. By default,  does not use ROS messages for the return path and no ROS dependency is created on the class. Typically there would be one  node running on every machine in a test setup as each  supports any number of tests with destination sinks on different machines. The  implements the action client for link tests, as well as logging and test control logic via three classes: More usage examples with more complex configurations can be found in the  package. MonitorSourceudpmonclient.pyudpmonsinkMonitorSourceudpmonsinkMonitorSourceMonitorSourceudpmonsinkudpmonservudpmoncliMonitorSourceudpmonsourcenodeMonitorSourceudpmonsourcenodeudpmonsourcenode.pysourcenodelinktest.pyUdpmonsourceHandleudpmonsourcenode.pyudpmonsourcenodeUdpmonsourceHandleLinktestLinkTestUdpmonsourceHandleMetricLogMetricLogdurationfloat0.00.0update_intervalfloat0.15bwfloat5000000.0bw_typechar'c''c''a'latency_thresholdfloat0.01pktloss_thresholdfloat0.5tosbyte0x00pktsizeint1500ros_returnpathbooleanFalseroundtripbooleanFalsemax_return_timefloatrostopic_prefixstring""""udpmonsinkudpsink_feedbackudpmonsinksink_ipstring""""udpmonsinksink_portint0udpmonsinklatency_binsfloat[][.005, .01, .025, .05, .075, .1]latencyfloatlossfloatbandwidthfloatlatency_histogramfloatudpmonsinkudpsink_feedbackudpmoncli.pyudpmonserv# rosrun network_monitor_udp udpmonserv 12345

# rosrun network_monitor_udp udpmoncli.py 127.0.0.1 12345 10 1500
  0.501: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %
  1.001: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %
  1.501: 100   0   0   /   0   0   0   0 avg:   0.3 ms avgr:   0.3 ms loss:   0.00 %
  2.001: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %
  2.501: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %
  3.000: 100   0   0   /   0   0   0   0 avg:   0.4 ms avgr:   0.4 ms loss:   0.00 %<launch>
<node name=""sink"" pkg=""network_monitor_udp"" type=""udpmonsink"" args=""12345"" output=""screen""/>
<node name=""source"" pkg=""network_monitor_udp"" type=""udpmonsourcenode.py"" output=""screen""/>
<node name=""test_node"" pkg=""network_monitor_udp"" type=""sample_bwtest.py"" required=""true"" output=""screen""/>
</launch> import roslib; roslib.load_manifest('network_monitor_udp')
import rospy

from network_monitor_udp.linktest import UdpmonsourceHandle
from network_monitor_udp.linktest import LinkTest
from network_monitor_udp.msg import LinktestGoal

if __name__ == '__main__':
    rospy.init_node('test_node')
        
    source = UdpmonsourceHandle() 
    source.cancel_all_tests()

    try:
        print ""Link capacity: %.2fMbit/s""%(source.get_link_capacity(sink_ip=""127.0.0.1"", sink_port=12345)/1e6)
    finally:
        source.cancel_all_tests()# roslaunch launch_nodes.launch

[...]

core service [/rosout] found
process[sink-1]: started with pid [20043]
process[source-2]: started with pid [20044]
process[test_node-3]: started with pid [20055]
Link capacity: 68.71Mbit/s"
W1333,https://wiki.ros.org/steer_drive_ros,Wiki,steer_drive_ros,Steer driving meta package for ROS.An example of using the packages can be seen in . 
W1334,https://wiki.ros.org/moveit_sim_controller,Wiki,moveit_sim_controller,"A simulation interface for a hardware interface for ros_control, and loads default joint values from SRDF
See  for full documentation. "
W1335,https://wiki.ros.org/wire_core,Wiki,wire_core,"The wire meta package is implements a framework that 
     generates and maintains one consistent world state estimate based 
     on object detections. It solves the data association problem by 
     maintaining multiple hypotheses and facilitates tracking of various
     object attributes. The state estimators used for estimation and the
     probabilistic models used for association can be configured.









The wire_core package it is the core of the  stack. It takes detections and fuses them to a world state estimate. Technical details can be found here: J. Elfring, S. van den Dries, M.J.G. van de Molengraft, M. Steinbuch, Semantic world modeling using probabilistic multiple hypothesis anchoring, Robotics and Autonomous Systems, Volume 61, Issue 2, February 2013, Pages 95-105, () An extended list of tutorials can be found . The package listens to  generated by perceptual algortihms. It fuses the evidence using object class specific models. It includes multiple hypothesis-based data association and can be configured easily. See the  for more information about the configuration of this package. First install the stack by following the steps mentioned . Then, launch: /world_evidence/world_stateworld_model_framestringoutput_framestringevidence_topicsstring[]$ roslaunch wire_core start.launch***** 1352890681.479009 ***** 
   Number of hypotheses        = 1 
   Max probability             = 1 
   Tree height                  = 0 
Num MAP objects:      0 
Last update:          0 seconds 
Max update:           0 seconds 
Evidence buffer size: 0 
***** 1352890682.228999 ***** 
   Number of hypotheses        = 1 
   Max probability             = 1 
   Tree height                  = 0 
Num MAP objects:      0 
Last update:          0 seconds 
Max update:           0 seconds 
Evidence buffer size: 0 $ roslaunch wire_tutorials rviz_wire_fuerte.launch$ roslaunch wire_tutorials rviz_wire_electric.launch








"
W1336,https://wiki.ros.org/rtt_common_msgs,Wiki,rtt_common_msgs,"The rtt_common_msgs package 




  sudo aptitude install ros-electric-rtt-common-msgsgit clone http://git.mech.kuleuven.be/robotics/rtt_common_msgs.git
rosmake rtt_common_msgs"
W1337,https://wiki.ros.org/stdr_launchers,Wiki,stdr_launchers,"Launch files, to easily bringup server, robots, guis





The  package provides ROS launchers for the basic  functionalities. Specifically the launchers available are: Initializes a bare . Initializes an  and automatically loads the  map (found in the  package). Initializes an  and automatically loads the  map (found in the  package. Also an instance of  is executed. Initializes an  and automatically loads the  map (see ). Also an instance of  is executed. Finally a robot of type  (see ) is spawned in the map. Wrapper launcher for the , modified so that the essential information about  are visible.  "
W1338,https://wiki.ros.org/sr_gui_movement_recorder,Wiki,sr_gui_movement_recorder,"
    This is a rosgui plugin for recording and replaying movements.
   "
W1339,https://wiki.ros.org/schunk_ezn64,Wiki,schunk_ezn64,"Xacro model and usb driver for basic communication with Schunk EZN64 gripper





 
 





  This package is part of  stack. It allows user to control Schunk EZN64 gripper over USB using standard ROS services and provides Xacro model for easier integration with various robots. Git clone  to your ""folder and  as usual. This package depends on  library which should be part of ROS installation. To check availibility type: These services are ROS user interface to Schunk EZN64 gripper. Except ""set_position"" all of them use  requests, so you don't need to specify any values, just ""rosservice call"" as in the example below. To test the driver start by calling the  service (  request): To get actual gripper position, call  service (  request): Gripper should respond with actual position value in  format: To move the gripper to target position, call  service ( request): where """" is within a range of <0 - 12> mm. The current driver supports, which means that ""goal_velocity"" and ""goal_acceleration"" are permanently set to default values. To reference gripper, call  service (  request). Referencing may also help in cases you are not able to move the gripper although everything else looks okay: joint_statesschunk_ezn64/referenceschunk_ezn64/get_errorschunk_ezn64/acknowledge_errorschunk_ezn64/get_positionschunk_ezn64/set_positionschunk_ezn64/stopvendor_idstd_msgs/UInt16product_idstd_msgs/UInt16gripper_idstd_msgs/UInt8robot_end_linkschunk_ezn64_base_linkschunk_ezn64_base_linkschunk_ezn64_finger_1_linkschunk_ezn64_base_linkschunk_ezn64_finger_2_linkschunk_ezn64_base_linkschunk_ezn64_finger_3_link$ sudo apt-get install libusb-1.0-0SUBSYSTEM==""usb""
ATTR{idVendor}==""7358""
ATTR{idProduct}==""371""
ACTION==""add""
MODE:=""0666""$ roslaunch schunk_ezn64 ezn64_usb_control.launch$ rostopic echo /joint_statesheader:
  seq: 34
  stamp:
    secs: 1443076490
    nsecs: 513091024
  frame_id: ''
name: ['ezn64_finger_1_joint', 'ezn64_finger_2_joint', 'ezn64_finger_3_joint']
position: [0.011971454620361328, 0.011971454620361328, 0.011971454620361328]
velocity: []
effort: []
---
header:
  seq: 35
  stamp:
    secs: 1443076490
    nsecs: 612699408
  frame_id: ''
name: ['ezn64_finger_1_joint', 'ezn64_finger_2_joint', 'ezn64_finger_3_joint']
position: [0.01197367763519287, 0.01197367763519287, 0.01197367763519287]
velocity: []
effort: []$ rosservice listschunk_ezn64/reference
schunk_ezn64/get_error
schunk_ezn64/acknowledge_error
schunk_ezn64/get_position
schunk_ezn64/set_position
schunk_ezn64/stop$ rosservice call /schunk_ezn64/get_errorerror_code: 0$ rosservice call /schunk_ezn64/get_positionactual_position: 11.9702377319$ rosservice call /schunk_ezn64/set_position valuegoal_accepted: True$ rosservice call schunk_ezn64/reference$ roslaunch schunk_ezn64 ezn64_visualize_standalone.launch"
W1340,https://wiki.ros.org/ridgeback_robot,Wiki,ridgeback_robot,"Metapackage of software to install on Ridgeback.
Metapackage capturing software to be installed on . "
W1341,https://wiki.ros.org/rail_grasp_collection,Wiki,rail_grasp_collection,"Grasp Collection for Constructing a Grasping and Recognition Database




The  package contains nodes to collect demonstration grasps for detected point cloud objects.  These demonstrations can then be used to build object models for recognition and manipulation using the  package.  Demonstrations are stored in a grasp database, handled by . To install the  package, you can install from source with the following commands: The  package contains launch files for launching either the rail_grasp_collection node or the rail_grasp_retriever node individually, and for launching both nodes together.  These can be launched with the following commands, respectively: Grasp collection can also be run and executed with an rviz plugin found in . rail_grasp_collectionrail_grasp_collection/grasp_and_storerail_grasp_collection/grasp_and_storegripper_action_server paramlift_action_server paramverify_grasp_action_server paramsegmented_objects_topic paramrail_grasp_collection/debugdebugboolrobot_fixed_frame_idstringeef_frame_idstringsegmented_objects_topicstringgripper_action_serverstringlift_action_serverstringverify_grasp_action_serverstring/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringrail_grasp_retriever/retrieve_grasprail_grasp_retriever/retrieve_grasprail_grasp_retriever/point_cloudrail_grasp_retriever/pose/graspdb/hoststring/graspdb/portint/graspdb/userstring/graspdb/passwordstring/graspdb/dbstringrail_pick_and_placerail_grasp_collection




roslaunch rail_grasp_collection rail_grasp_collection.launchroslaunch rail_grasp_collection rail_grasp_retriever.launchroslaunch rail_grasp_collection rail_grasp_collection_and_retriever.launch"
W1342,https://wiki.ros.org/pr2_mannequin_mode,Wiki,pr2_mannequin_mode,"The pr2_mannequin_mode package

As with all applications, you must first . roslaunch pr2_mannequin_mode pr2_mannequin_mode.launch"
W1343,https://wiki.ros.org/rospeex_msgs,Wiki,rospeex_msgs,This package defines messages used in rospeex.
W1344,https://wiki.ros.org/rqt_robot_plugins,Wiki,rqt_robot_plugins,"Metapackage of rqt plugins that are particularly used with robots
   during its operation.
   
   To run any rqt plugins, just type in a single command ""rqt"", then select any plugins you want from the GUI that launches afterwards.
   
   rqt consists of three following metapackages:
    

See .  Other than that, there's extra policy for this : metapackageThere's "
W1345,https://wiki.ros.org/velodyne_gazebo_plugins,Wiki,velodyne_gazebo_plugins,Gazebo plugin to provide simulated data from Velodyne laser scanners.Documentation at  
W1346,https://wiki.ros.org/qb_chain_description,Wiki,qb_chain_description,"This package contains the ROS description for complex chains of qbrobotics® devices.This package contains the description resources for  device chains. It includes the / model of the chained systems exploiting single module descriptions, and extends them with additional parts when required. "
W1347,https://wiki.ros.org/rcll_ros_msgs,Wiki,rcll_ros_msgs,"Message definitions for RCLL refbox communication


This package contains messages and services providing the interface to interact with the  of the  which is also used in the . In addition to this msgs package, you will also need the  (see its documentation there for a description of the actual topics). But you may, for example, choose to keep the calling code on a different machine than the peer. The messages have a close relation to the respective protobuf message types of the referee box. We suggest also consulting the .  "
W1348,https://wiki.ros.org/abb_irb2400_moveit_config,Wiki,abb_irb2400_moveit_config,"
      MoveIt package for the ABB IRB 2400.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 2400 with the MoveIt Motion Planning
      Framework.
    
This package is part of the  program. "
W1349,https://wiki.ros.org/rb1_base_pad,Wiki,rb1_base_pad,"The rb1_base_pad packageThis package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux () so that the final command to the robot can be set by different components (move_base, etc.) "
W1350,https://wiki.ros.org/rosfmt,Wiki,rosfmt,"fmt is an open-source formatting library for C++.
		It can be used as a safe and fast alternative to (s)printf and IOStreams."
W1351,https://wiki.ros.org/nav2d_msgs,Wiki,nav2d_msgs,Messages used for 2D-Navigation.
W1352,https://wiki.ros.org/maggie_skills_msgs,Wiki,maggie_skills_msgs,"maggie_skills_msgs metapackage


Newly proposed, mistyped, or obsolete package. Could not find package ""basic_states_skill_msgs"" in rosdoc: /home/rosbot/docs/api/basic_states_skill_msgs/manifest.yaml 
Newly proposed, mistyped, or obsolete package. Could not find package ""batteries_skill_msgs"" in rosdoc: /home/rosbot/docs/api/batteries_skill_msgs/manifest.yaml 
Newly proposed, mistyped, or obsolete package. Could not find package ""touch_skill_msgs"" in rosdoc: /home/rosbot/docs/api/touch_skill_msgs/manifest.yaml This package defines -specific message and service types for the skills. Most users will not use these types directly, but rather through Maggie-specific visualizations and utilities. "
W1353,https://wiki.ros.org/uos_rotunit_snapshotter,Wiki,uos_rotunit_snapshotter,This modul assemble a point cloud for a given rotational angle from a rotating laserscanner.
W1354,https://wiki.ros.org/rc_common_msgs,Wiki,rc_common_msgs,Common msg and srv definitions used by Roboception's ROS packages
W1355,https://wiki.ros.org/kuka_kr10_support,Wiki,kuka_kr10_support,"
      ROS-Industrial support for the KUKA KR 10 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 10 manipulators. This currently includes the R1100 sixx only.
    :
      Joint limits and maximum joint velocities are based on the information
      in the  version .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1356,https://wiki.ros.org/coverage_path,Wiki,coverage_path,"A package that generates an optimal path to cover a given area with a cyber physical system (CPS).

 (, default: 1)  (, default: ) 


The communication between CPSs is based on the . The following packages of the  are required: The following packages of the  are required: to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. coverage_pathidintegeroutputstringscreenscreenlogparamcoverage_path.yamlcoverage_pathcoverage_patharea/assigneddivide_area=truearea/mapdivide_area=falsecoverage_path/pathvisualizecoverage_path/waypointvisualizecoverage_path/mstvisualizecoverage_path/pathcoverage_path/waypointarea/get_area~loop_ratereal~queue_sizeinteger~resolutionreal~visualizeboolean~divide_areaboolean~verticalboolean~turning_pointsbooleanroslaunch coverage_path coverage_path.launch"
W1357,https://wiki.ros.org/slime_ros,Wiki,slime_ros,"Extensions for slime to assist in working with ROS packages




This is an extension of  (a ""contrib"") that helps you to deal with ASDF systems in ROS packages. It also adds a REPL shortcut  to the slime REPL. Then call the initialization script that generates  in your home directory for configuring your SBCL. And then add the following to your : The most up-to-date version of  code can be found . Installation instructions are in the README file. What you'll need to do will be something like the following: If you've set up your emacs init file correctly you should be able to start the REPL by typing . Now, by pressing  (coma) in an empty REPL prompt, you can select the shortcut . Press enter and select a ROS package and an ASDF system inside this ROS package. Slime will set the variable  and perform a load operation on the selected system. The package contains one customization variable, . It allows the user to select ido mode completion or similar completion mechanisms. To change its value, use . ros-load-system.sbclrcslime_rosM-x slime,ros-load-systemros-load:*current-ros-package*slime-ros-completion-functionM-x customize-group slime-ros$ sudo apt-get install ros-DISTRO-slime-ros$ rosrun slime_ros slime_ros_init(require 'slime-config ""/opt/ros/DISTRO/share/slime_ros/slime-config.el"")$ cd YOUR_CATKIN_WS/src
$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git
$ wstool update ros_emacs_utils
$ cd ..
$ catkin_make
$ catkin_make install
$ emacs -nw ~/.emacs.d/init.el # edit your emacs configuration file"
W1358,https://wiki.ros.org/kurt_base,Wiki,kurt_base,"

     This package contains a driver for KURT mobile robot bases and for their laser rotation units.

  

rot_velcmd_veljoint_statesodomimurange~wheel_perimeterfloat~axis_lengthfloat~turning_adaptationfloat~ticks_per_turn_of_wheelint~use_rotunitbool~x_stddevfloat~rotation_stddevfloat~cov_xyfloat~cov_xrotationfloat~cov_yrotationfloat~feedforward_turnfloat~speedtable~kifloat~speedtable~kpfloat~speedtable~publish_tfboolodombase_linktf_prefixstring~rotunit_speedint~speedtablestring"
W1359,https://wiki.ros.org/rwt_utils_3rdparty,Wiki,rwt_utils_3rdparty,The rwt_utils_3rdparty package
W1360,https://wiki.ros.org/view_controller_msgs,Wiki,view_controller_msgs,"Messages for (camera) view controllers


This package provides the messages necessary for controlling the behaviour of the RViz view controller plugin provided by the  package. This package has been released into Hydro and Indigo. Installation through  is easiest in most cases (note that installation of  should install this package as a dependency automatically): See the ,  and  Python scripts installed in the packages directory for examples of how to use the messages provided by this package. apt-getCameraTestControlsTestSquareTestsudo apt-get install ros-hydro-view-controller-msgssudo apt-get install ros-indigo-view-controller-msgs"
W1361,https://wiki.ros.org/nao_dcm_bringup,Wiki,nao_dcm_bringup,"Bring-up the nao_dcm driver to connect to Aldebaran's Nao robot (v4).




sudo apt-get install ros-indigo-nao-robot ros-indigo-nao-meshes ros-indigo-nao-controlcatkin_makeroslaunch nao_dcm_bringup nao_dcm_H25_bringup_remote.launch robot_ip:=<ROBOT_IP>roslaunch nao_moveit_config moveit_planner.launchroslaunch nao_dcm_bringup nao_dcm_H25_bringup_position.launch robot_ip:=<ROBOT_IP>rostopic pub /nao_dcm/LWristYaw_position_controller/command std_msgs/Float64 ""data: 0"""
W1362,https://wiki.ros.org/khi_robot,Wiki,khi_robot,Meta package for khi_robot
W1363,https://wiki.ros.org/kuka_rsi_hw_interface,Wiki,kuka_rsi_hw_interface,"A ROS-Control hardware interface for use with KUKA RSI



This package is part of the  program. See the  page. This package can be used with both KR C2 () and KR C4 () controllers. See the  page for a listing of common errors and possible solutions. "
W1364,https://wiki.ros.org/kuka_resources,Wiki,kuka_resources,"
      Shared resources for KUKA manipulators within ROS-Industrial.
    
      This package contains common urdf / xacro resources used by KUKA robot
      support packages within the ROS-Industrial program.
    

This package is part of the  program. See the  page. "
W1365,https://wiki.ros.org/rqt_nav_view,Wiki,rqt_nav_view,rqt_nav_view provides a gui for viewing navigation maps and paths.
W1366,https://wiki.ros.org/viodom,Wiki,viodom,"Visual odometry package, currently supporting stereo camera + IMU



 This package contains one single node: , which estimates robot motion based on incoming raw images and IMU mesaurements from the . To correctly estimate the motion, the node first needs to wait for a few seconds to initialize an IMU filter. The transforms tree (following ) is as follows: Visual odometry algorithms generally calculate To be able to calculate  based on ,  the transformation from the camera frame to the robot frame has to be  known. Therefore this implementation needs to know the tf  →  to be able to publish  → . The node currently uses default values from the sensor setup on the AscTec Neo Research platform. If you use viodom in an academic context, please cite the following publication:  viodom_nodeodombase_linkcamerabase_linkcameraodombase_link@INPROCEEDINGS{7502653,
  author={F. J. Perez-Grau and F. R. Fabresse and F. Caballero and A. Viguria and A. Ollero},
  booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)},
  title={Long-term aerial robot localization based on visual odometry and radio-based ranging},
  year={2016},
  pages={608-614},
  doi={10.1109/ICUAS.2016.7502653},
  month={June},}"
W1367,https://wiki.ros.org/pattern_manager,Wiki,pattern_manager,"A ROS package for defining, configuring, and working with patterns in robotics applications. This allows a robotics application developer to easily define a pattern, or group of patterns, for batch processing of structured parts, e.g. palletizing operations.

  A list of tutorials for getting started with pattern_manager can be found on the tutorials page . These tutorials cover interaction with the pattern_manager node via ROS service calls using CLI.  An RQt-plugin has also been created as a GUI for pattern_manager. It can be found  . Currently,  only exists as source files on , although an official release is planned for sometime in the future.     root [tf0]                      # <transform-name> [<transform-number>]
    ├── grp1 [tf1]                  # transform as pattern group/container
    │   ├── lin1 [tf2]              # ex. linear pattern of transforms
    │   │   ├── lin1_1 [tf3]           
    │   │   ├── lin1_2 [tf4]
    │   │   ├── lin1_3 [tf5]
    │   │   └── ...
    │   └── lin2 [tf11]
    │       ├── lin2_1 [tf12]           
    │       ├── lin2_2 [tf13]
    │       └── lin2_3 [tf14]
    ├── grp2 [tf6]
    │   ├── grp3 [tf7]
    │   │   ├── rect1 [tf8]         # ex. rectangular pattern of transforms
    │   │   │   ├── rect1_1 [tf9]
    │   │   │   ├── rect1_2 [tf10]
    │   │   │   └── ...
    │   │   └── ...
    │   └── ...
    └── ..."
W1368,https://wiki.ros.org/maggie_motor_drivers,Wiki,maggie_motor_drivers,"motor drivers for Maggie robot

"
W1369,https://wiki.ros.org/ros_ethercat_hardware,Wiki,ros_ethercat_hardware,Package for creating a hardware interface to the robot using the EtherCAT motor controller/driver
W1370,https://wiki.ros.org/pr2_plugs_common,Wiki,pr2_plugs_common,"

     pr2_plugs_common contains common utilies for plugging in the PR2 robot. 

  "
W1371,https://wiki.ros.org/maggie_bringup,Wiki,maggie_bringup,"maggie_bringup launchers is a package that collects together the scripts,  files, and dependencies that are required to bring the social robot  into a running state. 





For running all the system is necessary the file . This launch file contains all nodes to run the complete  robot. For running the basic of the robot is necessary the file . This launch file contains all nodes to run the complete  robot. maggie_bringupmaggie_start.launchmaggie_start_basic.launchmaggie_start_basic.launch $ roslaunch maggie_bringup maggie_start.launch $ roslaunch maggie_bringup maggie_start_basic.launch $ ls -la /etc/udev/rules.d | grep maggie $ rosrun maggie_bringup install.sh"
W1372,https://wiki.ros.org/mingw_cross,Wiki,mingw_cross,"

     Installer script for the mingw cross environment. This will install to /opt/mingw
     and immediately begin cross-compiling gcc, boost and qt. Other libraries can be added by
     simply cd'ing to /opt/mingw and running make for the desired target.

  



You can of course install the mingw cross environment directly yourself following the instructions at the . Alternatively: Installation location can be moved if the  environment variable is set before running . See the  for usage patterns. MINGW_INSTALL_PREFIXmake install> roscd mingw_cross
> make install       # downloads, installs into ~/mingw 
                     # compiles gcc, apr, apr-util, log4cxx, boost, qt
                     # adds mingw_cross binary path to PATH in ~/.bashrc
> make uninstall     # remove ~/mingw and delete modifications in ~/.bashrccd ~/mingw
make wxwidgets"
W1373,https://wiki.ros.org/ros_ethercat_loop,Wiki,ros_ethercat_loop,Main loop to run EtherCAT robot hardware.
W1374,https://wiki.ros.org/industrial_trajectory_filters,Wiki,industrial_trajectory_filters,"
     ROS Industrial libraries/plugins for filtering trajectories.
   
     This package is part of the ROS Industrial program and contains libraries
     and moveit plugins for filtering robot trajectories.
   





Use GitHub to . []
 For more detailed examples see the  page. sample_durationfloatn_pointsfloat  service_type: FilterJointTrajectoryWithConstraints
  filter_chain:
# Uniformly sample motion (creates smooth motion on controller)
  -
    name: uniform_sample_filter
    type: IndustrialUniformSampleFilterJointTrajectoryWithConstraints
    params: {sample_duration: 0.010}
# Limit the number of points sent to the controller
  -
    name: n_point_filter
    type: IndustrialNPointFilterJointTrajectoryWithConstraints
    params: {n_points: 10}<arg name=""planning_adapters"" value=""   my_filter_package/MyFilter
    default_planner_request_adapters/AddTimeParameterization
    default_planner_request_adapters/FixWorkspaceBounds
    default_planner_request_adapters/FixStartStateBounds
    default_planner_request_adapters/FixStartStateCollision
    default_planner_request_adapters/FixStartStatePathConstraints"" /><param name=""my_filter_parameter"" value=""40"" />"
W1375,https://wiki.ros.org/urdf_traverser,Wiki,urdf_traverser,"Urdf traverser (C++) which provides functions to traverse
      the URDF and convenience functions to access the URDF model."
W1376,https://wiki.ros.org/industrial_robot_client,Wiki,industrial_robot_client,"industrial robot client contains generic clients for connecting 
     to industrial robot controllers with servers that adhere to the
     simple message protocol.

 



Use GitHub to . []
 The  package provides a standardized interface for controlling industrial robots, based on the ROS-Industrial .  This package includes a C++ reference implementation of the specification, using the  protocol to communicate with a compatible server running on a standalone industrial robot controller. Primarily, this package provides the industrial_robot_client library.  The intent is for robot-specific implementations to reuse code from this library using standard C++ derived-class mechanisms, to avoid much of the copy/paste duplication in current industrial-robot driver implementations.   This package also provides generic nodes exposing the base industrial_robot_client functionality.  If a robot does not require any specific client-side code, then it may be sufficient to run these standard nodes.   describes this usage in more detail. A ROS-Industrial REP describing the Simple Message protocol is currently being reviewed. See . Rather than make a new copy of the entire ROS client codebase, it is recommended that the integrator use a derived-class approach to only re-implement the minimal functionality required.  Wherever possible, the new code should call the base class reference-implementation functions to avoid code duplication and maintain consistent operations.  It may be helpful to review the library's  to determine which functionality may need replacing.  Simple joint reordering and renaming can be handled through existing capabilities, as described . industrial_robot_client




























"
W1377,https://wiki.ros.org/kobuki_msgs,Wiki,kobuki_msgs,"
      Kobuki message and service types: custom messages and services for Kobuki packages.
     

<kobuki AT yujinrobot DOT com>$ sudo apt-get install ros-groovy-kobuki-msgs$ sudo apt-get install ros-hydro-kobuki-msgs"
W1378,https://wiki.ros.org/pr2_arm_kinematics,Wiki,pr2_arm_kinematics,"This package provides a kinematics implementation for the PR2 robot. It can be used to compute forward and inverse kinematics.







The pr2_arm_kinematics package is a PR2 specific package that provides IK solutions for the PR2 robot arms. The recommended interface is through ROS. The node provides multiple interfaces (listed in the ROS API below) and can be used to compute the closest IK solution to an initial guess. More information on using this package can be found in the API documentation. Example code for using this package can be found in the . pr2_arm_kinematics provides services for IK computation. It can be configured using ROS parameters. The ROS API is explained in greater detail below. To get a collision free version of this node, check out the . Tutorials for this package can be found in the . node_namespace/get_iknode_namespace/get_fknode_namespace/get_ik_solver_infonode_namespace/get_fk_solver_info~free_angleint~search_discretizationdouble~root_namestring~tip_namestring"
W1379,https://wiki.ros.org/rr_openrover_basic,Wiki,rr_openrover_basic,"The rr_openrover_basic package
 







 This code is for those working with the Rover Robotics . The  communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. /cmd_vel/managed/rr_openrover_basic/fan_speed/rr_openrover_basic/odom_encoder/rr_openrover_basic/raw_fast_rate_data/rr_openrover_basic/raw_med_rate_data/rr_openrover_basic/raw_slow_rate_data/rr_openrover_basic/battery_status_a/rr_openrover_basic/battery_status_b~portstring""/dev/ttyUSB0""~enable_timeoutbooltrue~timeoutfloat0.5~drive_typestring""4wd""~total_weightfloat20.0~traction_factorfloatdepends on drive type chosen~odom_covariance_0float0.01~odom_covariance_35float0.03sudo apt-get install ros-kinetic-rr-openrover-basicroslaunch rr_openrover_basic example.launchrostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_a
rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_bmanaged_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)
managed_control_input.header.stamp = rospy.Time.now()
managed_control_input.header.frame_id = 'none'
managed_control_input.twist.linear.x=0.0
managed_control_input.twist.angular.y=0.0
managed_control_input.twist.angular.z=0.5
managed_pub.publish(managed_control_input)rosrun rr_openrover_basic openrover_basic_node<launch>
    <arg name=""openrover_node_name"" default=""rr_openrover_basic""/>

    <!-- OpenRover Driver -->
    <node pkg=""rr_openrover_basic"" type=""openrover_basic_node"" name=""$(arg openrover_node_name)"" respawn=""false"" output=""screen"">
        <param name=""port"" value=""/dev/rover"" />
        <param name=""drive_type"" value=""4wd"" />
        <param name=""enable_timeout"" type=""bool"" value=""true""/>
        <param name=""timeout"" type=""double"" value=""0.3""/>
        <param name=""total_weight"" type=""double"" value=""20.41""/>
        <param name=""traction_factor"" value=""0.610""/>
        <param name=""odom_covariance_0"" value=""0.01""/>
        <param name=""odom_covariance_35"" value=""0.03""/>
    </node>

    <!-- OpenRover InOrbit Diagnostics -->
    <node pkg=""rr_openrover_basic"" type=""diagnostics.py"" name=""rr_openrover_diagnostics_node"">
        <remap from=""/raw_slow_rate_data"" to=""/$(arg openrover_node_name)/raw_slow_rate_data""/>
    </node>
</launch>"
W1380,https://wiki.ros.org/nao_description,Wiki,nao_description,"Description of the Nao robot model that can be used with robot_state_publisher to display the robot's state of joint angles. 
  Nao's URDF description contains all joints and links according to the  for V3 and V4 Naos. In accordance with  and  the root link is , directly connected to . The camera frames are  and .  publishes the  transform and a  frame, projected between the feet on the ground. The defined links for the end effectors are  for the arms and  for the feet. "
W1381,https://wiki.ros.org/utilmm,Wiki,utilmm,"
    This library is a collection of useful C++ classes
  "
W1382,https://wiki.ros.org/nao_apps,Wiki,nao_apps,"Applications for NAO using the NAOqi API

nao_alife/disablednao_alife/interactivenao_alife/safeguardnao_alife/solitarynao_behaviorsrun_behaviorget_installed_behaviorsdiagnosticsnao_footstepsfootstepfootstep_srvclip_footstep_srv~init_stiffnessfloatnao_ledsblinkcolorsblink_durationblink_rate_meanblink_rate_sdbg_colorfade_rgbled_namecolorfade_durationspeech_action/goal/speech_vocabulary_action/goalspeechword_recognizedreconfigurestart_recognitionstop_recognition~voicestring~languagestring~volumefloat~vocabularylist of strings~enable_audio_expressionboolean~enable_visual_expressionboolean~word_spottingbooleantactile_touchbumperfoot_contactnao_walkerspeechcmd_velcmd_posecmd_stepread_foot_gait_config_srvcmd_vel_srvcmd_step_srvcmd_pose_srvstop_walk_srvneeds_start_walk_pose_srvenable_arms_walking_srv~step_frequencydouble~use_walk_poseboolean~enable_foot_contact_protectionboolean~use_foot_gait_configboolean~foot_gait_configALValue/Tupel~init_stiffnessfloat"
W1383,https://wiki.ros.org/khi_duaro_gazebo,Wiki,khi_duaro_gazebo,The khi_duaro_gazebo package
W1384,https://wiki.ros.org/mpc_local_planner,Wiki,mpc_local_planner,"The mpc_local_planner package implements a plugin
    to the base_local_planner of the 2D navigation stack.
    It provides a generic and versatile model predictive control implementation
    with minimum-time and quadratic-form receding-horizon configurations."
W1385,https://wiki.ros.org/motoman_sia5d_moveit_config,Wiki,motoman_sia5d_moveit_config,"An automatically generated package with all the configuration and launch files for using the motoman_sia5d with the MoveIt Motion Planning Framework
This package is part of the  program.  "
W1386,https://wiki.ros.org/maggie_rfid,Wiki,maggie_rfid,"rfid node





This device supports all the drivers implemented in the  package. rfid_writerfid_write~num_deviceint $ roslaunch maggie_rfid rfid_head.launch robot:=maggie $ roslaunch maggie_rfid rfid_base.launch robot:=maggie $ rostopic echo /maggie/rfid_write"
W1387,https://wiki.ros.org/khi_duaro_ikfast_plugin,Wiki,khi_duaro_ikfast_plugin,The khi_duaro_ikfast_plugin package
W1388,https://wiki.ros.org/naoqi_driver_py,Wiki,naoqi_driver_py,"
      Python implementation of the driver package for the Naoqi robot, providing access to walking commands,
      joint angles, and sensor data (odometry, IMU, ...). The
      most-current version is compatible with the Nao API version 1.12 or newer,
      connecting to a real or simulated Nao by wrapping Aldebaran Robotics'
      NaoQI API in Python. This requires the ""lib"" directory of the Aldebaran
      Python SDK to be in your PYTHONPATH environment variable.

      Note that cameras drivers are provided in a separate package (naoqi_sensors_py).
    

odomimujoint_statesjoint_stiffness~sensor_ratefloat~base_frame_idstring~odom_frame_idstring~use_joint_sensorsbooleanbase_linkodom/move_base_simple/goal/rosout"
W1389,https://wiki.ros.org/urdf_viewer,Wiki,urdf_viewer,"A urdf viewer which converts the URDF to inventor first
      and then displays it in SoQtExaminerViewer"
W1390,https://wiki.ros.org/velo2cam_calibration,Wiki,velo2cam_calibration,"The velo2cam_calibration package
 











: In order to test the algorithm with a proper ground truth, a simulator environment in Gazebo is provided  
 : Other size may be used for convenience. If so, please configure nodes parameters accordingly. 
Package developed at , Universidad Carlos III de Madrid. cloud1 (velo2cam_calibration::) cloud2 (velo2cam_calibration::) 
[1] Guindel, C., Beltrán, J., Martín, D. and García, F. (2017). Automatic Extrinsic Calibration for Lidar-Stereo Vehicle Sensor Setups. . Pre-print available  roslaunch velo2cam_calibration laser_pattern.launchroslaunch velo2cam_calibration stereo_pattern.launchroslaunch velo2cam_calibration velo2cam_calibration.launch"
W1391,https://wiki.ros.org/soem,Wiki,soem,"ROS wrapper for the Simple Open EtherCAT Master SOEM.
    This is an updated version of the original SOEM wrapper released into ROS now including
    the upstream Repo as a git subtree.See  in the repository for further information. "
W1392,https://wiki.ros.org/tuw_multi_robot_goal_generator,Wiki,tuw_multi_robot_goal_generator,"The tuw_multi_robot_goal_generator package


  () 
 ( default: ""/tmp/goals.txt"")  ( default: ""false"") 

  () 
 ( default: ""/tmp/goals.txt"")  ( default: ""1.0"")  ( default: ""false"")  ( default: ""true"") 

  () 
  ()   () 
 ( default: ""-"")  ( default: ""-1"")  ( default: ""map"")  ( default: ""robot_"")  ( default: ""0.5"")  ( default: ""2.0"")  ( default: ""0.2"")  ( default: ""1000"") 
Use GitHub to . []
  goalstuw_multi_robot_msgs/RobotGoalsArray~run_oncestring~file_nameboolgoalstuw_multi_robot_msgs/RobotGoalsArray~file_namestring~loop_ratedouble~run_oncebool~time_nowtime_nowmapnav_msgs/OccupancyGridgoalstuw_multi_robot_msgs/RobotGoalsArrayvalid_goal_locationsnav_msgs/OccupancyGrid~nr_of_robotsint~nr_of_available_robotsint~frame_idstring~robot_name_prefixstring~distance_boundarydouble~distance_between_robotsdouble~distance_to_map_borderdouble~max_resampleint"
W1393,https://wiki.ros.org/pr2_mechanism_msgs,Wiki,pr2_mechanism_msgs,"This package defines services that are used to communicate with
     the realtime control loop. It also defines messages
     that represent the state of the realtime controllers, the joints
     and the actuators.
"
W1394,https://wiki.ros.org/oculus_rviz_plugins,Wiki,oculus_rviz_plugins,"RViz plugins for the Oculus Rift.
 In RViz, add an OculusDisplay. This will create an additional window with a stereo rendering of the contents of the main RViz rendering area. Check ""Render to Oculus"" to render in full screen mode on your Oculus headset. Like with any Oculus application, it must be set up as secondary screen for this to work. "
W1395,https://wiki.ros.org/raspimouse_sim,Wiki,raspimouse_sim,"ROS package suite for Raspberry Pi Mouse Simulator
 
 

"
W1396,https://wiki.ros.org/rotors_gazebo_plugins,Wiki,rotors_gazebo_plugins,The rotors_gazebo_plugins package
W1397,https://wiki.ros.org/rail_face_detection,Wiki,rail_face_detection,Face Detection methods used in the RAIL Lab
W1398,https://wiki.ros.org/master_discovery_fkie,Wiki,master_discovery_fkie,"Discover the running ROS Masters in local network. The 
     discovering is done by sending an echo heartbeat messages to a defined 
     multicast group.
     The alternative is to use a zeroconf/avahi daemon to register the ROS 
     master as service and discover other ROS masters.



 

   This package contains discovery nodes to detect a ROS master in a multi robot system. There are currently two nodes 'master_discovery' and 'zeroconf' which uses different discovery strategies. 'zeroconf' node uses an avahi implementation of zeroconf technique. The 'master_discovery' node sends periodically a multicast message to notify about an available ROS master.  Furthermore the ROS master will be monitored for changes. On changes other discovery nodes are notified using a timestamp. This feature is used e.g. by  to syncronize the ROS masters. Moreover an XML-RPC server created by a discovery node helps to avoid a lot of requests on remote ROS master for a synchronization. To use  for discovering you need to run: zeroconfpython-avahiavahi-daemon~changes~linkstatszeroconf~list_masters~nameStringhostname~rpc_portint11611~rosmaster_hzint1Hz~heartbeat_hzint2Hzmaster_discovery~mcast_groupStringmaster_discovery~mcast_portint11511master_discovery~static_hostslist[]master_discovery~changes~linkstatszeroconf~list_masters~refresh~nameStringhostname~rpc_portint11611~rosmaster_hzint1Hz~heartbeat_hzint2Hzmaster_discovery~mcast_groupStringmaster_discovery~mcast_portint11511master_discovery~interfacestrmaster_discovery~robot_hosts (since v0.4.0)list[]static_hostmaster_discovery~static_hosts (until v0.4.0)list[]master_discovery~remove_afterfloat300.0~active_request_afterfloat60.0master_discovery~send_mcastboolTruemaster_discovery~listen_mcast (since v0.7.0)boolTruemaster_discoverymasterContacts()empty[str, str, str, str, str]masterInfo()empty(float, float, str, str,[ [str,[str] ] ],[ [str,[str] ] ],[ [str,[str] ] ],[ [str,str] ],[ [str,str,str,int,str] ],[ [str,str,str,str,str] ])publisherssubscribersservicesnodestopicTypesserviceProviderrosmake master_discovery_fkiecatkin_makerosrun master_discovery_fkie master_discoveryrosrun master_discovery_fkie zeroconf[stamp, stamp of local changes, masteruri, name, publishers, subscribers, services, topicTypes, nodes, serviceProvider][ [topic1, [topic1Publisher1...topic1PublisherN]] ... ][ [topic1, [topic1Subscriber1...topic1SubscriberN]] ... ][ [service1, [service1Provider1...service1ProviderN]] ... ][ [topicName1, topicType1], ... ][ [nodename, XML-RPC URI, origin ROS_MASTER_URI, pid, {str(local) or str(remote)} ], ... ][ [service, XML-RPC URI, origin ROS_MASTER_URI, type, {str(local) or str(remote)} ], ... ]"
W1399,https://wiki.ros.org/simple_message,Wiki,simple_message,"simple_message defines a simple messaging connection and protocol for communicating 
	with an industrial robot controller.  Additional handler and manager classes are 
	included for handling connection limited systems.  This package is part of the ROS-Industrial 
	program.








Use GitHub to . []
 The Simple Message (SimpleMessage) protocol defines the message structure between the ROS driver layer and the robot controller itself.  The protocol meets the following requirements: See  for documentation on officially assigned message identifiers to be used for the  field. The message protocol allows for an arbitrary data payload for message and communications types.  However, the client/server model requires that both understand the data payload associated with the different message and communications types.  The typed message class enforces the data payload structure.  The typed message base class provides methods for creating topic, reply, and request messages.  If used in both the client and server, the developer need not understand the structure of the data payload.  Unfortunately, a typical robot controller cannot use C++ classes, and thus the developer must understand the message protocol and payload data structure in order to parse it on the robot controller side.  The documentation on message specific structures can be found in the source header files.  For convenience the message structure is also shown here for common message types.  For a more detailed example of a typed message structure and how it is used see the following . The point data serves as a waypoint along a trajectory and is meant to mirror the  message. This point differs from the ROS trajectory point in the following ways: The simple message utilizes a abstract connection (SmplMsgConnection) interface to send messages to the industrial robot controller.  The interface makes two assumptions: The Message Manager and Handler (MessageManager and MessageHandler) classes can be used to manage a connection that allows for multiple message types to be handled.  The message manager contains a list of message handlers and executed the appropriate handler when a message is received.  These classes are particularly useful on robot controllers which may have a limited number of connections available to them. A Lua Wireshark dissector plugin for the simple message protocol is available from  at GitHub. See the readme for information on how to install it. MSG_TYPErosbuild_add_executable(my_exe my_exe.cpp)
target_link_libraries(my_exe simple_message)
OR
target_link_libraries(my_exe simple_message_bswap)"
W1400,https://wiki.ros.org/pr2_computer_monitor,Wiki,pr2_computer_monitor,"Monitors the computer's processor and hard drives of the PR2 and publishes data to diagnostics.



 uses command line tools to monitor the CPU. These commands are called in timer threads every 10 seconds or so to keep load down. 


 uses command line tools to monitor the HD.  will only check the disk usage if the home directory argument is set from the command line. 


 uses ntpdate to check the offset in clocks, using the NTP protocol. 









Each computer has two times: the time  thinks it is, and the system time. When they disagree,  slowly slews the system time until they match again. When you do  you compare host's chrony time with the local system time. Doing  allows you to verify that the chrony time and the system time match. The  script uses the command: With proper system dependencies,  can work on almost any linux system. Use  to install required packages from the operating system: It's a good idea to verify the installation of . To contact  (which measures hard drive temperature), pr2_computer_monitor opens a socket to the  daemon. First, verify that the  daemon is running. If  isn't up and running, start it by typing: Now, check if you have  installed correctly. If you choose not to use ipmitool to monitor CPU temperature and fan speed, disable it with  parameter to False.  If this command returns with an error (below), then you will need to disable the ipmitool checks using the  parameter. The  command needs to work properly without a password. If the above command asks for a ""sudo"" password, you'll need to edit the sudoers file: Add the following line to use  without typing your password: If your computers uses NFS, then you should enable the  parameter for CPU monitor. The NFS status messages will have no data if not enabled. CPU monitor will warn if the CPU cores start throttling below 2240 MHz. This is appropriate for the PR2, but if your computer is different, disable the  parameter. cpu_monitor.py/diagnostics~check_core_tempsboolean~check_impi_toolboolean~enforce_clock_speedboolean~load1_thresholdfloat~load5_thresholdfloat~check_nfsboolean~num_coresintcpumonitor.pysudo ipmitool sdrcat /proc/cpuinfo | grep MHzuptimefree -mmpstat -P ALL 1 1find /sys/devices -name temp1_inputhd_monitor.py/diagnostics~no_hd_temp_warnbooleanhd_monitor.pydf -P --block-size=1G HOME_DIRhd_monitor.pyntp_monitor.pyntpdate/diagnosticsntp_monitor.pychronychronyntpdate -q <server>ntpdate -q <hostname>/diagnosticsgpu_statusnvidia_temp.pynetwork_detector/network/connected~interface_namestringpr2_computer_monitorhddtemphddtemphddtemphddtemphddtempipmitool~check_ipmi_tool~check_ipmi_toolipmitoolipmitool~check_nfs~enforce_clock_speedUsage: cpu_monitor.py [--diag-hostname=cX]

Options:
  -h, --help            show this help message and exit
  --diag-hostname=DIAG_HOSTNAME
                        Computer name in diagnostics output (ex: 'c1')roslaunch pr2_computer_monitor cpu_monitor.launchUsage: hd_monitor.py [--diag-hostname=cX]

Options:
  -h, --help            show this help message and exit
  --diag-hostname=DIAG_HOSTNAME
                        Computer name in diagnostics output (ex: 'c1')roslaunch pr2_computer_monitor hd_monitor.launch$ netcat localhost 7634
|/dev/sda|Hitachi HDT725032VLA360|43|C|Usage: ntp_monitor ntp-hostname []

Options:
  -h, --help            show this help message and exit
  --offset-tolerance=OFFSET-TOL
                        Offset from NTP host
  --self_offset-tolerance=SELF_OFFSET-TOL
                        Offset from self
  --diag-hostname=DIAG_HOSTNAME
                        Computer name in diagnostics output (ex: 'c1')roslaunch pr2_computer_monitor ntp_monitor.launchntpdate -q <server>
ntpdate -q <hostname>Usage: nvidia_temp.pysudo nvidia-smi -a  <node pkg=""pr2_computer_monitor"" type=""network_detector"" name=""network_detector"" output=""screen"">
    <param name=""interface_name"" value=""wan0""/>
  </node>$ rosdep install pr2_computer_monitor$ netcat localhost 7634|/dev/sda|Hitachi HDT725032VLA360|41|C|sudo hddtemp -d /dev/sdasudo ipmitool sdr$ sudo ipmitool sdr
Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0: No such file or directory
Get Device ID command failed
Unable to open SDR for readingsudo visudosudo ipmitool sdr ALL NOPASSWD"
W1401,https://wiki.ros.org/kuka_kr6_support,Wiki,kuka_kr6_support,"
      ROS-Industrial support for the KUKA KR 6 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 6 manipulators. This currently includes the R700 sixx and
      the R900 sixx.
    :
      Joint limits and maximum joint velocities are based on the information
      in the  version .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1402,https://wiki.ros.org/pr2_camera_synchronizer,Wiki,pr2_camera_synchronizer,"
    The PR2 is equipped with a texture projector that can be used to
    project a texture onto featureless surfaces, allowing their
    three-dimensional structure to be determined using stereoscopy. The
    projector operates in a pulsed mode, producing brief (2ms) pulses of
    light. Cameras that want to see the texture must expose during the
    projector pulse; other cameras should be expose while the projector is
    off.
    
      This package contains the pr2_projector_synchronizer node. Based on its dynamically reconfigurable parameters, this node controls the projector pulsing, and sets up triggering of the WGE100 cameras.
    
 
 
 


 






 

 




This section gives an overview of the PR2's camera systems. Some readers may want to skip directly to  for a more practical discussion of how to use the robot's cameras, or to the  for a detailed description of the pr2_camera_synchronizer parameters. This section shows how to use the  to set these parameters, they can be set just as easily using any other  mechanism as demonstrated in . Frame rates and projector modes should be set using  on the pr2_camera_synchronizer_node. For example:The synchronizer will make a best-effort attempt at using the rates and modes you requested, but may have to . In that case, the GUI and parameter will reflect the rates and modes that were actually set. Many WGE100 settings not managed by the synchronizer can be set directly with the cameras by using . A detailed list of which parameters can be set in this way without conflicting with the synchronizer can be found . For the forearm cameras, the camera node ( or ) should be configured directly. For the stereo pairs, the wge100_multi_configurator node ( or ) should be configured; this node controls both cameras of a stereo pair, and will dispatch configuration changes to both underlying camera nodes. For the wide stereo camera:For the narrow stereo camera:For the right forearm camera:For the left forearm camera:Please refer to the  documentation for details on what these parameters mean. The following parameters can be set: , , , , , , , , . Please refer to the  documentation for details on what these parameters mean. Note 1: the  stored in the camera is only valid for the region of interest parameters that were used when it was created. The  will refuse to use  with the wrong width and height, but will not detect changes in the other parameters. Images from the wide stereo camera and forearm cameras are published in the ,  and  namespaces, whether they are textured or not. To facilitate using the narrow stereo camera in  mode, textured images from the narrow stereo camera are always published in the  namespace, and untextured images are always published in the  namespace. Due to unresolved firmware bugs, it may happen that a WGE100 camera will become unresponsive. The unresponsiveness of the camera can be verified by running:The easiest way to reset all the WGE100 cameras while ROS is running on the PR2 is to use the   option to true in the  options. This will raise the camera's trigger signal for a few seconds, telling the camera to reset itself. The reset will take about 5-10 seconds.Alternatively, a single camera can be reset when ROS is not running by using the  utility in . For example:In a running PR2, many cameras may be simultaneously in use by different users. Whether the projector should be on at any given time is a combination of the operating modes requested by the user of each camera. The settings of a user's camera depend on whether the projector is on or off. To avoid spurious changes in the settings of one user's camera when another user's camera is reconfigured, the pr2_camera_synchronizer is organized so that there is a master  setting, and a  setting for each camera.  Users request the  that their camera should be in, and the synchronizer decides on the projector state based on the current . For a given , the pr2_camera_synchronizer ensures that the settings of one camera do not depend on the  of the other cameras. In a typical use of the synchronizer, the  is set once and for all by a high-level decision, and users can adjust  at will. The recommended operating mode is .  can be used if longer exposures are needed or if the projector is deemed too unpleasant.  will most likely not be used in practice. In many cases, the camera frame rate must be some suitable divisor of the . When a user sets the frame rate for a camera, the synchronizer will round that rate to the nearest suitable rate, and report the rounded value back to the user via the  mechanism.  The  is not affected by the camera settings. When it is set, it is simply rounded to the nearest divisor of 1 kHz. Again the rounded value is reported back via the  mechanism. To avoid having texture in images taken by the Prosilica camera, the  option can be turned on. In this case, an exposure signal from the Prosilica camera directly inhibits firing of the projector. When the projector is inhibited the WGE100 cameras will continue to be triggered as if the projector was active, so some frames that should be textured may be partially textured or not textured at all. On the other hand, the Prosilica camera projector inhibition will not work between robots. Therefore, Prosilica images from one robot may see texture projected by the other, even if  is true. reconfigure_guiforearm_camera_lforearm_camera_rwide_stereo_bothnarrow_stereo_bothbrightnessblack_levelauto_exposureexposureauto_gaingaincompandingauto_gain_alternategain_alternatecompandingwidthheighthorizontal_binningvertical_binninghorizontal_offsetvertical_offsetmirror_xmirror_yrotate_180camera_infowge100_camera_nodecamera_infocamera_resetcamera_synchronizer_nodereconfigure_camwge100_cameraprojector_mode_trig_mode_trig_modeprojector_modeprojector_modetrig_modeprojector_mode_trig_modenarrow_stereo_texturednarrow_stereo_texturednarrow_stereoprojector_rateprojector_rate~projector_ratedouble~projector_pulse_lengthdouble~projector_pulse_shiftdouble~projector_modeint~prosilica_projector_inhibitbool~stereo_ratedouble~wide_stereo_trig_modeint~narrow_stereo_trig_modeint~forearm_r_ratedouble~forearm_r_trig_modeint~forearm_l_ratedouble~forearm_l_trig_modeint~projector_tweakdouble~camera_resetbool$ rosrun dynamic_reconfigure reconfigure_gui /camera_synchronizer_node$ rosrun dynamic_reconfigure reconfigure_gui /wide_stereo_both$ rosrun dynamic_reconfigure reconfigure_gui /narrow_stereo_both$ rosrun dynamic_reconfigure reconfigure_gui /forearm_camera_r$ rosrun dynamic_reconfigure reconfigure_gui /forearm_camera_l$ rosrun wge100_camera discover lan0
Found camera serial://1800023 name://forearm_l MAC: 00:24:cd:00:00:f0 iface: lan0 current IP: 10.68.0.42, PCB rev: C HDL rev: 504 FW rev: 202
Found camera serial://3001038 name://wide_stereo_r MAC: 00:24:cd:00:01:01 iface: lan0 current IP: 10.68.0.46, PCB rev: C HDL rev: 504 FW rev: 202
Found camera serial://3001039 name://wide_stereo_l MAC: 00:24:cd:00:00:fc iface: lan0 current IP: 10.68.0.45, PCB rev: C HDL rev: 504 FW rev: 202
Found camera serial://2701021 name://narrow_stereo_r MAC: 00:24:cd:00:01:02 iface: lan0 current IP: 10.68.0.44, PCB rev: C HDL rev: 504 FW rev: 202
Found camera serial://1800031 name://forearm_r MAC: 00:24:cd:00:00:ea iface: lan0 current IP: 10.68.0.41, PCB rev: C HDL rev: 504 FW rev: 202
Found camera serial://2701031 name://narrow_stereo_l MAC: 00:24:cd:00:01:03 iface: lan0 current IP: 10.68.0.43, PCB rev: C HDL rev: 504 FW rev: 202$ rosrun dynamic_reconfigure dynparam /camera_synchronizer_node camera_reset true$ rosrun wge100_camera reconfigure_cam name://wide_stereo_l"
W1403,https://wiki.ros.org/imu_monitor,Wiki,imu_monitor,"This package contains a single node that monitors the drift of the IMU
gyroscopes. The results are published to the '/diagnostics' topic and
are aggregated in the PR2 dashboard. 

imu_monitor.pytorso_lift_imu/database_odometry/odometer/diagnostics"
W1404,https://wiki.ros.org/maggie_ir_drivers,Wiki,maggie_ir_drivers,"ir drivers for Maggie robot

"
W1405,https://wiki.ros.org/voronoi_planner,Wiki,voronoi_planner,"A path planner library, that searches a path from robot position to given goal on generalized Voronoi diagram (GVD) which is made up of regions around obstacles on costmap.
  uses  package to make generalized Voronoi diagrams (GVD) which is made up of regions around obstacles on costmap.  

 (, default: true) 
 may be useful. The  object exposes its functionality as a . It operates withing a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Planner was tested using ,  and . To use  you need to change  of  in such a way: Other parameters changed were global_costmap/width and global_costmap/height (in move_base.launch from ): Path generated is published in ~<name>/plan topic. Voronoi grid map is published (if publish_voronoi_grid parameter is true) in ~<name>/voronoi_grid. You should configure RViz to view it. voronoi_plannervoronoi_planner::VoronoiPlannernav_core::BaseGlobalPlanner~<name>/publish_voronoi_gridbool~<name>/smooth_pathbool~<name>/weight_datadouble~<name>/weight_smoothdoublevoronoi_plannerbase_global_planner    <arg name=""base_global_planner"" default=""voronoi_planner/VoronoiPlanner""/>    <param name=""global_costmap/width"" value=""35.0"" if=""$(arg no_static_map)""/>
    <param name=""global_costmap/height"" value=""35.0"" if=""$(arg no_static_map)""/>"
W1406,https://wiki.ros.org/segbot_logical_translator,Wiki,segbot_logical_translator,"High-level navigation application for the segbot allowing the segbot to
    approach and gothrough doors. The application can also be used to determine
    the segbot's logical location, as well as sense when a door in front of the
    robot is open or not."
W1407,https://wiki.ros.org/kurt_driver,Wiki,kurt_driver,"kurt_driver 

Use GitHub to . []
  For installation instructions, see . "
W1408,https://wiki.ros.org/iot_bridge,Wiki,iot_bridge,"The iot_bridge provides a bi-directional bridge between ROS and the OpenHAB Home Automation system. This allows a ROS robot to connect to a vast variety of IoT devices such as motion detectors, Z-Wave devices, lighting, door locks, etc.
 






 
 When iot_bridge receives a name/value pair from the ROS  topic, it publishes those to OpenHAB  and OpenHAB sends that command to the device specified.  The value must be valid for that device.  See  for a summary of valid values. A ROS program wants to turn on a ceiling light.  It publishes the following to the  topic: When the iot_bridge receives a name/value pair from the ROS  topic, it publishes those to OpenHAB and OpenHAB updates the status for the item specified (e.g. indicate that a switch is now ON). A ROS program running Facial Detection detects that Sarah is present.  It publishes the following to the  topic: The IoT bridge receives updates from OpenHAB and publishes those as name/value pairs to the  ROS topic. For example:  A motion detector is triggered in OpenHAB.  The openhab bridge will publish the following to the  topic in ROS A ROS program publishes the following to the  topic: Use GitHub to  roslaunch iot_bridge iot.launch        cd catkin_ws/src
        git clone address-from-above
        cd ..
        catkin_makeGroup ROS (All)
String ROS_Status ""ROS [%s]""
Switch Light_GF_Corridor_Ceiling  ""Ceiling""  (GF_Corridor, Lights, ROS)
Switch Light_GF_Bathroom (GF_Bathroom, Lights, ROS)       rostopic echo /iot_updates    cd catkin_ws/src/iot_bridge/scripts
    ./iot_test  item_name item_value           Text item=ROS_Status label=""ROS [%s]"""
W1409,https://wiki.ros.org/master_sync_fkie,Wiki,master_sync_fkie,"Synchronize the local ROS master to the remote masters 
     discovered by master_discovery_fkie node. The registration
     of topics and services is only perform by local ROS master.

 in the current state the  will be not synchronized. 



This package contains a node to synchronize the local ROS master to remote ROS masters discovered by  node. For synchronization the  will be used. Thereby the regitration of topics/services are performed only on the local ROS master. To obtain a complete synchronization of two ROS master one master_sync node in each ""ROS system"" have to be started. The syncronization will be performed on each time the remote ROS master is changed. The change detection is done by the  node. To avoid multiple calls over unreliable connections e.g. , needed for a synchronization, the XML-RPC server of the  node is used to get the current state of the remote ROS master. Run the  node first. ~changes~get_sync_info~changes~get_sync_info~interface_urlstrpkg://master_sync_fkie///sync_interface.syncignore_sync_~resync_on_reconnectboolTrue~resync_on_reconnect_timeoutfloat0~do_not_synclist[]~ignore_hostsarray[]~sync_hostsarray[]~ignore_hosts~ignore_nodesarray[/rosout, ""/*master_sync* node"", ""remote /*master_discovery* node"", ""/*node_manager"", /*zeroconf]~sync_nodesarray[]~ignore_nodes~ignore_topics~ignore_services~ignore_topicsarray['/rosout', '/rosout_agg']~ignore_nodes~ignore_publishersarray[]~ignore_subscribersarray[]~sync_topicsarray[]~ignore_nodes~ignore_topics~ignore_servicesarray['/*get_loggers', '/*set_logger_level']~ignore_nodes~sync_servicesarray[]~ignore_nodes~ignore_services~sync_topics_on_demandbooleansync_nodessync_topicssync_*~ignore_typearray['bond/Status']~sync_remote_nodesbooleanrosrun master_sync_fkie master_sync"
W1410,https://wiki.ros.org/reemc_controller_configuration,Wiki,reemc_controller_configuration,"Launch files and scripts needed to configure
    the controllers of the REEM-C robot."
W1411,https://wiki.ros.org/nav2d_navigator,Wiki,nav2d_navigator,"This package provides a node for higher level navigation of a mobile
    robot in a planar environment. It needs a map and the robot's position
    within this map to create a plan for navigation. When used together with
    a SLAM module it can also be used to perform autonomous exploration of
    the robot's workspace.






The  is a ROS node that implements a path planner for navigation and is supposed to be used in conjunction with the 'operator' node. Beside this, the whole functionality is provided by the  class, which is exported by this package and can be used from within other nodes as well. Interaction with the Navigator is implemented using the  interface. This allows other nodes (e.g. some high level mission control) to start actions like goal navigation or exploration, monitor the progress and eventually cancel an action in progress. The following four actions are available: See the  for an example how to setup the Navigator in Stage with a given map of the environment. navigatornavigatoroperatorscantfcmd~plan~markersrobot_idintmap_framestringrobot_framestringmap_servicestring~robot_radiusdouble~map_inflation_radiusdouble~navigation_goal_distancedouble~navigation_goal_angledouble~navigation_homing_distancedouble~exploration_strategystring~exploration_goal_distancedouble~min_replanning_perioddouble~max_replanning_perioddoublegoalStartMappingStartExploration"
W1412,https://wiki.ros.org/pose_follower,Wiki,pose_follower,A implementation of a local planner that attempts to follow a plan as closely as possible.
W1413,https://wiki.ros.org/naoqi_bridge,Wiki,naoqi_bridge,"Meta package to interface ROS with Aldebaran's NAOqi.

Use GitHub to . []
  This package is the meta-package for packages that create a bridge with Aldebaran's  (versions 1.14 and 2.1). "
W1414,https://wiki.ros.org/irb_2400_moveit_config,Wiki,irb_2400_moveit_config,"irb_2400_moveit_config
This package is part of the  program. "
W1415,https://wiki.ros.org/qb_move_hardware_interface,Wiki,qb_move_hardware_interface,"This package contains the hardware interface for qbrobotics® qbmove device.

This package is barely usable alone since it provides only the hardware interface for the  device. ~command_with_position_and_presetbooleantruefalse~encoder_resolutionsint08~preset_ticks_limitintencoder_resolutionspreset_ticks_limit"
W1416,https://wiki.ros.org/motoman_bmda3_support,Wiki,motoman_bmda3_support,"
      ROS Industrial support for the Motoman bmda3 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for Motoman bmda3 manipulators.
    
   
  
      Joint limits and maximum joint velocities are based on the information 
      found in the online 
      http://www.motoman.com/datasheets/bmda3.pdf
      All urdfs are based on the default motion and joint velocity limits, 
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1417,https://wiki.ros.org/maggie_eyelids,Wiki,maggie_eyelids,"eyelids node





This device supports all the drivers implemented in the  package. move_abs_posmove_str_pos~portstring~sidestring $ roslaunch maggie_eyelids eyelids.launch robot:=maggie $ rosservice call /maggie/move_str_pos eyelids_msgs/MoveStrPos ""open"""
W1418,https://wiki.ros.org/rovio,Wiki,rovio,"The rovio stack contains packages to control and query a WowWee Rovio.





To install the  stack, you can choose to either install from source, or from the Ubuntu package: Each control package contains a  file which should be edited with the appropriate ROS parameters (e.g. hostname, username, and password to login to your Rovio). These launch files launch the necessary nodes for reading sensor information and control of the Rovio. Additional information on each launch file is given in their respective package wiki pages. Please send bug reports to the . Feel free to contact me at any point with questions and comments.  rovio.wavrovio.launch




sudo apt-get install ros-fuerte-rovio"
W1419,https://wiki.ros.org/mpc_local_planner_examples,Wiki,mpc_local_planner_examples,The mpc_local_planner_examples package
W1420,https://wiki.ros.org/pr2_ethercat_drivers,Wiki,pr2_ethercat_drivers,"This stack contains drivers for the ethercat system and the peripherals
    that connect to it: motor control boards, fingertip sensors, texture
    projector, hand accelerometer.

The  stack provides support for the realtime ethernet variant that is used for communication on the PR2 robot.  These drivers are brought up as part of the realtime loop from . Report new issues on  pr2_ethercat_drivers"
W1421,https://wiki.ros.org/industrial_msgs,Wiki,industrial_msgs,"The industrial message package containes industrial specific messages 
	definitions. This package is part of the ROS-Industrial program.

Use GitHub to . []
 This package is part of the  program. It contains message definitions used by other packages in the  metapackage. "
W1422,https://wiki.ros.org/pheeno_ros_description,Wiki,pheeno_ros_description,"The pheeno_ros_description package
Documentation for our package can be found . We will also be adding documentation to this ROS page in the coming weeks. "
W1423,https://wiki.ros.org/nav2d_localizer,Wiki,nav2d_localizer,"Wrapper around Particle Filter implementation.
    The SelfLocalizer can be used as library or as a ros-node."
W1424,https://wiki.ros.org/pr2_navigation_apps,Wiki,pr2_navigation_apps,"The pr2_navigation_apps package

  This stack holds a number of navigation specific applications for the PR2. These applications can be run on the PR2 hardware, or in . The current set of applications in this stack consists of: "
W1425,https://wiki.ros.org/visual_pose_estimation,Wiki,visual_pose_estimation,"

     visual_pose_estimation

  "
W1426,https://wiki.ros.org/agvs_robot_control,Wiki,agvs_robot_control,"The agvs_robot_control package. Robot controller that interacts with Gazebo motor controllers.
"
W1427,https://wiki.ros.org/motoman_msgs,Wiki,motoman_msgs,Messages for the multi-group interface of motoman_driver.
W1428,https://wiki.ros.org/lex_node,Wiki,lex_node,"Package providing a ROS node for interacting with Amazon Lex
: Amazon Lex is a service for building conversational interfaces into any application using voice and text. Amazon Lex provides the advanced deep learning functionality of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (“chatbots”). 

The ROS  node enables a robot to comprehend natural language commands by voice or textual input and respond through a set of actions, which an Amazon Lex Bot maps to ROS messages. Out of the box this node provides a ROS interface to communicate with a specified Amazon Lex bot (configured via lex_config.yaml) and requires configuration of AWS credentials. The Amazon Lex bot needs to be defined with responses and slots for customer prompts. A set of default slots and mappings are demonstrated in the  and include actions as “Create <location_name>,” “Go to <location_name>” and “Stop.” Additional guides on configuring bots with are available at . The ROS   wraps the  in a ROS service API. The source code is released under an . lex_nodelex_node"
W1429,https://wiki.ros.org/nao_moveit_config,Wiki,nao_moveit_config,"An automatically generated package with all the configuration and launch files for using the NAO robot with the MoveIt Motion Planning Framework
Please, find the documentation on the github page . "
W1430,https://wiki.ros.org/ugv_random_walk,Wiki,ugv_random_walk,"A package performs random walk coverage with an unmanned ground vehicle (UGV).

 (, default: 1)  (, default: ) 


The following packages of the  are required: to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. single_target=trueugv_random_walkidintegeroutputstringscreenscreenlogparamugv_random_walk.yamlugv_random_walkugv_random_walksingle_targettrueugv_coverage/goalugv_coverage/resulttarget_foundsingle_targettrueobstacle_detection/get_clear_sectorarea/closest_bound~loop_ratereal~queue_sizeinteger~single_targetboolean~step_size_maxreal/rng_seedintegerroslaunch ugv_random_walk ugv_random_walk.launch"
W1431,https://wiki.ros.org/korg_nanokontrol,Wiki,korg_nanokontrol,"ROS driver to use the Korg NanoKontrol MIDI device as a joystick.

 Where  is the MIDI ID of your input device. On my system, the  is usually device 3. <id>"
W1432,https://wiki.ros.org/arbotix,Wiki,arbotix,"ArbotiX Drivers
 
  check out the latest code from our repository: 
Please see the individual packages within this stack for documentation. ArbotiX RoboControllers can be purchased from  Bug reports, feature requests and patches are welcome. Please post new issues on our  site. git clone https://github.com/vanadiumlabs/arbotix_ros.git"
W1433,https://wiki.ros.org/pioneer_teleop,Wiki,pioneer_teleop,"The pioneer_teleop package provides teleoperation using keyboard, sockets or command line for the Adept MobileRobots Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, AmigoBot, PeopleBot, PatrolBot, PowerBot, Seekur and Seekur Jr.).
Use GitHub to . []
 








The package is compatible with any robot using ROS ecosystem, but is originally implemented for Adept  Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, , , , , Seekur and Seekur Jr.). In case you have a different robot, please read  section You need first to get and install  package The expected commands are """", """", """" or """" The expected commands ( argument) are """", """", """" or """" The velocity commands are published in  topic (see the next section). You modify the .launch scripts to remove the pionner_bringup call, or you execute directly the python scripts located in  folder. By default, the scripts publish velocity commands to  topic. In case your velocity commands topic has a different name, or you are not using Pionner-compatible robots, you will have to remap your velocity topic to  or change the topic name in the python scripts which are located in  folder cd ~/catkin_ws/src
git clone https://github.com/amineHorseman/pioneer_teleop.git
rosdep install pioneer_teleopcd ~/catkin_ws/src/pioneer_teleop/nodes
sudo chmod +x *.pyroslaunch pioneer_teleop keyboard_teleop.launchroslaunch pioneer_teleop discrete_keyboard_teleop.launchroslaunch pionner_teleop socket_teleop.launchroslaunch pionner_teleop socket_teleop.launch _port:=12345 _speed:=0.3 _move_time:=2.0roslaunch pionner_teleop socket_commandline.launch _direction:=forwardroslaunch pionner_teleop socket_teleop.launch _direction:=backward _speed:=0.3 _move_time:=2.0"
W1434,https://wiki.ros.org/jsk_smart_gui,Wiki,jsk_smart_gui,"

     jsk_smart_gui for tablets

  Documentation is available . "
W1435,https://wiki.ros.org/mrpt_bridge,Wiki,mrpt_bridge,"C++ library to convert between ROS messages and MRPT classes










"
W1436,https://wiki.ros.org/nav2d_karto,Wiki,nav2d_karto,"Graph-based Simultaneous Localization and Mapping module.
    Includes OpenKarto GraphSLAM library by ""SRI International""."
W1437,https://wiki.ros.org/arbotix_python,Wiki,arbotix_python,"Bindings and low-level controllers for ArbotiX-powered robots.





 
The arbotix_python package provides a basic ROS interface to an  over a USB serial connection, or XBEE wireless radios.  The  package also offers several controllers which add higher-level interfaces to common hardware. These include:  The ControllerGUI is a test/teleop node that allows you to control a mobile base and/or your Dynamixel servos. The ControllerGUI publishes geometry_msgs/Twist commands to the  topic, and commands to individual servos. It will automatically determine the names and limits of your servos from your YAML specification file. Launching the ControllerGUI is as easy as:  Moving the red dot up drives the robot forward, moving left/right turns in place, etc. The slider bars move servos, but must be checked to be enabled. When not enabled, they will be updated with the values of the last joint_states message, so that when enabled they will not  to a position, but just torque-on in place. In the above image, only head_pan and head_tilt are enabled. Working with Dynamixel servos often requires some setup of the servos themselves. This is made easy with the ArbotiX terminal tool. The terminal works like a typical Linux terminal, you can type  to query which servos are attached,  will  the servo with ID 1 to an ID of 2, etc: The terminal has several other commands. Typing  will list all commands: <servo>/command/joint_states<servo>/relax~portstr~baudint~rateint~read_ratefloat~write_ratefloat~sync_readboolean~sync_writeboolean~dynamixels/<servo>/idstr~dynamixels/<servo>/neutralint~dynamixels/<servo>/rangefloat~dynamixels/<servo>/ticksint~dynamixels/<servo>/min_anglefloat~dynamixels/<servo>/max_anglefloat~dynamixels/<servo>/max_speedfloat~dynamixels/<servo>/invertboolean~dynamixels/<servo>/readablebooleanarbotix_pythoncontrol_msgs/FollowJointTrajectoryActionlsmv 1 2movehelpport: /dev/ttyUSB1
rate: 15
dynamixels: {
    head_pan_joint: {id: 1, invert: true},
    head_tilt_joint: {id: 2, max_angle: 100, min_angle: -100}
}
controllers: {
  head_controller: {type: follow_controller, joints: [head_pan_joint, head_tilt_joint], action_name: head_controller/follow_joint_trajectory },
  base_controller: {type: diff_controller, base_width: 0.140, ticks_meter: 26145 }
}<launch>
  <node name=""arbotix"" pkg=""arbotix_python"" type=""driver.py"" output=""screen"">
    <rosparam file=""$(find your_package)/default.yaml"" command=""load"" />
  </node>
</launch>rosrun arbotix_python controllerGUI.py$ rosrun arbotix_python terminal.py 
ArbotiX Terminal --- Version 0.1
Copyright 2011 Vanadium Labs LLC
>>  ls
   1 .... .... .... .... .... .... .... .... 
.... .... .... .... .... .... .... .... .... 
>>  mv 1 2
OK
>>  ls
....    2 .... .... .... .... .... .... .... 
.... .... .... .... .... .... .... .... ....>>  help
ArbotiX Terminal V0.1

valid commands:
 ls - list the servos found on the bus. 
 mv id id2 - rename any servo with ID=id, to id2
 baud b - set baud rate of bus to b
 get param id - get a parameter value from a servo
 set param id val - set parameter on servo ID=id to val

valid parameters
 pos - current position of a servo, 0-1023
 baud - baud rate
 temp - current temperature, degrees C, READ ONLY"
W1438,https://wiki.ros.org/qb_chain_control,Wiki,qb_chain_control,This package contains the ROS node to control multiple qbrobotics® devices simultaneously.
W1439,https://wiki.ros.org/ps4eye,Wiki,ps4eye,The ps4eye packagesee  for documentation 
W1440,https://wiki.ros.org/agvs_pad,Wiki,agvs_pad,"The agvs_pad package.Component to control the robot by using a ps3 pad.
"
W1441,https://wiki.ros.org/ainstein_radar_rviz_plugins,Wiki,ainstein_radar_rviz_plugins,"Radar message type plugins for RViz.

"
W1442,https://wiki.ros.org/motoman_driver,Wiki,motoman_driver,"ROS-Industrial nodes for interfacing with Yaskawa Motoman robot controllers.

 


: this is required for the . 
 The MotoROS application and source is available for public download.  However, ordering this part number will ensure your controller is updated with correct system software, the MotoROS driver is installed, and all internal parameters are properly configured. 
: This is , but will allow you to modify the MotoROS driver which runs on the robot controller. The MotoPlus SDK is  required to be able to develop ROS applications, it is only needed if the MotoROS application is to be changed. 





 The software will work on all , , ,  and  robot controllers.  However, for DX100 controllers, a specific software option must be explicitly ordered from Motoman in order to enable ROS-Industrial integration (see the  section below). For more detailed information, please contact one of the support resources listed on  or . The latest MotoROS binary ( or higher) requires the following controller firmware (or a newer version): Please note that the MotoROS application is now compatible with the Human Collaborative HC series robots. Please review the  document to understand the functionality and limitations. The Motoman driver communicates with ROS through the  interface, with a few additional Motoman-specific message types.  Trajectories are streamed to the controller using a message format that captures all the ROS  data: joint positions, velocities, accelerations, and path timing.  The controller buffers these points and interpolates between them to send commands to the controller at the required timing.  More detail on the internal operations and required  commands is documented . See the  page for details on installing and using the MotoROS software. See the  page for details on alarms and errors when using the MotoROS driver. v1.5.0FS3.30.00-00DS3.32.00-14-14DN2.21.00-00YAS1.11.00-00YAS2.80.00-00YBS2.31.00-00180014-1167536169272-3158302169272-1147961169272-2166386169272-4183387169272-5206078simple_message"
W1443,https://wiki.ros.org/mdm_library,Wiki,mdm_library,This is the core package of the Markov Decision Making Library.
W1444,https://wiki.ros.org/qb_move,Wiki,qb_move,This package contains the ROS interface for qbrobotics® qbmove device.
W1445,https://wiki.ros.org/maggie_navigation,Wiki,maggie_navigation,"maggie_navigation metapackage


The  stack provides configuration files for running the  stack on  robot in a number of common configurations. For example, the package holds files that configure the  node to operate in an odometric frame, and configure the sensors for autonomous navigation. These configuration files are intended for use as building blocks for applications that wish to use autonomous navigation as a component. "
W1446,https://wiki.ros.org/rovio_av,Wiki,rovio_av,"The rovio_av package contains nodes to control and query the audio/video devices on a WowWee Rovio. Video streaming is provided via the gscam package.







The  package contains nodes and launch files that can be used to stream video and play sounds on the Rovio. Additionally, included in the  package is a selection of  files that have been converted to 8000 Hz 16 bit PCM (the native format for the Rovio). These files are conversions from Willow Garage's . These sounds can then be sent to the Rovio via a service call and played on its internal speakers. To install the  stack, you can choose to either install from source, or from the Ubuntu package: The  package contains a  file which should be edited with the hostname, username and password to login to your Rovio. Additionally, the username, password, and host should be changed in the  variable in order to stream video using . This file launches an instance of the  and  nodes. To launch these nodes, the following command can be used: With the above nodes running, you can test video streaming with the  package using the following command: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  rovio_avrovio_av.wavrovio_audio.wav.wavwavwav_play/rovio_shared/host/rovio_shared/user/rovio_shared/passroviorovio_avrovio_av.launchGSCAM_CONFIGrovio_audiogscam




sudo apt-get install ros-fuerte-rovioroslaunch rovio_av rovio_av.launchrosrun image_view image_view image:=/gscam/image_rawrosservice call /wav_play /path/to/rovio/rovio_av/wav/G22.wav"
W1447,https://wiki.ros.org/segbot_bringup,Wiki,segbot_bringup,"Contains launch files and runtime scripts necessary for running
    segbots in simulation and in the real world. Contents 
The segbot robot is a configurable platform, and can support many different sensor configurations. The segbot_bringup package contains launch files for all common sensor configurations. Each configuration brings up all the low level interfaces of the segbot robot (mobile base + sensor drivers). A secondary goal of this package is to abstract potions of each configuration easily so that configuration can be used within the Gazebo simulator. More formally, a launch file in this package should launch the following: ROS node for the segway base driver, found in the  package. For ease of use, a launch file called  can be found in this package which wraps the driver with required parameters.  Kinect - The launch files for the Kinect driver can be found in the  package, which are called by launch files in segbot_bringup. Hokuyo - Launch file for the Hokuyo from  are launched in this package. Sensor Filters (common with simulation) - Data from each sensor is filtered using a number of filters, more details about which can be found in the  package.  (common with simulation) - publishes all fixed joints of the robot on the  tree.  (common with simulation) - publish all non-fixed joints to default values (wheels and the castor joint). Since the segbot robot does not have any true actuated joints, publishing default values for these joints is sufficient for now. 
Each configuration has an auxiliary files that captures all redundancy between real world and simulation, allowing the auxiliary file to be called from a launch script responsible for launching the robot inside simulation. For a robot configuration called  the real robot launch file is called  and the auxiliary file is called . In addition, each auxiliary file must expose  and  as arguments, which are required to launch multiple robots and choose the complexity of the simulation, respectively. To see how these parameters are used, take a look at one of the existing robot launch files in this package, as well as  in the  package.  
The main launch files that run on the real robot are stored in the  directory as  and include the auxiliary launch configuration directly. These files need to call ROS nodes corresponding to the drivers for the segway base and sensors directly. The auxiliary files are stored in the  directory.  A convenience wrapper around  (The segway driver) called  can be found in the  directory. launch/segway_base.launch<config_name>tf_prefixuse_full_gazebo_modelsegbot_mobile_base.launchsegway_base.launch"
W1448,https://wiki.ros.org/pepper_description,Wiki,pepper_description,The pepper_description package
W1449,https://wiki.ros.org/rcll_fawkes_sim,Wiki,rcll_fawkes_sim,"RCLL simulation access through Fawkes








This package provides topics and services specific for the ROS integration with the  of the  (RCLL) that is also used for the . The simulation environment is based on  and . Detailed information about the simulation is available on the . For general setup instructions to setup ROS and Fawkes on your system please have a look at our wiki for , or . Then it is time to . First, run without the ROS integration and with the default agent that comes with the simulation. This opens a separate terminal with several tabs. Please see the  in the simulation that gives an overview of the tabs and what to do to start the game. Once you set the game to the exploration phase the robots should start moving. If you are at this point, excellent! This will run the simulation without the original agent (no ""-a"" flag) and with the appropriate ROS nodes for a single robot (the robot should still appear in the refbox shell as before and  should show many topics, also in the robot1 namespace. At this point you are ready to go! Have a look at the  and make the robot do as you wish. If you run into trouble, please join the  to ask questions. This node provides an action to execute skills through the , more specifically through its Fawkes implementation . The current version of Fawkes provides the  which serves the same purpose (and provides exactly the same ROS message API), please see its documentation on how to execute skills. rostopic listrcll_sim/explore_zone_inforcll_sim/mps_marker_arrayrcll_sim/mps_light_statercll_sim/amcl_posercll_sim/navgraph_generatercll_sim/amcl_posercll/send_beaconskiller/goalskiller/resultskiller/feedbackskiller_statuscd fawkes-robotino/bin
./gazsim.bash -x start -r -a -t -n1cd fawkes-robotino/bin
./gazsim.bash -x start -n 1 -r -t \
  --ros-launch-main rcll_fawkes_sim:rcll_fawkes_sim_all_1robot.launchrosrun actionlib axclient.py /robot1/skiller fawkes_msgs/ExecSkillActionskillstring='ppgoto{place=""C-CS1-O""}'"
W1450,https://wiki.ros.org/realsense2_camera,Wiki,realsense2_camera,"RealSense Camera package allowing access to Intel T265 Tracking module and SR300 and D400 3D cameras




This package provides ROS node(s) for using the Intel® ™ SR300 and D400 cameras. Installation instructions can be found  The library is a ROS Debian packaging of the more generic cross-platform library. The packaging and release is maintained by the team supporting the various ROS  packages. Please  concerning this package to the realsense_camera  Issues. For updated details on this library see the . "
W1451,https://wiki.ros.org/dbc,Wiki,dbc,"DBC file interface.  Read a DBC file, unpack CAN messages and convert to engineering units, pack values into CAN messages for publishing."
W1452,https://wiki.ros.org/pr2_tuck_arms_action,Wiki,pr2_tuck_arms_action,"The pr2_tuck_arms_action package 

See  pr2_tuck_arm_actiontuck_arms/goaltuck_arms/resultr_arm_controller/<~joint_trajectory_action> and l_arm_controller/<~joint_trajectory_action>~r_joint_trajectory_actionstring~l_joint_trajectory_actionstring~move_durationfloat rosrun pr2_tuck_arms_action tuck_arms.py -lt "
W1453,https://wiki.ros.org/reemc_robot,Wiki,reemc_robot,"Description and launch files for the REEM-C robot

Use GitHub to . []
  "
W1454,https://wiki.ros.org/uvc_camera,Wiki,uvc_camera,"A collection of node(let)s that stream images from USB cameras (UVC)
     and provide CameraInfo messages to consumers. Includes a
     two-camera node that provides rough synchronization
     for stereo vision.

     Currently uses the base driver from Morgan Quigley's uvc_cam package.
 Please use another driver, such as  (). 
 

 


This package provides drivers for USB Video Class (UVC) cameras. This standard covers almost all consumer webcams.  The source is on github  It works with the ROS  like other streaming . Its  supports binocular streams, publishing synchronized image pairs from two cameras. The drivers are implemented as nodes and as . image_rawcamera_infocamera/image_rawvideo_modeset_camera_info~camera_info_urlstring~devicestring~fpsint~widthint~heightint~frame_idstringleft/image_rawright/image_rawleft/camera_infoleft/image_rawvideo_moderight/camera_inforight/image_rawleft/set_camera_inforight/set_camera_info~left/camera_info_urlstring~right/camera_info_urlstring~left/devicestring~right/devicestring~fpsint~skip_framesint~left/rotatebooltrue~right/rotatebooltrue~widthint~heightint~frame_idstring"
W1455,https://wiki.ros.org/joint_trajectory_generator,Wiki,joint_trajectory_generator,"joint_trajectory_generator action takes in a trajectory specified
    by a number of joint positions, and it generates a new smooth trajectory
    through these joint positions. 
joint_trajectory_generatorjoint_trajectory_generator/goaljoint_trajectory_generator/resultjoint_trajectory_action~max_accfloat64~/max_velfloat64robot_descriptionstring"
W1456,https://wiki.ros.org/app_manager,Wiki,app_manager,"app_manager
See  in the Building Manager project. "
W1457,https://wiki.ros.org/urdf_parser_plugin,Wiki,urdf_parser_plugin,This package contains a C++ base class for URDF parsers.
W1458,https://wiki.ros.org/naoqi_sensors_py,Wiki,naoqi_sensors_py,"ROS driver for miscellaneous sensors on NAO.
    Python bindings for camera, sonar and octomap
    C++: bindings for camera only (requires NAOqi to build)

cameraimage_rawcamera_info~audio_raw~use_ros_timeboolean~frequencyintegersonar~memory_keystringDevice/SubDeviceList/US/Left/Sensor/ValueDevice/SubDeviceList/US/Right/Sensor/Value~frame_idstringLSonar_frameRSonar_frame~sonar_ratefloat"
W1459,https://wiki.ros.org/roomba_stage,Wiki,roomba_stage,"The roomba_stage package
"
W1460,https://wiki.ros.org/prosilica_camera,Wiki,prosilica_camera,"A ROS driver node for AVT/Prosilica Gigabit Ethernet (GigE) cameras.

 


This package contains a ROS driver node for . It is built on top of the . The ROS API of this package is stable. The driver node has been tested extensively with the  model, which was used in the Willow Garage . The node should work with any AVT/Prosilica GigE camera, and we welcome reports of use with other cameras. This page and the  cover expected use of this package. Features of interest to advanced users only are documented . For basic vision processing of camera images, see the . Sets the camera to a fixed IP address. The camera must be visible to , and must be the only camera listed. The camera must be unopened (i.e.  should not be running). This tool is normally used once to configure a new camera (see the ). camera/image_rawcamera/camera_infocamera/image_rawcamera/camera_inforesponse_namespacerequest_image<response_namespace>/image_raw<response_namespace>/camera_infoset_camera_inforequest_image~ip_address~guid~ip_addressstring~guidstring~trigger_modestr~auto_exposurebool~exposure~exposuredouble~auto_gainbool~gain~gainint~auto_whitebalancebool~whitebalance_red~whitebalance_blue~whitebalance_redint~whitebalance_blueint~frame_idstr~x_offsetint~y_offsetint~widthint~heightint~trigger_modestr~auto_exposurebool~exposure~exposuredouble~auto_gainbool~gain~gainint~auto_whitebalancebool~whitebalance_red~whitebalance_blue~whitebalance_redint~whitebalance_blueint~binning_xint~binning_yint~x_offsetint~y_offsetint~widthint~heightint~frame_idstr~trig_timestamp_topicstr~trig_ratedoubleprosilica_node$ set_ip <IP address>"
W1461,https://wiki.ros.org/rospeex,Wiki,rospeex,Meta package for rospeex packages.
W1462,https://wiki.ros.org/pr2_gazebo_plugins,Wiki,pr2_gazebo_plugins,"Gazebo Plugins for various PR2-specific sensors and actuators on the robot.





 plugin provides ROS topic and service interfaces similar to those provided by the  on PR2. 


 plugin provides ROS topics and services similar to those provided by  on physical PR2. 





 plugin provides similar ROS interface as  on the physical PR2 robot.  This plugin is written in a way that  works transparently with either this simulated plugin or the  hardware.  For more information on using  or  with this plugin, please see . 

This package contains dynamic plugins for  and  integration with simulated hardware. Please see  for additional supported hardware components in simulation. This stack will be updated with new features as the PR2 hardware itself is updated. Future versions will also incorporate  options to match ORS driver functionality. GazeboRosControllerManagerGazeboRosProsilicaGazeboRosPowerMonitor<robotParam><robotNamespace>GazeboRosProsilica<robotNamespace><imageTopicName><cameraInfoTopicName><pollServiceName><frameName><CxPrime><Cx><Cy><focal_length><distortion_k1><distortion_k2><distortion_k3><distortion_t1><distortion_t2><hackBaseline>GazeboRosPowerNode<robotNamespace><powerStateTopic><powerStateRate><fullChargeCapacity><chargeRate><dischargeVoltage><dischargeRate><chargeVoltage>plugged_in<powerStateTopic><imageTopicName><cameraInfoTopicName>request_imageGazeboRosControllerManager    <!-- GazeboMechanismControl -->
    <controller:gazebo_ros_controller_manager name=""gazebo_ros_controller_manager"" plugin=""libgazebo_ros_controller_manager.so"">
      <alwaysOn>true</alwaysOn>
      <updateRate>1000.0</updateRate>
      <robotParam>robot_description</robotParam>
      <robotNamespace>/</robotNamespace>
    </controller:gazebo_ros_controller_manager>  <body:empty name=""camera_body_name"">
    <sensor:camera name=""high_def_sensor"">
      <imageFormat>R8G8B8</imageFormat>
      <imageSize>2448 2050</imageSize>
      <hfov>45</hfov>
      <nearClip>0.1</nearClip>
      <farClip>100</farClip>
      <updateRate>20.0</updateRate>
      <controller:gazebo_ros_prosilica name=""high_def_controller"" plugin=""libgazebo_ros_prosilica.so"">
        <alwaysOn>true</alwaysOn>
        <updateRate>20.0</updateRate>
        <imageTopicName>/prosilica/image_raw</imageTopicName>
        <cameraInfoTopicName>/prosilica/camera_info</cameraInfoTopicName>
        <pollServiceName>/prosilica/request_image</pollServiceName>
        <frameName>high_def_frame</frameName>
        <CxPrime>1224.5</CxPrime>
        <Cx>1224.5</Cx>
        <Cy>1025.5</Cy>
        <focal_length>2955</focal_length> <!-- image_width / (2*tan(hfov_radian /2)) -->
        <distortion_k1>0.00000001</distortion_k1>
        <distortion_k2>0.00000001</distortion_k2>
        <distortion_k3>0.00000001</distortion_k3>
        <distortion_t1>0.00000001</distortion_t1>
        <distortion_t2>0.00000001</distortion_t2>
        <interface:camera name=""high_def_iface""/>
      </controller:gazebo_ros_prosilica>
    </sensor:camera>
  </body:empty>    <controller:gazebo_ros_power_monitor name=""gazebo_ros_power_monitor_controller"" plugin=""libgazebo_ros_power_monitor.so"">
        <alwaysOn>true</alwaysOn>
        <updateRate>1.0</updateRate>
        <timeout>5</timeout>
        <interface:audio name=""power_monitor_dummy_interface"" />
        <powerStateTopic>power_state</powerStateTopic>
        <powerStateRate>10.0</powerStateRate>
        <fullChargeCapacity>87.78</fullChargeCapacity>
        <dischargeRate>-474</dischargeRate>
        <chargeRate>525</chargeRate>
        <dischargeVoltage>15.52</dischargeVoltage>
        <chargeVoltage>16.41</chargeVoltage>
    </controller:gazebo_ros_power_monitor>"
W1463,https://wiki.ros.org/ocean_battery_driver,Wiki,ocean_battery_driver,"This is an interface to the Ocean Server Technology Intelligent Battery and Power System.


 controls an array of battery controllers.  The API below is for informational purposes only; it is not intended for use by anything other than , which is where you should look for power data.  
 () 
 (, default: if no value specified on command-line, 4) The  node will report the status of the batteries to diagnostics. It will warn on the diagnostics if a battery does not update within a timeout. ocean_serverocean_server/diagnostics/battery/server2/battery/server~number_of_portsint~debug_levelint~port<ID>string""/dev/ttyUSB<ID>""~lag_timeoutint60~stale_timeoutint120"
W1464,https://wiki.ros.org/velodyne_simulator,Wiki,velodyne_simulator,"Metapackage allowing easy installation of Velodyne simulation components.
 "
W1465,https://wiki.ros.org/slime_wrapper,Wiki,slime_wrapper,"ROS wrapper for slimeThis is a ROS wrapper around , more precisely, the  branch of it, see . choose-swank-loading-method"
W1466,https://wiki.ros.org/rwt_moveit,Wiki,rwt_moveit,This package provides a web user interface of  on top of visualizer in .
W1467,https://wiki.ros.org/video_player,Wiki,video_player,"Video_player package to play/stream a video with ""gscam"".






 modestringgscam_configstringsudo apt-get install ros-hydro-gscamcd ~/catkin_ws/srcwstool init
wstool set gscam --git https://github.com/ros-drivers/gscam.git
wstool updatesudo apt-get install gstreamer-0.10 libgstreamer0.10-0 libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev gstreamer0.10-ffmpeg gstreamer0.10-gconf gstreamer0.10-tools gstreamer0.10-xcd ..
catkin_makeroscore
roslaunch video_player video_player.launch
rosrun video_player test_client ~/catkin_ws/src/tools_robin/video_player/data/Video1"
W1468,https://wiki.ros.org/unique_identifier,Wiki,unique_identifier,"ROS messages and interfaces for universally unique identifiers.

    Not needed for wet packages, use only to resolve dry stack
    dependencies.


 This stack defines a ROS message for a , as described in . This stack was originally released for Fuerte (without the  C++ API).  For Groovy, the C++  API was added. For Hydro, the packages were converted to build using . The  stack became an empty meta-stack, depending on  and  for backwards compatibility with rosbuild stacks. Catkin packages should depend on those packages directly, not depending on . The interface is now . unique_identifieruuid_msgsunique_idunique_identifier"
W1469,https://wiki.ros.org/ucl_drone,Wiki,ucl_drone,"The ucl_drone package





1. Install the  package. To do this, follow intructions at  # cd into ros root dir
roscd

# clone repository
git clone git:https://github.com/Felicien93/ucl_drone.git

# compile in the root of ucl_drone package
catkin_make#Connect your computer to the drone's network

#Use telnet to access the drone network informations
telnet 192.168.1.1

#Display relevant informations
ifconfig ath0

#Note the drone's MAC address. You will need it later. It is written in the ""HWaddr"" field. MAC address example: 90:03:B7:2A:DF:11

#Set up your network card
sudo ifconfig eth0 192.168.1.253

#Type the IP address of your router in your internet navigator
192.168.1.254

#Connect on the page using the password and ID of the router

#Go in Network>Interfaces>Edit>LAN and define 192.168.1.254 in the ipv4address field.

#Go in Network>wifi and click add. Use the controller with ""BGN"" in his description.

#In ""general setup"" configure the essid fiel on ""drone"" and hide essid.

#Go back in Network>wifi and click ""enable"" next to the ""drone"" network

#Click on ""edit"". Go in Mac filter, chose ""allow listed only"" and add the MAC addresses of the drones you connected.

#In your files (not in navigator) go in src>ucl_drone>drone_preparation>Appareillage and add one file per drone. The file name should be the drone's network name (example: ardrone2_00217) and it should contain the IP address you want it to have (example: 192.168.1.5)# Connect to the drones. Go in src>ucl_drone>drone_preparation>Appareillage
bash autoconfarparrot

# run the program
roslaunch ucl_drone two_simples_new.launch"
W1470,https://wiki.ros.org/ardrone_autonomy,Wiki,ardrone_autonomy,ardrone_autonomy is a ROS driver for Parrot AR-Drone 1.0 and 2.0 quadrocopters. This driver is based on official AR-Drone SDK version 2.0.1. Documentation is hosted . 
W1471,https://wiki.ros.org/rosemacs,Wiki,rosemacs,"ROS tools for those who live in Emacs.  










 ()
  ()
  ()
  ()
  ()
  ()  () 
 ()  

 maintains information about current ROS topics.  The topic list is used for tab completion, both in the shell and emacs commands, of topics in the appropriate places.    ()  ()  ()  () 
 () 
 ()  ()  () 
 () 


 is an Emacs extension that allows you to write snippets, which are templates for recurring patterns in source code.  Rosemacs (trunk) provides a few ros-specific ones in the  directory.  E.g., if you enable snippets support and set up your path as per the above instructions, if you open up a new file  in the  package and type  followed by , it will: 





   This is an emacs extension for dealing with ros.  Simplifies navigating the package system, tracking topics and nodes, and running various commands (, , ) directly from emacs. Setting up  defines a set of ROS-related emacs commands.  These can be either called using the full command names given below (using ) or using a keyboard shortcut, if you've set a prefix for the ros-keymap.  For example, given the setup below,  will find a package or file using rospack.  Type  to see if there's a shortcut for a given command.  Type  to see the entire list of keyboard shortcuts.  In this document, we'll list the keyboard shortcut with each command, which has to be preceded with whatever prefix you're using (in our case ). If you are a Lisp developer you'll probably need the  package. It installs  automatically as a dependency. The most up-to-date version of rosemacs code can be found . Installation instructions can be found in the README file. What you'll need to do will be something like the following: IMPORTANT: Make sure the standard ROS variables are always set in the emacs process environment.  For example, if you use bash, follow the standard ROS installation instructions about sourcing  in your , and launch emacs from a bash shell. Update your , e.g.: For troubleshooting consult the  file. Put the following in your  (e.g. ): The  buffer contains a timestamped list of noteworthy events in the ros system.  Useful for answering the question ""did something unexpectedly die?"" when your system is behaving strangely.  Currently, it keeps track of nodes starting and stopping.   By default, ROS tab completion does not work if you use shell-mode in emacs.   fixes this and adds completion of current nodes and topics.   You can add the following expression to the customization : Invoking rosemacs makes files with extension ,  and  open in Emacs's gdb-script-mode for syntax highlighting.  You can override this behavior by updating the  variable after calling . Emacs 23 and later includes  which, given a RELAX NG schema, validates xml documents online as you edit them and provides intelligent completion.  Rosemacs includes schemas for roslaunch and manifest.xml files.  This is now automatically setup (with Emacs 23 and later). For more information on programming ROS packages in Lisp see the  package wiki. There are various customizable options.  You can set these using emacs's customization system (in the  customization group), or by just doing  in your .emacs. roscorerosrunroslaunchrosemacsM-x command-nameC-x C-r C-fC-h f command-nameC-x C-r C-hC-x C-rrosemacssetup.bash.bashrc~/.emacsfind-ros-fileC-fview-ros-fileffind-ros-messageC-mview-ros-messagemfind-ros-serviceC-sview-ros-services{find|view}-ros-{file|message|service}ros-load-package-locationsrrosemacsros-rgrep-packagegros-find-diredfindrosemacsdisplay-ros-topic-infoC-t*ros-topics*add-hz-updatehrosemacs*ros-topics*remove-hz-updateHecho-ros-topictrosemacs/display-nodesC-nros-launchC-lkrqros-runC-rros-launchros-coreC-c*ros-core**ros-events*rosemacs/display-event-bufferC-erosemacssnippets/bar.hfoowgh[TAB]fooFOO_BAR_Hfoomode-line-format.msg.srv.actionauto-mode-alistinvoke-rosemacsrosemacs(setq variable value)ros-completion-functionros-completion-functionido-completing-readros-topic-update-intervalros-node-update-interval$ sudo apt-get install ros-DISTRO-rosemacs$ sudo apt-get install rosemacs-el$ cd YOUR_CATKIN_WS/src
$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git
$ wstool update ros_emacs_utils
$ cd ..
$ catkin_make
$ catkin_make install$ emacs -nw ~/.emacs.d/init.el(add-to-list 'load-path ""/opt/ros/DISTRO/share/emacs/site-lisp"")
;; or whatever your install space is + ""/share/emacs/site-lisp""
(require 'rosemacs-config);; Load the library and start it up
(require 'rosemacs)
(invoke-rosemacs)

;; Optional but highly recommended: add a prefix for quick access
;; to the rosemacs commands
(global-set-key ""\C-x\C-r"" ros-keymap)(:eval (ros-current-pkg-modeline-entry))(require 'yaml-mode)
(add-to-list 'auto-mode-alist '(""\\.yml$"" . yaml-mode))
(add-to-list 'auto-mode-alist '(""\\.yaml$"" . yaml-mode))"
W1472,https://wiki.ros.org/lanelet2,Wiki,lanelet2,"Meta-package for lanelet2
 is a C++ library for handling map data in the context of automated driving. It is designed to utilize high-definition map data in order to efficiently handle the challenges posed to a vehicle in complex traffic scenarios. Flexibility and extensibility are some of the core principles to handle the upcoming challenges of future maps.  
Use GitHub to . []
 
 Lanelet2 is the successor of the old  that was developed in 2013. 
For more information, please refer to our . If you are using Lanelet2 for scientific research, we would be pleased if you would cite our : @inproceedings{poggenhans2018lanelet2,
  title     = {Lanelet2: A High-Definition Map Framework for the Future of Automated Driving},
  author    = {Poggenhans, Fabian and Pauls, Jan-Hendrik and Janosovits, Johannes and Orf, Stefan and Naumann, Maximilian and Kuhnt, Florian and Mayr, Matthias},
  booktitle = {Proc.\ IEEE Intell.\ Trans.\ Syst.\ Conf.},
  year      = {2018},
  address   = {Hawaii, USA},
  owner     = {poggenhans},
  month     = {November},
  Url={http://www.mrt.kit.edu/z/publ/download/2018/Poggenhans2018Lanelet2.pdf}
}"
W1473,https://wiki.ros.org/nao_vision,Wiki,nao_vision,"Package for the Nao robot, providing access to NAOqi vision proxies





The  package allows easy control and access of the NAO's vision via ROS. These packages have been tested with . To install the  stack, simply run the following commands in your shell: The  package contains a  file which should be edited with the hostname and port of your NAO. Additionally, if your local  does not include the path to your NAOqi /lib folder, an optional parameter can be set in the launch file. Parameters are also included to configure the resolution and the camera (bottom or top) that will be streamed. These are set to the default values in the given launch file. This file launches an instance of the  node. To launch this node, the following commands can be used: With the above node running, you can test video streaming with the  package using the following command: Please send bug reports to the . Feel free to contact me at any point with questions and comments. nao_visionnao_visionnao_cameranao_vision/naoqi/host/naoqi/port/naoqi/pathnullPYTHONPATH~resolutionkQVGAkQQVGAkQVGAkVGA~cameranao_railnao_visionnao_vision.launchPYTHONPATHnao_vision




roslaunch nao_vision nao_vision.launchrosrun image_view image_view image:=/nao_camera"
W1474,https://wiki.ros.org/rovio_shared,Wiki,rovio_shared,"The rovio_shared package contains standard messages and services as well as a library that can be used to communicate with a WowWee Rovio.
Newly proposed, mistyped, or obsolete package. Could not find package ""rovio_shared"" in rosdoc: /home/rosbot/docs/api/rovio_shared/manifest.yaml 






 The  package contains a library that is used to communicate with the Rovio. This package and library are intended to be used with the packages provided in the  stack; however, it is possible to compile and use the library in your own packages as well. To install the  stack, you can choose to either install from source, or from the Ubuntu package: While the  library was constructed primarily for use within the  stack's packages, it is possible to utilize its functionality in any ROS node. The example below has the Rovio drive forwards until the user issues a  command. Other information on the  library can be found in the  . Create a  object by supplying it with the username and password to your Rovio. This object with use  to communicate to the Rovio's HTTP server. Here we construct and send an HTTP command based on the . In this example we will tell to Rovio to drive forwards at speed 5. This function will return a pointer to a 'rovio_response' struct containing the response from the Rovio. Even if this information is not need it is important to always free this struct once you are finished to prevent a memory leak. Please send bug reports to the . Feel free to contact me at any point with questions and comments.  rovio_sharedroviorovio_httprovioctrl-crovio_httprovio_httplibcurl




sudo apt-get install ros-fuerte-rovio






























































"
W1475,https://wiki.ros.org/kuka,Wiki,kuka,"ROS-Industrial support for KUKA manipulators (metapackage).



Use GitHub to . []
 This repository is part of the  program. See the  metapackage for additional packages, such as  configuration packages and  plugins. For questions related to the KUKA support or ROS Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. "
W1476,https://wiki.ros.org/qb_hand,Wiki,qb_hand,This package contains the ROS interface for qbrobotics® qbhand device.
W1477,https://wiki.ros.org/dbw_pacifica_can,Wiki,dbw_pacifica_can,Drive-by-wire interface to the Chrysler Pacifica DBW kit
W1478,https://wiki.ros.org/tuw_multi_robot_msgs,Wiki,tuw_multi_robot_msgs,"The tuw_multi_robot_msgs package contains messages for sending graph, route and sync data over topics.
 

Use GitHub to . []
  This package provides messages to the  package to send graphs over topics.  tuw_multi_robot"
W1479,https://wiki.ros.org/kobuki_description,Wiki,kobuki_description,"Description of the Kobuki model.
      Provides the model description of Kobuki for simulation and visualisation. The files in this 
      package are parsed and used by a variety of other components. Most users will not interact directly
      with this package.
      
      WARNING: This package is disabled because it cannot be catkinized by now, as xacro dependency is not
      catkin still. In the interim we use a unary pre-catkin stack named kobuki_description. 

kobuki.urdf.xacro<kobuki/>kobuki_standalone.urdf.xacrolaunch/view_model.launch> roslaunch kobuki_description view_model.launch"
W1480,https://wiki.ros.org/blink1,Wiki,blink1,"This package provides a node that manipulates Blink(1) RGB LED using a service. Accompanies the node an API that facilitates the use of the service.


 This node provides a ROS service that manipulates . Accompanies the node an API that facilitates the use of the service. Create a catkin workspace. For instructions on how to create the workspace go . Download and compile the package: To permanently change the permissions of the device and run the node in the user mode, please refer to the . sudo apt-get install libusb-devcatkin_ws/src
git clone git@bitbucket.org:castacks/blink1_node.git
cd ..
catkin_makecatkin_ws/src
git clone  https://bitbucket.org/castacks/blink1_node.git
cd ..
catkin_makesource devel/setup.bash
roslaunch blink1 blink1.launchsource devel/setup.bash
rosrun blink1 blink1_example"
W1481,https://wiki.ros.org/arni_rqt_overview_plugin,Wiki,arni_rqt_overview_plugin,The ARNI rqt_gui overview plugin.
W1482,https://wiki.ros.org/kobuki_testsuite,Wiki,kobuki_testsuite,Kobuki test suite: this package provides tools to thoroughly test Kobuki's hardware. 
W1483,https://wiki.ros.org/rbcar_common,Wiki,rbcar_common,"The rbcar_common package. It contains RBCAR common packages
 


This package contains the different controllers and launch files for the , shared for real robot and simulation.  "
W1484,https://wiki.ros.org/pid,Wiki,pid,"Launch a PID control node.





  
 








  





 

You can install the pid package from binaries or build from source. If you install from binaries, the example files discussed below will be in /opt/ros/<release>/share/pid If you're seeing high CPU usage, it's probably due to rqt_plot. You can comment it in the launch files. The PID controller itself (no graphics) typically runs at <10% CPU usage. $ sudo apt-get install ros-indigo-pid$ cd catkin_ws/src
$ git clone https://bitbucket.org/AndyZe/pid.git
$ cd ..
$ catkin_make$ roslaunch pid servo_sim.launch$ rosrun pid autotune    <node name=""left_wheel_pid"" pkg=""pid"" type=""controller"" >
      <param name=""Kp"" value=""5.0"" />
      <param name=""Ki"" value=""0.0"" />
      <param name=""Kd"" value=""0.1"" />
      <param name=""upper_limit"" value=""10"" />
      <param name=""lower_limit"" value=""-10"" />
      <param name=""windup_limit"" value=""10"" />
      <param name=""max_loop_frequency"" value=""100.0"" />
      <param name=""min_loop_frequency"" value=""100.0"" />
    </node>rosrun rqt_reconfigure rqt_reconfigure    <node name=""controller"" pkg=""pid"" type=""controller"" ns=""left_wheel"" output=""screen"" >
      <param name=""node_name"" value=""left_wheel_pid"" />
      <param name=""Kp"" value=""5.0"" />
      <param name=""Ki"" value=""0.0"" />
      <param name=""Kd"" value=""0.1"" />
      <param name=""upper_limit"" value=""10"" />
      <param name=""lower_limit"" value=""-10"" />
      <param name=""windup_limit"" value=""10"" />
      <param name=""max_loop_frequency"" value=""100.0"" />
      <param name=""min_loop_frequency"" value=""100.0"" />
      <remap from=""setpoint"" to=""/setpoint"" />
     </node>

    <node name=""servo_sim_node"" pkg=""pid"" type=""plant_sim"" ns=""left_wheel"" output=""screen"" >
      <param name=""plant_order"" value=""2"" />
    </node>

    <node name=""controller"" pkg=""pid"" type=""controller"" ns=""right_wheel"" output=""screen"" >
      <param name=""node_name"" value=""right_wheel_pid"" />
      <param name=""Kp"" value=""-4.0"" />
      <param name=""Ki"" value=""-0.0"" />
      <param name=""Kd"" value=""-0.3"" />
      <param name=""upper_limit"" value=""10"" />
      <param name=""lower_limit"" value=""-10"" />
      <param name=""windup_limit"" value=""10"" />
      <param name=""max_loop_frequency"" value=""100.0"" />
      <param name=""min_loop_frequency"" value=""100.0"" />
      <remap from=""setpoint"" to=""/setpoint"" />
     </node>

    <node name=""servo_sim_node"" pkg=""pid"" type=""plant_sim"" ns=""right_wheel"" output=""screen"" >
      <param name=""plant_order"" value=""2"" />
      <param name=""reverse_acting"" value=""true"" />
    </node>    <param name=""use_sim_time"" value=""true"" />

        <node name=""sim_time"" pkg=""pid"" type=""sim_time"" output=""screen"" >
      <param name=""sim_speedup"" value=""4"" />
    </node>"
W1485,https://wiki.ros.org/pr2_simulator,Wiki,pr2_simulator,"The pr2_simulator package 
 



  
The PR2 simulator is implemented using  stack. It is a three-dimensional, rigid-body model of the PR2 robot with most of the hardware-ROS interfaces found on the actual PR2 robot. You can see the  package for documentation on the supported interfaces. "
W1486,https://wiki.ros.org/aruco,Wiki,aruco,"The ARUCO Library has been developed by the Ava group of the Univeristy of Cordoba(Spain).
    It provides real-time marker based 3D pose estimation using AR markers."
W1487,https://wiki.ros.org/kuka_kr16_support,Wiki,kuka_kr16_support,"
      ROS-Industrial support for the KUKA KR16 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 16 manipulators. This currently includes the KR 16-2 only.
    :
      Joint limits and maximum joint velocities are based on the information
      found in the online datasheet . All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      : this package currently uses non-valid inertia parameters.
    "
W1488,https://wiki.ros.org/movie_publisher,Wiki,movie_publisher,"Node for using a video file as video topic source.
 













 The node can run with either of two backends -  and .  is strongly recommended, as it uses , which is quite versatile and efficient. Is you do not set the  param, autodetection is run. It is a Bash script with ROS node-like API - you pass it parameters via  on commandline or via ROS param server. Call this script from commandline setting the node-private parameters, and pass any other  arguments - these will be relayed to  as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ). It is a Bash script with ROS node-like API - you pass it parameters via  on commandline or via ROS param server. Call this script from commandline setting the node-private parameters, and pass any other  arguments - these will be relayed to movie_publisher.launch as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ). Goes through  and for all messages with a  field sets their publication time to the time stored in their  plus . If  are set, only works on messages on the listed topics. Reading timestamps from  is also supported. It is a Python script with ROS node-like API - you pass it parameters via  on commandline. movie_publisher_nodesensor_msgs/Imagemovie_publisher.launchimmediatemovie_to_bagadd_movie_to_bagfix_bag_timestampsmerge.pymoviepyopencvmoviepyffmpegbackendmovie (sensor_msgs/Image)movie_file (string, required)fps (float, optional)start (float|tuple|string, optional)15.35(min, sec)(hour, min, sec)'01:03:05.35'enddurationend (float|tuple|string, optional)15.35(min, sec)(hour, min, sec)'01:03:05.35'startdurationduration (float|tuple|string, optional)15.35(min, sec)(hour, min, sec)'01:03:05.35'startendloop (bool, default False)immediateimmediate (bool, default False)fake_time_startloopplayback_rate (float, optional)fake_time_start (float, default 0.0)immediateframe_id (string, default """")spin_after_end (bool, default False)verbose (bool, default False)wait_after_publisher_created (float, default 1.0)publisher_queue_size (int, default 1000 in immediate mode, 10 otherwise)queue_sizebackend (string, default ""moviepy"")moviepyopencvmoviepyopencvffmpeg (string, default """")transport (string, default 'raw')image_transport/republishrepublished_topic_basename (string, default movie_$(arg transport))$(arg republished_topic_basename)/$(arg transport)$(arg republished_topic_basename)rawmovie_publisher_nodemovie_param:=valuemovie (string)bag (string)topic (string)overwrite_bag (bool, default false)bagbagtmp_bag (string, default /tmp/movie.bag)transport (string, default compressed)rawcompressedtheoraarg:=valuemovie_publisher.launchmovie_file_param:=valuemovie (string)bag_in (string)bag_out (string, default: output.bag)topic (string)movie_delay (int, default 0)overwrite_out_bag (bool, default false)bag_outbag_outbag_tmp (string, default /tmp/movie_add_to.bag)transport (string, default compressed)rawcompressedtheoraarg:=valuemovie_filein_bagheaderheader.stampdelaytopics/tf_param:=valuein_bag (string)out_bag (string)topics (string, default: '')delay (int, default 0)headeroverwrite_existing (bool, default false)out_bagout_bagsudo pip install moviepyrosdep install python-moviepy-piprosrun movie_publisher movie_to_bag _movie:=movie.mp4 _bag:=movie.bag _topic:=""/movie"" start:=5 fake_time_start:=1548323340.24rosrun movie_publisher add_movie_to_bag _movie:=movie.mp4 _bag_in:=movie_in.bag _bag_out:=movie_out.bag _topic:=""/movie"" start:=5 movie_delay:=-1"
W1489,https://wiki.ros.org/urdfdom_headers,Wiki,urdfdom_headers,"C++ Headers for URDFThis is now an upstream package, and can be found here:  "
W1490,https://wiki.ros.org/velodyne_utils,Wiki,velodyne_utils,"

    ROS tools and utilities for Velodyne 3D LIDARs.

  

In Hydro it is , but still provided. Catkin stacks should never use it, but rosbuild stacks depending on  should still work. In Indigo, all references must be changed to use  directly. See , the only package. velodyne_utils"
W1491,https://wiki.ros.org/multimaster_msgs_fkie,Wiki,multimaster_msgs_fkie,"The messages required by multimaster packages.



The  describes a discovered ROS Master by  and . It offers also additional information about corresponding  node and timestamps of last detected changes of the ROS Master. The  service returns the list with current discovered ROS Masters. The changes of each ROS Master are annonced by . The  and  messages offers additional information about the link quality to discovered ROS Master machines. The  service uses  respectively  messages to return the all currently synchronized  and . The services  and  returns the nodes and their description. The  service can then be used to launch one of these nodes. See  for additional information. nameuritopicsservices"
W1492,https://wiki.ros.org/pepperl_fuchs_r2000,Wiki,pepperl_fuchs_r2000,"The Pepperl+Fuchs R2000 laser range finder driver package
 
 (from the official datasheet with permission from Pepperl+Fuchs) 






 The driver is based upon the widespread boost asio library () The driver comes as a library, which contains the actual driver, and has additionally a ROS-Node interface to the Robot Operating System (), which can be used optionally. Official Website:  Datasheet OMD10M-R2000 (en):  Datasheet OMD30M-R2000 (en):  The ROS package  consists of the driver library and a node named , which is linked to the library. This is the actual driver node. The  is only needed if you want to display the sensors data using the  method mentioned below. Copy the driver in your ROS workspace and compile it. Set the IP-Address of the scanner in  and run the following command: This starts  () and the driver and you should see the measuring output of the scanner. There exists a file  in the  directory. Replace  with it to compile the driver without ROS: This builds a SHARED library which can be used in your program.  To build a static library remove the  in the  command in the . The driver is commented in doxygen style.  You can create a latex and html documentation in the  directory  by entering the following command in the  directory: pepperl_fuchs_r2000r2000_nodedummy_slam_broadcasterscanscan_frequencyframe_idscanner_ipscan_frequencysamples_per_scanpepperl_fuchs_r2000/launch/gui_example.launchRVizCMakeLists.txt.NO_ROS_LIB_ONLYpepperl_fuchs_r2000CMakeLists.txtSHAREDadd_libraryCMakeLists.txtpepperl_fuchs_r2000/doxygenpepperl_fuchs_r2000    roslaunch pepperl_fuchs_r2000 gui_example.launch    $ cd pepperl_fuchs_r2000
    $ mv CMakeLists.txt.NO_ROS_LIB_ONLY CMakeLists.txt
    $ mkdir build
    $ cd build
    $ cmake ..
    $ make    #include <pepperl_fuchs_r2000/r2000_driver.h>

    int main(int argc, char **argv)
    {
      bool success;

      pepperl_fuchs::R2000Driver driver;
      success = driver.connect(""192.168.0.100""); // Replace IP
      success = driver.setScanFrequency(35);     // Set scanner frequency in the range [10;50]
      success = driver.setSamplesPerScan(3600);  // Set samples per scan in the range [72,25200] (valid values are listed in manual)

      auto params = driver.getParameters();      // Get all parameter values as std::map<string, string>
      for( auto key_value : params )
      { Do something with the parameter values }

      success = driver.startCapturingUDP();      // Notice: startCapturingTCP() also exists

      while(true)
      {
          pepperl_fuchs::ScanData  scandata = driver.getFullScan(); // Do something with:
          scandata.headers;                                         // headers,
          scandata.distance_data;                                   // distances and
          scandata.amplitude_data;                                  // amplitudes
      }

      driver.stopCapturing();
      driver.disconnect();
    }    $ doxygen doxygen.conf"
W1493,https://wiki.ros.org/nodelet,Wiki,nodelet,"The nodelet package is designed to provide a way to run multiple
    algorithms in the same process with zero copy transport between
    algorithms.

    This package provides both the nodelet base class needed for
    implementing a nodelet, as well as the NodeletLoader class used
    for instantiating nodelets.






 










 Nodelets are designed to provide a way to run multiple algorithms on a single machine, in a single process, without incurring copy costs when passing messages intraprocess. roscpp has optimizations to do zero copy pointer passing between publish and subscribe calls within the same node.  To do this nodelets allow dynamic loading of classes into the same node, however they provide simple separate namespaces such that the nodelet acts like a seperate node, despite being in the same process.  This has been extended further in that it is dynamically loadable at runtime using . For command line and launch file examples see this tutorial  These are nodelet aware wrappers around  macros.  They include verbosity levels DEBUG, INFO, WARN, ERROR, and FATAL.  These macros will only compile inside nodelet methods. If you want the no-copy pub/sub to work you must publish your messages as s.  See  for more details. Following commands are helpful to list all nodelets available on your system found in . Note that it's NOT the list of currently running nodelet nor nodelet managers. Or list the nodelet xml files for  by: shared_ptrROS_PACKAGE_PATHnodelet usage:
nodelet load pkg/Type manager - Launch a nodelet of type pkg/Type on manager manager
nodelet standalone pkg/Type   - Launch a nodelet of type pkg/Type in a standalone node
nodelet unload name manager   - Unload a nodelet a nodelet by name from manager
nodelet manager               - Launch a nodelet manager node



















rosrun nodelet declared_nodeletsrospack plugins --attrib=plugin nodelet"
W1494,https://wiki.ros.org/industrial_utils,Wiki,industrial_utils,"Industrial utils is a library package that captures common funcitonality for the ROS-Industrial distribution.



Use GitHub to . []
 The industrial utilities package provides a common package library for  functions.  The functions in this package apply across package boundaries.  Utility functions for single packages should not be included in this package. "
W1495,https://wiki.ros.org/arbotix_sensors,Wiki,arbotix_sensors,"Extends the arbotix_node package with a number of more sophisticated ROS wrappers for common devices.


The arbotix_sensors package contains several sensor modules that add additional layers of ROS interface onto the basic structure of . /<name>/ir_range/arbotix/SetupAnalogIn~namestr~pinint~rateint~typestr"
W1496,https://wiki.ros.org/adi_driver,Wiki,adi_driver,"The adi_driver packageUse GitHub to . []
 Documentation for  is now . "
W1497,https://wiki.ros.org/ping360_sonar,Wiki,ping360_sonar,A ROS package for Blue Robotics Ping360 Sonar
W1498,https://wiki.ros.org/pr2_image_snapshot_recorder,Wiki,pr2_image_snapshot_recorder,"

     pr2_image_snapshot_recorder

  "
W1499,https://wiki.ros.org/leptrino_force_torque,Wiki,leptrino_force_torque,"The leptrino_force_torque packageROS driver package for  force-torque sensor , , both of which seemingly only Japanese available as of Sep. 2016). Leptrino"
W1500,https://wiki.ros.org/mir_description,Wiki,mir_description,URDF description of the MiR100 robot
W1501,https://wiki.ros.org/rospeex_launch,Wiki,rospeex_launch,This package launches rospeex's core nodes.
W1502,https://wiki.ros.org/maggie_robot,Wiki,maggie_robot,"maggie_robot metapackage



The user's interface to the  stack is , which provides launch files that can be used to bring up the robot. The other packages in this stack are used during the bringup process, and are not usually accessed directly by users. Starting up the robot is not any different from launching a normal ROS program. Launch the  file. Check out the  that guide you through all the steps for running the Maggie devices. Go to . Report new issues on  maggie_robotmaggie_start.launch"
W1503,https://wiki.ros.org/rospeex_samples,Wiki,rospeex_samples,This package provides some rospeex samples.
W1504,https://wiki.ros.org/assisted_teleop,Wiki,assisted_teleop,"The assisted_teleop node subscribes to a desired trajectory topic
    (geometry_msgs/Twist) and uses TrajectoryPlannerROS to find a valid
    trajectory close to the desired trajectory before republishing. Useful for
    filtering teleop commands while avoiding obstacles. This package also
    contains LaserScanMaxRangeFilter, which is a LaserScan filter plugin that
    takes max range values in a scan and turns them into valid values that are
    slightly less than max range."
W1505,https://wiki.ros.org/nav2d_exploration,Wiki,nav2d_exploration,"This package holds a collection of plugins for the RobotNavigator, that provide
    different cooperative exploration strategies for a team of mobile robots."
W1506,https://wiki.ros.org/robot_pose_ekf,Wiki,robot_pose_ekf,"The Robot Pose EKF package is used to estimate the 3D pose of a robot, based on (partial) pose measurements coming from different sources. It uses an extended Kalman filter with a 6D model (3D position and 3D orientation) to combine measurements from wheel odometry, IMU sensor and visual odometry. The basic idea is to offer loosely coupled integration with different sensors, where sensor signals are received as ROS messages.










 



The  node does not require all three sensor sources to be available all the time. Each source gives a pose estimate and a covariance. The sources operate at different rates and with different latencies. A source can appear and disappear over time, and the node will automatically detect and use the available sensors.To add your own sensor inputs, check out  All the sensor sources that send information to the filter node can have their own  reference frame, and each of these  reference frames can drift arbitrary over time. Therefore, the  sent by the different sensors cannot be compared to each other. The node uses the  of each sensor to update the extended Kalman filter. As a robot moves around, the uncertainty on its pose in a world reference continues to grow larger and larger. Over time, the covariance would grow without bounds. Therefore it is not useful to publish the covariance on the pose itself, instead the sensor sources publish how the covariance changes over time, i.e. the covariance on the velocity.  Imagine the robot pose filter was last updated at time t_0. The node will not update the robot pose filter until at least one measurement of  sensor arrived with a timestamp later than t_0. When e.g. a message was received on the  topic with timestamp t_1 > t_0, and on the  topic with timestamp t_2 > t_1 > t_0, the filter will now update to the latest time at which information about all sensors is available, in this case to time t_1. The odom pose at t_1 is directly given, and the imu pose at t_1 is obtained by linear interpolation of the imu pose between t_0 and t_2. The robot pose filter is updated with the relative poses of the odom and imu, between t_0 and t_1. The above figure shows experimental results when the PR2 robot started from a given initial position (green dot), driven around, and returned to the initial position. A perfect odometry x-y plot should show an exact loop closure. The blue line shows the input from the wheel odometry, with the blue dot the estimated end position. The red line shows the output of the , which combined information of wheel odometry and imu, with the red dot the estimated end position.  robot_pose_ekfodomimu_datavorobot_pose_ekfrobot_pose_ekf/odom_combinedodom_combinedbase_footprintodomimu_datarobot_pose_ekf <launch>
  <node pkg=""robot_pose_ekf"" type=""robot_pose_ekf"" name=""robot_pose_ekf"">
    <param name=""output_frame"" value=""odom""/>
    <param name=""freq"" value=""30.0""/>
    <param name=""sensor_timeout"" value=""1.0""/>
    <param name=""odom_used"" value=""true""/>
    <param name=""imu_used"" value=""true""/>
    <param name=""vo_used"" value=""true""/>
    <param name=""debug"" value=""false""/>
    <param name=""self_diagnose"" value=""false""/>
  </node>
 </launch> $ rosdep install robot_pose_ekf
 $ roscd robot_pose_ekf
 $ rosmake $ roslaunch robot_pose_ekf.launch"
W1507,https://wiki.ros.org/agvs,Wiki,agvs,"The agvs package. This package contains all the components to simulate the AGVS robot. An ackermann type robot intended for logistics transport.










This package contains the different controllers and launch files for the  simulation.  1.  "
W1508,https://wiki.ros.org/ros_additive_manufacturing,Wiki,ros_additive_manufacturing,"ROS-Industrial additive manufacturing tools (metapackage)
Documentation is here:  "
W1509,https://wiki.ros.org/patrolling_sim,Wiki,patrolling_sim," Multi-Robot Patrolling Stage/ROS Simulation Package.  
Multi-Robot Patrolling Package for ROS. Composed of 7 running algorithms:  
 

To run the package, please read  Tutorial. 

monitorresultsConscientious_CognitiveConscientious_ReactiveCyclicGBSHeuristic_Conscientious_ReactiveMSPSEBS"
W1510,https://wiki.ros.org/lex_common_msgs,Wiki,lex_common_msgs,Common messages for interacting with Amazon Lex using the lex_node package
W1511,https://wiki.ros.org/pr2_moveit_tutorials,Wiki,pr2_moveit_tutorials,The pr2_moveit_tutorials package
W1512,https://wiki.ros.org/mir_driver,Wiki,mir_driver,A reverse ROS bridge for the MiR100 robot
W1513,https://wiki.ros.org/pr2_apps,Wiki,pr2_apps,"Basic applications for the PR2 robot 

  This stack comprises applications that can be run on the PR2.  In most cases, these applications can be run on PR2 hardware, or in . The latter example brings up the PR2 in an empty simulated world; for information on other worlds, including building your own, consult the . roslaunch /etc/ros/robot.launchroslaunch pr2_gazebo pr2_empty_world.launch "
W1514,https://wiki.ros.org/rsv_balance_simulator,Wiki,rsv_balance_simulator,Simulation packages for RoboSavvy's balancing platform. 
W1515,https://wiki.ros.org/maggie_ir_controller,Wiki,maggie_ir_controller,"ir_controller node





The  file contains all possible commands to use with a TV. To generate new commands for another TV consult the Users Manual. This device supports all the drivers implemented in the  package. tv_actionsend_command $ roslaunch maggie_ir_controller ir_controller.launch robot:=maggie $ rosservice call /maggie/send_command maggie_ir_controller_msgs/SetTvAction ""on"""
W1516,https://wiki.ros.org/kobuki_core,Wiki,kobuki_core,"Non-ROS software for Kobuki, Yujin Robot's mobile research base.
Driver documentation is provided by . For ros-related information about kobuki, visit either the  or the  pages. "
W1517,https://wiki.ros.org/abb_irb6640_moveit_config,Wiki,abb_irb6640_moveit_config,"
      MoveIt package for the ABB IRB 6640.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 6640 with the MoveIt Motion Planning
      Framework.
    
This package is part of the  program. "
W1518,https://wiki.ros.org/abb_irb6600_support,Wiki,abb_irb6600_support,"
      ROS-Industrial support for the ABB IRB 6600 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 6600 manipulators. This currently includes the base model.
    
      Joint limits and max joint velocities are based on the information in
      the ABB data sheets.  All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      The unqualified IRB 6400 model will be removed in ROS-Lunar, please
      use the abb_irb6640_support as a replacement.
    "
W1519,https://wiki.ros.org/rail_object_detector,Wiki,rail_object_detector,"The rail_object_detector package






: recognize objects in the latest image from the camera stream .  Takes no input, and outputs a list of detected, labeled objects and a corresponding image.  Only advertised if  is true. 
: recognize objects in an image passed to the service.  Takes an image as input, and outputs a list of detected, labeled objects and a corresponding image. Only advertised if  is true. 














 This package includes two object detectors which you may choose between, YOLOv2 and Deformable R-FCN (DRFCN). Detections from YOLOv2 are a bit faster, >10fps compared to ~4fps (on a Titan X), but less accurate than the detections from DRFCN. The YOLOv2 detector uses  to perform object detection. It provides the ability to query for objects in an image through both services as well as from a topic. The  detector is built on MXNet, and provides the ability to query for objects from a topic. The nodes in this package publish a list of  within a given image, each of which has the following properties: The DRFCN detector requires a CUDA and cuDNN capable GPU, so it is not installed by default. In order to use it, we recommend getting this code from Github and following the instructions in the . The rest of this documentation covers instructions for a CPU-only install of this package that uses darknet. This package contains a single ROS node -  - which serves as an interface between a ROS system and the trained object recognition network. Type:  Type:  Type:  Topic with object detections performed in the background by grabbing images at a specified interval. Only advertised if  is true. Type:  Default:  Number of asynchronous threads that can be used to service each of the services.  implies the use of one thread per processor Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  Type:  Default:  A good set of weights, to complement the default trained labels can be obtained from . To build using CUDA, obtain the package from Github and follow the instructions in the . This is necessary if you wish to use the Deformable R-FCN detector. The underlying Darknet code has been copied as is. So the detector can be trained and retrained following instructions on the . The same is true for the Deformable R-FCN. Check the  for details. labelprobabilitycentroid_xcentroid_yleft_bot_xleft_bot_yright_top_xright_top_xdarknet_nodeimage_sub_topic_nameuse_scene_serviceuse_image_servicepublish_detections_topicint00booltrueboolfalseboolfalsestring""/kinect/hd/image_color_rect""float1.0float0.25string""$(find rail_object_detector)/libs/darknet/data/coco.names""string""$(find rail_object_detector)/libs/darknet/cfg/yolo.cfg""string""$(find rail_object_detector)/libs/darknet/yolo.weights"""
W1520,https://wiki.ros.org/rwt_speech_recognition,Wiki,rwt_speech_recognition,The rwt_speech_recognition package
W1521,https://wiki.ros.org/rospack,Wiki,rospack,"ROS Package Tool
 is a command-line tool for retrieving information about ROS  available on the filesystem. It implements a wide variety of commands ranging from locating ROS packages in the filesystem, listing available packages, to calculating the dependency tree of packages. It is also used in the ROS  for calculating build information for packages. For an equivalent tool for , see . Prior to ROS ,  was included in the  stack.  Since Fuerte, it is a standalone tool. Documentation is available . rospackrospack"
W1522,https://wiki.ros.org/visualization_msgs,Wiki,visualization_msgs,"visualization_msgs is a set of messages used by higher level packages, such as , that deal in visualization-specific data.

    The main messages in visualization_msgs is .
    The marker message is used to send visualization ""markers"" such as boxes, spheres, arrows, lines, etc. to a visualization environment such as .
    See the rviz tutorial  for more information.: this package was moved from  to .  

 is the top-level message for sending data from the interactive marker server to the client (i.e. rviz).  The update message has an array of  messages which are new or which need to be updated.  It also has an array of  messages for sending only pose updates to existing interactive markers. A useful overview of  types can be found at . An introduction to the InteractiveMarker messages is given in the interactive marker tutorial at . Each  message has an array of s which describe its subcomponents.  Each  has an array of s which together describe the shape of the control. The  message also has an array of s which together define a context menu which should appear when the appropriate action happens in the client (like a right-click).  Although the entries are sent in a flat array, each one contains an id and a parent_id to specify a tree structure.  This is described in  . visualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Markervisualization_msgs/Marker"
W1523,https://wiki.ros.org/abb_common,Wiki,abb_common,"

     abb_common

  
This package is part of the  program.  "
W1524,https://wiki.ros.org/asr_flock_of_birds_tracking,Wiki,asr_flock_of_birds_tracking,"This package controls a motorized robot head (a sensor setup equipped with a PTU) in order to ensure that the hand of a human user remains inside its field of view. The human hand is tracked with the help of an Ascension - Flock of Birds system. The purpose of this package is to enable continuous localization of objects during their manipulation through the tracked hand. 

    








First of all, the position of magnet tracker (p) is transformed into the PTU's coordinate frame. Azimuth (a_xy) and altitude (a_yz) are calculated with the arccos of dot-Product divided by euclidiean distance. The following equations shows this:  To successfully run this tool the whole kinematic chain of the PbD -Dome has to be started (PTU and Flock of Birds) first and the correct topic- and framenames have to set in """". With keys ""R"" or ""L"" the PTU can look at the right or left tracker (autonomous tracking). In addition the PTU can be moved with the arrwokeys (direct PTU controlling). roslaunch asr_flock_of_birds_tracking tracker.launch"
W1525,https://wiki.ros.org/rviz,Wiki,rviz,"3D visualization tool for ROS.






.  [  ] rviz does not have a builtin capability to record movies.  You can, however, use an application like  (or ) to do so.  The  page has more information on recording and encoding. rosrun rviz rviz --help"
W1526,https://wiki.ros.org/joint_state_publisher_js,Wiki,joint_state_publisher_js,rosjs package for publishing joint states
W1527,https://wiki.ros.org/ar_pose,Wiki,ar_pose,"
    Augmented Reality Marker Pose Estimation using ARToolkit
    
 provides two nodes you can run. The program  provides a transform between the camera and a single AR Marker. The program  provides an array of transforms for multiple markers. 









 This package is an ROS wrapper for . Currently the  package requires calibration information from a camera_info topic. If there is no camera_info topic the marker pose estimation will not start. You can run  on a live video from a camera, or on a pre-recorded bag file that comes with the package. First, make sure you have  metapackage downloaded and installed and built. This demo uses  to track the location of an  relative to the location of a fixed camera. The position of the camera in the world frame is published by  as a static transform. The tracking process is visualized in . This demo uses  to track the position of the camera relative to the location of an . The position of the marker in the world frame is published by  as a static transform. The tracking process is visualized in . This demo uses  to track the location of multiple  relative to the location of a fixed camera. The position of the camera in the world frame is published by  as a static transform. The tracking process is visualized in . Two examples are provided that are configured and calibrated for use with a Logitech C600 webcam and the  driver. A multi-marker configuration can be started as well. The Markers used in this example are found in ~/ros/stacks/ccny-ros-pkg/ccny_vision/data/4x4/4x4_ps.tar.gz The 4x4 patterns were created with  which was developed by David Johnson, Christopher Berthiaume and Bryan Witkowski. These patterns are distributed with this software under the GPL with permission. Please use our  to  or . ar_singlear_multiar_singlestatic_tf_publishersetup_single.shar_singlestatic_tf_publishersetup_reverse.shar_multistatic_tf_publishersetup_multi.sh













"
W1528,https://wiki.ros.org/arni_core,Wiki,arni_core,"This package contains common ARNI functionality. Furthermore, generic launch files and integration tests."
W1529,https://wiki.ros.org/qb_device_driver,Wiki,qb_device_driver,"This package contains a device-independent API wrapper for qbrobotics® devices.



This is the only package among the ones in  which can be used as a stand-alone ROS node, called . It wraps the  API, manages the shared resources and provides a multi-node from/to multi-device communication interface. The  node manages the serial communication from the ROS ecosystem to the physical  devices connected to it through any serial ports, and vice versa. The need of such a mediator is demanded to the possibility to connect several devices together (i.e. in a chain) and access them through a single serial port. Each ROS node representing a device has to request services to the owner of the shared resources, i.e. the Communication Handler. To start an instance of the Communication Handler node, be sure that the  is running and then simply execute the following command from a terminal (it  any configuration parameters): To integrate the Communication Handler node in your application launch file you simply need to add the node to it (it  any configuration parameters). roscorederegister_deviceregister_deviceregister_device/communication_handler/activate_motorssuccesstrue/communication_handler/deactivate_motorssuccesstrue/communication_handler/deregister_device/communication_handler/get_infomessage/communication_handler/get_measurementssuccesstruecurrentspositions/communication_handler/register_devicesuccesstrue/communication_handler/set_commandscommands/communication_handler/sync_nodessuccesstruerosrun qb_device_driver qb_device_communication_handler<launch>
  <node name=""qb_device_communication_handler"" pkg=""qb_device_driver"" type=""qb_device_communication_handler"" respawn=""true"" output=""screen""/>
  ...
</launch>"
W1530,https://wiki.ros.org/ainstein_radar_msgs,Wiki,ainstein_radar_msgs,"ROS message definitions for Ainstein radars.

"
W1531,https://wiki.ros.org/sf30_node,Wiki,sf30_node,"The sf30_node package provides a driver for the sf30 laser range finder.



 This is a ROS node for  The node assume the following setup for the laser (I used the  terminal from the manufacture): Create a catkin workspace. For instructions on how to create the workspace go . Download and compile the package: The message of type  will be published in topic /sf30/range at 50Hz. The intensities field on this message means data confidence. It is 1 if we can trust the given range.    1: Active data port           USB distance in m
   2: Resolution                 0.03 m
   3: Serial port update rate    1000 / sec  (actual = 1665 / sec)
   4: Serial port baud rate      115200
   5: Analog port update rate    1 / sec  (actual = 1 / sec)
   6: Analog maximum range       256 m
   7: Alarm activation distance  17.50 m
   8: Alarm latch                Off
   9: USB port update rate       50 / sec  (actual = 50 / sec)0.57 m
0.57 m
0.59 m
0.57 m
0.59 m
0.59 m
0.55 m
0.59 m
0.57 m
0.57 m
0.57 mcatkin_ws/src
git clone git@bitbucket.org:castacks/sf30_node.git
cd ..
catkin_makesource devel/setup.bash
roslaunch sf30_node sf30.launch"
W1532,https://wiki.ros.org/pacifica_dbw,Wiki,pacifica_dbw,"A ROS interface to the New Eagle Raptor drive-by-wire controller







 The raptor_dbw  is a collection of packages for interacting with the New Eagle Raptor DBW controllers. The primary goal of this stack is to facilitate ROS-based DBW kit development and provide a set of ROS-CAN interface tools. The current development branch is  and targets ROS  and . For more on New Eagle Raptor controllers see:  masterkineticmelodic"
W1533,https://wiki.ros.org/qb_hand_control,Wiki,qb_hand_control,"This package contains the ROS control node for qbrobotics® qbhand device.




This package contains the ROS control node and its structures to control the  device. It exploits the features provided by the base device-independent control library (cf. ) and the specific hardware interface (cf. ). The two launch files start a ROS node for the  respectively to control it through a GUI and through predefined configurable waypoints (stored in the ). In both cases the controllers setup can be found in the ; it is recommended not to change the default settings though. This launch file calls the template  with the default settings to bringup a full control node for the  based on GUI inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf.  to control several devices together). This launch file calls the template  with the default settings to bringup a full control node for the  based on waypoint inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf.  to control several devices together). This control library specifically designed for the  extends the  and exploits the , therefore it provides all the ROS resources and requires all the specifications of this two base packages. config/qbhand_waypoints.yamlconfig/qbhand_controllers.yaml"
W1534,https://wiki.ros.org/pr2_plugs_msgs,Wiki,pr2_plugs_msgs,"

     pr2_plugs_msgs provides the msgs and action definitions required for plugging in.

  Newly proposed, mistyped, or obsolete package. Could not find package ""pr2_plugs_msgs"" in rosdoc: /home/rosbot/docs/api/pr2_plugs_msgs/manifest.yaml "
W1535,https://wiki.ros.org/pr2_ethercat,Wiki,pr2_ethercat,"Main loop that runs the robot.




 is usually executed from a launch file, such as /pr2.launch.  Common configuration: 
 is a utility that allows a regular user to run  with appropriate capabilities. See the section in  on ""Permissions."" 
 is a simple command-line script that calls the  service. (formerly  in Groovy and earlier) Running  requires the following ""capabilities"": Superuser has these capabilities, but they can also be granted to another executable by setting file system attributes on the executable file.  The  program is a setuid-root program which copies  to a part of the filesystem where attributes can be set (), and then grants the necessary capabilities to be able to run . pr2_ethercatpr2_ethercatpr2_ethercatpr2_ethercatpr2_ethercat/reset_motorshalt_motorspr2_ethercat/halt_motorsreset_motorspr2_ethercatpr2-grantpr2_ethercat/var/tmppr2_ethercaatpr2_ethercatpr2-grantpr2_ethercatpr2_ethercatreset_motors.pypr2_ethercat/reset_motorsUsage: ./pr2_ethercat [options]
  Available options
    -i, --interface <interface> Connect to EtherCAT devices on this interface
    -x, --xml <file|param>      Load the robot description from this file or parameter name
    -r, <param>                 Load the robot description from this parameter
    -u, --allow_unprogrammed    Allow control loop to run with unprogrammed devices
    -h, --help                  Print this message and exit<node name=""realtime_loop"" machine=""c1"" launch-prefix=""pr2-grant"" pkg=""pr2_ethercat"" type=""pr2_ethercat"" args=""-i ecat0 -x robot_description""/>$ rosrun pr2_ethercat reset_motors.py"
W1536,https://wiki.ros.org/motoman_sia20d_support,Wiki,motoman_sia20d_support," This package will be removed in ROS Kinetic. The configuration data and
      models included in this package can now be found in the motoman_sia_support
      package in ROS Jade.ROS-Industrial support for the Motoman SIA20D (and variants).
      This package contains configuration data, 3D models and launch files
      for Motoman SIA20D manipulators.
    
      
    
      Joint limits and maximum joint velocities are based on the information 
      found in the online 
      http://www.motoman.com/datasheets/sia20d.pdf
      All urdfs are based on the default motion and joint velocity limits, 
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1537,https://wiki.ros.org/nav2d_tutorials,Wiki,nav2d_tutorials,Contains a set of tutorials that run 2D-Navigation within Stage-Simulator.
W1538,https://wiki.ros.org/innok_heros_driver,Wiki,innok_heros_driver,"Driver for the Innok Heros robot plattform

Press the Power button on the Innok Heros. 
Start the ROS driver with Make sure that the  parameter in  is set to the correct address of your Heros (default host is 192.168.1.213). 

 ROS driver for the  robot plattform. hostheros_base.launchcmd_velodomhoststringodombase_linkroslaunch innok_heros_driver heros_base.launch"
W1539,https://wiki.ros.org/odometry_publisher_tutorial,Wiki,odometry_publisher_tutorial,The odometry_publisher_tutorial packageThis package provides the code for the  tutorial. 
W1540,https://wiki.ros.org/agvs_control,Wiki,agvs_control,"The agvs_control package. Config files used for Gazebo motor controllers.
"
W1541,https://wiki.ros.org/kobuki_bumper2pc,Wiki,kobuki_bumper2pc,"Bumper/cliff to pointcloud nodelet:
    Publish bumpers and cliff sensors events as points in a pointcloud, so navistack can use them
    for poor-man navigation. Implemented as a nodelet intended to run together with kobuki_node.~bumper_events~cliff_events~pointcloud~pointcloud_radiusdouble~bumper_events~cliff_events~pointcloud~pointcloud_radiusdouble"
W1542,https://wiki.ros.org/kobuki_controller_tutorial,Wiki,kobuki_controller_tutorial,"Code for the Kobuki controller tutorial. 
This package holds the supporting code for the . "
W1543,https://wiki.ros.org/qb_device_description,Wiki,qb_device_description,"This package contains a device-independent description utilities for qbrobotics® devices.
 
 
This package is barely usable alone since it provides only templates to create more structured launch files in the derived packages (cf. ). The two launch file templates come in help when loading the description package of a device. It could seem unlikely to split the two files (and actually they are often called sequentially), but it guarantees in a  to be able to load every single robot description in each device namespace (which is required to setup their control nodes) and to load the whole robot model complete with ,  and  only once. robot_descriptionmodel_namestringqb_deviceqb_device.urdf.xacro.urdf/_descriptionnamespacestringmy_devicemy_device_joint_...my_device_link_...package_prefixstringqb_deviceqb_device_descriptionrobot_descriptionfrequencyintHzpackage_prefixstringqb_deviceqb_device_descriptionrviz_configstringqb_deviceqb_device.rviz.rviz/_descriptionsource_list_namesstringuse_joint_state_guibooluse_rvizbool"
W1544,https://wiki.ros.org/applanix_driver,Wiki,applanix_driver,"applanix_driver 


 

  The  stack provides a comprehensive ROS interface to , which integrate GPS, IMU, and DMI data into a high accuracy position and orientation fix. These packages have not (yet) been released for Indigo or newer versions, but can be build from source in your catkin workspace. Refer to the  for more information on building catkin workspaces. If you're looking for the topic for a particular Applanix group, please consult the file . The  package provides a direct translation of the Applanix binary format into ROS messages and services. The remaining packages provide helper nodes which further convert those messages into familiar ROS messages (, , , etc), and offer some support for configuration via ROS parameters. The applanix_msgs package contains a ROS  for each Applanix data group and command message, as well as , which controls the naming of the resultant ROS topics and service. The applanix_generated_msgs package contains a script which creates a wrapper  for each command message, and also assembles a mega AllMsgs.msg file. This structure allows a natural service-oriented interface to configuring and commanding the Applanix hardware, while still allowing the user to subscribe to a single topic to receive a snapshot of the device's configuration at a given time. applanix_msgs/src/mapping.pymapping.pygpsmonsudo apt-get install ros-$ROS_DISTRO-applanix-driverroslaunch applanix_launch example.launch"
W1545,https://wiki.ros.org/schunk_canopen_driver,Wiki,schunk_canopen_driver,"The schunk_canopen_driver package


















 If you have the fzi_icl_core or fzi_icl_can package in your workspace you'll have to build it with , as those packages are plain cmake packages. See the  for details. The simpler -interface accepts series of waypoints which the robot will drive to with internal interpolation. It is not guaranteed (and might almost never happen), that all joints finish moving at the same time. If multiple waypoints are given, a new waypoint is started for all joints at the same time as soon as the last joint reached it's previous destination. Ramping up and down between waypoints is done by the robot internally depending on it's configuration. The ramping setup will be treated later on. The -interface provides a position controller in joint space which will interpolate between waypoints inside the controller (on the host PC). You can set joint velocities and time constraints for each waypoint which the controller will take care of. This launchfile gives a ready-to-use action interface for ros_control. It loads controllers defined in  (This can be changed in the ros_control.launch file). Parameters: If your robot arm does use custom canopen IDs, you can modify those in the  file. When modifying the canopen IDs you will also have to modify the node mapping in  which will perform the mapping between the canopen IDs and the URDF joint names. See the example config file for a syntax explanation. When using the simple profile position mode Ramping up and down is controlled by the hardware. The velocity and acceleration can be configured in the file. Also, targets can be commanded as a relative motion to the current position or as an absolute position relative to the home position (which is the default). Change the  parameter if you like to change this behavior. Canceling a goal at high speeds seems to set the robot into a fault state. This comes from within the used position controller as it commands the robot to hold a position which is too far away to be reached within one control cycle. As a workaround prefer the  service follow_joint_trajectory/follow_joint_trajectorypos_based_pos_traj_controller/follow_joint_trajectoryjoint_statesjoint_currentsclose_brakesenable_nodesquick_stop_nodeshome_reset_offset_by_idhome_reset_offset_by_namehome_reset_offset_allinit_devicesautostartboolcan_device_namestringfrequencyinttraj_controller_namestringuse_ros_controlbool   rosrun fzi_icl_can install_pcan_module.sh   catkin_make_isolated
   source devel_isolated/setup.bash
   # If Peak driver was not installed before.
   # Note: You will be asked for your sudo password during execution.
   rosrun fzi_icl_can install_pcan_module.sh  sudo apt-get install ros-indigo-schunk-canopen-driver
  # If Peak driver was not installed before.
  # Note: You will be asked for your sudo password during execution.
  rosrun fzi_icl_can install_pcan_module.sh"
W1546,https://wiki.ros.org/nao_audio,Wiki,nao_audio,"Package for the Nao robot, providing access to NAOqi vision proxies

nao_audio/audio_source_localizationnao_audio/master_volumenao_audio/play_filenao_audio/record"
W1547,https://wiki.ros.org/kuka_lbr_iiwa_support,Wiki,kuka_lbr_iiwa_support,"
      ROS-Industrial support for the KUKA LBR IIWA (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA LBR IIWA manipulators. This currently includes the base model.
    
      Joint limits and max joint velocities are based on the information in
      the KUKA  online. 
      All urdf's / xacro's are based on the default motion and joint velocity 
      limits, unless noted otherwise (ie: no support for high speed joints, 
      extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1548,https://wiki.ros.org/razor_imu_9dof,Wiki,razor_imu_9dof,"razor_imu_9dof is a package that provides a ROS driver
     for the Sparkfun Razor IMU 9DOF. It also provides Arduino
     firmware that runs on the Razor board, and which must be
     installed on the Razor board for the system to work. A node
     which displays the attitude (roll, pitch and yaw) of the Razor board 
     (or any IMU) is provided for testing.""sketchbook""""Arduino""Razor_AHRS""USER SETUP AREA""""HARDWARE OPTIONS""""Tools""""Board""""Arduino Pro or Pro Mini (3.3v, 8mhz) w/ATmega328""""Tools""""Serial Port""""File""""Upload to I/O Board""""Done uploading""""Tools""""Serial Monitor""""rostopic list""/imu""rostopic echo /imu""$(find razor_imu_9dof)/src/Razor_AHRS/Razor_AHRS.ino""USER SETUP AREA""""SENSOR CALIBRATION""#oc#oc#oc#ocRazor_AHRS.ino#oc#on#ocRazor_AHRS.ino$(find razor_imu_9dof)/magnetometer_calibration/Processing/Magnetometer_calibrationMagnetometer_calibration.pdeSPACE""USER SETUP AREA""""SENSOR CALIBRATION""magnetom.float$(find razor_imu_9dof)/magnetometer_calibration/Matlab/magnetometer_calibrationmagnetometer_calibration.m$rosmake razor_imu_9dofsudo apt-get install python-visual$ cd catkin_ws/src
$ git clone https://github.com/KristofRobot/razor_imu_9dof.git
$ cd ..
$ catkin_make$ sudo apt-get install ros-indigo-razor-imu-9dof$ roscd razor_imu_9dof
$ cp -r src/Razor_AHRS ~/Arduino$ roscd razor_imu_9dof/config
$ cp razor.yaml my_razor.yaml$ roslaunch razor_imu_9dof razor-pub-and-display.launch$ roslaunch razor_imu_9dof razor-pub.launch        #YPR=-155.73,-76.48,-129.51        accel x,y,z (min/max) = -5.00/-1.00  25.00/29.00  225.00/232.00gyro x,y,z (current/average) = -29.00/-27.98  102.00/100.51  -5.00/-5.85"
W1549,https://wiki.ros.org/rb1_base_control,Wiki,rb1_base_control,"The rb1_base_control package
"
W1550,https://wiki.ros.org/segbot_firmware,Wiki,segbot_firmware,"Arduino firmware for BWI segbot sensor array.

Select  followed by the desired firmware version. Then, click the  icon to compile the microcode and load it into the controller. When the firmware is loaded, start  and run the ROS device driver: File > Sketchbook > Libraries->roscore$ sudo apt-get install arduino
$ mkdir ~/sketchbook 
$ cd ~/sketchbook
$ ln -s $(rospack find segbot_firmware)/src/libraries .$ arduino$ rosrun segbot_sensors sensor_ranges_driver$ rostopic echo /sensor_ranges"
W1551,https://wiki.ros.org/mir_robot,Wiki,mir_robot,"URDF description, Gazebo simulation, navigation, bringup launch files, message and action descriptions for the MiR100 robot.

Use GitHub to . []
  "
W1552,https://wiki.ros.org/rb1_base_common,Wiki,rb1_base_common,"The rb1_base_common package. It contains rb1 base common packages used for robot control and for simulation
 


This package contains the different controllers and launch files for the , shared for real robot and simulation.  This package contains the node that subscribes to /joy messages and publishes command messages for the robot platform including speed level control. The joystick output is feed to a mux () so that the final command to the robot can be set by different components (move_base, etc.) "
W1553,https://wiki.ros.org/libccd,Wiki,libccd,libccd is library for collision detection between two convex shapes.
W1554,https://wiki.ros.org/tuw_multi_robot_ctrl,Wiki,tuw_multi_robot_ctrl,"A simple multi robot controller using Routes as input, which are used to execute the path synchronized.


  ()  ()  () 
  ()   () 
 ( default: ""[robot_0]"")  ( default: """")  ( default: ""[]"")  ( default: ""0.3"")  ( default: ""cmd_vel"")  ( default: ""route"")  ( default: ""ctrl"")  ( default: ""0.8"")  ( default: ""1.0"")  ( default: ""0.2"")  ( default: ""5.0"")  ( default: ""1.0"")  ( default: ""0.0"") 
Use GitHub to . []
  This package provides a simple multi robot controller to follow a route. It contains a node which controls all robots at once for performance reasons with a high number of robots (> 100). This node receives route messages from the . It provides control input for all robots to move on their routes in a synchronized fashion. tuw_multi_robot_router[robot_name]/pathtuw_multi_robot_msgs/Routerobot_infotuw_multi_robot_msgs/RobotInfo[robot_name]/ctrlstd_msgs/string[robot_name]/cmdVelgeometry_msgs/Twistrobot_infotuw_multi_robot_msgs/RobotInfo~robot_namesstring[]~robot_names_strstring~robot_radiusfloat[]~robot_default_radiusfloat~cmd_vel_topicstring~route_topicstring~topic_ctrlstring~max_vfloat~max_wfloat~goal_radiusfloat~Kpfloat~Kdfloat~Kifloat"
W1555,https://wiki.ros.org/navigation_layers,Wiki,navigation_layers,Extra navigation layers.
W1556,https://wiki.ros.org/pepper_sensors_py,Wiki,pepper_sensors_py,"The pepper_sensors package








Wraps the camera node from  Starts two sonar nodes (from ) to get the data from the front and the back sonar ~pepper/laser/shovel/scan~pepper/laser/ground_left/scan~pepper/laser/ground_right/scan~pepper/laser/srd_front/scan~pepper/laser/srd_left/scan~pepper/laser/srd_right/scan~pepper/laser/shovel/pointcloud~pepper/laser/ground_left/pointcloud~pepper/laser/ground_right/pointcloud~pepper/laser/srd_front/pointcloud~pepper/laser/srd_left/pointcloud~pepper/laser/srd_right/pointcloudpointcloudbooleanlaserscanboolean"
W1557,https://wiki.ros.org/ainstein_radar_tools,Wiki,ainstein_radar_tools,"Tools for monitoring and validating radar data.


radar_topiccamera_topic~image_out~use_snr_alphaboolean<RADAR FRAME><CAMERA FRAME>"
W1558,https://wiki.ros.org/khi_robot_msgs,Wiki,khi_robot_msgs,This package contains KHI ROS robot msgs
W1559,https://wiki.ros.org/segbot,Wiki,segbot,"ROS drivers for controlling Segway RMP 50 based robots at Learning Agents 
    Research Group (LARG), AI Laboratory, Department of Computer Science, 
    The University of Texas at Austin.

Use GitHub to . []
  "
W1560,https://wiki.ros.org/ainstein_radar,Wiki,ainstein_radar,"ROS support for Ainstein radar sensors.

Basic ROS support for  radars as well as simulation, visualization and processing tools and utilities for working with generic radar data. "
W1561,https://wiki.ros.org/pr2_robot,Wiki,pr2_robot,"This stack collects PR2-specific components that are used in bringing up
  a robot.



The user's interface to the  stack is , which provides launch files that can be used to bring up a robot.  The other packages in this stack are used during the bringup process, and are not usually accessed directly by users. Check out the  that guide you through all the steps for running the PR2. Go to . Report new issues on  pr2_robot source /opt/ros/DISTRO/setup.bash
 roslaunch /etc/ros/DISTRO/robot.launch"
W1562,https://wiki.ros.org/pr2_kinematics,Wiki,pr2_kinematics,"The pr2_kinematics package


  To learn how to use the kinematics nodes for the PR2 through a ROS API, check out . "
W1563,https://wiki.ros.org/rotors_comm,Wiki,rotors_comm,"RotorS specific messages and services.
"
W1564,https://wiki.ros.org/kurt_description,Wiki,kurt_description,"

     This package contains URDF descriptions of the KURT robots. The complete
     robots are available in the directory ""robots/"". Each robot consists of
     a base and a top (see those two directories). Usually, a top is made up
     from several parts (see directory ""parts/""), such as a laser scanner.

  "
W1565,https://wiki.ros.org/micros_swarm_framework,Wiki,micros_swarm_framework,"This is a programming framework to facilitate application development involving robot swarms. It makes coding for swarms much easier by providing an adequate swarm-level abstraction, as well as tools for swarm management, various communication mechanisms and so on. It also provides essential data structures, such as Neighbor, Swarm, and Virtual Stigmergy, to the user. Most importantly, it is completely compatible with ROS Indigo and presented in the form of a C++ library, which means that all resources in the ROS ecosystem are still available to the user. It is currently  extensible to Opensplice DDS.


 

 
 
 





































 note: we could define  structure using the simple type, for example int, float, string. For the user-defined data-type, we need to use the Macro definition defined in the micros_swarm_framework to serialize in order to store and transport data of this type. We provided two Macro definition:BOOST_SERIALIZE, MEMBER: mkdir -p catkin_ws/src
cd catkin_ws/src
catkin_init_workspace
git clone https://github.com/xuefengchang/micros_swarm_framework.git
cd ..
catkin_make -j1
source devel/setup.bashSwarm s = Swarm(1);  //create a swarm s with id 1Swarm s = Swarm(1);  //create a swarm s with id 1
int id=s.id();Swarm s = Swarm(1);  //create a swarm s with id 1
std::set<int> m=s.members();s.join();  //join in the swarm ss.leave();  //leave the swarm sbool checkID(unsigned int id)
{
    if(id%2==0)
        return true;
    return false;
}

/*
 *you might need to learn the bind and function in boost libarary.
 */
boost::function<bool()> bf=boost::bind(&checkID, self_id);

s.select(bf);  //the robot whose id is even join in the swarm sbool checkID(unsigned int id)
{
    if(id%2==0)
        return true;
    return false;
}

boost::function<bool()> bf=boost::bind(&checkID, self_id);

s.unselect(bf);  //the robot whose id is even leave the swarm svoid printID(unsigned int id)
{
    std::cout<<""id=""<<id<<std::endl;
}

boost::function<void()> f = boost::bind(&printID, self_id);

s.execute(f);  //the robot in the swarm s print the id of themselvesvoid printID(unsigned int id)
{
    std::cout<<""id=""<<id<<std::endl;
}

boost::function<void()> f = boost::bind(&printID, self_id);

s.execute(f);  //the robot in the swarm s print the id of themselvesSwarm s = Swarm(1);
s.breakup();  //break up an existing swarmSwarm a = Swarm(1);
Swarm b = Swarm(2);
Swarm c = a.intersection(b, 3);  //intersect swarm a and swarm b, generating a new swarm c with id 3Swarm a = Swarm(1);
Swarm b = Swarm(2);
Swarm c = a.swarm_union(b, 3);  //union swarm a and swarm b, generating a new swarm c with id 3Swarm a = Swarm(1);
Swarm b = Swarm(2);
Swarm c = a.difference(b, 3);  //swarm a difference with swarm b, generating a new swarm c with id 3Swarm a = Swarm(1);
Swarm b = a.negation(2);  //negate swarm a, generating a new swarm b with id 2Neighbors<NeighborBase> n;  //NeighborBase typeNeighbors<int> n1;  //int
Neighbors<float> n2;  //float
Neighbors<string> n3;  //string
Neighbors<Type> n4;  //user-defined typeNeighbors<int> n;

void testforeach(int a)
{
    std::cout<<""testforeach.""<<std::endl;
}

n.foreach(testforeach);

//If using class member functions
class TestForeach{
    public:
        void testforeach(int a)
        {
            std::cout<<""testforeach.""<<std::endl;
        }
}

TestForeach tf;

boost::function<void(int)> bf_testforeach=boost::bind(&TestForeach::testforeach, tf, _1);
n.foreach(bf_testforeach);Neighbors<int> n;

float testmap(int a)
{
    return a+3.14;
}

Neighbors<float> b = n.map(testmap);

//If using class member functions
class TestMap{
    public:
        float testmap(int a)
        {
            return a+3.14;
        }
}

TestMap tm;

boost::function<float(int)> bf_testmap=boost::bind(&TestMap::testmap, tm, _1);
n.map(bf_testmap);Neighbors<int> n;

float testreduce(int a, float& b)
{
    b=b+a*2;
    return b;
}

float t2=0;

t2 = n.reduce(testreduce, t2);

//If using class member functions
class TestReduce{
    public:
        float testreduce(int a, float &b)
        {
            b=b+a*2;
            return b;
        }
}

TestReduce tr;

boost::function<float(int,float&)> bf_testreduce=boost::bind(&TestReduce::testreduce, tr, _1, _2);
n.reduce(bf_testreduce);Neighbors<NeighborBase> n;

bool testfilter(int a, NeighborBase b)
{
    if(b.getX()>=5)
        return true;
    return false;
}

Neighbors<NeighborBase> c = n.filter(testfilter);

//If using class member functions
class TestFilter{
    public:
        bool testfilter(int a, NeighborBase b)
        {
            if(b.getX()>=5)
                return true;
            return false;
        }
}

TestFilter tf;

boost::function<bool(int, NeighborBase)> bf_testfilter=boost::bind(&TestFilter::testfilter, tf, _1, _2);
n.filter(bf_testfilter);Neighbors<float> n;
Neighbors<float> c=n.kin(1);  //the memeber of the neighbors n which belong to the swarm with id 1 at the same time form a new neighbors cNeighbors<float> n;
Neighbors<float> c=n.nonkin(1);  //the memeber of the neighbors n which don't belong to the swarm with id 1 form a new neighbors cVirtualStigmergy<float> v(1);  //data type is float，id is 1v.put(""test"", 3.14);  //put <""test"", 3.14> into the VirtualStigmergy vv.get(""test"");  //query the value with the key ""test"" of the VirtualStigmergy vv.size();class TestVstigDataType{
        private:
            int a_;
            float b_;
            std::string c_;

            BOOST_SERIALIZE
            {
                MEMBER a_;
                MEMBER b_;
                MEMBER c_;
            }

        public:
            TestVstigDataType(){}
            TestVstigDataType(int a, float b, std::string c)
            {
                a_=a;
                b_=b;
                c_=c;
            }

            void printTestVstigDataType()
            {
                std::cout<<""a_ = ""<<a_<<std::endl;
                std::cout<<""b_ = ""<<b_<<std::endl;
                std::cout<<""c_ = ""<<c_<<std::endl;
            }
};roslaunch micros_swarm_stage swarm_in_stage.launchroslaunch micros_swarm_stage daemon_node.launchroslaunch micros_swarm_stage app1.launchroslaunch micros_swarm_stage swarm_in_stage.launchroslaunch micros_swarm_stage daemon_node.launchroslaunch micros_swarm_stage app2.launchroslaunch micros_swarm_stage swarm_in_stage2.launchroslaunch micros_swarm_stage daemon_node.launchroslaunch micros_swarm_stage app3.launch"
W1566,https://wiki.ros.org/agvs_description,Wiki,agvs_description,"The agvs_description package. Robot description. Urdf and mesh files.
"
W1567,https://wiki.ros.org/khi_rs_ikfast_plugin,Wiki,khi_rs_ikfast_plugin,The khi_rs_ikfast_plugin package
W1568,https://wiki.ros.org/moveit_full_pr2,Wiki,moveit_full_pr2,"All MoveIt components, plugins and PR2-specific plugins"
W1569,https://wiki.ros.org/maggie_base,Wiki,maggie_base,"base node





This device supports all the drivers implemented in the  package. cmd_velodom $ roslaunch maggie_base base.launch robot:=maggie $ rostopic echo /maggie/odom"
W1570,https://wiki.ros.org/pr2_teleop_general,Wiki,pr2_teleop_general,"pr2_teleop_general

 


 
 


 









 (, default: ) 
 (, default: ) Note: This package originated as  and wasn't released before . The base control is accessible by pushing the top left front button.  Base and torso controls are essentially the same as that described in .  pr2_teleop_boothcontrol_bodyBooleantruecontrol_headBooleantruecontrol_rarmBooleantruecontrol_larmBooleantruecontrol_prosilicaBooleantruearm_controller_namestring""arm_controller""arm_controller_namestring""arm_controller""prosilica_namespacestring""prosilica_polled""roslaunch pr2_teleop_general pr2_teleop_general_joystick.launchroslaunch pr2_teleop_general pr2_teleop_general_joystick_noik.launchroslaunch pr2_teleop_general pr2_teleop_general_joystick_bodyhead_only.launch roslaunch pr2_teleop_general pr2_teleop_general_keyboard.launchroslaunch pr2_teleop_general pr2_teleop_general_keyboard_noik.launchroslaunch pr2_teleop_general pr2_teleop_general_keyboard_bodyhead_only.launch"
W1571,https://wiki.ros.org/predicate_manager,Wiki,predicate_manager,Predicate Manager is a ROS library to define and manage logical predicates and events.
W1572,https://wiki.ros.org/pr2_app_manager,Wiki,pr2_app_manager,"Scripts and tools for running the application manager on the PR2.

If you have the old version, you will be asked if you want to set up your SSH keys.  Answer ""Y"" for yes.  You should see a random ASCII art square.  Then type  to log back out of the ""applications"" user account. If you have the new version, you will not be asked anything, you will just get a regular shell prompt.  Type  to log out of the ""applications"" account. The QR codes for the PR2s are specified with a variety of attributes stored in YAML to help connect to them. They are generated using . To create the QR codes, use the ""Text"" mode, type in the text (examples below) and click generate. When you are finished, you can right click and save or print the QR code image. To avoid the hassle of printing, many devices can read the QR code directly off of your PC screen. exitexitsudo apt-get update
sudo apt-get install ros-electric-pr2-apps ros-electric-wg-common ros-electric-multimaster-experimental ros-electric-pr2-props-stacksudo userdel applications
sudo groupdel applications
sudo rm -rf /u/applications
sudo rm -rf /home/applicationsroscd pr2_app_manager/scripts/
sudo ./install_applications.shEnter the robot name (e.g. pri):sudo su applicationsrobot claim
robot start
roslaunch pr2_app_manager pr2_app_manager.launchURL: http://pri1:11311/
CURL: http://pri1/cgi-bin/control.py
WIFI: priLANWIFIPW: <then the wifi password>"
W1573,https://wiki.ros.org/keyboard,Wiki,keyboard,"publishes keyboard key presses

 keydownkeyup~allow_repeatbool~repeat_delayint~repeat_intervalint"
W1574,https://wiki.ros.org/ros_comm,Wiki,ros_comm,"ROS communications-related packages, including core client libraries (roscpp, rospy) and graph introspection tools (rostopic, rosnode, rosservice, rosparam).


Use GitHub to . Please use 'ros_comm:' at the beginning of the title. []
 The  stack contains the ROS middleware/communications packages. These packages are collectively known as the ROS ""Graph"" layer. They provide implementations and tools for , , , and . This includes the supported ROS client libraries: , , and . C Turtle has an empty version of the  stack. This is provided so that stacks may update their dependencies for Diamondback but not break dependency compatibility with a C Turtle release. ros_comm developers only:  ros_commros_comm"
W1575,https://wiki.ros.org/rotate_recovery,Wiki,rotate_recovery,"This package provides a recovery behavior for the navigation stack that attempts to clear space by performing a 360 degree rotation of the robot.




 (, default: 0.017) 
 (, default: 0.05) 
The  is a simple recovery behavior that attempts to clear out space in the navigation stack's  by rotating the robot 360 degrees if local obstacles allow. It adheres to the  interface found in the  package and can be used as a recovery behavior  for the  node. The  object exposes its functionality as a . It operates within a ROS namespace (assumed to be  from here on) specified on initialization. It adheres to the  interface found in the  package. Example creation of a  object: The  object assumes that the local planner used by the  node is the  documented in the  package and reads some of its parameters accordingly. It will work on its own, but this requires the user to specify additional parameters. These parameters are already set when using the  local planner, they only need to be set explicitly for the  recovery behavior if a different local planne is used with the . The C++  class adheres to the  interface found in the  package. For detailed documentation, please see . rotate_recovery::RotateRecoverynav_core::RecoveryBehaviorrotate_recovery::RotateRecoverynav_core::RecoveryBehaviorrotate_recovery::RotateRecoveryrotate_recovery::RotateRecoverybase_local_planner::TrajectoryPlannerROS~<name>/sim_granularitydouble~<name>/frequencydoublebase_local_planner::TrajectoryPlannerROSrotate_recovery::RotateRecovery~TrajectoryPlannerROS/yaw_goal_tolerancedouble~TrajectoryPlannerROS/acc_lim_thdouble~TrajectoryPlannerROS/max_rotational_veldouble~TrajectoryPlannerROS/min_in_place_rotational_veldoublerotate_recovery::RotateRecoverynav_core::RecoveryBehavior












"
W1576,https://wiki.ros.org/velodyne_description,Wiki,velodyne_description,URDF and meshes describing Velodyne laser scanners.Documentation at  
W1577,https://wiki.ros.org/rqt_robot_dashboard,Wiki,rqt_robot_dashboard,"rqt_robot_dashboard provides an infrastructure for building robot dashboard plugins in rqt.
Check out the  for more information. "
W1578,https://wiki.ros.org/nodelet_topic_tools,Wiki,nodelet_topic_tools,"This package contains common nodelet tools such as a mux, demux and throttle.
 represent a mux nodelet for topics: it takes N (<=8) input topics, and publishes all of them on one output topic. One implementation of  can be found in . 
 represent a demux nodelet for topics: it takes 1 input topic, and publishes on N (<=8) output topics. One implementation of  can be found in . 
  can throttle a topic in a nodelet to a specified rate. Note that this tool is in the  namespace. The  package contains a MUX () and a DEMUX () nodelet.  The above accepts data from  and , and republishes it on . To compile the  nodelet in your library, add something like: (replace  with the message type of choice). The above accepts data from , and republishes it on  and . To compile the  nodelet in your library, add something like: (replace  with the message type of choice). To compile the  nodelet in your library, add something like: (replace  with the message type of choice). nodelet_topic_toolsNodeletMUXNodeletDEMUXNodeletMUXNodeletMUX/passthrough/output/normal_estimation/output/data_mux/outputNodeletMUXsensor_msgs::PointCloud2NodeletDEMUXNodeletDEMUX/data_demux/input/data_demux/output1/data_demux/output2NodeletDEMUXsensor_msgs::PointCloud2NodeletThrottlenodelet_topic_toolsNodeletThrottlesensor_msgs::Image





























"
W1579,https://wiki.ros.org/abb_irb2400_support,Wiki,abb_irb2400_support,"
      ROS-Industrial support for the ABB IRB 2400 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 2400 manipulators. This currently includes the base model.
    
      Joint limits and max joint velocities are based on the information in
      the ABB data sheets.  All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      The unqualified IRB 2400 model will be removed in ROS-Lunar, please
      use the IRB 2400-12/1.55 as a replacement.
    "
W1580,https://wiki.ros.org/kvh_geo_fog_3d,Wiki,kvh_geo_fog_3d,"Provides a driver node for KVH GEO FOG 3D INS sensors, messages, and rviz plugins.
 ROS package for the  set of GNSS/INS sensors. "
W1581,https://wiki.ros.org/rotors_evaluation,Wiki,rotors_evaluation,The dataset evaluation package for the RotorS simulator.
W1582,https://wiki.ros.org/industrial_deprecated,Wiki,industrial_deprecated,"The Industrial deprecated package contains nodes, launch files, etc... that are slated for 
  deprecation.  This package is the last place something will end up before being deleted.  
  If you are missing a package/node and find it's contents here, then you should consider 
  a replacement.
This package is part of the  program.  "
W1583,https://wiki.ros.org/s3000_laser,Wiki,s3000_laser,"The s3000_laser package

 

s3000_laser/scan~portstring~frame_idstring~baud_rateint~serial_paritystring~serial_datasizeint~range_minfloat~range_maxfloat"
W1584,https://wiki.ros.org/roscpp,Wiki,roscpp,"roscpp is a C++ implementation of ROS. It provides
    a  that enables C++ programmers to quickly interface with
    ROS ,
    ,
    and .

    roscpp is the most widely used ROS client library and is designed to
    be the high-performance library for ROS.




Please refer to the  package For usage documentation and more in-depth treatment than the tutorials, please see the  For a detailed API reference, please consult the  "
W1585,https://wiki.ros.org/kobuki_keyop,Wiki,kobuki_keyop,Keyboard teleoperation for Kobuki: relays commands from a keyboard to Kobuki. 
W1586,https://wiki.ros.org/pepper_robot,Wiki,pepper_robot,The pepper_robot package
W1587,https://wiki.ros.org/pr2_run_stop_auto_restart,Wiki,pr2_run_stop_auto_restart,"This package provides a node that monitors the state of the run stops of the pr2_robot. When the state of the
   run stop changes from off to on, this node will automatically enable the power to the motors, and reset
   the motors. This allows you to use the run stop as a 'pause' button. By using the run stop as a tool to
   power up the robot, the run stop is also in reach of the user once the robot starts moving.

run_stop_auto_restartpower_board/statepower_board/controlpr2_etherCAT/reset_motors"
W1588,https://wiki.ros.org/ros_ethercat,Wiki,ros_ethercat,A pr2 agnostic replacement for robots using EtherCAT
W1589,https://wiki.ros.org/motoman_sia20d_moveit_config,Wiki,motoman_sia20d_moveit_config,"MoveIt package for the Motoman SIA20D.
      An automatically generated package with all the configuration and launch files for using the Motoman SIA20D with the MoveIt Motion Planning Framework.
    
This package is part of the  program.  "
W1590,https://wiki.ros.org/nao_interaction_launchers,Wiki,nao_interaction_launchers,Launchers for bringing up the nodes of nao_interaction metapackage.
W1591,https://wiki.ros.org/motoman_mh5_support,Wiki,motoman_mh5_support,"ROS-Industrial support for the Motoman MH5 (and variants).
      This package contains configuration data, 3D models and launch files
      for Motoman MH5 manipulators.
    
      
    
      Joint limits and maximum joint velocities are based on the information 
      found in the online 
      http://www.motoman.com/datasheets/mh5.pdf
      All urdfs are based on the default motion and joint velocity limits, 
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1592,https://wiki.ros.org/pr2_bringup,Wiki,pr2_bringup,"Launch files and scripts needed to bring a PR2 up into a running state. is a package that collects together the scripts,  files, and dependencies that are required to bring a PR2 robot into a running state. 


  
The user's entry point for this package is the file .  This launch file contains all nodes to run a complete PR2 system. However, you cannot use pr2.launch to start up the robot (see  for instructions), because pr2.launch requires another launch file to load the robot description and robot analyzer on the parameter server first. To disable the  set the ""no-prosilica"" arg to ""true"" in ""/etc/ros/robot.launch"" when launching your PR2: This manual will take you step by step through starting the PR2 robot, . Note: If you have a PR2 that is running both ROS Groovy and ROS Hydro, this is then the start sequence: When the PR2 starts up for the first time since a power down, it will move its arms, casters, head and later platform to find the reference position of each joint.  This is done by the calibration script . When finished, the PR2 joint calibration script stores the joint reference positions locally in the motor controller board (MCB) of the corresponding joint.  So the next time you start the PR2, it will remember the reference positions and won't have to repeat the same calibration routine over and over again. pr2_bringuppr2.launchpr2_bringup/scripts/calibrate_pr2.py<launch>
  <arg name=""no-prosilica"" value=""true"" />
  <include file=""$(find pr2_bringup)/pr2.launch"" />

  <!-- Other stuff -->
</launch>robot groovyexport ROS_ENV_LOADER=/etc/ros/env.shroslaunch /etc/ros/robot.launchrobot hydroexport ROS_ENV_LOADER=/etc/ros/env.shroslaunch /etc/ros/robot.launchrobot start"
W1593,https://wiki.ros.org/qb_device_utils,Wiki,qb_device_utils,This package contains a device-independent utility functions for qbrobotics® devices.This package contains a device-independent utility functions for  devices. 
W1594,https://wiki.ros.org/uav_simple_tracking,Wiki,uav_simple_tracking,"A package that tracks a target with an unmanned aerial vehicle (UAV).

 (, default: 1)  (, default: ) 


to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. uav_simple_trackingidintegeroutputstringscreenscreenlogparamuav_simple_tracking.yamluav_simple_trackinguav_simple_trackinguav_tracking/goaltarget_updatetarget_losttarget_done~loop_ratereal~queue_sizeintegerroslaunch uav_simple_tracking uav_simple_tracking.launch"
W1595,https://wiki.ros.org/roslisp_repl,Wiki,roslisp_repl,"This package provides a script that launches Emacs with Slime (the
    Superior Lisp Interaction Mode) ready for Lisp development and
    roslisp.


 is distributed through the ROS release infrastructure. 

This package provides you with a Lisp REPL configured to be used to program ROS packages as well as an integrated IDE for programming in Common Lisp with Emacs (see ). The most up-to-date version of  code can be found . Installation instructions are in the README file. What you'll need to do will be something like the following: To use the  just run the executable: If you're on earlier versions of ROS, look through the  configuration file,  and copy-paste the relevant code into your Emacs config file. roslisp_replroslisp_replroslisp_replroslisp_replroslisp_replroslisp_replrepl-config.el$ sudo apt-get install ros-DISTRO-roslisp-repl$ cd YOUR_CATKIN_WS/src
$ wstool set ros_emacs_utils --git https://github.com/code-iai/ros_emacs_utils.git
$ wstool update ros_emacs_utils
$ cd ..
$ catkin_make
$ catkin_make install
$ emacs -nw ~/.emacs.d/init.el # edit your emacs configuration file$ roslisp_repl$ source ~/.bashrc
$ rospack profile
$ rosrun roslisp_repl roslisp_repl"
W1596,https://wiki.ros.org/rb1_common,Wiki,rb1_common,The rb1_common package. It contains rb1 mobile manipulator common packages
W1597,https://wiki.ros.org/planner_msgs,Wiki,planner_msgs,"The planner_msgs package. Messages and actions for planning the autonomous movement of the robot.
"
W1598,https://wiki.ros.org/qt_paramedit,Wiki,qt_paramedit,"A GUI application for viewing and editing ROS parameters.

 Note: This package replaces groovy's  in hydro. rosrun qt_paramedit qt_paramedit [parameter root] (default: /)"
W1599,https://wiki.ros.org/rqt_pr2_dashboard,Wiki,rqt_pr2_dashboard,"rqt_pr2_dashboard is a GUI for debugging and controlling low-level state of the PR2.  It shows things like battery status and breaker states, as well as integrating tools like rqt_console and robot_monitor.
A successor of  with enhancements based on  framework. (see  for more installation details) rqt$ sudo apt-get install ros-%YOUR_ROS_DISTRO%-rqt-pr2-dashboard
$ sudo apt-get install ros-groovy-rqt-pr2-dashboard   (an example in Groovy)$ rosdep update
$ rosdep install rqt_pr2_dashboard"
W1600,https://wiki.ros.org/phantomx_reactor_arm_description,Wiki,phantomx_reactor_arm_description,The phantomx_reactor_arm_description package
W1601,https://wiki.ros.org/pepper_control,Wiki,pepper_control,Control for Pepper robotIs used within  and  packages  
W1602,https://wiki.ros.org/nao_interaction,Wiki,nao_interaction,"Metapackage for the Nao robot, providing access to: - NAOqi audio proxies - NAOqi vision proxies"
W1603,https://wiki.ros.org/mir_gazebo,Wiki,mir_gazebo,Simulation specific launch and configuration files for the MiR100 robot.
W1604,https://wiki.ros.org/kuka_experimental,Wiki,kuka_experimental,"Experimental packages for KUKA manipulators within ROS-Industrial.: This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status .





Use GitHub to . []
 This repository is part of the  program. It contains experimental packages that will be moved to the  repository once they've received sufficient testing and review. Refer to the  for more information. For the generic ROS-Industrial tutorials, please see the ROS-Industrial . For questions related to the KUKA support or ROS-Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. 











"
W1605,https://wiki.ros.org/libphidget21,Wiki,libphidget21,This package wraps the libphidget21 to use it as a ROS dependency
W1606,https://wiki.ros.org/pr2_controller_configuration_gazebo,Wiki,pr2_controller_configuration_gazebo,"A copy of the pr2_controller_configuration package, for use in 
    the PR2 simulator.  We maintain two copies to allow for controller
    gains to be set differently between hardware and simulation.Please see  for details of all the configuration and launch scripts. "
W1607,https://wiki.ros.org/mir_actions,Wiki,mir_actions,Action definitions for the MiR100 robot
W1608,https://wiki.ros.org/dbw_pacifica_msgs,Wiki,dbw_pacifica_msgs,Drive-by-wire messages for the Chrysler Pacifica
W1609,https://wiki.ros.org/kuka_kr120_support,Wiki,kuka_kr120_support,"
      ROS-Industrial support for the KUKA KR 120 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 120 manipulators. This currently includes the R2500 PRO
      (KR QUANTEC PRO) only.
    :
      Joint limits and maximum joint velocities are based on the information
      found in the online
      http://www.kuka-robotics.com/res/sps/e6c77545-9030-49b1-93f5-4d17c92173aa_Spez_KR_QUANTEC_pro_en.pdf.
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1610,https://wiki.ros.org/marti_common_msgs,Wiki,marti_common_msgs,marti_common_msgs
W1611,https://wiki.ros.org/map_merge_3d,Wiki,map_merge_3d,"Merging multiple 3D maps, represented as pointclouds,
  without knowledge of initial positions of robots.Use GitHub to . []
 
 
 finds robot maps automatically and new robots can be added to the system at any time. 3D maps are expected as , other map messages are not supported.  








The ROS node can merge maps from the arbitrary number of robots. It expects maps from individual robots as ROS topics and does not impose any particular messaging between robots. If your run multiple robots under the same ROS master then  may work for you out-of-the-box, this makes it easy to setup a simulation experiment. In the multi-robot exploration scenario your robots probably run multiple ROS masters and you need to setup a communication link between robots. Common solution might be . You need to provide maps from your robots on local topics (under the same master). Also if you want to distribute merged map and  transformations back to robots your communication must take care of it. Recommended topics names for robot maps are ,  etc. However the names are configurable. All robots are expected to publish map under , where topic name () is configurable, but must be the same for all robots. For each robot  is of cause different, but it does not need to follow any pattern. Further, you can exclude some topics using  parameter, to avoid merging unrelated point clouds. Estimating transforms between maps is cpu-intesive so you might want to tune  parameter to run the re-estimation less often. Alongside ROS node  provides command-line tools to work with point cloud maps saved in  files. Both tools accept any of the . The tools use PCL command-line parsing module. PCL command-line parsing has some limits (PCL users won't be surprised): it supports only  format,  is not accepted. Unknown options are ignored. Options may be arbitrarily mixed with filenames. There are no short versions for parameters. Tool for merging maps offline. Produces  with merged global map. This tool can merge arbitrary number of maps. After one step of the estimation a visualisation window appears. You can freely navigate the point cloud, save a screenshot or camera parameters (press  to see all shortcuts). After the window is closed, estimation continues with the next phase and the next visualisation window appears. Details about estimation progress are printed to . This package was developed as part of my master thesis at  in Prague. map_merge_3dmap_merge_3d/robot1/map/robot2/map<robot_namespace>/mapmap<robot_namespace>robot_namespaceestimation_rate<robot_namespace>/mapmap~robot_map_topicstringmap~robot_namespacestring<empty string>robot_map_topicrobot_namespace~merged_map_topicstringmap~world_framestringworld~compositing_ratedouble0.3~discovery_ratedouble0.05~estimation_ratedouble0.01~publish_tfbooltrue~resolutiondouble0.1~descriptor_radiusdoubleresolution * 8.0~outliers_min_neighboursint50~normal_radiusdoubleresolution * 6.0~keypoint_typestringSIFTSIFTHARRIS~keypoint_thresholddouble5.00.0~descriptor_typestringPFHPFHPFHRGBFPFHRSDSHOTSC3D~estimation_methodstringMATCHINGMATCHINGSAC_IA~refine_transformbooltrue~inlier_thresholddoubleresolution * 5.0~max_correspondence_distancedoubleinlier_threshold * 2.0~max_iterationsint500~matching_kint5~transform_epsilondouble1e-2~confidence_thresholddouble0.0~output_resolutiondouble0.05worldmapX_frameworld_frameframe_idmapX_framemap_merge_3dpcd--param value--param=valueoutput.pcdhstdoutrosrun map_merge_3d map_merge_tool [--param value] map1.pcd map2.pcd [map3.pcd...]rosrun map_merge_3d map_merge_tool --descriptor_type SHOT map1.pcd map2.pcd map3.pcdrosrun map_merge_3d registration_visualisation [--param value] map1.pcd map2.pcd"
W1612,https://wiki.ros.org/um6,Wiki,um6,"The um6 package provides a C++ implementation of the CH Robotics serial protocol, and a
    corresponding ROS node for publishing standard ROS orientation topics from a UM6. 



 A rosbuild branch is also available in the repository, for users working with rosbuild workspaces under Fuerte or Groovy. 

The UM6 is available for purchase . Alternatively, the UM6 is available as a standard supported accessory from Clearpath Robotics—for example, for use with . For further information about this device and its configuration, please see its . Please see  for more information. At , we use a configuration which subscribes to the magnetometer as a raw data feed, and fuses it into the orientation as a process external to the device. This functionality is provided via the  package. imu/dataimu/magimu/rpyimu/temperature~portstring~baudint~mag_updatesbool~accel_updatesbool~mag_ref/[x,y,z]float~accel_ref/[x,y,z]float~mag_bias/[x,y,z]float~accel_bias/[x,y,z]float~gyro_bias/[x,y,z]floatsudo apt-get install ros-$ROS_DISTRO-um6rosrun um6 um6_driver _port:=/dev/ttyUSB0"
W1613,https://wiki.ros.org/kurt_gazebo,Wiki,kurt_gazebo,"

     This package contains launch files for starting up Kurt in the Gazebo simulator.

  "
W1614,https://wiki.ros.org/uuid_msgs,Wiki,uuid_msgs,"ROS messages for universally unique identifiers.

This package defines a ROS message for a , as described in . "
W1615,https://wiki.ros.org/moveit_simple_grasps,Wiki,moveit_simple_grasps,"A basic grasp generator for simple objects such as blocks or cylinders for use with the MoveIt! pick and place pipeline. 
    Does not consider friction cones or other dynamics.Extensive documentation available on  "
W1616,https://wiki.ros.org/navigation_experimental,Wiki,navigation_experimental,"A collection of navigation plugins and tools: Various recovery behaviors,
    local and global planner plugins for move_base, a teleop filter for
    obstacle avoidance, a simple control-based move_base replacement
    etc.

Use GitHub to . []
  "
W1617,https://wiki.ros.org/rosbash_params,Wiki,rosbash_params,"Tools for writing ros-node-like bash scripts











 


 This Bash env-hook adds a ""node-like"" interface to your code written in Bash. The main thing it adds is ROS-like command-line parameter parsing (), so that you can easily call the Bash script from a launch file like _param:=value_param:=value_param:=value positional_arg1 positional_arg2 _andrew:=martinpositional_arg1positional_arg2:=rosbash_param var &quot;param&quot; &quot;default&quot;trueTrueyeson1Truefalsefalsenooff0False00rospyroscorerosbash_node_name__name:=name""$@""rosbash_unused_paramsrosbash_paramrosbash_unused_argvarg_string=""${rosbash_unused_argv[@]}""_rosbash_paramsrosbash_init_noderesult_varparamdefaultexit 1return 1ROS_BASH_PARAM_EXIT01FalseTrueTrueFalse01ROS_BASH_USE_PARAM_SERVER""0""ROS_BASH_USE_PARAM_VERBOSE""0""ROS_BASH_PARAM_EXIT""0""exit 1return 1<node name=""test"" pkg=""pkg"" type=""my_bash_script.sh"">
    <param name=""par"" value=""test"" />
</node>rosbash_init_node ""node_name"" ""$@""  # parse the command line arguments

rosbash_param mandatory_param ""param_name""  # if default value is not specified, the param is mandatory
rosbash_param optional_param ""param2_name"" ""default_value"" # optional param
rosbash_param bool_param1 ""bool_name1"" # bool param without default
rosbash_param bool_param2 ""bool_name2"" ""True"" # bool param with default
rosbash_param bool_param3 ""bool_name3"" ""False"" # bool param with default

echo ""mandatory_param = ${mandatory_param}""  # access the parsed parameter value
echo ""optional_param = ${optional_param}""  # access the parsed parameter value
echo ""bool_param1 = ${bool_param1}""  # access the parsed parameter value
echo ""bool_param2 = ${bool_param2}""  # access the parsed parameter value
echo ""bool_param3 = ${bool_param3}""  # access the parsed parameter value

echo ""rosbash_unused_argv = ${rosbash_unused_argv[@]}""  # all CLI args not parsed as a parameter $ ./test_rosbash _param_name:=1 _unparsed_param:=2 positional1 positional2 _bool_name1:=False
mandatory_param = 1
optional_param = default_value
bool_param1 = False
bool_param2 = True
bool_param3 = False
rosbash_unused_argv = _unparsed_param:=2 positional1 positional2$ ./test_rosbash positional1 positional2
Required parameter 'param_name' was not set.$ ./test_rosbash  _param_name:=test _bool_name1:=1 _bool_name2:=0 _bool_name3:=on
mandatory_param = test
optional_param = default_value
bool_param1 = 1  # without default value, we cannot safely convert all `1`s to `True`
bool_param2 = False  # with default value either `True` or `False`, we can convert `1` to `True` and `0` to `False`
bool_param3 = True  # `on` without quotes is always converted to `True`
rosbash_unused_argv = <launch>
    <node name=""test"" pkg=""test_pkg"" type=""test_rosbash"">
        <param name=""param_name"" value=""test"" />
        <param name=""param2_name"" value=""optional"" />
        <param name=""bool_name1"" value=""off"" />
    </node>
</launch>ROS_BASH_PARAM_EXIT=0 rosbash_param var ""mandatory"" || echo ""Please, fill the mandatory param"""
W1618,https://wiki.ros.org/voxel_grid,Wiki,voxel_grid,"voxel_grid provides an implementation of an efficient 3D voxel grid. The occupancy grid can support 3 different representations for the state of a cell: marked, free, or unknown. Due to the underlying implementation relying on bitwise and and or integer operations, the voxel grid only supports 16 different levels per voxel column. However, this limitation yields raytracing and cell marking performance in the grid comparable to standard 2D structures making it quite fast compared to most 3D structures.
The  has no API that we're supporting officially. You should still feel free to use the code, just know that we're making no guarantees about the stability of the current API. voxel_grid"
W1619,https://wiki.ros.org/v4r_uvc,Wiki,v4r_uvc,The v4r_uvc package is a USB-Camera driver with a dynamic reconfigure interface optimized for logitech cameras.
W1620,https://wiki.ros.org/rwt_robot_monitor,Wiki,rwt_robot_monitor,The rwt_robot_monitor package
W1621,https://wiki.ros.org/nerian_sp1,Wiki,nerian_sp1,"Node for the SP1 Stereo Vision System by Nerian Vision Technologies


 
 () 
 (, default: ) 
 
  The  by Nerian Vision Technologies is a stand-alone processing system for performing stereo matching in real time. It is connected to two industrial USB cameras that provide input image data.  The SP1 correlates the images of both cameras and produces a disparity map, which is transmitted through gigabit ethernet. The disparity map describes a mapping of image points from the left camera image to corresponding image points in the right camera image. With this information it is possible to reconstruct the 3D location of the corresponding scene points. The data delivered by the SP1 can be received using the available open source API. Using the API directly is recommended for high performance applications. Alternatively the  ROS node can be used for publishing the received data as ROS messages. The behaviour of the node can be configured through various parameters. An example parameterization can be found in the included launch file . The following parameters are supported: The topics published by the nerian_sp1 node can be viewed with . The disparity map can also be visualized with the  node. In this case color coding should be activated such that the disparity map can be displayed on a screen. In order to do so, please launch the image_view node as follows: nerian_sp1/nerian_sp1/point_cloud/nerian_sp1/disparity_map/nerian_sp1/left_image/nerian_sp1/right_image/nerian_sp1/stereo_camera_infonerian_sp1.launch~point_cloud_intensity_channelbool""true""~ros_coordinate_systembool""true""~color_code_disparity_mapbool""false""~color_code_legendbool""true""~framestring""world""~remote_hoststring""0.0.0.0""~remote_portstring""7681""~local_hoststring""0.0.0.0""~local_portstring""7681""~use_tcpbool""false""~calibration_filestring""""~delay_executiondouble0~max_depthdouble-1sudo apt-get update
sudo apt-get install ros-`rosversion -d`-nerian-sp1rosrun image_view image_view image:=/nerian_sp1/disparity_maprosrun image_view image_view image:=/nerian_sp1/left_image"
W1622,https://wiki.ros.org/navigation_stage,Wiki,navigation_stage,"This package holds example launch files for running the ROS navigation stack in stage.

This package holds example launch files for running the  stack in . launch/move_base_amcl_10cm.launchlaunch/move_base_amcl_5cm.launchlaunch/move_base_amcl_2.5cm.launchlaunch/move_base_fake_localization_10cm.launchlaunch/move_base_fake_localization_5cm.launchlaunch/move_base_fake_localization_2.5cm.launchlaunch/move_base_multi_robot.launchlaunch/move_base_gmapping_5cm.launch"
W1623,https://wiki.ros.org/khi_rs_gazebo,Wiki,khi_rs_gazebo,The khi_rs_gazebo package
W1624,https://wiki.ros.org/khi_rs007n_moveit_config,Wiki,khi_rs007n_moveit_config,An automatically generated package with all the configuration and launch files for using the khi_rs007n with the MoveIt! Motion Planning Framework
W1625,https://wiki.ros.org/global_planner,Wiki,global_planner,"A path planner library and node.



  Path follows the grid boundaries.  
  Slightly different calculation for the potential. Note that the original potential calculation from  is a quadratic approximation. Of what, the maintainer of this package has no idea.  
  Note that a lot less of the potential has been calculated (indicated by the colored areas). This is indeed faster than using Dijkstra's, but has the effect of not necessarily producing the same paths.  Another thing to note is that in this implementation of A*, the potentials are computed using 4-connected grid squares, while the path found by tracing the potential gradient from the goal back to the start uses the same grid in an 8-connected fashion.  Thus, the actual path found may not be fully optimal in an 8-connected sense.  (Also, no visited-state set is tracked while computing potentials, as in a more typical A* implementation, because such is unnecessary for 4-connected grids).  To see the differences between the behavior of Dijkstra's and the behavior of A*, consider the following example.  
 
 
 For reproducing paths just like  did.   


This package provides an implementation of a fast, interpolated global planner for navigation. This class adheres to the  interface specified in the  package. It was built as a more flexible replacement to , which in turn is based on .  The orientation of point i is calculated using the positions of  and `i + orientation_window_size`. The window size can be altered to smoothen the orientation calculation. nav_core::BaseGlobalPlanneruse_grid_path=Trueuse_quadratic=Falseuse_dijkstra=Falseold_navfn_behavior=TrueNone=0Forward=1Interpolate=2ForwardThenInterpolate=3Backward=4Leftward=5Rightward=6i - orientation_window_size~<name>/plan~<name>/allow_unknownbooltrue~<name>/default_tolerancedoubledefault_tolerance~<name>/visualize_potentialboolfalse~<name>/use_dijkstrabooltrue~<name>/use_quadraticbooltrue~<name>/use_grid_pathboolfalse~<name>/old_navfn_behaviorboolfalse~<name>/lethal_costint~<name>/neutral_costint~<name>/cost_factordouble~<name>/publish_potentialbool~<name>/orientation_modeintNone=0Forward=1Interpolate=2ForwardThenInterpolate=3Backward=4Leftward=5Rightward=6~<name>/orientation_window_sizeint"
W1626,https://wiki.ros.org/urdf_sim_tutorial,Wiki,urdf_sim_tutorial,The urdf_sim_tutorial package
W1627,https://wiki.ros.org/netft_utils,Wiki,netft_utils,"C++ class and ROS node for ATI force/torque sensors connected to a Netbox. Includes gravity compensation and transformations.





 This package builds on the original  package by Derek King, written in 2008 but not updated since ROS groovy. (You may have to do this every time you open a new terminal window, or add this line to your bashrc: ) Build the package The IP address should be the IP address of your sensor. You should see a steady stream of  data. The following code covers the gist of how to declare and use a netft object with C++. Do  to see it in action (you will have to adjust the IP address of the sensor in the source code, as it's hardcoded to 192.168.1.84. If the program Seg Faults immediately, you may have specified an incorrect IP address for the sensor. Follow this  to see a list of IP addresses on your network and find the right one. If the network latency increases significantly after launching the F/T sensor, it is probably pushing too much data. You can reduce its data transmission rate through the Netbox's web interface. Simply navigate to the sensor's IP in a browser, e.g.:  Reduce the data transmission rate downward via ""RDT Output Rate."" $rosrun netft_utils netft_utils_cpp_testhttp://192.168.1.84$ mkdir -p ~/Desktop/catkin_ws/src
$ cd catkin_ws
$ catkin_make$ cd src
$ git clone https://github.com/UTNuclearRoboticsPublic/netft_utils.git
$ cd ..$ source devel/setup.bash$ catkin_make$ roscore
$ rosrun netft_utils netft_utils_sim
$ rostopic echo /netft_data$ rosrun netft_utils netft_node 192.168.1.84
$ rostopic echo /netft_data$ rosrun netft_utils netft_utils base_frame sensor_frame
$ rostopic echo /raw_world  (raw data from the sensor, no bias applied, transformed to world frame)
$ rostopic echo /transformed_tool   (if you biased the sensor, it has an effect here)
$ rostopic echo /transformed_world  (if you biased the sensor, it has an effect here)$ rosservice call /bias true 20 10$ rosrun netft_utils netft_node 192.168.1.84
$ rosrun netft_utils netft_utils base_frame ft_sensor_frame
$ rostopic echo /transformed_world
$ rosservice call /gravity_comp true 20 10  ros::init(argc, argv, ""netft_utils_cpp_test"");
  ros::NodeHandle n;
  ros::AsyncSpinner* spinner;
  spinner = new ros::AsyncSpinner(3);
  spinner->start();
  double ftSleep; // controls the data acquisition rate

  // Subscribe to the F/T topic
  ros::Subscriber ftSub = n.subscribe(""/netft/netft_data"", 1, netftCallback);

  // Connect and bias the ft sensor
  NetftUtilsLean* fti = new NetftUtilsLean(&n);
  fti->setFTAddress(""192.168.1.84"");
  // Adjust the data acquisition rate and set the World and sensor frames, respectively
  fti->initialize(1/ftSleep, ""base_link"", ""sensor_frame"");

  // Set max and min force/torque readings
  fti->setMax(80.0, 8.0, 60.0, 6.0);
  std::future<bool> ftThread;
  ftThread = std::async(std::launch::async, &NetftUtilsLean::run, fti);
  fti->biasSensor(1);  geometry_msgs::WrenchStamped wrench;
  fti->getToolData(wrench);  fti->getWorldData(wrench);"
W1628,https://wiki.ros.org/maggie_labjack_drivers,Wiki,maggie_labjack_drivers,"labjack drivers for Maggie robot

"
W1629,https://wiki.ros.org/micros_mars_task_alloc,Wiki,micros_mars_task_alloc,"This is a ROS package used for the mult-task allocation in a robot team. It is based on Multi-Agent theory and is an abstraction of ALLIANCE model. A cooperative robot team is a multi-agent robot system in essence. In the team, each robot can be seen as an intelligent agent. We have developed a prototype system by python hitherto. The nodelet-based C++ version is being developed and will be released in short time periods.

 
 



 
 
  
 The main APIs are shown below. The parameter names present the parameter function clearly. As mentioned above, each motivational behavior is responsible for activating a forwarder to forward the messges sent from the attached behavior set. So the '' class should have a parameter named 'forwarder_name' indicating that which forwarder it activates. The paramters of the topics in 'Forwarder' indicate which behavior set they attach. The experimental videos can be downloaded and watched here.  Inhibitor(inhibitor_name, topic_in, in_out_msg_type, topic_out, inhibiting_topic, inhibiting_msg_type)

suppressor(suppressor_name, topic_in, in_out_msg_type, topic_out, suppressing_topic, suppressing_msg_type)

Forwarder(forwarder_name, topic_1_in , msg_1_type, topic_1_out, topic_2_in, msg_2_type, topic_2_out)

MotivationalBehavior(motivational_behavior_name, robot_ID, behavior_set_ID, forwarder_name)git clone https://github.com/daenny/collvoid.gitgit clone https://github.com/liminglong/multi_robot_stage.gitgit clone https://github.com/liminglong/micros_mars_task_alloc.git roslaunch multi_robot_stage multi_robot.launchcd /catkin_ws/src/micros_mars_task_alloc/scripts/basic_supportpython robot0.pypython robot1.pypython robot2.pyroslaunch micros_mars_task_alloc robot3_control.launch"
W1630,https://wiki.ros.org/maggie_devices,Wiki,maggie_devices,"maggie_devices metapackage

ROS packages for the devices of the robot . "
W1631,https://wiki.ros.org/qb_hand_description,Wiki,qb_hand_description,"This package contains the ROS description for qbrobotics® qbhand device.

This package contains the description resources for the  device. It includes the / model of the hand with its simplified meshes and its configuration setup. This launch file calls the template  with the default settings to visualize a  in  (and nothing more). roslaunch qb_hand_description qb_hand.launch"
W1632,https://wiki.ros.org/twist_recovery,Wiki,twist_recovery,A recovery behavior that performs a particular used-defined twist.
W1633,https://wiki.ros.org/gmapping,Wiki,gmapping,"This package contains a ROS wrapper for OpenSlam's Gmapping. 
  The gmapping package provides laser-based SLAM (Simultaneous Localization and Mapping), 
  as a ROS node called slam_gmapping. Using slam_gmapping, you can create a 2-D occupancy
  grid map (like a building floorplan) from laser and pose data collected by a mobile robot.




 This is mostly a third party package; the underlying GMapping library is .  Look there for details on many of the parameters listed below. To use , you need a mobile robot that provides odometry data and is equipped with a horizontally-mounted, fixed, laser range-finder.  The  node will attempt to transform each incoming scan into the  (odometry)  frame.  See the """" for more on required transforms. To make a map from a robot with a laser publishing scans on the  topic: slam_gmappingslam_gmappingodombase_scanslam_gmappingtfscanmap_metadatamap~entropydynamic_map~inverted_laserstring""false""~throttle_scansint~base_framestring""base_link""~map_framestring""map""~odom_framestring""odom""~map_update_intervalfloat~maxUrangefloat~sigmafloat~kernelSizeint~lstepfloat~astepfloat~iterationsint~lsigmafloat~ogainfloat~lskipint~minimumScorefloat~srrfloat~srtfloat~strfloat~sttfloat~linearUpdatefloat~angularUpdatefloat~temporalUpdatefloat~resampleThresholdfloat~particlesint~xminfloat~yminfloat~xmaxfloat~ymaxfloat~deltafloat~llsamplerangefloat~llsamplestepfloat~lasamplerangefloat~lasamplestepfloat~transform_publish_periodfloat0~occ_threshfloat~maxRangefloat<the frame attached to incoming scans>base_linktfbase_linkodommapodomrosrun gmapping slam_gmapping scan:=base_scan"
W1634,https://wiki.ros.org/visualization_rwt,Wiki,visualization_rwt,visualization packages using rwt
W1635,https://wiki.ros.org/ar_track_alvar_msgs,Wiki,ar_track_alvar_msgs,"This package is a ROS wrapper for Alvar, an open source AR tag tracking library.
"
W1636,https://wiki.ros.org/pepper_moveit_config,Wiki,pepper_moveit_config,"An automatically generated package with all the configuration and launch files for using the Pepper robot with the MoveIt Motion Planning Framework
Please, find the documentation on the github page . "
W1637,https://wiki.ros.org/abb_irb2400_moveit_plugins,Wiki,abb_irb2400_moveit_plugins,"
      MoveIt plugins for the ABB 2400 (and variants).
    
      This package contains plugins for use with MoveIt and ABB 2400 manipulators.
      Plugins included support the 2400. See the ABB 2400 support package for
      information on used joint angle and velocity limits.
    
      Before using any of the plugins included in this package, be sure to
      check they are correct for the particular robot model and configuration
      you intend to use them with.
    
This package is part of the  program. "
W1638,https://wiki.ros.org/v4r_artoolkitplus,Wiki,v4r_artoolkitplus,"The v4r_artoolkitplus package is a wrapper around the ARToolKitPlus software library for ROS.
  The ARToolKitPlus is a extended version of ARToolKit's library with a class-based API but with no VRML and camera library.
  It is also optimized to work with a set of precoded marker, so no marker training is needed.
  The ARToolKitPlus library was published under GPL2, thanks for that work goes to all people listed in a ./3rdParty/ARToolKitPlus/THANKS.
  More details about ARToolKitPlus package can be found under http://studierstube.org/handheld_ar/artoolkitplus.php

 This package uses the ARToolKitPlus to detect visual tags encoded with an id. Details to the tag detection can be found at  There are a large number of ROS  that can be set to customize the behavior of the  wrapper. Most of these parameters can also be changed using  but some of them must be set at start-up. ARToolKitPlussub{
  0.name= image
  0.type= sensor_msgs/Image
  0.desc= Image stream from the camera driver see parameter ''distorted_input''
  1.name= camera_info
  1.type= sensor_msgs/CameraInfo
  1.desc= Camera metadata
}
pub{
  0.name= ~<tf_prefix>/tf
  0.type= tf/tfMessage
  0.desc= TF related to the detected markers
}param{
  0.name = ~<name>/show_camera_image
  0.default = false
  0.type = bool
  0.desc = On true it opens a OpenCV window with debug information
  1.name = ~<name>/skip_frames
  1.default = 0
  1.type = int
  1.desc = Number of frames skipped between processing
  2.name = ~<name>/tracker_single_marker
  2.default = true
  2.type = bool
  2.desc = Sets the single marker mode it does not work with tracker_multi_marker = true
  3.name = ~<name>/tracker_multi_marker
  3.default = false
  3.type = double
  3.desc = Sets the multi marker mode it does not work with tracker_single_marker = true, the multi marker mode requires also a ''~<name>/pattern_file''
  4.name = ~<name>/pattern_file
  4.default = """"
  4.type = string
  4.desc = filename of the pattern file used for the  multi marker mode, there is a file within the packages cfg folder
  5.name = ~<name>/tf_prefix
  5.default = the node_name
  5.type = string
  5.desc = prefix for the tf publisher
  6.name = ~<name>/marker_mode
  6.default = ""bch""
  6.type = string
  6.desc = defines the marker id encoding, options are ""bch"" or ""simple""
  7.name = ~<name>/pattern_width
  7.default = 0.1
  7.type = double
  7.desc = size of single markers
  8.name = ~<name>/edge_threshold
  8.default = 0
  8.type = int
  8.desc = Edge threshold used for the detection, zero means automode
  9.name = ~<name>/border_width
  9.default = 0
  9.type = double
  9.desc = ratio of the marker border, zero means defined by marker_mode
  10.name = ~<name>/undist_mode
  10.default = ""std""
  10.type = string
  10.desc = undistorted function used to cope with image distortions, options are ""none"", ""std"" and ""lut"". ""lut"" only works up to 1024x1024
  11.name = ~<name>/undist_iterations
  11.default = 10
  11.type = int
  11.desc = Interactions used on the undistort approximation
  12.name = ~<name>/distorted_input
  12.default = true
  12.type = bool
  12.desc = Defines if the input image is distorted or not.
  13.name = ~<name>/pose_estimation_mode
  13.default = ""rpp""
  13.type = string
  13.desc = Defines the algorithm used to estimate a markers pose. Options are ""normal"", ""cont"" and ""rpp""
  14.name = ~<name>/use_multi_marker_lite_detection
  14.default = true
  14.type = bool
  14.desc = Only for multi marker mode, on true it uses a faster detection algorithm to find markers before the pattern pose is computed. This value should be set to true if one, next to the pattern, also wants to use the detected marker which is not part of an pattern.
  14.name = ~<name>/pattern_frame
  14.default = pattern
  14.type = string
  14.desc = name of the pattern tf related to a multi marker
}"
W1639,https://wiki.ros.org/abb,Wiki,abb,"ROS-Industrial support for ABB manipulators (metapackage).



Use GitHub to . []
 See the  metapackage for additional packages. For more information on what is required to be able to use these packages with your ABB controller and manipulator, see the  page. See the  page for an overview of the available tutorials. "
W1640,https://wiki.ros.org/rqt_moveit,Wiki,rqt_moveit,"An rqt-based tool that assists monitoring tasks
   for  motion planner
   developers and users. Currently the following items are monitored if they
   are either running, existing or published:
   

Follow 's general installation guide . On ,  is available as binary pkg that comes within  meta package.  If you happened to find any problem, follow the usual steps (defined at ), namely, Google search it,  if you haven't found a solution/workaround, and possiblly open a issue report or enhancement request ticket on Issue/Bug tracker listed above. rqtUbunturqt_moveitrqt_moveit"
W1641,https://wiki.ros.org/rgbd_launch,Wiki,rgbd_launch,"Launch files to open an RGBD device and load all nodelets to 
     convert raw depth/RGB/IR streams to depth images, disparity images, 
     and (registered) point clouds. 
 contains all the common launch files required by a driver specific launch package such as  or . There are 2 important launch files: 
 contains many internal launch files to split up processing. Only the following launch files should be used externally: 




 contains some example configurations that you can run and test running nodelets in the system: This package contains launch files for using RGB-D devices such as the Microsoft Kinect in ROS. It creates a  graph to transform raw data from the device driver into point clouds, disparity images, and other products suitable for processing and visualization. rgbd_launchprocessing.launch.xmlkinect_frames.launchrgbd_launchrgb_processingboolrgb/image_rawrgb/image_monorgb/image_rect_monorgb/image_colorrgb/image_rect_colordebayer_processingboolrgb_processingtruergb_processingfalsergb/image_rect_colorir_processingbooltrueir/image_rawir/image_rect_rawdepth_processingbooluint16floatdepth/image_rawdepth/image_rect_rawdepth/imagedepth/image_rectdepth/pointsdepth_registered_processingboolrgb_processingtruefalsedepth_processingtruetruedisparity_processingbooldepth/image_rect_rawprojector/camera_infodepth/disparitydepth_processingsw_registered_processingbooldepth/image_rect_rawdepth_registered/sw_registered/image_rect_rawdepth_registered/pointsdepth_registered/disparityhw_registered_processingbooldepth/image_rawdepth_registered/hw_registered/image_rect_rawdepth_registered/pointsdepth_registered/disparityqueue_sizeintrgbstringrgbirstringirdepthstringdepthdepth_registeredstringdepth_registeredprojectorstringprojectorroslaunch freenect_launch freenect-xyz.launch
roslaunch freenect_launch freenect-registered-xyzrgb.launch"
W1642,https://wiki.ros.org/tuw_multi_robot_rviz,Wiki,tuw_multi_robot_rviz,"Presents rviz plugins to set goal positions for the planner and a tool to visualize generated graphs.
 Figure: goal selector. 

Use GitHub to . []
  "
W1643,https://wiki.ros.org/octomap_mapping,Wiki,octomap_mapping,"Mapping tools to be used with the , implementing a 3D occupancy grid mapping.


 
To compile this stack from source you need to  (trunk or a tagged release), add the source directory to your ROS_PACKAGE_PATH (e.g. in ),  that file and run  For more documentation, see the documentation of the packages in this stack, in particular  and , or the OctoMap library at . Files are available at . Use the alufr-ros-pkg  to report bugs or request features. For questions (and FAQ), check  or contact  . ~/.bashrcsourcesudo apt-get install ros-fuerte-octomapsudo apt-get install ros-fuerte-octomap ros-fuerte-octomap-mappingrosdep install octomap_mapping
rosmake octomap_mapping"
W1644,https://wiki.ros.org/kvh_geo_fog_3d_msgs,Wiki,kvh_geo_fog_3d_msgs,kvh_geo_fog_3d_msgs contains raw messages for the KVH GEO FOG 3D INS devices. 
W1645,https://wiki.ros.org/move_basic,Wiki,move_basic,"Simple navigation package


  


 This package provides the  ROS Node which provides a very basic navigation node. 
The  node performs very basic navigation. Path planning consists of rotating in place to face the goal and then driving straight towards it. It is designed to provide the same software interfaces as , that is, it implements a   (see ), that takes in goals containing  messages.  It is assumed that we are dealing with imperfect localization data: -> is accurate but may be delayed and is at a slow rate and -> is more frequent, but drifts, particularly after rotating. To counter these issues,  plans in the  frame, and waits a short time after each step, and executes movement in the  frame. If goals in the  frame are received, they are interpreted as relative to the robot's current position.  This behavior is different to that of , which will not accept goals in the  frame.  Some of the data produced by  can be visualized with .  In the screen shot below, the portion of the laser scan data (in white) which is currently in the path of the robot is depicted as a red line.  The light purple line shows the path planned by the robot.   A navigation goal can be sent to  by  by pressing the  button and clicking on the map.   To move forward one meter using  (note that  completion will provide an empty message that can be filled out): This is an example of a relative goal, since the  is set to . The position of the target pose is set to 1 meter in the forward direction, and the orientation is the identity quaternion. move_basicmove_basicSimpleActionServergeometry_msgs/PoseStampedmapbase_linkodombase_linkmove_basicmapodombase_linkmove_basebase_linkmove_basicmove_basicrviz2D nav goal/move_base/goalmove_basic/move_base/cancel/move_base_simple/goalmove_basic/scan/sonars/tftfmapbase_linktfodombase_linktfodombase_linklasertfbase_linklaser/move_base/feedback/move_base/statusmove_base/move_base/resultmove_base/cmd_vel/plan/obstacle_distance/obstacle_viz~min_angular_velocitydouble~max_angular_velocitydouble~angular_accelerationdoublemin_angular_velocitymax_angular_velocity~angular_tolerancedouble~min_linear_velocitydouble~max_linear_velocitydouble~linear_accelerationdoublemin_linear_velocitymax_linear_velocity~linear_tolerancedouble~localization_latencydouble~rotation_attemptsint~obstacle_wait_limitdouble~reverse_without_turning_thresholddouble~map_framestring~robot_widthdoublebase_link~robot_front_lengthdoublebase_link~robot_back_lengthdoublebase_linkframe_idbase_linksudo apt install ros-kinetic-move-basicrostopic pub /move_base_simple/goal geometry_msgs/PoseStamped ""header:
  seq: 0
  stamp:
    secs: 0
    nsecs: 0
  frame_id: 'base_link'
pose:
  position:
    x: 1.0
    y: 0.0
    z: 0.0
  orientation:
    x: 0.0
    y: 0.0
    z: 0.0
    w: 1.0"" "
W1646,https://wiki.ros.org/abb_irb120_support,Wiki,abb_irb120_support,"
      ROS-Industrial support for the ABB IRB 120 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 120 manipulators. This includes the base model (120) and
      the 120T.
    
      Joint limits and max joint velocities are based on the information in the
       (Version: ROB0149EN_D, May 2012).
      All urdfs / xacros are based on the default motion and joint velocity
      limits, unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Inertial and mass properties were calculated using 3D modelling software, based on the 
      supplied .
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1647,https://wiki.ros.org/laser_scan_publisher_tutorial,Wiki,laser_scan_publisher_tutorial,The laser_scan_publisher_tutorial packageThis package provides the code for the  tutorial for the navigation stack. 
W1648,https://wiki.ros.org/arni_gui,Wiki,arni_gui,Common functionality for the ARNI rqt_gui overview and detail plugins.
W1649,https://wiki.ros.org/ainstein_radar_drivers,Wiki,ainstein_radar_drivers,"ROS drivers (interfaces) and nodes for Ainstein radars.





 

 To configure the radar type prior to testing, use the provided  script which depends on . Using eg.  is also useful debugging tool to monitor CAN traffic on the SocketCAN interface. These CAN radars require a  node publishing CAN frames to the  ROS topic (see the launch file below for an example).  This package can be installed with: The file k79_node.cpp implements a ROS node using the  interface class to create a UDP socket bound to the host IP address and port (which must match the radar's configuration), launch a thread to read and publish data to the  message type. The python script  can be used to configure the network parameters and flash new firmware. See the tutorials for more information. The easiest way to get started with any particular radar is to use the corresponding .  ~targets/raw~frame_idstring~host_ipstring~host_portint~radar_ipstring~radar_portint~targets/raw~frame_idstring~host_ipstring~host_portint~radar_ipstring~radar_portintreceived_messages~targets/raw~targets/tracked~frame_idstring~can_idint~min_rangefloat~max_rangefloat~min_anglefloat~max_anglefloatreceived_messages~targets/raw~targets/tracked~frame_idstring~radar_typeint~targets/raw~frame_idstring~device_idstring~firmware_versionstrindcandump can0/received_messagesbash sudo apt install ros-kinetic-socketcan-bridge"
W1650,https://wiki.ros.org/pioneer_bringup,Wiki,pioneer_bringup,"pioneer_bringup provides roslaunch scripts for starting the core functionnalities of Adept MobileRobots Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, AmigoBot, PeopleBot, PatrolBot, PowerBot, Seekur and Seekur Jr.)You may get this error message . In that case, simply install usb_cam package from source: 
Use GitHub to . []
 


 is used to communicate with Pioneer robots hardware: 









A ROS package providing roslaunch scripts for starting the Adept  Pioneer and Pioneer-compatible robots (Including Pioneer 2, Pioneer 3, Pioneer LX, , , , , Seekur and Seekur Jr.) Please refer to the  for more information. All the bringup modes call first  package which is responsible to link ROS with the robot hardware. Sometimes however,  need to communicate throught USB port, and then, you need to replace the followin line in the minimal.launch file: For more information about this modification, please refer to : cd ~/catkin_ws/src
git clone https://github.com/amor-ros-pkg/rosaria.git
source ~/catkin_ws/devel/setup.bash
rosdep install rosariasudo apt-get install ros-indigo-lms1xxsudo apt-get install ros-jade-lms1xxsudo apt-get install ros-kinetic-lms1xxsudo apt-get install ros-indigo-usb-camsudo apt-get install ros-jade-usb-camsudo apt-get install ros-kinetic-usb-camcd ~/catkin_ws/src
git clone https://github.com/bosch-ros-pkg/usb_cam.git
cd ..
catkin_makecd ~/catkin_ws/src
git clone https://github.com/amineHorseman/pioneer_bringup.git
cd ..
catkin_makeroslaunch pioneer_bringup minimal.launchroslaunch pioneer_bringup camera.launchroslaunch pioneer_bringup laser_lms1xx.launchroslaunch pionner_bringup laser_lms1xx.launch _camera:=1<param name=""port"" value=""/dev/ttyS0"" /><param name=""port"" value=""/dev/ttyUSB0"" />cd ~/catkin_ws/src
git clone https://github.com/bosch-ros-pkg/usb_cam.git
cd ..
catkin_make"
W1651,https://wiki.ros.org/rospeex_core,Wiki,rospeex_core,This package provides rospeex's core nodes.
W1652,https://wiki.ros.org/maggie_serial_comm_drivers,Wiki,maggie_serial_comm_drivers,"serial_comm drivers for Maggie robot

"
W1653,https://wiki.ros.org/maggie_drivers,Wiki,maggie_drivers,"maggie_drivers metapackage

ROS packages for the devices of the robot . "
W1654,https://wiki.ros.org/qb_device_msgs,Wiki,qb_device_msgs,"This package contains the device-independent custom ROS messages for qbrobotics® devices.
Each  device-independent custom ROS message is documented directly in its  specification and it is designed to fit most of the users needs. Indeed we recommend to use these messages as they are whenever it is possible. However we understand that your application may require few specific additional information. Since it is difficult to provide one-size-fit-all messages, integrate your specification in a new coherent custom message, and feel free to propose your changes with a Pull Request in our repository if you think that it could be helpful for someone else. .msg"
W1655,https://wiki.ros.org/moveit_tutorials,Wiki,moveit_tutorials,The moveit_tutorials package
W1656,https://wiki.ros.org/network_interface,Wiki,network_interface,"Network interfaces and messages.
 "
W1657,https://wiki.ros.org/move_base,Wiki,move_base,"The move_base package provides an implementation of an action (see the  package) that, given a goal in the world, will attempt to reach it with a mobile base. The move_base node links together a global and local planner to accomplish its global navigation task. It supports any global planner adhering to the nav_core::BaseGlobalPlanner interface specified in the  package and any local planner adhering to the nav_core::BaseLocalPlanner interface specified in the  package. The move_base node also maintains two costmaps, one for the global planner, and one for a local planner (see the  package) that are used to accomplish navigation tasks. 

 
 

 () 
 () 

This package provides the  ROS Node which is a major component of the . A detailed description of this Node and its configuration options is found below. The  node provides a ROS interface for configuring, running, and interacting with the  on a robot. A high-level view of the move_base node and its interaction with other components is shown above. The blue vary based on the robot platform, the gray are optional but are provided for all systems, and the white nodes are required but also provided for all systems. For more information on configuration of the  node, and the navigation stack as a whole, please see the  tutorial. Running the  node on a robot that is properly configured (please see  for more details) results in a robot that will attempt to achieve a goal pose with its base to within a user-specified tolerance. In the absence of dynamic obstacles, the move_base node will eventually get within this tolerance of its goal or signal failure to the user. The  node may optionally perform recovery behaviors when the robot perceives itself as stuck. By default, the  node will take the following actions to attempt to clear out space: First, obstacles outside of a user-specified region will be cleared from the robot's map. Next, if possible, the robot will perform an in-place rotation to clear out space. If this too fails, the robot will more aggressively clear its map, removing all obstacles outside of the rectangular region in which it can rotate in place. This will be followed by another in-place rotation. If all this fails, the robot will consider its goal infeasible and notify the user that it has aborted. These recovery behaviors can be configured using the  parameter, and disabled using the  parameter. The  node provides an implementation of the  (see ), that takes in goals containing  messages. You can communicate with the  node over ROS directly, but the recommended way to send goals to  if you care about tracking their status is by using the . Please see  for more information. The  node contains components that have their own ROS APIs. These components may vary based on the values of the , , and  respectively. Links to the APIs for the default components can be found below: Class Diagram (partially & not strictly drawn) is available . move_basemove_basemove_basemove_basemove_basemove_basemove_baseSimpleActionServergeometry_msgs/PoseStampedmove_basemove_baseSimpleActionClientmove_base/goalmove_basemove_base/cancelmove_base/feedbackmove_base/statusmove_basemove_base/resultmove_basemove_base_simple/goalcmd_vel~make_planmove_basemove_base~clear_unknown_space~clear_costmaps~base_global_plannerstring""navfn/NavfnROS""move_basenav_core::BaseGlobalPlanner""NavfnROS""~base_local_plannerstring""base_local_planner/TrajectoryPlannerROS""move_basenav_core::BaseLocalPlanner""TrajectoryPlannerROS""~recovery_behaviorslistmove_basemove_basemove_basemove_basenav_core::RecoveryBehavior~/local_costmap/circumscribed_radius~controller_frequencydouble~planner_patiencedouble~controller_patiencedouble~conservative_reset_distdoublemove_base~recovery_behavior_enabledbooltruemove_base~clearing_rotation_allowedbooltruerecovery_behaviors~shutdown_costmapsboolfalsemove_base~oscillation_timeoutdouble~oscillation_distancedouble~oscillation_timeout~planner_frequencydouble~max_planning_retriesint32_tmove_base~base_global_planner~base_local_planner~recovery_behaviorsnav_core::BaseGlobalPlannernav_core::BaseLocalPlannermove_basemove_basemove_basemove_basemove_base"
W1658,https://wiki.ros.org/kobuki_auto_docking,Wiki,kobuki_auto_docking,"Automatic docking for Kobuki:
	    Users owning a docking station for Kobuki can use this tool to let Kobuki find its nest autonomously.~odom~core~dock_ir~motor_power~velocity~odom~core~dock_ir~motor_power~velocity~min_abs_vdouble~min_abs_wdouble"
W1659,https://wiki.ros.org/abseil_cpp,Wiki,abseil_cpp,The abseil_cpp package
W1660,https://wiki.ros.org/pepper_bringup,Wiki,pepper_bringup,"The pepper_bringup package


 
 You can start Pepper either with a  or  version. The pepper_bringup package thus contains two launch files. See the  and  for further details.  
This is only available in the C++ versionsudo apt-get install ros-indigo-pepper-robot ros-indigo-pepper-meshesroslaunch pepper_bringup pepper_full.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip> [network_interface:=<eth0|wlan0|vpn0>]roslaunch pepper_bringup pepper_full_py.launch nao_ip:=<robot_ip> roscore_ip:=<roscore_ip>"
W1661,https://wiki.ros.org/naoqi_dcm_driver,Wiki,naoqi_dcm_driver,"Package containing the hardware interface to connect to Nao, Romeo, or Pepper robots.

*  *  *  "
W1662,https://wiki.ros.org/vrpn,Wiki,vrpn,"The VRPN is a library and set of servers that interfaces with virtual-reality systems, such as VICON, OptiTrack, and others."
W1663,https://wiki.ros.org/rospeex_if,Wiki,rospeex_if,This package provides interface libraries on C++ and Python.
W1664,https://wiki.ros.org/qb_device_hardware_interface,Wiki,qb_device_hardware_interface,"This package contains a device-independent hardware interface for qbrobotics® devices.
This package is barely usable alone since it provides only the common features to be exploited and expanded in the derived packages (cf.  and ). /<namespace>/state/communication_handler/activate_motorssuccesstrue/communication_handler/deactivate_motorssuccesstrue/communication_handler/deregister_device/communication_handler/get_infomessage/communication_handler/get_measurementssuccesstruecurrentspositions/communication_handler/register_devicesuccesstrue/communication_handler/set_commandscommands~actuatorsstring[]robot_description~device_idint1128~jointsstring[]robot_description~namespacestring~robot_descriptionstring~transmissionstringtransmission_interface::Transmission"
W1665,https://wiki.ros.org/pdu_msgs,Wiki,pdu_msgs,Control messages for the PDU
W1666,https://wiki.ros.org/qb_device,Wiki,qb_device,This package contains a device-independent ROS interface for qbrobotics® devices.
W1667,https://wiki.ros.org/pioneer_mrs,Wiki,pioneer_mrs,The pioneer_mrs ROS package for Pioneer 3-AT Multi-Robot Systems
W1668,https://wiki.ros.org/rtt,Wiki,rtt,Orocos/RTT component framework
W1669,https://wiki.ros.org/roswww,Wiki,roswww,"Feathery lightweight web server for ROS, that is based on  web server module.
See  "
W1670,https://wiki.ros.org/pr2_tilt_laser_interface,Wiki,pr2_tilt_laser_interface,"Provides a set of tools/actions for manipulating the pr2's tilting
    laser. Simplifies previously complex tasks, such as fetching
    a single sweep, given a set of desired parameters for both the laser
    driver and tilting platform."
W1671,https://wiki.ros.org/velo2cam_gazebo,Wiki,velo2cam_gazebo,"Metapackage allowing easy installation of velo2cam_gazebo components.
 







 This package includes Gazebo models, plugins and worlds of several sensors and calibration targets to help the process of designing and testing algorithms for extrinsic calibration of lidar-camera pairs. Package developed at , Universidad Carlos III de Madrid. Note: The models included in this repository were designed for evaluating the LIDAR-camera calibration algorithm described in [1], whose code is provided . Velodyne plugin providing  with same structure as driver (x, y, z, intensity, ring) and simulated Gaussian noise. (Code from , although minor patch for vertical resolution issue is included) [1] Guindel, C., Beltrán, J., Martín, D. and García, F. (2017). Automatic Extrinsic Calibration for Lidar-Stereo Vehicle Sensor Setups. . Pre-print available  roslaunch velo2cam_gazebo real_stereoVLP16_trans.launch"
W1672,https://wiki.ros.org/rotors_control,Wiki,rotors_control,RotorS control package
W1673,https://wiki.ros.org/asr_mild_base_fake_driving,Wiki,asr_mild_base_fake_driving,"The asr_mild_base_fake_driving package provides a simulation system for the robot driving. It simulates the desired driven way which is calculated by the navigation. 

 




Look at  on how to start the simulated navigation with fake driving,. All simulation launch files use the fake driving. cmd_vel ( ) odom ( ) roslaunch asr_mild_navigation simulation_manual_rearranged.launchrosrun asr_mild_base_fake_driving asr_mild_base_fake_driving"
W1674,https://wiki.ros.org/tuw_voronoi_graph,Wiki,tuw_voronoi_graph,"Contains different nodes to generate routing graphs for the robot router. voronoi_graph_generator generates a voronoi graph out of a map. dxf_to_graph generates a graph out of a dxf file and segments_to_graph creates a graph using a config file with line segments as input.
 

 () 
 ()  () 
 ( default: ""0.1"" [m])  ( default: ""0.9"")  ( default: ""0.2"")  ( default: ""0.4"")  ( default: ""."")  ( default: """")  ( default: ""false"") 

     


 () 
 ( default: ""segments.yaml"")  ( default: ""/segments"")  ( default: ""0.9"") 

Use GitHub to . []
 This package includes the , which generates a voronoi graph out of a pixel map and the , which generates a graph out of segments. Receives a pixel map (occupancy_grid) and converts it into a  message spanning the whole free space of the map. Additionally the graph is saved to a given folder. If a map is already converted to a graph the graph is loaded from memory to save computation time. This is a standard executable which takes a .dxf file as input and generates a graph which is saved to be loaded with the . Receives a pixel map (occupancy_grid) and converts it into a  message spanning the whole free space of the map. Additionally the graph is saved to a given folder. If a map is already converted to a graph the graph is loaded from memory to save computation time. tuw_voronoi_graph_nodetuw_segment_to_graph_nodetuw_multi_robot_msgs/Graph~mapnav_msgs/OccupancyGrid~segmentstuw_multi_robot_msgs/VoronoiGraph~map_erodednav_msgs/OccupancyGrid~map_inflationdouble~segment_lengthfloat~crossing_opimizationfloat~end_segment_optimizationfloat~graph_pathstring~custom_graph_pathstring~publish_map_erodedbooltuw_voronoi_graph_node-h [ --help ]-i [ --input ] arg (=./segments.dxf)-o [ --output ] arg (=./graphs/segments)-w [ --width ] arg (=0.600000024)-l [ --length ] arg (=1)tuw_multi_robot_msgs/Graph~segmentstuw_multi_robot_msgs/VoronoiGraph~segment_filestring~segments_topicstring~segment_lengthfloatstart_x:      [      0,        2,   3.2,    5]
start_y:      [   -1.5,     -1.5,    -2,   -4]
end_x:        [      2,      3.2,     5,    3]
end_y:        [   -1.5,       -2,    -4,   -4]
space:        [    1.0,      1.0,   1.0,  1.0]
origin_x:     -15
origin_y:     -15
resolution:   0.05"
W1675,https://wiki.ros.org/mongodb_log,Wiki,mongodb_log,"The mongodb_log package


 

  


This package provides nodes that can record any and all data transmitted via ROS topics and stores them in the document-oriented database  replicating the message type as document structure. Afterwards, data can be used and queried independently of a particular robot software framework using the existing MongoDB query features with indexes, data locality (sharding) and . This means you can also freely mix in data acquired from other sources, for example using . This project is joint work of the  at The Robotics Institute of the Carnegie Mellon University and the  at the RWTH Aachen University. For more details please visit the . The logger regularly creates graphs based an a round-robin database (RRD) using . Additionally, the  script can be run to create graphs showing the performance of MongoDB. Example graphs look like the following. The  package provides two functionalities. For one there is a node to store all messags of one specific topic to the database, for another it provides a library for other nodes to interact with the database. This mongodb_log package compares to the former part. The  node of the  package stores incoming messages as serialized blobs, much like rosbag does. This way, queries can only be made based on the time of the message. More powerful queries and usage of the data is only possible of a specific node has been created or modified to record data in more verbose documents. The upper graphs shows CPU and memory usage of rosbag, the generic mongodb_log python logger, and the specific C++ logger mongodb_log_tf, all recording the /tf topic at the same time, with transform messages containing 5 transforms at a rate of 100 Hz. We see that the MongoDB C++ logger and rosbag perform with about the same overhead. However, MongoDB is more efficient when writing, because rosbag writes the message type specification for each recorded message (note that MongoDB was writing two topics, one for the Python and the C++ logger each, while rosbag logged only one). The generic Python logger is much more demanding in terms of both, CPU and memory usage. The problem is the inherent Python overhead for deserializing message, which we had also analyzed when developing roslua (cf. ). Hence, logging many unknown topics can put a considerable burden on your logging machine. The data acquired can be useful for a plethora of tasks. We have used it for fault analysis and performance evaluation, as described on the  and in the . More information will be provided at a later point in time. If you want to get in touch please contact . Feel free to fork the  and let us know about your changes. Please report issues on the . mongodb_rrdrecord_to_dbgit clone https://github.com/timn/ros-mongodb_log.git mongodb_log
cd mongodb_log
makerosrun mongodb_log mongodb_log -a  MongoDB document                          rostopic echo /tf
------------------------------------------------------------------------------
{                                        |
  ""_id"" : ObjectId(""5011...""),           |
  ""__topic"" : ""/tf"",                     |
  ""__recorded"" : ISODate(""2012-07...""),  |
  ""transforms"" : [                       |  transforms:
    {                                    |  -
      ""header"" : {                       |    header:
        ""stamp"" : ISODate(""2012-07...""), |    stamp:
                                         |      secs: 1343297357
                                         |      nsecs: 291
        ""frame_id"" : ""/from"",            |      frame_id: /from
        ""seq"" : 0                        |      seq: 0
      },                                 |
      ""transform"" : {                    |    transform:
        ""translation"" : {                |      translation:
        ""x"" : 1,                         |        x: 1.0
        ""y"" : 0,                         |        y: 0.0
        ""z"" : 0                          |        z: 0.0
      },                                 |
      ""rotation"" : {                     |      rotation:
        ""x"" : 0,                         |        x: 0.0
        ""y"" : 0,                         |        y: 0.0
        ""z"" : 0,                         |        z: 0.0
        ""w"" : 1                          |        w: 1.0
      },                                 |
      ""child_frame_id"" : ""/some_other""   |    child_frame_id: /some_other
    }                                    |
  ]                                      |
}                                        |"
W1676,https://wiki.ros.org/hector_uav_msgs,Wiki,hector_uav_msgs,hector_uav_msgs is a message package that contains messages for UAV controller inputs and outputs and some sensor readings not covered by sensor_msgs.
W1677,https://wiki.ros.org/abb_experimental,Wiki,abb_experimental,"Experimental packages for ABB manipulators within ROS-Industrial.





Use GitHub to . []
 This stack is part of the  program. It contains experimental packages that will be moved to the  package once they've received sufficient testing and review. Packages in distribution branches (ie: ) may be expected to be compatible with the corresponding ROS distribution (ie: the  branch is usable on Indigo). In the absence of major differences between subsequent ROS releases, the  branch may be expected to be compatible with the next release as well (ie:  may be used on Jade, as long as no  branch exists). Refer to the  for more information on building catkin workspaces. See the  page for more information. $ROS_DISTRO-develindigo-devel-develindigo-develjade-devel$ROS_DISTRO-develapt-getkinetic-develapt-get





































"
W1678,https://wiki.ros.org/arni_nodeinterface,Wiki,arni_nodeinterface,"The ARNI host manager, which collects host/node statistics and enables the ARNI countermeasure node to run remote commands.




 is used to gather the current temperature of the host, maybe. It can be found .  "
W1679,https://wiki.ros.org/kuka_kr5_support,Wiki,kuka_kr5_support,"
      ROS-Industrial support for the KUKA KR5 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 5 manipulators. This currently includes the KR 5 arc only.
    :
      Joint limits and maximum joint velocities are based on the information
      found in the online datasheet . All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    
      : this package currently uses non-valid inertia parameters.
    "
W1680,https://wiki.ros.org/pr2_tuckarm,Wiki,pr2_tuckarm,"Tucks the arms of the PR2 robot into a safe position for moving the base of the robot.
     This also moves the arms out of the view of the tilting laser scanner, as much as possible.



As with all applications, you must first . The tuck arm application is a Python script, : The tuck arm application is a Python script, : tuckarms.pytuck_arms.pyUSAGE: tuck_arms.py [b | l | r] rosrun pr2_tuckarm tuck_arms.py bUSAGE: tuck_arms.py [-r <action>] [-l <action>]; <action> is '(t)uck' or '(u)ntuck'.rosrun pr2_tuckarm tuck_arms.py -r t -l trosrun pr2_tuckarm tuck_arms.py --right untuck "
W1681,https://wiki.ros.org/qb_device_bringup,Wiki,qb_device_bringup,"This package contains a device-independent bringup utilities for qbrobotics® devices.

 
 
 

This package is barely usable alone since it provides only templates to create more structured launch files in the derived packages (cf.  and ). This launch file calls the other templates ,  and  to bringup a control node for a single device without starting ,  and . 
Since the only difference w.r.t. the  launch file is the includes of the  rather than the , the parameters are exactly the same as the other a part from  which is not used. This launch file calls the other templates ,  and  to bringup a complete control node for a single device. 
It provides basically the same configuration parameters as the other launch files a part from  and  of the  which are not exported outside. use_rvizcontrol_actionstringfoo<namespace>_foo_trajectory_controller/follow_joint_trajectorycontrol_durationdoubledevice_idint1128device_controlstringqb_deviceqb_device_controldevice_namespacestringuse_waypointsbooltrue~waypointswaypoint_namespacestringmy_devicemy_device_waypoints.yamlconfig/_controlwaypoint_settingsstringqb_deviceqb_device_controlcontrollersstring*_trajectory_controllercontrollers_namespacestringmy_devicemy_device_controllers.yamlconfig/_controlcontrollers_settingsstringqb_deviceqb_device_controluse_controller_guibooldevice_descriptionstringqb_deviceqb_device_descriptiondevice_namespacestringmy_devicemy_device_joint_...my_device_link_...device_urdfstringqb_deviceqb_device.urdf.xacro.urdf/_descriptionfrequencyintHzsource_liststringuse_rvizbooltruedevice_urdfrviz/_descriptionfrequencysource_list"
W1682,https://wiki.ros.org/ainstein_radar_gazebo_plugins,Wiki,ainstein_radar_gazebo_plugins,"Radar sensor plugins for the Gazebo simulator.

  This package is intended to contain a collection of simulated radar sensor plugins for different Ainstein products. All radar plugins are based on the existing laser  with additional processing to convert laser range detections to radar targets and publish them as  messages. While the  shared library (plugin) is intended to be generic enough to simulate any Ainstein radar, it currently only is valid for 1d radars (a vertical scan dimension could be added and used to fill the elevation angle data), does not support target speed (this might be able to be computed numerically from successive scans) and the SNR is filled from the returned ray intensity (this has not really been tested and may be a bad idea). Once the package has been built (as normal in the catkin workspace), copy the folder(s) inside the  directory to somewhere on your , eg.  which can be added to your model path (if it isn't already) by adding this to your : Also, make sure that  is on your  as this is where the shared library will be built. To do this, add the following to your : To test that the sensor is able to be loaded correctly in Gazebo (before adding it to another model), use the provided test.launch file to attempt to start Gazebo with the radar sensor. If you see an error about not finding the .so file, check your . libgazebo_radar_sensor_plugin.somodels/GAZEBO_MODEL_PATH~/.gazebo/models.bashrcexport GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:~/.gazebo/models~/catkin_ws/devel/lib/GAZEBO_PLUGIN_PATH.bashrcexport GAZEBO_PLUGIN_PATH=$GAZEBO_PLUGIN_PATH:~/catkin_ws/devel/libGAZEBO_PLUGIN_PATH"
W1683,https://wiki.ros.org/sicktoolbox_wrapper,Wiki,sicktoolbox_wrapper,"sicktoolbox_wrapper is a ROS wrapper for the outstanding 
    library for interfacing with the SICK LMS2xx lasers. 



sicktoolbox_wrappersicktoolbox_wrappersicktoolbox_wrappersicktoolbox_wrappersicklmslms_configscan~use_rep_117bool~portstring/dev/lms200~baudint~invertedboolfalse~frame_idstringlaser~angleint~resolutiondouble~connect_delaydoublesickldld_configscan~portint49152~ipaddressstring~invertedboolfalse~frame_idstringlaser~timer_smoothing_factordouble~timer_error_thresholddouble~resolutiondouble~start_angledouble~stop_angledouble~scan_ratedouble"
W1684,https://wiki.ros.org/applanix_bridge,Wiki,applanix_bridge,"
    Contains the adapter node which translates between the Applanix serialized socket
    format and ROS messages. This node is implemented in Python for now, but could be
    re-implemented using roscpp if performance is a bottleneck.
  "
W1685,https://wiki.ros.org/outlet_pose_estimation,Wiki,outlet_pose_estimation,"

     outlet_pose_estimation

  "
W1686,https://wiki.ros.org/mpc_local_planner_msgs,Wiki,mpc_local_planner_msgs,This package provides message types that are used by the package mpc_local_planner
W1687,https://wiki.ros.org/segbot_apps,Wiki,segbot_apps,"High-level applications that run on Segway RMP 50 based robots at Learning
    Agents Research Group (LARG), AI Laboratory, Department of Computer
    Science, The University of Texas at Austin.

Use GitHub to . []
  "
W1688,https://wiki.ros.org/python_trep,Wiki,python_trep,"Trep: Mechanical Simulation and Optimal Control Software




Full documentation is available at . Trep can create a system model using certain tags from the .  The following tags are supported: The ROSMidpointVI class extends the MidpointVI class available in trep.  This class automatically publishes all frames imported from the URDF to the  topic every time  is called. An example package called  is available at .  This package has two demos which can be called from launch files. After cloning the package to your ROS workspace, run the following command: /tfROSMidpointVI.step()trep_urdf_demo





 roslaunch trep_urdf_demo rrbot.launch roslaunch trep_urdf_demo puppet.launch"
W1689,https://wiki.ros.org/actionlib,Wiki,actionlib,"The actionlib stack provides a standardized interface for
    interfacing with preemptable tasks. Examples of this include moving
    the base to a target location, performing a laser scan and returning
    the resulting point cloud, detecting the handle of a door, etc.


 

 To accomplish tasks using actions, we introduce the notion of a goal that can be sent to an ActionServer by an ActionClient. In the case of moving the base, the goal would be a PoseStamped message that contains information about where the robot should move to in the world.  For controlling the tilting laser scanner, the goal would contain the scan parameters (min angle, max angle, speed, etc). 
 Feedback provides server implementers a way to tell an ActionClient about the incremental progress of a goal. For moving the base, this might be the robot's current pose along the path.  For controlling the tilting laser scanner, this might be the time left until the scan completes. 
 A result is sent from the ActionServer to the ActionClient upon completion of the goal. This is different than feedback, since it is sent exactly once.  This is extremely useful when the purpose of the action is to provide some sort of information.  For move base, the result isn't very important, but it might contain the final pose of the robot.  For controlling the tilting laser scanner, the result might contain a point cloud generated from the requested scan. 
 


  


  
 Suppose you have defined  in the  package. The following snippet shows how to send a goal to a DoDishes ActionServer called ""do_dishes"".  For the C++ , the  method will only work if a separate thread is servicing the client's callback queue. This requires passing in  for the  option of the client's constructor, running with a multi-threaded spinner, or using your own thread to service ROS callback queues. 


  
 Suppose you have defined  in the  package. The following snippet shows how to write a DoDishes ActionServer called ""do_dishes"". 
  
 Suppose you have defined  in the  package. The following snippet shows how to write a DoDishes ActionServer called ""do_dishes"". 


In any large ROS based system, there are cases when someone would like to send a request to a node to perform some task, and also receive a reply to the request. This can currently be achieved via ROS . In some cases, however, if the service takes a long time to execute, the user might want the ability to cancel the request during execution or get periodic feedback about how the request is progressing. The  package provides tools to create servers that execute long-running goals that can be preempted. It also provides a client interface in order to send requests to the server. For a full discussion of how actionlib operates ""under the hood"", please see the  . The  and  communicate via a , which is built on top of ROS messages.  The client and server then provide a simple API for users to request goals (on the client side) or to execute goals (on the server side) via function calls and callbacks. In order for the client and server to communicate, we need to define a few messages on which they communicate.  This is with an . This defines the Goal, Feedback, and Result messages with which clients and servers communicate: The action specification is defined using a  file.  The  file has the goal definition, followed by the result definition, followed by the feedback definition, with each section separated by 3 hyphens (). These files are placed in a package's  directory, and look extremely similar to a service's  file. An action specification for doing the dishes might look like the following: Based on this  file, 6 messages need to be generated in order for the client and server to communicate. This generation can be automatically triggered during the make process: Add the following to your CMakeLists.txt file  . Additionally, the  of the package that includes  files must include the following dependencies: Package that depends on actionlib API to implement an action server or use an action client needs another dependency on . For the , the following messages are generated by : These messages are then used internally by actionlib to communicate between the ActionClient and ActionServer. Full API Reference for the  Full API reference for the  Suppose the  exists in the  package.  The following snippet shows how to send a goal to a DoDishes ActionServer called ""do_dishes"" using Python. Full API Reference for the  Full API Reference for the  The  implements a single goal policy on top of the  class. The specification of the policy is as follows:  Calling  accepts a new goal when one is available. The status of this goal is set to active upon acceptance, and the status of any previously active goal is set to preempted. Preempts received for the new goal between checking if  or invocation of a goal callback and the  call will not trigger a preempt callback.  This means,  should be called after accepting the goal even for callback-based implementations to make sure the new goal does not have a pending preempt request. Please refer to the  page Please report any bugs on the  by detailing your environment (OS, ROS Distro) and a minimal example how how to replicate the issue. actionlib.action.action---./action.srv./action/DoDishes.action.actioncatkin_package()package.xml.actiondependactionlibCMakeLists.txtpackage.xmlDoDishes.actiongenaction.pyDoDishesAction.msgDoDishesActionGoal.msgDoDishesActionResult.msgDoDishesActionFeedback.msgDoDishesGoal.msgDoDishesResult.msgDoDishesFeedback.msgDoDishes.actionchoresSimpleActionClientwaitForServertruespin_threadDoDishes.actionchoresDoDishes.actionchoresDoDishes.actionchoresSimpleActionServerActionServeracceptNewGoalisNewGoalAvailableacceptNewGoalisPreemptRequested# Define the goal
uint32 dishwasher_id  # Specify which dishwasher we want to use
---
# Define the result
uint32 total_dishes_cleaned
---
# Define a feedback message
float32 percent_completefind_package(catkin REQUIRED genmsg actionlib_msgs)
add_action_files(DIRECTORY action FILES DoDishes.action)
generate_messages(DEPENDENCIES actionlib_msgs)<build_depend>actionlib_msgs</build_depend>
<exec_depend>actionlib_msgs</exec_depend><depend>actionlib</depend>
<depend>actionlib_msgs</depend>find_package(catkin REQUIRED genmsg actionlib_msgs actionlib)
add_action_files(DIRECTORY action FILES DoDishes.action)
generate_messages(DEPENDENCIES actionlib_msgs)<build_depend>actionlib</build_depend>
<build_depend>actionlib_msgs</build_depend>
<exec_depend>actionlib</exec_depend>
<exec_depend>actionlib_msgs</exec_depend>















































































"
W1690,https://wiki.ros.org/vapor_master,Wiki,vapor_master,"high availability ros master

  
 Vapor_master is a drop in replacement for  enabling high availability ROS service discovery. Vapor removes the single point of failure fundamental to ROS1 enabling new options for achieving greater scale, up-time and resiliency in ROS 1.x solutions. Vapor implements the  as well as the  utilizing a modern micro services approach. Unlike rosmaster, which does only supports an in-memory datastore, vapor persists data to a mongodb database. This enables instances of vapor to come and go without the need to stop all other ROS nodes left running on other computers. In assembly lines and mobile robots utilizing 3 or more computers, vapor_master can be deployed to all compute nodes. While mongodb can be deployed to a minimum of 3 nodes. In this scenario the ROS_MASTER_URI can be set to  as if each node were its own rosmaster. In this way an given compute node can come and go as needed without preventing ros parameter access or service discovery. http://localhost:11311"
W1691,https://wiki.ros.org/uc3m_maps,Wiki,uc3m_maps,"uc3m_maps.
"
W1692,https://wiki.ros.org/seed_smartactuator_sdk,Wiki,seed_smartactuator_sdk,The seed_smartactuator_sdk package
W1693,https://wiki.ros.org/utilrb,Wiki,utilrb,"
    This library is a collection of useful Ruby classes
  "
W1694,https://wiki.ros.org/industrial_robot_status_controller,Wiki,industrial_robot_status_controller,"A ros_control controller that reports robot status using the ROS-Industrial RobotStatus message.




Use GitHub to . []
 This package provide a  compatible controller that publishes robot/controller state (e-stopped, in motion, etc) as  messages. See the documentation in the repository: . ros_controlindustrial_msgs/RobotStatushardware_interfacerobot_statuspublish_ratefloatRobotStatushandle_namestrIndustrialRobotStatusHandlehardware_interface"
W1695,https://wiki.ros.org/arbotix_controllers,Wiki,arbotix_controllers,"Extends the arbotix_python package with a number of more sophisticated ROS wrappers for common devices.
The arbotix_controllers package contains several controllers that add additional layers of ROS interface onto the basic structure of . "
W1696,https://wiki.ros.org/abb_irb1200_7_70_moveit_config,Wiki,abb_irb1200_7_70_moveit_config,"
      MoveIt package for the ABB IRB 1200-7/0.7.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 1200-7/0.7 with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  page. "
W1697,https://wiki.ros.org/rbcar_pad,Wiki,rbcar_pad,"The rbcar_pad package
"
W1698,https://wiki.ros.org/mir_navigation,Wiki,mir_navigation,"Launch and configuration files for move_base, localization etc. on the MiR robot."
W1699,https://wiki.ros.org/ros_opcua_impl_python_opcua,Wiki,ros_opcua_impl_python_opcua,"The ros_opcua_impl_python_opcua package implement binding for python-opcua - Pure Python OPC-UA / IEC 62541 Client and Server library.





Use GitHub to . []
  This package provides communication interface between ROS and  communication standard using  library  written in Python. This package currently implements an OPC UA Server mapping all ROS Topics, Services and Actions under defined namespace in the OPC UA address space. Check the  page. namespaceStringroslaunch ros_opcua_impl_python_opcua rosopcua.launch"
W1700,https://wiki.ros.org/area_division,Wiki,area_division,"A package that divides the available environment area among multiple cyber physical systems (CPSs) in a swarm.

 (, default: 1)  (, default: ) 


 The communication between CPSs is based on the . The following packages of the  are required: to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. area_divisionidintegeroutputstringscreenscreenlogparamarea_division.yamlarea_divisionarea_divisionstateswarm_statepos_provider/posearea/mapbridge/uuidbridge/events/area_divisionpos_controller/goal_positionarea_divisionarea/assignedarea/rotatedvisualizearea/downsampledvisualizearea/get_rotation~loop_ratereal~queue_sizeinteger~resolutionreal~swarm_timeoutreal~visualizeboolean~statesstring list~/optimizer/iterationsinteger~/optimizer/variate_weightreal~/optimizer/discrepancyintegerroslaunch area_division area_division.launch"
W1701,https://wiki.ros.org/phantomx_reactor_arm_controller,Wiki,phantomx_reactor_arm_controller,The phantomx_reactor_arm_controller package
W1702,https://wiki.ros.org/ros_ethercat_eml,Wiki,ros_ethercat_eml,This is an implementation of the EtherCAT master protocol for use wiht ros_ethercar package based on the work done at Flanders' Mechatronics Technology Centre and Willow Garage.
W1703,https://wiki.ros.org/qb_hand_hardware_interface,Wiki,qb_hand_hardware_interface,"This package contains the hardware interface for qbrobotics® qbhand device.

This package is barely usable alone since it provides only the hardware interface for the  device. This library inherits from the base device-independent  (therefore provides the same ROS API) and extends its features specifically for the . In brief, it provides the specific transmission interface for the hand, which is the only thing that is really device dependent, and exploits the same hardware interfaces properly initialized (cf. ) and the same Communication Handler to talk to the physical device (cf. ). "
W1704,https://wiki.ros.org/aruco_msgs,Wiki,aruco_msgs,The aruco_msgs package
W1705,https://wiki.ros.org/rgbdslam,Wiki,rgbdslam,"
    This package can be used to register the point clouds from RGBD sensors such as the kinect or stereo cameras.
    The rgbdslam node can be connected easily to an octomap_server node to create a memory-efficient 3D map.
  
 






 This page describes the RGB-D SLAM system for ROS Fuerte. ,  for. See . For the electric version and many details that still hold true, see  . Download rgbdslam with the following command to your . If not yet installed, install  first, then execute which will take a while. If you encounter problems, here is an example   for a successful build for reference (Revision 3949). As mentioned in , if ROS dependencies are still not met for some reason, you might need to install the following dependencies There are several example launch-files that set the parameters of RGB-D SLAM for certain use cases, a complete list of all options and their current settings can be found in the GUI: ""Settings""->""View Current Settings"". For a definitive list of all settings and the default values have a look at their quite readable definition in src/parameter_server.cpp. If you want to use RGB-D SLAM with a Kinect or Xtion Pro, you should install . If you want to edit the saved point clouds you might want to install meshlab. rgbdslam_v2svn co http://alufr-ros-pkg.googlecode.com/svn/trunk/rgbdslam_freiburgrosdep update
rosdep install rgbdslam_freiburgrosmake rgbdslam_freiburgsudo apt-get install libglew1.5-dev libdevil-dev libsuitesparse-dev  roslaunch rgbdslam kinect+rgbdslam.launch  roslaunch openni_launch openni.launch
  rosrun rgbdslam rgbdslam        roslaunch rgbdslam headless.launch        rosservice call /rgbdslam/ros_ui frame # Capture single frames via
        rosservice call /rgbdslam/ros_ui_b pause false # Capture a stream of data
        rosservice call /rgbdslam/ros_ui send_all # Send point clouds with computed transformations (e.g., to rviz or octomap_server)
        rosservice call /rgbdslam/ros_ui_s save_cloud /tmp/mycloud.pcd # Save the registered pointclouds in the given file
        rosservice call /rgbdslam/ros_ui_s save_individual /tmp/filenameprefix # As above, but save every pointcloud in its own file# Better pick a mirror close to you.
# See http://ros.org/wiki/ROS/Installation/UbuntuMirrors
sudo sh -c '. /etc/lsb-release && echo ""deb http://packages.ros.org/ros/ubuntu $DISTRIB_CODENAME main"" > /etc/apt/sources.list.d/ros-latest.list'

wget http://packages.ros.org/ros.key -O - | sudo apt-key add -

sudo aptitude update

# This will draw gigabytes from the network:
sudo apt-get install ros-fuerte-perception-pcl ros-fuerte-vision-opencv ros-fuerte-octomap-mapping python-rosdep

echo 'source /opt/ros/fuerte/setup.bash' >> ~/.bashrc

echo 'export ROS_PACKAGE_PATH=~/ros:$ROS_PACKAGE_PATH' >> ~/.bashrc

. ~/.bashrc

svn co http://alufr-ros-pkg.googlecode.com/svn/trunk/rgbdslam_freiburg ~/ros/rgbdslam_freiburg

sudo rosdep init

rosdep update

rosdep install rgbdslam_freiburg

roscd rgbdslam

# This will take a while:
rosmake rgbdslam_freiburgsudo apt-get install ros-fuerte-openni-launch"
W1706,https://wiki.ros.org/rosbag_storage,Wiki,rosbag_storage,"This is a set of tools for recording from and playing back ROS
    message without relying on the ROS client library."
W1707,https://wiki.ros.org/pr2_common_action_msgs,Wiki,pr2_common_action_msgs,"The pr2_common_action_msgs package
"
W1708,https://wiki.ros.org/log4cpp,Wiki,log4cpp,"Log4cpp maintained by Orocos developers
    This version of log4cpp deviates from the official release
    by adding custom category factories. Orocos requires this for
    setting up real-time logging."
W1709,https://wiki.ros.org/play_motion,Wiki,play_motion,Plays a pre-recorded motion on a robot
W1710,https://wiki.ros.org/abb_irb2600_support,Wiki,abb_irb2600_support,"
      ROS-Industrial support for the ABB IRB 2600 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 2600 manipulators. This currently includes the IRB 2600-12/1.65
      (20/1.65). Variants listed in parenthesis may use the files of the
      preceding model.
    
      Joint limits and max joint velocities are based on the information in the
       (Version: ROB0142EN_B, October
      2010). All urdfs / xacros are based on the default motion and joint
      velocity limits, unless noted otherwise (ie: no support for high speed
      joints, extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1711,https://wiki.ros.org/khi_robot_bringup,Wiki,khi_robot_bringup,Package contains bringup scripts/config/tools for KHI Robot
W1712,https://wiki.ros.org/segbot_sensors,Wiki,segbot_sensors,"Contains sensor specific launch files and all the relevant filters that are
    applied on sensor data before being used by the segbot.

For UTexas BWI Segbot robots, an extension of the  package. Contains special-purpose the sensor and sensor filters launch files. See the . "
W1713,https://wiki.ros.org/rovio_ctrl,Wiki,rovio_ctrl,"The rovio_ctrl package contains nodes to control and query the motor and head position of a WowWee Rovio.







The  package contains nodes to control the movement of the Rovio. This includes control the movement of the base itself, as well as controlling the head (camera) position. Furthermore, joystick teleoperation is provided via the  node. To install the  stack, you can choose to either install from source, or from the Ubuntu package: The  package contains a  file which should be edited with the hostname, username and password to login to your Rovio. This file launches an instance of the  and  nodes. To launch these nodes, the following command can be used: The  package also contains a  file which should be edited with the hostname, username and password to login to your Rovio as well as absolute path to the  folder within the  package. This file launches an instance of the , ,  and   nodes. To launch these nodes, the following command can be used: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  rovio_ctrlrovio_teleoprovio_moveman_drvcmd_velgeometry_msgs/Twist/rovio_shared/host/rovio_shared/user/rovio_shared/passrovio_headhead_sensorhead_ctrl/rovio_shared/host/rovio_shared/user/rovio_shared/passrovio_teleopjoycmd_velrovio_movehead_ctrlrovio_headwav_playrovio_audio0124567joycmd_velhead_ctrl012wav_play.wav4567/rovio_shared/rovio_wavwav4567roviorovio_ctrlrovio_ctrl.launchrovio_moverovio_headrovio_ctrlrovio_teleop.launchwavrovio_moverovio_headrovio_audiorovio_teleop




sudo apt-get install ros-fuerte-rovioroslaunch rovio_ctrl rovio_ctrl.launchroslaunch rovio_ctrl rovio_teleop.launch"
W1714,https://wiki.ros.org/ros_opcua_communication,Wiki,ros_opcua_communication,"The ros_opcua_communication mate-package are ROS bidings for different open-source OPC-UA implementations. Currently following libraries are supported: FreeOpcUa and python-opcua.


Use GitHub to . []
 This stack provides communication interface between ROS and  communication standard. Currently there are two open-source OPC UA implementations supported  (C++) and  (Python). Clone your repository into folder of your ROS workspace using: Using  clone of the repository OPC UA libraries will be automatically downloaded. After that compile your workspace. "
W1715,https://wiki.ros.org/khi_duaro_description,Wiki,khi_duaro_description,The khi_duaro_description package
W1716,https://wiki.ros.org/motoman_robot_pkg_gen,Wiki,motoman_robot_pkg_gen,"The motoman_robot_pkg_gen package generates robot support packages that conform to the ROS-Industrial package specification.  http://wiki.ros.org/Industrial/Tutorials/SuggestedPackageLayoutNewRepositories
This package is part of the  program.  "
W1717,https://wiki.ros.org/segbot_description,Wiki,segbot_description,"Contains URDF descriptions of all robot components and sensors for the
    segbot, as well as all the different sensor configurations for a segbot. Contents The segbot_description package contains all the robot and component descriptions. This includes descriptions for: Since the BWI Segbot robot has configurable sensor types and locations, this package also includes all the top level configuration files that might be in use by the BWI project at this time. For every robot configuration provided in the package, suitable URDF code for Gazebo is provided: Full Gazebo Model () - including this xacro file provides relatively accurate collision entries for each link. This is similar to how collisions are typically setup in ROS. Simple Collision Model () - including this xacro file provides null collision models to each joint except for base_link. base_link has a collision of a cylinder roughly the size of the robot. This model does not allow a conventional differential driver controller in Gazebo, but is much faster computationally and better for multi-robot experiments. See  on how this robot is controlled. The layout of the package is as follows:  - Gazebo specific URDF descriptions. These are only read by the ROS wrapper for Gazebo  - Contains meshes for the Hokuyo URG 04LX and the Segway RMP 50\ The Segway RMP 50 mesh is based on the original mesh be user Jose Prado on Trimble 3D Warehouse.  to original model.  - Contains all various robot configurations. This folder contains all the top level URDF (Xacro) files that are processed outside this package.  - Contains a wrapper around xacro that produces the simple collision model instead of the full collision model. This is done as xacro itself does not accept parameters (see )  - Contains a simple script to visualize individual sensor mounts or the sensor configuration on the robot. Mostly used to test that the designs are correct before being used externally.  - The main component of this package. Contains all the main URDF resources.  - Chassis Components  - Individual sensors. These have been replicated from  because of small incompatibilities  - Our hand designed sensor mounts. "
W1718,https://wiki.ros.org/kinematics_exchanger,Wiki,kinematics_exchanger,"A package that exchanges kinematic properties such as velocity or position between multiple cyber physical systems (CPSs) in a swarm.

 (, default: 1)  (, default: ) 


The communication between CPSs is based on the . The following packages of the  are required: to launch the  node. In the  subdirectory there is the parameter file  that allows to configure the behavior of the  node. This work is supported by the European Commission through the  under grant no. 731946. kinematics_exchangeridintegeroutputstringscreenscreenlogparamkinematics_exchanger.yamlkinematics_exchangerkinematics_exchangerpos_provider/posevel_provider/velocitybridge/events/positionbridge/events/velocitypositionvelocityswarm_positionswarm_position_relswarm_velocity_rel~loop_ratereal~queue_sizeinteger~timeoutreal~sample_sizeinteger~initintegerroslaunch kinematics_exchanger kinematics_exchanger.launch"
W1719,https://wiki.ros.org/nao_interaction_msgs,Wiki,nao_interaction_msgs,Messages and services declarations for the nao_interaction metapackage
W1720,https://wiki.ros.org/asctec_hl_interface,Wiki,asctec_hl_interface,"

     Interfaces to the ""HighLevel"" Processor of the Ascending Technologies helicopters where fast IMU datafusion with arbitrary external position input and position control is executed at 1 kHz. 
     Furthermore, all relevant data as IMU, GPS and status can be accessed at configurable rates and baudrates.

  













 This package provides a ros interface to communicate with the High Level Processor (HLP) of the AscTec AutoPilot. Therefore, firmware for the HLP is needed which is provided in the  package. It does not work with the firmware shipped with the HLP! Using a wired connection is recommended, e.g. to the Ascending Technologies . The cable supplied with the AtomBoard can be used. Connect to the serial port 0 of the Highlevel Processor (""HL serial 0"") as shown in the AscTec  in chapter 4.1. In this case, set  to the correct port, and leave  and  empty.  If you plan to use a wireless serial link, it might be useful to use a dedicated link for each rx and tx for higher bandwidth. In that case, set  and  accordingly and leave  empty.  The baudrate at which the  communicates with the HLP can be set with the  parameter. If it doesn't match a supported standard baudrate, the closest standard baudrate is chosen. The HLP tries to detect the baudrate automatically at startup or if there wasn't any communication with the hl_node for longer than ~10 seconds.  sets up its serial port(s) with the desired baudrate and sends a packet ('a') which the HLP uses to detect the correct baudrate. In order for this to work, always switch on the HLP first, then start . In case you need to restart  with a different baudrate, you have to wait ~10 s until the HLP accepts new baudrate configure packets. Restarting with the same baudrate works immediately. Tested baudrates are: 57600, 115200, 230400, 460800, 921600.  Packet rates of certain packets can be configured with the  parameters. No polling is done - instead a configuration packet is sent to the HLP which will send the packets in the desired rate accordingly. Note that no checking is done if the packet rates exceed the available bandwidth, so check the correct rate with  In all operation modes, you can enable/disable control output to the LLP by setting the  parameters accordingly. This is helpful, e.g. to debug a controller on a single axis first. Directions and orientations follow the . As with the direct interface to the LLP, it only accepts commands when the serial enable switch is on. In failure, flip off this switch and put the flightmode switch to ""acc"". There are three modes you can operate the helicopter which you can select with the  parameter: Set  to ""off"". This mode just forwards roll, pitch, yaw (angular velocity) and thrust commands to the LLP. This is similar to directly send commands to the LLP's serial interface. Set the values in  in rad for roll and pitch, in rad/s for yaw and 0.0 ... 1.0 for thrust and set /type to ""acceleration"". For the scaling to work correctly, you need to set  and  to the values you can read out from the LLP with the AscTec control software (default 25, 120). Messages have to arrive at least at 10 Hz, otherwise nothing will be forwarded to the LLP.  yaw rates are limited to +- 85% so that the motors cannot be switched on/off accidentally in case of bad commands (motors idle, full yaw). Set  to ""GPS"" and set /type to ""velocity"" in your messages. Commands are also forwarded to the LLP, but the GPS bit is set additionally. The values in  correnspond to velocities in boady coordinates in m/s and rad/s respectively. For the scaling to work correctly, you need to set  according to the maximum ""stick-GPS"" velocites which you can read out from the LLP with the AscTec control software. Defaults are 5 m/s for x/y, and 2 m/s for z.      Messages have to arrive at least at 10 Hz, otherwise nothing will be forwarded to the LLP.  yaw rates are limited to +- 85% so that the motors cannot be switched on/off accidentally in case of bad commands (full descend rate, full yaw) This is the most interesting part and main motivation for this project. It is designed for position control based on position measurements from e.g. onboard visual SLAM with typically slow update rates. To deal with those delays, datafusion with IMU and position control is performed on the HLP at a rate of 1 kHz. Details on how the controller and datafusion work can be found in . To work with this mode, please go carefully through this . ~serial_port~serial_port_rx~serial_port_tx~serial_port_rx~serial_port_tx~serial_porthl_node~baudratehl_nodehl_nodehl_node~packet_rate_*~/enable_*~/position_control~/position_control~/k_stick~/k_stick_yaw~/position_control~/max_velocity_*fcu/controlfcu/posefcu/statefcu/ekf_state_infcu/imu_customfcu/imufcu/gpsfcu/rcdatafcu/statusfcu/debugfcu/current_posefcu/ekf_state_outfcu/motor_control~serial_port_rxstring~serial_port_txstring~serial_portstring~baudrateint~frame_idstring~k_stickint~k_stick_yawint~stddev_angular_velocitydouble~stddev_linear_accelerationdouble~packet_rate_imudouble~packet_rate_rcdouble~packet_rate_gpsdouble~packet_rate_ssdk_debugdouble~packet_rate_ekf_statedouble~enable_xbool~enable_ybool~enable_zbool~enable_yawbool~position_controlstr~state_estimationstr~max_velocity_xydouble~max_velocity_zdouble~max_velocity_yawdouble~min_pos_xdouble~min_pos_ydouble~min_pos_zdouble~max_pos_xdouble~max_pos_ydouble~max_pos_zdouble~ssdk/listen_on_tfbool~ssdk/tf_ref_frame_idstr~ssdk/tf_tracked_frame_idstr~ssdk/sendbool~ssdk/omega_0_xydouble~ssdk/omega_0_zdouble~ssdk/zeta_xydouble~ssdk/zeta_zdouble~ssdk/p<channel>doubleworldmav~ssdk/tf_ref_frame_id~ssdk/tf_tracked_frame_idfcu/waypoint/goalfcu/waypoint/resultfcu/waypoint/feedbackfcu/current_posefcu/waypoint/goalfcu/waypoint/resultfcu/waypoint/feedbackrostopic hz <topic> -w <expected rate>rosrun asctec_hl_interface plot_position_input [namespace]
#e.g.
rosrun asctec_hl_interface plot_position_input pelican"
W1721,https://wiki.ros.org/kobuki_safety_controller,Wiki,kobuki_safety_controller,"A controller ensuring the safe operation of Kobuki.

    The SafetyController keeps track of bumper, cliff and wheel drop events. In case of the first two,
    Kobuki is commanded to move back. In the latter case, Kobuki is stopped.
    
    This controller can be enabled/disabled.
    The safety states (bumper pressed etc.) can be reset. WARNING: Dangerous! 

This controller is usually used together with the minimal configuration of Kobuki or with apps on top, e.g.  and  navigation. Use github to  or . "
W1722,https://wiki.ros.org/kobuki,Wiki,kobuki,"Software for Kobuki, Yujin Robot's mobile research base.
Components of this stack:  : Automatic docking for Kobuki  : Publish bumpers and cliff sensors events as a pointcloud so navistack can use them  : Tutorial-related code  : URDF and Gazebo model description of Kobuki  : Keyboard teleoperation for Kobuki  : A ROS node wrapper for the kobuki driver  : Random walker demo controller for Kobuki  : Watches the bumper, cliff and wheel drop sensor to allow safe operation  : Set of tools to thoroughly test Kobuki's hardware 
Check out the  section to find out about installing and running Kobukibot. 
Use github to  or . Check  for more information! 
   /dev/kobuki"
W1723,https://wiki.ros.org/maggie_motor_controller,Wiki,maggie_motor_controller,"motor_controller node




This device supports all the drivers implemented in the  package.  $ roslaunch maggie_motor_controller arms_controller.launch robot:=maggie $ roslaunch maggie_motor_controller neck_controller.launch robot:=maggie"
W1724,https://wiki.ros.org/screenrun,Wiki,screenrun,"
      screenrun is a small tool that pushes commands into a screen window.
      Use \015 after a command for ENTER, i.e. executing it.
  

If  is passed, byobu is used instead of screen. A screen session named  is started and screen windows with the program  name are created, where the commands are entered. Usually the  parameter will come from a configuration or launch file. See this example as a reference: rosrun screenrun screenrun [b]-
    name: planner
    commands:
        - roscd tidyup_grasp_actions\015
        - roslaunch tidyup_grasp_actions continual-planning-tidyup-grasp-tuck.launch 
-
    name: dashboard
    commands:
        - rosrun pr2_dashboard pr2_dashboard\015"
W1725,https://wiki.ros.org/pr2_plugs,Wiki,pr2_plugs,"The pr2_plugs stack provides the low level actions for autonomously plugging the PR2 into a standard wall outlet.
   
  You need to install the 'pr2 plugs' stack of ROS (see ). On Ubuntu, this means: Follow the  tutorial.  $ sudo apt-get install ros-fuerte-pr2-plugsplugs_calibration_offset:
  y: 0.0
  z: 0.0 $ rosparam load /etc/ros/plugs/hw_calibration.yaml $ roslaunch pr2_plugs_actions  pr2_base_application.launch
 $ roslaunch pr2_plugs_actions  plug_actions.launch run_sim:=0  $ rosrun pr2_plugs_actions  app_plugin.py  $ rosrun pr2_plugs_actions  app_unplug.py"
W1726,https://wiki.ros.org/qb_device_control,Wiki,qb_device_control,"This package contains a device-independent control library for qbrobotics® devices.
 


This package is barely usable alone since it provides only the common features to be exploited and expanded in the derived packages (cf.  and ). controllersstring*_trajectory_controllernamespacestringmy_devicemy_device_controllers.yamlconfig/_controlpackage_prefixstringqb_deviceqb_device_controluse_controller_guibool~<namespaced_action_type>_trajectory_controller/follow_joint_trajectory/communication_handler/sync_nodessuccesstrue~namespaced_action_typestringdevice_foodevice_foo_trajectory_controller/follow_joint_trajectory~control_durationdouble~waypointslist of mapstimejoint_positionsjoint_positions"
W1727,https://wiki.ros.org/kuka_eki_hw_interface,Wiki,kuka_eki_hw_interface,"A ROS-Control hardware interface for use with KUKA EKI


This package is part of the  program. See the  page. This package has been tested with KR C4 controllers. See  for more information on how to configure it and setup the robot controller. "
W1728,https://wiki.ros.org/rqt_bag_exporter,Wiki,rqt_bag_exporter,"Export data (images, numerics) from a bag file to create CSV and video filesDocumentation is here:  "
W1729,https://wiki.ros.org/pr2_power_board,Wiki,pr2_power_board,"This provides a ROS node for the PR2 Power Board.
 controls with the PR2 power board.  The API below is for informational purposes only; it is not intended for use by anything other than , which is where you should look for power data. 


The  runs on the PR2 and controls the PR2 power board. The node regulates the main fan speed of the PR2 based on battery and power board temperature.  power_node2power_node2battery/server2/diagnostics~state~control2~control~sample_frequencyfloat~transition_frequencyfloat/diagnostics~state~control"
W1730,https://wiki.ros.org/rr_control_input_manager,Wiki,rr_control_input_manager,"Filter velocity commands by ensuring that message time stamps do not exceed given timeout thresholds.
 

 /cmd_vel/joy/cmd_vel/autodock/cmd_vel/move_base/joystick/cmd_vel/joystick/a_button/b_button/x_button/y_button/joystick/delay~max_vel_fwdfloat2.6~max_vel_turnfloat9.0~max_vel_flipperfloat1.4~default_drive_throttleinteger0.15~default_flipper_throttleinteger0.6~adjustable_throttlebooltrue"
W1731,https://wiki.ros.org/robot_setup_tf_tutorial,Wiki,robot_setup_tf_tutorial,The robot_setup_tf_tutorial packageThis package provides code for the  tutorial for the navigation stack. 
W1732,https://wiki.ros.org/kobuki_capabilities,Wiki,kobuki_capabilities,Kobuki's capabilities
W1733,https://wiki.ros.org/checkerboard_pose_estimation,Wiki,checkerboard_pose_estimation,"

     checkerboard_pose_estimation

   "
W1734,https://wiki.ros.org/motoman_sia10d_support,Wiki,motoman_sia10d_support," This package will be removed in ROS Kinetic. The configuration data and
      models included in this package can now be found in the motoman_sia_support
      package in ROS Jade.ROS-Industrial support for the Motoman SIA10D (and variants).
      This package contains configuration data, 3D models and launch files
      for Motoman SIA10D manipulators.
    
      
    
      Joint limits and maximum joint velocities are based on the information 
      found in the online 
      http://www.motoman.com/datasheets/sia10d.pdf
      All urdfs are based on the default motion and joint velocity limits, 
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1735,https://wiki.ros.org/khi_rs_description,Wiki,khi_rs_description,The khi_rs_description package
W1736,https://wiki.ros.org/sick_ldmrs_laser,Wiki,sick_ldmrs_laser,"A ROS driver for the SICK LD-MRS series of laser scanners.

Use GitHub to . []
  All documentation is on . "
W1737,https://wiki.ros.org/markov_decision_making,Wiki,markov_decision_making,"Markov Decision Making (MDM) is a ROS library for robot decision-making based on MDPs.
                This metapackage contains: the Markov Decision Making Library itself (mdm_library), 
                the auxiliary packages Predicate Manager (predicate_manager) and Topological Tools (topological_tools),
                and an example application of MDM (mdm_example)


 MDM helps you map between the abstract representations of ,  and  that are used in decision-theoretic frameworks, and the actual actuators and sensors of your robots. It also interprets your decision-making policies and lets you configure an appropriate run-time execution strategy. Note that . For that you can use ROS-independent toolboxes such as . But once you have a decision-theoretic policy, MDM helps you execute that policy on your robot. MDM has been used (and is being used) in several international research projects, including ; ; and . In the following sections, you can find a light technical description of MDM, and information on how to use the library for your own MDP-based applications. For a more in-depth look into MDM, you can also refer to . For an overview of the concepts underlying MDM, please see the page . You can find examples of how to implement each MDM layer in the . MDM is modular and meant to be flexible and easy to adapt to your own applications. You can find more information on various specialized use-cases of MDM in the page:  Q: 
 A: There are so many generalizations and variants of the MDP framework that it is virtually impossible to design a library that supports all of them out-of-the-box. Rather than trying to explicitly support all MDP variants, MDM gives you the building blocks that you can use (and adapt) to put together a decision-theoretic controller for your robot(s). The underlying motivation is much of the implementation work that goes into deploying a decision-theoretic control policy can be re-used across different robot applications, regardless of the particular MDP variant that you're using. However, if you adapt MDM to your own application, you're encouraged to contribute to the library with your own modifications, since that may help other users in the future. Feel free to contact us, in that case! Q: 
 A: Without going into a discussion as to why regular discretizations aren't a particularly good idea, note that as long as your state space is discrete and finite, then your states can be indexed by a fixed-length string of logical values (i.e. in binary). In other words, as long as you have enough predicates, you can represent any (finite) discrete state space. The  package is lightweight and designed to handle a very large number of predicates, if needed. If you really want a ""grid world""-like representation of your state space, you can either write a generic  predicate and instantiate it for each your cells, or use the pose_labeler package (included in topological_tools) together with a map of the environment in which each cell is uniquely colored. Q: 
 A: Although the default MDM State and Action Layers implicitly describe discrete state and action spaces, you can potentially use the same node layout, and implement a State Layer that outputs real-valued scalars or vectors; a Control Layer that maps that into a real-valued action, and an Action Layer that just maps those into actuator controls. We don't have any plans at this time to extend MDM by ourselves to continuously-valued domains, but if you're interested in doing so, please feel free to contact us. Q: 
 A: Yes, there is a (currently experimental) branch in the Git repository that already supports some of the most basic RL algorithms for MDPs (Q-learning, SARSA). "
W1738,https://wiki.ros.org/kobuki_random_walker,Wiki,kobuki_random_walker,"Random walker app for Kobuki 

  $ roslaunch kobuki_node minimal.launch $ roslaunch kobuki_random_walker random_walker_app.launch
 # or the safe version (using the kobuki_safety_controller)
 $ roslaunch kobuki_random_walker safe_random_walker_app.launch"
W1739,https://wiki.ros.org/navigation_tutorials,Wiki,navigation_tutorials,"Navigation related tutorials.

  "
W1740,https://wiki.ros.org/maggie_labjack,Wiki,maggie_labjack,"labjack node





This device supports all the drivers implemented in the  package. get_touch_sensorsget_voltageis_pluggedget_stateset_state $ roslaunch maggie_labjack labjack.launch robot:=maggie"
W1741,https://wiki.ros.org/rbcar_description,Wiki,rbcar_description,"The rbcar_description package
"
W1742,https://wiki.ros.org/aruco_ros,Wiki,aruco_ros,"The ARUCO Library has been developed by the Ava group of the Univeristy of Cordoba(Spain).
    It provides real-time marker based 3D pose estimation using AR markers."
W1743,https://wiki.ros.org/khi_rs007l_moveit_config,Wiki,khi_rs007l_moveit_config,An automatically generated package with all the configuration and launch files for using the khi_rs007l with the MoveIt! Motion Planning Framework
W1744,https://wiki.ros.org/maggie_navigation_config,Wiki,maggie_navigation_config,"navigation config files for Social Robot Maggie.


This package holds a number of common configuration files for the  and  nodes meant to be run in an application that requires global navigation with a pre-specified static map. It also contains navigation specific sensor configurations. In particular, it holds parameter settings for the , , and  components of the  node that are shared between many different configurations of the  stack run on the . launch/real/navigation_real.launchlaunch/simulation/navigation_simulation.launchlaunch/amcl.launchlaunch/move_base.launchlaunch/laser/hokuyo.launchlaunch/laser/sick.launchconfig/base_local_planner_params.yamlconfig/costmap_common_params.yamlconfig/global_costmap_params.yamlmove_base.launchconfig/initial_pose.yamlconfig/local_costmap_params.yamlmove_base.launch"
W1745,https://wiki.ros.org/pdu,Wiki,pdu,"Interface for the New Eagle Multiplex Power Distribution Module (MPDM)
    https://store.neweagle.net/product/multiplexed-power-distribution-module-mpdm/"
W1746,https://wiki.ros.org/qb_move_description,Wiki,qb_move_description,"This package contains the ROS description for qbrobotics® qbmove device.

This package contains the description resources for the  device. It includes the / model of the cube with its simplified meshes and its configuration setup. This launch file calls the template  with the default settings to visualize a  in  (and nothing more). roslaunch qb_move_description qb_move.launch"
W1747,https://wiki.ros.org/arni_rqt_detail_plugin,Wiki,arni_rqt_detail_plugin,The ARNI rqt_gui detail plugin.
W1748,https://wiki.ros.org/pr2_plugs_actions,Wiki,pr2_plugs_actions,"

     pr2_plugs_actions contains actions specific to plugging in the PR2 robot.

  
 "
W1749,https://wiki.ros.org/qb_move_control,Wiki,qb_move_control,"This package contains the ROS control node for qbrobotics® qbmove device.




This package contains the ROS control node and its structures to control the  device. It exploits the features provided by the base device-independent control library (cf. ) and the specific hardware interface (cf. ). The two launch files start a ROS node for the  respectively to control it through a GUI and through predefined configurable waypoints (stored in the ). In both cases the controllers setup can be found in the ; it is recommended not to change the default settings though. This launch file calls the template  with the default settings to bringup a full control node for the  based on GUI inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf.  to control several devices together). This launch file calls the template  with the default settings to bringup a full control node for the  based on waypoint inputs. It also starts the Communication Handler and therefore it is recommended not to start other driver nodes while using this one (cf.  to control several devices together). This control library specifically designed for the  extends the  and exploits the , therefore it provides all the ROS resources and requires all the specifications of this two base packages. config/qbmove_waypoints.yamlconfig/qbmove_controllers.yaml"
W1750,https://wiki.ros.org/mir_msgs,Wiki,mir_msgs,Message definitions for the MiR100 robot
W1751,https://wiki.ros.org/argos3d_p100,Wiki,argos3d_p100,"The argos3D P100 ROS package

.    














There is a new package () that uses the new  developed by Bluetechnix for interacting with their sensors. To get more information about the Time of Flight camera Argos3D P100 please visit Bluetechnix website:  The ' works with ROS versions groovy and hydro.  You can use catkin workspaces or the previous rosbuild to configure, compile and get ready ROS. ROS tutorial:  Be sure your libboost library version is >= 1.49. Previous versions as 1.46 generate errors while compiling argos3d_p100-ros-pkg. In Ubuntu/linux copy the file from the driver folder to  Clone from repository:  to your src/ folder in your catkin workspace and compile it with: argos3d_p100_ros_pkgcd driver 
sudo cp 10-pmd-ubuntu.rules /etc/udev/rules.d/#PMD camera support
/.../PMDSDK/bin
/.../PMDSDK/includeldconfigapt-get install ros-hydro-pcl-ros ros-hydro-pcl-conversions ros-hydro-perception-pclcd catkin_ws
source devel/setup.bash ## initialize search path to include local workspace
cd src/
git clone https://github.com/voxel-dot-at/argos3d_p100_ros_pkg.git
cd ..
catkin_makeroscore &cd catkin_ws
source devel/setup.bash
rosrun argos3d_p100 argos3d_p100_node Using help for argos3d_p100_ros_pkg
 You can set default configuration values for the camera with the following options:

 Usage:
 rosrun argos3d_p100 argos3d_p100_node
        -it *Integration_Time*
          Integration time(in msec) for the sensor
          (min: 100 | max: 2700 | default: 1500)
        -mf  *Modulation_Frequency*
          Set the modulation frequency(Hz) of the sensor
          (min: 5000000 | max: 30000000 | default: 30000000)
         -fr *Frame_Rate* 
          Set the frame rate of the camera by setting the Phase Time (Please be careful when setting values higher than 40 FPS without using an extra cooling system. The camera can stress by overheating and be damaged). 
          (min: 1 | max: 160 | default: 40)
         -flip_x *flip_x* 
          Flip images in the x coordinate. 
          (ON: if set | OFF: default)
         -flip_y *flip_y* 
          Flip images in the y coordinate. 
          (ON: if set | OFF: default)
        -bf *Bilateral_Filter*
          Turns bilateral filtering on or off
          (ON: if set | OFF: default)
        -af *Amplitude_Filter_On*
          Whether to apply amplitude filter or not. Image pixels with amplitude values less than the threshold will be filtered out
          (ON: if set | OFF: odefault)
        -at *Amplitude_Threshold*
          What should be the amplitude filter threshold. Image pixels with lesser aplitude values will be filtered out. Amplitude Filter Status should be true to use this filter
          (min: 0 | max: 2500 | default: 0)

 Example:cp argos3d.cal catkin_ws
cd catkin_ws
rosrun argos3d_p100 argos3d_p100_node rosrun rviz rvizrosrun rqt_reconfigure rqt_reconfigure"
W1752,https://wiki.ros.org/pr2_power_drivers,Wiki,pr2_power_drivers,"Power drivers for the PR2 robot.
 contains the drivers that control the PR2 power system.  You should look at  for reading the power state of the robot. 
Report new issues on  pr2_power_drivers"
W1753,https://wiki.ros.org/ainstein_radar_filters,Wiki,ainstein_radar_filters,"Filtering and data conversion utilities for radar data.




~radar_in~cloud_out~radar_in~scan_out~angle_minfloat~angle_maxfloat~angle_incrementfloat~time_incrementfloat~scan_timefloat~range_minfloat~range_maxfloat~radar_inradar_vel~radar_out~min_speed_threshfloat~max_speed_threshfloat~compute_3dbool~is_rotatedbool<the frame attached to incoming data>map~radar_in~radar_out~min_rangefloat~max_rangefloat~radar_in~nearest_target~nearest_target_array~data_lpf_alphafloat~data_lpf_timeoutfloat~radar_in~tracked~boxes~filter_update_rateint~filter_min_timefloat~filter_timeoutfloat~filter_val_gate_threshstring map"
W1754,https://wiki.ros.org/maggie_description,Wiki,maggie_description,maggie_description urdf filesThis package will contain the description of the  robot. 
W1755,https://wiki.ros.org/agvs_complete,Wiki,agvs_complete,"The agvs package. This package contains all the components to simulate the AGVS robot. An ackermann type robot intended for logistics transport.
"
W1756,https://wiki.ros.org/ar_tools,Wiki,ar_tools,"CCNY Computer Vision Stack

 
Please use this  to report bugs or request new features. 








"
W1757,https://wiki.ros.org/abb_irb52_support,Wiki,abb_irb52_support,"
      ROS-Industrial support for the ABB IRB 52 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 52 manipulators. This currently includes the 7/1.2 and
      7/1.45 variants.
    
      Joint limits and max joint velocities are based on the information in the
       All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1758,https://wiki.ros.org/asctec_mav_framework,Wiki,asctec_mav_framework,"Framework for data aquisition and position control to be used with the highlevel processor of Ascending Technologies helicopters The following commands will fetch and compile the  stack. Version 2012 depends on . Please refer to  for installation instructions. If rosmake fails it means that you have downloaded a catkin package. In this case follow the instructions for hydro or indigo. 



 



 


 This stack contains drivers, tools, a nonlinear position controller and imu data fusion for  MAVs equipped with the AutoPilot sensor board. In contrast to  which communicate directly to the low level processor of the AutoPilot board (which has some ), this framework is based on the user-programmable high level processor of the AutoPilot board. Features are: Update to be compatible with the 2012 HL SDK and LL Firmware. Currently available in the ""version2012"" branch (see installation instructions). , it will not work with the older versions. The state prediction part of a full EKF runs now on the HLP, which works together with . Not only the obvious states as attitude, position and velocity are estimated, but also IMU biases, (visual) scale of the position measurement (e.g. from ) and pose/position-sensor (e.g. camera) to imu calibration. Also, a yaw measurement is not necessary anymore since this can be estimated by the EKF. More detailed information can be found here: catkin_workspace/srcasctec_mav_framework~max_velocity_xy~max_velocity_z# Fetch asctec_mav_framework stack
git clone git://github.com/ethz-asl/asctec_mav_framework.git asctec_mav_framework

# only if you need to use the 2011 version:
git checkout -b version2011 refs/tags/version2011

# Update ROS_PACKAGE_PATH (if necessary)
export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:`pwd`/asctec_mav_framework

# build
rosmake asctec_mav_framework"
W1759,https://wiki.ros.org/psen_scan,Wiki,psen_scan,"The psen_scan package for Pilz laser scanner




Use GitHub to . []
 
For a list of supported devices please refer to our . For getting started quickly please see the . We created a set of  that walk you through integrating the Pilz safety laser scanner PSENscan into your existing application, or creating a completely new one. For example you can learn how to store your configurations permanently and how to start multiple scanners simultaneously. You need further information? Our international hotline staff will support you individually about our ROS packages at  or visit us at . "
W1760,https://wiki.ros.org/pr2_gazebo,Wiki,pr2_gazebo,"Launch scripts for simulating the PR2 in .
    The simulation equivalent of pr2.launch is found here.
    pr2_fingertip_pressure_contact_translator produces the same ROS topics as fingertip_pressure package for simulated PR2.







Spawn a simulated PR2, assuming that an instance of Gazebo is already up.  This launch file is normally not used directly, but rather included in another launch file, as in . This file is meant to mirror the behavior , which is used to bringup a physical PR2, including default controllers. The launch files in  are included by the higher-level launch files documented above.  The controller launch files themselves should be modified only be advanced users. The programs in  are for developer testing only. Please see the  guide for tips on how to debug issues with . pr2_empty_world.launch/pr2.launchpr2_gazebo/controllerspr2_gazebo/scriptspr2_gazebo"
W1761,https://wiki.ros.org/rcll_refbox_peer,Wiki,rcll_refbox_peer,"RCLL refbox communication adapter


This package contains nodes providing a ROS-based interface to interact with the  of the  which is also used in the . Please refer to the  package for the interface message types. rcll/beaconrcll/game_statercll/machine_inforcll/exploration_inforcll/machine_report_inforcll/order_inforcll/ring_inforcll/send_beaconrcll/send_machine_reportrcll/send_prepare_machine~team_namestring~robot_namestring~robot_numberint~crypto_keystring~crypto_cipherstring~peer_addressstring~peer_public_recv_port and ~peer_public_send_portint~peer_cyan_recv_port and ~peer_cyan_send_portint~peer_magenta_recv_port and ~peer_magenta_send_portint"
W1762,https://wiki.ros.org/pepper_dcm_bringup,Wiki,pepper_dcm_bringup,"Bring-up the dcm driver to control Pepper






To choose the controllers you want to load, modify pepper_control/launch/pepper_control_trajectory.launch. The list of implemented controllers, you can find in pepper_control/config/pepper_trajectory_control.yaml. You can start and stop the ros-controllers using the rqt plugin . sudo apt-get install ros-indigo-pepper-robot ros-indigo-pepper-meshescatkin_makeroslaunch pepper_dcm_bringup pepper_bringup.launch robot_ip:=<ROBOT_IP>roslaunch naoqi_driver naoqi_driver.launch nao_ip:=<ROBOT_IP>roslaunch pepper_moveit_config moveit_planner.launchrosrun actionlib axclient.py <name of the goal topic of the action server>rosrun actionlib axclient.py /pepper_dcm/LeftArm_controller/follow_joint_trajectory/goalroslaunch pepper_dcm_bringup pepper_dcm_bringup_position.launch robot_ip:=<ROBOT_IP>rostopic pub /pepper_dcm/HeadYaw_position_controller/command std_msgs/Float64 ""data: 1"""
W1763,https://wiki.ros.org/rospeex_webaudiomonitor,Wiki,rospeex_webaudiomonitor,"This package provides a browser-based waveform monitor of rospeex's (beta version).
    This package requires an external web browser: Google Chrome or Firefox."
W1764,https://wiki.ros.org/pepper_gazebo_plugin,Wiki,pepper_gazebo_plugin,"Gazebo plugin for Pepper robot
All documentation is written in the github page . "
W1765,https://wiki.ros.org/motoman_sia5d_support,Wiki,motoman_sia5d_support," This package will be removed in ROS Kinetic. The configuration data and
      models included in this package can now be found in the motoman_sia_support
      package in ROS Jade.ROS-Industrial support for the Motoman SIA5D (and variants).
      This package contains configuration data, 3D models and launch files
      for Motoman SIA5D manipulators.
    
      
    
      Joint limits and maximum joint velocities are based on the information 
      found in the online 
      http://www.motoman.com/datasheets/sia5d.pdf
      All urdfs are based on the default motion and joint velocity limits, 
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1766,https://wiki.ros.org/maggie_rfid_drivers,Wiki,maggie_rfid_drivers,"rfid drivers for Maggie robot

"
W1767,https://wiki.ros.org/microstrain_3dmgx2_imu,Wiki,microstrain_3dmgx2_imu,"A driver for IMUs compatible the microstrain 3DM-GX2 and 3DM-GX3 protocol. Includes 
    a heavily modified standalone driver pulled from the player distribution, 
    and a ROS node. 



 

While a  exists, it has not been reviewed and should be considered unstable. The 3DM-GX2 protocol can be found . imu_nodeimu/datadiagnosticsimu/is_calibrated~self_testimu/calibrateimu/is_calibratedimu/is_calibratedimu/calibrate~portstring~frame_idstring~autocalibrateboolfalse~orientation_stdevdouble~angular_velocity_stdevdouble~linear_acceleration_stdevdouble~max_drift_ratedouble~assume_calibratedbool"
W1768,https://wiki.ros.org/power_monitor,Wiki,power_monitor,"The power_monitor collects messages from the ocean_battery_server and
     the pr2_power_board, and publishes a summary of their data in a
     friendlier message format.

 takes data from  and  and republishes it in a more user-friendly message format. 
 () 
 () 
 (, default: 0.1) The estimation method that  uses is reconfigurable via . Two methods are currently available: power_monitorpower_monitor/var/ros/power_monitor/power.logbattery/server2power_board/power_statepower_state~frequencyfloatpower_state~estimation_methodstring~advanced_log_filestring~battery_update_timeoutdouble"
W1769,https://wiki.ros.org/rr_openrover_driver_msgs,Wiki,rr_openrover_driver_msgs,"The rr_openrover_driver_msgs package




This package contains the messages used to publish hardware data from the . std_msgs/Header header
std_msgs/int32 left_motor
std_msgs/int32 right_motor
std_msgs/int32 flipper_motorstd_msgs/Header header
std_msgs/int32 reg_pwr_total_current
std_msgs/int32 reg_motor_fb_rpm_left
std_msgs/int32 reg_motor_fb_rpm_right
std_msgs/int32 reg_flipper_fb_position_pot1
std_msgs/int32 reg_flipper_fb_position_pot2
std_msgs/int32 reg_motor_fb_current_left
std_msgs/int32 reg_motor_fb_current_right
std_msgs/int32 reg_motor_charger_state
std_msgs/int32 reg_power_a_current
std_msgs/int32 reg_power_b_current
std_msgs/int32 reg_motor_flipper_angle
std_msgs/int16 battery_current_a
std_msgs/int16 battery_current_bstd_msgs/Header header
std_msgs/int32 reg_motor_fault_flag_left
std_msgs/int32 reg_motor_temp_left
std_msgs/int32 reg_motor_temp_right
std_msgs/int32 reg_power_bat_voltage_a
std_msgs/int32 reg_power_bat_voltage_b
std_msgs/int32 reg_robot_rel_soc_a
std_msgs/int32 reg_robot_rel_soc_b
std_msgs/uint16 battery_mode_a
std_msgs/uint16 battery_mode_b
std_msgs/uint16 battery_temp_a
std_msgs/uint16 battery_temp_b
std_msgs/uint16 battery_voltage_a
std_msgs/uint16 battery_voltage_b
std_msgs/int32 buildnostd_msgs/Header header

std_msgs/bool over_charged_alarm
std_msgs/bool terminate_charge_alarm
std_msgs/bool over_temp_alarm
std_msgs/bool terminate_discharge_alarm
std_msgs/bool remaining_capacity_alarm
std_msgs/bool remaining_time_alarm

std_msgs/bool initialized
std_msgs/bool discharging
std_msgs/bool fully_charged
std_msgs/bool fully_discharged"
W1770,https://wiki.ros.org/pr2_controller_configuration,Wiki,pr2_controller_configuration,"Configuration files for PR2 controllers.This package contains YAML files that are used to configure the default controllers and the calibration controllers on the pr2. The package also contains a  file that configures, loads and starts the default controllers via . The default controllers are: These files are used in places such as  to instantiate the default PR2 controllers. For , a clone of this package with separate configuration is in . "
W1771,https://wiki.ros.org/khi_duaro_moveit_config,Wiki,khi_duaro_moveit_config,An automatically generated package with all the configuration and launch files for using the khi_duaro with the MoveIt! Motion Planning Framework
W1772,https://wiki.ros.org/agvs_gazebo,Wiki,agvs_gazebo,"The agvs_gazebo package. Launch files and worlds to run Gazebo.
"
W1773,https://wiki.ros.org/abb_irb120t_moveit_config,Wiki,abb_irb120t_moveit_config,"
      MoveIt package for the ABB IRB 120T.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 120T with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  page. "
W1774,https://wiki.ros.org/abb_irb1600_support,Wiki,abb_irb1600_support,"
      ROS-Industrial support for the ABB IRB 1600 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 1600 manipulators. This package includes the 6kg 1.2m
      version.  Package based on ABB Document ID: 3HAC023604-001, Rev M.
    
      Joint limits and max joint velocities are based on the information in
      the ABB data sheets.  All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1775,https://wiki.ros.org/nmea_comms,Wiki,nmea_comms,"The nmea_comms package provides helper nodes for transmitting and receiving
    the NMEA sentences.



This package provides nodes which enable bidirectional communication between socket (server) or serial devices and the  message type. This may be useful for a number of scenarios, including if you: Finally, the combination of a  connected directly to a  can create a tee, where a device's serial data is directly available to ROS, but also served over a socket such that a remote machine may listen to it via netcat. This is particularly valuable if your device has a proprietary Windows-only GUI, which you'd like to be able to use while the device is part of a running ROS system. An example of this usage is , which you can launch like so: Once running, you should see the output of your serial NMEA device on the  topic, as well as when running . serial_nodesocket_node/navsat/nmea_sentencenc localhost 29500nmea_sentence_outnmea_sentence~frame_idstring~portstring~baudintnmea_sentence_outnmea_sentence~frame_idstring~portintroslaunch nmea_comms tee.launch port:=<serial port> baud:=<baud rate>"
W1776,https://wiki.ros.org/purepursuit_planner,Wiki,purepursuit_planner,"The purepursuit_planner package. Planner to follow a list of waypoints implementing the Pure Pursuit algorithm.
"
W1777,https://wiki.ros.org/mrt_cmake_modules,Wiki,mrt_cmake_modules,"CMake Functions and Modules for automating CMakeUse GitHub to . []
  Imagine you whould never have to write a   file again. Never forget to install everything, no need to update it  whenever you add a file, not time lost for figuring out how to call and  use find_package for your dependencies, etc. For more information, please refer to the documentation  "
W1778,https://wiki.ros.org/artoolkit,Wiki,artoolkit,"
	     Artoolkit Library
	

 This is  packaged for a local ROS installation. This package is primarily to make it easier to install . More information about  can be found at their home page. In Ubuntu 11.04 and 11.10, you may encounter errors related to . A possible workaround is to patch the header files manually with: $ roscd artoolkit
$ sed -i 's,#include <linux/videodev.h>,#include <libv4l1-videodev.h>,g' ./build/artoolkit/include/AR/sys/videoLinuxV4L.h
$ sed -i 's,#include <linux/videodev.h>,#include <libv4l1-videodev.h>,g' ./build/artoolkit/lib/SRC/VideoLinuxV4L/video.c"
W1779,https://wiki.ros.org/arni_countermeasure,Wiki,arni_countermeasure,"The ARNI countermeasure node.






 The arni_countermeasure package provides the possibillity to define specific reactions when a ros environement is not behaving as defined with . Constraints are definitions of how  need to behave for a certain amount of time to trigger . They can be set as parameters withing the namespace /arni/countermeasure/constraints. A statement has to start with only one entry. Multiple statements can be combined with  and . Its possible to negate a statement with . Where expected_value can be , , ,  Additionally a  can be set. Only reactions with an autonomy_level <= config/reaction_autonomy_level get executed. seuid: { statistic_type: expected_value, another_s_type: another_value }arni:
  countermeasure:
    constraints:
      unique_constraint_name:
        constraint:
        - or:
            some_seuid: {
              cpu_usage_mean: high,
              node_bandwith_mean: low
              }
            another_seuid: {
              ram_usage_mean: high}
        min_reaction_interval: 5
        reaction_timeout: 20
        reactions:
          reaction_name: {
            action: stop,
            autonomy_level: 100,
            node: node1}
          another_reaction_name: {
            action: publish,
            autonomy_level: 13,
            message: node1 has a problem,
            node: node1,
            loglevel: info}
      another_constraint:
        constraint:
        - and:
            some_seuid: {
              node_bandwith_mean: unknown
            }
            another_seuid: {
              node_bandwith_max: ok 
            }
            not:
              third_seuid: {
                cpu_usage_mean: high 
              }
    config:
      reaction_autonomy_level: 50
      storage_timeout: 10"
W1780,https://wiki.ros.org/kinesis_manager,Wiki,kinesis_manager,"AWS Kinesis stream management library intended for use with the Kinesis Video Producer SDK


The kinesis_manager package is a library for interacting with Amazon Kinesis Video Streams. It is used by the  package. The source code is released under an . kinesis_video_streamer"
W1781,https://wiki.ros.org/kuka_kr150_support,Wiki,kuka_kr150_support,"
      ROS-Industrial support for the KUKA KR 150 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for KUKA KR 150 manipulators. This currently includes the -2 variant
      only.
    :
      Joint limits and maximum joint velocities are based on the information
      found in , version .
      All urdfs are based on the default motion and joint velocity limits,
      unless noted otherwise.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1782,https://wiki.ros.org/segway_rmp,Wiki,segway_rmp,"segway_rmp


 


There are several variations of Segway RMP's available, but only a few have been tested, if you would like to test one of the platforms or if you need a platform/feature that is not currently supported, . *  You could use  to install this stack (and potentially others at the same time) that way.  Here is an example  file: Once you have the stack in your ROS setup, you can build the  stack, by running: There is an older version of this ROS stack that was based on the drivers from .  If you would like to use those packages instead you can checkout their tag in git: The ROS nodes that interface with the RMP200 ATV and RMP400 used to be based on the  and  drivers from . I would appreciate anyone reporting bugs or requesting features by emailing me at . git clone git://github.com/wjwwood/segway-rmp-ros-pkg.git- git:
    uri: 'git://github.com/wjwwood/segway-rmp-ros-pkg.git'
    local-name: segway-rmp-ros-pkgrosinstall ~/path/to/install/into ~/path/to/segway-rmp-ros-pkg.rosinstall

roscd segway_rmp
git checkout iri_version"
W1783,https://wiki.ros.org/arni_msgs,Wiki,arni_msgs,"ARNI message types, i.e. host, node and rated statistics.









This page describes the message and service types used by arni. This information might be out of date, for recent data look here:  Contains an array of  for a node, host , or connection. Represents a single entry of the master API# ip of the host  
string host

# the statistics apply to this time window
time window_start
time window_stop

# cpu  
float32 cpu_temp_mean
float32 cpu_temp_stddev
float32 cpu_temp_max

float32 cpu_usage_mean
float32 cpu_usage_stddev
float32 cpu_usage_max

float32[] cpu_usage_core_mean
float32[] cpu_usage_core_stddev
float32[] cpu_usage_core_max

float32[] cpu_temp_core  
float32[] cpu_temp_core_mean
float32[] cpu_temp_core_stddev
float32[] cpu_temp_core_max


# gpu
float32[] gpu_temp_mean
float32[] gpu_temp_stddev
float32[] gpu_temp_max

float32[] gpu_usage_mean
float32[] gpu_usage_stddev
float32[] gpu_usage_max
 

# ram  
float32 ram_usage_mean
float32 ram_usage_stddev
float32 ram_usage_max
  
# network

string[] interface_name 
int32[] message_frequency_mean
int32[] message_frequency_stddev
int32[] message_frequency_max

# bandwith of each network interface

float32[] bandwidth_mean
float32[] bandwidth_stddev
float32[] bandwidth_max #ip of the host this node belongs to
string host

#identifier of this node
string node

# the statistics apply to this time window
time window_start
time window_stop

#CPU

float32 node_cpu_usage_mean
float32 node_cpu_usage_stddev
float32 node_cpu_usage_max

float32[] node_cpu_usage_core_mean
float32[] node_cpu_usage_core_stddev
float32[] node_cpu_usage_core_max


#GPU 

float32[] node_gpu_usage_mean
float32[] node_gpu_usage_stddev
float32[] node_gpu_usage_max

# ram  
float32 node_ramusage_mean
float32 node_ramusage_stddev
float32 node_ramusage_max
  
# network load of the node
 
float32 node_message_frequency_mean
float32 node_message_frequency_stddev
float32 node_message_frequency_max

float32 node_bandwidth_mean
float32 node_bandwidth_stddev
float32 node_bandwidth_max

# Drive I/O statistics of the node 

float32 node_write_mean
float32 node_write_stddev
float32 node_write_max

float32 node_read_mean
float32 node_read_stddev
float32 node_read_max # type of statistic like cpu_usage_core or cpu_usage
string statistic_type

# the value of the type
string[] actual_value

# the expected value like ""40 - 70""
string[] expected_value

# constant
uint8 HIGH=0
uint8 LOW=1
uint8 UNKNOWN=2
uint8 OK=3

# state of the metadata from the node/host/connection : 
# state: { 0 = high ; 1 = low ; 2 = unknown; 3 = ok}  
uint8[] state # name of node/host/connection 
string seuid

# only used if seuid is a node. is the host ip the node runs on.
string host  

# the rated statistics apply to statistics from this time window
time window_start
time window_stop

# an array of rated entities
RatedStatisticsEntity[] rated_statistics_entity string name
string[] content# publisher
MasterApiEntity[] pubs
# subscriber
MasterApiEntity[] subs
# services
MasterApiEntity[] srvs # identifier of the affected node
string node

# action  [restart, stop, command]
string action

# command (for action command)
string command
---
# message returned upon completion
string returnmessage# get all statistics where timestamp in ms is > than timestamp
time timestamp
---
# each statistic has its own rated statistic. 
# timestamps can be found at the time windows of each statistic

HostStatistics[] host_statistics
RatedStatistics[] rated_host_statistics

NodeStatistics[] node_statistics
RatedStatistics[] rated_node_statistics

rosgraph_msgs/TopicStatistics[] topic_statistics
RatedStatistics[] rated_topic_statistics"
W1784,https://wiki.ros.org/abb_irb1200_5_90_moveit_config,Wiki,abb_irb1200_5_90_moveit_config,"
      MoveIt package for the ABB IRB 1200-5/0.9.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 1200-5/0.9 with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  page. "
W1785,https://wiki.ros.org/ros_monitoring_msgs,Wiki,ros_monitoring_msgs,Messages for publishing monitoring data about ROS systems
W1786,https://wiki.ros.org/rosruby,Wiki,rosruby,"This package is a Ruby client library for ROS, the Robot Operating System. 





 Please refer to the  package and read the  page. For a more detailed reference, please consult the . sudo apt-get install ros-hydro-rosruby ros-hydro-rosruby-common ros-hydro-rosruby-messagessource ~/.bashrcsource /opt/ros/hydro/setup.bash"
W1787,https://wiki.ros.org/point_cloud_publisher_tutorial,Wiki,point_cloud_publisher_tutorial,The point_cloud_publisher_tutorial packageThis package provides code for the  tutorial for the navigation stack. 
W1788,https://wiki.ros.org/livox_ros_driver,Wiki,livox_ros_driver,"The ROS device driver for Livox 3D LiDARs and Livox Hub
 format: 


Email:  ROS packages for Livox 3D LiDARs. This driver provides the measurement data as  or Livox defined cloudpoint data. <dev@livoxtech.com>Header header             # ROS standard message header
uint64 timebase           # The time of first point
uint32 point_num          # Total number of pointclouds
uint8  lidar_id           # Lidar device id number
uint8[3]  rsvd            # Reserved use
CustomPoint[] points      # Pointcloud datauint32 offset_time      # offset time relative to the base time
float32 x               # X axis, unit:m
float32 y               # Y axis, unit:m
float32 z               # Z axis, unit:m
uint8 reflectivity      # reflectivity, 0~255
uint8 line              # laser number in lidar"
W1789,https://wiki.ros.org/arni_processing,Wiki,arni_processing,"The ARNI processing node, which rates statistics against their specifications.



: If a measured value returns an array (for example bandwidth_max for multiple network adapters) you can give an array of such limits. If you receive more values than you defined limits, spare values will be rated as . If you don't give an array of limits, the given limit will be used for each value. 




The monitoring node retrieves data on the topics ,  and . It then rates them according to specifications stored in the parameter namespace . The resulting data are published on the topic . For parameters shared across the arni packages see . The processing node rates the incoming statistics based on given specifications. They are read from the namespace . There you might give your desired specifications for a given seuid according to this format: You can pack these specifications as list items in one single list, which will then overwrite the whole list when you load several lists or add one more namespace block with the list like . The latter method allows you to selectively unset specification blocks. Learn more about the . Note that the measurement fields can be basically every field in the respective . See theses for comments on units. Additionally the field  determines when the specified item is regarded as ""dead"" (see above).  that this field expects a single number unlike the other fields! Usually the limits for a measurement are given as list with minimum and maximum value. If a third parameter is set as ""relative"", the limits will be calculated as  etc. Connections use the built-in . /statistics/statistics_node/statistics_host/arni/specifications/statistics_rated/statistics/arni/specifications/arni/specifications/logical_unit1 = [], /arni/specifications/logical_unit2 = []alive_timerminvalue = value * (1 - deviation)- n!example_node: # a seuid
    measurement1: [minvalue, maxvalue]
    # or
    measurement2: [value, deviation, ""relative""]cpu_temp_mean (float32)
cpu_temp_stddev (float32)
cpu_temp_max (float32)

cpu_usage_mean (float32)
cpu_usage_stddev (float32)
cpu_usage_max (float32)

cpu_usage_core_mean (float32[])
cpu_usage_core_stddev (float32[])
cpu_usage_core_max (float32[])

cpu_temp_core_mean (float32[])
cpu_temp_core_stddev (float32[])
cpu_temp_core_max (float32[])

gpu_temp_mean (float32[])
gpu_temp_stddev (float32[])
gpu_temp_max (float32[])

gpu_usage_mean (float32[])
gpu_usage_stddev (float32[])
gpu_usage_max (float32[])

ram_usage_mean (float32)
ram_usage_stddev (float32)
ram_usage_max (float32)

message_frequency_mean (int32[])
message_frequency_stddev (int32[])
message_frequency_max (int32[])

bandwidth_mean (float32[])
bandwidth_stddev (float32[])
bandwidth_max (float32[])node_cpu_usage_mean (float32)
node_cpu_usage_stddev (float32)
node_cpu_usage_max (float32)

node_cpu_usage_core_mean (float32[])
node_cpu_usage_core_stddev (float32[])
node_cpu_usage_core_max (float32[])

node_gpu_usage_mean (float32[])
node_gpu_usage_stddev (float32[])
node_gpu_usage_max (float32[])

node_ramusage_mean (float32)
node_ramusage_stddev (float32)
node_ramusage_max (float32)
 
node_message_frequency_mean (float32)
node_message_frequency_stddev (float32)
node_message_frequency_max (float32)

node_bandwidth_mean (float32)
node_bandwidth_stddev (float32)
node_bandwidth_max (float32)

node_write_mean (float32)
node_write_stddev (float32)
node_write_max (float32)

node_read_mean (float32)
node_read_stddev (float32)
node_read_max  (float32)delivered_msgs (int32)
dropped_msgs (int32)
traffic (int32)
bandwidth (int32) # normalized traffic
period_mean (duration)
period_stddev (duration)
period_max (duration)
stamp_age_mean (duration)
stamp_age_stddev (duration)
stamp_age_max (duration)delivered_msgs (int32)
dropped_msgs (int32)
packages (int32) # number of packages included in the aggregation
packages_per_second (float32) # packages normalized over their timespan
traffic (int32)
bandwidth (float32) # normalized traffic
frequency (float32)
stamp_age_mean (duration)
stamp_age_stddev (duration)
stamp_age_max (duration)"
W1790,https://wiki.ros.org/arni,Wiki,arni,"Metapackage for Advanced Ros Network Introspection.
 





 
 
 
  
 Make sure you have the minimum required ROS Version for statistics. arni shell output and debug messages will tell you if there is any problem on the current host. On remote hosts you have to check their log as well.   This may be due to many different problems. Make sure the host really sends data and that the values in the GUI are changing. If this is the case it might be that the remote host is sending data too seldomly. Currently we do not interpolate between two data points, which means, if the host sends data every ten seconds and the graph show only 10 seconds the graph will move out of range immediately.  The solution is updating the time range, e.g. to 30 seconds.   Advanced ROS Network Introspection (ARNI) extends the  features introduced with Indigo and completes the collected data with measurements about the hosts and nodes participating in the network. These are gathered from an extra node that has to run on each host machine. All statistics or metadata can be compared against a set of reference values using the . The rated statistics allow to run optional  when a deviation from the reference is detected, in order to remedy the fault or at least bring the system in a safe state. All data can be displayed and monitored through new . a) Publishing  data for topics and connections.  Publishing /statistics_host and /statistics_node data.  Comparing actual values to a YAML specification (d) and publishing /statistics_rated.  Automatically acting on rated data, given a YAML countermeasure file (f). g) ARNI rqt_gui to visualize current state of ROS network. h) rqt_gui Node Graph showing /statistics data. If you have any further questions / issues / ideas do not hesitate to either use   or to  the current maintainer directly. Get the latest version from our  repository: The message types can be founde here:  (Note: may be deprecated, see in source code for most recent information. The package arni_msgs contains all needed information). Several Tutorials have been written to ease the use of ARNI. They can be found here:   If you ran into any other problems (and maybe also found a solution?) send us a mail or post it on ! ros-indigo-desktop-fullpipcd ~/catkin_ws/src
git clone https://github.com/ROS-PSE/arni.git
cd ..
catkin_makepip install --user --upgrade psutil
pip install --user pysensors
pip install --user pyqtgraph@Inbook{Bihlmaier2016,
author=""Bihlmaier, Andreas and Hadlich, Matthias and W{\""o}rn, Heinz"",
editor=""Koubaa, Anis"",
chapter=""Advanced ROS Network Introspection (ARNI)"",
title=""Robot Operating System (ROS): The Complete Reference (Volume 1)"",
year=""2016"",
publisher=""Springer International Publishing"",
pages=""651-670"",
isbn=""978-3-319-26054-9"",
doi=""10.1007/978-3-319-26054-9_25"",
url=""http://dx.doi.org/10.1007/978-3-319-26054-9_25""
}

@inproceedings{bihlmaier14arni,
  title = {Increasing ROS Reliability and Safety Through Advanced Introspection Capabilities},
  author = {Bihlmaier, Andreas and W{\""o}rn, Heinz},
  booktitle = {Proceedings of the INFORMATIK 2014},
  pages = {1319--1326},
  year = 2014
}"
W1791,https://wiki.ros.org/abb_irb7600_support,Wiki,abb_irb7600_support,"
      ROS-Industrial support for the ABB IRB 7600 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 7600 manipulators. This currently includes the 150/3.50
      variant only.
    
      Joint limits and max joint velocities are based on the information in the
      . All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1792,https://wiki.ros.org/rqt_paramedit,Wiki,rqt_paramedit,"rqt_paramedit - a rqt plugin for editing parameters using qt_paramedit.
 Note: This package replaces groovy's  in hydro. "
W1793,https://wiki.ros.org/rr_openrover_stack,Wiki,rr_openrover_stack,"Packages related to the operation of Rover Robotics rover hardware.  This includes a client
    for interfacing with the hardware (rr_openrover_driver) and a tool for filtering time stamped
    velocity commands (rr_control_input_manager).


 The rr_openrover_stack is a collection of software needed to operate the Rover Robotics  platform. It provides driver support for serial communication between compute hardware and the  platform, as well as support for remote control using Xbox 360 controllers.  This includes all the software required for use of the  with the . sudo apt-get install ros-kinetic-rr-openrover-stack"
W1794,https://wiki.ros.org/abb_irb1600_6_12_moveit_config,Wiki,abb_irb1600_6_12_moveit_config,"
      MoveIt package for the ABB IRB 1600-6/1.2.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 1600-6/1.2 with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  page. "
W1795,https://wiki.ros.org/abb_irb6650s_support,Wiki,abb_irb6650s_support,"
      ROS-Industrial support for the ABB IRB_6650S (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB_6650S manipulators. This currently includes the base model.
    
      Joint limits and max joint velocities are based on the information in the
       All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1796,https://wiki.ros.org/abb_irb120_moveit_config,Wiki,abb_irb120_moveit_config,"
      MoveIt package for the ABB IRB 120.
    
      An automatically generated package with all the configuration and launch
      files for using the ABB IRB 120 with the MoveIt Motion Planning
      Framework.
    

This package is part of the  program.  See the  page. "
W1797,https://wiki.ros.org/abb_irb6700_support,Wiki,abb_irb6700_support,"
      ROS-Industrial support for the ABB IRB 6700 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 6700 manipulators. This currently includes the 200/2.60 and
      235/2.65 variants.
    
      Joint limits and max joint velocities are based on the information in the
       All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1798,https://wiki.ros.org/abb_irb1200_support,Wiki,abb_irb1200_support,"
      ROS-Industrial support for the ABB IRB 1200 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 1200 manipulators. This currently includes the IRB 1200-5/0.9
      and the IRB 1200-7/0.7 variants.
    
      Joint limits and max joint velocities are based on the information in the
      , document ID: .
      All urdfs / xacros are based on the default motion and joint velocity
      limits, unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Note 1: inertial and dynamics values for the 5/0.9 variant were calculated
      from the meshes using , assuming constant density.
      As the datasheet only provides the mass of the entire robot,
      the mass of each link was estimated based on its volume, assuming
      constant density for the entire robot.
    
      Note 2: maximum joint effort values for the 5/0.9 variant do not
      correspond to real world limits of the robot. The current values were
      chosen to accomodate Gazebo simulations of this specific variant but
      are fictional values.
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1799,https://wiki.ros.org/rr_openrover_driver,Wiki,rr_openrover_driver,"Provides an interface between ros and Rover Robotics rover hardware. Inputs to rr_openrover_driver
    include emergency stop and velocity commands.  It outputs diagnostic data such as encoder
    readings and battery charge. 






 This code is for those working with the Rover Robotics . The  communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. /cmd_vel/managed/rr_openrover_driver/fan_speed/rr_openrover_driver/soft_estop/enable/rr_openrover_driver/soft_estop/reset/rr_openrover_driver/odom_encoder/rr_openrover_driver/raw_fast_rate_data/rr_openrover_driver/raw_med_rate_data/rr_openrover_driver/raw_slow_rate_data/rr_openrover_driver/battery_status_a/rr_openrover_driver/battery_status_b~use_legacyboolfalse~portstring""/dev/ttyUSB0""~enable_timeoutbooltrue~timeoutfloat0.5~drive_typestring""4wd""~total_weightfloat20.0~traction_factorfloatdepends on drive type chosen~odom_covariance_0float0.01~odom_covariance_35float0.03roslaunch rr_openrover_driver example.launchrostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_a
rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_bmanaged_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)
managed_control_input.header.stamp = rospy.Time.now()
managed_control_input.header.frame_id = 'none'
managed_control_input.twist.linear.x=0.0
managed_control_input.twist.angular.y=0.0
managed_control_input.twist.angular.z=0.5
managed_pub.publish(managed_control_input)rosrun rr_openrover_driver openrover_driver_node<launch>
    <arg name=""openrover_node_name"" default=""rr_openrover_driver""/>

    <!-- OpenRover Driver -->
    <node pkg=""rr_openrover_driver"" type=""openrover_driver_node"" name=""$(arg openrover_node_name)"" respawn=""false"" output=""screen"">
        <param name=""port"" value=""/dev/rover"" />
        <param name=""drive_type"" value=""4wd"" />
        <param name=""enable_timeout"" type=""bool"" value=""true""/>
        <param name=""timeout"" type=""double"" value=""0.3""/>
        <param name=""total_weight"" type=""double"" value=""20.41""/>
        <param name=""traction_factor"" value=""0.610""/>
        <param name=""odom_covariance_0"" value=""0.01""/>
        <param name=""odom_covariance_35"" value=""0.03""/>
    </node>

    <!-- OpenRover Diagnostics -->
    <node pkg=""rr_openrover_driver"" type=""diagnostics.py"" name=""rr_openrover_diagnostics_node"">
        <remap from=""/raw_slow_rate_data"" to=""/$(arg openrover_node_name)/raw_slow_rate_data""/>
    </node>
</launch>slow_rate_pub"
W1800,https://wiki.ros.org/kobuki_node,Wiki,kobuki_node,ROS nodelet for Kobuki: ROS wrapper for the Kobuki driver. ~commands/motor_power~commands/external_power~commands/reset_odometry~commands/sound~commands/led1~commands/led2~commands/digital_output~commands/velocityodomdiagnosticsjoint_states~events/button~events/bumper~events/cliff~events/wheel_drop~events/power_system~events/robot_state~events/digital_input~sensors/imu_data~sensors/imu_data_raw~sensors/dock_ir~sensors/core~version_info~device_portstring/dev/kobuki~wheel_left_joint_namestringwheel_left_joint~wheel_right_joint_namestringwheel_right_joint~battery_capacitydouble16.5~battery_lowdouble13.5~battery_dangerousdouble13.2~cmd_vel_timeoutdouble0.6~publish_tfboolFalse~odom_framestring~base_framestring~acceleration_limiterbool~commands/motor_power~commands/external_power~commands/reset_odometry~commands/sound~commands/led1~commands/led2~commands/digital_output~commands/velocity~commands/controller_infoodomdiagnosticsjoint_states~events/button~events/bumper~events/cliff~events/wheel_drop~events/power_system~events/robot_state~events/digital_input~sensors/imu_data~sensors/imu_data_raw~sensors/dock_ir~sensors/core~version_info~controller_info~debug/raw_data_stream~debug/raw_data_command~debug/raw_control_command~device_portstring/dev/kobuki~wheel_left_joint_namestringwheel_left_joint~wheel_right_joint_namestringwheel_right_joint~battery_capacitydouble16.5~battery_lowdouble13.5~battery_dangerousdouble13.2~cmd_vel_timeoutdouble0.6~publish_tfboolFalse~use_imu_headingboolTrue~odom_framestring~base_framestring~acceleration_limiterbool
W1801,https://wiki.ros.org/abb_irb120_gazebo,Wiki,abb_irb120_gazebo,"
      ROS-Industrial Gazebo support package for the ABB IRB 120 (and variants).
    
      This package contains the configuration data and launch files required
      to simulate the ABB IRB 120 manipulator in Gazebo. This includes the base
      model and the 120T.
    
      Before using any of the configuration files included in this package, be
      sure to check they are correct for the particular robot model and
      configuration you intend to use them with.
    

This package is part of the  program.  See the  page. "
W1802,https://wiki.ros.org/simple_navigation_goals_tutorial,Wiki,simple_navigation_goals_tutorial,The simple_navigation_goals_tutorial package The code in this package does not match the current version of the tutorial. This package provides the code for the  tutorial for the navigation stack. 
W1803,https://wiki.ros.org/abb_irb4600_support,Wiki,abb_irb4600_support,"
      ROS-Industrial support for the ABB IRB 4600 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 4600 manipulators. This currently includes the 20/2.50, the
      40/2.55 and the 60/2.05 variants.
    
      Joint limits and max joint velocities are based on the information in the
      , .
      All urdfs / xacros are based on the default motion and joint velocity
      limits, unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    


: the Webots integration shown here is provided by Cyberbotics and does not use the models provided by the  package. Please contact Cyberbotics for support and usage related questions of this simulation.  This package is part of the  program. See the  page. A  simulation model is available for the ABB IRB4600 arm with a . abb_irb4600_support"
W1804,https://wiki.ros.org/asctec_hl_comm,Wiki,asctec_hl_comm,"

     This Package contains header files for communication with the HL controller on the AscTec AutoPilot and custom message, server, and action definitions 

  "
W1805,https://wiki.ros.org/lanelet2_core,Wiki,lanelet2_core,Lanelet2 core module
W1806,https://wiki.ros.org/remote_rosbag_record,Wiki,remote_rosbag_record,The remote_rosbag_record package
W1807,https://wiki.ros.org/schunk_lwa4p_extended,Wiki,schunk_lwa4p_extended,schunk_lwa4p_extended
W1808,https://wiki.ros.org/robot_upstart,Wiki,robot_upstart,"The robot_upstart package provides scripts which may be used to install
    and uninstall Ubuntu Linux upstart jobs which launch groups of roslaunch files.

Please see usage and docs here:  "
W1809,https://wiki.ros.org/manipulator_h_gui,Wiki,manipulator_h_gui,"The manipulator_h_gui package
    This package provides simple GUI to control ROBOTIS MANIPULATOR-H.
    This GUI is connected to manipulator_h_base_module. 


 robotis/statusrobotis/base/ini_pose_msgrobotis/base/set_mode_msgrobotis/base/joint_pose_msgrobotis/base/kinematics_pose_msgrobotis/base/get_joint_poserobotis/base/get_kinematics_pose"
W1810,https://wiki.ros.org/robotino_description,Wiki,robotino_description,"The robotino_description package


The  package contains xacro files and meshes required to create a urdf model of Robotino. This urdf file is used by the  package to broadcast transforms and also by  for visualization. If the xacro files are modified, then the  would have to updated as well. This can be done by running the following command from the  directory. robotino.urdfrobotino_description/urdfrosrun xacro xacro.py robotino.urdf.xacro > robotino.urdf"
W1811,https://wiki.ros.org/slam6d_exporter,Wiki,slam6d_exporter,"slam6d_exporter package

Use GitHub to . []
  For installation instructions, see . "
W1812,https://wiki.ros.org/ros_explorer,Wiki,ros_explorer,"A web interface for exploring the ROS graph
 is a web-based utility for browsing the ROS graph.  

This will create a server that serves the website on . It should also open the webpage in your default web browser automatically (using the xdg-open command). If this does not work, you can just visit  manually. ros_explorersudo apt-get install ros-indigo-rosbridge-serversudo apt-get install ros-indigo-ros-explorer# If you do not already have a websocket server running:
roslaunch ros_explorer ros_explorer_websocket.launch

# If you are already running a websocket server for other purposes:
roslaunch ros_explorer ros_explorer.launch"
W1813,https://wiki.ros.org/rocon_console,Wiki,rocon_console,"Command line python console utilities (mostly for colourisation).


  







"
W1814,https://wiki.ros.org/rh_p12_rn,Wiki,rh_p12_rn,"ROS messages packages for the ROBOTIS RH-P12-RN (meta package) 
 



"
W1815,https://wiki.ros.org/rosmake,Wiki,rosmake,"rosmake is a ros dependency aware build tool which can be used to
     build all dependencies in the correct order. is a tool to assist with building ROS .  It facilitates building packages that have dependencies.  will determine 's dependencies (and the dependencies' dependencies, etc.), and will ensure that all dependencies are built prior to building . 
 runs recursively on the dependencies of the given package(s), eventually running  on a each one.  After all dependencies are built,  will build the given package(s).  If no package is given, it will try to build the current directory, which must contain a . 
  

 will skip packages with  in the root of the package. 
 will skip packages with a file  in the root of the package if the option --skip-blacklist is enabled. 
 ROS comprises a large number of packages.  However, with the exception of some core packages that everything else depends on, e.g.,  and , many of the packages are largely independent.  As such, we have provided a  to allow you to only build what is actually necessary to run the packages that you want to run. A package may depend on any number of other packages, requiring that those packages be built first.  These dependencies are specified in the package's  file.  However, it would be inconvenient to make you go and look at the dependencies for your package, and then in turn look at the dependencies for those packages and so on.  Instead, we provide  to do the ROS-wide build of everything you need for a given package. For example, to build the  package, you can simply run: If rosmake fails, there is a good chance you are missing  for one or more of the packages you are trying to install. NOTE: you can run  from anywhere, as it uses  to locate packages. If you really just want to build a package, and you know that its dependencies are up-to-date, you just type  in that package's top-level directory. You  run  multiple times simultaneously on one machine, unless you are sure that the builds don't share any dependencies.  You may end up building the same package simultaneously, which can cause various problems. Options available in ROS Electric and earlier: There are two parallelization options within : You can modify the behavior of  by placing files with special names in your directory tree. These file names and their associated behaviors are described below. If the options  only packages which declare the detected OS in their manifest (as demonstrated below) will be built. rosmakerosmakemove_baserosmakemove_basemove_baserosmakerosmakerosmakemakerosmakerosmakeparallel threadsrosmakeparallel jobsrosmakeROS_PARALLEL_JOBS-jNNrosmakerosmakeROS_NOBUILDrosmakeROS_BUILD_BLACKLIST--require-platform--require-platform-recursive$ rosmake move_baseUsage: rosmake [options] [PACKAGE]...

Options:
  -h, --help            show this help message and exit
  --test-only           only run tests
  -t                    build and test packages
  -a, --all             select all packages
  -i, --mark-installed  On successful build, mark packages as installed with
                        ROS_NOBUILD
  -u, --unmark-installed
                        Remove ROS_NOBUILD from the specified packages.  This
                        will not build anything.
  -v                    display errored builds
  -r, -k, --robust      do not stop build on error
  --build-everything    build all packages regardless of errors
  -V                    display all builds
  -s, --specified-only  only build packages specified on the command line
  --buildtest=BUILDTEST
                        package to buildtest
  --buildtest1=BUILDTEST1
                        package to buildtest1
  --output=OUTPUT_DIR   where to output results
  --pre-clean           run make clean first
  --bootstrap           Do the bootstrap packages even if there are no
                        arguments
  --disable-logging     turn off all logs
  --target=TARGET       run make with this target
  --pjobs=ROS_PARALLEL_JOBS
                        Override ROS_PARALLEL_JOBS environment variable with
                        this number of jobs.
  --threads=THREADS     Build up to N packages in parallel
  --profile             print time profile after build
  --skip-blacklist      skip packages containing a file called
                        ROS_BUILD_BLACKLIST (Default behavior will ignore the
                        presence of ROS_BUILD_BLACKLIST)
  --skip-blacklist-osx  deprecated option. it will do nothing, please use
                        platform declarations and --require-platform instead
  --require-platform    do not build a package unless it is marked as
                        supported on this platform
  --require-platform-recursive
                        do not build a package unless it is marked as
                        supported on this platform, and all dependents are
                        also marked
  --status-rate=STATUS_UPDATE_RATE
                        How fast to update the status bar in Hz.  Default: 5Hz  --rosdep-install      call rosdep install before running
  --rosdep-yes          call rosdep install with default yes argument
  --no-rosdep           disable the default check of rosdep<platform os=""ubuntu"" version=""9.10""/>"
W1816,https://wiki.ros.org/manipulator_h_description,Wiki,manipulator_h_description,"The manipulator_h_description package
    This package includes URDF model of ROBOTIS MANIPULATOR-H.
    Additionally, we provide full kinematics and dynamics information of each link. 
 "
W1817,https://wiki.ros.org/report_card,Wiki,report_card,"This package extends functionality of KnowRob system with robot's *log analysis*, *data extraction* and *report card generation*.

 








 The  is a CRAM package that extends  system and  environment with functionality of generating a PDF file that contains easy to read (e.g. pie charts, bar charts, tables) robot experiment statistics. Alternative version of this guide is available . This package is based on  and its interpreter - the main log analysis and computations are done therein.   Once the data is prepared part of it is passed to  via  interface where its processed and needed graphs are prepared.  is also used to store statistics and dump them into CSV and RData formats for easy post-processing. Then, links to prepared figures and log statistics are passed via JPL to  where they are prepared and injected into selected LaTeX templates with use of  . Finally, the same library is used to generate a PDF based on prepared tex files. For details please refer to below figure. To make the package the most universal the report card generation is based on two key concepts  and . This approach allows the user to choose the design of the report card and decide which sections should be placed within. Moreover, this design facilitates creating personalised section and including them in the report card without complex code alterations and rebuilding the whole package - see below. This templates specify overall design of the report card - please see  for an example. The most important part of it are  statements which include specified in  sections. The default layout allows up to 10 sections. Section templates specify the structure of each section in the document - please see  for an example. There are 4 different types of variables that can be used in each section: To add your custom section to the report card please create a file named  in the  directory. Use the arguments naming as described above - the order of the arguments is based on the order used in the  call done within .   To generate your section from within  add a new predicate to  file: Where  is path to the temporary directory of current report card;  is the section name (it MUST contain the exact name you gave to your section file without  extension),  and  are as described above and of type  and finally,  and  are as described above and of type . If you have no data of specific type to be passed to the section creator you should generate empty array for the first two types e.g.  and empty array of arrays for latter two types e.g. .   To alter current generator please append your section to  predicate as follows: If you prefer to create custom report card generator first add type predicate to the already existing list:  and then create custom loader for created type: To manually generate the report card (using  shell) please use the following sequence: Before generating a report card remember to load the data e.g. ! To perform statistical computations R is accessed via  interface in Prolog. As a rough guide please see the example shown below. For details please refer to this . Any section contributions are welcomed, please make a pull request with you custom  predicates,  declarations,  and all additional predicates extending .   Please document all your code and wrap it between  and . report_cardPrologRrealRJavareport_card/report_card/tex_templates/reportCard.tex\ifthenelse{ \equal{$section5}{} }{}{\input{$section5}}Prologreport_card/report_card/tex_templates/overview.texsection_name.texreport_card/report_card/tex_templatesJavaPrologPrologreport_card/prolog/report_card.plRcHomeOsSection.texStringsRawStringsSeqStringsRawSeqStringsjpl_new('[Ljava.lang.String;', 0, Strings)jpl_new('[[Ljava.lang.String;', 0, SeqStrings)generate_report_card(card_type(default))card_type(custom_card_type).Prologload_experiment('/home/ros/datasets/ds4/cram_log.owl').report_card.plgenerate_section_name(RcHomeOs, SectionPath) :-
  Section = 'section_name',

  code_to_get_all_statistics,

  jpl_datums_to_array([YourVariable1, YourVariable2], Strings),

  jpl_new('[Ljava.lang.String;', 0, RawStrings),

  jpl_datums_to_array([YourOtherVariable11, YourOtherVariable12], SeqStrings1),
  jpl_datums_to_array([YourOtherVariable21, YourOtherVariable22], SeqStrings2),
  jpl_datums_to_array([SeqStrings1, SeqStrings2], SeqStrings),

  jpl_new('[[Ljava.lang.String;', 0, RawSeqStrings),

  jpl_call( 'org.knowrob.report_card.Generator', section, [RcHomeOs, Section, Strings, RawStrings, SeqStrings, RawSeqStrings], SectionPath).generate_report_card(card_type(default)) :-
  % initialisation
  rc_temporary_directory(RcTempDir),
  create_directory(RcTempDir),
  prolog_to_os_filename(RcTempDir, RcHomeOs),

  % report card content
  generate_overview(RcHomeOs, Introduction),
  generate_actions(RcHomeOs, Actions),
  generate_statistics(RcHomeOs, Statistics),
  generate_failures(RcHomeOs, Failures),
  generate_summary(RcHomeOs, Summary),

  get_experiment_info(experimentId  , TrialId),

  %%%% custom content
  generate_section_name(RcHomeOs, CustomSection),
  jpl_datums_to_array([Introduction, Actions, CustomSection, Statistics, Failures, Summary], Strings),
  %%%%

  jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf),

  % data exporting and information outputting
  export_data(data_format(csv)),
  export_data(data_format(r)),
  write('Your report card is available at:\n'),
  write(RcPdf), !.generate_report_card(card_type(custom_card_type)) :-
  % initialisation
  rc_temporary_directory(RcTempDir),
  create_directory(RcTempDir),
  prolog_to_os_filename(RcTempDir, RcHomeOs),

  get_experiment_info(experimentId  , TrialId),

  % report card content
  generate_overview(RcHomeOs, Introduction),
  generate_actions(RcHomeOs, Actions),
  generate_statistics(RcHomeOs, Statistics),
  generate_failures(RcHomeOs, Failures),
  generate_summary(RcHomeOs, Summary),

  %%%% custom content
  generate_section_name1(RcHomeOs, Section1),
  generate_section_name2(RcHomeOs, Section2),
  generate_section_name3(RcHomeOs, Section3),
  jpl_datums_to_array([Section1, Section2, Section3], Strings),
  %%%%

  jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf),

  % data exporting and information outputting
  export_data(data_format(csv)),
  export_data(data_format(r)),
  write('Your report card is available at:\n'),
  write(RcPdf), !.rc_temporary_directory(RcTempDir), create_directory(RcTempDir), prolog_to_os_filename(RcTempDir, RcHomeOs), get_experiment_info(experimentId  , TrialId), generate_section_name1(RcHomeOs, Section1), generate_section_name2(RcHomeOs, Section2), generate_section_name3(RcHomeOs, Section3), jpl_datums_to_array([Section1, Section2, Section3], Strings), jpl_call( 'org.knowrob.report_card.Generator', rc, [RcHomeOs, TrialId, Strings], RcPdf), export_data(data_format(csv)), export_data(data_format(r)).A = [1, 2, 3, 4, 5, 6],
B = ['a', 'b', 'c', 'd', 'e', 'f'],
a <- A,
b <- B,'a.mean' <- mean(a),
Amean <- 'a.mean',
write(Amean),<- pdf(file = +""./filename.pdf""),
<- pie('a', labels = sprintf(+""%s of\n%s"", 'a', 'b'), main = +""Pie-chart name""),
<- invisible('dev.off()')."
W1818,https://wiki.ros.org/manipulator_h_manager,Wiki,manipulator_h_manager,"The manipulator_h_manager package
    This package describes robot manager to execute manipulator_h_base_module. 


 gazeboboolgazebo_robot_namestringrobot_file_pathstringinit_file_pathstringoffset_file_pathstring"
W1819,https://wiki.ros.org/reemc_hardware_gazebo,Wiki,reemc_hardware_gazebo,Gazebo plugin to control a REEM-C robot in simulation.
W1820,https://wiki.ros.org/rocon_app_manager,Wiki,rocon_app_manager,"The public interface and retaskable interface for a robot.



 () 
 () 

These services are freely shared to any ros subsystem that wants to consume them via the  advertise/pull mechanisms. The purpose is to provide introspection to the robot (i.e. the system that runs the app manager) to make a decision as to whether it wishes to assume control of the robot. Assuming control is managed by making a request to invite the robot. The list of arguments to use for standalone mode robot launcher.  The list of arguments to use for concert mode robot launcher.  /platform_info/list_rapps/status/invite/start_rapp/stop_rappplatform_infolist_rappsstatusinvitestart_rappstop_rappRequired Arguments:
  auto_start_rapp: autostart a rapp, e.g. rocon_apps/talker
Optional Arguments:
  auto_rapp_installation (default ""false""): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation
  capabilities (default ""false""): enable/disable a capability server
  capabilities_blacklist (default ""[]""): blacklist specific capabilities
  capabilities_nodelet_manager_name (default ""capability_server_nodelet_manager"")
  capabilities_package_whitelist (default ""[std_capabilities]""): get capabilities from these packages only
  capabilities_parameters (default ""/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml""): detailed parameter configuration for the providers
  capabilities_server_name (default ""capability_server"") 
  interactions (default ""false"")
  interactions_list (default ""[]"")
  rapp_package_blacklist (default ""[]"")
  rapp_package_whitelist (default ""[rocon_apps]""): comma separated list of package names
  rapp_preferred_configuration_file (default ""/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml"")
  robot_description (default ""To err is human, to 'arr is pirate."")
  robot_icon (default ""rocon_icons/cybernetic_pirate.png"") 
  robot_name (default ""Cybernetic Pirate"") 
  robot_type (default ""pc"")
  rosbridge_address (default ""localhost"")
  rosbridge_port (default ""9090"")
  screen (default ""true""): verbose output from running apps
  simulation (default ""false""): if simulated robot
  zeroconf (default ""false"")
  zeroconf_name (default ""Cybernetic Pirate"")
  zeroconf_port (default ""11311"")Required Arguments:
  concert_uri: configure concert hub uri for direct connection.
Optional Arguments:
  capabilities (default ""false""): enables/disables a default capability server in this concert client
  capabilities_blacklist (default ""[]""): blacklist specific capabilities
  capabilities_package_whitelist (default ""[]""): get capabilities from these packages only (e.g. std_capabilities)
  capabilities_parameters (default ""/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml""): detailed parameter configuration for the providers
  concert_watch_period (default ""10""): the period used by gateways for watching concert connections
  concert_whitelist (default ""[]""): list of concert names this robot will work with
  disable_zeroconf (default ""false""): disable zeroconfiguration
  firewall (default ""false""): typically false (don't let anything in), only for simulation clients
  interactions (default ""false"")
  interactions_list (default ""[]"")
  local_machine_only (default ""false""): only work with local concerts (testing, simulations)
  rapp_auto_installation (default ""false""): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation
  rapp_package_blacklist (default ""[]"")
  rapp_package_whitelist (default ""[rocon_apps]""): comma separated list of package names
  rapp_preferred_configuration_file (default ""/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml"")
  robot_description (default ""To err is human, to 'arr is pirate."")
  robot_icon (default ""rocon_icons/cybernetic_pirate.png"")
  robot_name (default ""Cybernetic Pirate"")
  robot_type (default ""turtlebot"")
  robot_unique_name (default ""true""): postfix a uuid to the robot name for uniqueness
  screen (default ""false""): verbose output from running apps
  simulation (default ""false""): if simulated robot"
W1821,https://wiki.ros.org/mm_core_msgs,Wiki,mm_core_msgs,Message definitions and serialisations for core messages.
W1822,https://wiki.ros.org/receive_xsens,Wiki,receive_xsens,"

     ROS driver for Xsens MTi-10 and MTi-100 series motion trackers

   

 
/imu/datarosrun receive_xsens receive_xsensroslaunch receive_xsens.launch"
W1823,https://wiki.ros.org/robotis_device,Wiki,robotis_device,"The package that manages device information of ROBOTIS robots.
    This package is used when reading device information with the robot information file
    from the robotis_controller package. 
"
W1824,https://wiki.ros.org/android_extras,Wiki,android_extras,"Various additional and useful general packages, but not core.For more general documentation on all things rosjava-android, refer to the  and  wiki pages. "
W1825,https://wiki.ros.org/schunk_lwa4d,Wiki,schunk_lwa4d,schunk_lwa4d
W1826,https://wiki.ros.org/soem_master,Wiki,soem_master,"soem_master contains a C++ wrapper around soem_core, a factory object to register and create drivers and a RTT component that will automatically create the drivers and their services for all the slave for which a driver is known."
W1827,https://wiki.ros.org/robotis_controller,Wiki,robotis_controller,"robotis_controller package for ROBOTIS's platform like Manipulator-H, THORMANG and OP series 


/robotis/write_control_table/robotis/sync_write_item/robotis/set_joint_ctrl_modules/robotis/enable_ctrl_module/robotis/set_control_moderobotis_controllerDIRECT_CONTROL_MODEMOTION_MODULE_MODE/robotis/set_joint_states/[gazebo_robot_name]/joint_states/robotis/goal_joint_states/robotis/present_joint_states/robotis/present_joint_ctrl_modules/robotis/get_present_joint_ctrl_modules/robotis/set_present_joint_ctrl_modules/robotis/set_present_ctrl_modules"
W1828,https://wiki.ros.org/rosbuild,Wiki,rosbuild,"rosbuild contains scripts for managing the CMake-based build system for ROS.rosbuildrosbuildrosbuildMakefileMakefilemakeMakefilerosbuildCMakeLists.txt$ROS_ROOT/core/rosbuild/rosconfig.cmake$ROS_ROOT/core/rosbuild/rosconfig.cmakeROS_BUILD_TYPERelWithDebInfoDebugReleaseRelWithDebInfoRelWithAssertsMinSizeRelROS_BUILD_STATIC_EXESROS_BUILD_SHARED_LIBSROS_BUILD_STATIC_LIBSROS_COMPILE_FLAGSROS_LINK_FLAGSCMakeLists.txtrosconfig.cmakeROS_PACKAGE_NAME='""foo""'fooCMakeLists.txt$(INTEL_DIR)/opt/intel/cc/10.1.008ccacheccache/usr/lib/ccache/gccpre1pre4include $(shell rospack find mk)/cmake.mkcmake_minimum_required(VERSION 2.4.6)
include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)
# Turn off shared libs and turn on static libs, just for this package
set(ROS_BUILD_STATIC_LIBS true)
set(ROS_BUILD_SHARED_LIBS false)
rosbuild_init()
rosbuild_add_library(mylib mysrc.cpp)cmake_minimum_required(VERSION 2.4.6)
include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)
# Turn on higher warnings, because I'm hard-core
set(ROS_COMPILE_FLAGS ""-W -Wall -Wextra -pedantic"")
rosbuild_init()
rosbuild_add_library(mylib mysrc.cpp)cmake_minimum_required(VERSION 2.4.6)
include($ENV{ROS_ROOT}/core/rosbuild/rosbuild.cmake)
# Go to a release build, because I'm done debugging and I want compiler optimizations
set(ROS_BUILD_TYPE Release)
rosbuild_init()
rosbuild_add_library(mylib mysrc.cpp)# I want both static and shared libs for all ROS packages (shared are enabled by default)
set(ROS_BUILD_STATIC_LIBS true)# I want just static libs, just for this package
set(ROS_BUILD_STATIC_LIBS true)
set(ROS_BUILD_SHARED_LIBS false)set (CMAKE_C_COMPILER $(INTEL_DIR)/bin/icc)
set (CMAKE_CXX_COMPILER $(INTEL_DIR)/bin/icpc)

set (CMAKE_C_EXECUTABLE $(INTEL_DIR)/bin/xild)
set (CMAKE_CXX_EXECUTABLE $(INTEL_DIR)/bin/xild)

set (CMAKE_C_FLAGS   ""-msse3 -ip  -no-prec-div         -parallel -O3 -fPIC"" )
set (CMAKE_CXX_FLAGS ""-msse3 -ip  -no-prec-div         -parallel -O3 -fPIC"" )

set (CMAKE_EXE_LINKER_FLAGS  ""-Wl,-rpath,$(INTEL_DIR)/lib -L$(INTEL_DIR)/lib -lguide -lcxaguard -limf -lsvml -lirc -lpthread -lintlc"" )export PATH=/usr/lib/ccache:$PATHwhich gccexport DISTCC_HOSTS='@pre1/1 @pre2/1 @pre3/1 @pre4/1'
export CCACHE_PREFIX=distcc"
W1829,https://wiki.ros.org/roboteq_msgs,Wiki,roboteq_msgs,"Messages for Roboteq motor controllerNewly proposed, mistyped, or obsolete package. Could not find package ""roboteq_msgs"" in rosdoc: /home/rosbot/docs/api/roboteq_msgs/manifest.yaml "
W1830,https://wiki.ros.org/mrpt_generic_sensor,Wiki,mrpt_generic_sensor,"ROS node for interfacing any sensor supported by mrpt-hwdrivers
"
W1831,https://wiki.ros.org/mrp2_robot,Wiki,mrp2_robot,MRP2 robot description and launch files
W1832,https://wiki.ros.org/roslib,Wiki,roslib,"Base dependencies and support libraries for ROS.
    roslib contains many of the common data structures and tools that are shared across ROS client library implementations.
 is the base dependency of all ROS  and tools. It contains common tools like the generators for  and  as well as common message definitions like  and . It also contains the common path-bootstrapping code for ROS Python nodes and tools. 


 contains command-line tools for message generation necessary for ROS  authors. These tools are . 
roslib contains the definition of the  and  objects used in  and other ROS C++ libraries. It also contains functions for querying the ROS package system. Please see the  and the  for more details. If you are a Python developer, you might be confused that there are both the  and  packages that support Python development in ROS. In fact, some of the functionality they provide is very similar.  There is only one line of  you need to know, which exists for bootstrapping reasons:Otherwise, the simple answer is . Unless you're more familiar with ROS Python development,  should provide you with all the APIs you need to run a node, call services, access the Parameter Server, etc... roslib is primarily an internal library used by ROS core developers to write tools. Currently no new features are planned for . But as new, common functionality is added to the ROS platform, it will likely be supported by libraries here. roslibHeaderLogros::Timeros::Durationroslibrospyroslibroslibimport roslib; roslib.load_manifest('YOUR_PACKAGE_NAME')"
W1833,https://wiki.ros.org/jaco_description,Wiki,jaco_description,"3D Model and URDF of the Kinova JACO Arm
 contains urdf and xacro files for the JACO arm.  It also includes a launch file for reading the robot model and setting up a  and  for visualization in tools such as rviz. 


To install the  package, you can install from source with the following commands: The  package includes a launch file that can be used to load the robot model and setup joint state and robot state publishing used to populate a tf tree and visualize the robot.  Once launched, the JACO model can be visualized in tools such as rviz.  It can be launched with the following command: The launch file also includes a parameter () to launch a GUI which can control each joint to test the model's behavior, which can be launched as follows: jaco_descriptionurdf/robots/meshes/wpi_jacojaco_descriptiongui




roslaunch jaco_description display.launchroslaunch jaco_description display.launch gui:=true"
W1834,https://wiki.ros.org/rosbash,Wiki,rosbash,"Assorted shell commands for using ros with bash.



 includes the following command line utilities:  
 allows you to change directories using a package name, stack name, or special location.  without argument will take you to .  
 is the  equivalent of .  It allows you to keep multiple locations in a directory-stack while still using ros package names.  You can then  use the number of any directory in your directory stack to jump back there.  
 lists the directories in your directory stack.  This is for use with .  
 allows you to view the contents of a package, stack, or location.  
 allows you to easily edit files in a ROS package by typing the package name and the name of the file you want to edit:  
 allows you to conveniently copy a file from a package.  Similar to  you can specify any file in the package regardless of hierarchy.  
 allows you to run an executable in an arbitrary package from anywhere without having to give its full path or / there first. 
 enables tab-completion for its own tools and for a number of other ros utilities: , , , , , , , , . The  package contains some useful bash functions and adds tab-completion to a large number of the basic ros utilities. The  package includes limited support for  and  by way of sourcing the  or  files respectively. We currently do not provide documentation on these shells, though much of the functionality is similar to the bash shell extensions. you can add this statement to the  directory to execute it automatically on login, such as . Sourcing a catkin workspace requires using : You can have this done automatically as soon as you  to the workspace directory, by adding a further config file (e.g. ): Additionally, the  environment variable can be used to add additional special locations for use with .   is a colon-separated list of  pairs. For example, adding the following to your  file: and end up in . The default editor for rosed is vim. To use a different editor, set the  environment variable.  E.g., in your ~/.bashrc: You also can change the editor for one  call on the fly: Will end up copying the file from  It's also possible to pass a  using the following syntax (replace the  with an ): Starting in , rosrun has a  option which can be used to run a node in gdb or valgrind. For more example prefixes, see:  There are a couple of generic completion rules that may be appropriate for other utilities.  Looking through the  source may provide insights into replicating similar functionality for other nodes, however, the code is not yet nicely generalized or re-usable.  In a future release of ROS, we plan to incorporate a more generically re-usable tab-completion framework into rosbash and the other common shells used by ROS. rosbashrosbashrosbashzshtcshroszshrostcshconf.d~/.config/fish/conf.d/rosfish.fishcd~/.config/fish/conf.d/catkin.autosource.fishrosbashpushdroscdroscdroscd$ROS_WORKSPACEROS_LOCATIONSroscdROS_LOCATIONSkey=path.bashrc~/ros/devrospdpushdroscdrosdrospdroslsrosedEDITORrosedroscprosed~/ros/pkgs/ros_tutorials/roscpp_tutorials/talker/talker.cpprosruncdroscd~parameter~_--prefixrosbashrosbashsource ${ROS_ROOT}/tools/rosbash/rosbashsource /opt/ros/$ROS_DISTRO/setup.bashsource /opt/ros/$ROS_DISTRO/share/rosbash/rosfishbass source ~/catkin_ws/devel/setup.bashfunction catkinSource --on-variable PWD
    status --is-command-substitution; and return
    if test -e "".catkin_workspace""; or test -e "".catkin_tools""
        bass source devel/setup.bash
        echo ""Configured the folder as a workspace""
    end
endroscd <package-or-stack>[/subdir]roscd roscpproscd roscpp/include/rosexport ROS_LOCATIONS=""pkgs=~/ros/pkgs:dev=~/ros/dev""$ roscd devleibs@bar:~$ rospd hokuyo_node/
0 ~/ros/pkgs/laser_drivers/hokuyo_node
1 ~
leibs@bar:~/ros/pkgs/laser_drivers/hokuyo_node$ rospd roscpp_tutorials/
0 ~/ros/pkgs/ros_tutorials/roscpp_tutorials
1 ~/ros/pkgs/laser_drivers/hokuyo_node
2 ~
leibs@bar:~/ros/pkgs/ros_tutorials/roscpp_tutorials$ rospd laser_pipeline/
0 ~/ros/dev/laser_pipeline
1 ~/ros/pkgs/ros_tutorials/roscpp_tutorials
2 ~/ros/pkgs/laser_drivers/hokuyo_node
3 ~
leibs@bar:~/ros/dev/laser_pipeline$ rospd 1
0 ~/ros/pkgs/ros_tutorials/roscpp_tutorials
1 ~/ros/pkgs/laser_drivers/hokuyo_node
2 ~
3 ~/ros/dev/laser_pipelineleibs@bar:~/ros/pkgs/laser_drivers/hokuyo_node$ rosd
0 ~/ros/pkgs/laser_drivers/hokuyo_node
1 ~
2 ~/ros/dev/laser_pipeline$ rosls roscpp
$ rosls roscpp/include/ros$ rosed roscpp_tutorials add_two_ints_server.cpp$ rosed roscpp CMakeLists.txt
You have chosen a non-unique filename, please pick one of the following:
1) ~/ros/ros/core/roscpp/test/CMakeLists.txt
2) ~/ros/ros/core/roscpp/CMakeLists.txt
3) ~/ros/ros/core/roscpp/src/CMakeLists.txt
4) ~/ros/ros/core/roscpp/src/libros/CMakeLists.txt
#?export EDITOR='emacs -nw'EDITOR=geany rosed rosbash rosbash$ roscp roscpp_tutorials talker.cpp .rosrun <package> <executable>rosrun roscpp_tutorials talkerrosrun package node _parameter:=valuerosrun my_package my_node _my_param:=valuerosrun package node __name:=namerosrun my_package my_node __name:=my_namerosrun --prefix 'gdb -ex run --args' my_package my_node"
W1835,https://wiki.ros.org/rl_env,Wiki,rl_env,"rl_env is is a package containing reinforcement learning (RL) environments.





  Please take a look at the  on how to install, compile, and use this package. Check out the code at:  This package contains a variety of environments that can be used for reinforcement learning experiments. These can be used with new RL agents written to use the  framework, or with existing agents from the  package. The package contains the following environments: The environment can interact with an RL agent in two ways. It can use the ROS messages defined in , or another method can call the agent and environment methods directly, as done in the  package. The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: Experiments can also be run by calling the agent and environment methods directly (as done in the  package). Methods that all environments must implement are defined in the Environment interface in the  package ().  Seeds can be retrieved from the environment with the getSeedings() method. An action is applied to the environment with a call to apply(action). The current state can be retrieved by calling sensation() and terminal() will indicate if the agent is in a terminal state or not. rosrun rl_env env --env type [options]taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworldrosrun rl_env env --env carrandom --lag --stochastic --prints"
W1836,https://wiki.ros.org/smach_msgs,Wiki,smach_msgs,"this package contains a set of messages that are used by the introspection
    interfaces for smach.
The smach messages are only used for communication between the introspection server and the , and are considered part of the . "
W1837,https://wiki.ros.org/rl_agent,Wiki,rl_agent,"rl_agent is a package containing reinforcement learning (RL) agents.













  Please take a look at the  on how to install, compile, and use this package. Check out the code at:  This package includes a number of reinforcement learning agents that can be used for learning on robots, or learning with the environments in the accompanying  package. In addition to these methods, the package contains a general model-based architecture that can be used with any combinations of planners and model learning algorithms. For example, the R-Max implementation is simply the general agent with an R-Max model and Value Iteration for planning and the TEXPLORE agent is the general agent with a random forest model () and UCT () for planning. Included in this package is a general model based agent that can use any model learning or planning method that match the interface defined by the  file in the  package. Any of these model learning methods can be combined with any of the planners. It is also easy to write new model learning and planning methods that match the interface defined in  and use those as well. In addition, there are multiple ways of performing exploration: The RL agent can interact with the environment in two ways: it can use the ROS messages defined in the  package, or another method can call the agent and environment methods directly, as done in the  package. The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: Experiments can also be run by calling the agent methods directly (as done in the  package).  The methods that all Agents must implement are defined in the Agent interface in the  package (). Seeds can be given to the method by calling the seedExp method. The agent can be queried for an action after getting a new state and reward by calling next_action(reward, state). To run the basic Q-Learning () agent, type the following: To run the basic Sarsa () agent, type the following: To run the basic Dyna () agent, type the following: To run the basic R-Max () agent, type the following: To run the basic TEXPLORE or TEXPLORE-VANIR () agent, type the following: TEXPLORE plans greedily with respect to the average of a number of decision tree models of the domain. By default, TEXPLORE uses nmodels = 5, C 4.5 discrete decision trees, and plans using the RTMBA real-time architecture () with an action rate of 10 Hz. To run TEXPLORE with Variance and Novelty Rewards (TEXPLORE-VANIR) (), set the coefficients for the variance and novelty explorations: rosrun rl_agent agent --agent type [options]qlearner sarsa modelbased rmax texplore dyna savedpolicyrosrun rl_agent agent --agent texplore --planner parallel-uct --nmodels 10 --model m5tree --actrate 25 --gamma 0.99--model tree --nmodels 10rosrun rl_agent agent --agent qlearnerrosrun rl_agent agent --agent sarsarosrun rl_agent agent --agent dynarosrun rl_agent agent --agent rmaxrosrun rl_agent agent --agent texplore--model m5tree--n 5
--v 5--history 5rosrun rl_agent agent --agent modelbased"
W1838,https://wiki.ros.org/robot_self_filter,Wiki,robot_self_filter,"Filters the robot's body out of point clouds.
 

NOTE: for indigo and above users, please take a look at newer repository at   Note: this node will output an XYZ  with no RGB information. If you need to filter an XYZRGB , look at  from the   stack. The  package is a filter to remove or mark the points corresponding to robot links in sensor data. The filter is essentially a node wrapper around the . "
W1839,https://wiki.ros.org/smarthome_network_zeroconf,Wiki,smarthome_network_zeroconf,The zeroconf package
W1840,https://wiki.ros.org/jaco_sdk,Wiki,jaco_sdk,"JACO Software SDK and API

The  package contains Kinova's API for communicating with the JACO arm for both 32bit and 64bit systems.  The package will install the JACO libraries for use with the other packages in the  metapackage. To install the  package, you can install from source with the following commands: jaco_sdkwpi_jacowpi_jaco




"
W1841,https://wiki.ros.org/scratch4robots,Wiki,scratch4robots,scratch4robots
W1842,https://wiki.ros.org/robotnik_sensors,Wiki,robotnik_sensors,"Robotnik standard sensors description. URDF and meshses.
"
W1843,https://wiki.ros.org/rflex,Wiki,rflex,"ROS adaptations of the RFLEX driver.

"
W1844,https://wiki.ros.org/softkinetic,Wiki,softkinetic,The softkinetic package
W1845,https://wiki.ros.org/jackal_gazebo,Wiki,jackal_gazebo,Launchfiles to use Jackal in Gazebo.This package contains launch files to spawn  in some example environments. Please see  for usage. 
W1846,https://wiki.ros.org/abb_irb6640_support,Wiki,abb_irb6640_support,"
      ROS-Industrial support for the ABB IRB 6640 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 6640 manipulators. This currently includes the
      IRB 6640-185/2.8m (6640-185) only.
    
      Joint limits and max joint velocities are based on the information in the
       (Version: 3HAC 028284-001 Rev. N). All urdfs /
      xacros are based on the default motion and joint velocity limits, unless
      noted otherwise (ie: no support for high speed joints, extended / limited
      motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1847,https://wiki.ros.org/rocon_apps,Wiki,rocon_apps,Core rocon apps for use with the appmanager and rocon concert.
W1848,https://wiki.ros.org/sensor_fusion_comm,Wiki,sensor_fusion_comm,"

     This package contains messages, services and action definitions needed by ethzasl_sensor_fusion and nodes communicating with it.  

  "
W1849,https://wiki.ros.org/mm_eigen_msgs,Wiki,mm_eigen_msgs,Message definitions and serialisations for Eigen messages.
W1850,https://wiki.ros.org/asr_mild_kinematic_chain,Wiki,asr_mild_kinematic_chain,"This package provides information about the mild's kinematic chain and contains launch-files to publish the chain to a robot_state_publisher 
     
   

 


The mild's kinematic chain is described in within this package. (See the  for a detailed explanation of the urdf format) The kinematic chain consists of two major parts: The robot's environment (map) as well as the robot's base and the camera-system including PTU, Guppy-Cameras (and Kinect as an optional component). The fixed reference Frame is in the PTU and is called . The transformation publisher is usually not run directly from this package. Instead, use the launch files provided in . See  for tutorials on how to set up the full kinematic chain. roslaunch asr_mild_kinematic_chain transformation_publishers_kinect_left.launch"
W1851,https://wiki.ros.org/rh_p12_rn_base_module,Wiki,rh_p12_rn_base_module,"Base module using ROBOTIS framework for RH-P12-RN 
"
W1852,https://wiki.ros.org/mh5_anomaly_detector,Wiki,mh5_anomaly_detector,"ROS Anomaly Detector for Motoman MH5 robot arm
 "
W1853,https://wiki.ros.org/rmp_teleop,Wiki,rmp_teleop,"The rmp_teleop package provides teleoperation functionalities for a Segway Robotics Mobility Platform.
    This package currently supports the xbox wireless joytsick.




 /rmp440le/joy/rmp440le/base/vel_cmd/rmp440le/deadman/rmp440le/audio_cmdjoy_topicstringvelocity_command_topicstringdeadman_topicstringaudio_command_topicstringupdate_frequencydoubletranslational_velocity_scaledoublerotational_velocity_scaledoubletranslational_velocity_boost_scaledoublerotational_velocity_boost_scaledouble$ roslaunch rmp_teleop joystick.launch"
W1854,https://wiki.ros.org/asr_ivt_bridge,Wiki,asr_ivt_bridge,"This package is used to convert between ROS messages and IVT images 
 





This package contains a library which is used to convert image data structures between ROS and . The structure of this library is based on the -package, for more information you can check out the documentation for that. Include and/or  to your code, depending on what you want to convert (images or camera calibrations). To convert a  to a e of the IVT-library call one of the following functions (notice that the -functions create a copy of the input messages while the other ones try to share the data if possible): The return-value is a -object, which contains a  member called image. To convert such an  back to ROS call one of the following member functions: To convert a ROS  to an IVT  instantiate either an  or an  object (depends on your camera system: mono or stereo). Then call one of the provided member functions with the ROS-CameraInfo-message you want to convert (for a stereo system you have to provide messages of both cameras of course): IvtImagePtr toIvtCopy(const sensor_msgs::ImageConstPtr& source, const std::string& encoding = std::string());
IvtImagePtr toIvtCopy(const sensor_msgs::Image& source, const std::string& encoding = std::string());IvtImageConstPtr toIvtShare(const sensor_msgs::ImageConstPtr& source, const std::string& encoding = std::string());
IvtImageConstPtr toIvtShare(const sensor_msgs::Image& source, const boost::shared_ptr<void const>& tracked_object, const std::string& encoding = std::string());sensor_msgs::ImagePtr toImageMsg() const;
void toImageMsg(sensor_msgs::Image& ros_image) const;bool fromCameraInfo(const sensor_msgs::CameraInfo& msg);
bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& msg);bool fromCameraInfo(const sensor_msgs::CameraInfo& left, const sensor_msgs::CameraInfo& right);
bool fromCameraInfo(const sensor_msgs::CameraInfoConstPtr& left, const sensor_msgs::CameraInfoConstPtr& right);boost::shared_ptr<CCalibration> getCalibration(bool forRectifiedImages=false) const;
boost::shared_ptr<CStereoCalibration> getStereoCalibration(bool forRectifiedImages=false) const;"
W1855,https://wiki.ros.org/mrp2_display,Wiki,mrp2_display,Package for managing touch LCD panel on MRP2
W1856,https://wiki.ros.org/robot_calibration,Wiki,robot_calibration,"Calibrate a Robot
"
W1857,https://wiki.ros.org/manipulator_h_base_module,Wiki,manipulator_h_base_module,"The manipulator_h_base_module package
    This package describes basic function to control ROBOTIS MANIPULATOR-H.
    This module is based on position control.
    We provides joint space and task space control (forward kinematics, inverse kinematics). 


 robotis/base/ini_pose_msgrobotis/base/set_mode_msgrobotis/base/joint_pose_msgrobotis/base/kinematics_pose_msgrobotis/statusrobotis/enable_ctrl_modulerobotis/base/get_joint_poserobotis/base/get_kinematics_pose"
W1858,https://wiki.ros.org/rocon_interaction_msgs,Wiki,rocon_interaction_msgs,Messages used by rocon interactions.
W1859,https://wiki.ros.org/mm_radio,Wiki,mm_radio,"Multiplexing many packet types across a two-way radio connection with publishers and subscribers.
   Great for embedded connections by two-way serial or ethernet types."
W1860,https://wiki.ros.org/nmea_gps_driver,Wiki,nmea_gps_driver,"
	Package to parse NMEA strings and publish standard ROS GPS messages. This package does not require the GPSD deamon.
   . 




Use GitHub to . []
 This package provides a ROS interface for GPS devices that output compatible NMEA sentences. See the  for details on the raw format. Of the thousands of NMEA-compatible GPS devices, we are compiling a list of . This package is compatible with the  project as well as any other nodes that support  and/or .  Due to the dependency on , this package is only compatible with  or newer. To get up and running quickly, you can use the following command to start outputting your GPS data onto ROS topics. This assumes your GPS is outputting GGA NMEA sentences, is connected to  and is communicating at 38400 baud. /dev/ttyUSB0fixveltime_referencetime_ref~portstring~baudint~frame_idstringframe_idtf_prefix~time_ref_sourcestring~useRMCboolTrueFalse$ rosrun nmea_gps_driver nmea_gps_driver.py _port:=/dev/ttyUSB0 _baud:=38400"
W1861,https://wiki.ros.org/rl_msgs,Wiki,rl_msgs,"rl_msgs is a package of ROS message definitions, which are used for a reinforcement learning agent to communicate with an environment.
 

  This package defines a standard way for agents and environments to communicate through ROS messages. In ROS computation is done by nodes that perform different tasks that communicate through a set of ROS messages. ROS provides the framework to publish, subscribe to and receive these messages, in addition to tools for logging, displaying, plotting, and playing back ROS messages. This package defines a set of ROS messages for a reinforcement learning agent and environment to communicate. These messages are similar to the messages used by RL-Glue (), but are simplified and defined in the ROS format. Please take a look at the  on how to install, compile, and use this package Check out the code at:  Agents from the  package can communicate with environments from the  package through this interface. In addition, you can write your own agents and environments that will work with the ones in those packages by passing the same messages defined here. The  framework is being designed to be as flexible as possible. While our  algorithms and environments will mostly follow a certain style, we understand that every robot and  every experiment differs. Our hope is to not force our philosophy onto  other people, as long as you adhere to  you can design and implement your algorithms and environments in your own style. "
W1862,https://wiki.ros.org/rviz_imu_plugin,Wiki,rviz_imu_plugin,"RVIZ plugin for IMU visualization
 
 The  package is used to display   messages in . Once you download and compile the package, it should be visible as a plugin. The package has been  for inclusion in ROS. Please submit your tickets through  (requires github account) or by emailing the maintainers. "
W1863,https://wiki.ros.org/langs-dev,Wiki,langs-dev,Meta package modeling the build-time dependencies for language bindings of messages.
W1864,https://wiki.ros.org/retalis,Wiki,retalis,"Retalis Language for Information Processing and Management in Autonomous Robot Software









  






  
     

   
  

 Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type  Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with .  The format of time-stampes are   where  encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above  message contains a list of  messages (only one here). While each   message is time-stamped, the  itself does not have a header. Therefore, the corresponding event is stamped with the current time. The following rule calls  the  function for every  event received by retalis. Each  message from  contains a list of recognized objects, each represented by a   message. The following rule generates a separate event for each object. where  represents a recognized object and  encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding  message. The events is also time stamped with . Retalis integrates the '.  supports temporal and logical reasoning on flow of events. Please see   for publications and for examples of rules implementing various event-processing functionalities. This memory instance keeps the history of events of the form , specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. The  event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as . We saw in Section 4.1.3 that the  and  functions are implemented as Prolog clauses. The  file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events The Prolog program in  together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our  list). An example of using  and  terms is in implementation of the  function, in the eventRules.txt. The input values to this function is the  of a memory instance, keeping the history of some  events, and a time point. The  events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time . This is implemented as follows. The last observation before  and the first observation after  are found using the  and  terms. Then the position is linearly interpolated by making a function call to the  library that has been integrated with retalis. The  function in eventRules.txt uses the  function to position an object in the world reference frame. Given , the position of an object relative to the camera at time , this function computes , the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between , , ,  and  at the time . Third, it applies these transformations on the  by making a function call to the  library. It is assumed that the  frame is aligned with the world reference frame. We saw in Section 4.1.6 that how calling  function interpolates the position between the  and  coordination frames at time . This function uses  and  terms to access the first and the last observations after and before , respectively. To interpolate the position at , the position should have been observed, at least once, after . The observations,  messages here, are received asynchronously. Therefore, the  function should be evaluated only after the  memory instance has been updated with an event occurring after . This is realized in retalis using a synchronized event, as follows. The  function, performs the , when the  are satisfied and then generate the . Consider the following clause from eventRules.txt: This rule computes the position of recognized markers in the world and is read as follows.   For each  event, specified in line 6, the position is computed by calling the  function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: Such a  event encodes the marker's name, its position in the world and the time of recogntion. The  are the followings, specified in line 4: These conditions specify that the  function should be evaluated, only after all , , ,  and  memory instances have been updated, at least once, with events occurring after time . The time  is the time of recognition of the marker. Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized  is posponed, until the  are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. The subscription subscribes the topic  to the  events in which  is . Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker  in the world coordination frame.  The id of the subscription is  which can be used to cancel the subscrition at any time. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the  and  ros topics. The retalis-ros-converter only subscribes retalis to the  topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to  and  topics in the pub-sub.xml file and instead, set the  boolean variable in the retalis_interface.cpp file to . You should also recompile the package. As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to  and  topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record  events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type  are added to the NAO example. These memory instances match all  events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type . However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. The following figure shows the CPU time for a number of runs where up to 40 memory instances of type  and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  The following figure shows the CPU time for a number of runs where up to 640 memory instances of type  and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type . The green line shows the CPU time for the case where there are 320 memory instances of type . We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for  events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. The brown line shows the CPU time for the case where there are 10 memory instances of type  and 320 memory instances of type . Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10  memory instances and 320  memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional  memory instance of size 128. This memory instance is queried by 1000  terms for each recognition of an object. In average, 7000  terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000  terms are evaluated per seconds. The figure shows that the costs of the evaluations of  and  terms are similar. The purple line shows the CPU time of the case where 14,000  terms are evaluated per second. We observe that the cost grows linearly, as expected. The blue line in the following figure visualizes the CPU time of the case where 7000  terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320  memory instances. The purple line visualizes the CPU time of the case where 7000  terms are evaluated per second and there are 320  memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. The green line in the following figure visualizes the CPU time of evaluating 7000  terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000  terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000  queries on a memory instance of size 2500 are evaluated. In addition, for each  query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see  for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. add_output_subscriptiondelete_output_subscriptionadd_memorydelete_memoryadd_input_subscriptiondelete_input_subscription__0____0____0____0__'""/odom""','""/base_link""''“/odom”', '“/base_link”'ToDoEventRelativePosAbsolutePoseRelativePosAbsolutePoseCameraTopRelativePosSynchConditionsQuerySynchConditionsEventPoseStampedSyncConditionsPoseStamped'""4x4_1""'__0____0__CameraTop_frame

















"
W1865,https://wiki.ros.org/shm_transport,Wiki,shm_transport,"The shared memory transport package




   A shm_transport::Topic object is an encapsulation of ros::. Note that shm_transport::Topic::advertise() has one more parameter comparing to ros::::advertise(). This parameter (3 * MSGLEN in the example) indicates the total size of shared memory segment. The total size of shared memory segment should be larger than two messages plus the space used by memory allocation algorithm. 




























































"
W1866,https://wiki.ros.org/raspigibbon_description,Wiki,raspigibbon_description,The raspigibbon_description package
W1867,https://wiki.ros.org/manipulator_h_bringup,Wiki,manipulator_h_bringup,"The manipulator_h_bringup package
    This package includes launch file to describe robotis in Rviz. 
 "
W1868,https://wiki.ros.org/rviz_animated_view_controller,Wiki,rviz_animated_view_controller,"A rviz view controller featuring smooth transitions.


This package provides an RViz view controller plugin that allows users to control the RViz camera by publishing  messages (from the  package) to the  topic. This package has been released into Hydro and Indigo. Installation through  is easiest in most cases: See the ,  and  scripts in the  package for examples of how to use the functionality provided by this package. CameraPlacement/rviz/camera_placementapt-getCameraTestControlsTestSquareTestsudo apt-get install ros-hydro-rviz-animated-view-controllersudo apt-get install ros-indigo-rviz-animated-view-controller"
W1869,https://wiki.ros.org/asr_calibration_tool_dome,Wiki,asr_calibration_tool_dome,"This package provides a tool for calibraiting the kinematic chain of the PdB-Dome. It provides a data-tracking for recording 6D positions of Flock of Birds data glove and a checkerboard mounted on it. With this construction, the kinematic chain is closed. The recorded data is written to a file and can be used for the asr_kinematic_chain_optimizer. 

 



   


The idea of this calibration process is to close the kinematic chain, track several hundred datasets, describe a default TF-configuration and minimize the distances. In addition, the PTU pan- and tilt-angle are also tracked. Dataset are the tracked training data. Each value is a configuration of a non-fix joint. A whole dataset (one row) contains all variables of a kinematic chain (See  for further information). A sample Dataset is shown in the following picture: 1. Define a kinematic chain as best as you could, or use the old kinematic chain. The format is shown in  package. Define also a goal function (e. g. Position of Frame1 and Frame2 should be equal. (See  for further information). Make sure that all non-fixed Frames are parameterized (like PTU). 2. Construct something, so the kinematic chain is closed. In this case a tracker of the  system is attached on a checkerboard detector. Define a transformation between the two tracked frames like you did in 1. 4. Run the  with you frames and datasets as inputfiles. rostopic echo /fob_objectsrostopic echo /ptu_driver/staterostopic echo /checkerboard_detector/objectdetection_poserosrun asr_flock_of_birds flock_of_birds_remote.sh

roslaunch asr_flir_ptu_driver ptu_left.launch

roslaunch asr_resources_for_vision guppy_head_full_pbd.launch

(roslaunch asr_flir_ptu_driver ptu_gui.launch)

roslaunch asr_calibration_tool_dome checkerboard_detector_single.launch"
W1870,https://wiki.ros.org/ar_kinect,Wiki,ar_kinect,"
    This package extends the ar_pose package to handle point clouds + images generated from the kinect for improved AR marker localization.
  
 has a single node that can be run, which takes RGB point clouds from the Kinect and outputs a transform between the camera and a recognized marker. This is based on the  node from the  package. 

This package is an ROS wrapper for , which improves marker localization using point cloud data from a Kinect.  ar_multipointsar_pose_markersvisualization_markermarker_pattern_liststring""$(find ar_kinect)/data/object_kinect""marker_data_directorystring""$(find ar_pose)""thresholddoublepublish_visual_markersboolpublish_tfboolcamera_frame_idmarker_frames"
W1871,https://wiki.ros.org/smacha,Wiki,smacha,"SMACHA (short for ""State Machine Assembler"", pronounced ""smasha"") aims at distilling the task-level simplicity of SMACH into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background.
 (short for ""State Machine Assembler"", pronounced ""smasha"") aims at distilling the task-level simplicity of  into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background. 


Use GitHub to . []
  The  provides an overview of the functionalities and core concepts of SMACHA. "
W1872,https://wiki.ros.org/launchman,Wiki,launchman,"Launch Manager
"
W1873,https://wiki.ros.org/slam_exporter,Wiki,slam_exporter,"

     slam_exporter

  "
W1874,https://wiki.ros.org/simple_drive,Wiki,simple_drive,"A simple robot drive system that includes skid steering joystick teleoperation, control of a panning servo to look around the robot, and Arduino firmware.
 
  


 




 If your microcontroller supports subscribing to ROS  messages (Arduinos can use ) then it would be simpler to do that and skip this node. However, this node is written in python so you could more easily add complex functionality in python and then in your microcontroller do the minimum amount of work necessary. 

 Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. 
 We like PlatformIO: ""Single source code. Multiple platforms."" PlatformIO supports approximately 200 and all major. Learn more on. 
       



  - Differential drive software with support for a velocity PID target, a small GUI to control the robot, and more.  - Differential drive software that is real-time safe, integrates with , and more.   - This teleop node converts joy messages to twist messages.  - This teleop node takes joy messages and publishes topics or calls actions according a configuration file.   - Multiplex several velocity command topics with prioritization or disabling according to a configuration file. 
A simple robot drive system. : This package : Package created by Ryerson University students for the , summer 2017. 3. Install the  onto a microcontroller connected to motors and wheels by PWM. The microcontroller must also be connected to the computer running the simple_drive ROS node by a serial connection (ex. USB). This diagram is also available in . This node converts  messages from the  node into a variety of commands to drive the robot at low, medium, and high speed, look around with a servo, and cancel move_base goals at any moment. This node simply sends commands to other nodes. Typically the servo is used to move a camera so that the teleoperator can look around the robot. The  node receives movement commands on two  topics, one for teleoperation and one for autonomous control, typically . Movement commands are multiplexed to a final topic for robot consumption. If any teleoperation command is received autonomous commands are blocked for a set time defined by the  parameter. This node communicates with the  using a custom serial protocol described below. An example serial data packet could be 0,0.5,0.5 which would mean drive motors forward at half speed and rotate at half speed.   The  microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers.  We deploy the  to an Arduino microcontroller using PlatformIO. More PlatformIO install info:  More PlatformIO info:  When a left and right joystick inputs are received by the  node, representing left and right wheel velocities (ie. skid steering or differential drive), a  with linear and rotational velocities is calculated as: When a  containing linear and rotational velocities is received by the , wheel velocities are calculated as: Feature requests, bug reports, and contributions are welcome at . joyteleop/cmd_velservo_pos~servo_pan_speedint~servo_pan_maxint~servo_pan_minintcmd_vel_muxblock_durationteleop/cmd_velmove_base/cmd_velcmd_velblock_duration~block_durationint(BYTE) 0, (FLOAT) LINEAR_VELOCITY, (FLOAT) ANGULAR_VELOCITY(BYTE) 2, (FLOAT) SERVO_ANGLEtwistcmd_velservo_pos~serial_devstring~baudrateintdrive_firmwaredrive_firmware(left_speed + right_speed) / 2.0(right_speed - left_speed) / 2.0linear_speed + angular_speedlinear_speed - angular_speed$ sudo apt-get install ros-kinetic-simple-drive$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0
$ roslaunch simple_drive cmd_vel_mux.launch
$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0

OR all-in-one launch:
$ roslaunch simple_drive drive.launch$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0$ roslaunch simple_drive cmd_vel_mux.launch$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0$ sudo python -c ""$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)""

# Enable Access to Serial Ports (USB/UART)
$ sudo usermod -a -G dialout <your username here>
$ curl https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules  > /etc/udev/rules.d/99-platformio-udev.rules
# After this file is installed, physically unplug and reconnect your board.
$ sudo service udev restart$ roscd simple_drive
$ cd ./drive_firmware/
# Find the microcontroller that you have in the list of PlatformIO boards
$ pio boards | grep -i mega2560
# Use the name of your board to initialize your project
$ pio init --board megaatmega2560$ vim src/main.cpp +4










$ vim src/main.cpp +17




$ pio run --target upload"
W1875,https://wiki.ros.org/rosruby_tutorials,Wiki,rosruby_tutorials,"rosruby_tutorials contains source codes of rosruby tutorials.




This package contains some samples for tutorials. Please refer to  for more detials. "
W1876,https://wiki.ros.org/drc_com_common,Wiki,drc_com_common,drc_com_common
W1877,https://wiki.ros.org/robot_state_publisher,Wiki,robot_state_publisher,"This package allows you to publish the state of a robot to
    . Once the state gets published, it is
    available to all components in the system that also use .
    The package takes the joint angles of the robot as input
    and publishes the 3D poses of the robot links, using a kinematic
    tree model of the robot. The package can both be used as a library
    and as a ROS node.  This package has been well tested and the code
    is stable. No major changes are planned in the near future. 
 All fixed transforms are  by 0.5s. 


 () 
 ()  ()  () robot_state_publisher uses the URDF specified by the parameter  and the joint positions from the topic  to calculate the forward kinematics of the robot and publish the results via . Please see the tutorial on .  It will explain how you can publish the state of your robot to , using the robot state publisher. tftftftftftftftftftfrobot_descriptionjoint_statesjoint_statesrobot_descriptionurdf maptf_prefixstringpublish_frequencydoubleignore_timestampbooluse_tf_staticbooluse_tf_staticbool"
W1878,https://wiki.ros.org/rocon_python_comms,Wiki,rocon_python_comms,"Service pair libraries for pub/sub non-blocking services. 


Full details and usage examples are in the sphinx documentation (), the following is just a brief reference of what is available. find_xxxSubscriberProxyServicePairs"
W1879,https://wiki.ros.org/rosbag_pandas,Wiki,rosbag_pandas,Create a Pandas data frame from a ros bag file.Python library (and some tools) for converting  to . Check the Github page for examples and how to use:  
W1880,https://wiki.ros.org/smach,Wiki,smach,"SMACH is a task-level architecture for rapidly creating complex robot
    behavior. At its core, SMACH is a ROS-independent Python library to build
    hierarchical state machines. SMACH is a new library that takes advantage of
    very old concepts in order to quickly create robust robot behavior with
    maintainable and modular code.
   
 You can build a finite state machine using SMACH, but SMACH can do much more. SMACH is a library for task-level execution and coordination, and provides several types of ""state containers"". One such container, is a finite state machine, but this container can also be a state in another container. See the  for a list of containers and states built into SMACH. The  provides an overview of the concepts used in SMACH. The  contains an extensive set of tutorials to get you up to speed building and running your own state machines.  "
W1881,https://wiki.ros.org/jackal_viz,Wiki,jackal_viz,"Visualization launchers and helpers for Jackal.


This package provides launchers and  configurations to assist with visualizing real or simulated  from a desktop environment. For help getting your desktop environment set up to use with Jackal, see the . For more information on simulating Jackal, see . For more examples, see . robotnavigation2D Nav Goalgmappinglocalization2D Pose Estimateroslaunch jackal_viz view_model.launchroslaunch jackal_viz view_robot.launchroslaunch jackal_viz view_robot.launch config:=navigation"
W1882,https://wiki.ros.org/omip,Wiki,omip,"This metapackage groups all the packages for Online Multimodal Interactive Perception (OMIP).





(Main author) Roberto Martín-Martin (, ) Sebastian Höfer (, ) Oliver Brock () 1. . Three estimation levels: feature tracking, feature-based rigid body tracking, kinematic model estimation. This option can execute only using RGB-D images and therefore requires less computational power.  To try this option, download one of the rosbags with the ""_imgs"" suffix and launch OMIP using the option ""--omip=1"" (or ""--omip=2"" if you want that the terminals  remain open after finishing the execution, for debugging purposes). More frequent problem: The feature tracking is not running and looks like frozen -> Check in feature_tracker/cfg/feature_tracker_cfg.yaml the depth_img_topic name. Depending if you are using openni or openni2 (or rosbags generated from one or the other package) the name of the topic for the depth maps is different. Based on the recursive estimation schema - prediction/correction -  our framework can cope with the high amount of data provided by the robot's sensors . The key (and the main idea of our framework) is to factorize the perceptual problem into smaller *perceptual units*, solve them with single recursive estimation loops and connect all the loops tightly.  The connection of the loops defines a bidirectional information flow between loops: a bottom-up flow to pass estimations as measurements to more abstract levels, and a top-down flow to pass predicted measurements as predicted next states to less abstract levels. By connecting the loops our framework can interpret the combined sensor-action stream as evidence of concepts of different level of abstraction. Each recursive estimation level is realized as a ROS node that implements the interface .  A recursive estimation level is defined by: * Measurement * State * Priors: Internally, each level contains at least one recursive estimation filter. These filters implement the interface . The levels call the corresponding correct-predict methods of the filters and pass the measurements/states up and down. rosrun omip_launch omip.sh --helpgit clone https://github.com/tu-rbo/omip.git
git clone https://github.com/tu-rbo/omip_msgs.gitgsettings set org.gnome.desktop.default-applications.terminal exec 'gnome-terminal'cp ~/.config/terminator/config ~/.config/terminator/config.bak
cp omip/omip_launch/cfg/terminator/config ~/.config/terminator/sudo apt-get install ros-indigo-pcl-ros ros-indigo-openni-launch ros-indigo-openni-camera
ros-indigo-openni2-launch ros-indigo-openni2-camera ros-indigo-cmake-modulessudo apt-get install ros-indigo-bflsudo cp omip/omip/third_party/bflConfig.cmake /opt/ros/indigo/share/bfl/git clone https://github.com/roberto-martinmartin/rviz_plugin_camerarenderpublisher.gitgit clone https://github.com/laas/rviz_plugin_covariance.gitsudo apt-get install ros-indigo-libpointmatchersudo cp your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake.baksudo cp omip/omip/third_party/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/touch omip/shape_tracker/CATKIN_IGNOREcatkin build (omip)rosbag decompress rosbagname.bagrosrun omip_launch omip.sh --omip=1 --rgbd=0rosrun omip_launch omip.sh --helprosbag play rosbagname.bag"
W1883,https://wiki.ros.org/smach_ros,Wiki,smach_ros,"The smach_ros package contains extensions for the SMACH library to
    integrate it tightly with ROS.  For example, SMACH-ROS can call
    ROS services, listen to ROS topics, and integrate
    with 
    both as a client, and a provider of action servers.  SMACH is a
    new library that takes advantage of very old concepts in order to
    quickly create robust robot behavior with maintainable and modular
    code.
For example, if you want to call an  action from SMACH, you can of course write a , which would look something like this: But you can call that same action with much less coding, using the SimpleActionState: SMACH ROS offers the same type of support for ROS services and ROS topics. For more details take a look at the . 






























"
W1884,https://wiki.ros.org/rocon_python_utils,Wiki,rocon_python_utils,"Python system and ros utilities. 

 pingwhichPopen"
W1885,https://wiki.ros.org/rh_p12_rn_base_module_msgs,Wiki,rh_p12_rn_base_module_msgs,"This package includes ROS messages and services for the rh_p12_rn packages 
"
W1886,https://wiki.ros.org/rbcar_robot_control,Wiki,rbcar_robot_control,"The rbcar_robot_control package
"
W1887,https://wiki.ros.org/ROS,Wiki,ROS,"ROS packaging system

     
 
Use GitHub to . []
 For an overview of ROS, please read the ROS . In ROS Diamondback, the  stack was separated into four stacks as part of .  REP 100 describes these changes and why they were made.  In summary: rosros"
W1888,https://wiki.ros.org/robotis_controller_msgs,Wiki,robotis_controller_msgs,"This package includes ROS messages and services for robotis_framework packages 
"
W1889,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14691/6  "
W1890,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20290/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W1891,https://wiki.ros.org/kobuki_softapps,Wiki,kobuki_softapps,The kobuki_softapps package
W1892,https://wiki.ros.org/android_remocons,Wiki,android_remocons,"Remote controllers for rocon appable robots.

This stack includes code for the android remocon and libraries for development of remocon usable android applications. The remocon is used on the . Refer to the  page for more information. "
W1893,https://wiki.ros.org/rosjava_extras,Wiki,rosjava_extras,"Extra packages for rosjava_core
"
W1894,https://wiki.ros.org/rmp_description,Wiki,rmp_description,"The rmp_description package provides Unified Robot Description Format files to represent a Segway Robotics Mobility Platform.

The rmp_description package provides Unified Robot Description Format files () to represent a Segway Robotics Mobility Platform. $ roslaunch rmp_description display_model.launch$ export DEBUG_URDF=true"
W1895,https://wiki.ros.org/rqt_mrta,Wiki,rqt_mrta,"The rqt_mrta package

 
 
 
Use GitHub to . []
  [1] Gerkey, Brian P., and Maja J. Matarić.  The International Journal of Robotics Research 23.9 (2004): 939-954. "
W1896,https://wiki.ros.org/pcl,Wiki,pcl,"


   - oint loud ibrary: a comprehensive open
  source library for  and .
  The library contains numerous state-of-the art algorithms for: filtering,
  feature estimation, surface reconstruction, registration, model fitting and
  segmentation, etc.  
 



 The Point Cloud Library (PCL) is a stand-alone C++ library for 3D point cloud processing. You can learn more about PCL by visiting its website, . The documentation on ROS.org will help you get started using PCL in your ROS applications.   For information about how to use PCL's ROS-specific data types and how to publish and subscribe to point cloud data, please consult the .   You can find numerous code examples on PCL's . For examples of how to include PCL code in a ROS node, please refer to the   page. For a reference guide to PCL's ROS-specific APIs, see the  for the  package. "
W1897,https://wiki.ros.org/asr_cyberglove_visualization,Wiki,asr_cyberglove_visualization,"This package is used to test the functionalities of the CyberGloves and FlockOfBirds. 
    It uses an URDF model of a human hand to provide a visualization of the glove movements in RViz. 
 









The asr_cyberglove_visualization package is used to test and visualize the functionalities of the  and  packages. It uses an URDF model of a human hand to provide a visualization of the movement data from the gloves and the magnet tracking system (Flock of Birds) in RViz. To use im combination with  and  the following hardware components are needed: RViz has to be configured to show/add the RobotModel. The RViz configuration files located in  can be used when launching to provide an ideal view of the model and its movements in RViz. They are included in the launch files. The sensor data of the Cybergloves is received as messages published by the asr_cyberglove_lib server. The topics to listen to are: The pose data of the Flock of Birds trackers is received as  messages published by the asr_flock_of_birds server. The topic to listen to is: The current Cyberglove state data is published to the model as  messages. They are published to the following topic: The Flock of Birds data is published using a . roslaunch asr_cyberglove_lib glove_lib.launch

roslaunch asr_flock_of_birds flock_of_birds.launchrosrun asr_cyberglove_lib glove_lib_remote.sh

rosrun asr_flock_of_birds flock_of_birds_remote.sh"
W1898,https://wiki.ros.org/jackal_simulator,Wiki,jackal_simulator,"Packages for simulating Jackal.

To work with simulated Jackal on your own machine, make sure if have  set up, and install the metapackages for desktop and simulation: Please see . sudo apt-get install ros-indigo-jackal-simulator ros-indigo-jackal-desktop"
W1899,https://wiki.ros.org/ros_mppt,Wiki,ros_mppt,"MPPT message sender package





 





 MPPT data registration into a xls file for experimental purposes.  MPPT ROS package. 

 VE.Direct Protocol - Version 3.25.  BlueSolar HEX protocol MPPT.  
    sudo apt-get install ros-kinetic-ros_mppt$ git clone https://github.com/AaronPB/ros_mppt.git



















































































float64 v_bat
float64 i_bat
float64 v_pv
float64 p_pvfloat64 v_bat
float64 i_bat
float64 v_pv
float64 p_pv
int32 error_mppt$ cd ~/catkin_ws
$ catkin_make
$ . ~/catkin_ws/devel/setup.bash$ rosrun roscore
$ rosrun ros_mppt vemppt_ros.py$ rosbag -a"
W1900,https://wiki.ros.org/raspigibbon_bringup,Wiki,raspigibbon_bringup,The raspigibbon_bringup package
W1901,https://wiki.ros.org/ros_statistics_msgs,Wiki,ros_statistics_msgs,ROS Host and Node Statistics MessagesThese messages are used with the  package's tools. 
W1902,https://wiki.ros.org/rqt_capabilities,Wiki,rqt_capabilities,rqt package for visualization and management of capabilities
W1903,https://wiki.ros.org/langs,Wiki,langs,Meta package modeling the run-time dependencies for language bindings of messages.
W1904,https://wiki.ros.org/kobuki_soft,Wiki,kobuki_soft,"Soft kobuki impementation meta package
Please refer  Wiki "
W1905,https://wiki.ros.org/rqt_alliance,Wiki,rqt_alliance,"The rqt_alliance package

Use GitHub to . []
  "
W1906,https://wiki.ros.org/elevator_move_base_pr2,Wiki,elevator_move_base_pr2,"

     elevator_move_base_pr2

  

 and  Documentation is available . Use trac to report  or .  "
W1907,https://wiki.ros.org/simple_robot_control,Wiki,simple_robot_control,"

     Simple C++ and python interface to move the arms, head, base, torso and grippers of a PR2 robot.

  
launch/simple_robot_control_without_collision_checking.launchlaunch/simple_robot_control.launch#include <ros/ros.h>

#include <simple_robot_control/robot_control.h>


int main(int argc, char** argv){



        ros::init(argc, argv, ""robot_control_test_app"");
        ros::NodeHandle nh;

        //Create robot controller interface
        simple_robot_control::Robot robot;

        //look straight
        robot.head.lookat(""torso_lift_link"", tf::Vector3(0.1, 0.0, 0.0));

        //do stuff with arms
        robot.left_arm.tuck();
        robot.right_arm.stretch();

        //specify joint angles for two waypoints
        double tuck_pos_right[] 
           = { -0.4,0.0,0.0,-2.25,0.0,0.0,0.0,
               -0.01, 1.35, -1.92, -1.68, 1.35, -0.18,0.31};
        std::vector<double> tuck_pos_vec(tuck_pos_right, tuck_pos_right+14);
        robot.right_arm.goToJointPos(tuck_pos_vec);

        robot.right_arm.stretch();

        //grab position from above
        robot.right_arm.moveGripperToPosition(tf::Vector3(0.6,-0.1, 0.0),    
                 ""torso_lift_link"", simple_robot_control::Arm::FROM_ABOVE);
        
        //grab position frontal
        robot.right_arm.moveGripperToPosition(tf::Vector3(0.8,-0.1, 0.1), 
                    ""torso_lift_link"", simple_robot_control::Arm::FRONTAL);

        //specify grab pose with postion and orientation as StampedTransform
        tf::StampedTransform tf_l (tf::Transform(tf::Quaternion(0,0,0,1), 
           tf::Vector3(0.8,0.1,0.0)),
           ros::Time::now(),""torso_lift_link"",""doesnt_matter"");
        robot.left_arm.moveGrippertoPose(tf_l);

        //look at left gripper
        robot.head.lookat(""l_gripper_tool_frame"");

        //drive 0.5m forward
        robot.base.driveForward(0.5);

        //raise torso to 10cm above lowest position
        robot.torso.move(0.1);

        return 0;

}"
W1908,https://wiki.ros.org/rbcar_gazebo,Wiki,rbcar_gazebo,"The rbcar_gazebo package
"
W1909,https://wiki.ros.org/manipulator_h_kinematics_dynamics,Wiki,manipulator_h_kinematics_dynamics,"The manipulator_h_kinematics_dynamics package
    This packages provides library of kinematics and dynamics information for ROBOTIS MANIPULATOR-H.
    Additionally, there are some function to calculate kinematics and dynamics. 
 "
W1910,https://wiki.ros.org/robotnik_msgs,Wiki,robotnik_msgs,The robotnik_msgs package. Common messages and services used by some Robotnik's packages.
W1911,https://wiki.ros.org/sick_visionary_t,Wiki,sick_visionary_t,Open source driver for the SICK Visionary-T 3D TOF camera.
W1912,https://wiki.ros.org/mrp2_hardware,Wiki,mrp2_hardware,Hardware files to communicate with MRP2 base.
W1913,https://wiki.ros.org/schunk_lwa4p,Wiki,schunk_lwa4p,schunk_lwa4p
W1914,https://wiki.ros.org/image_stream,Wiki,image_stream,"rosweb plugin to serve images as streams (MJPEG, Theora, FLV, etc)
"
W1915,https://wiki.ros.org/nanomsg,Wiki,nanomsg,"The nanomsg package
 is a very lightweight (smaller brother of zeromq) communications library accomodating various design patterns. It can be useful for specialised instances where ros doesn't really fit. e.g. Bridging connections to lightweight embedded boards or in grafting your own custom messaging architecture for a specific use case. 
"
W1916,https://wiki.ros.org/detect_cans_in_fridge_201202,Wiki,detect_cans_in_fridge_201202,"

     detect_cans_in_fridge_201202

  

 and  Documentation is available . Use trac to report  or .  "
W1917,https://wiki.ros.org/ackermann_qt,Wiki,ackermann_qt,"

     Qt tele-operation interface for driving a vehicle with Ackermann
     steering under human control.

  


ackermann_cmdrosrun ackermann_qt qteleop"
W1918,https://wiki.ros.org/motoman_mpl80_moveit_config,Wiki,motoman_mpl80_moveit_config,"
      MoveIt package for the Motoman MPL80.
    
      An automatically generated package with all the configuration and launch
      files for using the Motoman MPL80 with the MoveIt Motion Planning
      Framework.
    
This package is part of the  program.  "
W1919,https://wiki.ros.org/reemc_controller_configuration_gazebo,Wiki,reemc_controller_configuration_gazebo,"Gazebo-specifig launch files and scripts needed to configure
    the controllers of the REEM-C robot in simulation."
W1920,https://wiki.ros.org/agvs_common,Wiki,agvs_common,"URDF description of the Agvs and Agvs.
 


 This package contains the different controllers and launch files for the , shared for real robot and simulation.  "
W1921,https://wiki.ros.org/airbus_plugin_rviz,Wiki,airbus_plugin_rviz,The airbus_plugin_rviz package
W1922,https://wiki.ros.org/shared_serial,Wiki,shared_serial,"

    Shared serial port with locking functionality

  

Use trac to  or  [  ] <launch>
        <node name=""motor_comm"" pkg=""shared_serial"" type=""server"">
                <param name=""port_name"" value=""/dev/ttyUSB0""/>
                <param name=""port_type"" value=""RS485_FTDI""/>
                <param name=""baud_rate"" value=""921600""/>
        </node>
</launch>"
W1923,https://wiki.ros.org/raspigibbon_ros,Wiki,raspigibbon_ros,"The raspigibbon_ros package
 

"
W1924,https://wiki.ros.org/scriptable_monitor,Wiki,scriptable_monitor,"scriptable_monitoring


 


Suppose we have a node that publishes current CPU usage to the  topic. Each message contains an array named  with usage information for each core. We also have a topic with configuration information: . You can activate the script using rqt plugin -  
































 #! parameter_name parameter_value #! name cpu_monitor"
W1925,https://wiki.ros.org/rbcar_sim,Wiki,rbcar_sim,"The rbcar_sim package. It contains RBCAR simulation packages
 




 This package contains the different controllers and launch files for the  simulation. "
W1926,https://wiki.ros.org/ridgeback_viz,Wiki,ridgeback_viz,"Visualization launchers and helpers for Ridgeback.


This package provides launchers and  configurations to assist with visualizing real or simulated  from a desktop environment. For help getting your desktop environment set up to use with Ridgeback, see the . robotnavigation2D Nav Goalgmappinglocalization2D Pose Estimateroslaunch ridgeback_viz view_model.launchroslaunch ridgeback_viz view_robot.launchroslaunch ridgeback_viz view_robot.launch config:=navigation"
W1927,https://wiki.ros.org/rl_experiment,Wiki,rl_experiment,"rl_experiment is a package to run RL experiments using the rl_agent and rl_env packages.


  Please take a look at the  on how to install, compile, and use this package. Check out the code at:  This package provides a way of running reinforcement learning experiments with the agents from the  package and environments from the  package without using the  interface. Instead, the code instantiates agent and environment objects and calls their methods directly. It can be set to run for a particular number of episodes and trials, and prints out the sum of rewards for each episode to cerr. There are a number of options available to set parameters of both the agent and environment used.  More details on the agent options are available in the  documentation, and more details on the env options are available in the  documentation. In addition to these options, there a few variables that can be changed in the code, in the . Near the top of the file are two variables: MAXSTEPS and NUMTRIALS. MAXSTEPS determines the maximum number of steps for an episode. A new episode will be started after this many steps even if the agent has not reached a terminal state. As an example, here is how you would run Q-Learning () on the stochastic Taxi task (): Or to run real-time TEXPLORE (, ) at 10 Hz on the deterministic Fuel World task () with 8 discrete trees: While you should find that the qlearner, sarsa, dyna, and rmax agents work fine on the easier tasks (tworooms, taxi, etc), they will not converge within the default 1000 episodes on more complex tasks like Fuel World. As an example, here is how to run Q-Learning () on the Fuel World task () using the --nepisodes flag to run it for 1,000,000 episodes, which should be enough time for it to converge. Another problem you may run into is when running these methods on the continuous domains (mcar, cartpole, car2to7, car7to2, and carrrandom). For these domains, the tabular RL methods (Q-Learning, SARSA, Dyna, R-Max) will need the state to be discretized. The following command will run Q-Learning () on the Mountain Car task () while discretizing each of the state features into 10 discrete values using the --nstates option. rosrun rl_experiment experiment --agent type --env type [options]qlearner sarsa modelbased rmax texplore dyna savedpolicytaxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworldrosrun rl_experiment experiment --agent qlearner --env taxi --stochasticrosrun rl_experiment experiment --agent texplore --nmodels 8 --planner parallel-uct --actrate 10 --env fuelworld --deterministicrosrun rl_experiment experiment --agent qlearner --env fuelworld --nepisodes 1000000rosrun rl_experiment experiment --agent qlearner --env mcar --nstates 10"
W1928,https://wiki.ros.org/rbcar_control,Wiki,rbcar_control,"The rbcar_control package
"
W1929,https://wiki.ros.org/mr_tools,Wiki,mr_tools,"Some useful nodes for multi-robot teleoperation

 

This package contains 2 nodes that communicate with the input devices and publishes  to an arbitrary number of output topics, which allows control over a multiple number of robots. joy_cmd_veldevstring""/dev/input/js0""*input_topics parameter*set_inputset_output*input_topics parameter*current_inputcurrent_outputinput_topicsdictionaryoutput_topicslist of strings"
W1930,https://wiki.ros.org/ros_package_web_server,Wiki,ros_package_web_server,"Web server to host ROS package content


A webserver that serves ROS package resources. This is useful with  for serving resources that would normally be found with rospack. For example when displaying a URDF using  the robot model files must be served from somewhere. This package allows for these models to be served directly from the install location instead of having to copy resources to a separate web root. Resources are served with CORS enabled to allow for easy interop with resources served elsewhere. Navigating to the root path will display a list of all installed packages. Resources can then be loaded using by prefixing the path of the resource relative to the share location of the package. For installed packages this is in the share folder in the install location and for non-installed packages this is the package root. ~portint"
W1931,https://wiki.ros.org/rosprofiler,Wiki,rosprofiler,"The rosprofiler package provides the rosprofiler and rosgrapher tools.
      These tools run as nodes publishing their collected information on ros topics.
      They have been designed to work with the Topic Statistics feature found
      in ROS Indigo to provide a complete picture of a ROS System.



 () 


 () The rosprofiler package is commonly used with . /host_statistics/node_statistics/topologyrosparam set enable_statistics truerosrun rosprofiler rosprofilerrosrun rosprofiler rosgrapher"
W1932,https://wiki.ros.org/airbus_ssm_tutorial,Wiki,airbus_ssm_tutorial,The airbus_ssm_tutorial package
W1933,https://wiki.ros.org/cob_sick_s300,Wiki,cob_sick_s300,"This package published a laser scan message out of a Sick S300 laser scanner.


The  package provides two configurable nodes for operating with the scanners. 
This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g.  in the  stack. For starting use: All hardware configuration is done in the  package. A sample parameter file in ""cob_hardware_config/cob3-3/config/laser_front.yaml"" could look like this cob_sick_s300scanscan_standby/diagnosticsportstringbaudintscan_durationintscan_cycle_timeintinvertedbooleanscan_idintframe_idstringpublish_frequencyintcob_scan_filterscan_inscan_outscan_intervalslist of scan intervalsroslaunch cob_bringup laser_front.launch
roslaunch cob_bringup laser_rear.launch<include file=""$(find cob_bringup)/components/laser_front.launch"" />
<include file=""$(find cob_bringup)/components/laser_rear.launch"" />port: /dev/ttyScan1
baud: 500000
scan_duration: 0.025 #no info about that in SICK-docu, but 0.025 is believable and looks good in rviz
scan_cycle_time: 0.040 #SICK-docu says S300 scans every 40ms
inverted: true
scan_id: 7
frame_id: /base_laser_front_link
scan_intervals: [[-1.3526, 1.361357]] #[rad] these intervals are included to the scan"
W1934,https://wiki.ros.org/rocon_app_manager_msgs,Wiki,rocon_app_manager_msgs,Messages used by the platform app manager.
W1935,https://wiki.ros.org/simple_arm,Wiki,simple_arm,"Simple velocity controlled arm. Teleoperation software and firmware.
 




 
 Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. 
 We like PlatformIO: ""Single source code. Multiple platforms."" PlatformIO supports approximately 200 and all major. Learn more on. 
       
A simple arm system. : This package : This diagram is also available in . Package created by Ryerson University students for the , summer 2017. 3. Install the  onto a microcontroller connected to the arm joint motors by PWM. The microcontroller must also be connected to the computer running the simple_arm ROS node by a serial connection (ex. USB). This node converts  messages from the  node into a variety of commands that are sent over serial to a microcontroller to drive the robot arm. This node communicates with the  using a simple serial protocol. Each serial motion command is a list of floats, one for each joint. The  microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers. We deploy the  to an Arduino microcontroller using PlatformIO. More PlatformIO install info:  More PlatformIO info:  Feature requests, bug reports, and contributions are welcome at . joy_arm~microcontroller_serial_devicestring~baudrateintarm_firmwarearm_firmware$ sudo apt-get install ros-kinetic-simple-arm$ roslaunch simple_arm simple_arm.launch joystick_serial_dev:=/dev/input/js0 microcontroller_serial_dev:=/dev/ttyACM0(FLOAT) GRIP,
(FLOAT) WRIST_ROLL,
(FLOAT) WRIST_PITCH,
(FLOAT) UPPER_ELBOW,
(FLOAT) LOWER_ELBOW,
(FLOAT) BASE_YAW,
(FLOAT) CAMERA$ sudo python -c ""$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)""

# Enable Access to Serial Ports (USB/UART)
$ sudo usermod -a -G dialout <your username here>
$ curl https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules  > /etc/udev/rules.d/99-platformio-udev.rules
# After this file is installed, physically unplug and reconnect your board.
$ sudo service udev restart$ roscd simple_arm
$ cd ./arm_firmware/
# Find the microcontroller that you have in the list of PlatformIO boards
$ pio boards | grep -i mega2560
# Use the name of your board to initialize your project
$ pio init --board megaatmega2560$ vim src/main.cpp +9










$ vim src/main.cpp +4




$ pio run --target upload"
W1936,https://wiki.ros.org/kingfisher_teleop,Wiki,kingfisher_teleop,"
    This package contains launch files which enable simple 
    teleoperation of the Clearpath Robotics Kingfisher.
    "
W1937,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14692/6  "
W1938,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20291/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W1939,https://wiki.ros.org/neo_msgs,Wiki,neo_msgs,"This package contains copies of former pr2_msgs (ported to ROS indigo) 
	as well as new messages for neobotix robots."
W1940,https://wiki.ros.org/libviso2,Wiki,libviso2,"

    This is a ROS-Package for libviso2, a library for visual odometry created by Andeas Geiger
    from the Institute of Measurement and Control Systems at Karlsruhe Institute of Technology.

    Apart from the original libviso2 sources, this package contains
    a CMakeFile for easier integration into the ROS build system.

    Please note that this code is licensed under GPL. For a commercial usage, please
    contact Andreas Geiger directly (see
    ).

  See the  package for nodes that use this library. Related publications can be found . The main paper that describes this library is: @INPROCEEDINGS{Geiger11,
 author = {Andreas Geiger and Julius Ziegler and Christoph Stiller},
 title = {StereoScan: Dense 3d Reconstruction in Real-time},
 booktitle = {IEEE Intelligent Vehicles Symposium},
 year = {2011},
 month = {June},
 address = {Baden-Baden, Germany}
}"
W1941,https://wiki.ros.org/rb1_base_sim,Wiki,rb1_base_sim,"The rb1_base_sim metapackage
 






This package contains the different controllers and launch files for the  simulation.  "
W1942,https://wiki.ros.org/rocon_bubble_icons,Wiki,rocon_bubble_icons,"Bubble icon library for rocon. 

"
W1943,https://wiki.ros.org/multi_jackal_tutorials,Wiki,multi_jackal_tutorials,"Tutorials for multi-Jackal simulations.
 provides examples on how to simulate multiple  in Gazebo.  


   
 
 Gazebo will be generating the ROS clock, so it can simulate faster or slower than real time (this is set in the world description). If  is set to , the Gazebo client will also appear. This can also be done after launching by running  in a new terminal. The namespace  must be unique (like jackal0, jackal1, etc), so that individual robots can be identified. The configuration type  specifies the components on the jackal. This string must match a file located in . The configuration ID  is used if required by the configuration. Movement to goal locations is provided through . The model description (), navigation (), and controllers (), are all called through the Jackal base (). Frames have also been prefixed by the namespace (right click -> view image to zoom in): A number of arguments can be specified when creating a Jackal. These are listed in (). multi_jackal_tutorialsguitruegzclientnsconfigconfig_idrosdep install multi_jackal_tutorialssudo apt-get install ros-kinetic-multi-jackal-tutorialsroslaunch multi_jackal_tutorials one_jackal.launch rviz:=true
















roslaunch multi_jackal_tutorials two_jackal.launch rviz:=true













"
W1944,https://wiki.ros.org/rr_swiftnav_piksi,Wiki,rr_swiftnav_piksi,"Rover Robotics: ROS package for connecting to SwiftNav Piksi
 Install binaries via aptitude package manager  Install source from github (only use if you want to make custom changes to the source code) 


This package requires 's . Install before installing this package.  swiftnav_piksi_tcp_node/swift_nav/enable_comms/cmd_vel/managed/swift_gps/llh/position/swift_gps/llh/fix_mode/swift_gps/llh/n_sats/swift_gps/baseline/ecef/position/swift_gps/imu/raw~piksi_ip_addressstring1.2.3.10~piksi_portstring~base_station_ip_addressstring111.111.111.111~piksi_portstring~computer_ip_addressstring1.2.3.55sudo apt install ros-kinetic-rr-swiftnav-piksicd ~/catkin_ws/src/
git clone https://github.com/RoverRobotics/rr_swiftnav_piksi.git
cd ~/catkin_ws/
catkin_make
source devel/setup.bashrosrun rr_swiftnav_piksi swiftnav_piksi_tcp.py"
W1945,https://wiki.ros.org/rbcar_sim_bringup,Wiki,rbcar_sim_bringup,"The rbcar_sim_bringup package
"
W1946,https://wiki.ros.org/smach_viewer,Wiki,smach_viewer,"The smach viewer is a GUI that shows the state of hierarchical
    SMACH state machines. It can visualize the possible transitions
    between states, as well as the currently active state and the
    values of user data that is passed around between states. The
    smach viewer uses the SMACH debugging interface based on
    the  to gather information from running state machines.
 Your state machine needs to run an introspection server to allow the smach viewer to connect to it. See  for more details.  

 
 
 rosrun smach_viewer smach_viewer.py"
W1947,https://wiki.ros.org/jaco_teleop,Wiki,jaco_teleop,"Various Nodes for Teleoperating the JACO Arm







The  package provides various methods for human control of the JACO and JACO2 arm via keyboard teleoperation and joystick/gamepad teleoperation.  This may work for the MICO as well, but it has not yet been tested. The joystick teleop node currently supports both gamepads with analog triggers and gamepads with digital triggers.  The gamepad type can be set on launch with the  parameter.  Currently, the node has been tested with the Logitech Dual Action wired controller (digital triggers), the Logitech Wireless Gamepad (analog triggers), and the Microsoft XBOX 360 wired controller (analog triggers).  If your gamepad does not work with this node, you can remap the axes and buttons using  package, or open an issue in the code repository and support for the new controller may be added. To install the  package, you can install from source with the following commands: Joystick or keyboard teleop can be started with the launch files  and , respectively.  Both files have parameters for velocity limits, which can be set on launch to limit the velocities of the arm's translation, rotation, and finger movement.  Furthermore,  includes a parameter for the controller type, which can currently be set to either ""analog"" or ""digital"", representing controllers with analog triggers and digital triggers, respectively. Example launch syntax is given below. jaco_teleopjoyjaco_arm/angular_cmdjaco_arm/cartesian_cmdjaco_arm/software_estoplinear_throttle_factordoubleangular_throttle_factordoublefinger_throttle_factordoublecontroller_typestringwpi_jaco/arm_namestringjaco_arm/angular_cmdjaco_arm/cartesian_cmdlinear_throttle_factordoubleangular_throttle_factordoublefinger_throttle_factordoublewpi_jaco/arm_namestringcontroller_typewpi_jacojaco_joy_teleop.launchjaco_key_teleop.launchjaco_joy_teleop.launch




roslaunch jaco_teleop jaco_joy_teleop.launchroslaunch jaco_teleop jaco_key_teleop.launchroslaunch jaco_teleop jaco_joy_teleop.launch linear_throttle_factor:=0.5 angular_throttle_factor:=0.5 finger_throttle_factor:=0.75 controller_type:=""analog""roslaunch jaco_teleop jaco_key_teleop.launch linear_throttle_factor:=0.5 angular_throttle_factor:=0.5 finger_throttle_factor:=0.75"
W1948,https://wiki.ros.org/multi_jackal_description,Wiki,multi_jackal_description,"Spawns the Jackal model.
 contains the robot model description for a . It has been extended from the single robot  to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time. 
 There are tutorials on how to spawn robots using this package in . multi_jackal_description"
W1949,https://wiki.ros.org/asr_kinematic_chain_dome,Wiki,asr_kinematic_chain_dome,"This package provides information about the PbD dome's kinematic chain and contains launch-files to publish the chain to a robot_state_publisher. Available launchfiles are: dome with real PTU, dome with simulated PTU, dome with real PTU and Flock of Birds and additional transformation_publisher from guppy-cameras to the kinect cameras mounted above. It also contains the urdf model. 
 
     

 

The kinematic chain consists of two major parts: The camera-system (PTU, Guppy-Cameras and Kinect) and the Flock of Birds magnet tracking system (Receiver and Tracker). Colors form the picture above. The fixed reference Frame is in the PTU and is called . There is an identity transformation to  which is mostly used. The TF is published at topic /tf. The visualization is available in the RobotModel. start rviz and roslauch asr_kinematic_chain_dome dome_mock.launchroslauch asr_kinematic_chain_dome dome.launchrosrun asr_kinematic_chain_dome dome_with_fob.shroslauch asr_kinematic_chain_dome transformation_publishers_for_kinect_left.launch"
W1950,https://wiki.ros.org/map_store,Wiki,map_store,"

     Storage manager for OccupancyGrid maps.  Supports naming the most
     recent map, getting a list of map names, and publishing a
     specific map.

  

  "
W1951,https://wiki.ros.org/reemc_gazebo,Wiki,reemc_gazebo,Simulation files for the REEM-C robot.
W1952,https://wiki.ros.org/soem_ebox,Wiki,soem_ebox,This package contains the components of the soem_ebox package
W1953,https://wiki.ros.org/rocon_rosjava_core,Wiki,rocon_rosjava_core,"Rocon related libraries in rosjava.
For more information on the interactions framework, refer to  and example android development, refer to the  main page. "
W1954,https://wiki.ros.org/agvs_sim,Wiki,agvs_sim,"agvs Gazebo simulation packages
 





This package contains the different controllers and launch files for the  simulation.  1.  "
W1955,https://wiki.ros.org/agvs_sim_bringup,Wiki,agvs_sim_bringup,"The agvs_sim_bringup package. It contains multiple launch files to perform different tasks, from creating a map with gmapping to launching amcl.
"
W1956,https://wiki.ros.org/mrpt_sensors,Wiki,mrpt_sensors,"ROS nodes for various robotics sensors via mrpt-hwdrivers

Use GitHub to . []
  ROS nodes for various robotics sensors via . "
W1957,https://wiki.ros.org/ros_topology_msgs,Wiki,ros_topology_msgs,Messages describing the topology of the ros graph.These messages are used with the tools in the  package. 
W1958,https://wiki.ros.org/self_test,Wiki,self_test,"self_test





You can get a list of the available subtests with the rosservice command:You can then run the self test using rosservice:You can get different output with the   node: The  class will advertise a service ""~self_test"". When called, it will perform a check on the node's connection status, and any other checks a developer wants to perform on a node or device. An example use of the self_test package's API can be found in . self_test contains the  class that can be used to sequence a set of tests to be run in order to test a device. It advertises a self_test service. When the service is called, the  calls the tests that have been defined in order, and combines the results into a  array (see the service definition ). A detailed example can be found in . run_selftestself_test::TestRunner~node_to_teststring~max_delaystringself_test$ rosservice list | grep ""/self_test$""
/hokuyo_node/self_test$ rosservice call /hokuyo_node/self_test$ rosrun self_test run_selftest /hokuyo_node/self_test"
W1959,https://wiki.ros.org/rtt_typelib,Wiki,rtt_typelib,"
    "
W1960,https://wiki.ros.org/jackal_desktop,Wiki,jackal_desktop,"Packages for working with Jackal from a ROS desktop.To get started using Jackal from a desktop ROS environment, see . "
W1961,https://wiki.ros.org/abb_irb4400_support,Wiki,abb_irb4400_support,"
      ROS-Industrial support for the ABB IRB 4400 (and variants).
    
      This package contains configuration data, 3D models and launch files
      for ABB IRB 4400 manipulators. This currently includes the L30.
    
      Joint limits and max joint velocities are based on the information in the
       (Article No: 3HAC 8770-1).
      All urdfs / xacros are based on the default motion and joint velocity
      limits, unless noted otherwise (ie: no support for high speed joints,
      extended / limited motion ranges or other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1962,https://wiki.ros.org/micros_hopfield,Wiki,micros_hopfield,"A package for path planning



Run these commands under ~/catkin_ws directory for the terrain map loading. run different clients in independent terminal. 
 The package is inspired by and adapted from [1]. Related details about neural network based path planning may also be found in  ], ] and ]. 
cd catkin_ws/src
git clone http://github.com/micros-uav/micros_hopfield
cd ..
catkin_makerosrun rviz rvizsource devel/setup.bash
rosrun micros_hopfield plan_serversource devel/setup.bash
rosrun micros_hopfield plan_client i"
W1963,https://wiki.ros.org/robot_markers,Wiki,robot_markers,"Generates markers for a robotUse GitHub to . []
 
 is a library for creating  for a robot, given a .  
 is the main interface for building a  from a URDF. The library's generated documentation explains how to use . First, create a  for a given URDF: A notable feature of  is the ability to set the joint angles of the robot. To do so, pass in a map that gives the joint angles for a set of joint names.  does not check joint angle limits. Once you have configured the visualization, call , passing in a marker array to append the robot markers to. robot_markersrobot_markersBuilderBuilderBuilderBuilder::Build
















































































"
W1964,https://wiki.ros.org/kvh,Wiki,kvh,A driver for the KVH DSP-3000 single-axis Fiber Optic Gyroscope.
W1965,https://wiki.ros.org/multi_jackal_control,Wiki,multi_jackal_control,"Creates the joint and velocity controllers.
 contains the launch files and parameters providing joint and velocity controllers for multiple simulated . It has been extended from the single robot  to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  
There are tutorials on how to use this package in . multi_jackal_control"
W1966,https://wiki.ros.org/reemc_simulation,Wiki,reemc_simulation,"REEM-C-specific simulation components. These include plugins
               and launch scripts necessary for running REEM-C in simulation.

Use GitHub to . []
  "
W1967,https://wiki.ros.org/r2_moveit_config,Wiki,r2_moveit_config,An automatically generated package with all the configuration and launch files for using the r2 with the MoveIt Motion Planning Framework
W1968,https://wiki.ros.org/mm_messages,Wiki,mm_messages,Message definitions and serialisations for core messages.
W1969,https://wiki.ros.org/soem_beckhoff_drivers,Wiki,soem_beckhoff_drivers,"soem_beckhoff_drivers contains drivers for the ethercat beckhoff modules to work together with the soem_master package, every module creates the necessary services, dataports and properties for its own functionality."
W1970,https://wiki.ros.org/rocon_device_msgs,Wiki,rocon_device_msgs,"Messages used by rocon devices
"
W1971,https://wiki.ros.org/ros_in_hand_scanner,Wiki,ros_in_hand_scanner,"The ros_in_hand_scanner package
 




 This  shows a scanning process using Intel  Camera. This package needs PCL 1.8.0 to be installed. See  for further information. Due to performance issues, a realtime registration is very slow with down to < 0.1 fps. A workaround is to record a rosbag file during the scanprocess itself. You can use the preview window to get a view of your actual scan orientation. Play the rosbag file afterwards with a low rate ~0.1 and start registration now. Follow the hints in the PCL documentation for your scan process. camera/depth_registered/points#Prepare Workspace
source /opt/ros/indigo/setup.bash
mkdir -p ~/rihs_ws/src
cd ~/rihs_ws/src
catkin_init_workspace
cd ~/rihs_ws/
catkin_make
source devel/setup.bash

#Get ROS In-hand scanner
cd ~/rihs_ws/src
git clone http://github.com/RodBelaFarin/ros_in_hand_scanner
cd ~/rihs_ws/

#Install
rosdep update
rosdep install ros_in_hand_scanner
catkin_makeroscore
rosrun ros_in_hand_scanner ros_in_hand_scanner_node"
W1972,https://wiki.ros.org/schunk_robots,Wiki,schunk_robots,"
  
    This stack holds packages for hardware configuration as well as launch files for starting up Schunk components.

  


See . Please consult  to see if your problem is already known. Use  to report bugs or request features. "
W1973,https://wiki.ros.org/rocon_msgs,Wiki,rocon_msgs,"Communication types (msgs/srvs/actions) for robotics in concert (aka multimaster).
 
Use github to report . . "
W1974,https://wiki.ros.org/rh_p12_rn_gazebo,Wiki,rh_p12_rn_gazebo,"This package provides basic message pub and launch file to use RH-P12-RN on Gazebo 
"
W1975,https://wiki.ros.org/ackermann_hks,Wiki,ackermann_hks,"

     HKS game controller tele-operation interface for driving a
     vehicle with Ackermann steering under human control.

  



 ackermann_cmdrosrun ackermann_qt hks_teleop"
W1976,https://wiki.ros.org/asr_mild_base_laserscanner,Wiki,asr_mild_base_laserscanner,"This package provides streams of laser scan messages in cartesian coordinates from a planar sick laser scanner. 


  
 if you want to start the node with the mild.launch file. 
 



The main class is sick.cpp. It contains the SICK configuration and starts the code which communicates with the SICK. Also, it publishes the scan data to ROS. All other code is based on the  . The toolbox also contains code for other SICK laserscanners. For a successful laserscan you only need to connect the SICK PLS 101-312 laserscanner to your PC. You can use USB or a Serial interface. For a baudrate of 500k you need USB or a RS422 Serial port and cable. To establish a connection, you must adapt the name of the connected port (look at parameter ""serial""). Then you only need to start a launchfile with the laserscanner node e.g. . _/scan_ (  Look at  on how to adapt the parameters. roslaunch asr_mild_base_launch_files mild.launchrosrun mild_base_laserscanner mild_base_laserscannerInit. complete: Sick PLS is online and ready!
tScan Angle: 180
tScan Resolution: 0.5
tMeasuring Units: cm"
W1977,https://wiki.ros.org/asr_kinematic_chain_optimizer,Wiki,asr_kinematic_chain_optimizer,"This package calculates the best approximation for a kinematic chain's parameters using rosenbrock optimization. For calculation, a layout of the kinematic chain must be provided, as well as a set of transformations between two frames of the chain that has been acquired during calibration. 



.   








 <Data> </Data>  
    To specify an input-file use the -tag. This surrounds the whole file. To specify the structure of your kinematic chain use the -tag. In this area the tf-frames are defined. There are some different types of frames: A simple parent-child relation is defined as , with Frame1 is the parent node of Frame 2. To specify the goal function (for closing you kinematic chain) use the -tag. The goal can be ether the position, orientation or both. The position use the -Tag. With this goal, the algorithm tries to set the position of Frame1 equal to the one of Frame2. Same for  with the frames orientations. The data-file contains just the n-tuple datasets. One n-tuple is in one line. The single values are separated with a semicolon and a space. The program maps the data in column one to the first parameter (e. g. ""[1]"") and so on.  The optimizer outputs the calculated values for the kinematic chain parameters directly to the console.  roslaunch asr_kinematic_chain_optimizer optimizer.launch"
W1978,https://wiki.ros.org/b21_description,Wiki,b21_description,b21_description 
W1979,https://wiki.ros.org/robot_model,Wiki,robot_model," This metapackage will be removed in ROS M. Replace all dependencies on
      ""robot_model"" in your package.xml with dependencies on collada_parser,
      collada_urdf, joint_state_publisher, kdl_parser, resource-retriever, urdf,
      urdf_parser_plugin, and liburdfdom-tools instead. contains packages for modeling various
    aspects of robot information, specified in the Xml Robot
    Description Format (URDF). The core package of this stack
    is , which parses URDF files, and constructs an
    object model (C++) of the robot.


 provides the following ROS : 
  robot_modelrobot_modelrobot_modelrobot_modelrobot_modelrobot_modelrobot_modelrobot_modelrobot_model.iv.stl"
W1980,https://wiki.ros.org/scriptable_monitoring,Wiki,scriptable_monitoring,"scriptable_monitoring
 
Use GitHub to . []
  Scriptable monitoring provides a tool that runs monitoring scripts (Python or predicate-like), allowing a definition of monitoring rules for values obtained via topic messages, and also alerts about violated rules to the  topic, which can be monitored using rqt plugins like  or . scriptable_monitoring"
W1981,https://wiki.ros.org/phoxi_camera,Wiki,phoxi_camera,"The phoxi_camera package



 () 
 () 
The phoxi_camera driver provides a ROS interface for  devices. The point cloud published by the phoxi_camera node can be viewed with . /phoxi_camera/pointcloud/phoxi_camera/confidence_map/phoxi_camera/normal_map/phoxi_camera/texture~vertical_resolutionint~horizontal_resolutionint~scan_multiplierint~shutter_multiplierint~trigger_modeint~timeoutint~confidencedouble~send_point_cloudbool~send_normal_mapbool~send_texturebool~send_confidence_mapbool$ cd ~/catkin_ws/src
$ git clone https://github.com/photoneo/phoxi_cameraroslaunch phoxi_camera phoxi_camera.launch"
W1982,https://wiki.ros.org/shape_msgs,Wiki,shape_msgs,"This package contains messages for defining shapes, such as simple solid
    object primitives (cube, sphere, etc), planes, and meshes."
W1983,https://wiki.ros.org/motoman_mh_support,Wiki,motoman_mh_support,"
      ROS-Industrial support for the Motoman MH series (and variants).
    
      This package contains configuration data, 3D models and launch files
      for Motoman MH series manipulators. This currently includes the MH180-120
      only.
    
      Joint limits and max joint velocities are based on the information in the
      .
      All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W1984,https://wiki.ros.org/neo_watchdogs,Wiki,neo_watchdogs,"The neo_watchdogs package



/move_base/goal/srb_emergency_stop_state/move_base/goal"
W1985,https://wiki.ros.org/create_driver,Wiki,create_driver,"Driver for iRobot Create and Roomba
    
    This is a generic driver for iRobot Create that currently holds
    implementations for Turtlebot and Roomba. Port
    of pyrobot.py by Damon Kohler.  It is currently labeled as
    turtlebot_driver pending review by the entire create community
    before using the name create_driver.
  
    For ROS bindings, please see turtlebot_node."
W1986,https://wiki.ros.org/remote_monitor,Wiki,remote_monitor,"The remonot monitor package

 



















 (, default: 0.2) 
 (, default: 1.0) 
c () Remote monitoring package for navigation with . We actually succeeded in remotely monitoring 's pose running in Tsukuba from Fukuoka () How to connect remote PCs with OpenVPN can be seen in . Tutorial to integrate OpenVPN and ROS is . nodeservicenodeservice/amcl_posesubscribe<catkin_ws>tunratiodoubleinterval_distdoublepose_topicstringsubscribecurrenthistoryreset historyhistoryplus to ratiominus to ratio$ roslaunch cirkit_unit03_autorun autorun_gazebo.launch 
$ roslaunch remote_monitor remote_monitor_server_gazebo.launch
$ roslaunch remote_monitor remote_monitor_client_gazebo.launch $ cd <catkin_ws>/src
$ git clone https://github.com/CIR-KIT/remote_monitor.git$ cd <catkin_ws>
$ wstool init src
$ wstool merge -t src src/remote_monitor/remote_monitor.rosinstall
$ wstool update -t src$ rosdep update && rosdep install -r -y --from-paths src --ignore-src$ cd <catkin_ws>
$ catkin_make
$ source devel/setup.bash$ roslaunch remote_monitor remote_monitor_server.launch map_yaml:=hogehoge.yaml$ roslaunch remote_monitor remote_monitor_server_gazebo.launch map_yaml:=hogehoge.yaml$ cd /etc/openvpn
$ emacs client.conf# 省略

# グローバルIPアドレスを指定する．
remote 101.102.103.xxx 1194

# 省略$ service openvpn restart$ ifconfigtun0      Link encap:不明なネット  ハードウェアアドレス 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  
          inetアドレス:10.8.0.6  P-t-P:10.8.0.5  マスク:255.255.255.255
          UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1500  メトリック:1
          RXパケット:0 エラー:0 損失:0 オーバラン:0 フレーム:0
          TXパケット:12 エラー:0 損失:0 オーバラン:0 キャリア:0
          衝突(Collisions):0 TXキュー長:100 
          RXバイト:2892 (2.8 KB)  TXバイト:504 (504.0 KB)$ ping 10.8.0.1export ROS_MASTER_URI=http://10.8.0.6:11311
export ROS_HOST_NAME=10.8.0.6
export ROS_IP=10.8.0.6roscd remote_monitor/scripts
source vpn_setting_for_robot.sh$ env | grep ROS$ rosservice list/remote_monitor_robot_pose
/remote_monitor_human_pose$ roslaunch remote_monitor remote_monitor_client.launch$ roslaunch remote_monitor remote_monitor_client_gazebo.launch"
W1987,https://wiki.ros.org/serial_utils,Wiki,serial_utils,A package which adds useful additions to the serial package.
W1988,https://wiki.ros.org/rosweb,Wiki,rosweb,"rosweb is a temporary package to replace the original rosweb in the ROS
     repository.  It is placed in the sandbox while development is ongoing, so
     we are not gated on ROS stack releases.  When the server is more stable,
     it will be moved to the ROS repository and replace the old rosweb.
"
W1989,https://wiki.ros.org/rf2o_laser_odometry,Wiki,rf2o_laser_odometry,"Estimation of 2D odometry based on planar laser scans. Useful for mobile robots with innacurate base odometry.
    For full description of the algorithm, please refer to:
    Planar Odometry from a Radial Laser Scanner. A Range Flow-based Approach. ICRA 2016
    Available at: http://mapir.isa.uma.es/mapirwebsite/index.php/mapir-downloads/papers/217



The user is advised to check the related papers () for a more detailed description of the method. rf2o_laser_odometrytflaser_scantfodomtf~laser_scan_topicstring~base_frame_idstringtflaser_framebase_frame~odom_frame_idstring~freqdouble"
W1990,https://wiki.ros.org/rosjson,Wiki,rosjson,"rosjson is a Python library for converting ROS messages to JSON
     (JavaScript Object Notation) representation.


The JSON (JavaScript Object Notation) format is useful when building Web-based interfaces that need access to ROS data. rosjson is meant to be coupled with a Python Web server so that the JSON objects can be served over a Web connection.  is one example Web server implementation, but it is currently in high design flux. No further features are planned for the ROS JSON library as JSON itself is just a data representation. Python 2.6 has a json module that would simplify the existing code and make it more robust, but as the current package is < 50 lines of Python, there's not much to improve upon. "
W1991,https://wiki.ros.org/kingfisher_description,Wiki,kingfisher_description,URDF description for Kingfisher  
W1992,https://wiki.ros.org/neo_platformctrl_diff,Wiki,neo_platformctrl_diff,"transformation node for neobotix robots woth differential drive


 /joint_states/cmd_vel/odom/cmd_joint_trajkinematicswheelDiameterrobotWidthsendTransform"
W1993,https://wiki.ros.org/scheduler_msgs,Wiki,scheduler_msgs,Messages used by the rocon scheduler.
W1994,https://wiki.ros.org/softkinetic_camera,Wiki,softkinetic_camera,"Softkinetic cameras drivers, including filters."
W1995,https://wiki.ros.org/receive_ublox,Wiki,receive_ublox,"

     ROS driver for U-blox GPS receivers

   

/gps/dataroslaunch receive_ublox.launch"
W1996,https://wiki.ros.org/rv4fl_moveit_config,Wiki,rv4fl_moveit_config,An automatically generated package with all the configuration and launch files for using the rv4fl with the MoveIt! Motion Planning Framework
W1997,https://wiki.ros.org/lower_step_detector,Wiki,lower_step_detector,"The lower_step_detector package



To install the  package, you can install from source with the following commands: lower_step_detector




"
W1998,https://wiki.ros.org/roslang,Wiki,roslang,"roslang is a common package that all  depend on.
    This is mainly used to find client libraries (via 'rospack depends-on1 roslang').
The  package is only of interest to those implementing a ROS . Client libraries marks themselves as such by depending on the  package, which allows  and other tools to perform appropriate actions, such as - and -based code generation. The  package itself contains no actual code. roslangroslangroslang"
W1999,https://wiki.ros.org/multi_jackal_nav,Wiki,multi_jackal_nav,"Localization and navigation for the Jackal.
 contains the launch files and parameters providing localization and waypoint following for multiple simulated . It has been extended from the single robot  to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  
There are tutorials on how to use this package in . multi_jackal_nav"
W2000,https://wiki.ros.org/omip_msgs,Wiki,omip_msgs,"Messages for OMIP - Online Multimodal Interactive Perception

Package defining the messages for OMIP . (Main author) Roberto Martín-Martin (, ) Sebastian Höfer (, ) Oliver Brock () "
W2001,https://wiki.ros.org/prosilica_gige_sdk,Wiki,prosilica_gige_sdk,AVT GigE SDK version 1.26 for ROSNOTE: The recommended way of using Prosilica cameras in ROS is through the driver in . You need only use this package directly if you are writing your own software for interacting with Prosilica cameras without going through ROS. $ rosrun prosilica_gige_sdk EXE_NAME [OPTIONS]$ SampleViewer$ ListCameras$ Ping <IP>$ ListAttributes [IP]$ ResetCamera <IP>
W2002,https://wiki.ros.org/joint_tracker,Wiki,joint_tracker,Tracker of the kinematic model (structure and state) based on the motion of a set of rigid bodies
W2003,https://wiki.ros.org/neo_base_mpo_700,Wiki,neo_base_mpo_700,launchfiles for MPO_500
W2004,https://wiki.ros.org/airbus_pyqt_extend,Wiki,airbus_pyqt_extend,The airbus_pyqt_extend package
W2005,https://wiki.ros.org/sound_play,Wiki,sound_play,"sound_play provides a ROS node that translates commands on a ROS topic () into sounds. The node supports built-in sounds, playing OGG/WAV files, and doing speech synthesis via festival. C++ and Python bindings allow this node to be used without understanding the details of the message format, allowing faster development and resilience to message format changes.














 If you need the information in this section for something other than satisfying curiosity, you are probably doing something wrong. The  node considers each sound (built-in, wave file or synthesized text) as an entity that can be playing, playing repeatedly or stopped. Nodes change the state of a sound by publishing to the  topic. Multiple sounds can be played at once. C++ and Python bindings are provided. It should be unnecessary to directly generate messages when playing sounds from C++ or Python. Documentation of the language bindings are in . The following utilities can be used to play sound when  is running. For help on getting  running refer to the . The  script can play any  or  file. The file must be available on the computer on which  is running, and an absolute path should be given. Some standard sounds are built-into the driver, and can be played only by specifying their integer identifier using . For example ( should be running first): To get an up-to-date list of the built-in sounds, consult the definition of the  message. The relevant information is below the """" comment. The sound node can also be used to synthesize speech using the . The  script gives command-line access to this functionality. This script can take its input from the command line, or if the command-line is empty it can take input from standard input. Examples ( should be running first): The most immediate way to silence the robot is to use  to mute or lower the volume. In some cases, a node that had requested a continuous sound could crash with the sound still playing. In order to stop that sound the  script can be used. The  script sends a stop command on all sounds every 100ms until it is terminated. This behavior will immediately stop any continuous sounds that were playing, and will cut short any new sounds that are played. It will not completely silence the robot, however, as the first tens of milliseconds of newly requested sounds will be played before they are silenced. To test that  is operating correctly, you can use the  script. It will play the various built-in sounds, and exercise the  playing and text-to-speech capabilities. To run it: The following launch file, which starts , can be found in : Sound commands are issued to  via a  message. Commands define two things: a sound, and what to do with that sound.  The sound is defined by the  (int) and  (string) fields of the message, and can be one of four types: Each message on the  topic will cause a sound to transition between the playing continuously, playing once (or twice) and stopped states. For example, a backing up sound could be initiated by sending a command for a backing up sound to play continuously. When the robot stops backing up, a stop command will stop playback. Likewise, verbal debugging messages could be used by telling a sound to play once. In this case there is no need to stop playing the sound. robotsoundrobotsoundrobotsoundrobotsoundrobotsoundrobotsoundrobotsoundrobotsoundrobotsoundrobotsoundsound_playrobotsoundsoundplay_node.pysoundplay_node.pyplay.py.WAV.OGGsoundplay_node.pyplaybuiltin.pysoundplay_node.pySoundssay.pysoundplay_node.pyalsamixershutup.pyshutup.pysoundplay_node.pytest.py.WAVsoundplay_node.pyrobotsoundrobotsounddiagnosticssoundplay_node.pysoundplay_node.launchrobotsoundsoundplay_node.pysoundargsoundPLAY_FILEsoundsoundplay_node.pyargSAYsoundargALLsoundrobotsound$ rosrun sound_play play.py --help
Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/play.py sound_to_play.(ogg|wav)

Plays an .OGG or .WAV file. The path to the file should be absolute, and be valid on the computer on which sound_play is running.$rosrun sound_play play.py /usr/share/xemacs21/xemacs-packages/etc/sounds/im_so_happy.wav
Playing ""/usr/share/xemacs21/xemacs-packages/etc/sounds/im_so_happy.wav"".$ rosrun sound_play playbuiltin.py 
Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/playbuiltin.py <sound_id>

Plays one of the built-in sounds based on its integer ID. Look at the <<MsgLink(sound_play/SoundRequest)>> message definition for IDs.$ rosrun sound_play playbuiltin.py 2
Playing sound 2"".$ cat `rospack find sound_play`/msg/SoundRequest.msg
# Sounds
byte BACKINGUP = 1
byte NEEDS_UNPLUGGING = 2
byte NEEDS_PLUGGING = 3
byte NEEDS_UNPLUGGING_BADLY = 4
byte NEEDS_PLUGGING_BADLY = 5

# Sound identifiers that have special meaning
byte ALL = -1 # Only legal with PLAY_STOP
byte PLAY_FILE = -2
byte SAY = -3

byte sound # Selects which sound to play (see above)

# Commands
byte PLAY_STOP = 0 # Stop this sound from playing
byte PLAY_ONCE = 1 # Play the sound once
byte PLAY_START = 2 # Play the sound in a loop until a stop request occurs

byte command # Indicates what to do with the sound

string arg # file name or text to say$ rosrun sound_play say.py --help
$ rosrun sound_play say.py --help
Usage: /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/say.py 'String to say.'
       /u/blaise/ros/ros-pkg/stacks/sound_drivers/sound_play/scripts/say.py < file_to_say.txt

Says a string. For a string on the command line, you must use quotes as
appropriate. For a string on standard input, the command will wait for
EOF before saying anything.$ rosrun sound_play say.py 'Hello world'
Saying: Hello world.
$ echo Hello again|rosrun sound_play say.py
Awaiting something to say on standard input.
Saying: Hello again$ rosrun sound_play shutup.py 
Sending stopall command every 100 ms.
Note: This will not prevent a node that is continuing to issue commands
from producing sound.
Press Ctrl+C to exit.$ rosrun sound_play test.py<launch>
  <node name=""soundplay_node"" pkg=""sound_play"" type=""soundplay_node.py""/>
</launch>"
W2006,https://wiki.ros.org/mm_mux_demux,Wiki,mm_mux_demux,"Multiplexing many packet types across a single connection. Great for embedded connections
   by serial or ethernet types."
W2007,https://wiki.ros.org/rbcar_joystick,Wiki,rbcar_joystick,The rbcar_joystick package
W2008,https://wiki.ros.org/sick_visionary_t_driver,Wiki,sick_visionary_t_driver,"Open source driver for the SICK Visionary-T 3D TOF camera.
  




 
This is an open source driver for the . The visionary-T is a 3D camera based on the time-of- flight (TOF) principle. It provides real-time 3D data at up to 30 frame per second (fps). The 3D camera is configured and its images visualized via the  software. The digital i/o channel interface of this driver is considered  and  yet. The  parameter in the launch file needs to be set to the verified device IP address. This easiest way is to provide the parameter is in the launch file (). remote_device_iplaunch/sick_visionary_t_driver.launchcamera/camera_infocamera/depthuint16camera/confidenceuint16camera/intensityuint16camera/ios/diagnosticscamera/scancamera/cartesianenable_depth_mapenable_height_mapenable_polar_scan~remote_device_ipstring~frame_idstring~prevent_frame_skippingbool~io_polling_intervaldouble~channelstring~userstring"
W2009,https://wiki.ros.org/manipulator_h_gazebo,Wiki,manipulator_h_gazebo,"The manipulator_h_gazebo package
    This package provides GAZEBO simulation environment for ROBOTIS MANIPULATOR-H.
    We provides two controllers such as position and effort controllers. 
 "
W2010,https://wiki.ros.org/ros_wild,Wiki,ros_wild,"The ros_wild package






 Most usages are listed in  and some examples scripts are in . $ sudo apt install ros-kinetic-ros-wild$ cd /path/to/your/catkin_ws/src/
$ git clone https://github.com/yuma-m/ros_wild.git
$ cd ../
$ catkin_make"
W2011,https://wiki.ros.org/futaba_serial_servo,Wiki,futaba_serial_servo,The futaba_serial_servo package
W2012,https://wiki.ros.org/rosunit,Wiki,rosunit,"Unit-testing package for ROS. This is a lower-level library for rostest and handles unit tests, whereas rostest handles integration tests. 
 is an internal tool for running unit tests within ROS.  While it can be run by a regular user, most users will generally use  indirectly via  test macros.  The main feature that  provides is terminating a unit test based on a timeout and generating an appropriate test failure.  The rosbuild system uses this feature to ensure that unit tests properly terminate.  currently supports: 

      
 The library that comes with  can be used as described at  These helper scripts are intended for use only by the  and test reporting infrastructure. Historically, rosunit is based on a refactoring of . It provides the unit-test infrastructure and rostest provides the integration test infrastructure. rostest is also allowed to interact with a running ROS graph. The initial separation was not perfect. There is more room to migrate more code from rostest into rosunit. Similarly, there is code within rosunit that would be better supported by a graph-less version of , i.e. a process monitor unattached to a ROS master. Until that happens, rosunit contains code that is a copy of internal libraries within roslaunch. rosunitrosunitrosunitrosunitunittestrosunit-t--text--namepython--time-limitclean_junit_xml.pytest_results/_hudsoncheck_test_ran.py <test-file.xml>check_test_ran.py --rostest <pkg-name> <test-file.xml>--rostestsummarize_results.py <package>test_results_dir.pypycoverage_to_html.pycoverage.py$ rosrun rosunit rosunit -h

Usage: rosunit [options] <file> [test args...]

Options:
  -h, --help            show this help message and exit
  -t, --text            Run with stdout output instead of XML output
  --time-limit=TIME_LIMIT
                        Set time limit for test
  --name=TEST_NAME      Test name"
W2013,https://wiki.ros.org/mrp2_control,Wiki,mrp2_control,Teleoperation and ros controls related launch files and configurations.
W2014,https://wiki.ros.org/pano_ros,Wiki,pano_ros,"

	The ros frontend to the pano subsystem.

  To be documented. stitch_client.pypano_capture/snappano_capture/stopstopsnapsnap`pwd`/pano.bag`pwd`/roslaunch openni_camera openni_kinect.launch rosrun pano_ros capture_server.py camera:=/camera/rgbrosrun image_view image_view image:=/pano_capture/stitchrosrun pano_ros capture_client.py `pwd`/pano01.bag 10 1rosrun pano_ros capture_server.py camera:=/kinect/rgbIn [1]: actions.pano_capture('camera/rgb')In [1]: topics.pano_capture.snap()

In [2]: topics.pano_capture.snap()

In [3]: topics.pano_capture.stop()In [1]: actions.pano_capture('camera/rgb')
Out[1]: 
pano_id: 1292382284
n_captures: 6
bag_filename: /tmp/pano_1292382284.bagrosrun pano_ros capture_client.py `pwd`/pano.bag 30











































rosrun pano_ros bag_stitcher.pyrosrun pano_ros stitch_client.py test_pano.bag stitch.jpg
eog stitch.jpg"
W2015,https://wiki.ros.org/pano_core,Wiki,pano_core,"

        Library for the opencv-based panorama stitching algorithm

  "
W2016,https://wiki.ros.org/kingfisher_msgs,Wiki,kingfisher_msgs,"

     kingfisher_msgs

  Newly proposed, mistyped, or obsolete package. Could not find package ""kingfisher_msgs"" in rosdoc: /home/rosbot/docs/api/kingfisher_msgs/manifest.yaml  Used on the  from . "
W2017,https://wiki.ros.org/gazebo_gripper,Wiki,gazebo_gripper,"

     gazebo_gripper

  "
W2018,https://wiki.ros.org/rocon_std_msgs,Wiki,rocon_std_msgs,Standard messages used by other rocon specific package types.
W2019,https://wiki.ros.org/multi_jackal_base,Wiki,multi_jackal_base,"The Jackal simulation base that combines all components.
 provides a launch file for spawning all components of a simulated . It has been extended from the single robot  to separate the robots into unique namespaces, allowing multiple robots to be simulated at the same time.  

There are tutorials on how to use this package in . A number of arguments can be provided when launching . If you only want to use local odometry for positioning, set  to  and  to . If you want to use the Jackals GPS, set  to , and  to . If you want to use your own fusion, set them both to . multi_jackal_basejackal_base.launchnsxyzrollpitchyawconfigconfig_iduse_move_baseuse_global_tfmapns/odomuse_global_ekfmapns/odomuse_global_tftrueuse_global_ekffalseuse_global_ekftrueuse_global_tffalsefalse"
W2020,https://wiki.ros.org/rl_common,Wiki,rl_common,"rl_common is a package of common RL files needed by both the agent and the
environment. Mainly the interfaces defining their class methods, and some other
utility methods.


StateActionInfo is the struct that the model must return when quering the model for its predictions for a given state action. It has a confidence (a float), a boolean telling if it is a 'known' transition or not, a float predicting the reward, a float predicting the termination probability, and a map of states (vectors of floats) to floats that gives the probabilities of next states. Full documentation for the StateActionInfo struct is available . 



 This package defines interfaces for agents, environments, models, and plannersin the file . All agents, environments, models, and planners should inherit from their appropriate base class. Please take a look at the  on how to install, compile, and use this package. Check out the code at:  First, an experience <s,a,r,s'> tuple is defined, which is used to update the model. The state s the agent came from is a vector of floats, the action it took is an int, the reward it received is a float, and the next state s' it transitioned to is a vector of floats. In addition, there's a bool indicating if the transition was terminal or not. Full documentation for the experience struct is available . Agent is defined with a number of methods. Mainly it has first_action(state) which is called for the first action in an episode and returns an action. After that next_action(reward, state) should be called, which returns an action. Finally upon reaching a terminal state, last_action(reward) can be called. In addition to these methods, seedExp(vector of experiences) can be used to seed the agent with a set of experiences. Full documentation for the Agent class is available . The environment has a sensation() method which returns the current state vector and a terminal() method tells if the agent is in a terminal state or not. The agent can act upon the environment by calling apply(action) which returns a reward. A set of experience seeds to initialize agents is available using the getSeedings() method. There are also a number of methods to get information about the environment such as getNumActions, getMinMaxFeatures, getMinMaxReward, and isEpisodic. Full documentation for the Environment class is available . Full documentation for the MDPModelclass is available . Full documentation for the Planner class is available . "
W2021,https://wiki.ros.org/jaco_interaction,Wiki,jaco_interaction,"Interactive manipulation with the JACO Arm




The  package provides interactive marker-based control of the end effector pose and issuing of manipulation commands for the JACO and JACO2. To install the  package, you can install from source with the following commands: The interactive markers can be launched using two launch files:  and .  The  file launches all of the necessary ROS nodes to publish the interactive markers and send commands back to the arm, and as such it should be launched first on a computer connected directly to the JACO arm.  The  file launches rviz with a preset configuration to show the arm model and the interactive markers.  This can be launched on any computer capable of displaying a GUI.  The syntax for launching these nodes is as follows: jaco_interactionjaco_arm/manipulation/gripperjaco_arm/manipulation/liftjaco_arm/joint_statesjaco_arm/cartesian_cmdjaco_arm/kinematics/fkjaco_conversions/quaternion_to_eulerwpi_jaco/arm_namestringwpi_jacoim_backend.launchim_frontend.launchim_backend.launchim_frontend.launch




roslaunch jaco_interaction im_backend.launchroslaunch jaco_interaction im_frontend.launch"
W2022,https://wiki.ros.org/rh_p12_rn_description,Wiki,rh_p12_rn_description,"3D models of the RH-P12-RN for simulation and visualization 
"
W2023,https://wiki.ros.org/riskrrt,Wiki,riskrrt,"riskrrt is a risk-based rapidly exploring random tree algorithm for human aware navigation



 () Some example scenarios can be run using: trajamcl_posecontroller_feedbackcmd_velgoalmaprobot_*/base_pose_ground_truthrobot_*/cmd_velogarrayogarraygoalcontroller_feedbackamcl_poseodomtraj~timeStepdouble~maxDepthint~nvint~nphiint~thresholddouble~socialWeightdouble~rotationWeightdouble~growTimedouble~biasdouble~windowSizedouble~goalThdouble~robotLengthdouble~robotWidthdouble~vMindouble~vMaxdouble~accMaxdouble~omegaMaxdouble~accOmegaMaxdoubleroslaunch riskrrt scenario_name.launch"
W2024,https://wiki.ros.org/rviz_fixed_view_controller,Wiki,rviz_fixed_view_controller,A simple rviz view controller that follows a TF frame.
W2025,https://wiki.ros.org/rb_tracker,Wiki,rb_tracker,Tracker of rigid bodies using visual features and/or shape-based poses (extensible to use other modalities as source of information)
W2026,https://wiki.ros.org/rmp_base,Wiki,rmp_base,"The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform. 
    In addition, navigation and status data are also published such as odometry, imu, mottor and battery status, ...



The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform (). It supports USB and UDP interfaces. This package has only been tested on the RMP 440LE (). /rmp440le/base/vel_cmd/rmp440le/deadman/rmp440le/audio_cmd/rmp440le/odom/rmp440le/joint_states/rmp440le/inertial/rmp440le/pse/rmp440le/motor_status/rmp440le/battery/rmp440le/fault_statustransport_typestringip_addressstringport_numberintdevice_portstringupdate_frequencydoubleodometry_topicstringjoint_states_topicstringinertial_topicstringpse_topicstringmotor_status_topicstringbattery_topicstringvelocity_command_topicstringdeadman_topicstringaudio_command_topicstringfault_status_topicstringmax_translational_velocitydoublemax_turn_ratestring$ roslaunch rmp_base rmp440le.launch"
W2027,https://wiki.ros.org/feature_tracker,Wiki,feature_tracker,"Tracker of 3-D features (up to now, only LK point features, extensible to other type of basic features) on an RGB-D stream 
 The feature_tracker package is a versatile tool to detect and track point features in a RGB-D video stream. The framework can be easily modified to use different detection & tracking algorithms. The current implementation uses Kanade-Lucas-Tomasi algorithm (opencv implementation) to first detect corner features on the first frame and then track them in consecutive frames. it maintains a constant number of features by detecting new ones. "
W2028,https://wiki.ros.org/prbt_grippers,Wiki,prbt_grippers,The package provides gripper support for the pilz_robots package.
W2029,https://wiki.ros.org/ipcamera_driver,Wiki,ipcamera_driver,Simple node to publish regular IP camera video streams to a ros topic. 
W2030,https://wiki.ros.org/mjpeg_server,Wiki,mjpeg_server,"A node that provides a mjpeg server which is able to subscribe to any ros image stream.






In a , run the mjpeg_server: Optionally, you can set a different port on the command line when launching : Here, /IMAGE_TOPIC is a ROS topic generated by the  module, e.g.  in case you are using a PR2. Please send bug reports to the . Feel free to contact us at any point with questions and comments.  mjpeg_servermjpeg_server/wide_stereo/left/image_colorwidthintegerheightintegerqualityintegerinvertnone



sudo apt-get install ros-groovy-mjpeg-serverrosrun mjpeg_server mjpeg_serverrosrun mjpeg_server mjpeg_server _port:=8181http://localhost:8080/stream?topic=/IMAGE_TOPIChttp://localhost:8080/snapshot?topic=/IMAGE_TOPIChttp://localhost:8080/stream?topic=/IMAGE_TOPIC?param1=value1?param2=value2?param3=value3"
W2031,https://wiki.ros.org/rocon_service_pair_msgs,Wiki,rocon_service_pair_msgs,Paired pubsubs generators for non-blocking services.
W2032,https://wiki.ros.org/message_multiplexing,Wiki,message_multiplexing,"Lightweight communication patterns built on top of nanomsg for
    use in embedded scenarios where only a single socket connection is desirable."
W2033,https://wiki.ros.org/ros_pytest,Wiki,ros_pytest,The ros_pytest package
W2034,https://wiki.ros.org/rostune,Wiki,rostune,"rostune is a tool that helps ROS developers distribute their nodes in the most effective way. It collects statistics for topics and nodes, such as CPU and network usage."
W2035,https://wiki.ros.org/kobuki_softnode,Wiki,kobuki_softnode,ROS nodelet for fake Kobuki.
W2036,https://wiki.ros.org/airbus_docgen,Wiki,airbus_docgen,"The airbus_docgen package
  roslaunch airbus_docgen airbus_docgen.launch output_path:=""/tmp/docu"" ros_pkg:=""/home/user/my_workspace""roslaunch airbus_docgen airbus_docgen.launch output_path:=""/tmp/docu"" ros_pkg:=""package_name""rosrun airbus_docgen index.py"
W2037,https://wiki.ros.org/r2_msgs,Wiki,r2_msgs,"

     r2_msgs

  "
W2038,https://wiki.ros.org/mr_rqt,Wiki,mr_rqt,"Multi-robot teleoperation package collection
 
 
keyboard_cmd_velmouse_cmd_vel/output_topicslist of strings"
W2039,https://wiki.ros.org/robot_controllers_msgs,Wiki,robot_controllers_msgs,Messages for use with robot_controllers framework.
W2040,https://wiki.ros.org/robot_face,Wiki,robot_face,"

     This is an application to display a talking head on your robot for human robot interaction. It displays text and synchronized mouthmovements. It is also able to show emotions.

  




To model a robot face for the ros-package  you have to follow this guidelines to get a working model in the application. This guideline will not tell you how to model a complete face, but helps you to get things work. To get a working model in the  application, please follow this guidelines. "
W2041,https://wiki.ros.org/mico_description,Wiki,mico_description,"3D Model and URDF of the Kinova MICO Arm
 contains urdf and xacro files for the MICO arm.  It also includes a launch file for reading the robot model and setting up a  and  for visualization in tools such as rviz. 


To install the  package, you can install from source with the following commands: The  package includes a launch file that can be used to load the robot model and setup joint state and robot state publishing used to populate a tf tree and visualize the robot.  Once launched, the MICO model can be visualized in tools such as rviz.  It can be launched with the following command: The launch file also includes a parameter () to launch a GUI which can control each joint to test the model's behavior, which can be launched as follows: mico_descriptionurdf/robots/meshes/wpi_jacomico_descriptiongui




roslaunch mico_description display.launchroslaunch mico_description display.launch gui:=true"
W2042,https://wiki.ros.org/settlerlib,Wiki,settlerlib,"Defines helper functions and routines that greatly help when trying to create a settler
    for a specific sensor channel. This package is experimental and unstable.
    Expect its APIs to change.
"
W2043,https://wiki.ros.org/mrp2_bringup,Wiki,mrp2_bringup,"Launch files and configurations for starting MRP2 robot in a real environment.
"
W2044,https://wiki.ros.org/rosbag_image_compressor,Wiki,rosbag_image_compressor,"The rosbag_image_compressor package.
  This package has a script to compress and decompress images inside a bag file."
W2045,https://wiki.ros.org/rocon_tutorial_msgs,Wiki,rocon_tutorial_msgs,Messages used by rocon tutorials.
W2046,https://wiki.ros.org/kingfisher_viz,Wiki,kingfisher_viz,Visualization and rviz helpers for Kingfisher  
W2047,https://wiki.ros.org/razer_hydra,Wiki,razer_hydra,"Unofficial driver and ROS node for Razer Hydra
 





Please report bugs and request features on the github issue tracker:  hydra_calibhydra_rawhydra_joy~devicestring~publish_tfboolfalsetruehydra_basehydra_<left/right>_pivothydra_<left/right>_grab~polling_msint~corner_hzdouble~use_grab_frameboolfalsetruegrab_framepivot_frame~px,py,pzdoublehydra_<left/right>_pivot~gx,gy,gzdoublehydra_<left/right>_grabroscd razer_hydra
./configure_udev_rulesroslaunch razer_hydra hydra.launch publish_tf:=true/falserostopic echo /hydra_calibroslaunch razer_hydra hydra.launch corner_hz:=2.5"
W2048,https://wiki.ros.org/b21_teleop,Wiki,b21_teleop,Teleop Controller for B21
W2049,https://wiki.ros.org/kinect_aux,Wiki,kinect_aux,"A standalone driver for the Kinect accelerometers and tilt motor.  is now a standalone package. In Electric it was a package in , which is deprecated. 



 



Use GitHub to . []
 This driver provides access to additional features present in the Kinect sensor: accelerometer, tilt, and LED. One may use it in parallel with the  driver. Assuming a catkin workspace has been created as described in , follow the steps below. kinect_aux/tilt_angle/led_option/imu/cur_tilt_angle/cur_tilt_statusdevice_indexint$ sudo apt-get install ros-groovy-kinect-aux$ sudo apt-get install ros-hydro-kinect-aux$ sudo apt-get install ros-indigo-kinect-aux$ sudo apt-get install libusb-1.0-0 libusb-1.0-0-dev$ cd ~/catkin_ws/src
$ git clone https://github.com/muhrix/kinect_aux.git -b groovy
$ cd ~/catkin_ws
$ catkin_make$ cd ~/catkin_ws/src
$ git clone https://github.com/muhrix/kinect_aux.git -b hydro
$ cd ~/catkin_ws
$ catkin_make$ cd ~/catkin_ws/src
$ git clone https://github.com/muhrix/kinect_aux.git -b indigo
$ cd ~/catkin_ws
$ catkin_make$ rosrun kinect_aux kinect_aux_node$ rostopic pub /tilt_angle std_msgs/Float64 -- -15$ rostopic echo /cur_tilt_angle"
W2050,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20293/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W2051,https://wiki.ros.org/create_gazebo_plugins,Wiki,create_gazebo_plugins,"Gazebo plugins for the iRobot Create 



The plugin is configured throught the parameters given in the URDF description. See the  for details. Have a look at the  package to find out how to use this plugin. "
W2052,https://wiki.ros.org/pr2_sith,Wiki,pr2_sith,"An extension of the PR2 props demo, but instead of high fives, the PR2 swings a lightsaber until it detects an impact.



This, along with  gave me an idea. Essentially, what if you did the same exact demo, with slightly different arm positions, and a plastic lightsaber in the robots hand.  "
W2053,https://wiki.ros.org/rqt_py_trees,Wiki,rqt_py_trees,"rqt_py_trees provides a GUI plugin for visualizing py_trees behaviour trees based on rqt_tf_tree.
 See also , ,  "
W2054,https://wiki.ros.org/remote_manipulation_markers,Wiki,remote_manipulation_markers,"A set of interactive markers for various methods of remote teleoperation manipulation of 6-DOF robot end-effectors

 
Newly proposed, mistyped, or obsolete package. Could not find package ""remote_manipulation_markers"" in rosdoc: /home/rosbot/docs/api/remote_manipulation_markers/manifest.yaml 




The  package contains interactive marker servers for a set of remote manipulation interaction approaches.  The approaches include Free Positioning, Constrained Positioning, and Point-and-Click.  These interactive marker servers are intended for use with rviz or with Robot Web Tools interfaces. This package includes three approaches:  Free Positioning (FP), Constrained Positioning (CP), and Point-and-Click (P&C).  The three approaches are shown below, with interaction points for setting initial poses shown in yellow, and interaction points for adjusting poses shown in blue. Free positioning uses a ring-and-arrow marker which can be clicked and dragged to individually adjust translation along and rotation about each Cartesian axis.  Constrained positioning uses a sphere marker to first set a grasp point, followed by setting an approach angle by clicking on the surface of the sphere.  The approach angle is constrained to pass through the grasp point.  Point-and-click makes use of autonomous grasp calculation, and involves the user selecting a previously calculated grasp for execution from a list of potential grasps.  Further details on these can be found in , published in HRI 2017.  The approaches are designed for both 2D and 3D visualization modes.  For full details and a comparison of the efficiency and effectiveness of each approach in both 2D and 3D visualization modes, see our IJRR 2019 article . Videos of the approaches in action can be found  and . To install the  package, you can install from source with the following commands: Note that  and  include a boolean parameter .  Setting  to true will launch a  node that corresponds to the free or constrained positioning node. If you use this package in your work, please cite our : David Kent, Carl Saldanha, and Sonia Chernova.  Leveraging Depth Data in Remote Robot Teleoperation Interfaces for General Object Manipulation. , 2019. remote_manipulation_markersexecute_grasp/goalexecute_grasp/resultexecute_grasp/feedbackgraspgrasp_topicgripper_marker_posereset_marker_posebase_linkstringeef_linkstringgrasp_topicstringexecute_grasp/goalexecute_grasp/resultexecute_grasp/feedbackgraspgrasp_topicgripper_marker_poseclear_gripper_markerclear_full_markercreate_spheregrasp_topicstringexecute_grasp/goalexecute_grasp/resultexecute_grasp/feedbackgraspgrasp_topic/grasp_sampler/sampled_graspscalculatedPosesTopiccycle_graspsgrasp_topicstringcalculated_poses_topicstring/free_positioning/gripper_marker_posemarker_node_namemarker_node_namestringremote_manipulation_markersfree_positioning.launchconstrained_positioning.launchrun_separate_visrun_seperate_visgripper_marker_vis




roslaunch remote_manipulation_markers free_positioning.launchroslaunch remote_manipulation_markers constrained_positioning.launchroslaunch remote_manipulation_markers point_and_click.launch"
W2055,https://wiki.ros.org/scriptable_monitor_rqt,Wiki,scriptable_monitor_rqt,scriptable_monitoring
W2056,https://wiki.ros.org/rh_p12_rn_manager,Wiki,rh_p12_rn_manager,"Manager package using ROBOTIS framework to control the RH-P12-RN 



gazebobooloffset_file_pathstringrobot_file_pathstringinit_file_pathstringdevice_namestringbaud_rateint"
W2057,https://wiki.ros.org/rqt_graphprofiler,Wiki,rqt_graphprofiler,An experimental visualization system for anonymous publish subscribe architectures. 
W2058,https://wiki.ros.org/alliance,Wiki,alliance,"This package implements the ALLIANCE multi-robot task allocation architecture.

Use GitHub to . []
  "
W2059,https://wiki.ros.org/neo_base_mpo_500,Wiki,neo_base_mpo_500,launchfiles for MPO_500
W2060,https://wiki.ros.org/libsegwayrmp,Wiki,libsegwayrmp,This is a C++ library for interfacing with Segway's RMP line of robotic platforms.   This is an external library that provides access to the segway rmp's.  It is maintained by William Woodall . 
W2061,https://wiki.ros.org/object_recognition_clusters,Wiki,object_recognition_clusters,The object_recognition_clusters package
W2062,https://wiki.ros.org/kdl_wrapper,Wiki,kdl_wrapper,"C++ wrapper for easily using KDL kinematic solvers with robots defined in ROS through URDF files. Wraps the kdl and kdl_parser packages for generating KDL kinematic chains from URDF by just taking as inputs the IDs of the root and tip of the kinematic chain of a robot manipulator.


Use GitHub to . []
  This package requires the  package to be installed. An example C++ code for doing inverse kinematics with the PR2 is given under  : 3. Compile the  package. kdl_wrapper
















































sudo apt-get install ros-<rosdistro>-pr2-commonroslaunch pr2_description upload_pr2.launch kinect:=TRUErosrun kdl_wrapper pr2_kdl_wrapper_example"
W2063,https://wiki.ros.org/robotino_msgs,Wiki,robotino_msgs,"Message defintions for the Festo Robotion robotNewly proposed, mistyped, or obsolete package. Could not find package ""robotino_msgs"" in rosdoc: /home/rosbot/docs/api/robotino_msgs/manifest.yaml "
W2064,https://wiki.ros.org/robotis_framework_common,Wiki,robotis_framework_common,"The package contains commonly used Headers for the ROBOTIS Framework. 
"
W2065,https://wiki.ros.org/rrt_exploration,Wiki,rrt_exploration,"A ROS package that implements a multi-robot RRT-based map exploration algorithm. It also has the image-based frontier detection that uses image processing to extract frontier points If you are using this package in your research work, please cite this . 










 




 



 A mobile robot that can be used with the  (publishes /odom and /tf. Receives velocity commands ..). The robot must also be equipped with a laser scanner or any sensor that publishes laser scan message (). This package provides an exploration strategy for single or multiple robots. However, for it to work, you should have set your robots ready using the navigation stack. And each robot should run the ""slam_gmapping"" node from the  package. Note: If you want to quickly run and test the package, you can try out the  package which provides Gazebo simulation for single and multiple robots, you can use it directly with this package. The move_base_node node, which brings up the navigation stack on the robot, must be running. This package (rrt_exploration) generates target exploration goals, each robot must be able to receive these points and move towards them. This is why the navigation stack is needed. Additionally, each robot must have a global and local cost maps. All of these are proivded from the . The robot should have a local map generated from the  package. For the multi-robot configuration, the package doesn't require special network configuration, it simply works by having a single ROS master (can be one of the robots). So on the other robots, the  parameter should be pointing at the master's address. For more information on setting up ROS on multiple machines, follow  link. All robot's frames should be prefixed by its name. Naming of robots starts from ""/robot_1"", ""/robot_2"", ""/robot_3"", .. and so on. So for robot_1, the frames in the  tree should look like this: The move_base_node node, which brings up the navigation stack on the robot, must be running. This package (rrt_exploration) generates target exploration goals, each robot must be able to receive these points and move towards them. This is why the navigation stack is needed. Additionally, each robot must have a global and local cost maps. All of these are proivded from the . Each robot should have a local map generated from the  package. There should be a node that merges all the local maps into one global map. You can use the  package developed by Jiri Horner. mapclicked_pointdetected_points~shapes~map_topicstring~etafloatmapclicked_pointdetected_points~shapes~/robot_1/base_linkstring~map_topicstring~etafloatmapdetected_pointsshapes~map_topicstringmaprobot_x/move_base_node/global_costmap/costmapThe goals topicfrontierscentroidsfiltered_points~map_topicstring~costmap_clearing_thresholdfloat~info_radiusfloat~goals_topicstring~n_robotsfloat~namespacestring~namespace_init_countfloat~ratefloatmapFiltered frontier points topicThe goals topic~map_topicstring~info_radiusfloat~info_multiplierfloat~hysteresis_radiusfloat~hysteresis_gainfloat~frontiers_topicstring~n_robotsfloat~namespacestring~namespace_init_countfloat~delay_after_assignementfloat~global_framestringsudo apt-get install ros-$ROS_DISTRO-gmappingsudo apt-get install ros-$ROS_DISTRO-navigationsudo apt-get install python-opencvsudo apt-get install python-numpysudo apt-get install python-scikits-learn@INPROCEEDINGS{8202319,
author={H. Umari and S. Mukhopadhyay},
booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
title={Autonomous robotic exploration based on multiple rapidly-exploring randomized trees},
year={2017},
volume={},
number={},
pages={1396-1402},
keywords={},
doi={10.1109/IROS.2017.8202319},
ISSN={},
month={Sept},}"
W2066,https://wiki.ros.org/modelica_bridge,Wiki,modelica_bridge,"ROS package for bridging ROS with Modelica tools via TCP/IP sockets.
    Meant for use along with the ROS_Bridge Modelica package, made by the same developer. 
 establishes a bridge between , a component-oriented equation-centric modeling language, and ROS. The connection is done via TCP/IP sockets; in ROS, the  provides a node to run the server socket. , 's companion package in , contains a  component which runs a client socket connection to ROS. Using TCP/IP sockets allow the messages transmitted between  and ROS with preservation of order and content. The combination of  and  lets  models and ROS control architectures communicate with each other without any additional internal configurations.   
 is a ROS package, and so can only be run in Linux;  similarly can only be run on  systems, due to the current method of implementing sockets. Below is a list of  tools and operating systems  has been tested on: 



 () 
 () 
 (, default: 9091)  (, default: 20)  To get a better understanding of the way the bridge works, view the image below, depicting the flow of information between  and ROS.  Here are a few  that explain how to use the  package in detail: modelica_bridgemodelica_bridgemodelica_bridgeModelicablockModelicamodelica_bridgeROS_BridgeModelicaModelicaModelicaROS_BridgeModelicamodelica_bridgemodelica_bridgeModelicaModelicaModelicannn-1nnn+1samplePeriodModelicamodelica_bridgeROS_BridgeModelicaROS_Bridgemodelica_bridgemodelica_bridgemodelica_bridge/control_values/model_valuesport_num_intupdate_rate_int"
W2067,https://wiki.ros.org/smartek_camera,Wiki,smartek_camera,"Node for publishing frames from a Smartek camera






"
W2068,https://wiki.ros.org/rosruby_common,Wiki,rosruby_common,"rosruby_common libraries 
See . "
W2069,https://wiki.ros.org/airbus_ssm_core,Wiki,airbus_ssm_core,"The airbus_ssm_core package
       
 The SSM_core package is a SMACH overhaul including an interpretor of SCXML files.(). It creates a finite state machine (based on SMACH) using the data from the SCXML file. It can be usefull if you want to create a state machine using a GUI that generate a SCXML file like : Using the 'id' ""skill"" and set the 'expr' value to the name of the skill you want to use. In order to maintain the consistency of the , you have to link every outcome of this State inside the SCXML. If you forget to link one, them the  consistency check will fail. If you want to put the skill.xml file in a different folder/pkg, use this syntax  If you want to put scxml files in a different folder, use this syntax  or you can give the pull path to the file. <?xml version=""1.0"" encoding=""UTF-8""?>
<scxml initial=""Input Number"">
    <datamodel>
        <data id=""skill_file"" expr=""${airbus_ssm_tutorial}/resources/skills.xml""/>
    </datamodel>
    <state id=""Input Number"">
        <datamodel>
            <data id=""skill"" expr=""Input""/>
        </datamodel>
        <transition event=""Out"" target=""Primes""/>
        <transition event=""Test"" target=""IsPrime""/>
        <transition event=""Retry"" target=""Input Number""/>
    </state>
    <state id=""Primes"">
        <datamodel>
            <data id=""skill"" expr=""Primes""/>
        </datamodel>
        <transition event=""Off"" target=""End""/>
        <transition event=""Reset"" target=""Input Number""/>
        <transition event=""Continue"" target=""Input Number""/>
    </state>
    <state id=""IsPrime"">
        <transition type=""external"" event=""Return"" target=""Input Number""/>
        <datamodel>
            <data id=""skill"" expr=""isPrime""/>
        </datamodel>
    </state>
    <final id=""End""/>
</scxml><?xml version=""1.0"" encoding=""UTF-8""?>
<scxml initial=""Input Number"">
     <datamodel>
        <data id=""skill_file"" expr=""${airbus_ssm_tutorial}/resources/skills.xml""/>
    </datamodel>
    ...
</scxml><?xml version=""1.0""?>
<skills>
  <skill name=""Input""   pkg=""airbus_ssm_tutorial"" module=""airbus_ssm_tutorial1.skills"" class=""Input""/>
  <skill name=""isPrime"" pkg=""airbus_ssm_tutorial"" module=""airbus_ssm_tutorial1.skills"" class=""isPrime""/>
  <skill name=""Primes""  pkg=""airbus_ssm_tutorial"" module=""airbus_ssm_tutorial1.skills"" class=""Primes""/>
</skills><state id=""IsPrime"">
  <datamodel>
     <data id=""skill"" expr=""isPrime""/>
  </datamodel>
  ...
</state>roslaunch airbus_ssm_core ssm_descriptor.launch skill_xml_file:=empty_register.xml output_file:=/tmp/descriptor.txt<state id=""Parent"">
  <initial>
    <transition type=""external"" target=""foo""/>
  </initial>
  <state id=""foo"">
     <transition event=""to_bar1"" target=""Final_5""/>
     <transition event=""to_bar2"" target=""Final_7""/>
   </state>
   <final id=""Final_5""/>
   <final id=""Final_7""/>
   <transition event=""to_bar1"" target=""bar1""/>
   <transition event=""to_bar2"" target=""bar2""/>
</state><parallel id=""Parallel_1"">
  <state id=""A""/>
  <state id=""B""/>
  <state id=""C""/>
  <transition event=""Transition1"" target=""bar1"" cond=""A.outA1 AND B.outB1""/>
  <transition event=""Transition2"" target=""bar2"" cond=""B.outB2 OR C.outC""/>
  <transition event=""Transition3"" target=""bar3"" cond=""A.outA2""/>
</parallel>""/state/./outcome/"" ""AND/OR"" ""/state/./outcome/""roslaunch airbus_ssm_core ssm.launch scxml_file:=defaultroslaunch airbus_ssm_core ssm.launch scxml_file:=${airbus_ssm_core}/resources/defaulf.scxmlroslaunch airbus_ssm_core ssm_action_server.launch "
W2070,https://wiki.ros.org/libfovis,Wiki,libfovis,"

  Fovis is a visual odometry library that estimates the 3D motion of a camera using a source of depth information for each pixel. It's designed for sensors such as calibrated stereo cameras and RGB-D cameras like the Microsoft Kinect.

   Albert S. Huang, Abraham Bachrach, Peter Henry, Michael Krainin, Daniel Maturana, Dieter Fox, and Nicholas Roy. Int. Symposium on Robotics Research (ISRR), Flagstaff, Arizona, USA, Aug. 2011 . "
W2071,https://wiki.ros.org/airbus_plugin_rqt,Wiki,airbus_plugin_rqt,The airbus_plugin_rqt package
W2072,https://wiki.ros.org/rv7fl_moveit_config,Wiki,rv7fl_moveit_config,An automatically generated package with all the configuration and launch files for using the rv7fl with the MoveIt! Motion Planning Framework
W2073,https://wiki.ros.org/mr_teleoperator,Wiki,mr_teleoperator,"Multi-robot teleoperation package collection 

mr_teleoperator"
W2074,https://wiki.ros.org/pano_py,Wiki,pano_py,"

        This is a python wraper around the pano_core library (I think)

   "
W2075,https://wiki.ros.org/mrpt_sensorlib,Wiki,mrpt_sensorlib,C++ library for the base generic MRPT sensor node
W2076,https://wiki.ros.org/rosboost_cfg,Wiki,rosboost_cfg,Contains scripts used by the rosboost-cfg tool for determining cflags/lflags/etc. of boost on your system
W2077,https://wiki.ros.org/robot_pose_publisher,Wiki,robot_pose_publisher,"A Simple Node to Publish the Robot's Position Relative to the Map using TFs





The  package contains a ROS node that will publish the transform between the  frame and the  frame as a pose message. This information is useful if you are interested in the robots position but do not want to stream the entire TF tree to get this information. An example use case is for web widgets. To run the node, ensure that a valid transform exists between the  frame and the  frame (e.g., from a navigation node), and run the following: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  robot_pose_publisher/base_link/maprobot_pose_publisher/base_link/maprobot_pose/base_link/maprobot_pose_publisherrobot_pose_publisherrobot_pose_publisherrobot_pose_publisher/base_link/map



sudo apt-get install ros-fuerte-robot-pose-publisher



sudo apt-get install ros-groovy-robot-pose-publisher



sudo apt-get install ros-indigo-robot-pose-publisher



sudo apt-get install ros-jade-robot-pose-publisherrosrun robot_pose_publisher robot_pose_publisher"
W2078,https://wiki.ros.org/rosjava,Wiki,rosjava,"Contents 
Rosjava provides both a  for ros communications in java as well as growing list of core tools (e.g. tf, geometry) and drivers (e.g. hokuyo). Official source code for rosjava projects can be found on github in the . Rosjava is largely used to build Android applications. For information specific to that use case refer to the  wiki page. 
The documentation on the wiki here provides a general overview of the rosjava ecosystem and install/build instructions. For tutorials and coding level API documentation, refer to the github generated documentation. Links below.  : what to expect and what tools are used for rosjava development.  : list of all official and semi-official packages in the rosjava-android ecosystem.  : the anatomy of a typical rosjava package.  : some environment variables that can influence the build of rosjava stacks.  : messages are handled slightly differently in rosjava.  : detailed coding level documentation and tutorial information.  : frequently asked questions. 

These tutorials revolve mostly around development in a catkin-rosjava workspace environment (aside from the installation).  Installation instructions from debs, sources, or maven. Script wizards for conveniently creating rosjava packages and projects. How to create, compile, and execute a simple publisher and subscriber in rosjava. It shows how to create, compile and execute a service (both server and client) in Rosjava. How to create, compile and deploy rosjava libraries (maven artifacts). Generating ros-java message jars and artifacts Useful tips on how to survive in a catkin-gradle based rosjava workspace.  
Regular development on top of rosjava (free of catkin/ros itself) should not require any expertise aside from that which you already have and as such, is only briefly mentioned in the  tutorial. 
Packaging your java (possibly mixed) projects as debs. Share java and android artifacts via our github maven repo.  
    
 "
W2079,https://wiki.ros.org/rocon_uri,Wiki,rocon_uri,"Module for working with rocon uri strings. 


rocon:/turtlebot2/cybernetic_pirate#rocon_apps/im_here_to_make_you_lazyrocon:/pr2/bob#rocon_apps/look_menacingrocon://concert_name/hardware_platform/name/application_framework/operating_system#rocon_appUtility for introspecting on rocon uri strings.

Commands:
        rocon_uri parse URI     parse and attempt to validate a rocon URI.
        rocon_uri fields        print a full list of permitted fields in a rocon uri string.
        rocon_uri rules         print a full list of the ebnf rules for a rocon uri string."
W2080,https://wiki.ros.org/manipulator_h_base_module_msgs,Wiki,manipulator_h_base_module_msgs,"The manipulator_h_base_module_msgs package
    This package includes ROS messages and services for manipulator_h_base_module_msgs 

 
   
  
 
  
  "
W2081,https://wiki.ros.org/manipulator_h,Wiki,manipulator_h,"ROS packages for the ROBOTIS MANIPULATOR-H (metapackage) 
 



"
W2082,https://wiki.ros.org/pyclearsilver,Wiki,pyclearsilver,"A bunch of libraries to interface clearsilver with python and many databases.
"
W2083,https://wiki.ros.org/phm_tools,Wiki,phm_tools,"The phm_tools meta package

   Autonomous Transfer Vehicle  Use Case Scenario Module, Sub-Module and Components List   Use Case General Block Diagram   General Failure Rates and Reliabilities of Components   System Hazard Rate and Reliability at Different Temperature Conditions  Reliability of System at Different Temperatures    GAZEBO Test Environment  Locations of Some Specific Points  Followed Paths and Distance Between Each Neighbour Points  System PoTC for Each Route Segment 
In the motor sub-module, failure rate of this component is selected as . In encoder sub-module, we selected magnetic rotary encoder unit. Only use parameters  λ (other parameters are negligible), the failure rate of encoder unit selected as . In the sensor module, there is only one component which is SICK S300 Laser Sensor and the failure rate of this component selected as  using product datasheet.  In order to calculate hazard rate of the power card sub-module, we utilized diodes, capacitors and inductors. In addition, hazard rate of the fuse in the power card sub-modules selected as . Hazard rate of the selected buck converter (LM 2596), is found as . There is one more component in the Power Module which is battery and the failure rate of this component selected as . General failure rates and reliabilities of the all components at 35 ℃ are shown in Table 2.  Using Table 2, hazard rate of the system λ calculated as . In order to calculate the reliability of the system, we use Exponential Distribution function with the system hazard rate and time. Usage time selected as 1000 hours. The reliability of the system  R calculated as .  "
W2084,https://wiki.ros.org/baxter_ikfast_right_arm_plugin,Wiki,baxter_ikfast_right_arm_plugin,The baxter_ikfast_right_arm_plugin package
W2085,https://wiki.ros.org/neo_platformctrl_mecanum,Wiki,neo_platformctrl_mecanum,"transformation Node for neobotix robots with omnidirectional drive


 /joint_states/cmd_vel/odom/cmd_joint_trajkinematicswheelDiameterrobotWidthrobotLengthsendTransform"
W2086,https://wiki.ros.org/kdl_acc_solver,Wiki,kdl_acc_solver,Wraps the kdl and kdl_parser packages for generating KDL kinematic chains from URDF. 
W2087,https://wiki.ros.org/segwayrmp,Wiki,segwayrmp,"segwayrmp
"
W2088,https://wiki.ros.org/ridgeback_desktop,Wiki,ridgeback_desktop,"Packages for working with Ridgeback from a ROS desktop.To get started using Ridgeback from a desktop ROS environment, see . "
W2089,https://wiki.ros.org/rosclean,Wiki,rosclean,"rosclean: cleanup filesystem resources (e.g. log files). 


  will remove directories associated with storing ROS-related log files. You will be asked to confirm each deletion and it is important that you verify the command that  executes is correct. Otherwise you  rosclean purgerosclean purgeUsage: rosclean <command>

Commands:
  rosclean check        Check usage of log files
  rosclean purge        Remove log files$ rosclean check
348K ROS node logs
20K rosmake logs$ rosclean purge
Purging ROS node logs.
PLEASE BE CAREFUL TO VERIFY THE COMMAND BELOW!
Okay to execute:

rm -rf /u/username/.ros/log
(y/n)?"
W2090,https://wiki.ros.org/melfa_description,Wiki,melfa_description,The melfa_description package
W2091,https://wiki.ros.org/rh_p12_rn_gui,Wiki,rh_p12_rn_gui,"This package provides GUI interface to control the RH-P12-RN 
"
W2092,https://wiki.ros.org/robot_localization,Wiki,robot_localization,"Provides nonlinear state estimation through sensor fusion of an abritrary number of sensors.Documentation for  is now .   Use GitHub to . []
 robot_localizationrobot_localizationrobot_localizationrobot_localizationrobot_localizationrobot_localizationrobot_localization"
W2093,https://wiki.ros.org/ros_glass_tools,Wiki,ros_glass_tools,"The ros_glass_tools package - Provides ROS interface to Google Glass for topic
        monitoring and robot voice control

















<rosparam name=""monitors""> </rosparam> 


<rosparam param=""global_commands""> [ [stop, /all_stop], [go, /all_go] ] </rosparam> <rosparam param=""robots""> <rosparam param=""robot_commands""> [ [forward, move_forward], [backward, move_backward] ] </rosparam> 
 To successfully communicate to the ROS server from the Google Glassware, the rosbridge_suite package is required.  Follow the instructions to install and run the rosbridge webserver at . Next, the ROS tools must be configured as to enable communication in and functionality between the ROS and the Google Glasses.  Obtain the source code from github () and build the  package using the catkin tools.  It is important that the ""Commands"" and ""Topics"" services are built.  After building, the ROS system is ready to be run. To run the glass applications, it is first necessary to setup your development environment to use the Glass Development Kit Sneak Peak. Instructions to do so can be found at .   It is important that you install the latest version, as the API has changed, and the code will not compile on the older versions of the GDK.  The Glassware must also have debug mode enabled.  The instructions to do so are also found on the Google Glass development site above. After the environment is setup, the applications must be imported into the Eclipse Android environment.  This is done by selecting ""import"" -> ""Existing Android Code Into Workspace"" -> and selecting the ""Applications"" directory in the ros_glass_tools package.  All three applications can be imported in this way. After importing, ensure that the ""Glass Development Kit Sneak Peek"" is selected as the Android Build Target in the project properties.   Additionally, this project relies on the Autobahn Websocket library ().  Ensure that these jars are in the libs directory and on the build path. public final static String HOST_ADDRESS = ""ws://""; [a, b] </rosparam> ""robot one forward"" -> a/move_forward ""robot two backward"" -> b/move_backward ""all forward"" -> a/move_forward & b/move_forward ""execute stop""  –> /stop ""execute go"" –> /go ""robot one forward"" –> /a/forward "
W2094,https://wiki.ros.org/sensor_msgs,Wiki,sensor_msgs,"This package defines messages for commonly used sensors, including
    cameras and scanning laser rangefinders.A number of these messages have ROS  dedicated to manipulating them.  "
W2095,https://wiki.ros.org/slam_constructor,Wiki,slam_constructor,"The package provides implementation of several 2D laser-based simultaneous
    localization and mapping (SLAM) algorithms (tinySLAM, vinySLAM, GMapping)
    created with the SLAM constructor framework. The framework provides common
    SLAM components that may help to develop custom SLAM algorithms and can be
    accessed by provided links.




 











 The SLAM constructor framework provides common functionality and classes that may be used to create custom SLAM algorithms (currently only 2D laser scan-based methods are supported). It also includes implementation of several SLAM algorithms ,  and , which can be used as a base of a new SLAM algorithm. Current implementation requires odometry data and laser scans to be provided by the ROS topics (see ). It also supposes that a laser scanner is fixed in (0, 0) of a robot and mounted horizontally. Each algorithm is supplied with -files for the  and  datasets that give the idea of how to launch algorithms. The  launch-files can be used in general case if data provided by a dataset do not require any preprocessing. For example, tinySLAM can be launched in the following way: In order to run an algorithm on data received in real time you can remove a dataset player node from a launch file, but make sure that sensor data are provided through . GMapping has the following additional parameters (note that  shouldn't be provided or  be ), see  documentation for details: The package provides the tool  to launch algorithms in the offline mode to process  datasets. _mit_~in/lscan2D/ros/topic/name/base_scan~in/odometry/ros/tf/odom_frame_idodom_combined~ros/tf/map_frame_idmap~ros/tf/robot_pose_frame_idrobot_pose~ros/tf/async_correctionfalsetruemapodom~ros/subscribers_queue_size1000~ros/tf/buffer_duration5.0~ros/filter_queue_size1000~ros/rviz/map_publishing_rate5.0~ros/skip_exceeding_lsr_valsfalsetruefalse~slam/map/height_in_meters10.0~slam/map/width_in_meters10.0~slam/map/meters_per_cell0.1~slam/performance/use_trig_cachefalse~slam/occupancy_estimator/typeconstconstarea~slam/occupancy_estimator/base_occupied/prob0.95~slam/occupancy_estimator/base_occupied/qual1.0~slam/occupancy_estimator/base_empty/prob0.01~slam/occupancy_estimator/base_empty/qual1.0~slam/mapping/blur0.0~slam/mapping/max_range<infinity>~slam/scmtch/type<undefined>MC~slam/scmtch/MC/attempts_limit100~slam/scmtch/MC/seed<random>~slam/scmtch/MC/dispersion/translation0.2~slam/scmtch/MC/dispersion/rotation0.1~slam/scmtch/MC/dispersion/failed_attempts_limit20HC~slam/scmtch/HC/distortion/translation0.1~slam/scmtch/HC/distortion/rotation0.1~slam/scmtch/HC/distortion/failed_attempts_limit6BF~slam/scmtch/BF/[x, y, t]/from-0.5-0.5-5°~slam/scmtch/BF/[x, y, t]/to0.50.55°~slam/scmtch/BF/[x, y, t]/step0.10.11°~slam/scmtch/spe/type<undefined>wmpp~slam/scmtch/spe/wmpp/weighting/type<undefined>evenvinyahr~slam/scmtch/spe/wmpp/sp_skip_rate0~slam/scmtch/spe/wmpp/sp_max_usable_range-1.0~slam/scmtch/oope/typeobstacleobstaclemaxmeanoverlap~slam/cell/typebasebaseavg~slam/scmtch/oope/typecustom~slam/particles/number30~slam/particles/sample/xy/mean0.0~slam/particles/sample/xy/sigma0.1~slam/particles/sample/theta/mean0.0~slam/particles/sample/theta/sigma0.03~slam/particles/sm_delta_lim/xy/min0.6~slam/particles/sm_delta_lim/xy/max0.8~slam/particles/sm_delta_lim/theta/min0.3~slam/particles/sm_delta_lim/theta/max0.4~slam/scmtch/oope/custom/fullness_threshold0.1~slam/scmtch/oope/custom/window_size1/tf/base_scan<the frame attached to incoming scans>odom_frame_idodom_combinedmap_frame_idodom_frame_idmap_frame_idrobot_pose_frame_idlslam2d_bag_runner<slam type>vinytinygmapping<bag file>-v-t <traj file>traj file-m <map file>map file-p <properties file>key=valueroslaunch slam_constructor tiny_mit_run.launch path:=[path to dataset]lslam2d_bag_runner <slam type> <bag file>
                   [-v] [-t <traj file>] [-m <map file>] [-p <properties file>]"
W2096,https://wiki.ros.org/abb_resources,Wiki,abb_resources,"
      Shared configuration data for ABB manipulators.
    
      This package contains common urdf / xacro resources used by
      ABB related packages.
    
This package is part of the  program.  "
W2097,https://wiki.ros.org/airbus_plugin_node_manager,Wiki,airbus_plugin_node_manager,The airbus_plugin_node_manager package
W2098,https://wiki.ros.org/raspigibbon_msgs,Wiki,raspigibbon_msgs,The raspigibbon_msgs package
W2099,https://wiki.ros.org/robotis_math,Wiki,robotis_math,"This package is a set of basic math fuctions for ROBOTIS's robots.
    We provide some linear algebra and trajectory generation funntions and classes. 



"
W2100,https://wiki.ros.org/baxter_ikfast_left_arm_plugin,Wiki,baxter_ikfast_left_arm_plugin,The baxter_ikfast_left_arm_plugin package
W2101,https://wiki.ros.org/kurt_navigation_config,Wiki,kurt_navigation_config,"
    This package holds common configuration files for running the  node on the Kurt
    robot. It is modeled after pr2_navigation_config.
  "
W2102,https://wiki.ros.org/r2_moveit_generated,Wiki,r2_moveit_generated,r2_moveit_generated
W2103,https://wiki.ros.org/create_node,Wiki,create_node,"iRobot Create ROS driver node
    
    ROS bindings for the Create/Roomba driver.
    
    This is based on otl_roomba driver by OTL, ported to use
    create_driver's implementation instead. 
    This also contains a 'bonus' feature from the turtlebot 
    driver by Xuwen Cao and Morgan Quigley."
W2104,https://wiki.ros.org/motoman_mpl_support,Wiki,motoman_mpl_support,"
      ROS-Industrial support for the Motoman MPL series (and variants).
    
      This package contains configuration data, 3D models and launch files
      for Motoman MPL series manipulators. This currently includes the 80
      model only.
    
      Joint limits and max joint velocities are based on the information in
      the Motoman data sheets. All URDFs / XACROs are based on the
      default motion and joint velocity limits, unless noted otherwise (ie:
      no support for high speed joints, extended / limited motion ranges or
      other options).
    
      Before using any of the configuration files and / or meshes included
      in this package, be sure to check they are correct for the particular
      robot model and configuration you intend to use them with.
    "
W2105,https://wiki.ros.org/kurt_navigation_slam,Wiki,kurt_navigation_slam,"
    This package holds launch files for running the  node in
    conjunction with [[gmapping | SLAM]] on a Kurt robot. It is modeled after
    pr2_navigation_slam.
  "
W2106,https://wiki.ros.org/asr_mild_base_driving,Wiki,asr_mild_base_driving,"This package calculates and publishes the odometry information, transforms the velocity command into differential drive commands and writes it on the mild_base_driving bus 

    

 if you want to start the node with the mild.launch files. 

 




Get ""Ticks"" from the incremental encoder. Calculate the odometry from the ticks and publish them on the ROS-Topic /odom (). This picture shows you how a differential drive robot drives, with different wheel velocities (al and ar). If al > ar the robot drives a curve to the right. If al = ar the robot drives straight. - Dukenmotors Typ GR63x55 () - Maxon motorcontroller () cmd_vel ( ) odom ( ) Look at  on how to adapt the parameters. roslaunch asr_mild_base_launch_files mild.launchrosrun asr_mild_base_driving mild_base_drivingCan: Socket set successfully.
CanListener: Started successfully.
BaseController: Started successfully."
W2107,https://wiki.ros.org/asr_mild_base_launch_files,Wiki,asr_mild_base_launch_files,"This package contains the launch files and different documents needed to start the system 

 


Includes the mild.launch file which starts the  node and the  node. Also here you can adapt the parameters for the laserscanner and the speed up of the velocity (look at the  and  documentation). <launch>
    <env name=""ROSCONSOLE_CONFIG_FILE"" value=""$(find asr_mild_base_launch_files)/log/rosconsole.config"" />

    <node name=""sick"" pkg=""asr_mild_base_laserscanner"" type=""asr_mild_base_laserscanner"" output=""screen"" required=""true""/>
    <param name=""topic"" value=""scan"" />
    <!-- Laserscanner baudrate. Only four values: 9600, 19200, 38400, 500000. 38400 means 4 complete measurements in 1 sec. -->
    <param name=""baudrate"" value=""500000"" />
    <param name=""serial"" value=""/dev/rs422b"" />
    <param name=""init_attempts"" value=""10"" />

    <node name=""can"" pkg=""asr_mild_base_driving"" type=""asr_mild_base_driving"" output=""screen"" required=""true""/>
    <!-- Speedup of the mild. 1 = normal velocity. 2 = double velocity. Float value. --> <param name=""velocity"" value=""1"" />
</launch>roslaunch asr_mild_base_launch_files mild.launch"
W2108,https://wiki.ros.org/rqt_wrapper,Wiki,rqt_wrapper,A wrapper for keeping rqt programs alive.Documentation and examples in the . 
W2109,https://wiki.ros.org/android_core,Wiki,android_core,"Android support packages for rosjava.
For core library and example documentation, refer to the  and  sphinx documentation. For more general documentation on all things rosjava-android, refer to the  and  wiki pages. "
W2110,https://wiki.ros.org/airbus_cobot_gui,Wiki,airbus_cobot_gui,"The airbus_cobot_gui package

 

 Additionally the package  includes a library to customise easily qt applications. The user can also call this launch file to run a different configuration, using the input parameters  and  The configuration of the cobot_gui can be defined via a : For further information about the parameters see:  The user is allow to create and add new dashboards and plugins, by adding new entry lines to the dashboards_register.xml file and the plugins_register.xml. See the package  as example. Where the l includes an entry for a new dashboard: The package  define the python code of the qt level that will be popup inside your cobot_gui. Being the package  where the plugin functions is defined. roslaunch airbus_cobot_gui default.launchroslaunch airbus_cobot_gui default.launch config_path:='${PKG_NAME}/folder' file_name:='file.conf'<?xml version=""1.0""?>

<app mode=""debug"">
    <translate type=""en""/>
    <window display-mode=""-d"">
        <default-size>
            <width>1280</width>
            <height>720</height>
        </default-size>
        <header>
            <dashboards src=""${airbus_cobot_gui}/config/default_dashboards_register.xml"">
            </dashboards>
        </header>
        <launcher default-view=""Rviz"" default-mode=""manu"">
            <plugins src=""${airbus_cobot_gui}/config/default_plugins_register.xml"">
                <plugin name=""Rviz""/>
                <plugin name=""Rqt""/>
                <group name=""Monitoring"" icon=""${airbus_cobot_gui}/resources/images/icon_monitoring.png"">
                    <plugin name=""NodeManager""/>
                    <plugin name=""LogManager""/>
                </group>
           </plugins>
        </launcher>
    </window>
</app><?xml version=""1.0""?>

<app mode=""debug"">
    <translate type=""en""/>
    <window display-mode=""-d"">
        <default-size>
            <width>1280</width>
            <height>720</height>
        </default-size>
        <header>
            <dashboards src=""${airbus_templates}/config/default_dashboards_register.xml"">
                                <dashboard name=""Template""/>
            </dashboards>
        </header>
        <launcher default-view=""Template"" default-mode=""manu"">
            <plugins src=""${airbus_templates}/config/default_plugins_register.xml"">
                                <plugin name=""Template""/>
                <plugin name=""Rviz""/>
                <plugin name=""Rqt""/>
                <group name=""Monitoring"" icon=""${airbus_cobot_gui}/resources/images/icon_monitoring.png"">
                    <plugin name=""NodeManager""/>
                    <plugin name=""LogManager""/>
                </group>
           </plugins>
        </launcher>
    </window>
</app><?xml version='1.0' encoding='utf8'?>
<dashboards-register>
        <dashboard label=""Template"" package=""airbus_template_dashboard"" />
</dashboards-register><?xml version='1.0' encoding='utf8'?>
<plugins-register>
  <plugin label=""Rviz""           package=""airbus_plugin_rviz"" />
  <plugin label=""Rqt""            package=""airbus_plugin_rqt"" />
  <plugin label=""NodeManager""    package=""airbus_plugin_node_manager"" />
  <plugin label=""LogManager""     package=""airbus_plugin_log_manager"" />
  <plugin label=""Template""       package=""airbus_template_plugin"" />
</plugins-register>"
W2111,https://wiki.ros.org/interaction_cursor_3d,Wiki,interaction_cursor_3d,"Metapackage for interaction cursor functionality.

Use GitHub to . []
  "
W2112,https://wiki.ros.org/motoman_config,Wiki,motoman_config,"

     The motoman_config package includes common configurations and 3D models for motoman manipulators
     
  


Use GitHub to . []
 This package is part of the  program. It currently contains config files and meshes for the  meta-package. See the  page for an overview of the available tutorials. "
W2113,https://wiki.ros.org/motoman_experimental,Wiki,motoman_experimental,"Experimental packages for Motoman manipulators within ROS-Industrial.: This status indicates that this software is experimental code at best.  There are known issues and missing functionality.  The APIs are completely unstable and likely to change.  Use in production systems is not recommended.  All code starts at this level.  For more information see the ROS-Industrial software status .



Use GitHub to . []
 This repository is part of the  program. It contains experimental packages that will be moved to the  repository once they've received sufficient testing and review. See the  page for more information. "
W2114,https://wiki.ros.org/airbus_plugin_log_manager,Wiki,airbus_plugin_log_manager,The airbus_plugin_log_manager package
W2115,https://wiki.ros.org/kingfisher_desktop,Wiki,kingfisher_desktop,The kingfisher_desktop metapackageMetapackage of desktop tools supporting . 
W2116,https://wiki.ros.org/melfa_driver,Wiki,melfa_driver,The melfa_driver package
W2117,https://wiki.ros.org/photo,Wiki,photo,"The photo package provides access to digital cameras. Much of the underlying functionality is provide by the gPhoto libary. The system package libgphoto2-2-dev or equivalent is required.>


The photo package provides access to digital cameras. Much of the underlying functionality is provide by the  libary. The system package libgphoto2-2-dev or equivalent is required. Calls the set_config service of photo_node and attempts to set the exptime parameter to . get_configset_configcapture20"
W2118,https://wiki.ros.org/prbt_pg70_support,Wiki,prbt_pg70_support,PRBT support for Schunk pg70 gripper.
W2119,https://wiki.ros.org/create_dashboard,Wiki,create_dashboard,"The Create dashboard is a RQT-based plug-in for visualising data from the Create and giving easy access
    to basic functionalities. 
The Create dashboard is part of the . Head over there to find out how to use it and what it can do. "
W2120,https://wiki.ros.org/kurt_2dnav,Wiki,kurt_2dnav,"
     This application allows the Kurt robot to navigate autonomously with a
     pre-specified static map. This package is modeled after pr2_2dnav.
  "
W2121,https://wiki.ros.org/move_base_to_manip,Wiki,move_base_to_manip,"Move the robot base until a desired end-effector pose can be reached.
  





For mobile manipulators, this package calculates a robot base location where the end-effector (EE) can reach a desired pose (a.k.a. inverse reachability). The method is computationally fast (since it depends on a  Cartesian motion plan), simple (~300 lines), and easy to use (requiring just a service to provide the desired pose). Below, the first image shows a mobile manipulator which is too far to grasp the object of interest. The desired EE pose is shown in green. The second image shows the freshly-calculated base position (red cube) which will allow the robot to reach that pose. <<Please ignore the bad camera calibration>> This package uses  for base commands and  for manipulator motion planning.  ^This launches a ROS service that will make a desired pose available to the move_base_to_manip node. It also displays this desired pose in Rviz. When the client sends  on the service request, this node will shut down after providing the pose. ^This node requests the desired pose from the other node. It then moves the end-effector to the desired height and orientation. From there, it plans a Cartesian move to the desired pose. The % completion of the Cartesian move informs the base on how far it must move. If the Cartesian move is able to complete 100%, the arm moves and the program exits. Otherwise, there is a call to  to get closer to the object: The planner reads optional parameters on the . They can be adjusted from the command line, programmatically, or left as their default values. They are: * : A fraction between 0 and 1. A value of 1 means the EE will barely be able to reach the desired pose when fully extended. A value of 0 means the base motion will bring the EE to the desired pose without additional arm motion. Default: 0.15.  * : Use a Cartesian motion for the final arm approach, or a regular  motion? The Cartesian motion may be useful if your task requires the gripper to maintain a constant orientation (like grasping often does). Default: false, i.e. do a regular motion. * : Clear the octomap collision scene before the final arm approach? This is often necessary for grasping -- otherwise sensor noise/resolution may lead the robot to expect a collision. Default: true, i.e. the collision scene will be cleared. * : Clear the move_base costmaps before base motion? Default: true. * : Ask the user before making any motion? This is useful if you're just starting to use the package and aren't sure what to expect. Default: true. * : This is the ""request"" part of the service call. Can be used as a signal that the server can shutdown. Default: true (which I use to signal the pose provider node to shut down). * : A smaller number results in a more accurate prediction of the distance to the pose of interest. Default: 0.005m * : Default ""right_ur5"" * : Default ""RRTConnectkConfigDefault"" * : % of maximum robot speed for all arm motions. Default: 0.1 * : Default ""base_link"" * : Position tolerance for arm motions. It may be useful to bump this up if you are having trouble finding plans. Default: 0.01 m * : Orientation tolerance for arm motions. Default: 0.0001 rad * : If true, the planner will try to flip the EE +/-180 deg about Z (i.e. ) when it cannot reach a desired pose. Then it will attempt to plan again. Useful for 2-finger grippers. Default: true Here are some hints to get more suitable trajectories from : * Make sure the resolutions of your costmap and  planners are fine enough to get the accuracy you require. Here are  from the creator of . This package only calculates one base position which can reach the desired pose. If the base is not able to move there, it fails. However,  has some built-in obstacle avoidance capabilities and if it fails, it will generally be close to the goal. * (untested) Use the  package to calculate a good location for the manipulator's base. From the manipulator's position, calculate a mobile base location. This is the ""inverse reachability database"" approach. $ sudo apt-get install ros-indigo-move-base-to-manip$ rosrun move_base_to_manip provide_target$ roslaunch move_base_to_manip move_base_to_manip.launchac.sendGoal(goal);"
W2122,https://wiki.ros.org/neo_base_mp_500,Wiki,neo_base_mp_500,launchfiles for MP_500
W2123,https://wiki.ros.org/linux_hardware,Wiki,linux_hardware,"

     Simple scripts which help utilise, monitor, interact with computer
     hardware abstracted by a linux OS.

   This functionality has been moved out in indigo in favour of using the standard drivers in the  group. "
W2124,https://wiki.ros.org/apriltags_ros,Wiki,apriltags_ros,"A package that provides a ROS wrapper for the apriltags C++ package



 A ROS wrapper for the . The nodelet functions equivalently to the  node. apriltag_rosapriltag_rosapriltag_detector_node"
W2125,https://wiki.ros.org/asr_mild_navigation,Wiki,asr_mild_navigation,"The mild_navigation package. Launchfiles to start the navigation relevant nodes. Parameter for navigation and maps. 

    
 
  

   


 The asr_mild_navigation uses the standard  with some specific components. There are three overlay packages: Asr_move_base and asr_navcore are only needed if you use the asr_ftc_local_planner which is the standard local planner for the asr_mild_navigation. Look at the  documentation on how to use and include the asr_move_base and asr_nav_core packages. The asr_ftc_local_planner implements a new local planner and is used instead of the  or . The asr_navfn package includes an upgraded version of the standard navfn (check out the asr_navfn documentation). There are also two launch files to start the gazebo simulation with different rooms. There are also a launch file (launch/amcl_diff.launch"") to start , this is automaticly started if you launch ""launch/navigation.launch"". roslaunch asr_mild_navigation simulation_manual_rearranged.launchroslaunch asr_mild_navigation navigation.launch<node name=""map_server"" pkg=""map_server"" type=""map_server"" args=""$(find your_package)/your_map.yaml"" required=""true""/>roslaunch asr_mild_navigation gazebo_mild_manual_rearranged.launch"
W2126,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5052/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2127,https://wiki.ros.org/oculus_sdk,Wiki,oculus_sdk,The Oculus Rift SDK
W2128,https://wiki.ros.org/mrp2_common,Wiki,mrp2_common,Necessary packages in common for both simulation and real environment.
W2129,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14693/6  "
W2130,https://wiki.ros.org/fake_odom,Wiki,fake_odom,"The fake_odom package


To start the  in a faked odometry mode the '_fake' launch files in wheeled_robin_bringup. cmd_velodomjoint_statesodombase_footprintbase_footprintbase_link"
W2131,https://wiki.ros.org/asr_flock_of_birds,Wiki,asr_flock_of_birds,"The asr_flock_of_birds package is the driver for Ascension Technology Corp magnet-tracking system ""Flock of Birds"". It provides the remote server which publishes two 6d posemarker and the nessesary TF from the magnettracking system. It also contains launchfiles and calibration tools for the use of it. 

  


 magnet tracking system ""Flock of Birds"" is needed. 

The asr_flock_of_birds package is the driver for  magnet tracking system ""Flock of Birds"" (FoB). It provides the remote server which publishes two 6d posemarker and the necessary TF from the magnet tracking system. It also contains launch-files and calibration tools for the use of it. Flock of Birds is a 6D tracking system which can very precisely track position and orientation of three sensors in a magnetic field in front of the receiver. Each tracker is connected to an data-glove and so only two trackers are used currently (for left and right hand). If started, the node publishes periodically the pose of the trackers as TF-publisher as well as -Messages on the -Topic. This package can be used as a standalone-driver for the Flock of Birds tracker system, but it is recommended to use it as a part of the . This package depends on -Package for the publication of the fob_objects. There are mainly two ways to start the Flock of Birds server: To start it directly form the PC which the hardware is connected with, use  To start from another PC, the package provides a remote script. But Firstly, a ssh connection have to be set up. Secondly, use  The launched Node publishes -Messages on the -Topic. There are no configuration or controlling elements. "
W2132,https://wiki.ros.org/rosruby_actionlib,Wiki,rosruby_actionlib,"actionlib for rosruby.
See . "
W2133,https://wiki.ros.org/atlas_v3_moveit_config,Wiki,atlas_v3_moveit_config,An automatically generated package with all the configuration and launch files for using the atlas with the MoveIt Motion Planning Framework
W2134,https://wiki.ros.org/create_description,Wiki,create_description,Model description for the iRobot CreateThis just stores the urdf's of the create base for the turtlebot. The actual application of the urdf's happen in  where it is stitched together with the other turtlebot components. 
W2135,https://wiki.ros.org/rqt_dyn_tune,Wiki,rqt_dyn_tune,"The graphical user interface for dyn_tune package
"
W2136,https://wiki.ros.org/mrp2_description,Wiki,mrp2_description,URDF and xacro description files for MRP2.
W2137,https://wiki.ros.org/ptu46,Wiki,ptu46,"Driver for the Directed Perception ptu46 pan/tilt driver, forked from player
~cmd~state~hzInteger~portString~baudInteger~min_tilt, ~max_tilt, ~min_pan, ~max_panFloat~min_tilt_speed, ~max_tilt_speed, ~min_pan_speed, ~max_pan_speedFloat~tilt_step, ~pan_stepFloat"
W2138,https://wiki.ros.org/interaction_cursor_rviz,Wiki,interaction_cursor_rviz,"The interaction_cursor_rviz package




You may also need , which unfortunately must go in a rosbuild workspace. You can add the option start_hydra:=false, or change the radius of the hydra workspace with radius:=<a number>. Please send bug reports, feature requests, etc. to the .  https://github.com/ros-visualization/visualization_tutorialssudo apt-get install ros-groovy-rviz-animated-view-controller- git: {local-name: ros_3d_interaction_cursor, uri: 'https://github.com/aleeper/ros_3d_interaction_cursor.git'}
- git: {local-name: razer_hydra, uri: 'https://github.com/aleeper/razer_hydra.git'}
- git: {local-name: interactive_markers, uri: 'https://github.com/ros-visualization/interactive_markers.git'}
- git: {local-name: rviz, uri: 'https://github.com/ros-visualization/rviz.git'}roscd razer_hydra
./configure_udev_rulesroslaunch interaction_cursor_demo demo.launch"
W2139,https://wiki.ros.org/rosthrottle,Wiki,rosthrottle,"ROS Python package for throttling ROS topics programatically in Python. Sits on top of the 
        ros_comm topic_tools throttle utility."
W2140,https://wiki.ros.org/asr_aruco_marker_recognition,Wiki,asr_aruco_marker_recognition,"This package contains a marker recognition system using the ArUco library. 
    It can be used with a mono or stereo camera system but yields better results with the latter.
    


      











 The objects are detected in the image(s) using the -library. Depending on the used camera system (mono or stereo), the found markers are further processed. If a mono system is used, the found poses of the -library are published, if on the other hand a stereo system is used, the final marker pose is calculated based on the positions of the markers in the left and right image: If a marker with the same id was found in each of them, the 3D corner points are calculated using triangulation of the 2D corner points in each image. The final pose is then calculated using ICP and then published. Marker images can be created by using the marker creator tool this package contains. They need to be printed and then they can be attached to corresponding objects in the scene. This correspondance can be specified by adding mesh-models to the  and naming the object depending on the used marker id (compare already created objects in the database for more information). In this example 4 markers are in the scene, two of which have a corresponding object stored in the  (monitor and mouse). The markers each have the size of 1.5x1.5mm and the used cameras have a resolution of 1292x964. The following parameters can be changed in the  file in the param folder: The marker creator has the following parameters specified in  in the param folder: This package calls a service provided by the  to get information about the objects corresponding to the used markers: roslaunch asr_aruco_marker_recognition aruco_marker_recognition.launchrosservice call /asr_aruco_marker_recognition/get_recognizerrosservice call /asr_aruco_marker_recognition/release_recognizerroslaunch asr_aruco_marker_recognition marker_creator.launch"
W2141,https://wiki.ros.org/neo_relayboard,Wiki,neo_relayboard,Communication Node with neo_relayboard
W2142,https://wiki.ros.org/mrp2_analyzer,Wiki,mrp2_analyzer,The diagnostic package for MRP2.
W2143,https://wiki.ros.org/jointstick,Wiki,jointstick,Move any joint with any controller!
W2144,https://wiki.ros.org/ptu_control,Wiki,ptu_control,"Actionlib interface for PTUs which listen for JointState messages (such as PTU46)




















"
W2145,https://wiki.ros.org/android_apps,Wiki,android_apps,"Applications for robot-android pairing..
Applications for use with . Many of these are found on the . Refer to the  page for more information. "
W2146,https://wiki.ros.org/interaction_cursor_msgs,Wiki,interaction_cursor_msgs,"The interaction_cursor_msgs package

These are structured in a similar way to  Update/Feedback messages. In particular, a server application (such as interaction_cursor_demo) sends  messages that are received by a client application (such as Rviz running the interaction_cursor_rviz display plugin). The client plugin is then responsible for sending feedback messages to the server. Please send bug reports, feature requests, etc. to the . "
W2147,https://wiki.ros.org/kurt_2dnav_slam,Wiki,kurt_2dnav_slam,"
     This application allows the Kurt to navigate autonomously while also
     building a map of its environment as it drives along. It is modeled after
     pr2_2dnav_slam.
  "
W2148,https://wiki.ros.org/melfa_robot,Wiki,melfa_robot,The melfa_robot meta package
W2149,https://wiki.ros.org/nav2_navigation,Wiki,nav2_navigation,ROS navigation config and launch files for Nav2 Robot Platform
W2150,https://wiki.ros.org/modbus,Wiki,modbus,"The modbus package


 



 modbus_wrapper/outputmodbus_wrapper/inputmodbus_server/read_from_registersmodbus_server/write_to_registers"
W2151,https://wiki.ros.org/moveit_robots,Wiki,moveit_robots,moveit_robots meta-package contains multiple robots moveit configuration packages.
W2152,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5053/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2153,https://wiki.ros.org/rosruby_messages,Wiki,rosruby_messages,rosruby_messages is precompiled rosruby messages.
W2154,https://wiki.ros.org/asr_cyberglove_lib,Wiki,asr_cyberglove_lib,"This package is used to start a server that provides the current joint state values received from the CyberGloves via ROS topics 



 




Instead of using the preconfigured .launch-file, the server can also be started via , e.g. with: If the hardware is connected to a ROS Indigo Lab-PC and it is needed to start the asr_cyberglove_lib server from a remote ROS Kinetic Lab-PC, some workarounds / dirty hacks are needed. For the following, it is assumed that both ROS systems use the same file system and that the corresponding catkin workspaces are  and . Open the terminal and source Kinetic (if not already sourced via ~/): Additional ssh environment setups are needed (): A ssh connection can now be established, but the ~/ needs to be modified to be able to start the server on ROS Indigo: To listen to the publishing ROS-Topic in a new terminal, ROS Kinetic has to be sourced again (or modify the ~/ again before opening the new terminal): Alternatively, the glove movements can also be visualized with the  package (Kinetic needs to be sourced again): The sensor data of the Cybergloves are published as messages to the following topics: As mentioned in subsection 2.3, the asr_cyberglove_lib server can be started directly via  without using the preconfigured .launch-file. For this case, it is needed to specify the  arguments. The following arguments can be passed: roslaunch asr_cyberglove_lib glove_lib.launchrosrun asr_cyberglove_lib gloveServer_node -r --calibration-file-right $(find asr_cyberglove_lib)/cfg/GloveCalibrationRight.cal --tty-right /dev/ttyD2 -d 0rosrun asr_cyberglove_lib glove_lib_remote.sh"
W2155,https://wiki.ros.org/rb1_base_gazebo,Wiki,rb1_base_gazebo,"The rb1_base_gazebo package
"
W2156,https://wiki.ros.org/kurt_navigation_global,Wiki,kurt_navigation_global,"
     This package holds XML files for running the  node on a Kurt
     robot. The  node
     is configured to run over a pre-specified static map. This package is
     modeled after pr2_navigation_global.
  "
W2157,https://wiki.ros.org/interaction_cursor_demo,Wiki,interaction_cursor_demo,A demo 3D cursor interaction application.
W2158,https://wiki.ros.org/atlas_moveit_config,Wiki,atlas_moveit_config,An automatically generated package with all the configuration and launch files for using the atlas with the MoveIt Motion Planning Framework
W2159,https://wiki.ros.org/muse_bldc_motor_drive,Wiki,muse_bldc_motor_drive,"The muse_bldc_motor_drive package



<feedback_topic_name> (muse_bldc_motor_drive/feedback.msg) 
<control_commands_topic_name> (muse_bldc_motor_drive/control_cmd.msg) <state_machine_commands_topic_name> (muse_bldc_motor_drive/state_machine_cmd.msg) 
 Now  node publishes a list with Muse Drives that are visible on the network and is ready to listen to your commands. rosrun muse_bldc_motor_drive muse_bldc_motor_driverosrun muse_bldc_motor_drive muse_bldc_motor_drive <feedback_frequency(Hz)> <control_frequency(Hz)>"
W2160,https://wiki.ros.org/airbus_coop,Wiki,airbus_coop,"The airbus_coop metapackage

"
W2161,https://wiki.ros.org/neato_driver,Wiki,neato_driver,"

    This is a generic drivers for the Neato XV-11 Robotic Vacuum.

    ROS Bindings can be found in the neato_node package.

  "
W2162,https://wiki.ros.org/moveit_goal_builder,Wiki,moveit_goal_builder,"The moveit_goal_builder packageUse GitHub to . []
 
 is a library for building . This is useful for when you want to use the  actionlib interface directly, instead of using the  class. This allows you to poll when the action is done, which the normal  interface does not allow you to do. 


moveit_goal_builderBuild()build


















"
W2163,https://wiki.ros.org/baxter_moveit_config,Wiki,baxter_moveit_config,An automatically generated package with all the configuration and launch files for using the baxter with the MoveIt Motion Planning Framework
W2164,https://wiki.ros.org/clam_moveit_config,Wiki,clam_moveit_config,clam_moveit_config
W2165,https://wiki.ros.org/eband_local_planner,Wiki,eband_local_planner,"eband_local_planner implements a plugin to the
    base_local_planner. It implements the Elastic Band method on the
    SE2 manifold.




  (, default: 0.1)   (, default: 0.5)   (, default: 0.7)   (, default: 0.75)  The original implementation for this ROS  local planner only supported omni-directional (holonomic) robots. The current version was modified to work with differential drive machines. Set  to  to enable lateral/holonomic motion, but that mode has not been tested for a long time and should be considered experimental. This plugin runs inside the move_base process. Its parameter namespace is prefixed by that of  and the  name under which it was launched, typically , e.g.: differential_drivefalsexy_goal_tolerancerotation_threshold_multiplierxy_goal_tolerancerotation_threshold_multipliermove_basebase_local_plannerEBandPlannerROS~/EBandPlannerROS/xy_goal_tolerancedouble~/EBandPlannerROS/yaw_goal_tolerancedouble~/EBandPlannerROS/rot_stopped_veldouble~/EBandPlannerROS/trans_stopped_veldouble~/EBandPlannerROS/marker_lifetimedouble~/EBandPlannerROS/eband_min_relative_overlapdouble~/EBandPlannerROS/eband_tiny_bubble_distancedouble~/EBandPlannerROS/eband_tiny_bubble_expansiondouble~/EBandPlannerROS/eband_internal_force_gaindouble~/EBandPlannerROS/eband_external_force_gaindouble~/EBandPlannerROS/num_iterations_eband_optimizationint~/EBandPlannerROS/eband_equilibrium_approx_max_recursion_depthint~/EBandPlannerROS/eband_equilibrium_relative_overshootdouble~/EBandPlannerROS/eband_significant_force_lower_bounddouble~/EBandPlannerROS/costmap_weightdouble~/EBandPlannerROS/max_vel_lindouble~/EBandPlannerROS/max_vel_thdouble~/EBandPlannerROS/min_vel_lindouble~/EBandPlannerROS/min_vel_thdouble~/EBandPlannerROS/min_in_place_vel_thdouble~/EBandPlannerROS/in_place_trans_veldouble~/EBandPlannerROS/k_propdouble~/EBandPlannerROS/k_dampdouble~/EBandPlannerROS/Ctrl_Ratedouble~/EBandPlannerROS/max_accelerationdouble~/EBandPlannerROS/virtual_massdouble~/EBandPlannerROS/max_translational_accelerationdouble~/EBandPlannerROS/max_rotational_accelerationdouble~/EBandPlannerROS/rotation_correction_thresholddouble~/EBandPlannerROS/differential_drivebool~/EBandPlannerROS/bubble_velocity_multiplierdouble~/EBandPlannerROS/rotation_threshold_multiplierdouble~/EBandPlannerROS/disallow_hysteresisbool  <node pkg=""move_base"" type=""move_base"" name=""move_base"">
    <param name=""base_local_planner"" value=""eband_local_planner/EBandPlannerROS""/>
    ...
  </node>"
W2166,https://wiki.ros.org/mrp2_navigation,Wiki,mrp2_navigation,"Launch files, parameters and maps for different navigation applications."
W2167,https://wiki.ros.org/infinisoleil,Wiki,infinisoleil,"This package provides a ROS driver for Infinisoleil sensors.








range_imageir_imagepoint_cloud/diagnostics~hostnamestr~port_numberstr~connect_timeoutint~send_timeoutint~receive_timeoutint~range_frame_idstr~ir_frame_idstr~point_cloud_frame_idstr~diagnostics_enablebool~measure_modeint~measure_point_xint~measure_point_yint~swing_fsint~swing_ssint~xy_surface_countint~frame_cycleint~max_measure_modeint~xy_serial_numberstr~logic_versionstr~firm_versionstr~product_numberstr$ rosrun nodelet nodelet manager
$ rosrun nodelet nodelet load infinisoleil/FX8DriverNodelet manager$ rosrun nodelet nodelet manager
$ rosrun nodelet nodelet load infinisoleil/FX8DriverNodelet manager _hostname:=192.168.0.81$ roslaunch infinisoleil fx8_driver.launch$ roslaunch infinisoleil fx8_node.launch$ roslaunch infinisoleil fx8_node.launch hostname:=192.168.0.81$ roslaunch infinisoleil fx8_driver.launch diagnostics_enable:=false  <launch>
    <!-- launch fx8_driver.launch -->
    <include file=""$(find infinisoleil)/launch/fx8_driver.launch""/>
  
    <!-- Add another driver nodelet -->
    <node pkg=""nodelet"" type=""nodelet"" name=""add_driver""
      args=""load infinisoleil/FX8DriverNodelet fx8_nodelet_manager""
      output=""screen"">
      <remap from=""range_image"" to=""add_driver/range_image""/>
      <remap from=""ir_image"" to=""add_driver/ir_image""/>
      <remap from=""point_cloud"" to=""add_driver/point_cloud""/>
      <param name=""hostname"" type=""str"" value=""192.168.0.81""/>
    </node>
  </launch>$ rostest infinisoleil fx8_driver_hertz.test$ rostest infinisoleil fx8_driver_hertz.test set_hostname:=192.168.0.81$ rostest infinisoleil fx8_driver_hertz.test set_measure_mode:=1 hz:=16.0"
W2168,https://wiki.ros.org/alliance_msgs,Wiki,alliance_msgs,"This package contains the definition of the message, service and action files of the alliance stack."
W2169,https://wiki.ros.org/r2_control,Wiki,r2_control,Ready Poses for the Robonaut2
W2170,https://wiki.ros.org/apriltags,Wiki,apriltags,"A catkin version of the C++ apriltags library
A catkin version of the  apriltag_rosapriltag_ros"
W2171,https://wiki.ros.org/gazebo_taskboard,Wiki,gazebo_taskboard,"

     gazebo_taskboard

  "
W2172,https://wiki.ros.org/mtig_driver,Wiki,mtig_driver,"ROS driver for Xsens MTI-G-700 series motion trackers
	  - modified to publish GPS messages



Download the MT Software Suite and install it on a Windows machine (you may skip this step and use default sensor configuration), then download the MT SDK for Linux and install it on a Linux machine (this should be the machine that ROS is installed on). Here is the software website: . Follow the instructions in the MT SDK for Linux to install the software  and make sure the examples run correctly with the sensor. You may need to install the kernel available at . /xsens/imu/xsens/gps/xsens/velocity/xsens/temperature/xsens/pressure/xsens/magnetic/xsens/gps_extra $ ls /dev/ttyUSB0 $ sudo adduser this_user dialout $ roslaunch mtig_driver mtig_driver.launch<launch>
        <arg name=""frame"" default=""xsens"" />
        <node pkg=""mtig_driver"" type=""mtig_driver_node"" name=""mtig_driver"">
                <!-- Error parameters /-->
                <param name=""roll_error"" value=""0.2"" />
                <param name=""pitch_error"" value=""0.2"" />
                <param name=""yaw_error"" value=""1.0"" />
                <param name=""acc_noise"" value=""0.00015"" />
                <param name=""gyr_noise"" value=""0.01"" />

                <!-- Frame Parameter /-->
                <param name=""frame_id"" value=""$(arg frame)"" />

                <!-- Override Mode /-->
                <param name=""override"" value=""true"" />

                <!-- Module Setup Parameters /-->
                <param name=""orientation_enabled"" value=""true""/>
                <param name=""orientation_frequency"" value=""0""/>
                <param name=""gps_enabled"" value=""true""/>
                <param name=""gps_frequency"" value=""0""/>
                <param name=""temperature_enabled"" value=""true""/>
                <param name=""temperature_frequency"" value=""0""/>
                <param name=""acceleration_enabled"" value=""true""/>
                <param name=""acceleration_frequency"" value=""0""/>
                <param name=""pressure_enabled"" value=""true""/>
                <param name=""pressure_frequency"" value=""0""/>
                <param name=""magnetic_enabled"" value=""true""/>
                <param name=""magnetic_frequency"" value=""0""/>
                <param name=""altitude_enabled"" value=""true""/>
                <param name=""altitude_frequency"" value=""0""/>
                <param name=""velocity_enabled"" value=""true""/>
                <param name=""velocity_frequency"" value=""0""/>
                <param name=""gyroscope_enabled"" value=""true""/>
                <param name=""gyroscope_frequency"" value=""0""/>
        </node>
</launch>"
W2173,https://wiki.ros.org/nav2_driver,Wiki,nav2_driver,ROS driver node for the Nav2 base
W2174,https://wiki.ros.org/lslidar_n301,Wiki,lslidar_n301,"Basic ROS support for the Leishen N301 LIDARs.









 that this launch file launches both the driver and the decoder, which is the only launch file needed to be used. 

 Bug Report Prefer to open an issue. You can also send an E-mail to  . cd your_work_space
catkin_make --pkg lslidar_n301_driver lslidar_n301_decoder --cmake-args -DCMAKE_BUILD_TYPE=Releaseroslauch lslidar_n301_decoder lslidar_n301_decoder_nodelet.launch"
W2175,https://wiki.ros.org/r2_gazebo,Wiki,r2_gazebo,"

     r2_gazebo

  "
W2176,https://wiki.ros.org/nav2_platform,Wiki,nav2_platform,"ROS stack  containing all nodes, config, and launch files for Nav2 mobile robotics platform.

The  stack contains several component packages: To configure the  robot for usage, you should edit the launch files located in the  package. This is best done by cloning the package into your catkin workspace overlay, and making your changes locally: The Nav2 base can be controlled immediately by setting the appropriate IP/Hostname and port in the  launch file. This launch file will start the  node with the appropriate parameters, meaning that it will listen for Twist commands on the  topic, and output the appropriate transforms and odometry messages on  and  respectively. To use the Nav2 with ROS navigation and mapping packages, you need to configure the sensor and appropriate parameters. Demo configurations for OpenNI (e.g. MS Kinect, Asus Xtion) and Hokuyo (i.e. URG-XX) compatible sensors are provided (but commented out) in the  launch file. nav2_platformnav2_bringupnav2_drivernav2_navigationnav2_bringupnav2_robot.launchnav2_driver/cmd_vel/tfodomnav2_robot.launch#Create a catkin workspace if you don't have one yet
source /opt/ros/$(rosversion -d)/setup.bash
mkdir -p ~/catkin_ws/src
catkin_init_workspace ~/catkin_ws/src#Clone the nav2_platform git repo
cd ~/catkin_ws/src
git clone https://github.com/paulbovbel/nav2_platform.git
cd ~/catkin_ws/
catkin_make
source devel/setup.bash#Configure correct IP/Hostname and port
rosed nav2_bringup nav2_robot.launch
#Launch the robot bringup launch file
roslaunch nav2_bringup nav2_robot.launch"
W2177,https://wiki.ros.org/neato_robot,Wiki,neato_robot,"
    This stack contains drivers for the Neato XV-11 robot. It also contains sample configuration files for running the Navigation stack on an XV-11.
  

We are currently using the . "
W2178,https://wiki.ros.org/lslidar_c16,Wiki,lslidar_c16,"Basic ROS support for the Leishen C16 LIDARs.














   This  package is a linux ROS driver for lslidar c16 from Shenzhen Leishen Intelligence System Co, Ltd. lidar_ipstringdefault: 192.168.1.200device_portintdefault: 2368frame_idstringdefault: laseradd_multicastbooldefault: falsegroup_ipstringdefault: 234.2.3.2lslidar_packetslslidar_c16_msgs/LslidarC16Packetmin_rangedouble0.15max_rangedouble150.0frequencyfrequency10.0publish_point_cloudbooltrueuse_gps_tsboolfalseangle3_disable_mindouble-1angle3_disable_maxdouble-1lslidar_sweeplslidar_c16_msgs/LslidarC16Sweeplslidar_point_cloudsensor_msgs/PointCloud2publish_point_cloudtruelslidar_packetslslidar_c16_msgs/LslidarC16Packeteth0sudo tcpdump -i eth0roslaunch lslidar_c16_decoder lslidar_c16.launch --screen"
W2179,https://wiki.ros.org/neato_2dnav,Wiki,neato_2dnav,"This package contains configuration and launch files for using the navigation stack with the Neato XV-11 robot.


 can be used to create maps, as with any other robot. We've yet to find just the right set of parameters (work on the beam likelihood is probably needed), but the following seems to work on the Neato for smaller maps such as the one shown below:  roslaunch neato_node bringup.launch
roslaunch neato_2dnav move_base.launchrosrun gmapping slam_gmapping scan:=base_scan _srr:=0.001 _srt:=0.001 _str:=0.000001 _stt:=0.000001 _linearUpdate:=0.5 _angularUpdate:=0.4"
W2180,https://wiki.ros.org/gazebo_interface,Wiki,gazebo_interface,"

     gazebo_interface

  "
W2181,https://wiki.ros.org/neato_node,Wiki,neato_node,"
    This package contains a node that connects to the Neato Robotics XV-11. It enables control of motors through a geometry_msgs/Twist topic and publishes laser scans and odometry.
  



/cmd_vel/base_scan/odom~portstrlsusbsudo modprobe usbserial vendor=0x2108 product=0x780broslaunch neato_node bringup.launch"
W2182,https://wiki.ros.org/problib,Wiki,problib,"problib
Problib is a probabilistic library containing tools that can be used for representing or converting probabilistic information. It is part of the  stack. "
W2183,https://wiki.ros.org/ompl_ros_interface,Wiki,ompl_ros_interface,"

     ompl_ros_interface

  


 



To install this package, you will have to install the  stack: Examples for how to setup and configure motion planners for your robot can be found in the accompanying .  A quick example for use with the PR2 robot in simulation (Gazebo) can be found in the  in Gazebo. Follow the instructions on that page to see ompl_ros_interface in action. The tabletop manipulation stacks in diamondback now use the ompl_ros_interface for planning using OMPL. To run these stacks on the PR2 robot, try the tabletop manipulation demo .  sudo apt-get install ros-electric-arm-navigation"
W2184,https://wiki.ros.org/nav_core_adapter,Wiki,nav_core_adapter,"This package contains adapters for using `nav_core` plugins as `nav_core2` plugins and vice versa (more or less).
      See README.md for more information. "
W2185,https://wiki.ros.org/raspigibbon_control,Wiki,raspigibbon_control,The raspigibbon_control package
W2186,https://wiki.ros.org/mrp2_viz,Wiki,mrp2_viz,RViz configurations and launch files for visualization.
W2187,https://wiki.ros.org/pr2_object_manipulation,Wiki,pr2_object_manipulation,"
    Contains PR2-specific implementations of some of the generic
    functionality needed for pickup and place tasks. 
  


  In general, PR2 specific implementations contained here will implement general interfaces defined in the  stack. Contains PR2 specific launch files for using the manipulation functionality. To launch the manipulation pipeline complete with sensor input and execute pickup and place tasks using the PR2 robot, tutorials and launch files are provided in . "
W2188,https://wiki.ros.org/raspimouse_ros,Wiki,raspimouse_ros,"The raspimouse package
 



日本語版wikiはです。 "
W2189,https://wiki.ros.org/nj_oa_costmap,Wiki,nj_oa_costmap,"The nj_oa_costmap package is a navigating jockey for the Large
	  Maps framework. Its role is to drive the robot forward while avoiding
	  obstacles. It uses a local map which position is relative to the robot
	  but which orientation is constant.


The  package implements a navigating jockey for the Large Maps Framework () that drives the robot while avoiding obstacles. It is based on a local map (). The local map has a fixed position relative to the robot but its orientation is constant in the world reference frame. It is a reactive, memory-less jockey. Moreover, the package provides the class  that computes an appropriate  from a  in order to go as forward as possible while avoiding obstacles. nj_oa_costmapTwistHandler~<name>/local_map~<name>/cmd_vel~<name>/robot_radiusFloat~<name>/min_distanceFloat~<name>/long_distanceFloat~<name>/turnrate_collideFloat~<name>/max_velFloat~<name>/vel_close_obstacleFloat~<name>/turnrate_factorFloat~<name>/laser_frameString~<name>/navigating_jockey_server_nameString"
W2190,https://wiki.ros.org/naoqi_libqi,Wiki,naoqi_libqi,Aldebaran's libqi: a core library for NAOqiOS development
W2191,https://wiki.ros.org/openslam_gmapping,Wiki,openslam_gmapping,ROS-ified version of gmapping SLAM. Forked from https://openslam.informatik.uni-freiburg.de/data/svn/gmapping/trunk/
W2192,https://wiki.ros.org/mrp2_desktop,Wiki,mrp2_desktop,Visualization tools and configurations for MRP2 robot.
W2193,https://wiki.ros.org/pr2_gui,Wiki,pr2_gui,"

    Contains GUI tools for working with PR2s.

   is meant to be a collection of GUI tools for working specifically with PR2 robots.  Currently the only package included is , which provides status and debugging information, as well as allowing you to do things like reset breakers, motors, etc.  (replaced by  in ROS Groovy and later) 
  pr2_gui"
W2194,https://wiki.ros.org/openrtm_aist_python,Wiki,openrtm_aist_python,Python binding of OpenRTM-AIST (seefor further information).()
W2195,https://wiki.ros.org/pal_hardware_gazebo,Wiki,pal_hardware_gazebo,The pal_hardware_gazebo package
W2196,https://wiki.ros.org/opencv_apps,Wiki,opencv_apps,"opencv_apps provides various nodes that run internally OpenCV's functionalities and publish the result as ROS topics. With opencv_apps, you can skip writing OpenCV application codes for a lot of its functionalities by simply running a launch file that corresponds to OpenCV's functionality you want.The most of code is originally taken from https://github.com/Itseez/opencv/tree/master/samples/cpp


























With , you can run a lot of functionalities  provides in the simplest manner in ROS, i.e., running a launch file that corresponds to the functionality. opencv_appsOpenCVindigoopencv_appsimageimage~use_camera_infobool~debug_viewbool~edge_typeint~canny_threshold1int~canny_threshold2int~apertureSizeint~apply_blur_prebool~postBlurSizeint~postBlurSigmaint~apply_blur_postbool~L2gradientbool~queue_sizeintimageimagelines~use_camera_infobool~debug_viewbool~hough_typeint~threshouldint~rhodouble~thetadouble~minLineLengthdouble~maxLineGrapdouble~queue_sizeintimageimagecircles~use_camera_infobool~debug_viewbool~canny_thresholdint~accumulator_thresholdint~gaussian_blur_sizeint~gaussian_sigma_xdouble~gaussian_sigma_ydouble~dpint~min_circle_radiusint~max_circle_radiusint~queue_sizeintimageimagecontours~use_camera_infobool~debug_viewbool~canny_low_thresholdint~queue_sizeintimageimagehulls~use_camera_infobool~debug_viewbool~thresholdint~queue_sizeintimageimagerectanglesellipses~use_camera_infobool~debug_viewbool~thresholdint~queue_sizeintimageimagemoment~use_camera_infobool~debug_viewbool~canny_low_thresholdint~queue_sizeintimageimagefacesface_image~queue_size~use_camera_infobool~debug_viewbool~face_cascade_namestring~eyes_cascade_namestring~queue_sizeintimagefaces~output~debug_image~approximate_syncbool~queue_sizeint~model_methodstring~use_saved_databool~save_train_databool~data_dirstring~face_model_widthint~face_model_heightint~face_paddingdouble~model_num_componentsint~model_thresholddouble~lbph_radiusint~lbph_neighborsint~lbph_grid_xint~lbph_grid_yint~queue_sizeintimageimagefound~use_camera_infobool~debug_viewbool~hit_thresholddouble~win_strideint~paddingint~scale0double~group_thresholdint~queue_sizeintimageimagecorners~use_camera_infobool~debug_viewbool~max_cornersint~queue_sizeintimageimageback_projecttrack_box~use_camera_infobool~debug_viewbool~histogramarray~vminint~vmaxint~sminint~queue_sizeintimageimageflows~use_camera_infobool~debug_viewbool~queue_sizeintimageimageflowsinitialize_pointsdelete_pointstoggle_night_mode~use_camera_infobool~debug_viewbool~quality_leveldouble~min_distanceint~block_sizeint~harris_kdouble~queue_sizeintimageimageshift~use_camera_infobool~debug_viewbool~queue_sizeintimageflowsimage~use_camera_infobool~debug_viewbool~scaleint~queue_sizeintimageimagecontoursareaupdate_bg_model~use_camera_infobool~debug_viewbool~queue_sizeintimagecontoursimage~use_camera_infobool~debug_viewbool~queue_sizeintimageimage~use_camera_infobool~debug_viewbool~r_limit_maxint~r_limit_minint~g_limit_maxint~g_limit_minint~b_limit_maxint~b_limit_minint~queue_sizeintimageimage~use_camera_infobool~debug_viewbool~h_limit_maxint~h_limit_minint~s_limit_maxint~s_limit_minint~l_limit_maxint~l_limit_minint~queue_sizeintimageimage~use_camera_infobool~debug_viewbool~h_limit_maxint~h_limit_minint~s_limit_maxint~s_limit_minint~v_limit_maxint~v_limit_minint~queue_sizeint"
W2197,https://wiki.ros.org/polled_camera,Wiki,polled_camera,"polled_camera contains a service and C++ helper classes for implementing a polled
     camera driver node and requesting images from it. The package is currently for
     internal use as the API is still under development.
 defines the ROS interface that client nodes use to request images from a polling camera driver node (e.g. ). The protocol is: 


See the  (unstable) for more information on writing polled camera drivers or clients. polled_camera<camera>/request_image<response_namespace>/image_raw<response_namespace>/camera_info<output>/image_rawoutput<output>/camera_infooutput<camera>/request_imagecamera# Poll ""my_camera"" at 5 Hz, publishing in namespace my_polled_output/.
$ poller 5 camera:=my_camera output:=my_polled_output"
W2198,https://wiki.ros.org/object_manipulation,Wiki,object_manipulation,"
    Functionality for performing object pickup and placing, while
    avoiding collisions with the environment. This stack is designed
    to be robot independent. It contains a complete interface for
    pickup and place tasks, as well as general implementation of most
    of the needed functionality.


  



  This stack provides the core-functionality for pick and place tasks, implemented in a robot-independent way. For details and documentation, see the  package page. Complete applications of the functionality contained here on PR2 robot can be found, along with demos and launch files as well as documentation and tutorials, on the  page. To launch the manipulation pipeline and execute pickup and place tasks using the PR2 robot, tutorials and launch files are provided on the  page. "
W2199,https://wiki.ros.org/openni_launch,Wiki,openni_launch,"Launch files to open an OpenNI device and load all nodelets to 
     convert raw depth/RGB/IR streams to depth images, disparity images, 
     and (registered) point clouds.openni_launchopenni_launch/camera_depth_optical_frame/camera/depth/points/camera/driverdepth_registration/camera/depth_registered/pointsRGB8depth_registered/image_rect_rawdepth_registered/*camera/depth/*camera/depth_registeredcamera/depth_registered/image_rawcamera/depth/image_rawcamerastring<camera>device_idstringrgb_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/rgb_B00367707227042Bdepth_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/depth_B00367707227042Bdepth_registrationboolload_driverboolrgb_frame_idstring/<camera>_rgb_optical_framedepth_frame_idstring/<camera>_depth_optical_framepublish_tfboolrgbstringrgbirstringirdepthstringdepthdepth_registeredstringdepth_registeredprojectorstringprojectordebugboolrespawnboolcamera/rgb/camera_infocamera/rgb/image_rawcamera/rgb/image_monocamera/rgb/image_colorcamera/rgb/image_rectcamera/rgb/image_rect_colorcamera/depth/camera_infocamera/depth/image_rawuint16camera/depth/imagefloatcamera/depth/image_rectfloatcamera/depth/disparitycamera/depth/pointsPointCloud<PointXYZ>camera/depth_registered/camera_infocamera/rgb/camera_infocamera/depth_registered/image_rawuint16camera/depth_registered/imagefloatcamera/depth_registered/image_rectfloatcamera/depth_registered/disparitycamera/depth_registered/pointsPointCloud<PointXYZRGB>camera/ir/camera_infocamera/ir/image_rawuint16camera/ir/image_rectcamera/projector/camera_infodepth/camera_infodepthprojector/<camera>_rgb_optical_frame/<camera>_depth_optical_frameimage_modeintegerdepth_modeintegerdepth_registrationbooldepth_skipintegerdepth_time_offsetdoubleimage_time_offsetdoubledepth_ir_offset_xdoubledepth_ir_offset_ydoublez_offset_mmintz_scalingdoubleopenni_launchopenni_launchlaunch/openni.launch/camera_depth_optical_frame/camera/depth/points/camera/driverdepth_registration/camera/depth_registered/pointsRGB8openni_launchopenni.launchcamerastring<camera>device_idstringrgb_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/rgb_B00367707227042Bdepth_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/depth_B00367707227042Bdepth_registrationboolload_driverboolrgb_frame_idstring/<camera>_rgb_optical_framedepth_frame_idstring/<camera>_depth_optical_framepublish_tfbooltf_prefixstringopenni.launchrgbstringrgbirstringirdepthstringdepthdepth_registeredstringdepth_registeredprojectorstringprojectordebugboolrespawnboolnum_worker_threadsintopenni_launchopenni.launchroslaunch openni_launch openni.launchrosrun rviz rvizrosrun image_view disparity_view image:=/camera/depth/disparityrosrun rqt_reconfigure rqt_reconfigurerosrun image_view disparity_view image:=/camera/depth_registered/disparityrosrun image_view image_view image:=/camera/rgb/image_colorrosrun image_view image_view image:=/camera/rgb/image_mono[ERROR] [1351028964.484342461]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/compressedDepth/set_parameters]
[ERROR] [1351028964.489915028]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/compressed/set_parameters]
[ERROR] [1351028964.495383139]: Tried to advertise a service that is already advertised in this node [/camera/depth_registered/image_rect_raw/theora/set_parameters]roslaunch openni_launch openni.launchrosrun rviz rvizrosrun image_view disparity_view image:=/camera/depth/disparityrosrun rqt_reconfigure rqt_reconfigurerosrun image_view disparity_view image:=/camera/depth_registered/disparityrosrun image_view image_view image:=/camera/rgb/image_colorrosrun image_view image_view image:=/camera/rgb/image_mono"
W2200,https://wiki.ros.org/raspigibbon_master_slave,Wiki,raspigibbon_master_slave,The raspigibbon_master_slave package
W2201,https://wiki.ros.org/openhrp3,Wiki,openhrp3,"This package does not only wrap  but actually provides the built artifact from the code from its . Being ROS-agnostic by itself, you can also use this via ROS together with the packages in  that bridge between two framework. (). The package version number is synchronized to that of mainstream, based on ."
W2202,https://wiki.ros.org/panda_moveit_config,Wiki,panda_moveit_config,An automatically generated package with all the configuration and launch files for using the panda with the MoveIt! Motion Planning FrameworkDocumentation is available at . 
W2203,https://wiki.ros.org/raspigibbon_utils,Wiki,raspigibbon_utils,The raspigibbon_utils package
W2204,https://wiki.ros.org/nj_costmap,Wiki,nj_costmap,"The nj_costmap package implements a navigation jockey for the
	  Large Maps framework (LaMa) based on a local costmap (costmap position is
	  relative to the sensor but orientation is absolute).



The  package implements a navigation jockey for the Large Maps Framework () based on a local costmap such as those provided by the  package (costmap position is relative to the sensor but orientation is absolute). nj_costmap~<name>/local_costmap~<name>/cmd_vel~<name>/crossing_marker~<name>/exits_marker~<name>/ place_profile~<name>/abs_crossing~<name>/odom_frameString~<name>/frontier_widthFloat~<name>/robot_radiusFloat~<name>/laser_frameString~<name>/navigating_jockey_server_nameString"
W2205,https://wiki.ros.org/mrp2_simulator,Wiki,mrp2_simulator,Simulation-related packages for MRP2
W2206,https://wiki.ros.org/o3m151_driver,Wiki,o3m151_driver,ROS device driver for Ifm O3M151 TOF camera.
W2207,https://wiki.ros.org/ompl,Wiki,ompl,OMPL is a free sampling-based motion planning library.. Please see  on how to use it directly. Please see  for more on motion planning. Please report issues / send contribution to .  sudo apt-get install ros-fuerte-ompl sudo apt-get install ros-electric-arm-navigation
W2208,https://wiki.ros.org/raspigibbon_gazebo,Wiki,raspigibbon_gazebo,The raspigibbon_gazebo package
W2209,https://wiki.ros.org/open_karto,Wiki,open_karto,Catkinized ROS packaging of the OpenKarto library
W2210,https://wiki.ros.org/mrp2_hardware_gazebo,Wiki,mrp2_hardware_gazebo,Gazebo plugin of MRP2 robot hardware used in simulation.
W2211,https://wiki.ros.org/r2_controllers_ros,Wiki,r2_controllers_ros,"

     r2_controllers_ros

  "
W2212,https://wiki.ros.org/numatac_can_driver,Wiki,numatac_can_driver,"The numatac_can_driver package

   

 The numatac_can_driver package provides a ROS interface to  tactile sensors over a CAN interface. See  for details. To bring up the  tactile sensors, plug in the USB connector.  Configure the CAN interface by running the following command in a command line prompt: sudo ip link set can0 type can bitrate 1000000sudo ifconfig can0 uproslaunch numatac_can_driver numatac_can_driver.launchhand_pressure~canbus_dev~number_of_sensors~tare"
W2213,https://wiki.ros.org/mrp2_gazebo,Wiki,mrp2_gazebo,Launch files and simulation files to run MRP2 in Gazebo.
W2214,https://wiki.ros.org/raspigibbon_apps,Wiki,raspigibbon_apps,The raspigibbon_apps package
W2215,https://wiki.ros.org/openrtm_aist,Wiki,openrtm_aist,"This package represents  that's built within ROS eco system. Although being ROS-agnostic by itself, you can use this via ROS together with the packages in  that bridge between two framework. ()Its development is happening at . The repository listed below is where the development of its ROS wrapper happening."
W2216,https://wiki.ros.org/nanotron_swarm,Wiki,nanotron_swarm,"Driver for Nanotron radio ranging sensors which uses the Swarm API firmware.
     This driver will publish range measurements between the host node and 
     other nodes available in the wireless sensor network.
 



Use GitHub to . []
  
 nanotron_swarmrangenanotron_swarmrange"
W2217,https://wiki.ros.org/rangeonly_msgs,Wiki,rangeonly_msgs,"The rangeonly_msgs package constains generic ROS messages for range-only sensors.

 This message is used to store range-only measurements between a pair of devices (i.e. distance measurements between two sensors). The message includes other kind of information like the type of range-only sensor technology (ultrsonic, radio-based, etc), the unique identifiers of the ranging sensors, etc. As an example, this message has been used with the  driver for a radio-based range-only sensor in this . 
Use GitHub to . []
 This package is part of  stack. The package contains generic ROS messages for range-only sensors. "
W2218,https://wiki.ros.org/raspigibbon_sim,Wiki,raspigibbon_sim,The raspigibbon_sim package
W2219,https://wiki.ros.org/nav_core2,Wiki,nav_core2,"Interfaces for Costmap, LocalPlanner and GlobalPlanner. Replaces nav_core. "
W2220,https://wiki.ros.org/nao_msgs,Wiki,nao_msgs,"

     Message and service declarations for the Nao humanoid

  "
W2221,https://wiki.ros.org/planning_models,Wiki,planning_models,"
    A set of robot models that can be instantiated from a parsed URDF file.
  

"
W2222,https://wiki.ros.org/orocos_kdl,Wiki,orocos_kdl,"This package contains a recent version of the Kinematics and Dynamics
    Library (KDL), distributed by the Orocos Project. "
W2223,https://wiki.ros.org/orrosplanning,Wiki,orrosplanning,"
    Contains robot ik solvers, planners, and commonly used functions that integrate with the ROS framework.
  
"
W2224,https://wiki.ros.org/nav_msgs,Wiki,nav_msgs,"nav_msgs defines the common messages used to interact with the
     stack."
W2225,https://wiki.ros.org/nav_grid_iterators,Wiki,nav_grid_iterators,Iterator implementations for moving around the cells of a nav_grid in a number of common patterns. 
W2226,https://wiki.ros.org/nj_oa_laser,Wiki,nj_oa_laser,"The nj_oa_laser package is a navigating jockey for the Large
	  Maps framework. Its role is to drive the robot forward while avoiding
	  obstacles. It uses a LaserScan.


The  package implements a navigating jockey for the Large Maps Framework () that drives the robot while avoiding obstacles. It is based on a laser scan (). It is a reactive, memory-less jockey. Moreover, the package provides the class  that computes an appropriate  from a  in order to go as forward as possible while avoiding obstacles. nj_oa_laserTwistHandler~<name>/base_scan~<name>/cmd_vel~<name>/robot_radiusFloat~<name>/min_distanceFloat~<name>/long_distanceFloat~<name>/turnrate_collideFloat~<name>/max_velFloat~<name>/vel_close_obstacleFloat~<name>/turnrate_factorFloatrad.m^-1.s^-1~<name>/laser_frameString~<name>/navigating_jockey_server_nameString"
W2227,https://wiki.ros.org/openni2_launch,Wiki,openni2_launch,"Launch files to start the openni2_camera drivers using rgbd_launch.

This package contains launch files for using OpenNI-compliant devices in ROS. It supports the Asus Xtion, Xtion Pro, and multiple version of the Primesense 1.08 and 1.09 cameras. It does NOT support any versions of the Kinect.  or  is the recommended package for using a Kinect with ROS. More is documented  roslaunch openni2_launch openni2.launch"
W2228,https://wiki.ros.org/nlj_dummy,Wiki,nlj_dummy,"The nlj_dummy package
The role of this jockey is to demonstrate some functionalities of the Large Maps Framework (). The node  starts two jockeys ( servers): a localizing jockey and a navigating jockey. The localizing jockey () generates 4 randoms integer values () and stores them into the map. The navigating jockey () prints on the console the edge it was asked to traversed and its associated descriptor, and waits a random time. nlj_dummylj_dummynj_dummyroslaunch nlj_dummy random_walk.launch"
W2229,https://wiki.ros.org/opencv3,Wiki,opencv3,"OpenCV 3.x









 will only pull in  as an extra dependency while  will also pull in ,  and  so it depends on whether you go for something small or something you need. 

Since Indigo, there is a package for OpenCV3. It contains the  and  repos from . Some modules might not get included because the dependencies are hard to package for all platforms (e.g. the optical character recognition module that needs tesseract). Since Kinetic, OpenCV3 is the default. Discussion happened on . Switching code to OpenCV3 can be done following the official guide at . The rosdep key is . Also, if you write OpenCV3 code, chances are high that it will also compile with OpenCV 2.4.9+. E.g., in color conversion, when replacing  by , your code will also compile in OpenCV2 as this API has been backported (and not documented ...).  Instead of depending on , you should depend on  or . Depending on one of those two keys transitively makes you depend on  on Jade and below, or  on Kinetic and above. Then, just download the opencv3-release repo at  and: 





#include ""opencv2/core/version.hpp""
#if CV_MAJOR_VERSION == 2
// do opencv 2 code
#elif CV_MAJOR_VERSION == 3
// do opencv 3 code
#endifif(OpenCV_VERSION VERSION_LESS ""3.0"")
# use 2.4 modules
else()
# use 3.x modules
endif()

















































git-bloom-release kinetic"
W2230,https://wiki.ros.org/nj_escape_crossing,Wiki,nj_escape_crossing,"The nj_escape_crossing package is a navigating jockey used to move a robot from away from a crossing




The  package implements a navigating jockey for the Large Maps Framework () which role is to drive the robot away from the crossing center, where the robot is awaited to be when the jockey is started. nj_escape_crossing~<name>/odometry~<name>/direction~<name>/cmd_vel~<name>/kp_vFloat~<name>/kp_wFloat~<name>/min_linear_velocityFloat~<name>/min_angular_velocityFloat~<name>/escape_distanceFloat~<name>/crossing_interface_nameString~<name>/exit_angle_interface_nameString~<name>/exit_angle_topic_nameString"
W2231,https://wiki.ros.org/naoqi_libqicore,Wiki,naoqi_libqicore,Aldebaran's libqicore: a layer on top of libqi
W2232,https://wiki.ros.org/prosilica_driver,Wiki,prosilica_driver,"
    This stack contains the ROS driver and SDK for AVT/Prosilica cameras.
   


 ROS driver and SDK for AVT/Prosilica GigE cameras. See  for usage and tutorials. Prior to Fuerte, these packages resided in . This stack works with Allied Vision Tech / Prosilica . "
W2233,https://wiki.ros.org/nj_laser,Wiki,nj_laser,"The nj_laser package



The  package implements a navigation jockey for the Large Maps Framework () based on a . nj_laser~<name>/local_costmap~<name>/cmd_vel~<name>/crossing_marker~<name>/exits_marker~<name>place_profile~<name>/crossing~<name>/frontier_widthFloat~<name>/robot_radiusFloat~<name>/max_frontier_distanceFloat~<name>/navigating_jockey_server_nameString"
W2234,https://wiki.ros.org/openni2_camera,Wiki,openni2_camera,"Drivers for the Asus Xtion and Primesense Devices. For using a kinect
  with ROS, try the 

This package contains launch files for using OpenNI-compliant devices in ROS. It supports the Asus Xtion, Xtion Pro, and multiple version of the Primesense 1.08 and 1.09 cameras. It does NOT support any versions of the Kinect.  or  is the recommended driver for using a Kinect with ROS. It is recommended to use this driver through the launch files provided in  "
W2235,https://wiki.ros.org/openni_tracker,Wiki,openni_tracker,"

openni_tracker broadcasts the OpenNI skeleton frames using tf.

    is now a unary stack. Previously it was a package in .  
 - Independent node that does not require other nodes to run (however, make sure your  is powered. For example, on ,  needs to be run successfully). 
Once running, stand in front of the Kinect and surrender (i.e. hit the . You should see some variation on the following messages.  The user's pose will be published as a set of transforms () with the following frame names.  openni_trackerrosrun openni_tracker openni_trackerKinectTurtlebotkinect.launch/tf/head/neck/torso/left_shoulder/left_elbow/left_hand/right_shoulder/right_elbow/right_hand/left_hip/left_knee/left_foot/right_hip/right_knee/right_footcamera_frame_idstring/tfNew User 1
Pose Psi detected for user 1
Calibration started for user 1
Calibration complete, start tracking user 1
Lost User 1"
W2236,https://wiki.ros.org/python_orocos_kdl,Wiki,python_orocos_kdl,"This package contains the python bindings PyKDL for the Kinematics and Dynamics
    Library (KDL), distributed by the Orocos Project. "
W2237,https://wiki.ros.org/pyros,Wiki,pyros,"Provides Python to ROS multiprocess API, useful for using ROS from different multiprocess environment (think webserver, celery, etc.) while keeping both isolated."
W2238,https://wiki.ros.org/libvlfeat,Wiki,libvlfeat,The libvlfeat package
W2239,https://wiki.ros.org/opencv2,Wiki,opencv2,"


For documentation on OpenCV, please see the . For additional libraries to help you use OpenCV with ROS, please see the  package and  stack. If your issue is related to the OpenCV packaged in ROS (it is too old, you would like to see a backport in there ...), please file a bug using the link at . opencv2opencv2<depend package=""opencv2"" />find_package()CMakeLists.txtfind_package()manifest.xmlmanifest.xmlstack.xmlCMakeLists.txtfind_package()manifest.xmlmanifest.xmlstack.xml.debOpenCV2libopencv*OpenCVlibopencv*find_package(OpenCV REQUIRED)
#define some target ...
target_link_libraries(my_target ${OpenCV_LIBRARIES})  <rosdep name=""opencv2""/>  <depend package=""cv_bridge"" />

  <rosdep name=""opencv2.3""/>  <depend stack=""vision_opencv"" />rosdep install <your-package>sudo apt-get update
sudo apt-get install libopencv2.3-devfind_package(OpenCV REQUIRED)
#define some target ...
target_link_libraries(my_target ${OpenCV_LIBS})  <rosdep name=""opencv2""/>  <depend package=""cv_bridge"" />

  <rosdep name=""opencv2""/>  <depend stack=""vision_opencv"" />rosdep install <your-package>sudo apt-get update
sudo apt-get install ros-fuerte-opencv2$ rosversion opencv2"
W2240,https://wiki.ros.org/ompl_visual_tools,Wiki,ompl_visual_tools,"Rviz 3-D visualizer for planning algorithms implemented with the Open Motion Planning Library (OMPL)
See  for full documentation. "
W2241,https://wiki.ros.org/lama_test,Wiki,lama_test,"The lama_test package
The  package provides a few launch files to test the functionalities of the Large Maps Framework (). To test the high-level node : lama_testdfs_explorer/explorer.pyroslaunch dfs_explorer explorer.py __costmap:=false
"
W2242,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5054/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2243,https://wiki.ros.org/lj_laser_heading,Wiki,lj_laser_heading,"Localizing jockey from LaserScan and absolute heading.
    Implements a localizing jockey from a LaserScan and absolute heading.
    The associated descriptors are sensor_msgs/LaserScan[] and
    lama_msgs/Crossing.




The  package implements a localizing jockey that computes place dissimilarities based on a  and absolute heading. The behavior and properties are similar to those of the  jockey. The heading is given either as  or . The role of this jockey is to get the dissimilarity of the  descriptor of all vertices with the current place profile (represented by a ). The action is done when the dissimilarities are computed. Implemented actions: lj_laser_headingGET_VERTEX_DESCRIPTORGET_SIMILARITY~<name>/base_scan~<name>/pose~<name>/odom~<name>/dissimilarity_server~<name>/laser_interface_nameString~<name>/crossing_interface_nameString~<name>/dissimilarity_server_nameString"
W2244,https://wiki.ros.org/openni_camera,Wiki,openni_camera,"A ROS driver for OpenNI depth (+ RGB) cameras. These include: 
       Microsoft Kinect,
       PrimeSense PSDK,
       ASUS Xtion Pro and Pro Live

    The driver publishes raw depth, RGB, and IR image streams.Contents 
This package provides a ROS interface to depth sensors using the . These currently include: PrimeSense PSDK 5.0   is the best place to begin using your Kinect or similar device. It provides processed outputs such as point clouds. As of Electric,  has been trimmed down to just the driver node(let) publishing the raw depth, IR and (if applicable) RGB images. As of Fuerte, it has been trimmed of some heavyweight dependencies (OpenCV, PCL) and made a unary stack to ease installing and running  on resource-constrained systems. (If you are using the old, monolithic driver API dating to Diamondback, see  for migration instructions and API reference.) 
It is highly recommended to use this package through , which provides additional RGB-D processing capabilities for the data produced by  

To install only openni_camera: It's also recommended to install : To use the Microsoft Kinect you also need a driver: PPA:  Source:  


Please report all bugs at  
 
Note: This is the  for your usage of openni_camera / openni_launch for Kinect in ROS. You have to firstly install the Driver for Kinect on Ubuntu and make sure your kinect can work properly on ubuntu. To get started, please Refer  and you may meet some incompatible contents, do not worry, the thought and path is correct. The very important doc you should read carefully is that on  and that on . openni_camera/openni_rgb_optical_frame/camera/rgb/points/openni_node1openni_camerargb/camera_inforgb/image_raw~depth_registrationdepth/camera_infodepth/image_rawuint16~depth_registrationdepth_registered/camera_inforgb/camera_infodepth_registered/image_rawdepth_registered/image_rawuint16ir/camera_infoir/image_rawuint16projector/camera_infodepth/camera_infodepthprojectorrgb/set_camera_infoir/set_camera_info~device_idstring~rgb_frame_idstring/openni_rgb_optical_frame~depth_frame_idstring/openni_depth_optical_frame~rgb_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/rgb_B00367707227042B~depth_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/depth_B00367707227042B~time_outdouble~time_out~image_modeint~depth_modeint~depth_registrationbool~data_skipint~depth_time_offsetdouble~image_time_offsetdouble~depth_ir_offset_xdouble~depth_ir_offset_ydouble~z_offset_mmintopenni_nodeopenni_cameraopenni_cameraopenni_nodergb/camera_inforgb/image_raw~depth_registrationdepth/camera_infodepth/image_rawuint16~depth_registrationdepth_registered/camera_inforgb/camera_infodepth_registered/image_rawdepth_registered/image_rawuint16ir/camera_infoir/image_rawuint16projector/camera_infodepth/camera_infodepthprojectorrgb/set_camera_infoir/set_camera_info~device_idstring~rgb_frame_idstring/openni_rgb_optical_frame~depth_frame_idstring/openni_depth_optical_frame~rgb_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/rgb_B00367707227042B~depth_camera_info_urlstringfile://${ROS_HOME}/camera_info/${NAME}.yaml$HOME/.ros/camera_info/depth_B00367707227042B~time_outdouble~time_out~image_modeint~depth_modeint~depth_registrationbool~data_skipint~depth_time_offsetdouble~image_time_offsetdouble~depth_ir_offset_xdouble~depth_ir_offset_ydouble~z_offset_mmintopenni_noderosmake openni_cameraroslaunch openni_camera openni_node.launchrosrun rviz rvizrosrun image_view image_view image:=/camera/rgb/image_colorrosrun image_view image_view image:=/camera/rgb/image_monorosrun dynamic_reconfigure reconfigure_gui/openni_camera
|
|> /openni_rgb_frame
|  |
|  |> /openni_rgb_optical_frame  (Z forward)
|
|> /openni_depth_frame
   |
   |> /openni_depth_optical_frame (Z forward)sudo apt-get install ros-electric-openni-camerasudo apt-get install ros-electric-openni-launchsudo apt-get install ros-<rosdistro>-openni-camerasudo apt-get install ros-<rosdistro>-openni-launch"
W2245,https://wiki.ros.org/kinect_2d_scanner,Wiki,kinect_2d_scanner,"A ROS node to 
read range data from a Kinect sensor and convert it (in a flexible way) into 2D equivalent range scans. This allows low-cost implementation of classic SLAM and localization techniques originally designed to work with more expensive laser range finders.
 are considered and the minimum distance is kept in each direction. The horizontal FOV of the frustum is automatically computed from the intrinsic parameters of the range camera, but the vertical FOV must be provided by the user, and  which may be useful depending on the zone of interest where to look for obstacles. See  for an illustration of the frustum geometry and 3D obstacle points. 
The node  makes easy to connect to a Kinect sensor and publish equivalent 2D ""fake laser"" scans. Internally, the node uses  which in turn uses  to directly open the sensor. Since only 2D scan data is published here, you should employ this node only if you won't need the 3D points.  All spatial transformations are riguorously taken into account in this class, using the depth camera intrinsic calibration parameters.  should be provided in the format expected by MRPT (explain me!), but default values will be used otherwise. Read  for more details. This node implements the  interface. mrpt-hwdriverslibfreenectroscd kinect_2d_scanner
roslaunch kinect_2d_scanner_test.launch"
W2246,https://wiki.ros.org/innok_heros_control,Wiki,innok_heros_control,package to control the Innok Heros with several devices (e. g. joystick and keyboard)
W2247,https://wiki.ros.org/pykdl_utils,Wiki,pykdl_utils,"

    pykdl_utils contains kdl_parser.py, for parsing URDF objects
     from the robot_model_py stack into PyKDL trees and chains, 
     and kdl_kinematics.py, for wrapping KDL kinematics calls, making
     kinematics requests in Python far simpler.  jointspace_kdl_kin.py
     also contains a KDLKinematics superclass which subscribes to /joint_states,
     automatically filling the FK and jacobian requests with the current joint
     angles.

  



For running all of the unit tests, you can either pass a URDF xml file to use or leave it blank and have the URDF pulled from the parameter  on the parameter server. 






















rosrun pykdl_utils kdl_parser.py [robot.xml]
rosrun pykdl_utils kdl_kinematics.py [robot.xml]
rosrun pykdl_utils joint_kinematics.py [robot.xml]"
W2248,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14694/6  "
W2249,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20304/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W2250,https://wiki.ros.org/map_ray_caster,Wiki,map_ray_caster,"The map_ray_caster package provides a class for cached ray casting
  on maps. The origin of all rays is fixed relative to the map, it is the map center. provides a cached ray casting on a map, such as those provided by  of the Large Maps Framework (). 
 provides a cached ray casting on a map, such as those provided by . The origin of all rays is fixed relative to the map, it is the map center. It takes as input a costmap () and returns a laser scan (). The ray casting will be from  to . Moreover, other value of the input scan are used so that the scan message must be initialized with non-default values. 
To use the  class to compute a fake   from an occupancy grid in C++: map_ray_casterlocal_mapmap_ray_casterlocal_mapscan.angle_minscan.angle_maxmap_ray_caster::MapRayCaster














"
W2251,https://wiki.ros.org/jaguar_msgs,Wiki,jaguar_msgs,Messages for DrRobot's Jaguar 4X4
W2252,https://wiki.ros.org/jaguar_navigation,Wiki,jaguar_navigation,Navigation package for DrRobot's Jaguar 4X4
W2253,https://wiki.ros.org/jaguar_description,Wiki,jaguar_description,A robot description package for Dr Robot's Jaguar 4x4
W2254,https://wiki.ros.org/innok_heros_gazebo,Wiki,innok_heros_gazebo,"Innok Heros launch files for Gazebo6
The robot model was successfully tested with Gazebo6 thus . To install Gazebo6 see . 
"
W2255,https://wiki.ros.org/aras_visual_servo_controller,Wiki,aras_visual_servo_controller,"The aras_visual_servo package


"
W2256,https://wiki.ros.org/ackermann_controller,Wiki,ackermann_controller,The ackermann_controller package
W2257,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14695/6  "
W2258,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20305/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W2259,https://wiki.ros.org/lpms_imu,Wiki,lpms_imu,"ROS driver for lpms_imu sensors.







"
W2260,https://wiki.ros.org/innok_heros_lights,Wiki,innok_heros_lights,ROS driver for LED lights installed on Innok Heros
W2261,https://wiki.ros.org/look_at_pose,Wiki,look_at_pose,"Rotate camera to look at a given pose.
 This camera has a rough initial alignment with the object of interest (the pink cylinder) and it is nearly upside-down. The pose returned from a call to look_at_pose is well-aligned and the camera is upright.   

 

or, clone and build from . In RViz, turn on  and  (topic: visualization_marker) to see the original camera frame, new camera frame, and point of interest. * :  The current pose of the camera. This should  be point (0,0,0) and quaternion (0,0,0,1) in the camera's own frame. * : Where should the camera look? The orientation actually isn't used. * : A vector that defines ""UP."" If Z of the camera frame is up, then it would be (0,0,1). The service response is another  in the initial camera frame: *  It's currently assumed that X is the ""lens vector"" of the camera and Z of the camera frame should point up. If your situation requires something else, please create an issue on the . sudo apt install ros-kinetic-look-at-poserosrun rviz rvizrosrun look_at_pose look_at_pose_serverrosrun look_at_pose test_client"
W2262,https://wiki.ros.org/lj_costmap,Wiki,lj_costmap,"Implements a localizing jockey for the
	  Large Maps framework (LaMa) based on a local costmap (costmap position is
	  relative to the sensor but orientation is absolute).

	  Implement a localizing jockey from a LaserScan. The associated
	  descriptors are LaserScan[] and Crossing.




The  package is a localizing jockey for the Large Maps Framework () that computes place dissimilarities based on a local cost map, such as those obtained from the  package. The role of this jockey is to get the dissimilarity of the  descriptors of all vertices with the current place profile. The action is done when the dissimilarities are computed. Implemented actions: lj_costmapGET_VERTEX_DESCRIPTORGET_SIMILARITY~<name>/local_costmap~<name>/dissimilarity_server~<name>/costmap_interface_nameString~<name>/crossing_interface_nameString~<name>/dissimilarity_server_nameString"
W2263,https://wiki.ros.org/anj_featurenav,Wiki,anj_featurenav,"The anj_featurenav package provides a learning jockey and a
    navigating jockey for the Large Maps framework (LaMa). It learns a
    path by saving image features and is able to follow the same path.
    It is based on algorithms provided by OpenCV (free ones).
 implements a feature-based learning and navigating jockey based on free OpenCV feature descriptor and matcher. The package defines the feature extractor and the descriptor matcher functions required by the  package to obtain a working couple learning/navigating jockeys. 


The SimpleBlog algorithm takes no parameter, cf. . The FlannBased algorithm takes no parameter, cf. . anj_featurenavfeaturenav_base~<name>/feature_detector/typeString~<name>/descriptor_extractor/typeString~<name>/descriptor_matcher/typeString~<name>/feature_detector/thresholdInt~<name>/feature_detector/nonmax_suppressionBool~<name>/feature_detector/max_sizeInt~<name>/feature_detector/response_thresholdInt~<name>/feature_detector/line_threshold_projectedInt~<name>/feature_detector/line_threshold_binarizedInt~<name>/feature_detector/suppress_nonmax_sizeInt~<name>/feature_detector/scale_factorFloat~<name>/feature_detector/n_featuresInt~<name>/feature_detector/n_levelsInt~<name>/feature_detector/edge_thresholdInt~<name>/feature_detector/first_levelInt~<name>/feature_detector/wta_kInt~<name>/feature_detector/score_typeInt~<name>/feature_detector/patch_sizeInt~<name>/feature_detector/deltaInt~<name>/feature_detector/min_areaInt~<name>/feature_detector/max_areaInt~<name>/feature_detector/max_variationFloat~<name>/feature_detector/min_diversityFloat~<name>/feature_detector/max_evolutionInt~<name>/feature_detector/area_thresholdFloat~<name>/feature_detector/min_marginFloat~<name>/feature_detector/edge_blur_sizeInt~<name>/feature_detector/max_cornersInt~<name>/feature_detector/block_sizeInt~<name>/feature_detector/quality_levelFloat~<name>/feature_detector/min_distanceFloat~<name>/feature_detector/kFloat~<name>/feature_detector/use_harris_detectorBool~<name>/feature_detector/feature_scale_levelsInt~<name>/feature_detector/init_xy_stepInt~<name>/feature_detector/init_img_boundInt~<name>/feature_detector/init_feature_scaleFloat~<name>/feature_detector/feature_scale_mulFloat~<name>/feature_detector/vary_xy_step_with_scaleBool~<name>/feature_detector/vary_img_bound_with_scaleBool~<name>/descriptor_extractor/scale_factorFloat~<name>/descriptor_extractor/n_featuresInt~<name>/descriptor_extractor/n_levelsInt~<name>/descriptor_extractor/edge_thresholdInt~<name>/descriptor_extractor/first_levelInt~<name>/descriptor_extractor/wta_kInt~<name>/descriptor_extractor/score_typeInt~<name>/descriptor_extractor/patch_sizeInt~<name>/descriptor_extractor/bytesInt~<name>/descriptor_matcher/normString~<name>/descriptor_matcher/cross_checkBool"
W2264,https://wiki.ros.org/dfs_explorer,Wiki,dfs_explorer,"An explorer with depth-first search for finite worlds for the Large Maps Framework (LaMa).

The  package implements the node  which is an explorer with depth-first-search-like algorithm for finite worlds for the Large Maps Framework (). It proceeds as follows: A test launch file can be found in the  package: dfs_explorerexplorer.py
"
W2265,https://wiki.ros.org/lkh,Wiki,lkh,"ROS packages for solving the TSP and GTSP problems using LKH heuristic

Use GitHub to . []
  "
W2266,https://wiki.ros.org/log_server,Wiki,log_server,The log_server package
W2267,https://wiki.ros.org/goto_crossing,Wiki,goto_crossing,"The goto_crossing package provides a goToGoal behavior
	  to a crossing center if the crossing has at least three
	  frontiers and some kind of move forward behavior if it
	  has two or less frontiers.





The goto_crossing provides a Go-To-Goal behavior to reach the center of a crossing ( message) for the Large Maps Framework (). The goto_crossing provides a Go-To-Goal behavior to reach the center of a crossing ( message). Launch the node with . To use the  as class instance, one uses  to compute the twist necessary to reach the crossing center: rosrun goto_crossing goto_crossinggoto_crossing::CrossingGoergoto_crossing::CrossingGoer::goto_crossing~<name>/crossingcenter~<name>/cmd_vel~<name>/goal_reachedreach_distance~<name>/reset_integrals~<name>/kp_vfloat~<name>/kp_wfloat~<name>/ki_vfloat~<name>/ki_wfloat~<name>/min_linear_velocityfloat~<name>/max_linear_velocityfloat~<name>/min_angular_velocityfloat~<name>/max_angular_velocityfloat~<name>/reach_distancefloat~<name>/dtheta_force_leffloat~<name>/threshold_w_onlyfloat~<name>/max_sum_vfloat~<name>/max_sum_wfloat











"
W2268,https://wiki.ros.org/cassandra_ros,Wiki,cassandra_ros,"

     Library and tools for dynamically storing ROS messages in Apache Cassandra.

  

  partitioner is required to retrieve requested data ordered, otherwise it will appear. For more information, have look on the documentation on  










5514/1 Then change the Cassandra partitioner to """", which can be set in  partitioner: org.apache.cassandra.dht. The option -f hinders Cassandra to start a deamon in backgroud, for more information and help visit :  Check the following link:  How does it work? If you take a look into cassandra_ros/lib ... you will see a couple of files in the form of _'format'.py, which are all descendants of _.py. And each of them overwrites the methods: As you could see so far, you only work with the single class of . In fact, this class inherits those methods, required for encoding and decoding of messages, and only those of the required parent class. If you are seeking for more information, have a look at the follwing link:   If you want to analyze your data by using CQL, the , you will have to generate at first secondary indexes. Because this might be expensive and not required for every part of a message, this has to be done manually, as follows: For more information on CQL, check the following website:  $ bin/cassandra -f$ roslaunch cassandra_ros recordCamera.launch$ roslaunch cassandra_ros replayCamera.launch$ roslaunch cassandra_ros deleteCamera.launch
























































































































































"
W2269,https://wiki.ros.org/innok_heros_description,Wiki,innok_heros_description,"Innok Heros URDF description and RVIZ launch file
"
W2270,https://wiki.ros.org/joystick_sdl,Wiki,joystick_sdl,"A cross-platform joystick node, backed by SDL2."
W2271,https://wiki.ros.org/lj_laser,Wiki,lj_laser,"Localizing jockey from LaserScan

	  Implement a localizing jockey from a LaserScan. The associated descriptor
	  are LaserScan[] and Crossing.




The  package is a localizing jockey for the Large Maps Framework () that computes place dissimilarities based on a 360-degree . lj_laserGET_VERTEX_DESCRIPTORGET_SIMILARITY~<name>/base_scan~<name>/dissimilarity_server~<name>/laser_interface_nameString~<name>/crossing_interface_nameString~<name>/dissimilarity_server_nameString"
W2272,https://wiki.ros.org/lkh_solver,Wiki,lkh_solver,"ROS package for solving the Traveling Salesman Problem using the
    Lin-Kernighan heuristic."
W2273,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14696/6  "
W2274,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20307/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W2275,https://wiki.ros.org/aras_visual_servo_camera,Wiki,aras_visual_servo_camera,The aras_visual_servo_camera package   
W2276,https://wiki.ros.org/featurenav_base,Wiki,featurenav_base,"The featurenav_base package provides base functionality
    for learning and navigating jockeys based on feature detection for
    the Large Maps Framework (LaMa).
 provides base class for feature-based navigation for the Large Maps Framework (). Feature-based navigation implement the base functionalities of two jockeys. The first one, the learning jockey learns a path while the robot is driving externally. The learned path is a series of image descriptors with extra information. The second one, the navigating jockey can then drive the robot and follow this path. featurenav_base"
W2277,https://wiki.ros.org/lama_interfaces,Wiki,lama_interfaces,"The lama_interfaces package provides the interfaces between ROS nodes
	  (such as jockeys from lama_jockeys) and the map. provides the interfaces to the database as ROS services for the Large Maps Framework (). 
 provides the interfaces to the database as ROS services. 



The data storage is realized through a database. All databases supported by Python sqlalchemy can be used. The default database is an SQLite database which will be save as . The environment is represented as a directed graph, where vertices are points of interest such as crossings. Descriptors can be associated to vertices and edges, they give some information about the environment, so that jockeys can localize or drive the robot. Any ROS message can be saved as descriptor after a trivial implementation of two services (srv files), one to write the descriptor into the database and one to retrieve it. Other variable types can use the  message type. Descriptor storage occurs either in binary or clear-text mode. The first node that should be used when working with the LaMa Framework is : This node will run several services: , , , and , which are described in further sections. This service of type  is used for all actions over vertices and edges in the map. This service of type  is used to generate two services for each descriptor type, one to write the descriptor into the database and one to retrieve it. Descriptor storage occurs either in binary or clear-text mode (specified through the  service attribute. The name of these two services will be the name of the interface ( attribute) to which """" or """" are added. For example, to create a clear-text interface for  in C++: To add a database interface in Python, one can either use the  service or call the equivalent Python function. For example, for a """" descriptor with binary storage: The services  and  provide direct access to the graph vertices or edges. These functionalities are provided by the , which should be preferred. lama_interfaceslama_interfaces~/.ros/lama.sqlitemap_node/lama_map_agent/interface_factory/lama_object_getter/lama_object_setterinterface_typeinterface_name_getter_setterfloat64/interface_factorysensor_msgs/LaserScan[]/lama_object_getter/lama_object_setter/lama_map_agentrosrun lama_interfaces map_node



























"
W2278,https://wiki.ros.org/lama_msgs,Wiki,lama_msgs,"lama_msgs provides messages for the lama framework such as
	  Frontier, Crossing. contains messages that represent places for the Large Maps Framework (). 
 contains messages that represent places. These messages are used as descriptors for vertices. Newly proposed, mistyped, or obsolete package. Could not find package ""lama_msgs"" in rosdoc: /home/rosbot/docs/api/lama_msgs/manifest.yaml lama_msgslama_msgs"
W2279,https://wiki.ros.org/ardrone2islab,Wiki,ardrone2islab,"The ardrone2islab package




"
W2280,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5055/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2281,https://wiki.ros.org/local_map,Wiki,local_map,"The local_map package
	  The local_map package takes as input a LaserScan message and outputs
	  a local map as OccupancyGrid. The local map orientation is the same
	  as the one of the global frame. provides a simple local cost map for several jockeys for the Large Maps Framework (). The map is centered on the frame of the laser range finder on which it is based but its orientation is fixed. 
 


The image shows the map in player on the left and the local map obtained from the LaserScan (red dots) on the right. The robot's orientation is approximately 45° but the map's orientation is fixed. local_map~<name>/footprint~<name>/local_map~<name>/map_widthfloat~<name>/map_heightfloat~<name>/map_resolutiondouble"
W2282,https://wiki.ros.org/crossing_detector,Wiki,crossing_detector,"The crossing_detector package recognize frontiers from a LaserScan
  
Newly proposed, mistyped, or obsolete package. Could not find package ""crossing_detector"" in rosdoc: /home/rosbot/docs/api/crossing_detector/manifest.yaml The  package implements a method to recognize a crossing, i.e. a place from where the robot can take clearly distinctive paths. It is part of the Large Maps Framework (). The computation is based on a costmap such as those provided by the  package, a  message, or a  message. It is meant to be used in the form of a class instance but two nodes are provided that compute a  from a  or a , respectively, as a service. Packages  and  use the functionalities provided by the  package and can be used as example. crossing_detectorcrossing_detector"
W2283,https://wiki.ros.org/kobuki_led_controller,Wiki,kobuki_led_controller,"Convenient modules to control kobuki leds

Python library to control  LEDs. 




















"
W2284,https://wiki.ros.org/aras_visual_servo_gazebo,Wiki,aras_visual_servo_gazebo,"The aras_visual_servo_gazebo package


"
W2285,https://wiki.ros.org/lama_common,Wiki,lama_common,"Utilities for the LaMa package provides functionalities to convert messages of the  package to other ROS messages and to visualize these messages in rviz. It belongs to the Large Maps Framework (). 
 provides functionalities to convert messages of the  package to other ROS messages and to visualize these messages in . lama_commonlama_common"
W2286,https://wiki.ros.org/lost_comms_recovery,Wiki,lost_comms_recovery,"If your robot loses connection to the base station it will stop motors or navigate home.




: Instead of relying on this this feature, you're better off with motor control software that sets zero velocity after a certain amount of time not receiving any new commands. 




If move_base is not running when communication failure occurs then motors and joysticks are set to zero by publishing a zero  message and a zero  message. geometry_msgs/Twistsensor_msgs/Joymove_baserecovery_posegoal_frame_idcmd_velTwistjoyJoy~goal_frame_idstringmove_base~ping_fail_countint~ips_to_monitorstring$ sudo apt-get install ros-kinetic-lost-comms-recovery$ roslaunch lost_comms_recovery lost_comms_recovery.launch ips_to_monitor:=192.168.1.2$ roslaunch lost_comms_recovery lost_comms_recovery.launch ips_to_monitor:=192.168.190.136

[INFO] Monitoring base station on IP(s): 192.168.190.136.
[INFO] Connected to base station.
[INFO] Connected to base station.
...
[ERROR] No connection to base station.
[INFO] Executing move_base goal to position (x,y) 0.0, 0.0.
[INFO] Initial goal status: PENDING
[INFO] This goal has been accepted by the simple action server
[INFO] Final goal status: SUCCEEDED
[INFO] Goal reached."
W2287,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5056/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2288,https://wiki.ros.org/glkh_solver,Wiki,glkh_solver,"ROS package for solving the Generalized Traveling Salesman Problem using
    the Lin–Kernighan heuristic."
W2289,https://wiki.ros.org/jaco_gazebo,Wiki,jaco_gazebo,The jaco_gazebo package
W2290,https://wiki.ros.org/homer_gui,Wiki,homer_gui,commander interface 
W2291,https://wiki.ros.org/image_publisher,Wiki,image_publisher,"
      Contains a node publish an image stream from single image file
      or avi motion file.
    
 provides a node/nodelets for publishing image as a ROS image topic. 



image_publisherimage_rawcamera_infofilenamestringflip_horizontalboolflip_verticalboolframe_idstringpublish_ratedoublecamera_info_uristringimage_rawcamera_infoSame as image_publisher noderosrun image_publisher image_publisher /opt/ros/indigo/share/rviz/images/splash.png<launch>                                                                        
  <node pkg=""image_publisher"" type=""image_publisher"" name=""image_publisher""
        args=""$(find rviz)/images/splash.png"" >
    <param name=""flip_horizontal"" value=""false"" />
    <param name=""flip_vertical"" value=""false"" />
    <param name=""frame_id"" value=""my_camera"" />
    <param name=""publish_rate"" value=""1"" />
    <param name=""camera_info_url"" value=""file:///$(env HOME)/.ros/camera_info/camera.yaml"" />   <!-- relative to ~/.ros/ -->
  </node>
</launch><launch>                                                                        
  <node pkg=""nodelet"" type=""nodelet"" name=""manager"" args=""manager""/>

  <node pkg=""nodelet"" type=""nodelet"" name=""image_publisher""
        args=""load image_publisher/image_publisher manager"">
    <param name=""filename"" value=""$(find rviz)/images/splash.png"" />
    <param name=""flip_horizontal"" value=""false"" />
    <param name=""flip_vertical"" value=""false"" />
  </node>
  <param name=""/manager/frame_id"" value=""my_camera"" />
  <param name=""/manager/publish_rate"" value=""1"" />
  <param name=""camera_info_url"" value=""file:///$(env HOME)/.ros/camera_info/camera.yaml"" />  <!-- relative to ~/.ros/ -->
</launch>"
W2292,https://wiki.ros.org/imu_complementary_filter,Wiki,imu_complementary_filter,"Filter which fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into a quaternion to represent the orientation of the device wrt the global frame. Based on the algorithm by Roberto G. Valenti etal. described in the paper ""Keeping a Good Attitude: A Quaternion-Based Orientation Filter for IMUs and MARGs"" available at http://www.mdpi.com/1424-8220/15/8/19302 .

  




Use GitHub to . []
 imu/data_rawimu/magimu/dataimu/rpy/filteredimu_data~publish_debug_topicsimu/steady_state~publish_debug_topics~gain_accdouble~gain_magdouble~bias_alphadouble~do_bias_estimationbooltrue~do_adaptive_gainbooltrue~use_magboolfalse~fixed_framestringodompublish_tf~publish_tfboolfalsefixed_frame~reverse_tfboolfalsetrueimu_framefixed frame~constant_dtdouble~publish_debug_topicsboolfalsetruefixed_frameimu_framefixed_frameheader.frame_id"
W2293,https://wiki.ros.org/image_transport_plugins,Wiki,image_transport_plugins,"A set of plugins for publishing and subscribing to sensor_msgs/Image topics
    in representations other than raw pixel data. For example, for viewing a
    stream of images off-robot, a video codec will give much lower bandwidth
    and latency. For low frame rate tranport of high-definition images, you
    might prefer sending them as JPEG or PNG-compressed form.
 contains plugins to  for sending  topics in compressed representations. Its contents include: 

 These transports will only be available if the plugins are built on your system! On Ubuntu, they are included in the  deb for each distribution. If building from source, you must explicitly build the  stack. image_transport_pluginsros-<distro>-image-transport-pluginsimage_transport_plugins"
W2294,https://wiki.ros.org/image_cb_detector,Wiki,image_cb_detector,"Provide a node that extracts checkerboard corners from ROS images.
    This package is still experimental and unstable.
    Expect its APIs to change.
"
W2295,https://wiki.ros.org/laser_cb_detector,Wiki,laser_cb_detector,"Extracts checkerboard corners from a dense laser snapshot.
     This package is experimental and unstable. Expect its APIs to change.
"
W2296,https://wiki.ros.org/image_transport,Wiki,image_transport,"image_transport should always be used to subscribe to and publish images. It provides transparent
     support for transporting images in low-bandwidth compressed formats. Examples (provided by separate
     plugin packages) include JPEG/PNG compression and Theora streaming video.

 should always be used to publish and subscribe to images. At this basic level of usage, it is very similar to using ROS Publishers and Subscribers. Using  instead of the ROS primitives, however, gives you great flexibility in how images are communicated between nodes. 
 publishers advertise individual ROS  for each available transport - unlike ROS Publishers, which advertise a single topic. The topic names follow a standard naming convention, outlined below. Note, however, that all code interfaces take only a ""base topic"" name (to which the transport type is automatically appended); typically you should not directly reference the transport-specific topic used by a particular plugin. 
 does not yet support Python, though it is on the . If you need to interface a Python node with some compressed image transport, try interposing a  node. 


 publishers are used much like ROS Publishers, but may offer a variety of specialized transport options (JPEG compression, streaming video, etc.). Different subscribers may request images from the same publisher using different transports. 
 publishers advertise individual ROS  for each available transport - unlike ROS Publishers, which advertise a single topic. The topic names follow a standard naming convention, outlined below. Note, however, that all code interfaces take only a ""base topic"" name; typically you should not directly reference the transport-specific topic used by a particular plugin. 
 publishers have no independent parameters, but plugins are permitted to make use of the  for configuration options, e.g. bit rate, compression level, etc. See the plugin package documentation. 
 subscribers are used much like 's , but may use a specialized transport to receive images. 
 may be used to specify a different namespace for parameter lookup. This is useful to remap  into a separate namespace to allow different transports for different image subscriptions. The node writer may even specify a parameter name other than , although this is discouraged for the sake of consistency. Nodes that subscribe to image topics should document what parameter(s) control transport, especially if different from . 



 itself does not make use of the . Plugins may read or set plugin-specific parameters, however. 

 lists the declared image transport options across all ROS packages and attempts to determine whether they are currently available for use (packages built, plugins able to be loaded properly, etc.). 
When working with images we often want specialized transport strategies, such as using image compression or streaming video codecs.  provides classes and nodes for transporting images in arbitrary over-the-wire representations, while abstracting this complexity so that the developer only sees  messages. Specialized transports are provided by plugins.  itself provides only  transport so as not to impose unnecessary dependencies on client packages. Other transports will only be available if they are built on your system. On Ubuntu, the  debians include the  and  transports provided by the  stack. For complete examples of publishing and subscribing to images using , see the . If you have implemented a new transport option in a public repository and would like to see it added to this list, please email our . ROS Publishers and Subscribers are used to transport messages of any type.  offers publishers and subscribers specialized for images. Because they encapsulate complicated communication behavior,  publishers and subscribers have a public ROS API as well as a C++ code API. Please see the separate  documentation for C++ usage. The ROS API is documented below. C++:  (),  () The raw  is published on the base topic, just as with using a normal  . If additional plugins are available, they advertise subtopics of the base topic, conventionally of the form . For example, using plugins for  and  transports, with a base topic of , the topics would be: Publisher plugin parameters give subscribers hooks to configure the publisher-side encoding to suit the needs on the client side. Lookup therefore occurs in the public namespace defined by , rather than the private namespace of the publishing node. Note that these parameters are a shared resource, controlling the behavior observed by all subscribers to the image topic. C++:  (),  () A  instance is created with a ""base topic"" name and the name of the transport to use. It subscribes to the transport-specific ROS topic associated with the base topic. For example, if the base topic is , the subscribed topics for transports  and  are respectively: If this parameter is not set, the transport from the  argument of  is used. Subscriber plugins are permitted to make use of the  for configuration options, e.g. video post-processing level. See the plugin package documentation. Subscriber plugin parameters configure the behavior of one particular subscriber. They affect how the data received is interpreted (decoded). This differs from publisher plugin parameters, which are a shared resource affecting the data sent to all subscribers. The namespace used for parameter lookup is again specified through , defaulting to the private namespace of the subscribing node. image_transportimage_transport""raw""ros-<distro>-base""compressed""""theora""image_transportimage_transportimage_transportimage_transportimage_transport""raw""""compressed""""theora""image_transportimage_transportimage_transportimage_transport::Publisherimage_transport::CameraPublisherimage_transportros::Publisher<base topic>/<transport name>""compressed""""theora""/stereo/left/imageimage_transport<base_topic><base topic>/<transport name>_image_transport_<parameter name>type<base_topic>stereo/compressed_image_transport_jpeg_qualityint""compressed""stereo<base topic>/<transport name>/<parameter name>type/camera/image/compressed/jpeg_qualityint""compressed""/camera/imageimage_transportros::Subscriberimage_transport::Subscriberimage_transport::CameraSubscriberSubscriber/stereo/left/image""raw""""compressed""image_transport::TransportHintsimage_transport::ImageTransport::subscribe()image_transport::TransportHints~image_transport~image_transport~image_transportimage_transport::TransportHints~<transport name>_image_transport_<parameter name>type~foo_image_transport_post_processing_levelint""foo""~<transport name>/<parameter name>type~theora/post_processing_levelint""theora""""theora""ros::Subscriberimage_transport::Publisherrepublishlist_transports























$ rosrun image_transport republish [in_transport] in:=<in_base_topic> [out_transport] out:=<out_base_topic>$ rosrun image_transport republish theora in:=camera/image raw out:=camera/image_decompressed$ rosrun image_transport republish raw in:=camera/image out:=camera/image_repub$ rosrun image_transport list_transports"
W2297,https://wiki.ros.org/libntcan,Wiki,libntcan,This package wraps the libntcan to use it as a ros dependency.
W2298,https://wiki.ros.org/jaco_msgs,Wiki,jaco_msgs,"This contains the messages, actions and services for interfacing with the Kinova
  Jaco arm through ROS."
W2299,https://wiki.ros.org/image_proc,Wiki,image_proc,Single image rectification and color processing.image_procimage_procrostopic list | grep image_rawimage_procimage_proc/my_camera/image_raw/my_camera/camera_infoimage_proc/my_cameraimage_rawcamera_info/my_cameraimage_procimage_rawcamera_infoimage_rawcamera_infoimage_monoimage_rectimage_colorimage_rect_colorimage_procimage_procrostopic list | grep image_rawimage_procimage_proc/my_camera/image_raw/my_camera/camera_infoimage_proc/my_cameraimage_rawcamera_info/my_cameraimage_procimage_rawcamera_infoimage_rawcamera_infoimage_monoimage_rectimage_colorimage_rect_color~queue_sizeintimage_procimage_procdebayerrectifyimage_rawimage_monoimage_color~debayerintBilinearEdgeAwareEdgeAwareWeightedVNGimage_monocamera_infoimage_rect~queue_sizeint~interpolationintNNLinearCubicLanczos4cameracamera_outcamera/image_rawcamera/camera_infocamera_out/image_rawcamera_out/camera_info~queue_sizeint~decimation_xint~decimation_yint~x_offsetint~y_offsetint~widthint~heightint~interpolationintNNLinearCubicAreaLanczos4imagecamera_info~image~camera_infoimage_procimage_procrostopic list | grep image_rawimage_procimage_proc/my_camera/image_raw/my_camera/camera_infoimage_proc/my_cameraimage_rawcamera_info/my_cameraimage_procimage_rawcamera_infoimage_rawcamera_infoimage_monoimage_rectimage_colorimage_rect_color~queue_sizeintimage_procimage_procdebayerrectifyimage_rawimage_monoimage_color~debayerintBilinearEdgeAwareEdgeAwareWeightedVNGimage_monocamera_infoimage_rect~queue_sizeint~interpolationintNNLinearCubicLanczos4cameracamera_outcamera/image_rawcamera/camera_infocamera_out/image_rawcamera_out/camera_info~queue_sizeint~decimation_xint~decimation_yint~x_offsetint~y_offsetint~widthint~heightint~interpolationintNNLinearCubicAreaLanczos4imagecamera_info~image~camera_infoimage_procimage_procrostopic list | grep image_rawimage_procimage_proc/my_camera/image_raw/my_camera/camera_infoimage_proc/my_cameraimage_rawcamera_info/my_cameraimage_procimage_rawcamera_infoimage_rawcamera_infoimage_monoimage_rectimage_colorimage_rect_color~queue_sizeintimage_procimage_procdebayerrectifyimage_rawimage_monoimage_color~debayerintBilinearEdgeAwareEdgeAwareWeightedVNGimage_monocamera_infoimage_rect~queue_sizeint~interpolationintNNLinearCubicLanczos4cameracamera_outcamera/image_rawcamera/camera_infocamera_out/image_rawcamera_out/camera_info~queue_sizeint~decimation_xint~decimation_yint~x_offsetint~y_offsetint~widthint~heightint~interpolationintNNLinearCubicAreaLanczos4imagecamera_info~image~camera_infodebayerrectifyimage_procimage_procmanagerstring/my_managerrespawnboolimage_proc$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc$ rosrun image_view image_view image:=my_camera/image_rect_color$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc$ rosrun image_view image_view image:=my_camera/image_rect_color$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc$ rosrun image_view image_view image:=my_camera/image_rect_color$ ROS_NAMESPACE=my_camera rosrun image_proc image_proc$ rosrun image_view image_view image:=my_camera/image_rect_color
W2300,https://wiki.ros.org/image_view,Wiki,image_view,"A simple viewer for ROS image topics. Includes a specialized viewer
  for stereo + disparity images./camera/imageframe0000.jpgframe0001.jpgtheora~image_transport/my_stereo_cam/left/image_rect_color/my_stereo_cam/right/image_rect_colorstereo_viewleft0000.jpgright0000.jpgleft0001.jpgright0001.jpgimage~autosizebool~filename_formatstring""frame%04i.jpg""~image_transportstring""raw""image_view~window_namestring<stereo>/left/<image>stereoimage<stereo>/right/<image>stereoimage<stereo>/disparity~autosizebool~filename_formatstring""%s%04i.jpg""""left""""right""~image_transportstring""raw""/camera/imageframe0000.jpgframe0001.jpgtheora~image_transport/my_stereo_cam/left/image_rect_color/my_stereo_cam/right/image_rect_colorstereo_viewleft0000.jpgright0000.jpgdisp0000.jpgleft0001.jpgright0001.jpgdisp0001.jpgimage_viewimage~autosizebool~filename_formatstring""frame%04i.jpg""~image_transportstring""raw""image_view~window_namestringimage~autosizebool~window_namestring<stereo>/left/<image>stereoimage<stereo>/right/<image>stereoimage<stereo>/disparity~autosizebool~filename_formatstring""%s%04i.jpg""""left""""right""~image_transportstring""raw""~approximate_syncbool~queue_sizeintimage~autosizebool~filename_formatstring""frame%04i.jpg""~image_transportstring""raw""image_view~window_namestringimage~autosizebool~window_namestringrosrun image_view image_saver image:=[your topic]imagesave~filename_formatstringleft%04d.%s~encodingstring~save_all_imageboolimage_saverimage~filename_formatstringframe%04d.jpg~sec_per_framedoubleoutput.aviimage~filenamestringoutput.avi~fpsint~codecstringMJPG~encodingstringbgr8image_view image:=<image topic> [image transport type]image_view image:=/camera/imageimage_view image:=/camera/image theoraimage_view image:=/camera/image _image_transport:=theorastereo_view stereo:=<stereo namespace> image:=<image topic identifier>stereo_view stereo:=/my_stereo_cam image:=image_rect_colorrosrun image_view image_view image:=<image topic> [image transport type]rosrun image_view image_view image:=/camera/imagerosrun image_view image_view image:=/camera/image theorarosrun image_view image_view image:=/camera/image _image_transport:=theorarosrun image_view stereo_view stereo:=<stereo namespace> image:=<image topic identifier>rosrun image_view stereo_view stereo:=/my_stereo_cam image:=image_rect_color"
W2301,https://wiki.ros.org/joint_states_settler,Wiki,joint_states_settler,"Provides a node that reports how long a subset of joints has been
     settled. That is, it calculates how long a set of joints has remained
     within a specified threshold. This package is experimental and unstable.
     Expect its APIs to change.
"
W2302,https://wiki.ros.org/image_pipeline,Wiki,image_pipeline,"image_pipeline fills the gap between getting raw images from a camera driver and higher-level vision processing.



  The  stack is designed to process raw camera images into useful inputs to vision algorithms: rectified mono/color images, stereo disparity images, and stereo point clouds. Components include: The image pipeline will work with any conforming ROS camera driver node. See  for cameras already supported in ROS. The minimal requirements for such a node are: Camera drivers normally have parameters (exposure, gain, etc.) that you can configure at runtime.  has runtime-configurable stereo processing parameters of its own. The  is useful for tweaking your configuration to get best results. image_pipelineimage_rawcamera_infoset_camera_info"
W2303,https://wiki.ros.org/ir_trans_drivers,Wiki,ir_trans_drivers,"irtrans drivers third party code for Maggie robot

"
W2304,https://wiki.ros.org/libphidgets,Wiki,libphidgets,"This package wraps the libphidgets to use it as a ros dependency The following doc might be significantly outdated. Please consider contributing to update it. 
rosdep install libphidgets
rosmake libphidgetsroscd libphidgets
sudo ./install_phidgets.sh"
W2305,https://wiki.ros.org/kdl_conversions,Wiki,kdl_conversions,Conversion functions between KDL and geometry_msgs types.
W2306,https://wiki.ros.org/laser_drivers,Wiki,laser_drivers,"
  This stack contains drivers for laser rangefinders, including Hokuyo SCIP 2.0-compliant and SICK models.
   




 contains a  for Leuze rotoScan ROD-4 laser range-finders. scan"
W2307,https://wiki.ros.org/kdl,Wiki,kdl,"

This package contains a recent version of the Kinematics and Dynamics
Library (KDL), distributed by the Orocos Project. It is a meta-package that depends on orocos_kdl which contains the c++ version and python_orocos_kdl which contains the generated python bindings 

  



 See the  The ""rosmake"" command checks out code from the KDL svn repository (see ). KDL is a 3rd party library that is part of the Orocos project  .    $ rosdep install kdl  $ rosmake kdl"
W2308,https://wiki.ros.org/mk,Wiki,mk,"A collection of .mk include files for building ROS architectural elements.
    Most package authors should use cmake .mk, which calls CMake for the build of the package.
    The other files in this package are intended for use in exotic situations that mostly arise when importing 3rdparty code.  when using  to find the -package, the  needs to be set accordingly. Thus, you should have a dependency to  in your , as this provides the respective  that set this. 






Most packages, and all stacks, use CMake to build. But every package must provide a  if it does any building.  The following files are provided to simplify the  in most packages, and all stacks: Use these files by including them, as explained in the  and . For a 3rdparty package that pulls code from an tarball (or equivalent downloadable file), you should use , like so: The following variables should be defined prior to including : After including , you can make targets depend on the  file; it will be created (and updated) after the tarball has been downloaded, unpacked, and (optionally) patched. Some packages that use : For a 3rdparty package that pulls code from an SVN repository, you should use , like so: The following variables should be defined prior to including : After including , you can make your targets depend on the  file; it will be created after the working copy is checked out and (optionally) patched. Some packages that use : Similar to , there are also: These are based on , so you can generally use them by substituting the appropriate three-letter abbreviation for . svn checkouts are both slow and more prone to downtime.  A hybrid approach using the tarball for distribution, and a fancy makefile can be done with a script like the  package   This uses the svn_checkout script to build the tarball when developing, but most users simply use the tarball.   rospackmkROS_PACKAGE_PATHroslibpackage.xmlMakefileMakefilecmake.mkcmake_stack.mkdownload_unpack_build.mkdownload_unpack_build.mkTARBALLbuild/TARBALL_URLSOURCE_DIRbuild/INITIAL_DIRSOURCE_DIRbuild/UNPACK_CMDtar xzfMD5SUM_FILEmd5sumTARBALL_PATCHdownload_unpack_build.mk$(SOURCE_DIR)/unpackeddownload_unpack_build.mksvn_checkout.mksvn_checkout.mkSVN_DIRSVN_URLSVN_REVISION-r-r 8262SVN_CMDLINEsvnsvn --non-interactiveSVN_PATCHsvn_checkout.mkpatchedsvn_checkout.mksvn_checkout.mkgit_checkout.mkhg_checkout.mkbzr_checkout.mksvn_checkout.mkSVNall: paramiko

TARBALL = build/paramiko-1.7.5.tar.gz
TARBALL_URL = http://pr.willowgarage.com/downloads/paramiko-1.7.5.tar.gz
SOURCE_DIR = build/paramiko-1.7.5
MD5SUM_FILE = paramiko-1.7.5.tar.gz.md5sum
UNPACK_CMD = tar xzf
include $(shell rospack find mk)/download_unpack_build.mk

paramiko: $(SOURCE_DIR)/unpacked
        mkdir -p src
        cd $(SOURCE_DIR) && python setup.py build 
        rm -rf src
        mv `python find_pylib.py paramiko $(SOURCE_DIR)/build/` src
        touch paramiko
clean:
        -rm -rf src $(SOURCE_DIR) paramiko
wipe: clean
        -rm -rf buildall: installed

SVN_DIR = build/stage-svn
SVN_URL = https://playerstage.svn.sourceforge.net/svnroot/playerstage/code/stage/branches/stage-ros
SVN_REVISION = -r 8262
include $(shell rospack find mk)/svn_checkout.mk

installed: $(SVN_DIR) patched Makefile.stage
        cd $(SVN_DIR) && autoreconf -i -s
        cd $(SVN_DIR) && ./configure --prefix=`pwd`/../..
        cd $(SVN_DIR) && make install
        touch installed

clean:
        -cd $(SVN_DIR) && make clean
        rm -rf stage installed patched

wipe: clean
        rm -rf $(SVN_DIR)"
W2309,https://wiki.ros.org/monocam_settler,Wiki,monocam_settler,"Listens on a ImageFeatures topic, and waits for the data to settle.
     This package is experimental and unstable.
     Expect its APIs to change.
"
W2310,https://wiki.ros.org/image_common,Wiki,image_common,"Common code for working with images in ROS.

"
W2311,https://wiki.ros.org/knowrob_common,Wiki,knowrob_common,"

     knowrob_common

  "
W2312,https://wiki.ros.org/knowrob_omics,Wiki,knowrob_omics,"

     knowrob_omics

  "
W2313,https://wiki.ros.org/imu_filter_madgwick,Wiki,imu_filter_madgwick,"Filter which fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into an orientation. Based on code by Sebastian Madgwick, http://www.x-io.co.uk/node/8#open_source_ahrs_and_imu_algorithms.

 




 The  package is used to filter and fuse raw data from IMU devices. It fuses angular velocities, accelerations, and (optionally) magnetic readings from a generic IMU device into an orientation quaternion, and publishes the fused data on the  topic. The package has been tested using the raw data output of a Phidgets IMU (Spatial 3/3/3) device. The package is a wrapper of Sebastian Madgwick's IMU filter [1]. Two drivers are available:  and . Their parameters and topics are identical. [1]  Please submit your tickets through  (requires github account) or by emailing the maintainers.` imu/dataimu_filter_nodeimu_filter_nodeletimu/data_rawimu/magsensor_msgs/MagneticFieldgeometry_msgs/Vector3Stampeduse_magnetic_field_msgimu/data~gaindouble~zetadouble~mag_bias_xdouble~mag_bias_ydouble~mag_bias_zdouble~orientation_stddevdouble~world_framestring""nwu""""enu""~use_magbooltrue~use_magnetic_field_msgboolfalsetruetrue/imu/magsensor_msgs/MagneticFieldfalsegeometry_msgs/Vector3Stamped~fixed_framestringodompublish_tf~publish_tfbooltruefixed_frame~reverse_tfboolfalsetrueimu_framefixed frame~constant_dtdouble~publish_debug_topicsboolfalsetrue~statelessboolfalsetrue~remove_gravity_vectorboolfalsetrueacceleration"
W2314,https://wiki.ros.org/libg2o,Wiki,libg2o,The libg2o library from http://openslam.org/g2o.htmlSee:  
W2315,https://wiki.ros.org/json_prolog,Wiki,json_prolog,"
    json_prolog provides an interface to SWI prolog through ROS
    services. It is implemented in Java by using rosjava and JPL.
  








This package provides methods for querying the  ontology via ROS. json_prolog can load the  file of a ros package at startup. Just pass the corresponding ros package name as first parameter. Examples on how to use the different client libraries can be found in the  subdirectory. For interfacing json_prolog, the python client library provides the class Prolog as an interface for making queries and the class PrologQuery to encapsulate results. Solutions are python dictionaries that map variables to their bindings. Prolog lists are represented as lists. Atoms are represented as strings. More complex terms are represented as dictionaries with the sole mapping from  to a list of values. The first value is always an atom, i.e. a python string. The other values can be of any valid result type, i.e. again a dictionary containing a , a string, a list or a number. The main interface class of the C++ client is . It provides the methods: The class  provides a very simplistic container like interface to a sequence of bindings. In particular, it provides the methods  that returns an iterator to the beginning of the prolog result,  that returns a past-end iterator and the method  to close the query. Dereferencing a PrologQueryProxy::Iterator returns an instance of type . This class essentially is a std::map<std::string, json_prolog::PrologValue> that maps variables to their actual values. The PrologValue class is a wrapper around boost::any with support for the types To check if a PrologValue contains a specific type, it provides the methods To get the value as a specific type, the casting operator to the desired type and the method as<type>() are implemented. Lists are represented as std::vector<PrologValue>. Terms are represented by the special class PrologTerm which provides the following method: The method  returns a pretty printed representation of the contained value. Prolog expressions are either , , ,  or . All types apart from terms, lists and variables are represented by their native JSON format. Terms, lists and variables are represented as dictionaries with exactly one mapping. For terms, they contain a mapping from  to a list with the name of the term as first element and the parameters as the rest of the list. For lists, they contain a mapping from  to the (JSON) list of the members. For variables, they contain a mapping from  to the name of the variable. Strings should always be enclosed by \"" to prevent the JSON parser from doing something stupid. The following example shows how a the Prolog query  Please note that for calling the service , the outer map has to be omitted, i.e. only the list corresponding to the outer  must be passed to the service. init.plexamplestermtermquery(query_str, incremental=False)incrementalsolutions()finish()once(query_strjson_prolog::Prologquery(const std::string &query_str, bool incremental=false)once(const std::string &query_str)json_prolog::!Prologbegin()end()finish()json_prolog::!PrologBindingstype()isValid()isDouble()isInt()isString()isTerm()isList()name()arity()values()operator[]toString~queryquery~simple_queryquery~next_solution~finishtermlistvariable~querytermrosrun json_prolog json_prolog comp_germandelimember(X, [1, 2, 3]), Y = foo(X){\""term\"":[\"",\"",{\""term\"":[\""MEMBER\"",{\""variable\"":\""X\""},{\""list\"":[1,2,3]}]},{\""term\"":[\""=\"",{\""variable\"":\""Y\""},{\""term\"":[\""foo\"",{\""variable\"":\""X\""}]}]}]}X = 1, Y = 2{\""X\"":1, \""Y\"":2}"
W2316,https://wiki.ros.org/mod_vis,Wiki,mod_vis,"

     Visualization module for the Prolog knowledge base.

     Instances in the knowledge base can be pushed to the visualization
     canvas, are then drawn and can be further inspected.

     Currently supported: Action sequences, linked to the resp. human pose
     sequence, as well as most objects that are relevant in the IAS kitchen.

  


The visualization is written in  and Java. You can either call the services directly or, from within Java, use the wrapper function in the  class: See here for documentation:  comm_vis_set_left_img
comm_vis_set_right_img
comm_vis_set_req_text
comm_vis_set_res_text rosrun mod_vis communication_vis CommunicationVisApplet.visualizeCommunication(""Retrieving model..."", """", null, ""cop.png"");"
W2317,https://wiki.ros.org/libpcan,Wiki,libpcan,"This package wraps the libpcan to use it as a ros dependency

You can use this package with a PCAN-USB or a PCAN-PCI adapter from . If you need additional documentation you can read the manual :  rosdep install libpcan
rosmake libpcanroscd libpcan
sudo ./install_pcan.shsudo modprobe pcanls -l /dev/pcan*"
W2318,https://wiki.ros.org/lizi,Wiki,lizi,"The main Lizi robot package



Use GitHub to . []
 The lizi package is the main package which allows to communicate and control the Lizi robot which is made by . 
This command should be executed on the lizi robot computer. For remote operation see the  package. The id number sets the robot name to be lizi_<ID>, this is extremely important when working with several Lizi robot as a group of robots. This allows giving each robot in the group a unique name. The id argument can be any desired id number. The id number affect the namespace and the robot description file links and joint names. All the topics, services and parameters will have a lizi_<ID> prefix. The lizi.launch can also be used to load nodes for the front webcam, the Asus RGB-D camera and the Hokuyo laser scanner. cmd_velgps_pubimu_pubodom_pubRangers/Left_URFRangers/Rear_URFRangers/Right_URFset_odomLizi_IDstrfuse_imu_roll_pitchbooleanfuse_imu_roll_pitchbooleanwheel_diameterdoublewheel_base_lengthdoubleencoder_cprdoublecommandpan_tiltlizi_statusraw_gpslizi_rawreset_encodersimu_calibpid_constantsfloat array$ roslaunch lizi lizi.launch id:=<ID>$ roslaunch lizi lizi.launch id:=1"
W2319,https://wiki.ros.org/ias_knowledge_base,Wiki,ias_knowledge_base,"

    The KnowRob ontology and some other required OWL files (e.g. owl.owl defining the OWL language, and rdf-schema.xml defining the RDFS concepts).

   This package contains the basic  ontology, the base for the IAS knowledge processing system. Currently, the documentation can be found in the  wiki:  "
W2320,https://wiki.ros.org/kinematics_base,Wiki,kinematics_base,"
    This is a base class for kinematics implementations
  






Note this wiki is for the deprecated Arm Navigation version of . For the much newer  Kinematics Base, see . You can create your own plugin implementation of kinematics - essentially a wrapper that wraps your custom kinematics solver by inheriting from the base class defined in this package. The typical procedure for this would be to create your own package (named example_kinematics) and have a dependency on both the  and  packages. Then, have a look at the . You will need to implement all the pure virtual functions after inheriting from the base class. Make sure you add the following lines to the manifest.xml file in .  In a file named  in your example_kinematics package, add the following lines and modify them to match the names you have chosen for your components. In the manifest.xml file for example_kinematics, make sure the following lines are present in the  tag:  <depend package=""pluginlib""/>
 <depend package=""kinematics_base""/><library path=""lib/libarm_kinematics_constraint_aware_lib"">
  <class name=""arm_kinematics_constraint_aware/KDLArmKinematicsPlugin"" type=""arm_kinematics_constraint_aware::KDLArmKinematicsPlugin"" base_class_type=""kinematics::KinematicsBase"">
    <description>
      A generic implementation of kinematics as a plugin based on KDL.
    </description>
  </class>
</library><library path=""lib/libexample_kinematics"">  <kinematics_base plugin=""${prefix}/example_plugins.xml"" />PLUGINLIB_DECLARE_CLASS(example_kinematics,ExampleKinematicsPlugin, example_kinematics::ExampleKinematicsPlugin, kinematics::KinematicsBase)"
W2321,https://wiki.ros.org/rosR_demos,Wiki,rosR_demos,"

     rosR_demos

  

 
 14698/6  "
W2322,https://wiki.ros.org/rosR,Wiki,rosR,"

     rosR

   















20312/10  See also . Within this subsection we will describe all steps that are required to install ros-groovy under an Ubuntu 12.04 32-bit (with long time support) and then our extension for the R-programming language (especially for users with totally no ROS experience). The first steps were taken from the manual () and we guess, you already have installed Ubuntu on your PC. The handling of  arrays is a bit tricky, because in the background these are handled as C structures std::vector. Thus, the size of our new  is currently 0: $ sudo apt-get install swig3.0$ sudo apt-get install r-base$ sudo apt-get install r-cran-rcpp$ sudo sh -c 'echo ""deb http://packages.ros.org/ros/ubuntu precise main"" > /etc/apt/sources.list.d/ros-latest.list'$ wget http://packages.ros.org/ros.key -O - | sudo apt-key add -$ sudo apt-get install ros-groovy-desktop$ sudo apt-get install r-base      # R base system
$ sudo apt-get install r-cran-rcpp # the R-development package
$ sudo apt-get install swig2.0     # to generate the ros-wrapper for R
$ sudo apt-get install subversion  # svn, to be able to download our package# to set all required variables
source /opt/ros/groovy/setup.bash
export ROS_MASTER_URI=http://localhost:11311/
# this is the path where we will install and run our local packages
export ROS_PACKAGE_PATH=$HOME/ros-projects:$ROS_PACKAGE_PATH$ source ~/.bashrc$ sudo rosdep init
$ rosdep update$ mkdir $HOME/ros-projects$ cd $HOME/ros-projects$ svn co http://svn.code.sf.net/p/ivs-ros-pkg/code/trunk/rosR$ cd rosR$ rosmake$ roslaunch rosR random.launch$ roslaunch rosR sensor.launch



















































"
W2323,https://wiki.ros.org/rosshell,Wiki,rosshell,"
		Two simple nodes that can be used as mediators for shell commands.
  




 is by default subscribed to /rosshellX/stdin and publishes at topic /rosshellX/stdout and /rosshellX/stderr, all of type . 
 is just a simple commandline-calculator 



5058/2 This package provides the two nodes, that enable to run and interact with different non-ros-programs.  can be used to start a program or any kind of shell-command. If some kind of interaction with the programs is required, use  to receive and send messages from stdin, stdout, and stderr. both are the same but you also have the possibility to change the command and topics, also within the launch-file, have a look at  ...  rosshellrosshellXrosshellXbcbcbcrosshellX.launch/rosshellX/stdin/rosshellX/stdout/rosshellX/stderrcommandstring""""stdoutstringstdinstringstderrstring$ rosrun rosshell rosshell.py ""command""$ rosrun rosshell rosshellX.py ""command""$ rosrun rosshell rosshell.py ""aplay -c 2 -f S16_LE -r 44100 /dev/urandom""$ rosrun rosshell rosshell.py ""cat /dev/random > test.txt""$ rosrun rosshell rosshell.py ""ls -Shal > test.txt""$ rosrun rosshell rosshellX.py ""bc""$ rostopic echo /rosshellX/stdout



$ rostopic echo /rosshellX/stderr
$ rosrun rosshell rosshellX.py ""ls -Shal""$ rosrun rosshell rosshellX.py _command:=""ls -Shal""





"
W2324,https://wiki.ros.org/audio_common_msgs,Wiki,audio_common_msgs,Messages for transmitting audio via ROSSee  for usage. 
W2325,https://wiki.ros.org/audio_play,Wiki,audio_play,Outputs audio to a speaker from a source node.See  for usage. 
W2326,https://wiki.ros.org/baxter_maintenance_msgs,Wiki,baxter_maintenance_msgs,"Messages and Services required for use with maintenance procedures
    with the Baxter Research Robot from Rethink Robotics."
W2327,https://wiki.ros.org/baxter_gazebo,Wiki,baxter_gazebo,Baxter Gazebo plugins and launch files
W2328,https://wiki.ros.org/asr_object_database,Wiki,asr_object_database,"This package is used to store and provide objects and their information which can be used by other packages like object recognizers 
  







 There are several services this package offers to access the object models which are stored in the  directory located at the base path of it. Inside this directory in there are subdirectories which group the objects together based on their usage (mostly depending on the recognizer which is used to detect them in a scene). Take note that groups and their objects within can only be queried by services if they are declared in config.xml in the  directory. This doesn't apply for example to the environment objects, which are only used for visualization purposes by other packages; they can be accessed by specifying the path to them directly without any service call. rosrun asr_object_database asr_object_database"
W2329,https://wiki.ros.org/asctec_hl_firmware,Wiki,asctec_hl_firmware,"

     Firmware code for the Asctec Autopilot HighLevel Processor 

  
You need to flash the HLP with a custom firmware () which is provided in this package. Flash the HLP following the instructions in the AscTec .  main.hex"
W2330,https://wiki.ros.org/asr_ros_uri,Wiki,asr_ros_uri,"The asr_ros_uri package delivers functionality equally to resource_finder.
    With one exception: It doesn't load the resource into memory but just delivers the uri path to a given file or a file path for a given uri. 




The functionality is similar to that of  with the exception that this package does not load the given resource into memory and just delivers the uri path to a given file or the file path for a given uri. See  on how to use the provided functions. "
W2331,https://wiki.ros.org/aws_ros1_common,Wiki,aws_ros1_common,"Common utilities for ROS1 nodes using Amazon Web Services


This is the common library for all AWS  ROS1 packages. The source code is released under an . "
W2332,https://wiki.ros.org/aruco_detect,Wiki,aruco_detect,"Fiducial detection based on the aruco library





 (, default: 7) There are two categories of ROS  that can be used to configure the  node: general and detection. The  used in the library are paramaters of the  node.  They can also be set via . /camera/camera_info/fiducial_vertices/fiducial_transformsaruco_detect~dictionaryint~fiducial_lendouble~fiducial_len_overridestringfiducial_len""1-10: 0.05, 12: 0.06""~ignore_fiducialsstring""1-10, 12""~publish_imagesboolaruco_detect~adaptiveThreshConstantint~adaptiveThreshWinSizeMaxint~adaptiveThreshWinSizeMinint~adaptiveThreshWinSizeStepint~cornerRefinementMaxIterationsint~cornerRefinementWinSizeint~cornerRefinementMinAccuracydouble~doCornerRefinementbool~errorCorrectionRatedouble~minCornerDistanceRatedouble~markerBorderBitsint~maxErroneousBitsInBorderRatedouble~minDistanceToBorderint~minMarkerDistanceRatedouble~minMarkerPerimeterRatedouble~maxMarkerPerimeterRatedouble~minOtsuStdDevdouble~perspectiveRemoveIgnoredMarginPerCelldouble~perspectiveRemovePixelPerCellint~polygonalApproxAccuracyRatedouble"
W2333,https://wiki.ros.org/baxter_sim_controllers,Wiki,baxter_sim_controllers,Baxter specific controllers for Gazebo use
W2334,https://wiki.ros.org/asr_rapidxml,Wiki,asr_rapidxml,"This package contains a Ros wrapper for RapidXML (version 1.13) 



This package contains a ROS-Wrapper for the (version 1.13). Add this package to the list of dependencies of your project and then you can use the rapidxml library as it is stated in its. "
W2335,https://wiki.ros.org/asr_resources_for_vision,Wiki,asr_resources_for_vision,"This package holds bits and pieces that are related to the acquisition of color and depth-image data streams with robot heads. 
    Currently, it contains a hierarchy of launch scripts to start up simultaneous data acquisition from complex setups of vision sensors as encountered on robot heads 
    (e.g. RGB-D in combination with a color camera or a stereo camera setup). 
  





  



The launch system of the kinect uses  and  to process the data and the scripts in are used to call those nodes with the correct parameters. Kinectcamera Stereo camera For more information on the image processing parameters and the general functionality check out the /  packages. "
W2336,https://wiki.ros.org/angles,Wiki,angles,"This package provides a set of simple math utilities to work
        with angles. The utilities cover simple things like
        normalizing an angle and conversion between degrees and
        radians. But even if you're trying to calculate things like
        the shortest angular distance between two joint space
        positions of your robot, but the joint motion is constrained
        by joint limits, this package is what you need. The code in
        this package is stable and well tested. There are no plans for
        major changes in the near future.
The best place to find out how to use this package is the  "
W2337,https://wiki.ros.org/asr_next_best_view,Wiki,asr_next_best_view,"This package estimates Next-Best-Views as well as configurations (target positions and orientations) for a robot, where it is most likely to find and recognize searched objects the poses of which have, e.g., been predicted by means of ISM trees. 












   This tool uses an iterative generate-and-test algorithm. Each iteration results in a , the algorithm stops if the  of two consecutive iteration steps have almost no improvement. The idea of the  is that it tells you where it is most probable that objects will be found. The following images describe basic concepts to understand the next_best_view node:    In each iteration step, views are generated and then rated. The view with the best rating is chosen as NextBestView for that iteration step. To get a set of viewports from a set of positions and orientations, the cross product between those two sets is used. The resulting set of viewports is filtered by world and hypotheses information (MapHelper and CameraModelFilter class). The following two images show the orientation and position sampling. Each arrow on the sphere shows the endposition of one direction vector which starts in the center of the sphere. The red rectangle limits the space sampling area. All hexagon corners and the center of the rectangle are used to generate viewports.   The NextBestViewCalculator class manages all modules. To find a NextBestView, we must first call the SetAttributedPointCloud and SetInitRobotState service calls, then we can use the GetNextBestView service call to get our NextBestView. SetAttributedPointCloud sets and visualizes the pointcloud as shown above in the second and third image, triggerFrustumVisualization is used to display the blue frustum which can be seen above in the first image. To invalidate hypotheses in a frustum, call the UpdatePointCloud service call with the camera pose. Just run  to get the next_best_view node running for the simulation or to get it running in a real environment. "
W2338,https://wiki.ros.org/audio_common,Wiki,audio_common,"Common code for working with audio in ROS
Note: This stack is downloadable in debian package format as part of the  package. ros-*-audio-common"
W2339,https://wiki.ros.org/baxter_examples,Wiki,baxter_examples,Example programs for Baxter SDK usage.
W2340,https://wiki.ros.org/baxter_core_msgs,Wiki,baxter_core_msgs,"Messages and Services required for communication with the Baxter
    Research Robot from Rethink Robotics."
W2341,https://wiki.ros.org/baxter_description,Wiki,baxter_description,"Description of Baxter Research Robot from Rethink Robotics.
    This package contains the URDF and meshes describing Baxter."
W2342,https://wiki.ros.org/baxter_tools,Wiki,baxter_tools,"Useful operational and maintenance tools for use with the Baxter Research
    Robot from Rethink Robotics"
W2343,https://wiki.ros.org/aws_common,Wiki,aws_common,"Common AWS SDK utilities, intended for use by ROS packages using the AWS SDK


 This is the common library for all AWS  packages. The source code is released under . "
W2344,https://wiki.ros.org/asr_sick_lms_400,Wiki,asr_sick_lms_400,"This package is used to access the sick lms400 laser range-finder. It contains all necessary functionality to communicate with the sensor via rosmessages. 



 



  (string)  (string)  (int)   (int)  (int)  (int)  (int)   (double)  (int)  (bool)  (int) A  is required to use this package. _/laser_scan_ ( rosrun asr_sick_lms_400 asr_sick_lms_400"
W2345,https://wiki.ros.org/actionlib_msgs,Wiki,actionlib_msgs,"actionlib_msgs defines the common messages to interact with an
     action server and an action client.  For full documentation of
     the actionlib API see
     the 
     package."
W2346,https://wiki.ros.org/astra_launch,Wiki,astra_launch,Drivers for Orbbec Astra Devices.
W2347,https://wiki.ros.org/asr_robot_model_services,Wiki,asr_robot_model_services,"This package provides services to perform calculations related to the mild's kinematic model. 




 
  
  
     















- with ,  as the 2D position of the robot's base,  as the robot's rotation on the 2D map and ,  as the angles of the PTU unit - Considering this simplified version of the kinematic chain, an optimization algorithm provided by the  package is used to find an optimal solution for pan and tilt angles, as well as the base rotation. The goal is to find a camera pose (and a corresponding view frustum - red), that faces the center of the target view frustum (black) in the same distance  while minimizing the angle deviation  as much as possible. Given the position of the target view frustum center , the camera distance to the center , the projected distance between tilt joint and camera center point  as well as the tilt joint's constant height above ground , the tilt angle can be determined. Once a solution for the tilt angle has been found, the position of can be calculated directly. A more detailed description of how this problem is being solve can be found here . Starting the  for the  robot model: Starting the  for the  robot model: This file specifies the names of key frames in the robot's kinematic chain.Seefor an overview over the mild's kinematic chain. The functionality for the pose correction is described here: (x, y, z, uw, ux, uy, uz)(x, y, alpha, ptu-pan, ptu-tilt)(ptu-pan, ptu-tilt)launch asr_robot_model_services RobotModelServiceReal.launchlaunch asr_robot_model_services RobotModelServiceSim.launchlaunch asr_robot_model_services set_focus_point.launch"
W2348,https://wiki.ros.org/axis_camera,Wiki,axis_camera,"Python ROS drivers for accessing an Axis camera's MJPG
    stream. Also provides control for PTZ cameras. 
 




 


ROS camera driver for . Parameters are resolved starting with the driver's private namespace. If desired, they may be defined in some containing namespace. That is useful for sharing parameters with the  node. The  must already be running before any of these example commands. While you can run the driver in the ROS root namespace, the image pipeline prefers running each camera in its own subordinate namespace. These examples use the  namespace. With multiple cameras, use something unique to the device, like the camera name. Pass the network host name and password of the camera on the command line, assuming the default username (""root""). This example uses the  local  address, alternatively one could provide the static IP address for which the camera is configured. This publishes two topics:  and . To see the raw image, run  in another terminal this way: The  parameter is necessary, because the camera is actually publishing a motion JPEG stream, via the ROS  message. Wide-angle network camera lenses generally exhibit significant intrinsic distortion. For robotics work, it is very helpful to calibrate each camera and use  to provide rectified output. Since the driver produces compressed motion JPEG, and  expects raw  data, an extra step is needed to convert the data stream: To see the rectified color image, run  in another terminal this way: The  parameter is not needed in this case, because image_proc publishes its output using . Then, in a third terminal, run : Then, follow the instructions in the . The resulting calibration parameters will be stored in , which resolves to  in this example (assuming $ROS_HOME points to the default  directory). The next time the driver runs on the same machine it should automatically pick up the existing calibration information in that same location. You can store the calibration elsewhere by setting  appropriately for the driver. For example, to store it in a package named , append this to the driver's argument list: See  for details. axis_ptzroscoreaxis/axis/camera_info/axis/image_raw/compressed_image_transportimage_proc_image_transportfile://${ROS_HOME}/camera_info/${NAME}.yaml~/.ros/camera_info/axis_00408c8ae301_local.yaml~/.ros~camera_info_urlmy_calibrations $ export ROS_NAMESPACE=axis
 $ rosrun axis_camera axis.py _hostname:=axis-00408c8ae301.local _password:=xxxxxxxx $ rosrun image_view image_view image:=/axis/image_raw _image_transport:=compressed $ export ROS_NAMESPACE=axis
 $ rosrun image_transport republish compressed in:=image_raw raw out:=image_raw $ ROS_NAMESPACE=axis rosrun image_proc image_proc $ rosrun image_view image_view image:=/axis/image_rect_color $ export ROS_NAMESPACE=axis
 $ rosrun axis_camera axis.py _hostname:=axis-00408c8ae301.local _password:=xxxxxxxx $ export ROS_NAMESPACE=axis
 $ rosrun image_transport republish compressed in:=image_raw raw out:=image_raw $ rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 \
          image:=/axis/image_raw camera:=/axis_camera_info_url:=package://my_calibrations/info/${NAME}.yamlhttp://IP_ADDRESS_OF_YOUR_CAMERA -> Setup -> Basic Setup -> Usersrosrun axis_camera axis_ptz.py _hostname:=IP_ADDRESS_OF_YOUR_CAMERA"
W2349,https://wiki.ros.org/baxter_interface,Wiki,baxter_interface,"Convenient python interface classes for control
    of the Baxter Research Robot from Rethink Robotics.Since  API Doc is . "
W2350,https://wiki.ros.org/baxter_sim_io,Wiki,baxter_sim_io,"The Navigator buttons for the Baxter Research Robot are simulated, and their states are captured and published on the corresponding rostopics"
W2351,https://wiki.ros.org/async_web_server_cpp,Wiki,async_web_server_cpp,Asynchronous Web/WebSocket Server in C++
W2352,https://wiki.ros.org/actionlib_tutorials,Wiki,actionlib_tutorials,"The actionlib_tutorials package
actionlib_tutorials is a series of tutorials for using the  client API. You can browse these tutorials by installing  and -ing to the  package, i.e. roscdactionlib_tutorialsROS~/tutorials/workspace.bashrc.bashrcsrccatkinlearning_actionlibROS_PACKAGE_PATHrosbuild_genmsg()learning_actionlib/CMakeLists.txt$ apt-get install ros-$ROS_DISTRO-common-tutorials
$ roscd actionlib_tutorials- other: { local-name: workspace }rosinstall ~/tutorials /opt/ros/$ROS_DISTRO>> ~/tutorials.rosinstallsource ~/tutorials/setup.bash$ source /opt/ros/$ROS_DISTRO/setup.bash
$ mkdir -p ~/tutorial_ws/src
$ cd ~/tutorial_ws
$ catkin_init_workspace src
$ catkin_make$ source devel/setup.bash$ cd %YOUR_CATKIN_WORKSPACE%/src
$ catkin_create_pkg actionlib_tutorials actionlib message_generation roscpp rospy std_msgs actionlib_msgs$ roscd tutorials
$ roscreate-pkg learning_actionlib actionlib roscpp rospy roslib std_msgs actionlib_msgs$ rosmake learning_actionlib"
W2353,https://wiki.ros.org/airbus_ssm_plugin,Wiki,airbus_ssm_plugin,The airbus_ssm_plugin package
W2354,https://wiki.ros.org/battery_monitor_rmp,Wiki,battery_monitor_rmp,"Monitor for the Segway Batteries







The  package uses the feedback provided by the RMP to monitor the segway batteries and then uses espeak to tell the user if a battery is getting low. It also publishes this information. To install the  package, you can choose to either install from source, or from the Ubuntu package: The  package contains a  file. This file launches an instance of the . To launch these nodes the following command can be used: Please send bug reports to the . Feel free to contact me at any point with questions and comments.  battery_monitor_rmpmonitor_rmp.pyrmp_feedbackbattery_status_rmp~front_base_batt_1~front_base_batt_2~rear_base_batt_1~rear_base_batt_2~aux_battbattery_monitor_rmpbattery_monitor_rmpbattery_monitor_rmp.launchbattery_monitor_rmp.py




sudo apt-get install ros-indigo-battery-monitor-rmproslaunch battery_monitor_rmp battery_monitor_rmp.launch "
W2355,https://wiki.ros.org/audio_capture,Wiki,audio_capture,"Transports audio from a source to a destination. Audio sources can come
      from a microphone or file. The destination can play the audio or save it
      to an mp3 file.See  for usage. "
W2356,https://wiki.ros.org/ecl_config,Wiki,ecl_config,"These tools inspect and describe your system with macros, types 
     and functions.






When autodetection fails (you have a very embedded board, or your toolchain has been patched together in a very non-standard way) there is provision to manually supply details via the  macro. Refer to the . Checking for : ecl/config/ecl.hppECLECL_IS_POSIXECL_IS_CUSTOM










// Platform macros - automatically detected by the build.
- ECL_IS_POSIX || ECL_IS_WIN32 || ECL_IS_APPLE || ECL_IS_CUSTOM
- ECL_HAS_POSIX_THREADS || ECL_HAS_WIN32_THREADS
- ECL_SIZE_OF_CHAR
- ECL_SIZE_OF_SHORT
- ECL_SIZE_OF_INT
- ECL_SIZE_OF_LONG
- ECL_SIZE_OF_LONG_LONG
- ECL_SIZE_OF_FLOAT
- ECL_SIZE_OF_DOUBLE
- ECL_SIZE_OF_LONG_DOUBLE
- ECL_CHAR_IS_SIGNED || ECL_CHAR_IS_UNSIGNED
- ECL_HAS_SHARED_LIBS || ECL_HAS_STATIC_LIBS
// ECL Development macros
- ECL_DISABLE_EXCEPTIONS
- ECL_DONT_INLINE
- ECL_DEPRECATED
- ECL_PUBLIC || ECL_LOCAL- ecl::int8,  ecl::uint8
- ecl::int16, ecl::uint16
- ecl::int32, ecl::uint32
- ecl::int64, ecl::uint64
- ecl::float32
- ecl::float64 
- ecl::float96 
- ecl::float128// The function operates like a macro, and a good compiler will compile
// out the if mechanism and leave behind the required section of code.
if ( ecl::is_big_endian() {
    // ...
}


"
W2357,https://wiki.ros.org/cob_cartesian_controller,Wiki,cob_cartesian_controller,"This package provides nodes that broadcast tf-frames along various (model-based) Cartesian paths (e.g. Linear, Circular).
    The tf-frames are interpolated using a given velocity profile (e.g. Ramp, Sinoid) and can be used as targets for the cob_frame_tracker/cob_twist_controller."
W2358,https://wiki.ros.org/ecl_containers,Wiki,ecl_containers,"The containers included here are intended to extend the stl containers.
    In all cases, these implementations are designed to implement
    c++ conveniences and safety where speed is not sacrificed. 

    Also includes techniques for memory debugging of common problems such
    as buffer overruns.


See the programs in the  and  subdirectories. src/testsrc/examples






"
W2359,https://wiki.ros.org/cob_teleop,Wiki,cob_teleop,"Teleop node





This package uses a joystick or keyboard for teleoperation of Care-O-bot. To use this package you need either a real Care-O-bot or a simulated one (see ). The  package provides both, a configurable node for teleoperation by joystick or by keyboard. 
To be able to use the joystick the  has to be pressed all the time, as soon as the button is released a stop will be send to all hardware components. Have a look at the following image to see which buttons command which components.  For : Hold the  button and use the base  and  axis to move the base. For : Hold the  button and the  or  neck button, then use the  or  axis to move the torso. For : Hold the  button and the  button, then use the  axis to move the tray. For : Hold the  button and one of the  buttons, then use the  or  axis to move the selected arm joints. cob_teleopjoy/joint_statesarm_controller/commandtorso_controller/commandtray_controller/commandbase_controller/command~run_factorfloat~lower_neck_buttonint~upper_neck_buttonint~tray_buttonint~arm_joint12_buttonint~arm_joint34_buttonint~arm_joint56_buttonint~arm_joint7_buttonint~deadman_buttonint~run_buttonint~axis_vxint~axis_vyint~axis_vthint~lower_tilt_stepfloat~lower_pan_stepfloat~upper_tilt_stepfloat~upper_pan_stepfloat~tray_stepfloat~arm_left_right_stepfloat~arm_up_down_stepfloat~max_vxfloat~max_vyfloat~max_vthfloat~max_axfloat~max_ayfloat~max_athfloatdeadman_buttondeadmanrotationtranslationdeadmanupperlowerup_downleft_rightdeadmantrayup_downdeadmanarmup_downleft_rightroslaunch cob_bringup teleop.launch<include file=""$(find cob_bringup)/tools/teleop.launch"" />roslaunch cob_teleop teleop_keyboard.launch# common params
run_factor: 2.0

# buttons
lower_neck_button: 6
upper_neck_button: 4
tray_button: 3
arm_joint12_button: 0
arm_joint34_button: 1
arm_joint56_button: 2
arm_joint7_button: 3
deadman_button: 5
run_button: 7

# axes
axis_vx: 1
axis_vy: 0
axis_vth: 2
up_down: 5 #tray--up/down; tilt--front/back, here we just name up_down
left_right: 4 #pan--left/right

# velocities in rad/sec, m/sec
lower_tilt_step: 0.05
lower_pan_step: 0.05
upper_tilt_step: 0.075
upper_pan_step: 0.075
tray_step: 0.15
arm_left_right_step: 0.1
arm_up_down_step: 0.1
max_vx: 0.3
max_ax: 0.5
max_vy: 0.2
max_ay: 0.5
max_vth: 0.3
max_ath: 0.7"
W2360,https://wiki.ros.org/class_loader,Wiki,class_loader,"The class_loader package is a ROS-independent package for loading plugins during runtime and the foundation of the higher level ROS ""pluginlib"" library. class_loader utilizes the host operating system's runtime loader to open runtime libraries (e.g. .so/.dll files), introspect the library for exported plugin classes, and allows users to instantiate objects of said exported classes without the explicit declaration (i.e. header file) for those classes. 
 is a ROS-independent package that allows one to dynamically load exported C++ classes during runtime from a runtime library (i.e. .so/.dll file) and create objects of those classes. What makes a class loaded through  different from just linking against a runtime library and using classes from it is that your code does not require the definition of the class (i.e. the header file for the class) in your client code. Classes loaded in this fashion are also often called .  
 is used in the implementation of the higher-level ROS package  which is the encouraged method for loading plugins in the ROS  ecosystem.  
 is simple to use and requires linking against a single library (). 








  


 as of version 1.9 and class_loader HIGHLY discourage linking applications directly against libraries containing plugins. Often times users will place plugins into libraries along side code intended to directly be linked. Other times they want to be able to use classes as plugins as well as directly use them without a . This was fine in previous versions of pluginlib, but as version 1.9, pluginlib sits on top of class_loader for plugin loading which cannot handle this.  






  It is important to note that the  can only inspect classes and create objects of those classes if those classes are registered to be exportable.  For any classes you want to export, make sure to have a declaration of the following macro for each class within your source (.cpp) files: where  refers to the name of the class to be exported and  refers to the name of the class from which it is derived. Though you do not need the definition of the Derived class in the code that will load the class, you still need to have a definition to its base class so as to be able to use the plugin. Notice in the code examples that when introspecting the library via  or creating a plugin via  that both methods require a template type argument indicating the base class. If the correct base class is not given, the class will not be seen or instantiable by the . It is ok to have classes with different base classes registered or even register the same class multiple times with different bases in the same library and transitively the same . Just note the base class argument must be provided at compile time via a template argument for methods where it matters. Once you have built all your source files using the macro, you can package the object files into a runtime library and then load that library via the . All methods to  and  are thread safe. The use of templates allows for all types to be statically verified and it is impossible to load an invalid plugin with an incompatible interface. This is a powerful concept in guaranteeing the integrity of plugins at both compile and runtime which is of course very important in robotics. When one uses the  to create and destroy plugins, it results in the opening and closing of the runtime libraries containing those plugins. When a runtime library is loaded by an operating system, symbols in the host executable that are stubs to the runtime library are resolved. When the library is unloaded, the symbols at those corresponding memory addresses are unavailable as the code has been removed from executable's address space and [possibly] unloaded from memory. If one attempts to use symbols that are unresolved, it leads to a runtime link error. This means if I create an object from a class defined within a runtime library, I then unload the library, and then I try to use the object...things will go bad.  In the example code above, the library is loaded and unloaded by  automatically, though  provides methods for explicitly loading and unloading the underlying library ( and  respectively). The  is smart in that it will automatically load a library when created and unload it when the  goes out of scope. One may wonder why the load and unload methods are then exposed. In order to understand that, we must first understand the 's on-demand (lazy) load/unload mode. The  constructor provides an optional boolean flag () to indicate if the  is to perform on-demand (lazy) loading of a library as needed and automatically closing it after the last plugin in created by it is destroyed. By default, this flag is set to false. When set to false, the  loads the library at construction time and unloads it at destruction time. In on-demand mode, the library is only opened when the first plugin is created via  and unloaded when the only remaining plugin created by the  is destroyed. This mode is helpful when we want to minimize the number of libraries loaded in memory. It is often useful, particularly in on-demand mode, to control when the library is loaded and unloaded. One can force this by calling . When one calls  and , the library is forcefully loaded into memory and cannot be unloaded automatically by the system until  is called. This allows multiple threads sharing the same  to force a shared library, even if it's open in on-demand mode, to stay in memory until it's done. This is not a thread safety issue, but rather one for performance to prevent a library from continuously being loaded/unloaded if a thread is going to need it heavily for some period of time and wants to guarantee the library stays in memory. A  allows one to create objects in the form of  values so as to provide automatic cleanup of objects. Another one of the important reasons this is implemented is so that the user cannot unload the library prematurely. The user is free to create unmanaged objects via the alternate  method, but this will prevent the  from stopping the user on unloading the library when there are still objects in memory. This is because the  cannot be aware of the state of unmanaged instances. Many  methods will raise an exception of base class type  if an error occurs. The subclasses of  are defined in  and indicate the various problems. These include: The  is designed to be bound only to a single runtime library. Often it is convenient to have multiple libraries open and be able to load/unload classes from them through a uniform interface. That is why the class  is provided. This class provides as an almost identical interface to  but allows one to bind several libraries to a single loader object. Internally, the  is just a manager for a collection of  objects. The issue is that the way class_loader implements plugin introspection is by having plugin   automatically register themselves when the library is opened. This is not how pluginlib prior to version 1.9 operated. However, the problem is is that when you directly link an executable against a library with plugins, when that program starts up, all the plugin factories will be created outside the scope of a . See  for more details. For those interested in understanding the internals of , go to the  page. class_loader::ClassLoaderclass_loader::MultiLibraryClassLoaderclass_loader/class_loader.hclass_loader::ClassLoaderCLASS_LOADER_REGISTER_CLASS(Derived, Base)getAvailableClasses()createInstance()class_loader::ClassLoaderclass_loader::MultiLibraryClassLoaderclass_loader::ClassLoaderloadLibrary()unloadLibrary()ondemand_loadunloadcreateInstance()loadLibraryloadLibaryunloadLibraryunloadLibraryclass_loader::ClassLoaderboost::shared_ptrclass_loader::ClassLoader::createUnmanagedInstanceclass_loader::ClassLoader::createInstance()class_loader::ClassLoaderExceptionclass_loader::ClassLoaderExceptionclass_loader/class_loader_exceptions.hclass_loader::LibraryLoadExceptionclass_loader::LibraryUnloadExceptionclass_loader::CreateClassExceptionclass_loader::MultiLibraryClassLoaderclass_loader::ClassLoaderclass_loader::MultiLibraryClassLoaderclass_loader::ClassLoaderclass_loader::ClassLoader   class_loader::ClassLoader loader(""libMyLibrary.so"");   std::vector<std::string> classes = loader.getAvailableClasses<MyBase>() for(unsigned int c = 0; c < classes.size(); ++c)
 {
   boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);
   plugin->someMethod();
   //'plugin' will automatically be deleted when it goes out of scope
 }#include <class_loader/class_loader.h>
#include ""MyBase.h"" //Defines class MyBase

int main()
{
  class_loader::ClassLoader loader(""libMyLibrary.so"");
  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();
  for(unsigned int c = 0; c < classes.size(); ++c)
  {
    boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);
    plugin->someMethod();
  }
}#include <class_loader/multi_library_class_loader.h>
#include ""MyBase.h"" //Defines class MyBase

int main()
{
  class_loader::MultiLibraryClassLoader loader;
  loader.loadLibrary(""libSomeLib.so"");
  loader.loadLibrary(""libAnotherLib.so"");
  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();
  for(unsigned int c = 0; c < classes.size(); ++c)
  {
    boost::shared_ptr plugin<MyBase> = loader.createInstance<MyBase>(classes[c]);
    plugin->someMethod();
  }
}"
W2361,https://wiki.ros.org/control_box_rst,Wiki,control_box_rst,"The control_box_rst package provides C++ libraries for predictive control, 
               direct optimal control, optimization and simulation."
W2362,https://wiki.ros.org/depth_image_proc,Wiki,depth_image_proc,"Contains nodelets for processing depth images such as those
     produced by OpenNI camera. Functions include creating disparity
     images and point clouds, as well as registering (reprojecting)
     a depth image into another camera frame.  has found a new home in . In Electric it resided in . 
 provides basic processing for depth images, much as  does for traditional 2D images. The two packages are complementary; for example, you can (and should!) rectify your depth image before converting it to a point cloud. 








See  for details on depth image representation. The REP recommends that, wherever possible, producers and consumers of depth data use depth images (of type ) instead of . All nodelets (besides ) in this package support both standard floating point depth images and OpenNI-specific  depth images. Thus when working with OpenNI cameras (e.g. the Kinect), you can save a few CPU cycles by using the  raw topics instead of the  topics. For an example of  in practice, examine the contents of . depth_image_procdepth_image_procconvert_metricuint16uint16floatdepth_image_procuint16floatimage_rawuint16imagefloatleft/image_rectright/camera_infoleft/disparitymin_rangedoublemax_rangedoubledelta_ddoublequeue_sizeintcamera_infoimage_rectpointsPointCloud<PointXYZ>queue_sizeintrgb/camera_inforgb/image_rect_colordepth_registered/image_rectdepth_registered/pointsPointCloud<PointXYZRGB>queue_sizeintrgb/camera_infodepth/camera_infodepth/image_rectdepth_registered/camera_inforgb/camera_infodepth_registered/image_rectdepth_registered/image_rectqueue_sizeint/depth_optical_frame/rgb_optical_frame/depth_optical_frame/rgb_optical_frame"
W2363,https://wiki.ros.org/comp_spatial,Wiki,comp_spatial,"

     Routines for spatial reasoning in Prolog.

     Contains Prolog computables for calculating qualitative spatial relations,
     but also those for extracting certain elements from the string representation
     of a matrix.

  This package is part of the  knowledge processing system. "
W2364,https://wiki.ros.org/cassandra_ros,Wiki,cassandra_ros,"

     Library and tools for dynamically storing ROS messages in Apache Cassandra.

  

  partitioner is required to retrieve requested data ordered, otherwise it will appear. For more information, have look on the documentation on  










5515/1 Then change the Cassandra partitioner to """", which can be set in  partitioner: org.apache.cassandra.dht. The option -f hinders Cassandra to start a deamon in backgroud, for more information and help visit :  Check the following link:  How does it work? If you take a look into cassandra_ros/lib ... you will see a couple of files in the form of _'format'.py, which are all descendants of _.py. And each of them overwrites the methods: As you could see so far, you only work with the single class of . In fact, this class inherits those methods, required for encoding and decoding of messages, and only those of the required parent class. If you are seeking for more information, have a look at the follwing link:   If you want to analyze your data by using CQL, the , you will have to generate at first secondary indexes. Because this might be expensive and not required for every part of a message, this has to be done manually, as follows: For more information on CQL, check the following website:  $ bin/cassandra -f$ roslaunch cassandra_ros recordCamera.launch$ roslaunch cassandra_ros replayCamera.launch$ roslaunch cassandra_ros deleteCamera.launch
























































































































































"
W2365,https://wiki.ros.org/cob_command_gui,Wiki,cob_command_gui,"This package provides a simple GUI for operating Care-O-bot. 


To use this package you don't need any hardware, but it is intended to be used with either a real Care-O-bot or a simulated one (see  or ). The  package provides a configurable node for operating different hardware parts of Care-O-bot. The command_gui uses the functionalities of the  package. 
The parameters of the command_gui are  defined in  and  and loaded in the parameter server.  knoeppkes.pyrosdep install cob_command_gui
rosmake cob_command_guiexport ROBOT=cob3-3
export ROBOT_ENV=ipa-kitchen
roslaunch cob_bringup dashboard.launch"
W2366,https://wiki.ros.org/camera_info_manager_py,Wiki,camera_info_manager_py,"Python interface for camera calibration information.

    This ROS package provides a CameraInfo interface for Python camera
    drivers similar to the C++ camera_info_manager package.





: a driver can now handle more than one camera, using a different  with the CameraInfoManager class instance of each device.  

It provides a Python module for camera drivers to manage the  required by the . The API includes a camera name, which is written when  is saved and checked when data are loaded, with a warning logged if the name read does not match. Camera driver authors should refer to the  for syntax details and recommendations for assigning camera names.  The location for getting and saving calibration data is expressed by Uniform Resource Locator (URL). These URLs are commonly used in the APIs of this package and may also contain substitution variables to refer to common locations. Please see the  for supported URLs, file formats and substitution variables, which include  and the camera name, . This package does not read ROS parameters directly. Where appropriate, we recommend that drivers provide a  parameter for the URL string passed to CameraInfoManager. Open a link from  in the top-right corner of this web page. CameraInfo${ROS_HOME}${NAME}set_camera_info~camera_info_urlCode API"
W2367,https://wiki.ros.org/diffdrive_gazebo_plugin,Wiki,diffdrive_gazebo_plugin,"This package provides Gazebo plugins for differential drive robots. It is based on turtlebot_gazebo_plugins by Nate Koenig.

Use GitHub to . []
  For installation instructions, see . "
W2368,https://wiki.ros.org/concert_scheduler_requests,Wiki,concert_scheduler_requests,Python interfaces for managing ROCON scheduler requests.This package was renamed from . The older version is now . 
W2369,https://wiki.ros.org/bwi_msgs,Wiki,bwi_msgs,"Contails messages used in the utexas-bwi codebase.
Newly proposed, mistyped, or obsolete package. Could not find package ""bwi_msgs"" in rosdoc: /home/rosbot/docs/api/bwi_msgs/manifest.yaml This package collects ROS messages, services and actions that are specific to the Building-Wide Intelligence project of the University of Texas at Austin.  It simplifies the dependencies between various  repository components.  "
W2370,https://wiki.ros.org/dbw_mkz_twist_controller,Wiki,dbw_mkz_twist_controller, The package dbw_mkz_twist_controller has been deprecated with migration to dataspeed_ulc_can. The drive-by-wire firmware now includes a much better twist control implementation.Twist (speed and angular rate) controller for brake/throttle/steering
W2371,https://wiki.ros.org/cob_gazebo_ros_control,Wiki,cob_gazebo_ros_control,"This package contains a specialization of the gazebo_ros_control plugin.
    The cob_gazebo_ros_control plugin allows Multi-HardwareInterface-Support."
W2372,https://wiki.ros.org/diagnostic_msgs,Wiki,diagnostic_msgs,"This package holds the diagnostic messages which provide the
    standardized interface for the diagnostic and runtime monitoring
    systems in ROS. These messages are currently used by
    the 
    Stack, which provides libraries for simple ways to set and access
    the messages, as well as automated ways to process the diagnostic
    data.

    These messages are used for long term logging and will not be
    changed unless there is a very important reason.

The  package in the  stack assists in sending diagnostics There are several ways to view diagnostics in the  package in the  stack.  "
W2373,https://wiki.ros.org/bwi_tools,Wiki,bwi_tools,"Contains commonly used Python and C++ structures and tools in the BWI
    project codebase"
W2374,https://wiki.ros.org/depthimage_to_laserscan,Wiki,depthimage_to_laserscan,"depthimage_to_laserscan

 
 
 projected on top of the .  
 


 Note the  overlayed in color on the .  Red is close to camera, purple is far from camera. Top down view of the . depthimage_to_laserscanimagecamera_infoscanimage/camera/depth/image_rawimage_rectcamera_infoimagescan~scan_heightint~scan_timedouble~range_mindouble~range_maxdouble~output_frame_idstrdepthimage_to_laserscan/DepthImageToLaserScanNodelet"
W2375,https://wiki.ros.org/dynamixel_msgs,Wiki,dynamixel_msgs,Common messages used throughout dynamixel_motor stack.
W2376,https://wiki.ros.org/cob_footprint_observer,Wiki,cob_footprint_observer,"The cob_footprint_observer package adjusts the footprint of the robot based on the setup (e.g. arm and/or tray). The  only works with rectangular footprints. 


The  observes the setup of the Care-O-Bot (including arm and tray) and inflates the footprint to contain the arm and the tray. It allows for reading the adjusted footprint using either the  service or the published  topic. To use this package you need either need a real or a simulated Care-O-Bot (see  and  respectively). The  package provides a configurable node for checking and adjusting the footprint based on the current setup. 
cob_footprint_observerGetFootprintadjusted_footprintcob_footprint_observercob_footprint_observertf::TransformListeneradjusted_footprint/get_footprint~footprint_sourcestring~frames_to_checkstring~robot_base_framestringcollision_velocity_filterroslaunch cob_bringup base_collision_observer.launch<!-- start footprint observer node -->
<node pkg=""cob_footprint_observer"" type=""footprint_observer"" name=""footprint_observer"" output=""screen"">
  <!-- load parameter file -->
  <rosparam file=""$(find cob_hardware_config)/$(env ROBOT)/config/footprint_observer_params.yaml"" command=""load"" />
</node># node from which initial footprint is read
footprint_source: /local_costmap_node/costmap

# 
robot_base_frame: /base_link
# frames to check for footprint adjustment
frames_to_check: /sdh_tip_link /arm_6_link /arm_4_link"
W2377,https://wiki.ros.org/cob_dashboard,Wiki,cob_dashboard,cob_dashboard is a modified version of [[pr2_dashboard]].
W2378,https://wiki.ros.org/concert_service_teleop,Wiki,concert_service_teleop,Teleop by request from a rocon interactive program.
W2379,https://wiki.ros.org/bond,Wiki,bond,"A bond allows two processes, A and B, to know when the other has
    terminated, either cleanly or by crashing.  The bond remains
    connected until it is either broken explicitly or until a
    heartbeat times out."
W2380,https://wiki.ros.org/concert_service_admin,Wiki,concert_service_admin,A general purpose admin service (mostly configures rocon interactions).
W2381,https://wiki.ros.org/bondcpp,Wiki,bondcpp,"C++ implementation of bond, a mechanism for checking when
    another process has terminated.

  
Use GitHub to . []
 bondcpp is an implementation of  in C++.  To use bondcpp, please see the example below as well as the . 




















"
W2382,https://wiki.ros.org/calibration_launch,Wiki,calibration_launch,"This package contains a collection of launch files that can be helpful in configuring
    the calibration stack to run on your robot."
W2383,https://wiki.ros.org/concert_msgs,Wiki,concert_msgs,Shared communication types for the concert framework.
W2384,https://wiki.ros.org/cob_camera_sensors,Wiki,cob_camera_sensors,"For more information read the readme.htm file located in







 The  package is a collection of ROS compatible drivers for the cameras installed on Care-O-bot 3. These include two color cameras (either of type  or ) and one  time-of-flight sensor from Mesa Imaging or the  sensor. All camera types are supported for Windows and Linux. To enable Windows compatibility, remove all  flags from  located at . The two Prosilica GC1380CH are natively supported by ROS with the  package. The binaries of the  package are executed within the related launch files. The same holds for the Kinect whose driver is located in the  package. Setting the camera parameters for the  and  is different from the suggested ROS standard. Instead of setting all parameters within the ROS launch file, camera specific parameters are set within IPA specific configuration files. This originates from IPA internal requirements to maintain backward compatibility to existing components. The ROS launch file only holds parameters related to the camera setup (e.g. specifying the used camera types) and a link to the IPA internal configuration file. In order to launch the camera nodes, do the following (Replace  with your personal Care-O-bot identifier) For quitting do not close the viewer window, but hit  on your console For quitting do not close the viewer window, but hit  on your console The IPA configuration file is located at  in a folder related to your sensor setup e.g.  or . The configuration is XML-based. It holds one XML-tag for each camera e.g.  for a AVT Pike C145 camera. The number within the tag-name is used to differentiate several camera of the same type. Here is an excerpt from the IPA configuration file of one of our Care-O-bots. Camera intrinsics may be set for each camera within the designated tags. The information is later published with the images using the ROS  from the  package. The user has the possibility of specifying different intrinsic for one camera. This is related to stereo vision, where intrinsics are optimize to fit to another camera. Within the ROS node that publishes camera images, the non-optimized intrinsic are published with the images. Extrinsic specify the rotation and translation relative to another camera. These parameters are not yet published and for IPA internal usage only. For each camera there is also a related  tag. This is also related to backward compatibility issues and not used within ROS. Originally, it provided support for loading saved image data from disk and using it as if it came from a real camera device. However, ROS already provides more sophisticated means to record and play back data using  and . ROS launch files are located in  and hold information about the overall sensor setup not related to a specific camera. There is a launch file to start each camera independently () and a launch file to start all Care-O-bot cameras at once (). Before you can start these launch files, you have to specify your robot id via  for example. Each launch file specifies the location of the related IPA configuration file and the used color camera or time-of-flight camera type. The robot specific launch and configuration files are located in the  folders. The following camera types are supported: The Prosilica GC1380CH color camera is supported through the ROS  package. To get more information, have a look at their tutorial. The camera specific launch files have an additional parameter specifying the camera's ID which is related to the number within the tag-name in the IPA configuration file e.g. . A detailed guide for configuring and starting the stereo pair of  cameras can be found in the . A detailed guide for configuring and starting the stereo pair of  cameras can be found in the . Instructions for the usage of the Swissranger 3000 or 4000 sensor mounted on the Care-O-Bot can be found at . Instructions for the usage of the Microsoft Kinect sensor mounted on the Care-O-Bot can be found at . -D__LINUX__cob3-2CTRL-CCTRL-C/stereo/left/image_color/stereo/left/camera_info/stereo/right/image_color/stereo/right/camera_info/cam3d/depth/camera_info/cam3d/depth/image/cam3d/depth/points/cam3d/rgb/camera_info/cam3d/rgb/image_color/cam3d/rgb/image_mono/cam3d/rgb/points~ip_addressstr~trigger_modestr<AVTPikeCam_0><VirtualXXXCam_X>cob_driver/cob_camera_sensors/ros/launchcam3d.launch, left.launch, right.launchall_cameras.launchexport ROBOT=cob3-1cob_driver/cob_camera_sensors/ros/launch/$ROBOTexport ROBOT=cob3-2
roslaunch cob_camera_sensors all_cameras.launchroslaunch cob_camera_sensors left.launch
roslaunch cob_camera_sensors right.launchroslaunch cob_camera_sensors cam3d.launchrosrun image_view image_view image:=/stereo/left/image_colorrosrun image_view image_view image:=/stereo/right/image_colorroslaunch cob_camera_sensors tof_camera_viewer.launch<!-- Camera sensors initialization file -->
<LibCameraSensors>

<AVTPikeCam_0>
  <!-- Holds the 64-Bit GUID of a connected node -->
  <!-- A GUID consists of a 32-Bit high part that holds the VendorId (Highest 24 Bits) -->
  <!-- and the ChipIdHigh (8 Bits) and a 32-Bit low part that holds the ChipIdLow. -->
  <!-- The GUID is unique for all FireWire devices on the world. -->
  <GUID high=""000A4701"" low=""10077005"" />

  <!-- The master initializes and releases the camera library and is -->
  <!-- respnsible for emitting the trigger signal to other cameras -->
  <!-- The slave is synchronizing its image acquisition with the trigger signal -->
  <!-- Valid roles: MASTER oR SLAVE -->
  <Role value=""MASTER"" />

  <!-- Valid values: appropriate framerte or AUTO and DEFAULT -->
  <FrameRate fps=""3"" />

    <!-- Valid values: FORMAT_0, FORMAT_1, FORMAT_2 ,FORMAT_7, DEFAULT-->
  <VideoFormat type=""FORMAT_7"" />

  <!-- Valid values: MODE_0 - MODE_7, DEFAULT -->
  <VideoMode type=""MODE_0"" />
  ...
<AVTPikeCam_0/>
<LibCameraSensors/>"
W2385,https://wiki.ros.org/dynamixel_driver,Wiki,dynamixel_driver,"This package provides low level IO for Robotis Dynamixel servos.
    Fully supports and was tested with AX-12, AX-18, RX-24, RX-28,
    MX-28, RX-64, EX-106 models. Hardware specific constants are
    defined for reading and writing information from/to Dynamixel
    servos. This low level package won't be used directly by most
    ROS users. The higher level dynamixel_controllers and specific
    robot joint controllers make use of this package."
W2386,https://wiki.ros.org/concert_service_msgs,Wiki,concert_service_msgs,Messages used by official rocon services.
W2387,https://wiki.ros.org/control,Wiki,control,"control 

  "
W2388,https://wiki.ros.org/brics_actuator,Wiki,brics_actuator,Message defined in the BRICS project
W2389,https://wiki.ros.org/collada_parser,Wiki,collada_parser,"This package contains a C++ parser for the Collada robot
    description format. The parser reads a Collada XML robot
    description, and creates a C++ URDF model. Although it is possible
    to directly use this parser when working with Collada robot
    descriptions, the preferred user API is found in the urdf package. 
The code API for this package is for internal use only.  Please use the  package instead. "
W2390,https://wiki.ros.org/dwb_local_planner,Wiki,dwb_local_planner,Plugin based local planner implementing the nav_core2::LocalPlanner interface. 
W2391,https://wiki.ros.org/console_bridge,Wiki,console_bridge,"Lightweight tool for forwarding output from libraries to other logging systems. console_bridge  Mirza Shah (), Ioan Sucan ()  Ioan Sucan ()   
 is a ROS-independent, pure CMake (i.e. non-catkin and non-rosbuild package) that provides logging calls that mirror those found in , but for applications that are not necessarily using ROS.   

Normally in ROS C++ code, developers can log data via  using the macros ROS_DEBUG, ROS_INFO, ROS_WARN, and ROS_ERROR. These logging messages are not only outputted to the screen (depending on log level of course), but are also published to  so that other ROS nodes can subscribe to them. Applications like  and its predecessor  provide graphical interfaces for seeing logs during application runtime. Once you use , the implementations of  will simply become equivalent to  respectively. /rosoutlogDebug, logInform, logWarn, and logErrorROS_DEBUG, ROS_INFO, ROS_WARN, and ROS_ERRORlogDebug  -- ROS_DEBUG
logInform -- ROS_INFO
logWarn   -- ROS_WARN
logError  -- ROS_ERROR$ git clone git://github.com/ros/console_bridge.git
$ cd console_bridge
$ cmake .
$ make
$ sudo make install"
W2392,https://wiki.ros.org/cob_twist_controller,Wiki,cob_twist_controller,"The main purpose of the cob_twist_controller is to convert target twists into joint velocities. 
  Therefore it makes use of several implemented inverse kinematics approaches at the first order differential level. 
  The inverse differential kinematics solver considers kinematic chain extensions, singularity robustness, 
  redundancy resolution and priority-based methods.
  To avoid hardware destruction there is a limiter interface active as well. 
  Via parameter server users can dynamically configure the solving strategy."
W2393,https://wiki.ros.org/control_msgs,Wiki,control_msgs,"control_msgs contains base messages and actions useful for
    controlling robots.  It provides representations for controller
    setpoints and joint and cartesian trajectories.
"
W2394,https://wiki.ros.org/cob_control_mode_adapter,Wiki,cob_control_mode_adapter,The cob_control_mode_adapter package provides a node that automatically loads respective ros_controllers depending on required control mode.
W2395,https://wiki.ros.org/common_tutorials,Wiki,common_tutorials,"Metapackage that contains common tutorials

  "
W2396,https://wiki.ros.org/bwi_services,Wiki,bwi_services,High-level services for the UTexas Building-Wide Intelligence project.
W2397,https://wiki.ros.org/compressed_image_transport,Wiki,compressed_image_transport,"Compressed_image_transport provides a plugin to image_transport for transparently sending images
    encoded as JPEG or PNG.
 is a plugin package for . It enables any node using  classes to publish and subscribe to compressed image topics. Compression format (JPEG or PNG) and quality can be changed on the fly.  




See  for general instruction on using .  is featured in the  tutorial . Some cameras (particularly webcams) output their image data already in JPEG format. When writing a driver for such a camera, a quick and dirty approach is to simply copy the JPEG data into a  message and publish it on a topic of the form . Then any ROS node using  can subscribe to  with transport , just as if  were used on the publisher side. Of course, the other transport topics (including  itself) will not be available. compressed_image_transportimage_transportimage_transportcompressed_image_transportimage_transport<base_topic>/compressed<base_topic>/image/compressed_image_transport_jpeg_quality/image/compressed_image_transport_jpeg_quality<base_topic>/compressed_image_transport_formatstring<base_topic>/compressed_image_transport_jpeg_qualityint<base_topic>/compressed_image_transport_png_levelint<base_topic>/compressed/formatstring<base_topic>/compressed/jpeg_qualityint<base_topic>/compressed/png_levelint<base_topic>/compressedimage_raw/compressedimage_rawcompressedimage_transportimage_raw"
W2398,https://wiki.ros.org/driver_base,Wiki,driver_base,"A framework for writing drivers that helps with runtime reconfiguration, diagnostics and self-test.

    This package is deprecated.
This package is for internal use only. Its API is stable, but  recommended for use by new packages. "
W2399,https://wiki.ros.org/collada_urdf,Wiki,collada_urdf,"This package contains a tool to convert Unified Robot Description Format (URDF) documents into COLLAborative Design Activity (COLLADA) documents.

    Implements robot-specific COLLADA extensions as defined by
    http://openrave.programmingvision.com/index.php/Started:COLLADA


The urdf_to_collada tool will convert  files into COLLADA  files. .urdf.daerosrun collada_urdf urdf_to_collada <input-urdf> <output.dae>rosrun collada_urdf urdf_to_collada pr2.urdf pr2.daerosrun collada_urdf collada_to_urdf <input.dae> <output.urdf>"
W2400,https://wiki.ros.org/clearpath_base,Wiki,clearpath_base,"
     The base drivers needed to connect with the onboard system for all Clearpath Robotics platforms.
  Newly proposed, mistyped, or obsolete package. Could not find package ""clearpath_base"" in rosdoc: /home/rosbot/docs/api/clearpath_base/manifest.yaml "
W2401,https://wiki.ros.org/cob_light,Wiki,cob_light,"This package contains scripts to operate the LED lights on Care-O-bot.


The  package provides a node that connects to the light hardware board and offers a message interface over . The current state of the light is published as a . 
cob_light.pycommandmarker~devicestringstring~baudrateintroslaunch cob_bringup light.launch<include file=""$(find cob_bringup)/components/light.launch"" />devicestring: /dev/ttyUSB3
baudrate: 230400rosrun cob_light test.py"
W2402,https://wiki.ros.org/dnn_detect,Wiki,dnn_detect,"DNN based detection



A camera node, such as  needs to be running Then  can be launched: /camera/dnn_objects/dnn_images~detect~single_shotbooldetect~publish_imagesbool~data_dirstring~protonet_filestringdata_dir~caffe_model_filestringdata_dir~min_confidencefloat~im_sizeint~scale_factorfloat~mean_valfloat~class_namesstringdnn_detectsudo apt install ros-kinetic-dnn-detectrosrun usb_cam usb_cam_noderoslaunch dnn_detect dnn_detect.launch camera:=/usb_cam image:=image_rawrostopic echo /dnn_objects"
W2403,https://wiki.ros.org/capabilities,Wiki,capabilities,"Package which implements capabilities, including code to parse capability interface specs, to parse capability provider specs, and implement the capability server.





There are tutorials located here:  The provided (Python) API can be used to discover local packages which define one or more of the spec files defined by this package, load them, and interact with them. It also provides an API to discover what capabilities are provided by a  running on a remote machine, which is useful for tools like the  plugin. This package provides the  ROS node which loads all capability spec files from packages on the  and provides a ROS interface for querying and running those capabilities. The  is documented in the CodeAPI (linked to on the right). capability_servercapability_serverROS_PACKAGE_PATHcapability_server"
W2404,https://wiki.ros.org/dynamicvoronoi,Wiki,dynamicvoronoi,"


This package provides software to compute and update Euclidean distance maps (DM) and Euclidean Voronoi diagrams (GVD) on 2D grid maps.

The program is initialized with a binary occupancy grid map and computes the corresponding DM and GVD. When provided with points that mark newly occupied or freed cells, the DM and GVD can be updated efficiently to reflect the changes in the environment.

Details on the algorithms can be found in the corresponding paper. Please cite the paper if you use it for scientific work:
B. Lau, C. Sprunk and W. Burgard, Improved Updating of Euclidean Distance Maps and Voronoi Diagrams, IEEE Intl. Conf. on Intelligent Robots and Systems (IROS), Taipei, Taiwan, 2010.
See also 
"
W2405,https://wiki.ros.org/bwi_interruptable_action_server,Wiki,bwi_interruptable_action_server,"This wraps the move_base node from the standard ROS navigation
    stack. The purpose of the interruptable navigator is to allow
    seamless multi-robot interactions by temporarily interrupting
    robots and diverting them when two robots are about to collide."
W2406,https://wiki.ros.org/concert_service_gazebo,Wiki,concert_service_gazebo,"Sets up the gazebo robot manager as a service to assist in spawning/killing robots as concert clients.



An example is available in the  package. RobotManager/services/<service-name>//use_sim_timetrue"
W2407,https://wiki.ros.org/cob_relayboard,Wiki,cob_relayboard,cob_relayboard 
W2408,https://wiki.ros.org/csm,Wiki,csm,"This is a ROS 3rd-party wrapper  of Andrea Censi's CSM package. 

    From :
    

 Please submit your tickets through  (requires github account) or by emailing the maintainers. "
W2409,https://wiki.ros.org/costmap_prohibition_layer,Wiki,costmap_prohibition_layer,"ROS-Package that implements a costmap layer to add prohibited areas to the costmap-2D by a user configuration.
 If used in combination with a local costmap, make sure that the global-frame parameter of the local costmap coincides with global costmap's parameter. Furthermore, the global-frame should be fixed (e.g. /map and not /odom), since currently no coordinate transformations are performed internally. 


The costmap2D from ros is able to add plugins (see ). In step two you see how to add the YAML file to the parameters. If you're doing this in the launch file of the move base, you should load them into the namespace . The underlayed namespace ( should accord with the plugin name, defined in the next step: In step three it is described how to add the plugin itself. For this plugin you have to add: prohibition_areas:
 # your first prohibited area is only a point
 - [17.09, -6.388]
 # now we define a line
 # it will become the thickness of the costmap resolution
 - [[8.33, 2.11],
    [8.26, 5.11]]
 # and last but not least a polygon with an individual number of points
 - [[-11.15, -15.614],
    [-12.35, -13.89],
    [-10.05, -12.218]]   plugins:
     # ... your own plugins     
     - {name: costmap_prohibition_layer,       type: costmap_prohibition_layer_namespace::CostmapProhibitionLayer""}"
W2410,https://wiki.ros.org/cob_phidgets,Wiki,cob_phidgets,"cob_phidgets

Make sure your user is in the group ""dialout"" with . groupssudo echo 'SUBSYSTEM==""usb"", ATTRS{idVendor}==""06c2"", MODE=""0666"", GROUP=""dialout""' >>  /etc/udev/rules.d/10-persistent-usb.rules && sudo chmod a+r /etc/udev/rules.d/10-persistent-usb.rules && sudo udevadm control --reload-rules "
W2411,https://wiki.ros.org/compressed_depth_image_transport,Wiki,compressed_depth_image_transport,"Compressed_depth_image_transport provides a plugin to image_transport for transparently sending
    depth images (raw, floating-point) using PNG compression.
 is a plugin package for . It enables any node using  classes to publish and subscribe to compressed depth image/map topics. Compression parameters can be changed on the fly using the dynamic_reconfigure package.  works only with floating-point or 16-bit integer encoded depth images.  



See  for general instruction on using .  works similar to  which is featured in the  tutorial . compressed_depth_image_transportimage_transportcompressed_depth_image_transportimage_transportcompressed_depth_image_transportcompressed_image_transportimage_transport<base_topic>/compressedDepth<base_topic>/compressed/formatstring<base_topic>/compressed/jpeg_qualityint<base_topic>/compressed/png_levelint<base_topic>/compressedDepth"
W2412,https://wiki.ros.org/diagnostic_common_diagnostics,Wiki,diagnostic_common_diagnostics,"diagnostic_common_diagnostics

diagnosticsrosrun diagnostic_common_diagnostics ntp_monitor.py -hdiagnosticssensorsdiagnostics~ignore_fansbooltfdiagnostics"
W2413,https://wiki.ros.org/concert_service_indoor_2d_map_prep,Wiki,concert_service_indoor_2d_map_prep,Services to initilise indoor 2d map environment. Make a map and annotation
W2414,https://wiki.ros.org/calibration,Wiki,calibration,"Provides a toolchain running through the robot calibration process. This
     involves capturing calibration data, estimating parameters, and
     then updating the URDF.


Documentation is coming for setting up your own robot. See  or  package for an example Please report bugs at:  - hg:
    local-name: calibration
    uri: 'http://kforge.ros.org/calibration/calibration'
- hg:
    local-name: pr2_calibration
    uri: 'http://kforge.ros.org/calibration/pr2_calibration'
- svn:
    local-name: pr2_common
    uri: 'https://code.ros.org/svn/wg-ros-pkg/stacks/pr2_common/trunk'
- other:
    local-name: /opt/ros/electric/ros
- other:
    local-name: /opt/ros/electric/stacksrosinstall PATH new_calibration.rosinstall
rosmake pr2_calibration"
W2415,https://wiki.ros.org/concert_master,Wiki,concert_master,The ros master at the heard of the concert subsystem along with a few utility functions.
W2416,https://wiki.ros.org/camera1394,Wiki,camera1394,"ROS driver for devices supporting the IEEE 1394 Digital Camera
    (IIDC) protocol. Supports the ROS image_pipeline, using libdc1394
    for device access.









 
 


This package provides a ROS interface for digital cameras meeting the  using , which supports . Of the thousands of IIDC models, we are accumulating a  with this driver. It works with the ROS  like other streaming . For help, please check . If your question is not answered, open a new one with the  tag, so we can see it and respond. To report problems or request new features:  The  driver was first released with ROS C-Turtle. That API is stable. Additional features have been added since. They are all compatible with the previous release, except for the default  value. By default,  requires the message timestamps for both images to match exactly, which the  driver cannot do. The Diamondback release of  provided a solution for this problem (enhancement ). The  had some significant limitations. Some have been removed in later releases. Please check the specific documentation for that release, if you are still using ROS C-Turtle. For each supported feature there is a corresponding  parameter providing user control. Different cameras handle these controls in various ways. When setting an IIDC feature to a specific value, it is necessary to set the corresponding control state to  (3), otherwise the corresponding value will be ignored unless the device is already in the  state when the driver starts. For example, to set  to 256 on the command line: Many IIDC cameras use  to provide color information. For cameras of this type, set  to an appropriate  value, and select the correct . If the  is , all  images are monochrome. Best performance is likely to come from using the default  method while running  and  nodelets both in a single process (see the  example below). In both cases the  image stream is compatible with the ROS . Format7 parameters specify image size, position and pixel format. Some Format7 modes may provide binning, combining groups of hardware pixels into a single image pixel. The Format7 Region of Interest (ROI) selects a rectangular subset from the full hardware image. These options sometimes allow the camera to send images at a faster rate. (The  parameter has no effect in Format7.) With an available  selected, a number of Format7-specific parameters  be supported, depending on the device: All these parameters are ignored when  is not one of the Format7 options. This driver publishes the same topics and provides the same parameters as the  version. Run a standalone , this behaves almost the same as running .   For that, see the following example. To run the driver nodelet and  all in a single address space with zero-copy message passing between those nodelets, use a  like this: Depending on specific needs, some of the  nodelets could be omitted. But, they do not incur much overhead when not being used. camera1394reset_on_openreset_on_openFalsevideo_modeframe_ratecamera1394camera1394stereo_image_procauto_brightnessvideo_modemono8bayer_patternbayer_pattern""""mono8bayer_method""""bayer_methodbayer_decodingimage_proc/debayercamera1394/drivercamera/image_rawimage_pipeline~frame_ratevideo_mode~binning_x~binning_y~roi_width~roi_height~x_offset~y_offset~format7_color_codingraw8~bayer_method~bayer_patternvideo_modecamera/image_rawcamera/camera_infocamera/image_rawvideo_modediagnosticscamera/set_camera_info~guidstr~reset_on_openbool~video_modestr~frame_idstr~frame_ratedouble~iso_speedint~camera_info_urlstr~binning_xint~binning_yint~roi_widthint~roi_heightint~x_offsetint~y_offsetint~format7_packet_sizeint~format7_color_codingstr~bayer_patternstr~bayer_methodstr~auto_brightnessint~brightnessdouble~auto_exposureint~exposuredouble~auto_focusint~focusdouble~auto_gainint~gaindouble~auto_gammaint~gammadouble~auto_hueint~huedouble~auto_irisint~irisdouble~auto_saturationint~saturationdouble~auto_sharpnessint~sharpnessdouble~auto_shutterint~shutterdouble~auto_white_balanceint~white_balance_BUdouble~white_balance_RVdouble~auto_zoomint~zoomdouble~num_dma_buffersint~max_consecutive_errorsintcamera1394_nodeletcamera1394_nodeimage_proc$ rosrun camera1394 camera1394_node _auto_brightness:=3 _brightness:=256.0$ rosrun nodelet nodelet standalone camera1394/driver<launch>

  <!-- nodelet manager process -->
  <node pkg=""nodelet"" type=""nodelet"" name=""camera_nodelet_manager""
        args=""manager"" />

  <!-- camera driver nodelet -->
  <node pkg=""nodelet"" type=""nodelet"" name=""camera1394_nodelet""
        args=""load camera1394/driver camera_nodelet_manager"" />
    
  <!-- Bayer color decoding -->
  <node pkg=""nodelet"" type=""nodelet"" name=""image_proc_debayer""
        args=""load image_proc/debayer camera_nodelet_manager"">
    <remap from=""image_color"" to=""camera/image_color"" />
    <remap from=""image_mono"" to=""camera/image_mono"" />
    <remap from=""image_raw"" to=""camera/image_raw"" />
  </node>

  <!-- mono rectification -->
  <node pkg=""nodelet"" type=""nodelet"" name=""image_proc_rect""
        args=""load image_proc/rectify camera_nodelet_manager"">
    <remap from=""image_mono"" to=""camera/image_mono"" />
    <remap from=""image_rect"" to=""camera/image_rect"" />
  </node>

  <!-- color rectification -->
  <node pkg=""nodelet"" type=""nodelet"" name=""image_proc_rect_color""
        args=""load image_proc/rectify camera_nodelet_manager"">
    <remap from=""image_mono"" to=""camera/image_color"" />
    <remap from=""image_rect"" to=""camera/image_rect_color"" />
  </node>

</launch>"
W2417,https://wiki.ros.org/bond_core,Wiki,bond_core,"A bond allows two processes, A and B, to know when the other has
    terminated, either cleanly or by crashing. The bond remains
    connected until it is either broken explicitly or until a
    heartbeat times out.
: the bond packages are now part of bond_core.  In previous releases, they were part of . 
  Groovy and above, please use the infrastructure at:  "
W2418,https://wiki.ros.org/calibration_estimation,Wiki,calibration_estimation,"Runs an optimization to estimate the a robot's kinematic parameters. This package is a
    generic rewrite of pr2_calibration_estimation."
W2419,https://wiki.ros.org/bwi_mapper,Wiki,bwi_mapper,"Mapping package that provides utilties for handling ROS 
    style maps. Also provides functions for generating topological graphs from 
    pixel maps."
W2420,https://wiki.ros.org/catkin_virtualenv,Wiki,catkin_virtualenv,Bundle python requirements in a catkin package via virtualenv.See  for package documentation. 
W2421,https://wiki.ros.org/bwi_logging,Wiki,bwi_logging,Logging package that creates ROS bag files
W2422,https://wiki.ros.org/catkin,Wiki,catkin,"Low-level build system macros and infrastructure for ROS.

 Catkin is included by default when ROS is installed. Catkin can also be installed from source or prebuilt packages. Most users will want to use the prebuilt packages, but installing it from source is also quite simple. 









 For an explanation of the design goals and design decisions, in addition to the rationale for why Catkin ("""") was created, see the  page. If you are using a ROS binary distribution (Groovy or higher) on Ubuntu then you can install catkin with : If you are  on Ubuntu you can install  from  via pip. See  See the external  containing: See  apt-getcatkin_pkgcmake -DCMAKE_BUILD_TYPE=Release ../RelWithDebInfoDebugReleasesudo apt-get install ros-$ROS_DISTRO-catkinsudo apt-get install cmake python-catkin-pkg python-empy python-nose python-setuptools libgtest-dev build-essentialmkdir build && cd build && cmake ../ && make && sudo make install"
W2423,https://wiki.ros.org/cob_script_server,Wiki,cob_script_server,"The cob_script_server package provides a simple interface to operate Care-O-bot. It can be used via the python API or the actionlib interface.






This package was created to be used with Care-O-bot but is not limited to one specific robot. It can be used for a real robot as well as for a simulated one (see ). This package provides all methods as a python API (see ). The table below shows a summary of the most important commands and their parameters. Each of the above function (except , which returns the keyboard input) returns a handle which offers the following commands.  you can access all script_server commands in an ipython terminal with the prefix , e.g. All functions from the python API are also available as  calls. All the parameters that are loaded in the name space /script_server are defined in .yaml files in the package . Tutorials can be found on the . init()sss.init(""base"")recoversss.recover(""base"")stopsss.stop(""base"")movesss.move(""torso"",""front"")movesss.move(""torso"",  [[0, 0, 0, 0],  [0.1, 0, 0.2, 0],  [...], ...])movesss.move(""base"",""home"")movesss.move(""base"",[0, 0, 0])move_base_relsss.move_base_rel(""base"",[0, 0, 1.57])sleepsss.sleep(2.0)wait_for_inputret = sss.wait_for_input()saysss.say(""sentence1"")saysss.say([""Hello.""])set_lightsss.set_light(""red"")set_lightsss.set_light([0.5,0.5,0.5])wait_for_inputwait()handle.wait()wait(timeout)handle.wait(2.0)timeoutget_state()handle.get_state()sssscript_server/goalscript_server/resultscript_server/feedbackrosrun cob_script_server cob_consolesss.move(""head"",""front"")roslaunch cob_script_server script_server.launchrosrun cob_script_server test_script.pyrosrun cob_script_server script_viewer.py"
W2424,https://wiki.ros.org/code_coverage,Wiki,code_coverage,CMake configuration to run coverage
W2425,https://wiki.ros.org/cob_description,Wiki,cob_description,"This package contains the description (mechanical, kinematic, visual,
  etc.) of the Care-O-bot robot. The files in this package are parsed and used by
  a variety of other components. Most users will not interact directly
  with this package.






In the package  you can find for each robot the urdf file that load the component descriptions together.  sed -i '0,/RE/s/solid/robot/' */*.stl"
W2426,https://wiki.ros.org/common_rosdeps,Wiki,common_rosdeps,common_rosdeps declares commonly used rosdep system dependencies.
W2427,https://wiki.ros.org/distance_field,Wiki,distance_field,"

This package contains algorithms that can compute the
Euclidean Distance Transform (EDT) of a 3-D voxel grid. The input to these algorithms is
an array of points (which could represent the positions of obstacles in the world). 
The EDT provides a voxel grid in which in which each cell contains the distance to the
closest obstacle. The VoxelGrid class can also be used as a generic, templatized container for a discretized 3-D voxel grid.

  
Further details are available in the . "
W2428,https://wiki.ros.org/camera_calibration,Wiki,camera_calibration,"camera_calibration allows easy calibration of monocular or stereo
     cameras using a checkerboard calibration target.
 will work with any camera driver node satisfying the standard ROS camera interface. See the . 


 supports the following options: 
 
 

 
 This package uses OpenCV camera calibration, described .  For detailed information on the parameters produced by the calibration, see . There are tutorials on how to run the calibration tool for  and  cameras. To run the  node for a monocular camera using an 8x6 chessboard with 108mm squares: To run the  node for a stereo camera: By default, the  assumes that stereo cameras are triggered to capture images simultaneously, and that matching image pairs have identical timestamps. This is the ideal situation, but requires hardware support. To enable approximate timestamp matching, give the  option. This permits a ""slop"" of 0.01s between image pairs. If you still don't see a display window, or it is sporadically updated, try increasing the slop. To use multiple checkerboards, give multiple  and  options for additional boards. Make sure the boards have different dimensions, so the calibration system can tell them apart. camera_calibrationcameracalibrator.pycameracalibrator.pycameracalibrator.pyimage_pipeline--approximate=0.01--size--squarecameracalibrator.pyimageleftrightcamera/set_camera_infoleft_camera/set_camera_inforight_camera/set_camera_infocameracheck.pymonocular/imagemonocular/camera_infostereo/left/imagestereo/right/imagestereo/camera_inforosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/my_camera/image camera:=/my_camerarosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 right:=/my_stereo/right/image_raw left:=/my_stereo/left/image_raw left_camera:=/my_stereo/left right_camera:=/my_stereo/right  Chessboard Options:
    You must specify one or more chessboards as pairs of --size and
    --square options.

    -p PATTERN, --pattern=PATTERN
                        calibration pattern to detect - 'chessboard',
                        'circles', 'acircles'
    -s SIZE, --size=SIZE
                        chessboard size as NxM, counting interior corners
                        (e.g. a standard chessboard is 7x7)
    -q SQUARE, --square=SQUARE
                        chessboard square size in meters

  ROS Communication Options:
    --approximate=APPROXIMATE
                        allow specified slop (in seconds) when pairing images
                        from unsynchronized stereo cameras
    --no-service-check  disable check for set_camera_info services at startup

  Calibration Optimizer Options:
    --fix-principal-point
                        fix the principal point at the image center
    --fix-aspect-ratio  enforce focal lengths (fx, fy) are equal
    --zero-tangent-dist
                        set tangential distortion coefficients (p1, p2) to
                        zero
    -k NUM_COEFFS, --k-coefficients=NUM_COEFFS
                        number of radial distortion coefficients to use (up to
                        6, default 2)rosrun camera_calibration cameracheck.py --size 8x6 monocular:=/forearm image:=image_rectrosrun camera_calibration cameracheck.py --size 8x6 stereo:=/wide_stereo image:=image_rect"
W2429,https://wiki.ros.org/diagnostics,Wiki,diagnostics,"diagnostics





The diagnostics toolchain is built around the  topic. On this topic, hardware drivers and devices publish  messages with the device names, status and specific data points.  The  and  packages allow nodes to collect and publish diagnostics data. The  can categorize and analyze diagnostics at runtime. Operators and developers can view the diagnostics data using the  package. The  package can convert diagnostics logs to CSV files for examination and after-the-fact analysis. To collect and publish diagnostics data, nodes can use tools in the  package. The updater allows nodes, especially hardware drivers, to collect and publish diagnostics data. Using the tools in the updated package, drivers can monitor frequency and connection status. The  package uses the  to perform a self test on a driver, using a special service call. The  package contains tools for categorizing and analyzing diagnostics at runtime. Using a plug-in model, a diagnostic aggregator can be configured for different types of robots to allow simple analysis of diagnostics. It is easy to summarize hundreds of diagnostic items into just a few categories. The diagnostic aggregator plug-ins can allow developers to give users easy to understand messages for common problems. The  package contains the  tool which displays the processed data from a  in graphical form. For robots without a , the  package contains a simple monitor that displays data from the  topic. The tools in  allow users to convert diagnostics bag files into one or more CSV files for plotting or viewing with off-the-shelf spreadsheet software. The  tool allows the bag file to be converted into several CSV files, with each diagnostic status name made into its own file. Further information will be found in the . /diagnosticsrobot_monitordiagnostic_aggregatordiagnostic_aggregator/diagnosticsexport_csv.py"
W2430,https://wiki.ros.org/cob_frame_tracker,Wiki,cob_frame_tracker,The cob_frame_tracker package contains nodes that publish Twist commands based on the distance to the desired tf frame target.
W2431,https://wiki.ros.org/control_toolbox,Wiki,control_toolbox,"The control toolbox contains modules that are useful across all controllers.This package contains several C++ classes useful in writing controllers, and so the main documentation can be found on the . "
W2432,https://wiki.ros.org/diagnostic_updater,Wiki,diagnostic_updater,"diagnostic_updater contains tools for easily updating diagnostics. it is commonly used in device drivers to keep track of the status of output topics, device status, etc.





A working example of a diagnostic_updater can be found in . This example goes through some of the most common uses of an updater. The  class eases the pain of filling out a  message. It handles setting the summary, possibly with -type formatting of the message field, and setting of key-value pairs with type-conversion and formatting of the values. It also has facilities for merging multiple  messages without losing information in the status message. The  class manages a set of diagnostic update functions, and their periodic publication. Monitoring a topic's frequency, a common diagnostics feature, and the validity of its timestamps can be done using pre-packaged diagnostic update functions. A  wraps a Publisher and standard diagnostics that relate to it in a single class. printf"
W2433,https://wiki.ros.org/dynamic_reconfigure,Wiki,dynamic_reconfigure,"This unary stack contains the dynamic_reconfigure package which provides a means to change
    node parameters at any time without having to restart the node.dynamic_reconfigurereconfigure_guireconfigure_guidynparamdynparamdynparam listdynparam getdynparam setdynparam set_from_parametersdynparam dumpdynparam loadlistget node_name-t secsset node_name parameter_name parameter_valueset node_name yaml_dictionary-t secsset_from_parameters node_name-t secsdump node_name file.yaml-t secsload node_name file.yaml-t secsdynamic_reconfigure.clientdynamic_reconfigurereconfigure_guirqtdynparamdynparamdynparam listdynparam getdynparam setdynparam set_from_parametersdynparam dumpdynparam loadlistget node_name-t secsset node_name parameter_name parameter_valueset node_name yaml_dictionary-t secsset_from_parameters node_name-t secsdump node_name file.yaml-t secsload node_name file.yaml-t secsdynamic_reconfigure.client$ rosrun dynamic_reconfigure reconfigure_gui$ rosrun dynamic_reconfigure dynparam COMMAND$ rosrun dynamic_reconfigure dynparam list$ rosrun dynamic_reconfigure dynparam get /node$ rosrun dynamic_reconfigure dynparam set /node parameter_name value$ rosrun dynamic_reconfigure dynparam set wge100_camera ""{'camera_url':'foo', 'brightness':58}"" $ rosrun dynamic_reconfigure dynparam set_from_parameters /node$ rosrun dynamic_reconfigure dynparam dump /node dump.yaml$ rosrun dynamic_reconfigure dynparam load /node dump.yaml$ rosrun dynamic_reconfigure dynparam COMMAND$ rosrun dynamic_reconfigure dynparam list$ rosrun dynamic_reconfigure dynparam get /node$ rosrun dynamic_reconfigure dynparam set /node parameter_name value$ rosrun dynamic_reconfigure dynparam set wge100_camera ""{'camera_url':'foo', 'brightness':58}"" $ rosrun dynamic_reconfigure dynparam set_from_parameters /node$ rosrun dynamic_reconfigure dynparam dump /node dump.yaml$ rosrun dynamic_reconfigure dynparam load /node dump.yaml"
W2434,https://wiki.ros.org/camera_calibration_parsers,Wiki,camera_calibration_parsers,"camera_calibration_parsers contains routines for reading and writing camera calibration parameters.
 contains C++ functions for reading and writing camera parameters. These are mainly used internally by camera drivers and camera calibration tools, but the formats are human-readable. 





 


For usage, see the . camera_calibration_parsers$ rosrun  camera_calibration_parsers convert  in-file out-file$ rosrun  camera_calibration_parsers convert  cal.yml cal.ini$ mv ost.txt ost.ini
$ rosrun  camera_calibration_parsers convert  ost.ini cal.yml# Prosilica camera intrinsics

[image]

width
2448

height
2050

[prosilica]

camera matrix
4827.93789 0.00000 1223.50000
0.00000 4835.62362 1024.50000
0.00000 0.00000 1.00000

distortion
-0.41527 0.31874 -0.00197 0.00071 0.00000

rectification
1.00000 0.00000 0.00000
0.00000 1.00000 0.00000
0.00000 0.00000 1.00000

projection
4827.93789 0.00000 1223.50000 0.00000
0.00000 4835.62362 1024.50000 0.00000
0.00000 0.00000 1.00000 0.00000image_width: 2448
image_height: 2050
camera_name: prosilica
camera_matrix:
  rows: 3
  cols: 3
  data: [4827.94, 0, 1223.5, 0, 4835.62, 1024.5, 0, 0, 1]
distortion_model: plumb_bob
distortion_coefficients:
  rows: 1
  cols: 5
  data: [-0.41527, 0.31874, -0.00197, 0.00071, 0]
rectification_matrix:
  rows: 3
  cols: 3
  data: [1, 0, 0, 0, 1, 0, 0, 0, 1]
projection_matrix:
  rows: 3
  cols: 4
  data: [4827.94, 0, 1223.5, 0, 0, 4835.62, 1024.5, 0, 0, 0, 1, 0]"
W2435,https://wiki.ros.org/ecl_converters,Wiki,ecl_converters,"Some fast/convenient type converters, mostly for char strings or strings.
     These are not really fully fleshed out, alot of them could use the addition for
     the whole range of fundamental types (e.g. all integers, not just int, unsigned int).
     
     They will come as the need arises.





"
W2436,https://wiki.ros.org/cob_srvs,Wiki,cob_srvs,"This Package contains Care-O-bot specific service definitions.
"
W2437,https://wiki.ros.org/dynamixel_sdk,Wiki,dynamixel_sdk,"This package is wrapping version of ROBOTIS Dynamixel SDK for ROS. The ROBOTIS Dynamixel SDK, or SDK, is a software development library that provides Dynamixel control functions for packet communication. The API is designed for Dynamixel actuators and Dynamixel-based platforms. 
   



This package wraps the  to be available for ROS. The ROBOTIS Dynamixel SDK is a software development library that provides Dynamixel control functions for packet communication. The API is designed for Dynamixel actuators and Dynamixel-based platforms. "
W2438,https://wiki.ros.org/cob_sound,Wiki,cob_sound,"This package implements a sound play module using text2wave and aplay through python.





By default  is used.  For  you need to buy a license key.  Download and install voice. Adopted from . * apply fix for Ubuntu > 12.04 * Register voice with license (you need to buy a license from , for IPA robots ask UHR or FMW for license key) roslaunch cob_sound sound.launchrosservice call /sound/say ""Hello, my name is Care-O-bot.""rosservice call /sound/mute
rosservice call /sound/unmuterosparam set /sound/mode cepstralwget http://www.cepstral.com/downloads/installers/linux32/Cepstral_David_i386-linux_6.2.3.873.tar.gz
wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_David_x86-64-linux_6.2.3.873.tar.gzwget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Diane_i386-linux_6.2.3.873.tar.gz
wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Diane_x86-64-linux_6.2.3.873.gzwget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Matthias_i386-linux_6.2.3.873.tar.gz
wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Matthias_x86-64-linux_6.2.3.873.tar.gzwget http://www.cepstral.com/downloads/installers/linux32/Cepstral_Katrin_i386-linux_6.2.3.873.tar.gz
wget http://www.cepstral.com/downloads/installers/linux64/Cepstral_Katrin_x86-64-linux_6.2.3.873.tar.gztar xzvf Cepstral_David_x86-64-linux_6.2.3.873.tar.gz
cd Cepstral_David_x86-64-linux_6.2.3.873
sudo ./install.sh
sudo touch /etc/ld.so.conf.d/cepstral.conf
sudo sh -c 'echo ""/opt/swift/lib"" > /etc/ld.so.conf.d/cepstral.conf'
sudo ldconfigroscd cob_sound
sudo ./fix_swift_for_precise.shsudo apt-get install alsa-ossif test -x /usr/bin/padsp ; then  exec aoss /opt/swift/bin/swift ""$@"" ; else  exec /opt/swift/bin/swift ""$@"" ; fisudo swift --reg-voicealsamixeramixer -c 1 set Speaker xx%amixer -c 1 set PCM xx%sudo alsactl store"
W2439,https://wiki.ros.org/common_msgs,Wiki,common_msgs,"common_msgs contains messages that are widely used by other ROS packages.
    These includes messages for
    actions (),
    diagnostics (),
    geometric primitives (),
    robot navigation (),
    and common sensors (), such as laser range finders, cameras, point clouds.










  This is a summary of the  and  types available in the various ROS  in the  stack. For more documentation, please see the relevant package. Please see  for documentation on the standard units of measure and coordinate conventions followed here. Please see the . common_msgs"
W2440,https://wiki.ros.org/ecl_exceptions,Wiki,ecl_exceptions,"Template based exceptions - these are simple and practical
     and avoid the proliferation of exception types. Although not
     syntatactically ideal, it is convenient and eminently practical.








If outside ros, you will also need to link to . These are in . src/examples/exceptions.cppsrc/examples/exception_tracer.cpp/src/benchmarks/exceptions.cpp










"
W2441,https://wiki.ros.org/ecl_build,Wiki,ecl_build,"Collection of cmake/make build tools primarily for ecl development itself, but also
     contains a few cmake modules useful outside of the ecl."
W2442,https://wiki.ros.org/cob_base_drive_chain,Wiki,cob_base_drive_chain,"This package contains classes that are able to control the platform of the Care-O-Bot. This means to establish a CAN communication to drive and steering motors of the platform and later send motion commands and receive motor information.





 To keep the communication with the Care-O-Bot platform variable (as different motors or CAN-hardware could be used),  implements the communication to different motors through a generic interface  and for different CAN modules through . The used CAN module is specified in an .ini-File, as well as motor-specific parameters. Each motor-object is loaded with appropriate parameters and during initialization each wheel is homed. After initialization, the user can easily command the platform using the provided functions of  like . It is implemented in  and again provided to the ROS network via services. To use the Elmo Recorder without the services, you can use the interface of  directly as desribed below. There are two other levels of “user”-interfaces, to keep the drive interface-classes slight. The function  basically is just a wrapper function for the main Elmo-Recorder interface in . With these arguments you can control all of the Recorders features.  specifies the general task, you are going to set up: To avoid that effect, the user only has to start-up the read-out process. From then, the transfer process is running autonomously, triggered by the receive of data packets, which are led to the appropriate functions after having been fetched from the CAN-buffer. During such a segmented SDO transfer, the data is collected in the  collection class. It also holds some SDO-transfer-specific features like the state of the transmission. When receiving the last segment of a transfer, the collected data is handed to an adequate processing function. In our case, it's . Finally, the collected data is saved to a file; you also could imagine of keeping it temporarily in a variable to give the calling function the opportunity to process the data itself. How to read out data from the Elmo Recorder is described in . cob_base_drive_chain::CanCtrlPltfCOb3cob_canopen_motor::CanDriveItfcob_generic_can::CanItfcob_base_drive_chain::CanCtrlPltfCOb3setVelGearRadSjoint_commandJointStateDiagnosticInitResetShutdownGetJointStateElmoRecorderConfigElmoRecorderReadoutcob_base_drive_chain::CanCtrlPltfCOb3cob_base_drive_chain::CanCtrlPltfCOb3CanCtrlPltfCOb3::ElmoRecordingscob_canopen_motor::CanDriveHarmonica::setRecorder(int iFlag, int iParam, std::string sParam)iFlagiFlag = 0iFlag = 1iFlag = 2iFlag = 99cob_canopen_motor::SDOSegmentedElmoRecorder::processData()"
W2443,https://wiki.ros.org/boost_numpy,Wiki,boost_numpy,Python wrappers for converting Boost C++ datatypes into Numpy objects.
W2444,https://wiki.ros.org/calibration_msgs,Wiki,calibration_msgs,"This package defines messages for storing calibration samples
     to be used in full robot calibration procedures. This package
     is still unstable. Expect the messages to change.
"
W2445,https://wiki.ros.org/convex_decomposition,Wiki,convex_decomposition,"Convex Decomposition Tool for Robot Model
This is a thirdparty package with . convex_decompositionconvex_decompositionconvex_decomposition"
W2446,https://wiki.ros.org/driver_common,Wiki,driver_common,"The driver_common stack contains classes and tools that are useful
    throughout the driver stacks. It currently contains:

    driver_base: A base class for sensors to provide a consistent state machine
    (retries, error handling, etc.) and interface

    timestamp_tools: Classes to help timestamp hardware events
: the  package (formerly part of this stack) became a separate stack. 
Use GitHub to . []
  "
W2447,https://wiki.ros.org/bwi_planning,Wiki,bwi_planning,"The planner_krr14 package


Use GitHub to . []
 This package is now . A newer version is now in the  package: "
W2448,https://wiki.ros.org/diagnostic_aggregator,Wiki,diagnostic_aggregator,"diagnostic_aggregator














The  contains a ROS node, , that listens to  messages on the  topic, processes and categorizes the data, and republishes on . The  loads ""Analyzer"" plugins to perform the diagnostics processing and categorization. The configuration and setup for each diagnostic aggregator is specific to each robot and can be determined by users or developers. The two analyzers in this package,  and , hold and categorize diagnostic messages. They're useful for categorizing components or systems. They can warn when an item is stale, but do not do additional analysis of the diagnostics. Other analyzers can be loaded as plugins by the  on startup. The aggregated diagnostic output can be displayed in the  tool. The  displays these messages in a hierarchical format. To determine the hierarchy, the diagnostic aggregator prepends diagnostic status names with a path, joined with ""/"". For example: This shows how an  might categorize and analyze diagnostics data from a simple robot. Using the diagnostic aggregator, we can move these diagnostic messages into easy to understand categories to display in our . To do this, just prepend the name of the category to the status names, and separate them with ""/"". The  will load analyzers to store and process the diagnostic data. Each analyzer inherits from the base class . Analyzers must be in packages that depend directly on  and . The base analyzer class is the pure virtual  class. All derived classes must implement these methods: Analyzers can choose the error state for any  message they analyze and report. Generally, the ""parent"" of an analyzer has an error state of the maximum of its children, but some analyzers may have more advanced methods. The analyzers are responsible for correctly setting the names of each item they analyze. The  does not do any checking or enforcement of the diagnostic status name hierarchy. Users can create Analyzers to load as plugins for different robots. See the tutorial  for details. For a full tutorial, see the tutorial . Under each sub namespace under , a different analyzer is configured. Analyzers can be robot specific, or they can be general purpose ones like the . Each analyzer needs a special parameter, , in the namespace. The  parameter gives the  the class name of the . The  parameter (publish rate of ) is optional, and defaults to 1.0. The  is prepended to all  output, and defaults to """" (empty string). To look for an example of an aggregator in use, look in the ""diagnostic_aggregator/demo"" directory. Users specify each  in the private parameter space of the , then start the node.  In the  package, the two analyzer types provided:  and . The  can be used to categorize and track stale items. The  categorizes analyzers themselves, allowing users to ""sub-categorize"" analyzers. The  class is useful for categorizing diagnostics data. It's mostly used for a particular device or category, like a Hokuyo node or EtherCAT devices. It can be configured to analyze almost any set of diagnostics data. For a full tutorial on the , see  The  can load a group of analyzers as a sub group. This can be useful for analyzing a group of similar items, like 4 different cameras. The  can use any type of analyzer as one of the sub-analyzers.  The above example can analyze the instruments on a PR2. The  uses the parameter  to prepend to all output names. In the above example,  All sub-analyzers should go under the  namespace of the . They should be specified in the same way that any diagnostic analyzer would be specified. Note: The diagnostic aggregator uses the  internally, which is why this is very similar to setting up a diagnostic aggregator. The  is a subclass of the . It will ""match"" any item that the  matches, but will discard the items and not report it. The  will simply ignore all parameters in its namespace, and not match or report anything.  The difference between this and the  above is that since the  doesn't match anything, anything that it is ignoring will be reported in ""Other"". The  will suppress any output from anything that it matches. PR2 robots use the  and the  for diagnostic display. The launch files in ""pr2_bringup/pr2.launch"" contain the configuration file for the .  The ""diagnostic_aggregator/demo"" directory has an example of an  used for testing and demonstrations. diagnostic_aggregatoraggregator_node/diagnostics/diagnostics_aggaggregator_nodeGenericAnalyzerAnalyzerGroupaggregator_noderobot_monitorprosilica: Frequency StatusMy Robot/Sensors/Prosilica/prosilica: Frequency Statusaggregator_noderobot_monitoraggregator_nodediagnostic_aggregator::Analyzerinit()match()analyze()report()getPath()getName()aggregator_node~analyzersGenericAnalyzertypetypeaggregator_nodeAnalyzerpub_rate/diagnostics_aggbase_path/diagnostics_aggAnalyzeraggregator_nodediagnostic_aggregatorGenericAnalyzerAnalyzerGroupGenericAnalyzerAnalyzerGroupGenericAnalyzerGenericAnalyzerAnalyzerGroupAnalyzerGrouppathtilt_hokuyo_node: Frequency StatusSensors/Tilt Hokuyo/tilt_hokuyo_node: Frequency Status~analyzersAnalyzerGroupAnalyzerGroupDiscardAnalyzerGenericAnalyzerGenericAnalyzerIgnoreAnalyzerDiscardAnalyzerIgnoreAnalyzerDiscardAnalyzer/diagnostics/diagnostics_agg/diagnostics_toplevel_state~pub_ratedouble~base_pathstring~analyzers{}~analyzers{}aggregator_noderobot_monitoraggregator_nodeaggregator_nodeLeft Wheel
Right Wheel
SICK Frequency
SICK Temperature
SICK Connection Status
Stereo Left Camera
Stereo Right Camera
Stereo Analysis
Stereo Connection Status
Battery 1 Level
Battery 2 Level
Battery 3 Level
Battery 4 Level
Voltage StatusMy Robot/Wheels/Left
My Robot/Wheels/Right
My Robot/SICK/Frequency
My Robot/SICK/Temperature
My Robot/SICK/Connection Status
My Robot/Stereo/Left Camera
My Robot/Stereo/Right Camera
My Robot/Stereo/Analysis
My Robot/Stereo/Connection Status
My Robot/Power System/Battery 1 Level
My Robot/Power System/Battery 2 Level
My Robot/Power System/Battery 3 Level
My Robot/Power System/Battery 4 Level
My Robot/Power System/Voltage StatusMy Robot
  -- Wheels
    -- Left
    -- Right
  -- SICK
    -- etc ...
  -- Stereo
  -- Power Systempub_rate: 1.0 # Optional, defaults to 1.0
base_path: 'PRE' # Optional, defaults to """"
analyzers:
  motors:
    type: PR2MotorsAnalyzer
  joints:
    type: GenericAnalyzer
    path: 'Joints'
    regex: 'Joint*'




type: AnalyzerGroup
path: Sensors
analyzers:
  base_hk:
    type: GenericAnalyzer
    path: Base Hokuyo
    startswith: base_hokuyo_node
    num_items: 3
  tilt_hk:
    type: GenericAnalyzer
    path: Tilt Hokuyo
    startswith: tilt_hokuyo_node
    num_items: 3
  imu:
    type: GenericAnalyzer
    path: IMU
    startswith: imu_node
    num_items: 3"
W2449,https://wiki.ros.org/dbw_pacifica_description,Wiki,dbw_pacifica_description,URDF and meshes describing the Pacifica.
W2450,https://wiki.ros.org/carl_dynamixel,Wiki,carl_dynamixel,"Configuration for CARLS's Head Dynamixel ServoNewly proposed, mistyped, or obsolete package. Could not find package ""carl_dynamixel"" in rosdoc: /home/rosbot/docs/api/carl_dynamixel/manifest.yaml 













The  package is a package which launches the correct nodes and controllers from the 'dynamixel_motors' package. It also has a sensor_msgs/JointState publisher. The  package contains a  This file launches an instance of the  and  nodes from the 'dynamixel_motor' metapackage. It also launches the 'back_joints_node' and , as well as the  node for velocity commands. To launch these nodes, the following command can be used: The id for the servo can be found from the 'motor_states/<port>' topic Please send bug reports to the . Feel free to contact me at any point with questions and comments. carl_dynamixelback_joint_nodemotor_states/back_portdynamixel_backback_servos/num_servosback_servos/1/idback_servos/1/link_namefront_joint_nodemotor_states/front_portdynamixel_frontfront_servos/num_servosfront_servos/1/idfront_servos/1/link_nameservo_pan_tiltasus_controller/tiltcreative_controller/pandynamixel_backdynamixel_frontasus_controller/commandcreative_controller/commandasus_controller/look_at_pointasus_controller/look_at_framecarl_dynamixelcarl_servos.launchdynamixel_managertilt_controller_spawnerfront_joints_nodeservo_pan_tiltasus_controller/commandcreative_controller/commandasus_controller/tiltcreative_controller/panmotor_states/back_portmotor_states/front_portasus_controller/statecreative_controller/state




sudo apt-get install ros-indigo-carl-botroslaunch carl_dynamixel carl_servos.launchexample_controller:
    controller:
        package: dynamixel_controllers
        module: joint_position_controller
        type: JointPositionController
    joint_name: example_joint
    joint_speed: 0.5
    motor:
        id: 1
        init: 512
        min: 0
        max: 1023<!-- Start example joint controller -->
    <rosparam file=""$(find carl_dynamixel)/config/example.yaml"" command=""load""/>
    <node name=""example_controller_spawner"" pkg=""dynamixel_controllers"" type=""controller_spawner.py""
          args=""--manager=dxl_manager
                --port back_port
                example_controller""
          output=""screen""/>""2"": 
    id: 2
    link_name: joint_2back_servos: 
   num_servos: 3
   ""1"": 
    id: 1
    link_name: asus_servo_asus_servo_arm_joint 
   ""2"": 
    id: 2
    link_name: joint_2
   ""3"": 
    id: 12
    link_name: joint_3 "
W2451,https://wiki.ros.org/cob_object_detection_msgs,Wiki,cob_object_detection_msgs,This package contains message type definitions for object detection
W2452,https://wiki.ros.org/ecl_command_line,Wiki,ecl_command_line,"Embeds the TCLAP library inside the ecl. This is a very convenient
     command line parser in templatised c++.




boost::program_optionssrc/examples/command_line.cpp











"
W2453,https://wiki.ros.org/catch_ros,Wiki,catch_ros,ROS integration for the Catch unit test framework
W2454,https://wiki.ros.org/ecl_devices,Wiki,ecl_devices,"Provides an extensible and standardised framework for input-output devices.



If outside ros, you will also need to link against . These are in . src/examples/serial_timeout.cppsrc/benchmarks/files.cppsrc/demos/socket_client.cppsrc/demos/socket_server.cppsrc/utils/hex.cppsrc/utils/serial.cpp










"
W2455,https://wiki.ros.org/cmvision,Wiki,cmvision,"Node for the Color Machine Vision Project, used for fast color blob detection

 



The above command will bring up an interface that provides a means for graphically selecting desired colors for blobs.  displays values for  and  which can be used in a colors file. Blob parameters are specified to  using two components: Example  for detecting a  RWI B21r Multiple blob colors can be specified in the same file by adding lines under  and . colorguiRGBYUVcmvisionRGBYUVcolors.txtcolorsthresholdsimageimageblobs/cmvision/color_filestring/cmvision/mean_shift_onbooltrue/cmvision/debug_onbool/cmvision/spatial_radius_pixint/cmvision/color_radius_pixintrosrun cmvision colorgui image:=<image topic>[colors]
(159,  62, 71) 0.000000 7 ResearchRobotRed

[thresholds]
(56:99, 108:117, 173:193)rosparam set /cmvision/color_file /path/to/colors.txt
rosrun cmvision cmvision image:=<image topic>"
W2456,https://wiki.ros.org/cyberglove,Wiki,cyberglove,"This is a generic ROS interface to the Cyberglove from Immersion. It reads data from the Cyberglove, calibrate them
     and streams them to two different /joint_states topic: calibrated and raw data.


 


This node publishes /jointState messages on two topics for the raw and calibrated values. The two topics are  and  The calibration file is loaded from  the /param/cyberglove.cal file. To change which file you want to use, you can simply edit the parameter  of the  file. A calibration process is available in the  plugin of the . The standard Cyberglove connected to the serial port has been tested, as well as the bluetooth version of the cyberglove. To use the bluetooth version, you need to pair it with your computer. A good howto is available on the . <node pkg=""cyberglove"" name=""cyberglove"" type=""cyberglove"">
    <param name=""cyberglove_prefix"" type=""string"" value=""/cyberglove"" />
    <param name=""publish_frequency"" type=""double"" value=""20.0"" />
    <param name=""path_to_glove"" type=""string"" value=""/dev/ttyS0"" />
    <param name=""path_to_calibration"" type=""string"" value=""$(find
    sr_control_gui)/param/cyberglove.cal"" />
</node>"
W2457,https://wiki.ros.org/catkin_pip,Wiki,catkin_pip,Catkin macros to allow using pure python packages in usual catkin workspaces with normal python workflow.
W2458,https://wiki.ros.org/bfl,Wiki,bfl,"This package contains a recent version of the Bayesian Filtering
  Library (BFL), distributed by the Orocos Project.  For stability
  reasons, this package is currently locked to revision 31655 (April
  19, 2010), but this revision will be updated on a regular basis to
  the latest available BFL trunk.  This ROS package does not modify
  BFL in any way, it simply provides a convenient way to download and
  compile the library, because BFL is not available from an OS package
  manager.  This ROS package compiles BFL with the Boost library for
  matrix operations and random number generation. 

This is a third party package with . 













"
W2459,https://wiki.ros.org/camera_info_manager,Wiki,camera_info_manager,"This package provides a C++ interface for camera calibration
     information.  It provides CameraInfo, and handles SetCameraInfo
     service requests, saving and restoring the camera calibration
     data.



: the URL may now contain substitution variables, including the camera name and . 




 class : the global  class is no longer available, use  instead. : a new  method allows the caller to set  parameters directly. 
It provides a C++ class used by many camera drivers to manage the  required by the . For camera drivers written in Python, the  package provides a similar interface. For ROS Diamondback, this package moved to the  stack. For C Turtle, it was part of . In ROS Diamondback the  class moved to the  namespace. For compatibility with ROS C Turtle, the global  class name is still supported. It is deprecated in Electric Emys and removed in Fuerte. The API includes a camera name, which is written when  is saved, and checked when data are loaded, with a warning logged if the name read does not match. Camera driver authors should refer to the  for syntax details and recommendations for assigning camera names.  The location for getting and saving calibration data is expressed by Uniform Resource Locator (URL). These URLs are commonly used in the APIs of this package and may also contain substitution variables to refer to common locations. Please see the  for supported URLs, file formats and substitution variables. This package does not read ROS parameters directly. Where appropriate, we recommend  that drivers provide a  parameter for the URL string passed to CameraInfoManager. For compatibility with C Turtle, the global  class name was still supported, but it was  in Electric. The camera_info_manager is used in the  driver.  Search for  in the source code to see where the CameraInfoManager class is used. In particular, note the handling of Header time stamps and transform frame IDs. CameraInfoManagercamera_info_managerCameraInfoManagerCameraInfo${ROS_HOME}set_camera_info~camera_info_urlCameraInfoManagerCameraInfoManagercamera_info_manager::CameraInfoManagersetCameraInfo()CameraInfocinfo_"
W2460,https://wiki.ros.org/cob_trajectory_controller,Wiki,cob_trajectory_controller,"This package provides a trajectory controller which controlls velocities for a chain of joints. This controller can be used e.g. with [[schunk_powercube_chain]].

cob_trajectory_controllerjoint_trajectory_action/goaljoint_trajectory_action/resultjoint_trajectory_action/feedback/joint_statescommand_velset_joint_velocityset_joint_acceleration~ptp_veldouble~ptp_accdouble~max_errordouble"
W2461,https://wiki.ros.org/dynamixel_controllers,Wiki,dynamixel_controllers,"This package contains a configurable node, services and a spawner script
        to start, stop and restart one or more controller plugins. Reusable
        controller types are defined for common Dynamixel motor joints. Both speed and
        torque can be set for each joint. This python package can be used by more
        specific robot controllers and all configurable parameters can be loaded
        via a yaml file.start_controller/serial_port_namestop_controller/serial_port_namerestart_controller/serial_port_name~port_namestr~baud_rateint~min_motor_idint~max_motor_idint~update_rateintjoint_controller_name/controller/packagestrjoint_controller_name/controller/modulestrjoint_controller_name/controller/typestrjoint_controller_name/commandmotor_states/serial_port_namejoint_controller_name/statejoint_controller_name/set_speedjoint_controller_name/torque_enablejoint_controller_name/set_compliance_slopejoint_controller_name/set_compliance_marginjoint_controller_name/set_compliance_punchjoint_controller_name/set_torque_limitjoint_controller_name/joint_namestrjoint_controller_name/joint_max_speedfloatjoint_controller_name/joint_speedfloatjoint_controller_name/joint_compliance_slopeintjoint_controller_name/joint_compliance_marginintjoint_controller_name/joint_compliance_punchintjoint_controller_name/joint_torque_limitfloat<manager_namespace>/<port_namespace>/start_controller<manager_namespace>/<port_namespace>/stop_controller<manager_namespace>/<port_namespace>/restart_controller~namespacestr~diagnostics_ratefloat~serial_portsmap~serial_ports/<port_namespace>/port_namestr~serial_ports/<port_namespace>/baud_rateint~serial_ports/<port_namespace>/min_motor_idint~serial_ports/<port_namespace>/max_motor_idint~serial_ports/<port_namespace>/update_rateint~serial_ports/<port_namespace>/diagnostics/error_level_tempint~serial_ports/<port_namespace>/diagnostics/warn_level_tempintjoint_controller_name/controller/packagestrjoint_controller_name/controller/modulestrjoint_controller_name/controller/typestr<joint_controller_name>/commandmotor_states/<serial_port_name><joint_controller_name>/state<joint_controller_name>/set_speed<joint_controller_name>/torque_enable<joint_controller_name>/set_compliance_slope<joint_controller_name>/set_compliance_margin<joint_controller_name>/set_compliance_punch<joint_controller_name>/set_torque_limit~<joint_controller_name>/joint_namestr~<joint_controller_name>/joint_max_speedfloat~<joint_controller_name>/joint_speedfloat~<joint_controller_name>/joint_compliance_slopeint~<joint_controller_name>/joint_compliance_marginint~<joint_controller_name>/joint_compliance_punchint~<joint_controller_name>/joint_torque_limitfloat"
W2462,https://wiki.ros.org/bwi_planning_common,Wiki,bwi_planning_common,"Common data structures, messages and service defintions used for
    deterministic planning work in the BWI project at the University of Texas
    at Austin"
W2463,https://wiki.ros.org/costmap_converter,Wiki,costmap_converter,"A ros package that includes plugins and nodes to convert occupied costmap2d cells to primitive types.


  
 (, default: 0.4) 
 
 (, default: 0.4) 
  
 (, default: 0.4) 
  
 (, default: 0.4) 
This package defines an  interface and provides some plugins for converting occupied cells of  to geometric primitives. This primitives (points, lines, polygons) represent obstacles in the map. It is intendend for nodes that incorporate obstacles (e.g. in navigation) and do not rely on cost cells, but consider obstacles defined by shapes in the plane (e.g. polygons). The costmap is still favorable in conjunction with  since it fuses multiple range sensors with a global static map and some filtering might be applied. A naive approach to further incorporate the costmap is to take each occupied cell as point-obstacle. However, by integrating the costmap_converter interface the costmap is converted continuously during runtime and if desired the conversion is invoked in a separate thread. For that purpose the internal  node () might be employed. Currently, parameters are hardcoded. These are going to be substituted with changeble parameters in an upcoming release. Before then please inspect the source code for further details. ~<name>/cluster_max_distancedouble~<name>/cluster_min_ptsint~<name>/cluster_max_ptsint~<name>/convex_hull_min_pt_separationdouble~<name>/cluster_max_distancedouble~<name>/cluster_min_ptsint~<name>/cluster_max_ptsint~<name>/convex_hull_min_pt_separationdouble~<name>/concave_hull_depthdouble~<name>/cluster_max_distancedouble~<name>/cluster_min_ptsint~<name>/cluster_max_ptsint~<name>/convex_hull_min_pt_separationdouble~<name>/support_pts_max_distdouble~<name>/support_pts_max_dist_inbetweendouble~<name>/min_support_ptsint~<name>/cluster_max_distancedouble~<name>/cluster_min_ptsint~<name>/cluster_max_ptsint~<name>/ransac_inlier_distancedouble~<name>/ransac_min_inliersint~<name>/ransac_no_iterationsint~<name>/ransac_remainig_outliersint~<name>/ransac_convert_outlier_ptsbool~<name>/ransac_filter_remaining_outlier_ptsbool~<name>/convex_hull_min_pt_separationdoublestandalone_converter"
W2464,https://wiki.ros.org/comp_temporal,Wiki,comp_temporal,"

     Temporal reasoning methods for the knowledge base.

     Time points and intervals are supported, and the system can
     calculate if one interval subsumes another one, happens before
     or after another, and how long it takes.

  This package is part of the  knowledge processing system. "
W2465,https://wiki.ros.org/blob,Wiki,blob,"blob provides a new message type blob/Blob for binary data.
Use GitHub to . []
 "
W2466,https://wiki.ros.org/camera_drivers,Wiki,camera_drivers,"
    This stack contains drivers for a variety of cameras, and some
    associated tools.
  
: each camera driver formerly included here now resides in its own separate stack. For backwards compatibility, those stacks are listed as  dependencies, but external dependencies should refer directly to the desired driver stack. : the camera_drivers metapackage is no longer supported. Update dependencies to refer to specific drivers, instead. 


  To encourage compatibility between camera nodes, it is recommended that cameras provide one or both of the the following minimal APIs. The  package provides a CameraPublisher class to help implementing this API. The  package exports a CameraInfoManager C++ class that provides  data and handles  service requests. 
camera_driverscamera/image_rawcamera/camera_infocamera/set_camera_inforesponse_namespacerequest_image<response_namespace>/image_raw<response_namespace>/camera_infoset_camera_inforequest_image"
W2467,https://wiki.ros.org/cmake_modules,Wiki,cmake_modules,A common repository for CMake Modules which are not distributed with CMake but are commonly used by ROS packages. 
W2468,https://wiki.ros.org/geometry2,Wiki,geometry2,"A metapackage to bring in the default packages second generation Transform Library in ros, tf2.This is a metapackage see  for more detailed information. "
W2469,https://wiki.ros.org/geometry_experimental,Wiki,geometry_experimental,"The second generation Transform Library in ros.  This metapackage is deprecated, but is kept for backwards compatability.

  "
W2470,https://wiki.ros.org/head_action,Wiki,head_action,"The head action is a node that provides an action interface for
  pointing the head of the configured robot. It passes trajectory goals to the
  controller, and reports success when they have finished executing. 







See  for information on the controller that the head action communicates with. An example of using the head action on  can be found on the video below. The joint trajectory action provides an action server (see ) that takes in goals of the type .  It reports success when the head is pointed at the target. ~pan_linkstring~tilt_linkstring~success_angle_thresholddouble~point_head_action/goal~point_head_action/cancel~point_head_action/feedback~point_head_action/status~point_head_action/result~state~command"
W2471,https://wiki.ros.org/eigen_stl_containers,Wiki,eigen_stl_containers,"This package provides a set of typedef's that allow
  using Eigen datatypes in STL containers"
W2472,https://wiki.ros.org/executive_smach,Wiki,executive_smach,"This metapackage depends on the SMACH library and ROS SMACH integration
    packages.


  See  for SMACH state classes with a variety of additional behaviors. On the  you can find a number of easy examples. But if you are looking for some 'real' examples running SMACH: "
W2473,https://wiki.ros.org/ecl_mobile_robot,Wiki,ecl_mobile_robot,"Contains transforms (e.g. differential drive inverse kinematics)
    for the various types of mobile robot platforms."
W2474,https://wiki.ros.org/gazebo_ros_control,Wiki,gazebo_ros_control,gazebo_ros_control
W2475,https://wiki.ros.org/filters,Wiki,filters,"This library provides a standardized interface for processing data as a sequence 
    of filters.  This package contains a base class upon which to build specific implementations
    as well as an interface which dynamically loads filters based on runtime parameters.: filters is now a separate stack.  In previous releases, it was part of . 



 
 ()  ()  () 


 (list(Filters)) 



: A new simpler plugin macro is now recommended: 
Filters are closely linked to .  Please make sure that you are familiar with the  before continuing.   It is recommended to use a  whenever using more than one instances of . However, you need to understand the base Filter C++ API first before using the Filter Chain API. The core of the  Package is a templated base class  which defines the external API to any filter.  The methods are  and .  It also provides helper methods for a Filter implementation. To use a Filter simply instantiate it in your code.   Filters are configured from parameters on the .  The configure method passes in the parameter namespace to read from of the Parameter Server.   A Filter expects to find a map with three elements: ,  and .   The  class has been designed to facilitate dynamically loading a sequence of Filters based on runtime parameters.  The Filter Chain is configured from the  just like Filters.  Based on the parameters the Filter Chain will dynamically load the Filters by their name.   The public API looks just like the Filter API with  and  methods.   Here's an example of a multi-channel filter chain for doubles.  To do a non-vector style use a  and change  and  to type .   Implementing a  is simply a specific form of a dynamically loaded class for .   This whole document refers simply to  and .  However there are  versions of both.  Instead of the templated data type, , they expect  on the update calls.  And the configure method has one extra argument which is the number of channels expected(aka how many elements are expected in the ).   filters::FilterChainfilters::Filterfiltersfilters::FilterBase<TemplateType>configure()update()nametypeparamsnamestringtypestringparamsmapfilters::FilterChainconfigure()update()filter_chainfilters::FilterChain<double>inoutdoubleFilterFilterBase<T>configure()update()filtersfilters::FilterBasefilters::FilterChainMultiChannelTstd::vector<T>vectorparameter_namespace_passed_to_configure:
  name: unique_name
  type: FilterName
  params: { param1: a, param2: b}param_namespace_passed_to_configure:
  filter_chain:
    -
      name: median_test_unique
      type: MultiChannelMedianFilterDouble
      params: {number_of_observations: 5}
    - 
      name: median_test2
      type: MultiChannelMedianFilterDouble
      params: {number_of_observations: 5}filters::MultiChannelFilterChain<double> chain(""double""); //Node template type and argument must match
chain.configure(""param_namespace_passed_to_configure"");
std::vector<double> in, out; chain.update(in, out);PLUGINLIB_REGISTER_PLUGIN(UniqueFullClassNameSoSpecialCharacters, my_package::ClassName, filters::FilterBase<Type>)PLUGINLIB_EXPORT_PLUGIN(my_package::ClassName, filters::FilterBase<Type>)"
W2476,https://wiki.ros.org/gennodejs,Wiki,gennodejs,Javascript ROS message and service generators.This package generates the Javascript messages for ROS packages and is used by . 
W2477,https://wiki.ros.org/fanuc_experimental,Wiki,fanuc_experimental,"Experimental packages for Fanuc manipulators within ROS-Industrial.






Use GitHub to . []
 This stack is part of the  program. It contains experimental packages that will be moved to the  package once they've received sufficient testing and review. Packages in distribution branches (ie: ) may be expected to be compatible with the corresponding ROS distribution (ie: the  branch is usable on Indigo). In the absence of major differences between subsequent ROS releases, the  branch may be expected to be compatible with the next release as well (ie:  may be used on Jade, as long as no  branch exists). Refer to the  for more information on building catkin workspaces. See the  page for more information. For questions related to the Fanuc support or ROS-Industrial in general, please contact the developers by posting a message in the  on ROS Discourse. $ROS_DISTRO-develindigo-devel-develindigo-develjade-devel$ROS_DISTRO-develapt-getindigo-develapt-get





































"
W2478,https://wiki.ros.org/hector_worldmodel_msgs,Wiki,hector_worldmodel_msgs,"hector_worldmodel_msgs is a message package to comes with the hector_worldmodel stack.
     The messages can be used to send percepts from images (hector_worldmodel_msgs/ImagePercept) or other sources
     (hector_worldmodel_msgs/PosePercept) to the hector_object_tracker node. The tracker publishes model updates as
     hector_worldmodel_msgs/Object messages and latches the whole model state as a hector_worldmodel_msgs/ObjectModel message."
W2479,https://wiki.ros.org/freenect_stack,Wiki,freenect_stack,"A libfreenect-based ROS driver for the Microsoft Kinect




, you need to blacklist the kernel module that gets loaded by default for the Kinect: 


The freenect_stack ROS driver supports USB 3.0, but users running Ubuntu 12.04 (precise) or older Ubuntu versions will have to patch their Kernel or upgrade to Kernel 3.4.2 or later to get this to work. See  for more details. As mentioned in this thread , you need to forward all 3 devices (camera, motor, audio) to the VM for libfreenect to work properly. sudo apt-get install ros-fuerte-freenect-stacksudo apt-get install ros-groovy-freenect-stacksudo apt-get install ros-hydro-freenect-stacksudo modprobe -r gspca_kinect
echo 'blacklist gspca_kinect' | sudo tee -a /etc/modprobe.d/blacklist.conf"
W2480,https://wiki.ros.org/gencpp,Wiki,gencpp,C++ ROS message and service generators.
W2481,https://wiki.ros.org/fcl,Wiki,fcl,"

     fcl

   Please see  




For more technical details, check out the  More collision detection and proximity collision packages developed at UNC Chapel Hill are available in . git clone git://github.com/flexible-collision-library/fcl.git"
W2482,https://wiki.ros.org/fake_joint_launch,Wiki,fake_joint_launch,Collection of the launch files for fake_joint_driver.
W2483,https://wiki.ros.org/eigen_conversions,Wiki,eigen_conversions,"Conversion functions between:
      - Eigen and KDL
      - Eigen and geometry_msgs.
"
W2484,https://wiki.ros.org/ecl_geometry,Wiki,ecl_geometry,"Any tools relating to mathematical geometry. 
     Primarily featuring polynomials and interpolations.


If outside ros, you will also need to link to . There are quite a few useful tools also in eigen's geometry module. You can use these directly from eigen or via the  package. 
























"
W2485,https://wiki.ros.org/four_wheel_steering_msgs,Wiki,four_wheel_steering_msgs,ROS messages for robots using FourWheelSteering.
W2486,https://wiki.ros.org/hrpsys,Wiki,hrpsys,"An -based robot controller. This package is the most tailored for humanoid (dual-arm and/or biped) robots for historical reason.hrpsys package does not only wraps but build and installs the code from its mainstream repository ().The package version number is synchronized to that of mainstream, based on . Its semantics:
    API document is .
   





As a 3rd party package to ROS we need some extra chores to release. Discussed . NOTE for 2 different repositories are involved: hrpsysfkanehiro/hrpsys-basecatkin_generate_changelogpackage.xmlcatkin_prepare_release"
W2487,https://wiki.ros.org/grizzly_msgs,Wiki,grizzly_msgs,"Common messages for Grizzly.Newly proposed, mistyped, or obsolete package. Could not find package ""grizzly_msgs"" in rosdoc: /home/rosbot/docs/api/grizzly_msgs/manifest.yaml 
Included as well in this package is a helper to assist with using  messages in conjunction with Eigen. See the . "
W2488,https://wiki.ros.org/grasping_msgs,Wiki,grasping_msgs,Messages for describing objects and how to grasp them.
W2489,https://wiki.ros.org/fetch_navigation,Wiki,fetch_navigation,Configuration and launch files for running ROS navigation on Fetch.
W2490,https://wiki.ros.org/ecl_sigslots,Wiki,ecl_sigslots,"Provides a signal/slot mechanism (in the same vein as qt sigslots, 
     boost::signals etc for intra-process communication. These include 
     some improvements - they do not need a preprocessor, are fully type safe,
     allow for simple connections via a posix style string identifier 
     and are multithread-safe.








You will also need to link to . 




"
W2491,https://wiki.ros.org/euslisp,Wiki,euslisp,"EusLisp is an integrated programming system for the
  research on intelligent robots based on Common Lisp and
  Object-Oriented programming

 Documentation is available . Use trac to report  or .  "
W2492,https://wiki.ros.org/graph_msgs,Wiki,graph_msgs,"ROS messages for publishing graphs of different data types
See  for full documentation. "
W2493,https://wiki.ros.org/hokuyo_node,Wiki,hokuyo_node,"A ROS node to provide access to SCIP 2.0-compliant Hokuyo laser range finders (including 04LX). 



: : 

 




Image credit:  On the UTM-30LX, unless the  option is selected, the hokuyo_node will limit the angular range to values that are known to work. The angular range limit depends on the firmware version, and is proportional to the  parameter. The  and  programs can be used to get information about a hokuyo laser scanner. Each of them can be invoked in a human readable way: The  program can be used to get the hardware ID of a Hokuyo device given its port. Combined with udev, this allows a consistent device name to be given to each device, even if the order in which they are plugged in varies. The following udev rule should work universally on any ROS system: clusterskipintensitymin_angmax_angclusterskipintensitymin_angmax_ang~allow_unsafe_settingsclusterhokuyo_nodescandiagnostics~self_test~use_rep_117bool~min_angdouble~max_angdouble~intensityboolfalse~clusterint~skipint~portstring/dev/ttyACM0~calibrate_timebooltrue~frame_idstringlaser~time_offsetdouble~allow_unsafe_settingsbool~min_ang_limitdouble~min_ang~max_ang_limitdouble~max_ang~min_rangedouble~max_rangedoubleintensityskipintensitymin_angmax_anggetIDgetFirmwareVersiongetID$ rosrun hokuyo_node getID /dev/ttyACM0
Device at /dev/ttyACM0 has ID H0807228$ rosrun hokuyo_node getID /dev/ttyACM0 --
H0807228KERNEL==""ttyACM[0-9]*"", ACTION==""add"", ATTRS{idVendor}==""15d1"", MODE=""0666"", GROUP=""dialout"", PROGRAM=""/opt/ros/hydro/env.sh rosrun hokuyo_node getID %N q"", SYMLINK+=""sensors/hokuyo_%c""$ ls -l /etc/ros/sensors/base_hokuyo
lrwxrwxrwx 1 root root 28 2010-01-12 15:53 /etc/ros/sensors/base_hokuyo -> /dev/sensors/hokuyo_H0902620
$ ls -l /dev/sensors/hokuyo_H0902620
lrwxrwxrwx 1 root root 10 2010-04-12 12:34 /dev/sensors/hokuyo_H0902620 -> ../ttyACM1"
W2494,https://wiki.ros.org/geometric_shapes,Wiki,geometric_shapes,"This package contains generic definitions of geometric shapes and bodies.
"
W2495,https://wiki.ros.org/household_objects_database_msgs,Wiki,household_objects_database_msgs,"The household_objects_database_msgs package This package is . You probably want to use  where some have been moved to. See also . This package defines the ROS API for the household objects database. For the API documentation as well as details on the database, see the  package page. "
W2496,https://wiki.ros.org/ecl_linear_algebra,Wiki,ecl_linear_algebra,"Ecl frontend to a linear matrix package (currently eigen).


Using ros eigen now, but you can also opt to use the internal . 



























"
W2497,https://wiki.ros.org/genmsg,Wiki,genmsg,Standalone Python library for generating ROS message and service data structures for various languages.See the  
W2498,https://wiki.ros.org/eml,Wiki,eml,"This is an implementation of the EtherCAT master protocol for the PR2 robot based on the work done at Flanders' Mechatronics Technology Centre.
"
W2499,https://wiki.ros.org/fanuc,Wiki,fanuc,"ROS-Industrial support for Fanuc manipulators (metapackage).
: This status indicates that this software is not yet production ready code.  The software has some level of unit-testing.  There are known issues and missing functionality.  The APIs are unstable but unlikely to change drastically.  Use in production systems will likely require modifications including improvements and/or bug fixes.  For more information see the ROS-Industrial software status .Contents 
This repository is part of the  program. It currently contains packages that provide nodes for communication with Fanuc industrial robot controllers and urdf models for various Fanuc manipulators. See the  metapackage for additional packages, such as  configuration packages and  plugins. 
Not all packages in this repository have been released into ROS Kinetic. Most notably the various  configuration and plugins packages have not. All robot support packages,  and  have been released (and can be installed using ). They can however be used after building them from source. Refer to the  page for instructions on how to do this. 
See the  specific version of this page for information on requirements, access to the tutorials, the Troubleshooting page and other information. 
apt-getapt-getapt-getfanuc_driverfanuc_resourcesapt installfanuc_driverfanuc_resourcesapt installsudo apt-get install ros-groovy-fanucsudo apt-get install ros-hydro-fanucsudo apt-get install ros-indigo-fanuc"
W2500,https://wiki.ros.org/fetch_driver_msgs,Wiki,fetch_driver_msgs,Messages for the fetch_drivers package
W2501,https://wiki.ros.org/ecl_time,Wiki,ecl_time,"Timing utilities are very dependent on the system api provided for their use.
	This package provides a means for handling different timing models. Current support
	
	- posix rt : complete.
	- macosx : posix timers only, missing absolute timers.
	- win : none.






Many of the classes/methods in this package have many characteristics in common with the  package - in fact they are almost identical. It was made before ros came about and is kept in the ecl for both legacy reasons and because it is still sometimes useful outside a ros runtime environment (particularly when cross-compiling). If outside ros, you will also need to link to . clock_gettimeclock_nanosleep












"
W2502,https://wiki.ros.org/hector_mapping,Wiki,hector_mapping,"hector_mapping is a SLAM approach that can be used without odometry as well as on platforms that exhibit roll/pitch motion (of the sensor, the platform or both).
    It leverages the high update rate of modern LIDAR systems like the Hokuyo UTM-30LX and provides 2D pose estimates at scan rate of the sensors (40Hz for the UTM-30LX).
    While the system does not provide explicit loop closing ability, it is sufficiently accurate for many real world scenarios. The system has successfully been used on
    Unmanned Ground Robots, Unmanned Surface Vehicles, Handheld Mapping Devices and logged data from quadrotor UAVs.


 
available  . To use , you need a source of  data (for example a Hokuyo UTM-30LX LIDAR or bagfiles). The node uses  for transformation of scan data, so the LIDAR does not have to be fixed related to the specified base frame. Odometry data is not needed. hector_mappinghector_mappingscansyscommandmap_metadatamapslam_out_poseposeupdatedynamic_map~base_framestring~map_framestring~odom_framestring~map_resolutiondouble~map_sizeint~map_start_xdouble~map_start_ydouble~map_update_distance_threshdouble~map_update_angle_threshdouble~map_pub_perioddouble~map_multi_res_levelsint~update_factor_freedouble~update_factor_occupieddouble~laser_min_distdouble~laser_max_distdouble~laser_z_min_valuedouble~laser_z_max_valuedouble~pub_map_odom_transformbool~output_timingbool~scan_subscriber_queue_sizeint~pub_map_scanmatch_transformbool~tf_map_scanmatch_transform_frame_namestring<the frame attached to incoming scans>base_frametfmapodom@INPROCEEDINGS{KohlbrecherMeyerStrykKlingaufFlexibleSlamSystem2011,
  author = {S. Kohlbrecher and J. Meyer and O. von Stryk and U. Klingauf},
  title = {A Flexible and Scalable SLAM System with Full 3D Motion Estimation},
  year = {2011},
  month = {November},
  booktitle = {Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR)},
  organization = {IEEE},
}"
W2503,https://wiki.ros.org/gazebo_ros_pkgs,Wiki,gazebo_ros_pkgs,"Interface for using ROS with the  simulator.  A list of all the changes are available at the . : some ROS specific code could need to be upgraded when upgrading. The instructions are well covered in the  






gazebo_ros_pkgs is a set of ROS packages that provide the necessary interfaces to simulate a robot in the  3D rigid body simulator for robots. It integrates with ROS using ROS messages, services and dynamic reconfigure. "
W2504,https://wiki.ros.org/humanoid_nav_msgs,Wiki,humanoid_nav_msgs,Messages and services for humanoid robot navigation
W2505,https://wiki.ros.org/ecl_formatters,Wiki,ecl_formatters,"The formatters here simply format various input types to a specified
   text format. They can be used with most streaming types (including both
   ecl and stl streams).



Typically c/c++ libraries bundle streaming and formatting within the same tool (printf, iostream, ...). This tends to make them cumbersome for simple tasks. The formatter classes in this package externalise the formatting task from the io manipulation (which is usually just (u)char manipulation), This increases the efficiency of low level operations whilst also maintaining type safety. They typically do this by making use of the lower level functionality provided by . The formatter classes can be used standalone, with stl streams or with . If outside of ros, you will also need to link to . Each standard formatter is a template specialisation of the form  where the available input types are: Format<inputType>


















"
W2506,https://wiki.ros.org/hector_gazebo_plugins,Wiki,hector_gazebo_plugins,"hector_gazebo_plugins provides gazebo plugins from Team Hector.
     Currently it contains a 6wd differential drive plugin, an IMU sensor plugin,
     an earth magnetic field sensor plugin, a GPS sensor plugin and a
     sonar ranger plugin.


 is a replacement for the  plugin in package . It simulates an Inertial Measurement Unit (IMU) affected by Gaussian noise and low-frequency random drift. The orientation returned mimics a simple Attitude and Heading Reference System (AHRS) using the (erroneous) rates and accelerations. 



 simulates a GNSS (Global Navigation Satellite System) receiver which is attached to a robot. It publishs  messages with the robot's position and altitude in WGS84 coordinates. The reference point that corresponds to the origin of the gazebo frame can be configured using the XML parameters. The conversion between gazebo coordinates and WGS84 is done using a simple , which is accurate enough if you do not go far away from the configured reference point and if you do not want to use the plugin for polar regions. 









 This plugin simulates a 3-axis magnetometer like PNI Corp's . Like for the GPS plugin, the orientation of the gazebo frame can be specified via the referenceHeading parameter. Declination, inclination and field magnitude have to be configured depending on your location on earth. The default parameters are valid for Europe and North America without magnitude information (normalized vector). Check  for exact parameters. The  plugin is a ROS controller for gazebo's built-in ray sensor. The value returned as sonar range is the minimum of all rays, as a sonar ranger returns the distance corresponding to the first echo returned from a object within it's field of view. The behavior of this controller plugin depends mainly on the parameters of the sensor it is attached to. The <controller:hector_gazebo_ros_sonar> tag is only valid within a surrounding  tag. You should use the macro defined in  in package  to include a sonar sensor to your model. You can find some more plugins useful for aerial vehicles in package . GazeboRosImuGazeboRosImuimuimu/calibrateimu/set_accel_biasimu/set_gyro_biasupdateRaterobotNamespacebodyNametopicNameimuserviceName[topicName]/calibrateaccelOffsetaccelDriftaccelDriftFrequencyaccelGaussianNoiserateOffsetrateDriftrateDriftFrequencyrateGaussianNoiseyawOffsetyawDriftyawDriftFrequencyyawGaussianNoiserpyOffsetsaccelOffsetyawOffsetgaussianNoiseGazeboRosGpsfixfix_velocityupdateRaterobotNamespacebodyNameframeIdtopicNamefixvelocityTopicNamefix_velocityreferenceLatitudereferenceLongitudereferenceHeadingreferenceAltitudestatusSTATUS_FIXserviceSERVICE_GPSoffsetdriftdriftFrequencygaussianNoisevelocityOffsetvelocityDriftvelocityDriftFrequencyvelocityGaussianNoisemagneticupdateRaterobotNamespacebodyNametopicNamemagnitudereferenceHeadingdeclinationinclinationoffsetdriftdriftFrequencygaussianNoiseGazeboRosSonar<sensor:ray>sonar_sensor.urdf.xacrosonarupdateRaterobotNamespaceframeIdtopicNamesonaroffsetdriftdriftFrequencygaussianNoise"
W2507,https://wiki.ros.org/gazebo_plugins,Wiki,gazebo_plugins,"Robot-independent Gazebo plugins for sensors, motors and dynamic reconfigurable components.
Gazebo"
W2508,https://wiki.ros.org/hector_nav_msgs,Wiki,hector_nav_msgs,hector_nav_msgs contains messages and services used in the hector_slam stack.
W2509,https://wiki.ros.org/ee_cart_imped_msgs,Wiki,ee_cart_imped_msgs,"

     Messages for ee_cart_imped stack.

  See the  for the message and action definitions. "
W2510,https://wiki.ros.org/fzi_icl_core,Wiki,fzi_icl_core,The fzi_icl_core package
W2511,https://wiki.ros.org/genrb,Wiki,genrb,ruby ROS message and service generators
W2512,https://wiki.ros.org/graft,Wiki,graft,"Graft is not yet finished. It's intended to be a full replacement to robot_pose_ekf, including native absolute references, and arbitrary topic configuration. If you try to use Graft now, please note that not all parameters are configured and you will not always see a change in behavior by modifying the parameters."
W2513,https://wiki.ros.org/geometry,Wiki,geometry,"A metapackage for geometry library suite.: Since ROS Hydro, tf has been ""deprecated"" in favor of . tf2 is an iteration on tf providing generally the same feature set more efficiently. As well as adding a few new features.
    As tf2 is a major change the tf API has been maintained in its current form. Since tf2 has a superset of the tf features with a subset of the dependencies the tf implementation has been removed and replaced with calls to tf2 under the hood. This will mean that all users will be compatible with tf2. It is recommended for new work to use tf2 directly as it has a cleaner interface. However tf will continue to be supported for through at least J Turtle.
    


  
Use GitHub to . []
  "
W2514,https://wiki.ros.org/fetch_moveit_config,Wiki,fetch_moveit_config,An automatically generated package with all the configuration and launch files for using the fetch_urdf with the MoveIt Motion Planning Framework
W2515,https://wiki.ros.org/gps_common,Wiki,gps_common,"GPS messages and common routines for use in GPS drivers




This package is a space to stage messages and common GPS-processing routines that are undergoing a standardization process. Its contents will probably be moved into  once they've matured. gps_common defines two common messages for GPS drivers to output:  and . See  for an example of a sender node that uses this package's messages. utm_odometry_nodefixodom~rot_covariancedouble~frame_idstringframe_idfix~child_frame_idstring"
W2516,https://wiki.ros.org/fetch_gazebo,Wiki,fetch_gazebo,Gazebo package for Fetch.
W2517,https://wiki.ros.org/genjava,Wiki,genjava,"Java ROS message and service generators.

See the  tutorial for more information. "
W2518,https://wiki.ros.org/ecl_utilities,Wiki,ecl_utilities,"Includes various supporting tools and utilities for c++ programming.
"
W2519,https://wiki.ros.org/ee_cart_imped_action,Wiki,ee_cart_imped_action,"

     An action server and interface for the ee_cart_imped_control package.  The EECartImped Controller should always be accessed through this action.

  
 







The ee_cart_imped_action is a node that provides an action interface for the  node.  Specifically, it allows tracking trajectories that involve force control and sending goals and cancel signals to the controller.  The action can also put constraints on the trajectory and aborts trajectory execution when the constraints are violated.  All interaction with the  package should be done through this action interface. For more videos, look at the . Example configuration (from /pr2_arms_cart_imped_controller.yaml): The EECartImpedAction provides an  that takes in goals of the type  and publishes feedback of the type . In general, interaction with the action server should take place through an action client.  To facilitate this process, we have written C++ and python wrappers around the  and included them in the package.  To use the these clients, look at their code APIs   or the . constraints/goal/timedoubleconstraints/goal/geometry_msgs/Poseconstraints/goal/effortdoubleconstraints/trajectory/geometry_msgs/Poseconstraints/trajectory/effortdoubleee_cart_imped_action/goalee_cart_imped_action/cancelee_cart_imped_action/feedbackee_cart_imped_action/statusee_cart_imped_action/resultstatecommand  r_arm_cart_imped_action_node:
    constraints:
      goal:
        time: 0.0
        position:
          x: 0.2
          y: 0.2
          z: 0.2
        orientation:
          x: 0.2
          y: 0.2
          z: 0.2
          w: 0.2
        effort: 0.002
      trajectory:
        effort: -1.0"
W2520,https://wiki.ros.org/gazebo_ros,Wiki,gazebo_ros,"Provides ROS plugins that offer message and service publishers for interfacing with  through ROS.
    Formally simulator_gazebo/gazebo: This package replaces  in ROS Hydro 
See  "
W2521,https://wiki.ros.org/fetch_teleop,Wiki,fetch_teleop,Teleoperation for fetch and freight.
W2522,https://wiki.ros.org/ecl_streams,Wiki,ecl_streams,"These are lightweight text streaming classes that connect to standardised
     ecl type devices.



If outside ros, you will also need to link to . 





















"
W2523,https://wiki.ros.org/geographic_msgs,Wiki,geographic_msgs,"ROS messages for Geographic Information Systems.



Map points, features and segments all have universally unique identifier names (), using  messages. Each UUID is stored as an array of unsigned bytes. UUID generation is up to the programmer, but the intent is for matching features within a domain such as Open Street Map to yield the same UUID.  The  package provides C++ and Python interfaces for generating them: use the  method on a URL constructed from the map source. Here,  is the decimal representation of the integer OSM node, way, or relation ID without leading zeros. The  service takes a map URL and optional , returning a , The map contains a  vector and a  vector. Each point or feature is identified by a , and optional  properties describing their roles.  Not all way points in a map are drivable by any particular vehicle. Some delimit buildings, rivers, or property boundaries. The  message represents drivable paths as a directed graph using a  vector and a  vector. Each segment represents an edge from one point to another. Unless the path is one-way, another segment will point in the opposite direction. fromURL()http://openstreetmap.org/node/999999http://openstreetmap.org/way/999999http://openstreetmap.org/relation/999999999999"
W2524,https://wiki.ros.org/face_recognition,Wiki,face_recognition,"A ROS package for face recognition in video stream.
Face recognition is performed using Eigenfaces (also called ""Principal Component Analysis"" or PCA) by utilizing the c++ source code provided by Shervin Emami (http://www.shervinemami.info/faceRecognition.html)

 $ cd ~/rosbuild_ws
$ rosws set face_recognition --git git://github.com/procrob/procrob_functional.git
$ rosws update$ rosmake face_recognition$ roscd face_recognition
$ rosrun face_recognition Fserver$ roscore$ roscd gscam/bin
$ rosrun gscam gscam /gscam/image_raw:=/camera/image_raw$ rosrun face_recognition Fserver
$ rosrun face_recognition Fclient$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 ""your_name""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 3 ""none""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 ""none"" $ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 ""your_friend's_name""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 0 ""none""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 ""none"" $ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 4 ""none"" $ cd ~/catkin_ws/src
$ git clone https://github.com/procrob/procrob_functional.git --branch catkin
$ cd ~/catkin_ws
$ catkin_make
$ source ~/catkin_ws/devel/setup.bash$ roscd face_recognition
$ rosrun face_recognition Fserver$ roscore$ rosrun usb_cam usb_cam_node usb_cam_node/image_raw:=camera/image_raw _image_height:=<usb_cam_height> _image_width:=<usb_cam_width>$ rosrun face_recognition Fserver
$ rosrun face_recognition Fclient$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 ""your_name""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 3 ""none""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 ""none"" $ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 2 ""your_friend's_name""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 0 ""none""$ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 1 ""none"" $ rostopic pub -1 /fr_order face_recognition/FRClientGoal -- 4 ""none"" "
W2525,https://wiki.ros.org/hls_lfcd_lds_driver,Wiki,hls_lfcd_lds_driver,"ROS package for LDS(HLS-LFCD2).
    The LDS (Laser Distance Sensor) is a sensor sending the data to Host for the simultaneous localization and mapping (SLAM). Simultaneously the detecting obstacle data can also be sent to Host. HLDS(Hitachi-LG Data Storage) is developing the technology for the moving platform sensor such as Robot Vacuum Cleaners, Home Robot, Robotics Lawn Mower Sensor, etc. 
 



360 Laser Distance Sensor 'HLS-LFCD-LDS' (a.k.a. LDS-01) is a 2D laser scanner capable of sensing 360 degrees that collects a set of data around the robot to use for SLAM (Simultaneous Localization and Mapping) and Navigation. The LDS-01 is used for TurtleBot3 Burger, Waffle and Waffle Pi models. It supports USB interface(USB2LDS) and is easy to install on a PC. It supports UART interface for embedded baord. This hls_lfcd_lds_driver package is a driver for LDS-01. "
W2526,https://wiki.ros.org/genpy,Wiki,genpy,Python ROS message and service generators.
W2527,https://wiki.ros.org/gateway_msgs,Wiki,gateway_msgs,Messages used by the gateway model.
W2528,https://wiki.ros.org/geneus,Wiki,geneus,EusLisp ROS message and service generators.
W2529,https://wiki.ros.org/geometry_msgs,Wiki,geometry_msgs,"geometry_msgs provides messages for common geometric primitives
    such as points, vectors, and poses. These primitives are designed
    to provide a common data type and facilitate interoperability
    throughout the system."
W2530,https://wiki.ros.org/handle_detector,Wiki,handle_detector,"ROS package to detect handles.






 
 This requires an openni-compatible device, and has only been tested with an Asus Xtion Pro. 

  






 If you like this package and use it in your own work, please cite our . For the given point cloud file (), the output in rviz should look like this: If you like this package and use it in your own work, please cite our : Andreas ten Pas and Robert Platt.  International Symposium on Experimental Robotics (ISER), Morocco, June 2014. "
W2531,https://wiki.ros.org/ee_cart_imped_control,Wiki,ee_cart_imped_control,"

     A force/impedance controller.

  








The controller is an open-loop Jacobian-transpose force controller.  At every point on the trajectory the desired stiffness or desired wrench is converted into a Cartesian force/wrench vector and ultimately into a joint torque vector using the transpose of the arm's instantaneous Jacobian matrix.  No guarantee is made to the  of the applied force/wrench/impedance because this is an open-loop controller.  There is currently not adequate feedback on the arm to determine the applied force/wrench/impedance.  Joint stiction, joint position limits,  motor torque limits, and sometimes the arm configuration (at a singularity, for example) will cause the applied force/wrench/impedance to deviate from the desired values.  Generally, unless the arm is at a singularity or a joint is at its limit, the  of the force/wrench/impedance will be correct. This controller should never be used directly; rather, all interaction with it should take place through the . In this video, the PR2 first moves its gripper to the center of its body and then applies a constant force in the  direction (towards/away from the robot).  As you can see, the force is light so the human can easily stop the motion.  However, with no intervention, the robot hand will continue to move as far in the  direction as it can go.  There is no sense of trying to achieve a goal in this direction.  This type of control is useful if you wish to exert a constant force against something. In this video, the PR2 first moves its gripper to the center of its body and then tries to extend the gripper about 25 cm farther away, but with low stiffness in the  direction (towards/away from the robot).  Since the stiffness is low, it is easy for a human to move the hand away from the center of the body in the  direction and it returns slowly.  In the  and  directions, however, where the stiffness is set to the maximum, it takes a lot of strength to displace the gripper and it returns very quickly to its set point. For even more videos, see the . Example configuration (from /pr2_arms_cart_imped_controller.yaml): root_namestringtip_namestringstatecommandr_arm_cart_imped_controller:
  type: EECartImpedControlPlugin
  root_name: torso_lift_link
  tip_name: r_gripper_tool_frame"
W2532,https://wiki.ros.org/gazebo,Wiki,gazebo,"


  This ROS package checks out, patches and compiles a pre-release version of the
    
  from a WG branch which is based on svn trunk with some local patches and contains wrappers for using Gazebo with ROS.
  The local patch provides modifications for performance, debug outputs, ROS-specific customizations, capabilities, etc.
  The less ROS-specific patches are pushed back to the Gazebo repository incrementally as the package evolves.

  This package will update to newer revisions of Gazebo incrementally as new updates are made stable.
  
  Contents 
This is primarily a third party wrapper package with .  
Beginning with C-Turtle (latest releases) distro, gazebo is started as a ROS node, offering the following ROS API interfaces. 
 () 
 () 
 () 

 .  Also, pure  questions (without  involved) should be asked on its . GazeboROSgazebo/set_link_stategazebo/set_model_state/use_sim_timeBool/clock/clock/use_sim_timegazebo/link_statesgazebo/model_statesgazebo/spawn_urdf_modelgazebo/spawn_gazebo_modelgazebo/delete_modelgazebo/get_model_propertiesgazebo/get_model_stategazebo/get_world_propertiesgazebo/get_joint_propertiesgazebo/get_link_propertiesgazebo/get_link_stategazebo/get_physics_propertiesgazebo/set_link_propertiesgazebo/set_physics_propertiesgazebo/set_model_stategazebo/set_joint_propertiesgazebo/set_link_stategazebo/pause_physicsgazebo/unpause_physicsgazebo/apply_body_wrenchgazebo/apply_joint_effortgazebo/clear_joint_forcesgazebo/clear_body_wrenchesgazebo/set_link_stategazebo/set_model_state/use_sim_timeBool/clock/clock/use_sim_timegazebo/link_statesgazebo/model_statesgazebo/spawn_urdf_modelgazebo/spawn_gazebo_modelgazebo/delete_modelgazebo/get_model_propertiesgazebo/get_model_stategazebo/get_world_propertiesgazebo/get_joint_propertiesgazebo/get_link_propertiesgazebo/get_link_stategazebo/get_physics_propertiesgazebo/set_link_propertiesgazebo/set_physics_propertiesgazebo/set_model_stategazebo/set_model_configurationgazebo/set_joint_propertiesgazebo/set_link_stategazebo/pause_physicsgazebo/unpause_physicsgazebo/apply_body_wrenchgazebo/apply_joint_effortgazebo/clear_joint_forcesgazebo/clear_body_wrenchesgazebo/set_link_stategazebo/set_model_state/use_sim_timeBool/clock/clock/use_sim_timegazebo/link_statesgazebo/model_statesgazebo/spawn_urdf_modelgazebo/spawn_gazebo_modelgazebo/delete_modelgazebo/get_model_propertiesgazebo/get_model_stategazebo/get_world_propertiesgazebo/get_joint_propertiesgazebo/get_link_propertiesgazebo/get_link_stategazebo/get_physics_propertiesgazebo/set_link_propertiesgazebo/set_physics_propertiesgazebo/set_model_stategazebo/set_model_configurationgazebo/set_joint_propertiesgazebo/set_link_stategazebo/pause_physicsgazebo/unpause_physicsgazebo/apply_body_wrenchgazebo/apply_joint_effortgazebo/clear_joint_forcesgazebo/clear_body_wrenches/clockgzservergzserver~/set_link_state~/set_model_state/use_sim_timeBool/clock/clock/use_sim_time~/link_states~/model_states~/spawn_urdf_model~/spawn_gazebo_model~/delete_model~/get_model_properties~/get_model_state~/get_world_properties~/get_joint_properties~/get_link_properties~/get_link_state~/get_physics_properties~/set_link_properties~/set_physics_properties~/set_model_state~/set_model_configuration~/set_joint_properties~/set_link_state~/pause_physics~/unpause_physics~/apply_body_wrench~/apply_joint_effort~/clear_joint_forces~/clear_body_wrenches/clockgzservergzserver~/set_link_state~/set_model_state/use_sim_timeBool/clock/clock/use_sim_time~/link_states~/model_states~/spawn_urdf_model~/spawn_gazebo_model~/delete_model~/get_model_properties~/get_model_state~/get_world_properties~/get_joint_properties~/get_link_properties~/get_link_state~/get_physics_properties~/set_link_properties~/set_physics_properties~/set_model_state~/set_model_configuration~/set_joint_properties~/set_link_state~/pause_physics~/unpause_physics~/apply_body_wrench~/apply_joint_effort~/clear_joint_forces~/clear_body_wrenches"
W2533,https://wiki.ros.org/ecto_ros,Wiki,ecto_ros,A set of generic cells to interact with ROS
W2534,https://wiki.ros.org/gl_dependency,Wiki,gl_dependency,This encapsulates the GL dependency for a specific ROS distribution and its Qt version
W2535,https://wiki.ros.org/frontier_exploration,Wiki,frontier_exploration,"Implementation of  for ROS, extending on the existing navigation stack (costmap_2d, move_base).
  It accepts exploration goals via  (Rviz UI provided), sends movement commands to .











 () 

Please check the  for common problems, or open an  if still unsolved. The best way to try  is using the demo provided in , see the . The  package provides a  layer plugin , and  client/server nodes  and . The provided nodes can be used to demo the functionality of the costmap layer by executing a frontier exploration task bounded by a user-defined polygon area. Layer  can certainly be used for more complex exploration tasks, functionality is exposed through two :  and . To run this demo on your host, see  section. Also, this video is an example of  integrated with  (). At this point the demo robot should start moving . If you just want to start taking advantage of the functionality of this package,  helps. If you like to understand a little more in depth, generally, when launched  will spin until it receives an exploration goal. To submit a goal: Once the server receives a goal, it will create the initial exploration map, start processing sensor/costmap data, and issuing  action goals. By default, the exploration task will explore all areas within boundary (whether previously visited or not). Sample launch files for several use cases are provided below. When running the action server/client without a global  information source, enable the  parameter to dynamically resize the map based on the action goal's polygon boundary. Error messages thrown up by  regarding the sensor being outside of map bounds will occur when the robot is traveling outside the exploration boundary. These can be safely ignored, and could be suppressed using  configuration files. If not using  (e.g. running unbounded exploration), make sure the costmap is configured with a large enough height/width. Sample launch file:  When running the action server/client with a global  information source (either from  or ), the exploration costmap will match size/resolution to the external map source map loaded by the static layer, so it is important to disable the  parameter and that the  of the exploration costmap matches that of the external /map. When exploring with , you must also disable  to prevent the node from re-exploring known areas. Sample launch file:  The  node executes exploration actions for any connected clients. It uses a  object to keep track of the exploration progress, and creates movement goals for  as necessary. frontier_explorationfrontier_explorationBoundedExploreLayerexplore_clientexplore_serverBoundedExploreLayerUpdatePolygonBoundaryGetNextFrontierfrontier_exploration/mapMarker pluginDisplays --> Marker --> Marker Topicexploration_polygon_markerPublish Pointnexplore_serverexplore_clientexploration_polygon_markermove_base/mapresize_to_boundarycostmap_2drosconsoleresize_to_boundary/mapmap_servergmappingresize_to_boundaryglobal_framegmappingexplore_clear_spaceexplore_clientExploreTaskexplore_serverexplore_serverexplore_server/clicked_pointexploration_polygon_markerexplore_serverexplore_servermove_basemove_base~explore_costmap/explore_boundary/update_boundary_polygon~explore_costmap/explore_boundary/get_next_frontier~explore_costmappluginsBoundedExploreLayer~frequencyfloat0.0move_basemove_base~goal_aliasingfloatfrequency0.0~goal_aliasingmove_basesensor_range/2~goal_aliasing0.0frontier_exploration::BoundedExploreLayer~frontierspcl::Pointcloud<pcl::PointXYZI>~get_next_frontier~update_boundary_polygon~get_next_frontier~resize_to_boundarybool~update_boundary_polygon~frontier_travel_pointstringpose~get_next_frontierpose.positionclosestmiddlecentroid~explore_clear_spaceboolsudo apt-get install ros-$ROS_DISTRO-frontier-exploration ros-$ROS_DISTRO-navigation-stageroslaunch navigation_stage move_base_gmapping_5cm.launch

roslaunch navigation_stage move_base.xml

roslaunch frontier_exploration global_map.launch"
W2536,https://wiki.ros.org/epos_driver,Wiki,epos_driver,"ROS driver for EPOS controller


 Package includes C library () to control the EPOS motor control from maxon motor () using a GNU/Linux system and ROS wrapper. /tf/EPOSState/MoveTo/MoveCycle"
W2537,https://wiki.ros.org/find_object_2d,Wiki,find_object_2d,"The find_object_2d package
 


 


Simple Qt interface to try OpenCV implementations of SIFT, SURF, FAST, BRIEF and other feature detectors and descriptors. Using a webcam, objects can be detected and published on a ROS topic with ID and position (pixels in the image). This package is a ROS integration of the  application. Visit  for some tutorials. 
Kinect v2 example (you will need  package and ): imagesubscribe_depthrgb/image_rect_colorsubscribe_depthrgb/camera_infosubscribe_depthregistered_depth/image_rawsubscribe_depthobjectsobjectsStamped~subscribe_depthbool""true""~guibool""true""~objects_pathstring""""~session_pathstring""""objects_path~settings_pathstring""""~object_prefixstring""object""@misc{labbe11findobject,
   Author = {{Labb\'{e}, M.}},
   Howpublished = {\url{http://introlab.github.io/find-object}},
   Note = {accessed YYYY-MM-DD},
   Title = {{Find-Object}},
   Year = 2011
} $ roscore &
 # Launch your preferred usb camera driver
 $ rosrun uvc_camera uvc_camera_node &
 $ rosrun find_object_2d find_object_2d image:=image_raw $ rosrun find_object_2d print_objects_detected
  (...)
  ---
  Object 6 detected at (271.389282,138.113373)
  Object 7 detected at (115.537971,151.215271)
  ---
  Object 6 detected at (271.389862,138.345398)
  Object 7 detected at (115.422760,163.439835)
  (...)$ roslaunch openni_launch openni.launch depth_registration:=true
$ roslaunch find_object_2d find_object_3d.launch
$ rosrun rviz rviz  (for visualisation purpose: set ""fixed_frame"" to ""/camera_link"" and add TF display)$ roslaunch kinect2_bridge kinect2_bridge.launch publish_tf:=true
$ roslaunch find_object_2d find_object_3d_kinect2.launch"
W2538,https://wiki.ros.org/genlisp,Wiki,genlisp,Common-Lisp ROS message and service generators.
W2539,https://wiki.ros.org/fiducial_slam,Wiki,fiducial_slam,"ROS node to build a 3D map of fiducials and estimate robot pose from fiducial transforms


 ,  and  specify the translation of the fiducial from the origin in meters, and , , and  specify its orientation in degrees. The fields  and  represent how good the pose estimate is considered to be, and how many observations were used to generate it.   is a list of the ids of fiducials that have been observed at the same time as the current fiducial. The coordinate frame used is the  frame, which is relative to the floor, so markers of the ceiling will have been rotated.  The supplied launch files specify the map file as .  fiducial_slam/fiducial_transforms/tf/fiducial_posefiducials/fiducial_map/tf~clear_map~map_filestring~odom_framestringtftfodombase_linktfmapodom~map_framestring~base_framestringtf~future_date_transformsdouble~publish_6dof_poseboolz~read_only_mapbool~tf_publish_intervalfloatid x y z pan tilt roll variance numObservations linksxyzpantiltrollvariancenumObservationslinksmap~/.ros/slam/map.txt"
W2540,https://wiki.ros.org/gscam,Wiki,gscam,"A ROS camera driver that uses gstreamer to connect to
    devices such as webcams.
 is meant as a simple approach to using a webcam in ROS that maximizes compatibility.  leverages , a multimedia framework similar to DirectShow. Specifically: Gstreamer can be used to build up multimedia ""pipelines"" consisting of sources, sinks, and filters.  For example: a v4l webcam  might be  by an upscaler before being sent to the screen (a ). Alternately, a mp4 file might act as a source and be filtered into an avi file as a sink. There are many possibilities.  For an overview see: .  can attach itself to a specially formatted pipeline. Provided this pipeline is processing RGB video,  will rebroadcast the video over as  a standard ROS image transport  a ROS Camera. Since Gstreamer is compatibile with almost every video capture standard under Linux (and many on OSX),  makes ROS defacto compatible with almost every Linux webcam or video system available. Moreover, because there are a number of Gstreamer filters for processing video (e.g. white-balancing, cropping, etc.) gscam allows for a more advanced video processing even with cheaper webcams. 
 expects an environmental variable, , to contain a gstreamer pipeline definition for it to launch. There is one important restriction: 
 is fully compatible with the ROS Camera interface and can be calibrated to provided rectified images. For details, see the appropriate ROS documentation on the  wiki page. 



If you see a ""Processing..."" message, it means  is happily publishing. You need to set the TF frame via the  service described above. gscamgscamgscamgscamgscamgscamGSCAM_CONFIGgscam/dev/video2gscamgscamgst-inspect-0.10GSCAM_CONFIGgscamimage_rawcamera_infoset_camera_infoset_camera_inforoscd gscam
cd bin
export GSCAM_CONFIG=""v4l2src device=/dev/video2 ! video/x-raw-rgb,framerate=30/1 ! ffmpegcolorspace""
rosrun gscam gscam<launch>
  <!-- Set this to your camera's name -->
  <arg name=""cam_name"" value=""creative_cam"" />

  <!-- Start the GSCAM node -->
  <env name=""GSCAM_CONFIG"" value=""v4l2src device=/dev/video0 ! video/x-raw-yuv,framerate=30/1,width=640,height=480 ! ffmpegcolorspace "" />
  <node pkg=""gscam"" type=""gscam"" name=""$(arg cam_name)"">
    <param name=""camera_name"" value=""$(arg cam_name)"" />
    <param name=""camera_info_url"" value=""package://localcam/calibrations/${NAME}.yaml"" />
    <remap from=""camera/image_raw"" to=""$(arg cam_name)/image_raw"" />
  </node>

  <!-- Provide rectification -->
  <node pkg=""image_proc"" type=""image_proc"" name=""creative_image_proc""
        ns=""$(arg cam_name)"" />

  <!-- View the raw and rectified output -->
  <node pkg=""image_view"" type=""image_view"" name=""creative_view"" >
    <remap from=""image"" to=""/$(arg cam_name)/image_raw"" />
  </node>
    
  <node pkg=""image_view"" type=""image_view"" name=""creative_view_rect"" >
    <remap from=""image"" to=""/$(arg cam_name)/image_rect_color"" />
  </node>
</launch>MessageFilter [target=/map ]: Discarding message from [/gscam_publisher] due to empty frame_id.  This message will only print once."
W2541,https://wiki.ros.org/gazebo_msgs,Wiki,gazebo_msgs,"Message and service data structures for interacting with Gazebo from ROS.
See  "
W2542,https://wiki.ros.org/ecl_threads,Wiki,ecl_threads,"This package provides the c++ extensions for a variety of threaded 
     programming tools. These are usually different on different 
     platforms, so the architecture for a cross-platform framework
     is also implemented.



If outside ros, you will also need to link to . MutexThreadThreadable



















find_package(catkin REQUIRED COMPONENTS
   ecl_threads
   # other dependencies ...
)"
W2543,https://wiki.ros.org/fs100_motoman,Wiki,fs100_motoman,"The fs100_motoman package. Contains a node for connect and streaming to a FS100 controller.




Source:  The fs100_motoman package was created together with the Technical University of Denmark (DTU), Institute for Automation and Control (). The reason for this package was to provide an easy way to continuously stream a trajectory to the FS100 controller, to enable real-time sensor based control. Use github to report a bug and view current issues.  fs100_motoman/mh5l/joint_targetfs100_motoman/mh5l/joint_statefs100_motoman/mh5l/reset_trajectoryIPstringsudo apt-get install ros-hydro-fs100-motoman"
W2544,https://wiki.ros.org/geometry_tutorials,Wiki,geometry_tutorials,"Metapackage of geometry tutorials ROS.

 See . "
W2545,https://wiki.ros.org/freenect_launch,Wiki,freenect_launch,"Launch files for freenect_camera to produce rectified, registered
    or disparity images.  Also produce point clouds and registered
    point clouds.  Based on the openni_launch package. 

 contains a few modifications from  apart from running the libfreenect based driver. These are documented below. 

This package contains launch files for using a Microsoft Kinect using the libfreenect library. This folder replicates the API offered by  in an effort to maintain maximum compatibility with the OpenNI driver. Differences are mentioned below. To use this package, please refer to  and  documentation. The migration guide to/from the OpenNI driver is documented . There are a few additional launch files in  that demonstrate running a different constellation of nodelets. This is useful for launching the minimum set of required processing nodelets, as well as avoid unnecessary warnings during launch. For example: freenect_launchfreenect.launchopenni.launchfreenect.launch supportsfreenect-ns.launchfreenect.launchfreenect-diagnostics.launchfreenect.launchfreenect-debug.launchfreenect_launchfreenect-xyz.launch/camera/depth/pointsfreenect-registered-xyzrgb.launch/camera/depth_registered/pointsroslaunch freenect_launch freenect.launch"
W2546,https://wiki.ros.org/geodesy,Wiki,geodesy,"Python and C++ interfaces for manipulating geodetic coordinates.





All C++ symbols defined by this package reside in the  namespace.  This is the base type for communicating geodetic information between ROS nodes, using  and   messages. All Python modules defined by this package reside in the  namespace.  "
