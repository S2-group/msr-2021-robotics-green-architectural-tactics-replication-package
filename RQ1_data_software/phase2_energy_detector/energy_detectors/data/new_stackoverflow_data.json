[
{"title": "Difference between spin and rate.sleep in ROS", "time": "2014-04-22 18:03:33Z", "post_content": ["I am new to ROS and trying to understand this powerful tool. I am confused by the spin and rate.sleep functions. Could anyone help me with difference between those two functions and when to use which? Thanks. "], "answer": [" and ", " are resposible to handle communication events, e.g. arriving messages. If you are subscribing messages, services or actions you must call spin to process the events. ", "While ros::spinOnce() handles the events and returns immediately, ros::spin() blocks until ros invokes a shutdown. So ros::spinOnce() gives you more control if needed. More on that matter here: ", ".", "rate.sleep() on the other hand is merely a thread sleep with duration defined be a frequency. Here is an example", "This loop will be executed 24 times a second or less, depends what you do inside the loop. A ", " object keeps track of how much time since last ", " was executed and sleep for the correct amount of time to hit the 24 Hz mark. See ", "API.", "The equivalent way in the time domain is ", "Which one you use is just a matter of convenience."], "answer_code": ["ros::spin()", "ros::spinOnce()", "ros::Rate rate(24.);\nwhile(ros::ok())\n{\n    rate.sleep();\n}\n", "ros::Rate", "rate.sleep()", "ros::Rate::sleep()", "ros::Duration::sleep()", "ros::Duration duration(1./24.);\nwhile(ros::ok())\n{\n    duration.sleep();\n}\n"], "url": "https://stackoverflow.com/questions/23227024/difference-between-spin-and-rate-sleep-in-ros"},
{"title": "kinect not connecting even though powered", "time": "2016-04-19 16:15:22Z", "post_content": ["I'm trying to use a kinect xbox360 with ubuntu 12.04 (and eventually ROS).  ", "The kinect is plugged in and powered on (blinking green light).  When running ", ", I do ", " see the expected three Microsoft devices ", "When running ", ", I do see a device, with device ID that changes when plugging in/ unplugging the kinect (I also see a different device ID when plugging in a USB drive to test...).", "\nI thought it might be a permissions issue, so I've added my user name to the \"dialout\" group ", " and logged out... without a change in behaviour.  ", "Any ideas would be appreciated. Thanks."], "answer": [], "question_code": ["lsusb", "Bus 002 Device 009: ID 045e:02ae Microsoft Corp. \n Bus 002 Device 008: ID 045e:02ad Microsoft Corp. \n Bus 002 Device 007: ID 045e:02b0 Microsoft Corp.", "lsusb -t", "sudo adduser username dialout"], "url": "https://stackoverflow.com/questions/36723982/kinect-not-connecting-even-though-powered"},
{"title": "My ROS DWAPlanner planned overshoot trajectories", "time": "2018-04-14 16:38:58Z", "post_content": ["I'm running ROS move_base with DWAPlanner and I got strange navigation behavior. The DWAPlanner seems plan overshoot trajectories when the robot is closed to the goal,\nso that the robot moves thru the goal and moves back.. and so on... ", "I checked the topic /move_base/DWAPlannerROS/global_plan and /move_base/DWAPlannerROS/local_plan. The local_plan did actually follow the global plan and target to the correct target goal pose when the goal is in local costmap. The result trajectories are so strange. Please help and any comment will be appreciated. ", "Look:\n", "The pink is the goal, the green is the global plan and the red is the result trajectory. You can see the result trajectory is overshoot. ", "Here is the video: \n", "and parameters"], "answer": [], "question_code": ["DWAPlannerROS:\n  max_trans_vel: 0.8\n  min_trans_vel: 0.05 # 0.05 # 0.05\n  max_vel_x: 0.6\n  min_vel_x: -0.6\n  max_vel_y: 0.0  # zero for a differential drive robot\n  min_vel_y: 0.0\n  max_rot_vel: 0.6 # 1.0\n  min_rot_vel: 0.02 # 0.2\n  acc_lim_x: 1.0\n  acc_lim_y: 0.0  # zero for a differential drive robot\n  acc_lim_theta: 2.0\n\n  xy_goal_tolerance: 0.10\n  yaw_goal_tolerance: 0.10\n  latch_xy_goal_tolerance: true\n\n  oscillation_reset_dist: 0.05\n  oscillation_reset_angle: 0.2\n\n  path_distance_bias:  32.0 # 32.0 # 60\n  goal_distance_bias:  24.0 # 24.0\n  occdist_scale:      0.01 # 1.0 # 0.5 # 0.01\n  forward_point_distance: 0.325\n  sim_time: 2.0 # 3.0 # 2.0\n  sim_granularity: 0.05 # 0.025 # 0.1\n  angular_sim_granularity: 0.06 # 0.02\n  vx_samples: 5 # 3\n  vy_samples: 1  # zero for a differential drive robot\n  vtheta_samples: 10 # 40 # 20\n  dwa: false # true\n\nglobal_costmap:\n  global_frame: /map\n  robot_base_frame: /base_footprint\n  update_frequency: 2.0\n  publish_frequency: 1.0\n  static_map: true\n#  width: 10.0\n#  height: 10.0 \n  origin_x: 0\n  origin_y: 0\n  resolution: 0.05\n#  inflation_radius: 1.5\n#  cost_scaling_factor: 5.0\n  inflation_radius: 1.5\n  cost_scaling_factor: 2.0\n  allow_unknown: true\n#  plugins:\n#    - {name: static_layer, type: \"costmap_2d::StaticLayer\"}\n    #- {name: sonar_layer,   type: \"range_sensor_layer::RangeSensorLayer\"}\n#    - {name: obstacle_layer, type: \"costmap_2d::VoxelLayer\"}\n    #- {name: sonar_layer,   type: \"range_sensor_layer::RangeSensorLayer\"}\n#    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n    #- {name: sonar_layer,   type: \"range_sensor_layer::RangeSensorLayer\"}\n  plugins:\n      - {name: static_map,       type: \"costmap_2d::StaticLayer\"}\n      - {name: obstacles,        type: \"costmap_2d::VoxelLayer\"}\n#      - {name: simplelayer,      type: \"simple_layer_namespace::SimpleLayer\"}     \n      - {name: inflation_layer,  type: \"costmap_2d::InflationLayer\"}\n\n\nlocal_costmap:\n  global_frame: /map\n  robot_base_frame: /base_footprint\n  update_frequency: 10.0\n  publish_frequency: 5.0\n  static_map: false\n  rolling_window: true\n  width: 4.0\n  height: 4.0\n  resolution: 0.05\n  publish_cost_grid: true\n  #ORIG  inflation_radius: 1.5\n  #ORIG  cost_scaling_factor: 2.0\n  inflation_radius: 1.5\n  cost_scaling_factor: 2.0\n  plugins:\n    - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n"], "url": "https://stackoverflow.com/questions/49827856/my-ros-dwaplanner-planned-overshoot-trajectories"},
{"title": "Precise Intrinsic Camera Calibration - for ROS camera_info message", "time": "2018-06-14 07:38:04Z", "post_content": ["I use for intrinsic camera calibration the CALDE Tool (", ") which is really powerfull and I would advise everybody to use this for precise intrinsic camera calibration.", "Calde gives me in the end a file that looks like this:", "Now I need this data stored in a ros camera_info message that looks like this:\nSee here: "], "answer": ["It seems you have a single camera. In P matrix:", "fx: first value in fc_1.", "fy: second value in fc_1.", "cx and cy: values in cc_1 in same order as f.", "and if you have a single camera, documentation says Tx and Ty are 0.", "About distortion parameters, In ROS documentation distortion parameters with k are radial distortion parameters and t are tangential distortion parameters (plumb bob is combination of radial and tangential distortion). Since your CALDE tool only calculated first two radial distortion parameters, you can use those in same order."], "question_code": ["% CAMERA # 1\n% \n\n% Image size:\nimagesize_1 = [ 640 480 ]\n\n% Focal length:\nfc_1 = [ 537.417 537.311 ]\n\n% Principal point:\ncc_1 = [ 314.329 239.206 ]\n\n% Skew (please note Skew = Gamma/ScaleX):\nalpha_c_1 = [ 0.00168813 ]\n\n% Distortion (radial, decentering, and thin-prism, if any)\n% (only kc_ is present in Bouguets toolbox, in that order)\nkc_1 = [ 0.0450068 -0.144093 0.00000 0.00000 0.00000 ]\nradial_1 = [ 0.0450068 -0.144093 0.00000 ]\ndecentering_1 = [ 0.00000 0.00000 0.00000 ]\nthinprism_1 = [ 0.00000 0.00000 0.00000 ]\n\n% TCP_T_CAMERA:\nTCP_T_CAMERA1 = [ ...\n 1.00000 0.00000 0.00000 0.00000 ;\n 0.00000 1.00000 0.00000 0.00000 ;\n 0.00000 0.00000 1.00000 0.00000 ]\n\n\n% MAINCAMERA_T_OBJECT:\n\nMAINCAMERA_T_OBJECT(1:3,1:4,1) = [ ...\n 0.973021 0.118707 -0.197836 -41.0266 ;\n -0.0730198 0.971849 0.224004 -11.4107 ;\n 0.218857 -0.203514 0.954297 662.759 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,2) = [ ...\n 0.999266 0.0369076 0.0102493 76.4807 ;\n -0.0381896 0.980636 0.192078 116.143 ;\n -0.00296168 -0.192328 0.981326 1084.49 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,3) = [ ...\n 0.992568 -0.0105678 -0.121230 106.536 ;\n 0.0316905 0.984295 0.173663 -159.832 ;\n 0.117491 -0.176215 0.977315 1087.52 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,4) = [ ...\n 0.877250 -0.0191499 0.479652 166.351 ;\n -0.0501447 0.990082 0.131240 -29.7432 ;\n -0.477408 -0.139182 0.867589 988.947 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,5) = [ ...\n 0.527366 -0.00319134 0.849632 144.484 ;\n -0.124694 0.988874 0.0811117 -24.5847 ;\n -0.840438 -0.148719 0.521101 969.772 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,6) = [ ...\n 0.891724 0.0522552 -0.449552 94.2428 ;\n 0.0213817 0.987339 0.157179 -0.458213 ;\n 0.452074 -0.149773 0.879317 1082.62 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,7) = [ ...\n 0.693097 0.0722656 -0.717212 76.8902 ;\n 0.0699173 0.983531 0.166666 -17.6251 ;\n 0.717445 -0.165661 0.676631 1050.90 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,8) = [ ...\n 0.985416 0.0898682 -0.144496 -31.7523 ;\n -0.0664750 0.984994 0.159272 140.445 ;\n 0.156641 -0.147344 0.976603 1565.78 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,9) = [ ...\n 0.992972 0.0389569 -0.111755 -211.173 ;\n -0.0133414 0.975099 0.221369 228.341 ;\n 0.117596 -0.218323 0.968765 1974.26 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,10) = [ ...\n 0.997039 0.0730305 -0.0240702 -26.9394 ;\n -0.0675975 0.981645 0.178339 -45.1356 ;\n 0.0366525 -0.176183 0.983675 706.637 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,11) = [ ...\n 0.998929 0.0272116 -0.0374343 -5.70587 ;\n -0.0215852 0.989451 0.143250 -2.35603 ;\n 0.0409375 -0.142289 0.988978 647.193 ]\n\nMAINCAMERA_T_OBJECT(1:3,1:4,12) = [ ...\n 0.987303 0.121919 -0.101829 -177.281 ;\n 0.00962968 0.593922 0.804465 91.9028 ;\n 0.158558 -0.795231 0.585206 1072.55 ]\n", "The distortion model used. Supported models are listed in\nsensor_msgs/distortion_models.h. For most cameras, \"plumb_bob\" - a\nsimple model of radial and tangential distortion - is sufficient.\nstring distortion_model\n\nThe distortion parameters, size depending on the distortion model.\nFor \"plumb_bob\", the 5 parameters are: (k1, k2, t1, t2, k3).\nfloat64[] D\n\nIntrinsic camera matrix for the raw (distorted) images.\n     [fx  0 cx]\n K = [ 0 fy cy]\n     [ 0  0  1]\nProjects 3D points in the camera coordinate frame to 2D pixel\ncoordinates using the focal lengths (fx, fy) and principal point\n(cx, cy).\nfloat64[9]  K # 3x3 row-major matrix\n\nRectification matrix (stereo cameras only)\nA rotation matrix aligning the camera coordinate system to the ideal\nstereo image plane so that epipolar lines in both stereo images are\nparallel.\nfloat64[9]  R # 3x3 row-major matrix\n\nProjection/camera matrix\n    [fx'  0  cx' Tx]\n P = [ 0  fy' cy' Ty]\n    [ 0   0   1   0]\n By convention, this matrix specifies the intrinsic (camera) matrix\n  of the processed (rectified) image. That is, the left 3x3 portion\n  is the normal camera intrinsic matrix for the rectified image.\n It projects 3D points in the camera coordinate frame to 2D pixel\n  coordinates using the focal lengths (fx', fy') and principal point\n (cx', cy') - these may differ from the values in K.\n For monocular cameras, Tx = Ty = 0. Normally, monocular cameras will\n  also have R = the identity and P[1:3,1:3] = K.\n For a stereo pair, the fourth column [Tx Ty 0]' is related to the\n  position of the optical center of the second camera in the first\n  camera's frame. We assume Tz = 0 so both cameras are in the same\n  stereo image plane. The first camera always has Tx = Ty = 0. For\n  the right (second) camera of a horizontal stereo pair, Ty = 0 and\n  Tx = -fx' * B, where B is the baseline between the cameras.\n Given a 3D point [X Y Z]', the projection (x, y) of the point onto\n the rectified image is given by:\n  [u v w]' = P * [X Y Z 1]'\n         x = u / w\n         y = v / w\n  This holds for both images of a stereo pair.\nfloat64[12] P # 3x4 row-major matrix\n"], "url": "https://stackoverflow.com/questions/50852077/precise-intrinsic-camera-calibration-for-ros-camera-info-message"},
{"title": "RosAria node doesn\u2019t receive messages", "time": "2018-10-29 14:55:46Z", "post_content": ["Macbook Air with Ubuntu virtual machine via VMWare", "\nPioneer3 AT robot", "\nROS", "\nRosAria", "I have at least most of the setup for Ros+RosAria already working:", "The RosAria node running on the robot confirms it\u2019s able to connect to the master, and if I run the command ", " on the laptop I can see ", " as one of the available topics.", "In the terminal window where I try to publish to ", " I\u2019m told that the message is sending but the robot shows no signs of having received it, neither console message nor movement of the wheels.", "However, if I quit the RosAria node on the robot and restart it while leaving the ", " command running on my laptop, the robot registers the message once upon startup, moves accordingly for a bit, and then does nothing.", "I\u2019ve also tried to ", " other topics like battery state, motors status and pose, but I don\u2019t receive any messages from the robot.", "I already tried changing the parameters ", " and ", " according to ", ".", "The project I was working on where this problem came up isn\u2019t using the same equipment anymore, so now this question is not so urgent for me. I\u2019m also not able to test proposed solutions in the near future since I no longer have access to that Pioneer robot. However, I\u2019ll keep this topic unanswered in case someone else encounters this problem too."], "answer": ["You need To Set ROS_IP On Robot side too to let the ROS System Knows What IP To Use as It's Network Interface", "I myself Set This Environments Inside ", " Like This:", "and then source ", ".", "I think You can use ", " Too  But  I never tested."], "question_code": ["192.168.1.112", "roscore", "192.168.1.108", "rosrun rosaria RosAria", "rosparam set...", "ROS_MASTER_URI=192.168.1.112:11311", "ROS_IP=192.168.1.112", "rostopic pub /RosAria/cmd_vel geometry_msgs/Twist \u201clinear:... angular:...\u201d", "rostopic list", "/RosAria/cmd_vel", "/RosAria/cmd_vel", "rostopic pub", "rostopic echo", "/RosAria/TicksMM", "/RosAria/RevCount", "cmd_vel"], "answer_code": [".bashrc", "export ROS_IP=192.168.1.108", ".bashrc", "rosparam", "ROS_IP", "ROS_MASTER_URI"], "url": "https://stackoverflow.com/questions/52939173/rosaria-node-doesn-t-receive-messages"},
{"title": "Switching ROS local planner in pre-existing project", "time": "2019-02-26 12:26:06Z", "post_content": ["Currently, I am working on a autonomous robot, which has a non-standard method of steering. Rather than using tank steering, it instead has two pivot wheels in the rear and two front-powered wheels.\nBecause the base_local_planner that is currently being used does not have any support for this setup, the planning is basically useless.", "The core question is:\nIs it possible to change the local planner used from base_local_planner to something like the teb_local_planner, which at least has support for the shape of the robot, and how would something like this be achieved?", "Additional information:"], "answer": ["I believe that the local planners you are talking about only support differential steering or skid steering.  Sounds like your robot is more similar to Ackermann steering.  I am not aware of any out of the box options for Ackermann in ROS, but I do know it has been done with ", ", if you can find how they did it, it might solve your issue."], "url": "https://stackoverflow.com/questions/54885567/switching-ros-local-planner-in-pre-existing-project"},
{"title": "Raspberry Pi is freezing since CPU usage reaches 100 while installing ROS", "time": "2018-10-03 09:05:44Z", "post_content": ["I am trying to install ROS on Raspberry Pi 3 (Raspbian Jessie).", "After invoking following command, I realized that Raspberry Pi is freezing and it is not responding anymore-", "I tried to power it off and re-run the above command. However, it got stuck again on the same line. I also tried to use CLI but got in vain. Please see below a picture-", "Please see below the output of ", " command-"], "answer": ["Your system is running out of memory. Even your swap is full. You can solve this issue in multiple ways:"], "question_code": ["sudo ./src/catkin/bin/catkin_make_isolated --install -DCMAKE_BUILD_TYPE=Release --install-space /opt/ros/indigo\n", "top", "htop", "top"], "answer_code": ["--jobs 1"], "url": "https://stackoverflow.com/questions/52621056/raspberry-pi-is-freezing-since-cpu-usage-reaches-100-while-installing-ros"},
{"title": "How to make a pyqt gui refresh", "time": "2018-06-21 21:24:20Z", "post_content": ["I am making a gui in pyqt which gets battery levels for a robot and then displays them. The gui would therefore have to constantly update its battery level displays (which are displayed using QProgressBar). ", "However, if I were to put the progress bars in a loop, it makes infinite copies of the graphics and stacks them on top of each other. So essentially my question would be how might I make the progress bars refresh without making additional copies? Is there a way to delete everything in the loop after each recurrence?"], "answer": ["make the progress bar a global var, and have another thread call the update progress method, don't copy the progress bar itself.", "Also, in this site, it is customary to copy and paste code, otherwise how will other people will follow the time honored tradition to copy the question instead of the answer?"], "url": "https://stackoverflow.com/questions/50977603/how-to-make-a-pyqt-gui-refresh"},
{"title": "System hangs while running a .cpp code using SURF algorithm", "time": "2018-05-24 07:10:51Z", "post_content": ["I am working on image processing using openCV and c++. I wrote a code using SURF algorithm for detecting the keypoints from an image and show the detected keypoints. I am able to build and run the code without any error. But the system hangs after running the code.", "I am using Ubuntu 16.04, ROS Kinetic and OpenCV 3.3.1 which was installed automatically with ROS.", "I included all the necessary header files for using SURF algorithm and also used required 'namespaces'. The main file of my code is as follows:", "I had edited the CMakeLists.txt and Package.xml file also. After that I followed the steps:", "When the code start running, the system hangs. So, I just try to build and run each steps. I came to know that the system works fine till ", ". But the system hangs if I include the step ", ". If I try to run the whole code (above code), after 5-6 minutes, it will display the number of detected keypoints and the windows 'template_image' and 'temp_kp' with the image(sign.jpg), but not displaying the detected keypoints in 'temp_kp'. And finally I have to force restart the system using power button.", "How can I fix this and what might be the reason?", "Thanks in advance."], "answer": [], "question_code": ["using namespace cv;\nusing namespace std\nusing namespace cv::xfeatures2d;\nint main(int argc,char **argv)\n{\nros::init(argc,argv,\"image_detection\");\nwhile(1)\n{\nMat temp_image=imread(\"/home/pelican/Pictures/sign.jpg\",CV_LOAD_IMAGE_GRAYSCALE);\nMat temp_kp;\n\n//initialize SURF\nPtr<SURF>detector=SURF::create(500,4,4,false,false);\n\n//compute keypoints\nvector<KeyPoint>kp;\ndetector->detect(temp_image,kp);\n\n//display keypoints\ndrawKeypoints(temp_image,kp,temp_kp,Scalar(255,0,150),DrawMatchesFlags::DEFAULT);\ncout<<\"detected kp=\"<<kp.size()<<endl;\n\nnamedWindow(\"template_image\",CV_WINDOW_NORMAL);\nimshow(\"template_image\",temp_image);\nnamedWindow(\"temp_kp\",CV_WINDOW_NORMAL);\nimshow(\"temp_kp\",temp_kp);\n\nros::spinOnce();\nif(waitKey(30)==27) //wait for esc key press for 30ms. If pressed,break loop\n{\ncout<<\"esc key pressed\"<<endl;\nbreak;\n}\n}\nreturn 0;\n}\n", "vector<KeyPoint>kp;", "detector->detect(temp_image,kp);"], "url": "https://stackoverflow.com/questions/50503152/system-hangs-while-running-a-cpp-code-using-surf-algorithm"},
{"title": "Link library correct with ROS and cmake", "time": "2015-01-12 08:49:56Z", "post_content": ["I'm trying to add use some code for a MOXA I/O Ethernet module with ROS. I'm using some example code, to ensure it works. I have compiled the code with gcc, so I know the code works. I compiled it from a terminal with this line:", "g++ -L/usr/lib/x86_64-linux-gnu -pthread main.cpp -Wall -O3 -omain_test -L/usr/local/lib -lmxio_x64    ", "I get the main_test.out and it works.", "So I created a catkin workspace and a new package by following the ROS tutorial. I add my code to the src folder, edits the CMakeList and the package.xml. Then when I try to run catkin_make -Wall (to get rid of a lot of warnings), I get the following message:", "I also got the \"undefined reference to 'phread_create'\" when I compiled with gcc, and solved that problem by calling -pthread before main.cpp.\nSo my problem now is, how can I do the same with CMake?\nI have searched a lot and tried different solutions, but nothing have worked so far. I'm pretty green, when it comes to ROS and CMake, so I'm not sure what to add where, or if I have written something wrong somewhere in my CMakeLists.txt or package.xml. ", "I'm using Ubuntu 14.04 LTS and ROS Indigo.\nIf you need anymore info, let my know.", "On before hand, thanks.", "[EDIT 1]\nI have now tried adding", "set(CMAKE_CXX_FLAGS \"-lpthread\")", "After project(master) in the CMakeLists.txt.\nI also tried with:", "set(CMAKE_CXX_FLAGS \"-L/usr/lib/x86_64-linux-gnu -pthread\")", "and", "But it gave the same error message.", "My CMakeLists.txt:", "My package.xml:", "[EDIT 2]\nAfter request from @Lu-Niu did I run ", " (catkin_make should be the same as the make command, as far as I know, the catkin part is just because it's within ROS) and the output is in the box bellow. As far, as I can see, so is -pthread specified, while I think it should be -lpthread, when the directory isn't specified first (correct me, if I'm wrong). So what should I edit, to change the order of the command?", "[EDIT 3]\nBoth of @fenix688 's suggestions are giving this output (with VERBOSE=1):", "While if I remove everything with pthread from the CMakeLists.txt do I get this VERBOSE=1 output, where -lpthread still is set.", "[EDIT 4]\nTried with the CMakeLists.txt @fenix688 wrote and it gave the same error with this output:"], "answer": ["Well, we need to investigate on your issue. When you run make after cmake, could you run ", " so that we can see the actual command it execute and whether the pthread flag is specified correctly. you can also refer to this thread: ", "You could try this complete ", " code:", "I hope it works!"], "quote": ["g++ -L/usr/lib/x86_64-linux-gnu -pthread main.cpp -Wall -O3 -omain_test -L/usr/local/lib -lmxio_x64    ", "set(CMAKE_CXX_FLAGS \"-lpthread\")", "set(CMAKE_CXX_FLAGS \"-L/usr/lib/x86_64-linux-gnu -pthread\")"], "question_code": ["Base path: /home/johau/ros_ws\nSource space: /home/johau/ros_ws/src\nBuild space: /home/johau/ros_ws/build\nDevel space: /home/johau/ros_ws/devel\nInstall space: /home/johau/ros_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/johau/ros_ws/build\"\n####\n-- Using CATKIN_DEVEL_PREFIX: /home/johau/ros_ws/devel\n-- Using CMAKE_PREFIX_PATH: /home/johau/ros_ws/devel;/opt/ros/indigo\n-- This workspace overlays: /home/johau/ros_ws/devel;/opt/ros/indigo\n-- Using PYTHON_EXECUTABLE: /usr/bin/python\n-- Using Debian Python package layout\n-- Using empy: /usr/bin/empy\n-- Using CATKIN_ENABLE_TESTING: ON\n-- Call enable_testing()\n-- Using CATKIN_TEST_RESULTS_DIR: /home/johau/ros_ws/build/test_results\n-- Found gtest sources under '/usr/src/gtest': gtests will be built\n-- Using Python nosetests: /usr/bin/nosetests-2.7\n-- catkin 0.6.9\n-- BUILD_SHARED_LIBS is on\n-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-- ~~  traversing 1 packages in topological order:\n-- ~~  - master\n-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-- +++ processing catkin package: 'master'\n-- ==> add_subdirectory(master)\n-- Boost version: 1.54.0\n-- Found the following Boost libraries:\n--   thread\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/johau/ros_ws/build\n####\n#### Running command: \"make -Wall -j8 -l8\" in \"/home/johau/ros_ws/build\"\n####\nLinking CXX executable /home/johau/ros_ws/devel/lib/master/main\nCMakeFiles/main.dir/src/main.cpp.o: In function `main':\nmain.cpp:(.text+0xdd0): warning: the `gets' function is dangerous and should not be used.\n/usr/local/lib/libmxio_x64.so: undefined reference to `pthread_create'\ncollect2: error: ld returned 1 exit status\nmake[2]: *** [/home/johau/ros_ws/devel/lib/master/main] Error 1\nmake[1]: *** [master/CMakeFiles/main.dir/all] Error 2\nmake: *** [all] Error 2\nInvoking \"make\" failed\n", "set(CMAKE_CXX_FLAGS \"-L/usr/lib/x86_64-linux-gnu\")\nset(CMAKE_CXX_FLAGS \"-pthread\")\n", "cmake_minimum_required(VERSION 2.8.3)\nproject(master)\n\nunset(MOXA_LIBRARY CACHE)\n\nfind_library(\n   MOXA_LIBRARY\n   NAMES mxio_x64\n   PATHS /usr/local/lib\n   PATH_SUFFIXES lib\n   NO_DEFAULT_PATH\n)\n\nif(MOXA_LIBRARY STREQUAL \"MOXA_LIBRARY-NOTFOUND\")\n    message(WARNING \"Moxa Library not present !\")\nelse()\n    add_definitions(-DUSE_MOXA)\nendif()\n\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\n find_package(Boost REQUIRED COMPONENTS thread)\n\n###################################\n## catkin specific configuration ##\n###################################\n\ncatkin_package(\n   CATKIN_DEPENDS roscpp std_msgs\n)\n\n###########\n## Build ##\n###########\n\n## Specify additional locations of header files\n## Your package locations should be listed before other locations\n# include_directories(include)\ninclude_directories(\n  ${catkin_INCLUDE_DIRS}\n  /usr/lib/x86_64-linux-gnu/\n)\n\n## Declare a cpp executable\n add_executable(main\n     src/main.cpp)\n\n## Specify libraries to link a library or executable target against\n target_link_libraries(main\n   ${MOXA_LIBRARY}\n   ${catkin_LIBRARIES}\n   ${CMAKE_THREAD_LIBS_INIT}\n )\n", "<?xml version=\"1.0\"?>\n<package>\n  <name>master</name>\n  <version>0.0.0</version>\n  <description>The master package</description>\n\n  <maintainer email=\"johau@todo.todo\">johau</maintainer>\n\n  <license>BSD</license>\n\n  <buildtool_depend>catkin</buildtool_depend>\n  <build_depend>roscpp</build_depend>\n  <build_depend>std_msgs</build_depend>\n  <run_depend>roscpp</run_depend>\n  <run_depend>std_msgs</run_depend>\n\n\n  <!-- The export tag contains other, unspecified, tags -->\n  <export>\n    <!-- You can specify that this package is a metapackage here: -->\n    <!-- <metapackage/> -->\n\n    <!-- Other tools can request additional information be placed here -->\n\n  </export>\n</package>\n", "catkin_make VERBOSE=1", "Base path: /home/johau/ros_ws\nSource space: /home/johau/ros_ws/src\nBuild space: /home/johau/ros_ws/build\nDevel space: /home/johau/ros_ws/devel\nInstall space: /home/johau/ros_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/johau/ros_ws/build\"\n####\n####\n#### Running command: \"make VERBOSE=1 -j8 -l8\" in \"/home/johau/ros_ws/build\"\n####\n/usr/bin/cmake -H/home/johau/ros_ws/src -B/home/johau/ros_ws/build --check-build-system CMakeFiles/Makefile.cmake 0\n/usr/bin/cmake -E cmake_progress_start /home/johau/ros_ws/build/CMakeFiles /home/johau/ros_ws/build/CMakeFiles/progress.marks\nmake -f CMakeFiles/Makefile2 all\nmake[1]: Entering directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/depend\nmake[2]: Entering directory `/home/johau/ros_ws/build'\ncd /home/johau/ros_ws/build && /usr/bin/cmake -E cmake_depends \"Unix Makefiles\" /home/johau/ros_ws/src /home/johau/ros_ws/src/master /home/johau/ros_ws/build /home/johau/ros_ws/build/master /home/johau/ros_ws/build/master/CMakeFiles/main.dir/DependInfo.cmake --color=\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/build\nmake[2]: Entering directory `/home/johau/ros_ws/build'\nLinking CXX executable /home/johau/ros_ws/devel/lib/master/main\ncd /home/johau/ros_ws/build/master && /usr/bin/cmake -E cmake_link_script CMakeFiles/main.dir/link.txt --verbose=1\n/usr/bin/c++   -lpthread    CMakeFiles/main.dir/src/main.cpp.o  -o /home/johau/ros_ws/devel/lib/master/main  -L/usr/local/lib -rdynamic -lmxio_x64 /opt/ros/indigo/lib/libroscpp.so -lboost_signals -lboost_filesystem /opt/ros/indigo/lib/librosconsole.so /opt/ros/indigo/lib/librosconsole_log4cxx.so /opt/ros/indigo/lib/librosconsole_backend_interface.so -llog4cxx -lboost_regex /opt/ros/indigo/lib/libxmlrpcpp.so /opt/ros/indigo/lib/libroscpp_serialization.so /opt/ros/indigo/lib/librostime.so -lboost_date_time /opt/ros/indigo/lib/libcpp_common.so -lboost_system -lboost_thread -lpthread -lconsole_bridge -Wl,-rpath,/usr/local/lib:/opt/ros/indigo/lib \nCMakeFiles/main.dir/src/main.cpp.o: In function `main':\nmain.cpp:(.text+0xdd0): warning: the `gets' function is dangerous and should not be used.\n/usr/local/lib/libmxio_x64.so: undefined reference to `pthread_create'\ncollect2: error: ld returned 1 exit status\nmake[2]: *** [/home/johau/ros_ws/devel/lib/master/main] Error 1\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake[1]: *** [master/CMakeFiles/main.dir/all] Error 2\nmake[1]: Leaving directory `/home/johau/ros_ws/build'\nmake: *** [all] Error 2\nInvoking \"make\" failed\n", "Base path: /home/johau/ros_ws\nSource space: /home/johau/ros_ws/src\nBuild space: /home/johau/ros_ws/build\nDevel space: /home/johau/ros_ws/devel\nInstall space: /home/johau/ros_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/johau/ros_ws/build\"\n####\n#### Running command: \"make VERBOSE=1 -j8 -l8\" in \"/home/johau/ros_ws/build\"\n####\n/usr/bin/cmake -H/home/johau/ros_ws/src -B/home/johau/ros_ws/build --check-build-system CMakeFiles/Makefile.cmake 0\n/usr/bin/cmake -E cmake_progress_start /home/johau/ros_ws/build/CMakeFiles /home/johau/ros_ws/build/CMakeFiles/progress.marks\nmake -f CMakeFiles/Makefile2 all\nmake[1]: Entering directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/depend\nmake[2]: Entering directory `/home/johau/ros_ws/build'\ncd /home/johau/ros_ws/build && /usr/bin/cmake -E cmake_depends \"Unix Makefiles\" /home/johau/ros_ws/src /home/johau/ros_ws/src/master /home/johau/ros_ws/build /home/johau/ros_ws/build/master /home/johau/ros_ws/build/master/CMakeFiles/main.dir/DependInfo.cmake --color=\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/build\nmake[2]: Entering directory `/home/johau/ros_ws/build'\nLinking CXX executable /home/johau/ros_ws/devel/lib/master/main\ncd /home/johau/ros_ws/build/master && /usr/bin/cmake -E cmake_link_script CMakeFiles/main.dir/link.txt --verbose=1\n/usr/bin/c++       CMakeFiles/main.dir/src/main.cpp.o  -o /home/johau/ros_ws/devel/lib/master/main  -L/usr/local/lib -rdynamic -lpthread -lboost_thread -lpthread -lmxio_x64 /opt/ros/indigo/lib/libroscpp.so -lboost_signals -lboost_filesystem /opt/ros/indigo/lib/librosconsole.so /opt/ros/indigo/lib/librosconsole_log4cxx.so /opt/ros/indigo/lib/librosconsole_backend_interface.so -llog4cxx -lboost_regex /opt/ros/indigo/lib/libxmlrpcpp.so /opt/ros/indigo/lib/libroscpp_serialization.so /opt/ros/indigo/lib/librostime.so -lboost_date_time /opt/ros/indigo/lib/libcpp_common.so -lboost_system -lboost_thread -lpthread -lconsole_bridge -lmxio_x64 /opt/ros/indigo/lib/libroscpp.so -lboost_signals -lboost_filesystem /opt/ros/indigo/lib/librosconsole.so /opt/ros/indigo/lib/librosconsole_log4cxx.so /opt/ros/indigo/lib/librosconsole_backend_interface.so -llog4cxx -lboost_regex /opt/ros/indigo/lib/libxmlrpcpp.so /opt/ros/indigo/lib/libroscpp_serialization.so /opt/ros/indigo/lib/librostime.so -lboost_date_time /opt/ros/indigo/lib/libcpp_common.so -lboost_system -lconsole_bridge -Wl,-rpath,/usr/local/lib:/opt/ros/indigo/lib \nCMakeFiles/main.dir/src/main.cpp.o: In function `main':\nmain.cpp:(.text+0xdd0): warning: the `gets' function is dangerous and should not be used.\n/usr/local/lib/libmxio_x64.so: undefined reference to `pthread_create'\ncollect2: error: ld returned 1 exit status\nmake[2]: *** [/home/johau/ros_ws/devel/lib/master/main] Error 1\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake[1]: *** [master/CMakeFiles/main.dir/all] Error 2\nmake[1]: Leaving directory `/home/johau/ros_ws/build'\nmake: *** [all] Error 2\nInvoking \"make\" failed\n", "Base path: /home/johau/ros_ws\nSource space: /home/johau/ros_ws/src\nBuild space: /home/johau/ros_ws/build\nDevel space: /home/johau/ros_ws/devel\nInstall space: /home/johau/ros_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/johau/ros_ws/build\"\n####\n####\n#### Running command: \"make VERBOSE=1 -j8 -l8\" in \"/home/johau/ros_ws/build\"\n####\n/usr/bin/cmake -H/home/johau/ros_ws/src -B/home/johau/ros_ws/build --check-build-system CMakeFiles/Makefile.cmake 0\n/usr/bin/cmake -E cmake_progress_start /home/johau/ros_ws/build/CMakeFiles /home/johau/ros_ws/build/CMakeFiles/progress.marks\nmake -f CMakeFiles/Makefile2 all\nmake[1]: Entering directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/depend\nmake[2]: Entering directory `/home/johau/ros_ws/build'\ncd /home/johau/ros_ws/build && /usr/bin/cmake -E cmake_depends \"Unix Makefiles\" /home/johau/ros_ws/src /home/johau/ros_ws/src/master /home/johau/ros_ws/build /home/johau/ros_ws/build/master /home/johau/ros_ws/build/master/CMakeFiles/main.dir/DependInfo.cmake --color=\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/build\nmake[2]: Entering directory `/home/johau/ros_ws/build'\nLinking CXX executable /home/johau/ros_ws/devel/lib/master/main\ncd /home/johau/ros_ws/build/master && /usr/bin/cmake -E cmake_link_script CMakeFiles/main.dir/link.txt --verbose=1\n/usr/bin/c++       CMakeFiles/main.dir/src/main.cpp.o  -o /home/johau/ros_ws/devel/lib/master/main  -L/usr/local/lib -rdynamic -lmxio_x64 /opt/ros/indigo/lib/libroscpp.so -lboost_signals -lboost_filesystem /opt/ros/indigo/lib/librosconsole.so /opt/ros/indigo/lib/librosconsole_log4cxx.so /opt/ros/indigo/lib/librosconsole_backend_interface.so -llog4cxx -lboost_regex /opt/ros/indigo/lib/libxmlrpcpp.so /opt/ros/indigo/lib/libroscpp_serialization.so /opt/ros/indigo/lib/librostime.so -lboost_date_time /opt/ros/indigo/lib/libcpp_common.so -lboost_system -lboost_thread -lpthread -lconsole_bridge -Wl,-rpath,/usr/local/lib:/opt/ros/indigo/lib \nCMakeFiles/main.dir/src/main.cpp.o: In function `main':\nmain.cpp:(.text+0xdd0): warning: the `gets' function is dangerous and should not be used.\n/usr/local/lib/libmxio_x64.so: undefined reference to `pthread_create'\ncollect2: error: ld returned 1 exit status\nmake[2]: *** [/home/johau/ros_ws/devel/lib/master/main] Error 1\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake[1]: *** [master/CMakeFiles/main.dir/all] Error 2\nmake[1]: Leaving directory `/home/johau/ros_ws/build'\nmake: *** [all] Error 2\nInvoking \"make\" failed\n", "Base path: /home/johau/ros_ws\nSource space: /home/johau/ros_ws/src\nBuild space: /home/johau/ros_ws/build\nDevel space: /home/johau/ros_ws/devel\nInstall space: /home/johau/ros_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/johau/ros_ws/build\"\n####\n####\n#### Running command: \"make VERBOSE=1 -j8 -l8\" in \"/home/johau/ros_ws/build\"\n####\n/usr/bin/cmake -H/home/johau/ros_ws/src -B/home/johau/ros_ws/build --check-build-system CMakeFiles/Makefile.cmake 0\n/usr/bin/cmake -E cmake_progress_start /home/johau/ros_ws/build/CMakeFiles /home/johau/ros_ws/build/CMakeFiles/progress.marks\nmake -f CMakeFiles/Makefile2 all\nmake[1]: Entering directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/depend\nmake[2]: Entering directory `/home/johau/ros_ws/build'\ncd /home/johau/ros_ws/build && /usr/bin/cmake -E cmake_depends \"Unix Makefiles\" /home/johau/ros_ws/src /home/johau/ros_ws/src/master /home/johau/ros_ws/build /home/johau/ros_ws/build/master /home/johau/ros_ws/build/master/CMakeFiles/main.dir/DependInfo.cmake --color=\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake -f master/CMakeFiles/main.dir/build.make master/CMakeFiles/main.dir/build\nmake[2]: Entering directory `/home/johau/ros_ws/build'\nLinking CXX executable /home/johau/ros_ws/devel/lib/master/main\ncd /home/johau/ros_ws/build/master && /usr/bin/cmake -E cmake_link_script CMakeFiles/main.dir/link.txt --verbose=1\n/usr/bin/c++       CMakeFiles/main.dir/src/main.cpp.o  -o /home/johau/ros_ws/devel/lib/master/main  -L/usr/local/lib -rdynamic -lpthread -lmxio_x64 /opt/ros/indigo/lib/libroscpp.so -lboost_signals -lboost_filesystem /opt/ros/indigo/lib/librosconsole.so /opt/ros/indigo/lib/librosconsole_log4cxx.so /opt/ros/indigo/lib/librosconsole_backend_interface.so -llog4cxx -lboost_regex /opt/ros/indigo/lib/libxmlrpcpp.so /opt/ros/indigo/lib/libroscpp_serialization.so /opt/ros/indigo/lib/librostime.so -lboost_date_time /opt/ros/indigo/lib/libcpp_common.so -lboost_system -lboost_thread -lpthread -lconsole_bridge -lboost_thread -lpthread -lconsole_bridge -Wl,-rpath,/usr/local/lib:/opt/ros/indigo/lib \nCMakeFiles/main.dir/src/main.cpp.o: In function `main':\nmain.cpp:(.text+0xdd0): warning: the `gets' function is dangerous and should not be used.\n/usr/local/lib/libmxio_x64.so: undefined reference to `pthread_create'\ncollect2: error: ld returned 1 exit status\nmake[2]: *** [/home/johau/ros_ws/devel/lib/master/main] Error 1\nmake[2]: Leaving directory `/home/johau/ros_ws/build'\nmake[1]: *** [master/CMakeFiles/main.dir/all] Error 2\nmake[1]: Leaving directory `/home/johau/ros_ws/build'\nmake: *** [all] Error 2\nInvoking \"make\" failed\n", "project(master)", "set(CMAKE_CXX_FLAGS \"-lpthread\")"], "answer_code": ["make VERBOSE=1", "cmake_minimum_required(VERSION 2.8.3)\nproject(master)\n\nunset(MOXA_LIBRARY CACHE)\n\nfind_library(\n   MOXA_LIBRARY\n   NAMES mxio_x64\n   PATHS /usr/local/lib\n   PATH_SUFFIXES lib\n   NO_DEFAULT_PATH\n)\n\nif(MOXA_LIBRARY STREQUAL \"MOXA_LIBRARY-NOTFOUND\")\n    message(WARNING \"Moxa Library not present !\")\nelse()\n    add_definitions(-DUSE_MOXA)\nendif()\n\nfind_package(catkin REQUIRED COMPONENTS\n  roscpp\n  std_msgs\n)\n\n## System dependencies are found with CMake's conventions\nfind_package(Boost COMPONENTS thread REQUIRED)\ninclude_directories(${Boost_INCLUDE_DIRS})\n\n###################################\n## catkin specific configuration ##\n###################################\n\ncatkin_package(\n   CATKIN_DEPENDS roscpp std_msgs\n)\n\ninclude_directories(${catkin_INCLUDE_DIRS})\n\nfind_package(Threads REQUIRED)\n\n## Declare a cpp executable\nadd_executable(main src/main.cpp)\n\n## Specify libraries to link a library or executable target against\ntarget_link_libraries (main    ${CMAKE_THREAD_LIBS_INIT}\n                               ${MOXA_LIBRARY}\n                               ${catkin_LIBRARIES}\n                               ${Boost_LIBRARIES})\n"], "url": "https://stackoverflow.com/questions/27842373/link-library-correct-with-ros-and-cmake"},
{"title": "Simulating battery life of a Turtlebot 3 in Gazebo", "time": "2020-01-16 21:24:03Z", "post_content": ["I have been researching ROS, Gazebo and Turtlebot 3 for the last 3 days for the first time ever and I have been trying to create a simulation where I can drive around a Turtlebot 3 while its battery state is simulated.", "I have read about the Gazebo battery class, but I do not know how to use or implement it. I have also read that a Turtlebot 3 should output its BatteryState under the sensor_msgs topic, however my gazebo simulation does not publish this topic. I do know that this ", " be possible to achieve but do not know what file to edit or what config to add. I am a very big ROS noob, especially in combination with Gazebo considering my 3 day limited research. I use the standard simulation provided by Turtlebot3:", "roslaunch turtlebot3_gazebo turtlebot3_house.launch", "I cannot imagine simulating battery life is not possible in Gazebo so I have reached my last resort, which is to ask for help here. I have found the brass_gazebo_plugin but find its GitHub README and generally any info on it very non-descriptive and would need help from the community to at least get me started towards a simulation where a Turtlebot 3 is just standing in an open space, publishing its battery state."], "answer": [], "quote": ["roslaunch turtlebot3_gazebo turtlebot3_house.launch"], "url": "https://stackoverflow.com/questions/59778016/simulating-battery-life-of-a-turtlebot-3-in-gazebo"},
{"title": "ROS error while mapping using Kinect camera \u201cNot received any frames since 5 seconds\u201d", "time": "2020-01-23 17:37:13Z", "post_content": ["I am trying to use ROS and rtabmap to map a room using the Kinect camera. I have followed all the ROS Kinect installation instructions here ", ". Following mapping instructions from here ", " , I receive the following error: \u201cNot received any frames since 5 seconds\u201c [please refer to attached images] \nImage 1: ", " -AND-\nImage 2: \u201cNot received any frames since 5 seconds (at bottom) : ", "The led on the Kinect goes from green to red when I press play to map. ", "I am using Ubuntu 16.04 (as a VirtualBox on a MacBook Air), and a Kinect v2 camera (for which I am using the Freenect driver). I have checked connected devices and the camera is detected. It is new and should not have issues.  ", "Please help! Thank you in advance."], "answer": [], "url": "https://stackoverflow.com/questions/59884290/ros-error-while-mapping-using-kinect-camera-not-received-any-frames-since-5-sec"},
{"title": "I can't find ROS when I use CMAKE to compile", "time": "2019-08-16 19:20:57Z", "post_content": ["I am using a software which connects to ROS, when I compile the package by Cmake, I meet the error \"Can't find ROS package\"", "I have added the ROS directory to \"CMAKE_PREFIX_PATH\",but it failed. And I check the ROS package , I can't find the relevant files.", "ERROR:", "Cmake.list"], "answer": ["ROS is not a single package, it is a collection of packages. ROS is simply a name associated with the main aptitude package ", ", and has nothing to do with CMake.", "Usually, somebody converts their code to ROS so that they can access the built-in functionality of networked comms with prebuilt message types and libraries to access sensors with hardware (though you don't need robot hardware to use ROS).", "ROS is simply an abstraction of communication. If you want the libraries from ROS in your project, then I suggest you use the build-sytem ", ". ", " is what ", " all of the ROS packages so that you can then use them in your CMake files.", "I suggest you follow ", " where somebody shows their CMakeLists.txt file. The important part that you need to understand is this:", "And then towards the end, after you have defined your executable,", "I should note that I am not testing any of this CMake for verification. The point here is to illustrate how to get the packages that you want from the ROS ecosystem. Once you have the CMake correct, you can simply ", " the correct header files. What is going on is that CMake is \"invoking\" ", " to find the required packages (refer to the links above for more details). It sounds like, given the fact that you are trying to \"import ROS\", that you are less than experienced with ROS (which is okay, I was a newbie too), and that this is not a ROS package, but rather a separate project that can be simplified using the libraries given in the ROS ecosystem. I have to say though, since you are quite a ways off the correct method for including ROS, I am not entirely sure how else more to help since you don't provide details in the question why you want ROS in the first place.", "(If this answers your question, that green check mark is friendly :)"], "question_code": ["CMake Error at applications/plugins/SoftRobots/CMakeLists.txt:190\n(find_package):\nBy not providing \"FindROS.cmake\" in CMAKE_MODULE_PATH this project \nhas asked CMake to find a package configuration file provided by \"ROS\", \nbut CMake did not find one.\n\nCould not find a package configuration file provided by \"ROS\" with any of\nthe following names:\n\nROSConfig.cmake\nros-config.cmake\n\nAdd the installation prefix of \"ROS\" to CMAKE_PREFIX_PATH or set \"ROS_DIR\"\nto a directory containing one of the above files.  If \"ROS\" provides a\nseparate development package or SDK, be sure it has been installed.\n", "find_package(ROS QUIET REQUIRED)\nmessage(STATUS \"ROS found: ${ROS_FOUND}\")\n"], "answer_code": ["ros-${ROS_DISTRO}-desktop-full", "catkin", "catkin", "find_package(catkin REQUIRED COMPONENTS\n  roscpp\n  rospy\n  std_msgs\n  genmsg\n  message_generation\n  depend_1\n  depend_2\n)\n\n\ncatkin_package(\n   INCLUDE_DIRS include\n   LIBRARIES ${PROJECT_NAME}\n   CATKIN_DEPENDS\n   DEPENDS system_lib\n\n)\n\ninclude_directories(\n  include\n  ${catkin_INCLUDE_DIRS}\n)\n", "target_link_libraries(run_${PROJECT_NAME}\n    ${PROJECT_NAME}\n    ${catkin_LIBRARIES}\n)\n", "#include", "catkin", "catkin", "catkin", "catkin_make"], "url": "https://stackoverflow.com/questions/57530052/i-cant-find-ros-when-i-use-cmake-to-compile"},
{"title": "Translating Cartesian Coordinates from Hand frame to World Frame: ROS & Baxter (python)", "time": "2016-06-13 14:25:13Z", "post_content": ["So I'm working with the baxter robot and using the ROS workspace. The baxter has a camera attached to its arm, from which I can read x,y,z coordinates of certain object, relative to the hand frame.", "Once my object is detected, I need its x,y,z coordinate, but from the robot's main frame, so i need to translate from the hand to the robot frame, and given that the robot has 6 degrees of motion, I'm having a hard time figuring out how to do that. I know that I'm supposed to use DH matrices, but could someone try and explain to me how i should proceed?"], "answer": ["There are very active question forums available for ", " and ", ". Also ", " for robotics question. So you better ask this question on one of them.", "If I were you I would ask on ROS forum. Using a powerful library called ", " you can easily transform coordinates over the chain of joints. In your case you may still need to figure out the coordinate of the object detected, which would be the focus of the question."], "url": "https://stackoverflow.com/questions/37792280/translating-cartesian-coordinates-from-hand-frame-to-world-frame-ros-baxter"},
{"title": "Running camera calibration node in Raspberry pi in ROS Indigo", "time": "2017-10-17 07:16:37Z", "post_content": ["I am following this ", " for calibrating raspberry pi camera module. After executing the command", "I am getting a half blank display without any checkerboard and the buttons are disabled. There is no X, Y and size also in the display. I am using rosberrypi_cam driver as suggested in the ", "...", "I am unable to calibrate the monocular camera. Please help with a possible way out."], "answer": ["For anybody stumbling in this page or with similar problems calibrating the ", " on the Raspberry, the answer is simple: don't do it on the Pi. Do the calibration remotely on a powerful pc.", "On the Pi, just launch the capture:", "where:", "On the remote host, just change the ", ", check that all the topics are exported correctly with ", " and then launch:"], "question_code": ["rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/rosberrypi_cam/image_raw camera:=/rosberrypi_cam\n", "rosrun rosberrypi_cam rosberrypicam_node\n"], "answer_code": ["Camera Module v2", "roslaunch raspicam_node camera_module_v2_1920x1080_30fps_autocapture.launch\n", "#> cat camera_module_v2_1920x1080_30fps_autocapture.launch\n<?xml version=\"1.0\"?>\n<launch>\n  <arg name=\"name\" default=\"raspicam_node\" />\n  <node type=\"raspicam_node\" pkg=\"raspicam_node\" name=\"$(arg name)\" output=\"screen\">\n\n    <param name=\"camera_info_url\" value=\"package://$(arg name)/camera_info/camera_module_v2_1920x1080.yaml\"/>\n    <param name=\"width\" value=\"1920\"/>\n    <param name=\"height\" value=\"1080\"/>\n    <param name=\"framerate\" value=\"30\"/>\n    <param name=\"camera_frame_id\" value=\"raspicam\"/>\n\n  </node>\n\n  <node pkg=\"rosservice\" type=\"rosservice\" name=\"start_capture\" args=\"call --wait $(arg name)/start_capture\"/>\n\n</launch>\n", "$ROS_MASTER_URI", "rostopic list", "rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/raspicam_node/image_raw camera:=/raspicam_node\n"], "url": "https://stackoverflow.com/questions/46784514/running-camera-calibration-node-in-raspberry-pi-in-ros-indigo"},
{"title": "Robot reverses at high speed before following path given by ros nav stack", "time": "2019-02-28 22:25:19Z", "post_content": ["I am using ros nav stack in conjunction with google cartographer (Mapping and localization) to navigate the robot through a known map. Right now, the robot follows the path generated with acceptable accuracy. But,often, once the path has been generated, the robot reverses at the highest speed set in the params file (escape_velocity parameter), and then starts to move forward correctly on the genrated path.", "I have attached images of all my param file: 1.", " 2. ", ". The name of each parameter file is mentioned at the top. But to avoid confusion, they are in the order:", "A. Param Files-1:\n   1. Global Costmap Params  2. Local Costmap Params  3. Common Costmap Params \n   4. Global Plnner Params  5. Local Planner Params", "B. Param Files-2: Move Base Params", "This is a link to a video of how it looks on rviz. ", "The thinner line in green is the plan generated by ros nav stack. The thicker line seen later in the video is the actual robot movement. You can see that the robot first reverses and then starts moving forward.", "I am new to this forum so please let me know if I need to give anymore data for anyone to answer this", "Has anyone else has this problem? Will appreciate any tips on fixing this! Thanks in advance!", "P.S: I am using ROS Indigo on Ubuntu 14.04"], "answer": ["This is a list of observation that may help you to find the problem:", "Your robot seem not sure of is position at the beginning. Try to improve that to get a better navigation.", "(I think it's your problem) Your robot start in the inflation layer of the local costmap. I don't see your local planner file but by default the robot will avoid to be in this place. \nHave a look at  : ", "Check if your robot radius, obstacle avoidance and all that config match to your robot.", "Navfn is quite old, it should works on your project but it might be nice to use global planner. Another local planner could also be tried.", "Hope this help.", "Have a nice day! ", "The only time the robot goes into the escape mode is if it is unable to find a viable forward path to get to a low cost region and closer to the required path. A couple things to check would be:", "\n1. Does localization work accurately, does the robot know where it is accurately?", "\n2. Turn on debug mode so you might be able to get more clues from the nodes, you can enable debugging as described here at ", "\n3. Finally, in your videos the green line is jumping around between two different paths.  Any chance you have two nodes processing the same data and giving out conflicting messages?"], "url": "https://stackoverflow.com/questions/54935240/robot-reverses-at-high-speed-before-following-path-given-by-ros-nav-stack"},
{"title": "Should I make a large function atomic in order to benchmark it accurately?", "time": "2017-05-23 11:53:50Z", "post_content": ["I would like to know how long it takes to execute some code. The code I am executing deals with openCV matrices and operations. The code will be run in a ROS environment on Linux. I don't want the code to be interrupted by system functions during my benchmarking.", "Looking at ", " about benchmarking, the answerer said the granularity of the result is 15ms. I would like to do much better than that and so I was considering to make the function atomic (just for benchmarking purposes). I'm not sure if it is a good idea for a few reasons, primarily because I don't have a deep understanding of processor architecture. ", "The function I am trying to bench mark is not a short function. ", "Will the result be accurate? For marking the time I'm considering to use ", ".", "Will it do something horrible to my computer? Call me superstitious but I think it's good to ask this question.", "I'm using C++11 on the Linux Kernel."], "answer": ["C++11 atomics are not atomic in the RTOS way, they just provide guarantees when writing multithreaded code. Linux is not an RTOS. Your code can and will always be interrupted. There are some ways to lessen the effects though, but not without diving very deeply into linux.", "You can for example configure the ", " to get interrupted less by other userspace programs. You can tell the kernel on which CPU core to process interrupts, then pin your program to a different cpu. You can increase the timer precision etc, but:", "There are many other things that might change the runtime of your algorithm like several layers of CPU caches, power saving features of your CPU, etc... If you are really only interested in benchmarking the execution time of your function for non-hard realtime problems, it is easier to just run the algorithm many many times and get a statistical estimate for the execution time.", "OR: You say that you want to know what influence the algorithm has on your total program runtime? Use profiling tools like ", " (integratable into QtCreator)."], "question_code": ["void atomic_wrapper_function(const object& A, const object& B) {\n  static unsigned long running_sum = 0;\n  unsigned long before, after;\n  before = GetTimeMs64();\n  function_to_benchmark(A, B);\n  after = GetTimeMs64();\n  running_sum += (after - before);\n}\n"], "answer_code": ["callgrind"], "url": "https://stackoverflow.com/questions/42150311/should-i-make-a-large-function-atomic-in-order-to-benchmark-it-accurately"},
{"title": "What is the difference between the Point and Vector3 geometry message if they're exactly the same?", "time": "2017-06-22 15:03:03Z", "post_content": ["I'm pretty new to ROS but I was manipulating a custom message that was made up of ", " and ", " messages. When I printed out the message I noticed that both the ", " and the ", " had the same 3 attributes (", ", ", ", and ", ") and this made me curious because it seemed redundant... right? ", "Upon further digging in the source code, it turns out the ", " and the ", " are exactly the same. They're both composed of a ", ", ", ", and a ", ". ", "But after reading the ", ", it seems like there IS a difference between these two messages. The docs mention that a Point should be used if the user wants to apply a translation whereas a Vector3 should be used to only represent a direction (and magnitude I guess?).", "Since the two messages are defined exactly the same, I reckon if I could apply a translation to a ", " I could also apply a translation to the ", ". Is there a difference I'm not seeing between the ", " and ", " that isn't their name?"], "answer": ["Even though ", " and ", " have the same content, the ", " library checks the type of message and acts on it differently, depending on whether it is a ", " or a ", ".", "Ultimately, this was a decision made by the developer to highlight the conceptual distinction between a ", " (a point in space which cannot be rotated), and a ", " (a direction which has no definite location in space but which can be rotated). ", "The developer did not have to make this distinction, and in fact many physics libraries use a single ", " datatype to handle directions, points, velocities, etc. ", "As with Colors (red, green, blue) and Dates (year, month, day) and many other things which can be represented as a ", ", ultimately it comes down to the need to draw artificial distinctions to make the code easier to understand for users and other programmers."], "question_code": ["geometry_msgs/Point", "geometry_msgs/Vector3", "Point", "Vector3", "x", "y", "z", "Point", "Vector3", "float x", "float y", "float z", "Point", "Vector3", "Point", "Vector3"], "answer_code": ["Point", "Vector3", "tf2", "Point", "Vector3", "Point", "Vector3", "Vector3", "Vector3"], "url": "https://stackoverflow.com/questions/44703102/what-is-the-difference-between-the-point-and-vector3-geometry-message-if-theyre"},
{"title": "ROS package: 64 bit vs 32 bit.Problems in execution", "time": "2014-10-07 07:17:22Z", "post_content": ["I have a ROS package that uses PCL libraries  and that works perfectly in Groovy and Hydro, both in 64 bit machines.\nIn 32 bit machines, I can compile the package exactly the same way, without problems, but in execution it does not work.\nThe callbacks in it go indredibly slow, sometimes taking more than a minute, when in 64 bit they work perfectly fine.\nAny possible causes for this package being stuck in 32 bit?\nI am runnning Ubuntu 12.04 64 bit with Hydro and Groovy, and Ubuntu 12.04 32 bit with Hydro.", "Thank you all in advance,"], "answer": ["Problem solved. The execution problems were due to the processing power difference between 32 and 64 bit, and also due to RAM memory available in both systems.\nDownsampling the point cloud that I was trying to process solved the problem and now the algorithm runs ok in 32 bit platform.", "Thanks to all,", "Alberto"], "url": "https://stackoverflow.com/questions/26230545/ros-package-64-bit-vs-32-bit-problems-in-execution"},
{"title": "roslaunch activation failure what should i do?", "time": "2019-11-04 06:06:32Z", "post_content": ["i tried to launch the sdk package by typing", "however every time i get this error:", "here is the steps that i followed to activate the drone:", "where i edit the baud rate/app id/ enc key/ and serial name.", "app_id: 1079440\nbaud_rate: 921600\nserial_name: /dev/ttyUSB0\nenc_key: 39d353a8e9ad01b6c659111904bae57ebb138785aa5159699383f28da3f56563", "and i continued with the following commands:", "its where i got the error.", "i'm using USB-TTL cable to connect manifold 2-c with M210 RTK V2, also i got the permission first before typing any code by typing :", "and then log out and log in\nthen i typed :", "to read and give permission to serial port.", "TX (green wire) and Rx (white wire) and ground (black wire) there were put respectively.", "so now what should i do?"], "answer": ["There are too many possibility\nPlease refer my previous answers and check them one by one", "Information you have given is not enough, there could be many possibilities. Please go through with the following checklist (this is what first comes to my mind, if I remember sth new, I`ll add it in)", "The list is meant for error such as  Drone version not obtained  or  new device error  or  first success connection(get firmware) then failed activation for Both DJI OSDK and DJI OSDK-ROS. Assuming you already enabled the API control, then check", "Does UART on RPI is enabled? if not, enable it. Are you using the correct serial ID as well? If not, set it right. Recommend using /dev/serial/by-id/usb-XXX method", "Does Baud rate in DJI assisatnt2 is same as the one in the USERCONFIG file of OSDK? if not, make it same", "Did u give permission to the serial device e.g sudo chmod a+rw  or  sudo usermod -a -G dialout $USER   or  set the udev rule .  If not choose a way to get it right.", "FTDI series problems", "4.1 Did you use this FTDI cable successfully on other platform before?(to make sure tx rx is correct)  ", "4.2 Is this FTDI 3.3V? If not, high chance your FCU board is already burned. Send it back for repair. ", "4.3 Measure the voltage on Tx and RX pin while everything is connected, is it being pulled up at 3.3V? if less than 3 then there is a serious communication issue.  ", "4.4 Is there EMI generator around?( this one happen to me once, took me 2 weeks to isolate the issue, EMI cause unreliable connection)", "4.5 As an additional test, prob the tx and tx by Y cable using real-term to see if you can see any proper communication happening.", "Did u forget to turn on the RC ? If so turn it on while calling the sdk.launch", "GO app side issue", "6.1 Did u connect the Go app while running sdk.launch? If not connect by GO app, connect it as it will pop up sth. ", "6.2 Did you login to your account which creates the app id?If not, login to it. ", "6.3 And is your account being banned for flying in the non-authorized area before(e.g caught by DJI aeroscope/Flyhub) and police is actually going after you? If so, stop playing the drone and surrender urself in. Normally it should be max of one year Jail time, but if you resist, the punishment can be more deadly.", "Did u give authority from GO app? click ok or confirm on the GO App once you run sdk.launch in the RPI. Once you launch the sdk, ", " After changing the firmware, you should experience this again.", "Did u tried the hardware with the 3.8 with a Normal X86/X64 Intel PC/notebook with Ubuntu 16/18 before? is it working? ( rule out hardware / connection issue ) If can work, then its RPI issue. If can not, high chance drone/RC side.  I do have couple RPI burn down experience b4. ", "Did u have valid/correct app id and enc key? double check it. If not, enter is correct.", "Is the voltage supplied to A3 stable and clean?", "Have you tried this way of calling? /the_sample_u_wish_to_run UserConfig.txt /dev/ttyACM0  (this is what I gathered from other peoples experience)", "Which version of RPI you are using, if you are using 2 series, the high chance you have to use ", " with older version firmware.  I only tested with RPI 3B. Can not guarantee the function of other versions. That's why number 8 is important to isolate the issue. ", "Are you calling the sdk.launch from somewhere else? make sure you only call it once and prevent it from being calling again. Make sure the serial port is not occupied. ", "Make sure API is enabled in DJI assistant2. Close everything power on and connect to DJI assistant 2 again to verify this. If by any chance the board has an issue, the API enable you set in the previous run will get auto deselected. This is to rule out burned FCU board issue. ", "If by now it is still can not work, then you should try other 3.8 or 3.7 with firmware 1.7.7 and 1.7.5 or whatever firmware you can access. as far as I know, their delay+ wait for ACK always have all sorts of issues. Maybe adding more delay in the wait for serial ack will help you(solution from other github dji_osdk post)", "In case of this particular A3 burned, swap another fresh open A3 and proven working FTDI cable(test with Arduino) to rule out the A3 problem", "If still no luck, file a ticket to dev@dji.com + send a complaint to Samuel@DJI. Send them the long list of thing you tested, and if they say high chance it is a hardware issue. Do send it back for RMA. I do have experience of one Normal A3 and one M600 A3 has burned FCU board issue before.", "After this, if you encounter can not fly GPS mission by OSDK or can not do local flight control. Just try different firmware version. DJI firmware release is usually very buggy for developer. ", "For you case, use windows. as i have no issue with windows based method\nMake sure the slider to the right with my image view. I have no MAC so cant test MAC solution. ", "YOu might need to plug in and un plug and plug in for couple time", "by default api is disabled. so you have to enable it and select the hz rate for topic you wish to receive. Good Luck. This is all I can do. "], "question_code": ["roslaunch dji_sdk sdk.launch\n", "... logging to /home/dji/.ros/log/b31d5e94-fec0-11e9-9835-74da38ebc18f/roslaunch-manifold2-18825.log\nChecking log directory for disk usage. This may take awhile.\nPress Ctrl-C to interrupt\nDone checking log file disk usage. Usage is <1GB.\n\nstarted roslaunch server http://manifold2:41911/\n\nSUMMARY\n\nPARAMETERS\n\n/dji_sdk/align_time: False\n/dji_sdk/app_id: 1079440\n/dji_sdk/app_version: 1\n/dji_sdk/baud_rate: 921600\n/dji_sdk/enc_key: 39d353a8e9ad01b6c...\n/dji_sdk/serial_name: /dev/ttyUSB0\n/dji_sdk/use_broadcast: False\n/rosdistro: kinetic\n/rosversion: 1.12.13\nNODES\n/\ndji_sdk (dji_sdk/dji_sdk_node)\n\nauto-starting new master\nprocess[master]: started with pid [18835]\nROS_MASTER_URI=http://localhost:11311\n\nsetting /run_id to b31d5e94-fec0-11e9-9835-74da38ebc18f\nprocess[rosout-1]: started with pid [18848]\nstarted core service [/rosout]\nprocess[dji_sdk-2]: started with pid [18856]\n\nSTATUS/1 @ init, L56: Attempting to open device /dev/ttyUSB0 with baudrate 921600...\n\nSTATUS/1 @ init, L66: ...Serial started successfully.\n\nERRORLOG/1 @ getDroneVersion, L1503: Drone version not obtained! Please do not proceed.\nPossible reasons:\nSerial port connection:\n\nSDK is not enabled, please check DJI Assistant2 -> SDK -> [v] Enable API Control.\nBaudrate is not correct, please double-check from DJI Assistant2 -> SDK -> baudrate.\nTX and RX pins are inverted.\nSerial port is occupied by another program.\nPermission required. Please do 'sudo usermod -a -G dialout $USER' (you do not need to replace $USER with your username). Then logout and login again\nERRORLOG/1 @ activate, L1387: Unable to initialize some vehicle components![ERROR] [1572843926.785053218]: drone activation error\n[ERROR] [1572843926.785190956]: Vehicle initialization failed\n^C[dji_sdk-2] killing on exit\n[rosout-1] killing on exit\n[master] killing on exit\nshutting down processing monitor...\n... shutting down processing monitor complete\ndone\n", "source devel/setup.bash\ncatkin_make\nrosed dji_sdk sdk.launch\n", "roslaunch dji_sdk sdk.launch\n", "usermod -a -G dialout $USER\n", "sudo chmod 666 /dev/ttyUSB0\n"], "url": "https://stackoverflow.com/questions/58688023/roslaunch-activation-failure-what-should-i-do"},
{"title": "Increase the precision of the values returned by the heart beat sensor on a Tizen device", "time": "2017-02-09 12:22:34Z", "post_content": ["what i want to achieve, is try to increase the precison of the values returned by the heart beat sensor of a Tizen smartwatch.\nThe values are Float64 numbers, since the language is Javascript.\nI tried to use a function like this:", "but with no success. Maybe i'm doing something wrong, like doing some programming mistakes, i really don't know. Apparently, the IDE compile and build the package to install with no problem, but i can't see something different with or without this function included.\nI will post my entire code below. Please check when is created the function ", " . I've used the escamotage ", " because i don't want the zeros to be printed. Please note that i want the variable streamed to the ROS topic HeartRateInterval to remain a Float; this is why i've also used the parseFloat function.\nThank you!\nCode :"], "answer": ["Am I missing something here, but I can not find where you actually call that new function?\nAnd why do you create it inline inside the onchangedCB function?", "It looks as if you expected that function to be called because you declare it there and call the parameter the same as the interval variable. Which will not work (as far as I know in any programming language).", "Then what I would try is call that function parseFloat(interval).toPrecision\ndirectly instead of putting it in another function.", "But what I'm far more interested in is:\nhere hrmInfo.rRInterval/1000\nthe orginal value is devived by a thousand.", "Remove that division (like this var interval = hrmInfo.rRInterval;) and see if there actually are more numbers where the decimal point would be.", "I can not make it up from your example, but if the value normally is something like 120 per minute. And you want to know if there are more precise values behind that, then the value should now look something like 1200054 if it is all zeroes like 120000 all the time, then the systems creating that event does not give off a more precise measure."], "question_code": ["function strip(interval) {\nreturn (parseFloat(interval).toPrecision(4));\n}\n", "strip", "if (interval !== 0) {\n   interval_screen = interval;\n   }", "document.addEventListener('tizenhwkey', function(e) {\n    if(e.keyName === \"back\")\n        window.webapis.motion.stop(\"HRM\");\n        tizen.application.getCurrentApplication().exit();\n});\n\nfunction Connect(){\n\nvar ip;\nvar connection=false;\nvar interval_screen = 0;\nif (document.getElementById(\"ip\").value===\"\")\n{ \n    ip=\"10.42.0.1\";\n}\nelse \n{ \n    ip=document.getElementById(\"ip\").value;\n}\n\nvar ros = new ROSLIB.Ros({\n    url : 'ws://' + ip +':9090'\n    });\n\nros.on('connection', function() {\n    connection=true;\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"green\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Connected';\n    tizen.power.request(\"SCREEN\", \"SCREEN_DIM\");\n});\n\nros.on('error', function(error) {\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"orange\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Error';\n});\n\nros.on('close', function() {\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"red\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Unconnected';\n    connection=false;\n    tizen.power.release(\"SCREEN\");\n});\n\n    var RatePub = new ROSLIB.Topic({\n    ros : ros,\n    name : '/HeartRateData',\n    messageType : 'std_msgs/Float64'\n});\n\nvar IntervalPub = new ROSLIB.Topic({\n    ros : ros,\n    name : '/HeartRateInterval',\n    messageType : 'std_msgs/Float64'\n});\n\nwindow.webapis.motion.start(\"HRM\", onchangedCB);\n\nfunction onchangedCB(hrmInfo)\n{\n   var rate = hrmInfo.heartRate;\n   document.getElementById(\"mytext\").innerHTML = 'Heart Rate= ' + rate + ' bpm';\n\n   var interval = hrmInfo.rRInterval/1000;\n   function strip(interval) {\n   return (parseFloat(interval).toPrecision(4));\n   }\n   if (interval !== 0) {\n   interval_screen = interval;\n   }\n   document.getElementById(\"mytext1\").innerHTML = 'RR Interval= ' + interval_screen + ' s';\n\n   var Float64 = new ROSLIB.Message({\n            data:rate\n        });\n\n        if(connection===true)\n            {\n            RatePub.publish(Float64);\n            }\n        else\n        {\n            document.getElementById(\"mytext\").innerHTML = 'Heart Rate = 0 bpm';\n        }\n\n   var Float64 = new ROSLIB.Message({\n            data:interval\n        });\n\n        if(connection===true)\n            { if (interval !== 0) {\n            IntervalPub.publish(Float64);\n            }\n            else {\n\n            }\n            }\n        else\n        {\n            document.getElementById(\"mytext1\").innerHTML = 'RR Interval = 0 s';\n        }\n\n        }}\n", "interval.toPrecision(4);", "var interval = hrmInfo.rRInterval/1000;", "parseFloat(interval).toPrecision(4);"], "url": "https://stackoverflow.com/questions/42136618/increase-the-precision-of-the-values-returned-by-the-heart-beat-sensor-on-a-tize"},
{"title": "ROS bebop_autonomy error with parrot bebop drone", "time": "2017-04-01 20:18:35Z", "post_content": ["I am relatively new to ROS and bebop drones, and I am just starting to install and use bebop_autonomy to connect to my  Parrot Bebop drone.", "I could ping my drone at  192.168.42.1, but then I encounter problems when I am following the documentation on \"Running the Driver\".", "When I try to run the driver as a node or a nodelet, I get error messages as followings:", "What could be the possible cause of this and how could I fix this?"], "answer": ["Turns out the error is caused by the network setting of my virtual machine.\nAfter I changed the adapter from NAT to bridged network, the problem is resolved."], "question_code": ["$ roslaunch bebop_driver bebop_node.launch\n... logging to /home/brian/.ros/log/4d22fb4c-1711-11e7-80d1-0800279b4b72/roslaunch-brian-VirtualBox-28034.log\nChecking log directory for disk usage. This may take awhile.\nPress Ctrl-C to interrupt\nDone checking log file disk usage. Usage is <1GB.\n\nxacro: Traditional processing is deprecated. Switch to --inorder processing!\nTo check for compatibility of your document, use option --check-order.\nFor more infos, see http://wiki.ros.org/xacro#Processing_Order\nstarted roslaunch server http://brian-VirtualBox:35861/\n\nSUMMARY\n========\n\nPARAMETERS\n * /bebop/bebop_driver/bebop_ip: 192.168.42.1\n * /bebop/bebop_driver/camera_info_url: package://bebop_d...\n * /bebop/bebop_driver/cmd_vel_timeout: 0.2\n * /bebop/bebop_driver/odom_frame_id: odom\n * /bebop/bebop_driver/publish_odom_tf: True\n * /bebop/bebop_driver/reset_settings: True\n * /bebop/bebop_driver/states/enable_altitudechanged: True\n * /bebop/bebop_driver/states/enable_autotakeoffmodechanged: True\n * /bebop/bebop_driver/states/enable_camerastate_orientation: True\n * /bebop/bebop_driver/states/enable_commonstate_batterystatechanged: True\n * /bebop/bebop_driver/states/enable_commonstate_wifisignalchanged: True\n * /bebop/bebop_driver/states/enable_controllerstate_ispilotingchanged: True\n * /bebop/bebop_driver/states/enable_flightplanstate_availabilitystatechanged: True\n * /bebop/bebop_driver/states/enable_flightplanstate_componentstatelistchanged: True\n * /bebop/bebop_driver/states/enable_gpsstate_numberofsatellitechanged: True\n * /bebop/bebop_driver/states/enable_mavlinkstate_mavlinkfileplayingstatechanged: True\n * /bebop/bebop_driver/states/enable_mavlinkstate_mavlinkplayerrorstatechanged: True\n * /bebop/bebop_driver/states/enable_mediastreamingstate_videoenablechanged: True\n * /bebop/bebop_driver/states/enable_numberofsatellitechanged: True\n * /bebop/bebop_driver/states/enable_overheatstate_overheatchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_altitudechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_attitudechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_flattrimchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_flyingstatechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_navigatehomestatechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_positionchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_speedchanged: True\n * /bebop/robot_description: <?xml version=\"1....\n * /rosdistro: kinetic\n * /rosversion: 1.12.7\n\nNODES\n  /bebop/\n    bebop_driver (bebop_driver/bebop_driver_node)\n    robot_state_publisher (robot_state_publisher/robot_state_publisher)\n\nauto-starting new master\nprocess[master]: started with pid [28048]\nROS_MASTER_URI=http://localhost:11311\n\nsetting /run_id to 4d22fb4c-1711-11e7-80d1-0800279b4b72\nprocess[rosout-1]: started with pid [28061]\nstarted core service [/rosout]\nprocess[bebop/bebop_driver-2]: started with pid [28073]\nprocess[bebop/robot_state_publisher-3]: started with pid [28079]\n[ INFO] [1491074874.747679255]: Initializing nodelet with 1 worker threads.\n[ INFO] [1491074874.904582440]: [BebopSDK] 03:27:54:904 | Bebop:225 - Bebop Cnstr()\n[ INFO] [1491074874.905884516]: Nodelet Cstr\n[ INFO] [1491074874.919409933]: Connecting to Bebop ...\n[ INFO] [1491074874.925985788]: [CB] 03:27:54:925 | Ardrone3PilotingStateFlatTrimChanged:386 - [STATES] Enabling states/ardrone3/PilotingState/FlatTrimChanged\n[ INFO] [1491074874.927999006]: [CB] 03:27:54:927 | Ardrone3PilotingStateFlyingStateChanged:430 - [STATES] Enabling states/ardrone3/PilotingState/FlyingStateChanged\n[ INFO] [1491074874.935265924]: [CB] 03:27:54:935 | Ardrone3PilotingStateNavigateHomeStateChanged:532 - [STATES] Enabling states/ardrone3/PilotingState/NavigateHomeStateChanged\n[ INFO] [1491074874.938969647]: [CB] 03:27:54:938 | Ardrone3PilotingStatePositionChanged:590 - [STATES] Enabling states/ardrone3/PilotingState/PositionChanged\n[ INFO] [1491074874.942837436]: [CB] 03:27:54:942 | Ardrone3PilotingStateSpeedChanged:655 - [STATES] Enabling states/ardrone3/PilotingState/SpeedChanged\n[ INFO] [1491074874.954468087]: [CB] 03:27:54:954 | Ardrone3PilotingStateAttitudeChanged:720 - [STATES] Enabling states/ardrone3/PilotingState/AttitudeChanged\n[ INFO] [1491074874.958549970]: [CB] 03:27:54:958 | Ardrone3PilotingStateAltitudeChanged:836 - [STATES] Enabling states/ardrone3/PilotingState/AltitudeChanged\n[ INFO] [1491074874.979685917]: [CB] 03:27:54:979 | Ardrone3MediaStreamingStateVideoEnableChanged:1300 - [STATES] Enabling states/ardrone3/MediaStreamingState/VideoEnableChanged\n[ INFO] [1491074874.983328651]: [CB] 03:27:54:983 | Ardrone3CameraStateOrientation:1402 - [STATES] Enabling states/ardrone3/CameraState/Orientation\n[ INFO] [1491074875.002872666]: [CB] 03:27:55:002 | Ardrone3GPSStateNumberOfSatelliteChanged:1794 - [STATES] Enabling states/ardrone3/GPSState/NumberOfSatelliteChanged\n[ INFO] [1491074875.012341492]: [CB] 03:27:55:012 | CommonCommonStateBatteryStateChanged:148 - [STATES] Enabling states/common/CommonState/BatteryStateChanged\n[ INFO] [1491074875.025082885]: [CB] 03:27:55:025 | CommonCommonStateWifiSignalChanged:510 - [STATES] Enabling states/common/CommonState/WifiSignalChanged\n[ INFO] [1491074875.037880400]: [CB] 03:27:55:037 | CommonOverHeatStateOverHeatChanged:1023 - [STATES] Enabling states/common/OverHeatState/OverHeatChanged\n[ INFO] [1491074875.042039410]: [CB] 03:27:55:042 | CommonMavlinkStateMavlinkFilePlayingStateChanged:1118 - [STATES] Enabling states/common/MavlinkState/MavlinkFilePlayingStateChanged\n[ INFO] [1491074875.043688593]: [CB] 03:27:55:043 | CommonMavlinkStateMavlinkPlayErrorStateChanged:1183 - [STATES] Enabling states/common/MavlinkState/MavlinkPlayErrorStateChanged\n[ INFO] [1491074875.055460926]: [CB] 03:27:55:055 | CommonFlightPlanStateAvailabilityStateChanged:1568 - [STATES] Enabling states/common/FlightPlanState/AvailabilityStateChanged\n[ INFO] [1491074875.058350203]: [CB] 03:27:55:058 | CommonFlightPlanStateComponentStateListChanged:1619 - [STATES] Enabling states/common/FlightPlanState/ComponentStateListChanged\n[ INFO] [1491074875.080061404]: [ARCONTROLLER_Network] 03:27:55:080 | ARCONTROLLER_Network_GetAvailableSocketPort:110 - d2c_port port: 57751\n[ INFO] [1491074875.080260750]: [ARCONTROLLER_Stream2] 03:27:55:080 | ARCONTROLLER_Stream2_Open_Socket:124 - udp local port stream: 40425\n[ INFO] [1491074875.080321851]: [ARCONTROLLER_Stream2] 03:27:55:080 | ARCONTROLLER_Stream2_Open_Socket:124 - udp local port control: 59888\n**[ERROR] [1491074875.844809497]: [ARNETWORK_Sender] 03:27:55:844 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074875.844930504]: [ARNETWORK_Sender] 03:27:55:844 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074876.345381668]: [ARNETWORK_Sender] 03:27:56:345 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074876.345512497]: [ARNETWORK_Sender] 03:27:56:345 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074876.846253700]: [ARNETWORK_Sender] 03:27:56:846 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074876.846399317]: [ARNETWORK_Sender] 03:27:56:846 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074877.346791394]: [ARNETWORK_Sender] 03:27:57:346 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11**\n_[ WARN] [1491074877.346930301]: [ARNETWORK_Sender] 03:27:57:346 | ARNETWORK_Sender_TimeOutCallback:655 - [0x7ff9182a7de0] Did timeout sending command : project = 0 | class = 4 | command = 1 - 0_\n**[ERROR] [1491074877.847247018]: [ARNETWORK_Sender] 03:27:57:847 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074877.847486088]: [ARNETWORK_Sender] 03:27:57:847 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074878.348124995]: [ARNETWORK_Sender] 03:27:58:348 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074878.348251012]: [ARNETWORK_Sender] 03:27:58:348 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074878.848439032]: [ARNETWORK_Sender] 03:27:58:848 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074878.848561779]: [ARNETWORK_Sender] 03:27:58:848 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074879.349409300]: [ARNETWORK_Sender] 03:27:59:349 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11**\n_[ WARN] [1491074879.349558890]: [ARNETWORK_Sender] 03:27:59:349 | ARNETWORK_Sender_TimeOutCallback:655 - [0x7ff9182a7de0] Did timeout sending command : project = 0 | class = 4 | command = 2 - 0_\n**[ERROR] [1491074879.849932869]: [ARNETWORK_Sender] 03:27:59:849 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074879.850073686]: [ARNETWORK_Sender] 03:27:59:850 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11**\n[ INFO] [1491074880.327451025]: [ARNETWORKAL_WifiNetwork] 03:28:00:327 | ARNETWORKAL_WifiNetwork_Receive:918 - [0x7ff91824dff0] connection lost (too long time without reception)\n[ INFO] [1491074880.327663960]: [ARCONTROLLER_Device] 03:28:00:327 | ARCONTROLLER_Device_StartRun:4987 - Start failed or canceled.\n**[ERROR] [1491074880.351238007]: [ARNETWORK_Sender] 03:28:00:351 | ARNETWORK_Sender_ProcessBufferToSend:405 - [0x7ff9182a7de0] Timeout waiting for ack in buffer 11\n[ERROR] [1491074880.351367810]: [ARNETWORK_Sender] 03:28:00:351 | ARNETWORK_Sender_ProcessBufferToSend:421 - [0x7ff9182a7de0] Will retry sending data of buffer 11\n[ERROR] [1491074881.325474151]: [ARCONTROLLER_Device] 03:28:01:325 | ARCONTROLLER_Device_StartRun:4995 - Start fail error :start canceled**\n[ INFO] [1491074881.325635335]: [BebopSDK] 03:28:01:325 | Cleanup:326 - Bebop Cleanup()\n[FATAL] [1491074881.325830937]: Init failed: Waiting for device failed: No error\n[ INFO] [1491074881.325905075]: Bebop Nodelet Dstr: 0\n[ INFO] [1491074881.325916417]: Killing Camera Thread ...\n[ INFO] [1491074881.325929273]: Killing Aux Thread ...\n^C[bebop/robot_state_publisher-3] killing on exit\n[bebop/bebop_driver-2] killing on exit\n[rosout-1] killing on exit\n[master] killing on exit\n"], "url": "https://stackoverflow.com/questions/43161584/ros-bebop-autonomy-error-with-parrot-bebop-drone"},
{"title": "Gazebo model does not stand", "time": "2018-02-15 07:17:28Z", "post_content": ["Apologies for a very long post. I created the following xacro file, when I load in gazebo using the following launch file, the robot does not stand straight and falls down. I tried with different values of mass for different links, but no luck. It looks like I am missing something, can anyone help? ", "When I edit the model in Gazebo and then toggle the static flag, it seems to be stable."], "answer": ["I could solve this issue by adding the friction and damping elements to the URDF file.", "Sample usage of the property in joint is given below,"], "question_code": ["<?xml version=\"1.0\" ?>\n\n<robot xmlns:xacro=\"http://www.ros.org/wiki/xacro\" \n    xmlns:sensor=\"http://playerstage.sourceforge.net/gazebo/xmlschema/#sensor\"\n        xmlns:controller=\"http://playerstage.sourceforge.net/gazebo/xmlschema/#controller\"\n        xmlns:interface=\"http://playerstage.sourceforge.net/gazebo/xmlschema/#interface\"\n    name=\"rosbot_v1\">\n\n<!--Formula for calculation of mass moment of inertia of a cylinder\nis given by the following formula:\nReference: http://www.amesweb.info/SectionalPropertiesTabs/Mass-Moment-of-Inertia-Cylinder.aspx\nMass moment of inertia about x axis     Ix  Ix= (m/12) * (3r^2+h^2)\nMass moment of inertia about y axis     Iy  Iy= (m/12) * (3r^2+h^2)\nMass moment of inertia about z axis     Iz  Iz= (mr2)/2-->\n\n<xacro:macro name=\"inertial_matrix_cylinder\" params=\"mass arm_radius arm_length\">\n               <inertial>\n                       <mass value=\"${mass}\" />\n                       <inertia ixx=\"${mass*(3*arm_radius*arm_radius+arm_length*arm_length)/12}\" \n                                ixy = \"0\" ixz = \"0\"\n                                iyy=\"${mass*(3*arm_radius*arm_radius+arm_length*arm_length)/12}\" iyz = \"0\"\n                                izz=\"${mass*arm_radius*arm_radius/2}\" />\n               </inertial>\n</xacro:macro>\n\n<!--Physical attributes definition for base box-->\n\n<xacro:property name=\"base_box_length\" value=\"1\" />\n<xacro:property name=\"base_box_width\" value=\"1\" />\n<xacro:property name=\"base_box_height\" value=\"0.6\" />\n<xacro:property name=\"base_box_mass\" value=\"4\" />\n\n<!--Physical attributes definition for the swivel arm-->\n<xacro:property name=\"swivel_arm_length\" value=\"0.2\" />\n<xacro:property name=\"swivel_arm_radius\" value=\"0.2\" />\n<xacro:property name=\"swivel_arm_mass\" value=\"1\" />\n\n<!--Physical attributes definition for the arms-->\n<xacro:property name=\"arm_length\" value=\"1\" />\n<xacro:property name=\"arm_radius\" value=\"0.1\" />\n<xacro:property name=\"arm_mass\" value=\"0.1\" />\n\n<!--Physical attributes definition for gripper box-->\n<xacro:property name=\"gripper_box_length\" value=\"0.5\" />\n<xacro:property name=\"gripper_box_width\" value=\"0.4\" />\n<xacro:property name=\"gripper_box_height\" value=\"0.2\" />\n<xacro:property name=\"gripper_box_mass\" value=\"0.01\" />\n\n<!--Physical attributes definition for gripper fingers-->\n<xacro:property name=\"gripper_finger_length\" value=\"0.12\" />\n<xacro:property name=\"gripper_finger_width\" value=\"0.4\" />\n<xacro:property name=\"gripper_finger_height\" value=\"0.12\" />\n<xacro:property name=\"gripper_finger_mass\" value=\"0.001\" />\n\n<!--Formula for calculation of mass moment of inertia of a cuboid\nis given by the following formula: a=x(length); b=y(width)\nMass moment of inertia about x axis     Ix  Ix= (M/12) * a^2\nMass moment of inertia about y axis     Iy  Iy= (M/12) * b^2\nMass moment of inertia about z axis     Iz  Iz= (1/12)*M*(a^2+b^2)-->\n\n<xacro:macro name=\"inertial_matrix_cuboid\" params=\"mass box_length box_width\">\n               <inertial>\n                       <mass value=\"${mass}\" />\n                       <inertia ixx=\"${mass/12*(box_length*box_length)}\" \n                                ixy = \"0\" ixz = \"0\"\n                                iyy=\"${mass/12*(box_width*box_width)}\" iyz = \"0\"\n                                izz=\"${mass/12*(box_length*box_length + box_width*box_width)}\" />\n               </inertial>\n</xacro:macro>\n\n<material name=\"blue\">\n  <color rgba=\"0 0 0.8 1\"/>\n</material>\n\n<material name=\"white\">\n  <color rgba=\"1 1 1 1\"/>\n</material>\n\n<material name=\"green\">\n  <color rgba=\"0 1 0 1\"/>\n</material>\n\n<material name=\"cyan\">\n  <color rgba=\"0 1 1 1\"/>\n</material>\n\n<!-- world link -->\n<link name=\"base_link\"/>\n\n<link name=\"rosbot_base\">\n    <xacro:inertial_matrix_cuboid mass=\"${base_box_mass}\" box_length=\"${base_box_length}\" box_width=\"${base_box_width}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"0  0  0\"/>\n      <geometry>\n        <box size=\"${base_box_length} ${base_box_width} ${base_box_height}\"/>\n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"0  0  0\"/>\n      <geometry>\n        <box size=\"${base_box_length} ${base_box_width} ${base_box_height}\"/>\n      </geometry>\n      <material name=\"blue\"/>\n    </visual>\n</link>\n\n<!-- base_link and its fixed joint -->\n<joint name=\"joint_fix\" type=\"fixed\">\n    <parent link=\"base_link\"/>\n    <child link=\"rosbot_base\"/>\n</joint>\n\n<!-- A swiveling base on which next arm will sit -->\n<link name=\"rosbot_swivel_base\">\n    <xacro:inertial_matrix_cylinder mass=\"${swivel_arm_mass}\" arm_length=\"${swivel_arm_length}\" arm_radius=\"${swivel_arm_radius}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0  ${swivel_arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${swivel_arm_length}\" radius=\"${swivel_arm_radius}\"/>\n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0  ${swivel_arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${swivel_arm_length}\" radius=\"${swivel_arm_radius}\"/>\n      </geometry>\n      <material name=\"white\"/>\n    </visual>\n</link>\n\n<!-- The joint between swivel and base needs to be flush on the top face of rosbot_base  -->\n<joint name=\"rosbot_base_swivel_joint\" type=\"revolute\">\n  <parent link=\"rosbot_base\"/>\n  <child link=\"rosbot_swivel_base\"/>\n  <origin rpy=\"0  0  0\" xyz=\"0  0  ${base_box_height/2}\"/>\n  <axis xyz=\"0  0  1\"/>\n  <limit effort=\"100\" lower=\"-1.57\" upper=\"1.57\" velocity=\"100\"/>\n</joint>\n\n<!-- A moving/manipulating arm1 -->\n<link name=\"rosbot_arm1\">\n    <xacro:inertial_matrix_cylinder mass=\"${arm_mass}\" arm_length=\"${arm_length}\"  arm_radius=\"${arm_radius}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0   ${arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/> \n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0   ${arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/> \n      </geometry>\n      <material name=\"blue\"/>\n    </visual>\n</link>\n\n<!-- The joint between swivel and arm1 needs to be at the height of swivel link  -->\n<joint name=\"rosbot_swivel_arm1_joint\" type=\"revolute\">\n  <parent link=\"rosbot_swivel_base\"/>\n  <child link=\"rosbot_arm1\"/>\n  <origin rpy=\"0  0  0\" xyz=\"0  0  ${swivel_arm_length}\"/>\n  <axis xyz=\"1  0  0\"/>\n  <limit effort=\"100\" lower=\"-1.57\" upper=\"1.57\" velocity=\"100\"/>\n</joint>\n\n<!-- A moving/manipulating arm2 -->\n<link name=\"rosbot_arm2\">\n    <xacro:inertial_matrix_cylinder mass=\"${arm_mass}\" arm_length=\"${arm_length}\"  arm_radius=\"${arm_radius}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0   ${arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/> \n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0   ${arm_length/2}\"/>\n      <geometry>\n        <cylinder length=\"${arm_length}\" radius=\"${arm_radius}\"/> \n      </geometry>\n      <material name=\"blue\"/>\n    </visual>\n</link>\n\n<!-- The joint between arm1 and arm2 needs to be at height of arm1  -->\n<joint name=\"rosbot_arm1_arm2_joint\" type=\"revolute\">\n  <parent link=\"rosbot_arm1\"/>\n  <child link=\"rosbot_arm2\"/>\n  <origin rpy=\"0  0  0\" xyz=\"0  0  ${arm_length}\"/>\n  <axis xyz=\"1  0  0\"/>\n  <limit effort=\"100\" lower=\"-1.57\" upper=\"1.57\" velocity=\"100\"/>\n</joint>\n\n<!-- A gripper box, which holds the gripper joints -->\n<link name=\"rosbot_gripper_box\">\n    <xacro:inertial_matrix_cuboid mass=\"${gripper_box_mass}\" box_length=\"${gripper_box_length}\" box_width=\"${gripper_box_width}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0  ${gripper_box_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_box_length} ${gripper_box_width} ${gripper_box_height}\"/>\n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"0   0  ${gripper_box_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_box_length} ${gripper_box_width} ${gripper_box_height}\"/>\n      </geometry>\n       <material name=\"cyan\"/>\n    </visual>\n</link>\n\n<!-- The joint between arm2 and gripper needs to be at height of arm2  -->\n<joint name=\"rosbot_arm2_gripper_joint\" type=\"revolute\">\n  <parent link=\"rosbot_arm2\"/>\n  <child link=\"rosbot_gripper_box\"/>\n  <origin rpy=\"0  0  0\" xyz=\"0  0  ${arm_length}\"/>\n  <axis xyz=\"0  0  1\"/>\n  <limit effort=\"100\" lower=\"-1.57\" upper=\"1.57\" velocity=\"100\"/>\n</joint>\n\n<!-- The left gripper  -->\n<link name=\"rosbot_lgripper\">\n    <xacro:inertial_matrix_cuboid mass=\"${gripper_finger_mass}\" box_length=\"${gripper_finger_length}\" box_width=\"${gripper_finger_width}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"-0.0  0.20  ${gripper_finger_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_finger_length} ${gripper_finger_width} ${gripper_finger_height}\"/>\n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"-0.0  0.20  ${gripper_finger_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_finger_length} ${gripper_finger_width} ${gripper_finger_height}\"/>\n      </geometry>\n      <material name=\"green\"/>\n    </visual>\n  </link>\n\n<!-- The joint between gripper box and gripper needs to be at origin/slightly higher than origin of gripper box  -->\n<joint name=\"rosbot_lgripper_joint\" type=\"prismatic\">\n    <parent link=\"rosbot_gripper_box\"/>\n    <child link=\"rosbot_lgripper\"/>\n    <origin rpy=\"0  0  0\" xyz=\"-0.2  0.2  0.02\"/>\n    <axis xyz=\"1  0  0\"/>\n    <limit effort=\"100\" lower=\"0\" upper=\"0.14\" velocity=\"100\"/>\n</joint>\n\n<!-- The right gripper  -->\n<link name=\"rosbot_rgripper\">\n    <xacro:inertial_matrix_cuboid mass=\"${gripper_finger_mass}\" box_length=\"${gripper_finger_length}\" box_width=\"${gripper_finger_width}\"/>\n    <collision name=\"rosbot_collision\">\n      <origin rpy=\"0  0  0\" xyz=\"-0.0  0.20  ${gripper_finger_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_finger_length} ${gripper_finger_width} ${gripper_finger_height}\"/>\n      </geometry>\n    </collision>\n    <visual name=\"rosbot_visual\">\n      <origin rpy=\"0  0  0\" xyz=\"-0.0  0.20  ${gripper_finger_height/2}\"/>\n      <geometry>\n        <box size=\"${gripper_finger_length} ${gripper_finger_width} ${gripper_finger_height}\"/>\n      </geometry>\n      <material name=\"green\"/>\n    </visual>\n  </link>\n\n<!-- The joint between gripper box and gripper needs to be at origin or slightly higher than origin of gripper box  -->\n<joint name=\"rosbot_rgripper_joint\" type=\"prismatic\">\n    <parent link=\"rosbot_gripper_box\"/>\n    <child link=\"rosbot_rgripper\"/>\n    <origin rpy=\"0  0  0\" xyz=\"0.2  0.2  0.02\"/>\n    <axis xyz=\"1  0  0\"/>\n    <limit effort=\"100\" lower=\"-0.14\" upper=\"0\" velocity=\"100\"/>\n</joint>\n\n</robot>\n"], "answer_code": ["<xacro:property name=\"damping_value\" value=\"10\" />\n<xacro:property name=\"friction_value\" value=\"0.1\" />\n", "<!-- The joint between swivel and base needs to be flush on the top face of rosbot_base  -->\n<joint name=\"rosbot_base_swivel_joint\" type=\"revolute\">\n  <parent link=\"rosbot_base\"/>\n  <child link=\"rosbot_swivel_base\"/>\n  <origin rpy=\"0  0  0\" xyz=\"0  0  ${base_box_height/2}\"/>\n  <axis xyz=\"0  0  1\"/>\n  <limit effort=\"100\" lower=\"-1.57\" upper=\"1.57\" velocity=\"100\"/>\n  <dynamics damping=\"${damping_value}\" friction=\"${friction_value}\"/>\n</joint>\n"], "url": "https://stackoverflow.com/questions/48801772/gazebo-model-does-not-stand"},
{"title": "Using rosserial to communicate with MX-64 DYNAMIXEL motor", "time": "2018-08-03 05:17:02Z", "post_content": ["When I try to use rosserial to communicate with an Arduino to control the MX-64 motor, every time I use rostopic pub to send a message, it will give me this error:", "\"Mismatched protocol version in packet: lost sync or rosserial_python is from different ros release than the rosserial client \"", "If I remove the ", " function in the code or don't send any information though ROS, there will be no error. I tried all the rosserial examples, all of them are working just fine without any error.", "The weird thing is even if it gives me an error, the program is still working. Every time I send a message, the DYNAMIXEL motor will start moving."], "answer": ["It looks like your Dynamixel servo is hooked up to the same serial port that you use to communicate with the rosserial server. In many Arduino boards like the Uno the hardware serial port (where your Dynamixel is hooked up) is connected to a USB serial converter (which connects ROS via USB).", "You need to connect your Dynamixel to a different hardware (or ", ") serial on your Arduino and initialize it with ", " (", "), where ", " is that hardware / software serial."], "quote": ["\"Mismatched protocol version in packet: lost sync or rosserial_python is from different ros release than the rosserial client \""], "question_code": ["Dynamixel.move(X_SERVO_ID,rollint);", "#if (ARDUINO >= 100)\n #include <Arduino.h>\n#else\n #include <WProgram.h>\n#endif\n\n#include <ros.h>\n#include <std_msgs/Int8.h>\n\n\nros::NodeHandle  nh;\n\n#include <Dynamixel_Serial.h>       // Library needed to control Dynamixal servo\n#include <sensor_msgs/Imu.h>\n\n#define X_SERVO_ID 0x01 // ID which we will be set in Dynamixel too \n\nint rollint = 0;\n\nvoid motor_cb(const std_msgs::Int8& cmd_msg) {\n  rollint = ((1.00*(90-cmd_msg.data))/360)*4095;\n  Dynamixel.move(X_SERVO_ID,rollint); \n}\n\nros::Subscriber<std_msgs::Int8> sub(\"MX_Motor\", motor_cb);\n\nvoid setup() {\n  delay(100); // Give time for Dynamixel to start on power-up\n  nh.initNode();\n  nh.subscribe(sub);\n\n}\n\nvoid loop(){\n  nh.spinOnce();\n  delay(1);\n}\n"], "answer_code": ["Dynamixel.begin(Stream&)", "Stream&"], "url": "https://stackoverflow.com/questions/51644717/using-rosserial-to-communicate-with-mx-64-dynamixel-motor"},
{"title": "Replotting graph based on ROS subscribed data", "time": "2014-05-08 12:42:46Z", "post_content": ["I have a plot. And a curve in that plot.\nI have a node in the file and a subscriber. This subscriber subscribes to some float data, that is being published.\nEvery time some data is published, I update the curve by adding the new datapoint to the existing set.", "The graph is not updated properly. As the data comes in every second, the GUI is getting hanged up and after some time, the GUI is aborted due to a Segmentation Fault.", "Calling these functions :-", "Once the listener is called, the subscriber is automatically associated with the callback function. The callback function looks at the new data, adds it to the y-axis and then, replots the graph.", "I am getting this error everytime a new datapoint is published :-", "I don't understand this error.", "ROS follows the ", " pattern. I have already created a node that publishes a random integer. This integer should be plotted on the graph."], "answer": ["Your ", " method is running in thread. You cannot update Qt GUI objects from another thread. This is why you see errors and get segfaults.", "The solutions are:", "In the callback, append the data to a list. Use a ", " started from the main thread to periodically check the list for updates and replot the graph (not an ideal solutions, but will likely get the job done)", "In the callback, place the data in a python ", ". Have a ", " block on reading from this queue and emit a qt signal (with the data in it) each time something is read from the ", ". Connect a method in your main thread to this qt signal. Your method in the main thread thus gets the data and can update the plot from the main thread.", "Here are a bunch of other stack overflow questions which do something similar (send data from a thread into the qt main thread to avoid segfaults) or will be useful when delving into multithreaded pyqt applications:"], "question_code": ["def initUI(self):\n\n    # x11.XInitThreads()\n\n    # xlib.XInitThreads()\n\n    # initialising the window\n\n    QtGui.QWidget.__init__(self)\n\n    # self.setGeometry(300, 300, 160, 1000)\n    # self.setWindowTitle('Visualizer')\n\n    # main layout\n\n    self.layout = QtGui.QVBoxLayout(self)\n\n    # Creating the elements in this widget\n\n    a = QtGui.QLabel(\"Navigation\", self)\n\n    a.setStyleSheet(\"QLabel{ background-color: white; color: black; font-size: 25px; }\")\n\n    self.plot = Qwt.QwtPlot(self)\n    self.plot.setCanvasBackground(Qt.black)\n    self.plot.setAxisTitle(Qwt.QwtPlot.xBottom, 'Time')\n    self.plot.setAxisScale(Qwt.QwtPlot.xBottom, 0, 10, 1)\n    self.plot.setAxisTitle(Qwt.QwtPlot.yLeft, 'Temperature')\n    self.plot.setAxisScale(Qwt.QwtPlot.yLeft, 0, 250, 40)\n    self.plot.replot()\n\n    self.curve = Qwt.QwtPlotCurve('')\n    self.curve.setRenderHint(Qwt.QwtPlotItem.RenderAntialiased)\n    pen = QPen(QColor('limegreen'))\n    pen.setWidth(2)\n    self.curve.setPen(pen)\n    self.curve.attach(self.plot)\n\n    self.layout.addWidget(a)\n    self.layout.addWidget(self.plot)\n\ndef listener(self):       \n\n    rospy.init_node('listener', anonymous=True)\n\n    rospy.Subscriber(TOPIC_NAME, String, self.callback)\n\ndef callback(self, data):\n\n    self.xData.append(self.counter + 1)\n    self.yData.append(int(str(data.data)))\n    self.counter += 1\n\n    self.curve.setData(self.xData, self.yData)\n    self.plot.replot()\n", "self.listener()\nself.initUI()\n", "QCoreApplication::sendPostedEvents: Cannot send posted events for objects in another thread\nQPixmap: It is not safe to use pixmaps outside the GUI thread\nQPixmap: It is not safe to use pixmaps outside the GUI thread\nQPainter::begin: Paint device returned engine == 0, type: 2\nQPainter::setPen: Painter not active\nQPainter::setBrush: Painter not active\nQPainter::drawRects: Painter not active\nQPainter::begin: Paint device returned engine == 0, type: 2\nQPainter::translate: Painter not active\nQPainter::save: Painter not active\nQPainter::setRenderHint: Painter must be active to set rendering hints\nQPainter::save: Painter not active\nQPainter::setPen: Painter not active\nQPainter::restore: Unbalanced save/restore\nQPainter::restore: Unbalanced save/restore\nQPainter::end: Painter not active, aborted\n", "Ubuntu 12.04\nROS Hydro\nPyQt4\nQwt5\n"], "answer_code": ["callback", "QTimer", "Queue.Queue()", "QThread", "Queue"], "url": "https://stackoverflow.com/questions/23541974/replotting-graph-based-on-ros-subscribed-data"},
{"title": "OpenCV and ROS: NULL Pointer error in cvMAT", "time": "2012-08-17 09:17:41Z", "post_content": ["I'm using the following to to detect the position, orientation of two colored objects.\nEverything works well unless the camera is unable to fine any of those two objects(yellow and blue) or when I put my hand in front of the camera. It throws the following error:", "OpenCV Error: Null pointer (NULL array pointer is passed) in cvGetMat, file /tmp/buildd/libopencv-2.3.1+svn6514+branch23/modules/core/src/array.cpp, line 2382\nterminate called after throwing an instance of 'cv::Exception'\n  what():  /tmp/buildd/libopencv-2.3.1+svn6514+branch23/modules/core/src/array.cpp:2382: error: (-27) NULL array pointer is passed in function cvGetMat", "I'd be grateful if someone could help me resolve this error.", "Thank You"], "answer": ["When you call ", " you check the returned value for ", " when calling ", ". However, you use the returned value after that as well, without checking for ", ".", "The simple solution is to add more checks for ", " before you use the returned value."], "question_code": ["#include <ros/ros.h>\n#include <opencv/cv.h>\n#include <opencv/highgui.h>\n\n\n\n#include <iostream>\n#include <fstream>\n#include <stdio.h>\n#include <stdlib.h>\n\n#include <math.h>\n\n#include <geometry_msgs/Twist.h>\n\n#define MAX_CONTOUR_LEVELS 5 //This will be used when displaying contours\n#define PI 3.14159265\nusing namespace cv;\nusing namespace std;\n// Class Definition\nclass color_control {\npublic:\n    void mainLoop1();\n    void mainLoop2();\n    double R_X, R_Y; /* red center of gravity x,y in the frame normalized from -1.0 to 1.0 */\n    int C_C;\n    double setSpeed( double, double );\n    void do_some_magic( IplImage* , int , int , int , int );\n\n    color_control()\n    {\n      // node creation in root-namespace \n      ros::NodeHandle m_nodeHandle(\"/\");\n\n      m_commandPublisher = m_nodeHandle.advertise<geometry_msgs::Twist> (\"cmd_vel\", 20);\n    }\n\n    ~color_control()\n    {\n      cvDestroyWindow(\"result\");\n    }\n\n\n\nprotected:\n\n    ros::NodeHandle m_nodeHandle;\n\n    // Publisher und Membervariable f\u00fcr die Fahrbefehle\n    ros::Publisher m_commandPublisher;\n    geometry_msgs::Twist m_roombaCommand;\n\n};\n\nint abort_error_handler(int status, char const* func_name, char const* err_msg, char const* file_name, int line, void*) {\ncout << \"ERROR: in \" << func_name << \"(\" << file_name << \":\" << line << \") Message: \" << err_msg << endl;\nabort();\n}\n\nIplImage* GetThresholdedImage1(IplImage* img)\n{\n    IplImage* imgHSV = cvCreateImage(cvGetSize(img), 8, 3);\n    cvCvtColor(img, imgHSV, CV_BGR2HSV);\n    IplImage* imgThreshed1=cvCreateImage(cvGetSize(img),8,1);\n    //cvInRangeS(imgHSV, cvScalar(20, 100, 100), cvScalar(30, 255, 255), imgYellow);\n    cvInRangeS(imgHSV, cvScalar(22, 100, 100), cvScalar(32, 255, 255), imgThreshed1);\n    cvReleaseImage(&imgHSV);\n    //cvAdd(imgYellow,imgGreen,imgThreshed);\n    //if (imgThreshed1 != NULL)\n            return imgThreshed1;\n    //cvShowImage( \"result\", imgThreshed1 );\n}\n\nIplImage* GetThresholdedImage2(IplImage* img)\n{\n    IplImage* imgHSV = cvCreateImage(cvGetSize(img), 8, 3);\n    cvCvtColor(img, imgHSV, CV_BGR2HSV);\n    IplImage* imgThreshed2=cvCreateImage(cvGetSize(img),8,1);\n    //cvInRangeS(imgHSV, cvScalar(20, 100, 100), cvScalar(30, 255, 255), imgYellow);\n    cvInRangeS(imgHSV, cvScalar(100,100,100^3),cvScalar(120,255,255^3), imgThreshed2);\n    cvReleaseImage(&imgHSV);\n    //cvAdd(imgYellow,imgGreen,imgThreshed);\n    //if (imgThreshed2 == NULL)\n            return imgThreshed2;\n\n\n}\n\n// find the largest contour (by area) from a sequence of contours and return a\n// pointer to that item in the sequence\n\nCvSeq* findLargestContour(CvSeq* contours){\n\n  CvSeq* current_contour = contours;\n  double largestArea = 0;\n  CvSeq* largest_contour = NULL;\n\n  // check we at least have some contours\n\n  if (contours == NULL){return NULL;}\n\n  // for each contour compare it to current largest area on\n  // record and remember the contour with the largest area\n  // (note the use of fabs() for the cvContourArea() function)\n\n  while (current_contour != NULL){\n\n      double area = fabs(cvContourArea(current_contour));\n\n      if(area > largestArea){\n          largestArea = area;\n          largest_contour = current_contour;\n      }\n\n      current_contour = current_contour->h_next;\n  }\n\n  // return pointer to largest\n\n  return largest_contour;\n\n}\n\n// normalize center of color to propulsion command\ndouble color_control::setSpeed( double center, double width ){\n\n\n  double normedCenter = (12.0*center/width) - 6.0;\n    //ROS_INFO(\"normed center: %f\", normedCenter);\n  double retval = 0.0;\n\n  if ( fabs( normedCenter ) > 1.0 ){\n      retval = (trunc( normedCenter )/10.0 );\n  }\n  return retval;\n\n}\n\n//\n// comments R 4 mollycoddles, guess what i'm doing!\n// \n// Please help me ! I need someone writing comments. Thanx\n//\nvoid color_control::do_some_magic( IplImage* img, int red, int green, int blue, int tolerance) {\n\n    int radius = 20 ;\n\n    int width = img->width;\n    int height = img->height;\n    int channels = img->nChannels;\n    int step = img->widthStep;\n\n    unsigned char redP = 0, greenP = 0, blueP = 0;\n    double S_x = 0.0 ;\n    double S_y = 0.0 ;\n    int red_difference, green_difference, blue_difference = 255;\n\n    C_C = 0 ;\n\n    for(int y=0;y<height;y++) {\n        for(int x=0;x<width;x++) {\n          blueP = img->imageData[y*step+x*channels+0] ;\n          greenP = img->imageData[y*step+x*channels+1] ;\n          redP = img->imageData[y*step+x*channels+2] ;\n\n      red_difference = fabs(red - (int)redP);\n      green_difference = fabs(green - (int)greenP);\n      blue_difference = fabs(blue - (int)blueP);\n\n      if ( (red_difference + green_difference + blue_difference) < tolerance ) {\n         C_C++ ;\n         S_x += x;\n         S_y += y;\n\n         //ROS_INFO( \"Difference to target color: %i\", (red_difference + green_difference + blue_difference) );\n        }\n\n        }\n     }\n\n    S_x = S_x / (C_C) ;\n    S_y = S_y / (C_C) ;\n\n    R_X = setSpeed( S_x, img->width );\n    R_Y = setSpeed( S_y, img->height );\n\n    // for monitoring, draw a circle and display the respective picture\n    CvPoint center;\n    center.x = S_x;\n    center.y = S_y;\n    cvCircle( img, center, radius, CV_RGB( 255 - red, 255 - green, 255 - blue ) , 3, 8, 0 );\n    cvShowImage( \"result\", img );\n}\n\n// Main Loop\nvoid color_control::mainLoop1() {\n    // determines the number of frames per second\n    ros::Rate loop_rate(20);\n     int radius ;\n    CvCapture* capture = 0;\n    //IplImage *frame, *frame_copy = 0;\n    IplImage* imgScribble=NULL;\n    // open the camera\n    capture = cvCaptureFromCAM( 0 );\n    cvSetCaptureProperty(capture,CV_CAP_PROP_FRAME_HEIGHT, 640);\n    cvSetCaptureProperty(capture,CV_CAP_PROP_FRAME_WIDTH, 480);\n    //capture = cvCaptureFromCAM( 1 );\n    //cvRedirectError(abort_error_handler);\n\n\n\n    // loop stops, e.g. if the node recieves a kill signal\n    while (m_nodeHandle.ok())\n    {\n        IplImage* frame=0;\n                    frame=cvQueryFrame(capture);\n\n                    if(!frame)\n                                break;\n//                  if(imgScribble == NULL)\n//                  {\n//                      imgScribble=cvCreateImage(cvGetSize(frame),8,1);\n//                  }\n\n\n                    IplImage* imgYellowThresh = GetThresholdedImage1(frame);\n                    IplImage* imgGreenThresh = GetThresholdedImage2(frame);\n\n\n\n            //CvMemStorage and CvSeq are structures used for dynamic data collection. CvMemStorage contains pointers to the actual\n            //allocated memory, but CvSeq is used to access this data. Here, it will hold the list of image contours.\n            CvMemStorage *storage = cvCreateMemStorage(0);\n            CvSeq *contours = 0;\n\n            //Once we have a binary image, we can look for contours in it. cvFindContours will scan through the image and store connected contours in \"sorage\".\n            //\"contours\" will point to the first contour detected. CV_RETR_TREE means that the function will create a contour hierarchy. Each contour will contain\n            //a pointer to contours that are contained inside it (holes). CV_CHAIN_APPROX_NONE means that all the contours points will be stored. Finally, an offset\n            //value can be specified, but we set it to (0,0).\n            cvFindContours(imgYellowThresh, storage, &contours, sizeof(CvContour), CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE, cvPoint(0,0));\n\n            //This function will display contours on top of an image. We can specify different colours depending on whether the contour in a hole or not.\n            CvSeq* largest_contour = NULL;\n            largest_contour = findLargestContour(contours);\n\n                //cvDrawContours(imgYellowThresh, largest_contour, CV_RGB(255,255,255), CV_RGB(0,255,0), MAX_CONTOUR_LEVELS, 3, CV_AA, cvPoint(0,0));\nif(largest_contour!=NULL) {\n                cvDrawContours(imgYellowThresh, largest_contour, CV_RGB(255,255,255), CV_RGB(0,255,0), 0, 2, 8, cvPoint(0,0));\n\n}\n\n            static int posX_Yellow=0;\n            static int posY_Yellow=0;\n\n\n            //int lastX=posX;\n            //int lastY=posY;\n\n           CvMoments moments1,cenmoments1;\n           double M00, M01, M10;\n\n           cvMoments(largest_contour,&moments1);\n           M00 = cvGetSpatialMoment(&moments1,0,0);\n           M10 = cvGetSpatialMoment(&moments1,1,0);\n           M01 = cvGetSpatialMoment(&moments1,0,1);\n           posX_Yellow = (int)(M10/M00);\n           posY_Yellow = (int)(M01/M00);\n\n          double theta = 0.5 * atan(\n                    (2 * cvGetCentralMoment(&moments1, 1, 1)) /\n                    (cvGetCentralMoment(&moments1, 2, 0) -  cvGetCentralMoment(&moments1, 0, 2)));\n                theta = (theta / PI) * 180;\n\n                // fit an ellipse (and draw it)\n\n                if (largest_contour->total >= 6) // can only do an ellipse fit\n                                                 // if we have > 6 points\n                {\n                    CvBox2D box = cvFitEllipse2(largest_contour);\n                    if ((box.size.width < imgYellowThresh->width) &&  (box.size.height < imgYellowThresh->height))\n                    {\n                        // get the angle of the ellipse correct (taking into account MS Windows\n                        // seems to draw ellipses differently\n\n                        box.angle =  270 - box.angle;\n                        #ifndef WIN32\n                            if( imgYellowThresh->origin ) {\n                                box.angle = - box.angle;\n                            }\n                        #endif\n                        cvEllipseBox(imgYellowThresh, box, CV_RGB(255, 255 ,255), 3, 8, 0 );\n                    }\n                }\n              CvFont font;\n              cvInitFont(&font, CV_FONT_HERSHEY_PLAIN, 1, 1 , 0, 2, 8 );\n\n            #ifdef WIN32\n                int height_offset = 20;\n            #else\n                int height_offset = 5;\n            #endif\n                char outputString[255];\n\n                sprintf(outputString, \"angle: %.10f\", theta);\n                cvPutText(imgYellowThresh, outputString,\n                    cvPoint(10,imgYellowThresh->height - height_offset), &font, CV_RGB(255, 255,255));\n\n\n\n\n\n\n                              CvMemStorage *storageG = cvCreateMemStorage(0);\n\n    CvSeq *contoursG = 0;\n\n        //Once we have a binary image, we can look for contours in it. cvFindContours will scan through the image and store connected contours in \"sorage\".\n        //\"contours\" will point to the first contour detected. CV_RETR_TREE means that the function will create a contour hierarchy. Each contour will contain\n        //a pointer to contours that are contained inside it (holes). CV_CHAIN_APPROX_NONE means that all the contours points will be stored. Finally, an offset\n        //value can be specified, but we set it to (0,0).\n        cvFindContours(imgGreenThresh, storageG, &contoursG, sizeof(CvContour), CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE, cvPoint(0,0));\n\n        //This function will display contours on top of an image. We can specify different colours depending on whether the contour in a hole or not.\n        CvSeq* largest_contourG = NULL;\n        largest_contourG = findLargestContour(contoursG);\n\nif(largest_contourG!=NULL) {\n            //cvDrawContours(imgYellowThresh, largest_contour, CV_RGB(255,255,255), CV_RGB(0,255,0), MAX_CONTOUR_LEVELS, 3, CV_AA, cvPoint(0,0));\n\n            cvDrawContours(imgGreenThresh, largest_contourG, CV_RGB(255,255,255), CV_RGB(0,255,0), 0, 2, 8, cvPoint(0,0));\n}\n        //cvShowImage( \"result2\", imgGreenThresh );\n    CvMoments moments2;\n                               double M00g, M01g, M10g;\n\n                               cvMoments(largest_contourG,&moments2);\n                               M00g = cvGetSpatialMoment(&moments2,0,0);\n                               M10g = cvGetSpatialMoment(&moments2,1,0);\n                               M01g = cvGetSpatialMoment(&moments2,0,1);\n                               static int posX_Green=0;\n                                        static int posY_Green=0;\n                                posX_Green = (int)(M10g/M00g);\n                               posY_Green = (int)(M01g/M00g);\n\n                               //printf(\"%d\\n\",M00g);\n   //ROS_INFO(\"position (%d,%d)\\n\",posX_Yellow,posY_Yellow);\n   //ROS_INFO(\"position (%d,%d)\\n\",posX_Green,posY_Green);\n\n            //do_some_magic( frame , 0, 0, 0, 100);\n\n\n\n\n//          if(lastX>0 && lastY>0 && posX>0 && posY>0)\n//                  {\n//                      cvLine(imgScribble,cvPoint(posX,posY),cvPoint(lastX,lastY),cvScalar(0,255,255), 5);\n//                  }\n//          cvAdd(frame,imgScribble,frame);\n            cv::Point centerY(posX_Yellow,posY_Yellow);\n            //centerY.x = posX_Yellow;\n            //centerY.y = posY_Yellow;\n            //radius = sqrt(areaY/3.14);\n            cvCircle( frame, centerY, 10, CV_RGB( 255, 255, 255) , 3, 8, 0 );\n\n            cv::Point centerG(posX_Green,posY_Green);\n            //centerG.x = posX_Green;\n            //centerG.y = posY_Green;\n            cv::Point diff = centerY - centerG;\n            //radius = sqrt(areaG/3.14);\n            cvCircle( frame, centerG, 10, CV_RGB( 255, 255, 255) , 3, 8, 0 );\n            //float angle = atan2(centerY,centerX);\n            int slope = ((diff.y)/(diff.x));\n            int len = cv::sqrt(diff.x*diff.x + diff.y*diff.y);\n            double newdist = (len / 2000000);\n            cvLine(frame, centerY, centerG, CV_RGB( 255, 255, 255), 5,8,0);\n            //cvCircle( frame, diff, 10, CV_RGB( 255, 255, 255) , 3, 8, 0 );\n            //ROS_INFO(\"angle :  %d\\n\",theta);\n            //ROS_INFO(\"len: %d    slope: %d\\n\",len,slope);\n            //printf(\"len: %f\\n\", slope);\n            cvShowImage( \"result\", frame );\n            cvShowImage( \"result1\", imgYellowThresh );\n            cvShowImage( \"result2\", imgGreenThresh );\n\n            if( cvWaitKey( 10 ) >= 0 )\n                                    break;\n\n         //ROS_INFO( \"C_C: %d\", C_C );\n\n\n\n         // set driving direction and velocity\n//       if (len > 50 || slope > 0)\n//        {\n//          m_roombaCommand.linear.x = 0.1;\n//          m_roombaCommand.angular.z = 0.0;\n//        } else {\n//          m_roombaCommand.linear.x = 0.0;\n//          m_roombaCommand.angular.z = 0.1;\n//        }\n\n\n         //\n//      ROS_INFO(\"Forward: %f - Turning: %f\", m_roombaCommand.linear.x, m_roombaCommand.angular.z);\n//\n//      // send the driving command to the roomba\n        //m_commandPublisher.publish(m_roombaCommand);\n\n    // spinOnce is doing the loop exactly once\n    ros::spinOnce();\n            //cvReleaseCapture( &capture );\n\n    // sleep stops the process for approx ~50ms, to keep the timing for the looprate\n    loop_rate.sleep();\n\n\n    }\n\n    //cvReleaseImage( &frame_copy );\n\n\n}\n\n\nint main(int argc, char** argv) {\n    //sleep(10);\n    // Initialize\n    ros::init(argc, argv, \"color_control\");\n\n    ros::NodeHandle n;\n    color_control f_g;\n    f_g.mainLoop1();\n    //color_control g_g;\n    //g_g.mainLoop2();\n    ros::spin();\n    //cvRedirectError(abort_error_handler);\n    return 0;\n\n\n\n\n        //cvNamedWindow(\"Video\");\n        //cvNamedWindow(\"thresh\");\n    }\n"], "answer_code": ["findlargestContour", "NULL", "cvDrawContours", "NULL", "NULL"], "url": "https://stackoverflow.com/questions/12003050/opencv-and-ros-null-pointer-error-in-cvmat"},
{"title": "How to read a frame (raw_Image) from a virtual turtlebot's camera in Gazebo, and manipulate it using OpenCV and publish for viewing in Rviz", "time": "2019-12-02 02:36:06Z", "post_content": ["For my class robotics project, we are required to read in video feed frame by frame from a virtual turtlebot being simulated using gazebo. Then we detect colors in this image (red, blue, and green) if they are at the center of the image, within a rectangle that we have to draw in the center of the frame. If one of the colors are detected, the rectangle should change from green to red, and if the 's' button is clicked while the rectangle is red (ie it detects a color) then it should publish to a topic saying that the target was shot. The majority of this code was written for a previous assignment, in which we had to detect any of these colors anywhere in a frame from a webcam and indicate it with a bounding box or circle, and my code worked for that assignment. Now I have changed my code slightly to read frames from the virtual camera, and I added some code from some example code that our professor provided us with to try to publish the modified image so that I can view it using Rviz. Whatever I added is making the code no longer work as it should and I am getting an error, but I don't understand the code deeply enough to find my error. ", "The error that I am receiving is as follows: ", "[ERROR] [1575253473.863051, 2724.055000]: bad callback: ", "Traceback (most recent call last):", "File \"/opt/ros/melodic/lib/python2.7/dist-packages/rospy/topics.py\", line 750, in _invoke_callback\n      cb(msg)", "File \"/home/project_ws/src/project_gazebo/scripts/color_detect.py\", line 49, in ImageCallback\n      upper_left(int(w/4), h)", "TypeError: 'NoneType' object is not callable", "I have no idea what this means or how to fix it. I know that it is probably a problem with the subscriber callback function, but I tried to write it exactly how the professor's example did for face detection (rather than color detection). Other than that, I have no idea how to fix this issue. I could really use some guidance. ", "Here is what the file looks like (I would only post a snippet, but since I am unsure where the issue is I am posting all of it):"], "answer": [], "quote": ["[ERROR] [1575253473.863051, 2724.055000]: bad callback: ", "Traceback (most recent call last):", "File \"/opt/ros/melodic/lib/python2.7/dist-packages/rospy/topics.py\", line 750, in _invoke_callback\n      cb(msg)", "File \"/home/project_ws/src/project_gazebo/scripts/color_detect.py\", line 49, in ImageCallback\n      upper_left(int(w/4), h)", "TypeError: 'NoneType' object is not callable"], "question_code": ["#!/usr/bin/env python\nfrom __future__ import print_function\nfrom collections import deque\nimport numpy as np\nimport cv2\nimport sys\nimport rospy\nimport rospkg\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\n\n\nhit_pub = rospy.Publisher('Cait/hit', String, queue_size=10)\nimage_pub = rospy.Publisher(\"Cait/image_topic_2\",Image, queue_size=10)\n\nbridge = CvBridge()\nframe = None\n\nheight= None\nwidth= None\nupper_left=None\nlower_right=None\n\ninRange= False\ntargetHit = False\n\ndef ImageCallback(data):\n    try:\n        global frame\n        frame = bridge.imgmsg_to_cv2(data, \"bgr8\")\n        #frame = data.data\n        global height\n        global width\n\n        (h, w) = frame.shape[:2] #w:image-width and h:image-height\n\n        height = h\n        width = w\n\n        global centerPoint_x\n        global centerPoint_y\n        centerPoint_x = w/2\n        centerpoint_y= h/2\n\n        global upper_left\n        global lower_right\n        upper_left(int(w/4), h)\n        lower_right(int(w*3/4), 0)\n\n    except CvBridgeError as e:\n        print(e)\n\nimage_sub = rospy.Subscriber(\"Cait/camera/rgb/image_raw\",Image,ImageCallback)\n\ndef Image_converter():\n    # define the lower and upper boundaries of the colors in the HSV color space\n    lower = {'red':(166, 84, 141), 'green':(66, 122, 129), 'yellow':(23, 59, 119)} \n    upper = {'red':(186,255,255), 'green':(86,255,255), 'yellow':(54,255,255)}\n\n\n\n\n    # grab frames from webcam -> now grab fromm rviz raw_image in subscriber\n    #camera = cv2.VideoCapture(0)\n\n\n    # keep looping\n    while True:\n     # grab the current frame -> now done by ImageCallback()\n        #(grabbed, frame) = camera.read()\n\n\n\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n        #for each color in dictionary check object in frame\n\n        #draw rectangle in the center of the frame\n        cv2.rectangle(frame, upper_left, lower_right, (0, 255, 0), 2)\n\n        for key, value in upper.items():\n            # construct a mask for the color from dictionary`1, then remove any small blobs left in the mask\n            kernel = np.ones((9,9),np.uint8)\n            mask = cv2.inRange(hsv, lower[key], upper[key])\n            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n            # find contours in the mask and initialize the current (x, y) center of the ball\n            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n                cv2.CHAIN_APPROX_SIMPLE)[-2]\n            center = None\n\n            # only proceed if at least one contour was found\n            if len(cnts) > 0:\n                # find the largest contour in the mask, then use it to compute the minimum enclosing circle \n                c = max(cnts, key=cv2.contourArea)\n                ((x, y), radius) = cv2.minEnclosingCircle(c)\n\n                #check to see if the point found is at the center of the screen, and if yes change the color of the rectangle\n                global inRange\n\n                if (x > int(width/4) & x< int(width*3/4)):\n                    if(y > 0 & y < height):\n                        cv2.rectangle(frame, upper_left, lower_right, (0, 0, 255), 2)\n                        inRange = True\n                else:\n                    cv2.rectangle(frame, upper_left, lower_right, (0, 255, 0), 2)\n                    inRange= False\n\n\n\n        # show the frame to our screen\n        cv2.imshow(\"Image window\", frame)\n        key = cv2.waitKey(1) & 0xFF\n\n        try:\n            image_pub.publish(bridge.cv2_to_imgmsg(frame, \"bgr8\"))\n        except CvBridgeError as e:\n            print(e)\n\n        # if the 's' key is pressed, publish an answer to the topic\n        if key == ord(\"s\"):\n            if (inRange):\n                hit_pub.publish(\"Target hit!\")\n            else: \n                hit_pub.publish(\"Sorry. Nothing was hit.\")\n        if key == ord(\"q\"): #q quits loop\n            break   \n\ndef main(args):\n  rospy.init_node('image_converter', anonymous=True)\n  Image_converter()\n\n  try:\n    rospy.spin()\n  except KeyboardInterrupt:\n    print(\"Shutting down\")\n  cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main(sys.argv)\n", "upper_left", "upper_right", "= None", "NoneType", "None", "=", "upper_left = (int(w/4), h)", "lower_right = (int(w*3/4), 0)"], "url": "https://stackoverflow.com/questions/59131771/how-to-read-a-frame-raw-image-from-a-virtual-turtlebots-camera-in-gazebo-and"},
{"title": "How do we dynamically change the text in label widget of Tkinter according to the change of subscribed topic message?", "time": "2016-05-11 15:34:27Z", "post_content": ["I wanted to change the text of my label according to the topic message to which my node subscribes. But the problem is that the text in the label is not changing with the change of topic message. A portion of my code is given below:(I used the code to dynamically change the text in the label from ", ")"], "answer": ["Well, your code (or at least the portion you posted) seems to be a messy one.", "ROS talking,", "That being said, here's an example of how the code should look like : (fill in the blanks)"], "question_code": ["v = StringVar()\nv.set(distance)\nself.clock = Label(frame, font=('times', 20, 'bold'), bg='green', textvariable = v)\nself.clock.pack(fill=BOTH, expand=1)\nrate = rospy.Rate(2)\n\nwhile not rospy.is_shutdown():\n    rospy.Subscriber(\"distance\", Float32, self.callback)\n    v.set(distance)\n    print(\"distance = %f\", distance)\n    frame.update_idletasks()\n    rate.sleep()\n", "distance", "print"], "answer_code": ["define your subscriber in the initialization of the node", "create a callback to get the messages", "update your label", "#!/usr/bin/env python\nimport rospy\nfrom std_msgs.msg import Float32\n\ndef callback(data):\n    distance = data.data\n    rospy.loginfo(rospy.get_caller_id() + \"distance = \", distance )\n    #here update your label, I assume the following (maybe not correct)\n    v = StringVar()\n    v.set(distance)\n    self.clock = Label(frame, font=('times', 20, 'bold'), bg='green', textvariable = v)\n    self.clock.pack(fill=BOTH, expand=1)\n\ndef listener():\n    rospy.init_node('listener', anonymous=True)\n    rospy.Subscriber(\"distance\", Float32, self.callback)  \n    # spin() simply keeps python from exiting until this node is stopped\n    rospy.spin()\n\n\nif __name__ == '__main__':\n    listener()\n"], "url": "https://stackoverflow.com/questions/37167238/how-do-we-dynamically-change-the-text-in-label-widget-of-tkinter-according-to-th"},
{"title": "How to install ROS (Robotics Operating System) on Raspberry pi 3", "time": "2018-11-09 06:40:44Z", "post_content": ["How i will able to install ROS (Robotics Operating System). I want to install ROS on my raspberry pi 3."], "answer": ["There are many of Image list item you need to choice one", "It take some minutes about 1 GB file. When download completed Unzip ROS image into a folder ", " ", "$ rostopic list", "Output"], "answer_code": ["/battery_state\n/cmd_vel\n/diagnostics\n/joint_states\n/joy\n/left_error\n/motor_node/parameter_descriptions\n/motor_node/parameter_updates\n/right_error\n/rosout\n/rosout_agg\n/statistics\n/tf\n/tf2_web_republisher/cancel\n/tf2_web_republisher/feedback\n/tf2_web_republisher/goal\n/tf2_web_republisher/result\n/tf2_web_republisher/status\n/tf_static\n"], "url": "https://stackoverflow.com/questions/53220885/how-to-install-ros-robotics-operating-system-on-raspberry-pi-3"},
{"title": "I'm trying to publish a message of a Tizen based app on ros using rosbridge and i get an error", "time": "2016-10-12 09:01:52Z", "post_content": ["as the title says, I'm trying to publish a message on ros using rosbridge, because my app is written in javascript. Basically i want to cast a stream of heart rate data on a pc running ros to so some elaboration. The app is running on a Tizen based smartwatch. If i try to publish geometry messages, like the device orientation, i have no problem and they are published on ros. I tried the sensor message type (channelfloat32 in particular) to cast the stream of the heart rate with no success. I investigated on the type of the data coming out from the sensor and i discovered that is a number type data of javascript.\nSo i used the standard message type (Float64 in particular because, as far as i know based on some searching, apparently javascript uses only this type for numbers) with no success again.\nMaybe i could cast the variable or change its type, but i don't know if this could be a possible solution and i really don't know how to do it, maybe i only have to change the type of the ros message.\nAs you can see from my previous questions I'm very new to coding and I'm again on the same project.", "Thank you in advance for your help!", "Marco", "The code is below:", "function Connect(){"], "answer": ["If you are reading HRM data from Tizen wearable device you may use ", " of Human Activity Monitor API Instead of using ", "Rather using ", "You may try ", "And add the necessary privileges in config.xml file", "According to the ", " datatype of the heartRate is long.", "Please Check the ", " and ", " for details implementation."], "question_code": ["document.addEventListener('tizenhwkey', function(e) {\n    if(e.keyName === \"back\")\n        window.webapis.motion.stop(\"HRM\");\n        tizen.application.getCurrentApplication().exit();\n});\n", "var ip;\nvar connection=false;\n\nif (document.getElementById(\"ip\").value===\"\")\n{ \n    ip=\"10.42.0.1\";\n}\nelse \n{ \n    ip=document.getElementById(\"ip\").value;\n}\n\nvar ros = new ROSLIB.Ros({\n    url : 'ws://' + ip +':9090'\n    });\n\nros.on('connection', function() {\n    connection=true;\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"green\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Connected';\n    tizen.power.request(\"SCREEN\", \"SCREEN_DIM\");\n});\n\nros.on('error', function(error) {\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"orange\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Error';\n});\n\nros.on('close', function() {\n    document.getElementById(\"Connection_status\").setAttribute(\"color\",\"red\");\n    document.getElementById(\"Connection_status\").innerHTML = 'Unconnected';\n    connection=false;\n    tizen.power.release(\"SCREEN\");\n});\n\nvar RatePub = new ROSLIB.Topic({\n    ros : ros,\n    name : '/HeartRateData',\n    messageType : 'std_msgs/Float64'\n});\n\nwindow.webapis.motion.start(\"HRM\", onchangedCB);\n\nfunction onchangedCB(hrmInfo)\n{\n   var data = hrmInfo.heartRate;\n   document.getElementById(\"mytext\").innerHTML = 'Heart Rate= ' + data + ' bpm';\n\n\n   var Float64 = new ROSLIB.Message({\n            data:[data]\n        });\n\n        if(connection===true)\n            {\n            RatePub.publish(Float64);\n            }\n        else\n        {\n            document.getElementById(\"mytext\").innerHTML = 'Heart Rate= 0 bpm';\n        }\n\n        }}\n"], "answer_code": ["window.webapis.motion.start(\"HRM\", onchangedCB);\n\nfunction onchangedCB(hrmInfo) {\n    var data = hrmInfo.heartRate;\n    document.getElementById(\"mytext\").innerHTML = 'Heart Rate= ' + data + ' bpm';\n    ...\n    ..\n   }\n", "var dataCount = 0;\n\nfunction onsuccessCB(hrmInfo)\n{\n   console.log(\"Heart Rate: \" + hrmInfo.heartRate);\n   console.log(\"Peak-to-peak interval: \" + hrmInfo.rRInterval + \" milliseconds\");\n   dataCount++;\n\n   ...\n   ..\n\n   if (dataCount > 10){\n       /* Stop the sensor after detecting a few changes */\n       tizen.humanactivitymonitor.stop(\"HRM\");\n   }\n}\n\ntizen.humanactivitymonitor.start(\"HRM\", onsuccessCB);\n", "<tizen:privilege name=\"http://tizen.org/privilege/healthinfo\"/>\n<tizen:privilege name=\"http://tizen.org/privilege/power\"/>\n"], "url": "https://stackoverflow.com/questions/39994564/im-trying-to-publish-a-message-of-a-tizen-based-app-on-ros-using-rosbridge-and"},
{"title": "Android: NullPointerException 'double java.lang.Double.doubleValue()'", "time": "2019-10-04 07:25:11Z", "post_content": ["I'm new to android programming and I'm having a problem with my codes. Can anyone help me or point out the cause of my error because I'm not really sure why it's giving me a NullPointerException when its a text view or if that is possible.", "LogCat:", "Here is the code for that line:", "But when i run my app my voltage is setting null and here is the code for the voltage:", "Here is the full code:"], "answer": ["Check weather your created class with ", " is not null", "and then check class fields values  is not null or 0.", "You can check null before you set text on textview like the following.", "Everytime when you are setting the text to textview, you must need to check if it is not null."], "question_code": ["    java.lang.NullPointerException: Attempt to invoke virtual method 'double java.lang.Double.doubleValue()' on a null object reference\n    at com.example.app.rosbridge.MainActivity$2$1.run(MainActivity.java:133)\n", "   current.setText(String.format(\"%.4f%s\", batteryStateData.msg.current * Math.pow(10, 6), \"A\"));\n", "   voltage.setText(String.format(\"%.4f%s\", batteryStateData.msg.voltage, \"v\"));\n", "public class MainActivity extends Activity {\n\n\nprivate TextView voltage, current, percentage, status;\nprivate SubscribedData<BatteryState> batteryStateData;\nprivate RosbridgeListener rosbridge;\nprivate boolean subscribed = false;\nprivate boolean advertised = false;\n\n/** Indicates that Lint should ignore the specified warnings for the annotated element. */\n@SuppressLint(\"ClickableViewAccessibility\")\n@Override\n\nprotected void onCreate(Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState);\n    setContentView(R.layout.activity_main_activity);\n\n    Button settings_btn = (Button) findViewById(R.id.connect_btn);\n\n    voltage = findViewById(R.id.voltage_txt);\n    current = findViewById(R.id.current_txt);\n    percentage = findViewById(R.id.percentage_txt);\n    status = findViewById(R.id.status_txt);\n    connectButton = findViewById(R.id.connect_btn);\n\n    batteryStateData = new SubscribedData<>();\n    final Type batteryStateType = new TypeToken<SubscribedData<BatteryState>>() {\n    }.getType();\n\n\n    // ROSBRIDGE protocol allows access to underlying ROS messages and services as serialized JavaScript Object Notation (JSON) objects\n     WebSocket protocol communicates to a server for the connection from a user's web browser\n\n    //A connection to the rosbridge thru the IP address of the robot from the socket\n    rosbridge = new RosbridgeListener(\"ws://10.24.204.231:9090\");\n    rosbridge.setOnDataReceivedListener(new RosbridgeMessageListener() {\n\n        // a running thread that when the connection is made the data of the topic will serialize and deserialized java objects to (and from) JSON. @param msg\n\n            @Override\n            public void onDataReceived(final String msg) {\n                try {\n                    runOnUiThread(new Runnable() {\n                        @Override\n                        public void run() {\n                            batteryStateData = new Gson().fromJson(msg, batteryStateType);\n                            voltage.setText(String.format(\"%.4f%s\", batteryStateData.msg.voltage, \"v\"));\n                            current.setText(String.format(\"%.4f%s\", batteryStateData.msg.current * Math.pow(10, 6), \"A\"));\n                            percentage.setText(String.format(\"%.2f%s\", batteryStateData.msg.percentage, \"%\"));\n                            status.setText(String.format(\"%s\", PowerSupplyStatus.values()[batteryStateData.msg.powerSupplyStatus]));\n                        }\n                    });\n\n                    Log.d(\"B9T\", String.format(\"Received data: %s\", msg));\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        });\n\n    connectButton.setOnClickListener(new View.OnClickListener() {\n        @Override\n        public void onClick(View view) {\n\n            if (!subscribed) {\n                 rosbridge.Subscribe(\"/battery\", \"sensor_msgs/BatteryState\");\n                 subscribed = true;\n\n            connectButton.setText(\"Disconnect\");\n\n              } else {\n\n                rosbridge.UnSubscribe(\"/battery\");\n                subscribed = false;\n            connectButton.setText(\"Connect\");\n\n      }\n          }\n    });\n", "batteryStateData.msg.current "], "answer_code": ["batteryStateData = new Gson().fromJson(msg, batteryStateType);\nif (batteryStateData != null) {\n\n    if (batteryStateData.msg.voltage!=0)\n        voltage.setText(String.format(\"%.4f%s\", batteryStateData.msg.voltage, \"v\"));\n\n    if (batteryStateData.msg.current!=0)\n        current.setText(String.format(\"%.4f%s\", batteryStateData.msg.current * Math.pow(10, 6), \"A\"));\n\n    if (batteryStateData.msg.percentage!=0)\n        percentage.setText(String.format(\"%.2f%s\", batteryStateData.msg.percentage, \"%\"));\n\n    if (batteryStateData.msg.values !=null)\n        status.setText(String.format(\"%s\", PowerSupplyStatus.values()[batteryStateData.msg.powerSupplyStatus]));\n\n}\n", " @Override\n public void run() {\n     batteryStateData = new Gson().fromJson(msg, batteryStateType);\n\n     // check null before set text or calculate something\n     if(batteryStateData.msg.current != null){\n         current.setText(String.format(\"%.4f%s\", batteryStateData.msg.current * Math.pow(10, 6), \"A\"));\n     }\n     // you can check belows like above\n\n     voltage.setText(String.format(\"%.4f%s\", batteryStateData.msg.voltage, \"v\"));\n\n     percentage.setText(String.format(\"%.2f%s\", batteryStateData.msg.percentage, \"%\"));\n     status.setText(String.format(\"%s\", PowerSupplyStatus.values()[batteryStateData.msg.powerSupplyStatus]));\n}\n"], "url": "https://stackoverflow.com/questions/58230939/android-nullpointerexception-double-java-lang-double-doublevalue"},
{"title": "Displaying rgb8 pixel data in-browser", "time": "2020-01-08 16:36:21Z", "post_content": ["I have found similar questions to mine on SO, but have not yet come across an answer to this problem. I have a rgb8 encoded image that I am trying to display in-browser, either in an ", " or ", " element. I am unsure how to convert this pixel data into an image properly, and was looking for any insight.", "For context, the source of this rgb8 data is from a ROS topic with type ", ". When subscribing to this topic using ", ", I am given the following object:", "With the ", " string, I have tried displaying it on canvas, converting it to base64, etc. but have not been able to. I know about ", " in ROS to help send these images over a port, but that is not an option for me unfortunately - I need to work directly with the ", ".", "Is there a way I can go about displaying this rgb8 data in the browser? Based on the documentation on ", ", ", " should be represented as a ", " (if that helps).", "Thank you so much! "], "answer": ["First create a canvas of the correct size and obtain a ", "Then create an ", " to hold the pixels", "Then read the data from the image message. Making sure to use the correct order as defined in the flag ", "    ", "The ", " into the canvas;", "And add the canvas to your HTML", "And you are done.", "Note that I may have is_bigendian the wrong way around. If so just change the line ", " to ", "With more information regarding the data format i was able to extract the image.", "I used ", " to decode the Base64 string. This returns another string. I then iterated each character in the string, getting the character code to add to each pixel.", "It is unclear where the endianess is. My guess is that it is in the decoded string and thus the code swaps bytes for each char code as it makes no sense to have endianess on multiples of 3 bytes", "From the example data I got an image of some paving near a road."], "question_code": ["img", "canvas", "sensor_msgs/Image", "roslibjs", "{\n  data: \u201cMT4+CR\u2026\u201d, (of length 1228800)\n  encoding: \"rgb8\",\n  header: {\n    frame_id: \u201ccamera_color_optical_frame\u201d,\n    seq: 1455,\n    stamp: ...timestamp info\n  },\n  height: 480,\n  is_bigendian: 0,\n  step: 1920,\n  width: 640\n}\n", "data", "web_video_server", "data", "data", "uint8[]"], "answer_code": ["CanvasRenderingContext2D", "// Assuming that imgMes is the image message as linked in question\n\nconst can = document.createElement(\"canvas\");\ncan.width = imgMes.width;\ncan.height = imgMes.height; \nconst ctx = can.getcontext(\"2d\");\n", "const imgData = ctx.createImageData(0, 0, imgMes.width, imgMes.height);\nconst data = imgData.data;\nconst inData = imgMes.data;\n", "is_bigendian", "var i = 0, j, y = 0, x;\nwhile (y < imgMes.height) {\n    j = y * imgMes.step;\n    for (x = 0; x < imgMes.width; x ++) {\n        if (imgMes.is_bigendian) {\n            data[i]     = inData[j];     // red\n            data[i + 1] = inData[j + 1]; // green\n            data[i + 2] = inData[j + 2]; // blue\n        } else {\n            data[i + 2] = inData[j];     // blue\n            data[i + 1] = inData[j + 1]; // green\n            data[i]     = inData[j + 2]; // red\n        }\n        data[i + 3] = 255;  // alpha\n        i += 4;\n        j += 3;\n     }\n     y++;\n }\n", " ctx.putImageData(imgData, 0, 0);\n", " document.body.appendChild(can);\n", "if (imgMes.is_bigendian) {", "if (!imgMes.is_bigendian) {", "const can = document.createElement(\"canvas\");\ncan.width = imgMes.width;\ncan.height = imgMes.height;\nconst ctx = can.getContext(\"2d\");\n\nconst imgData = ctx.createImageData(imgMes.width, imgMes.height);\nconst data = imgData.data;\nconst inData = atob(imgMes.data);\n\nvar j = 0; i = 4; // j data in , i data out\nwhile( j < inData.length) {\n    const w1 = inData.charCodeAt(j++);  // read 3 16 bit words represent 1 pixel\n    const w2 = inData.charCodeAt(j++);\n    const w3 = inData.charCodeAt(j++);\n    if (!imgMes.is_bigendian) {\n        data[i++] = w1; // red\n        data[i++] = w2; // green\n        data[i++] = w3; // blue\n    } else {\n        data[i++] = (w1 >> 8) + ((w1 & 0xFF) << 8);\n        data[i++] = (w2 >> 8) + ((w2 & 0xFF) << 8);\n        data[i++] = (w3 >> 8) + ((w3 & 0xFF) << 8);\n    }\n    data[i++] = 255;  // alpha\n}\n\nctx.putImageData(imgData, 0, 0);\ndocument.body.appendChild(can);\n", "data", "is_bigendian", "imgMes.data", "inData", "imgMes.data", "const inData = imgMes.data.split(\",\").map(Number)"], "url": "https://stackoverflow.com/questions/59650216/displaying-rgb8-pixel-data-in-browser"}
]