[
{"url": "https://wiki.ros.org/power_msgs", "package": "power_msgs", "package_summary": ["ROS messages for power measurement and breaker control."], "package_details": [" "]},
{"url": "https://wiki.ros.org/laptop_battery_monitor", "package": "laptop_battery_monitor", "package_summary": ["Simple script to check battery status"]},
{"url": "https://wiki.ros.org/ps3joy", "package": "ps3joy", "package_summary": ["Playstation 3 SIXAXIS or DUAL SHOCK 3 joystick driver.\n    Driver for the Sony PlayStation 3 SIXAXIS or DUAL SHOCK 3\n    joysticks. In its current state, this driver is not compatible\n    with the use of other Bluetooth HID devices. The driver listens\n    for a connection on the HID ports, starts the joystick\n    streaming data, and passes the data to the Linux uinput device\n    so that it shows up as a normal joystick."], "package_details": ["\n", "\n", "\n", " is known to work with Ubuntu 12.10, Ubuntu 12.04, Ubuntu Jaunty 9.04, and Ubuntu Hardy 8.04. To make it work with Ubuntu Karmic 9.10, you will have to follow these ", ". ", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", " ", " ", "  ", " ", " ", "\n", "\n", "\n", "\n", " ", " ", " ", " also exposes the joystick's three-axis accelerometer and the single-axis gyroscope: ", "\n", "This driver exists because Linux's native support for the PS3 joystick is unreliable, and does not give access to the joystick's accelerometers and gyroscope. This driver solves both problems. However in its current form, ", ". In future releases, we plan to allow first non-HID and later any bluetooth device to coexist with this driver. If you have a need for such functionality, let it be known. ", "The ", " is a good starting point for how to use this package. ", "This is the same for ", " and ", ". ", "Or you could write a sudo script for sourcing ROS and starting ps3joy_node; I use ", " to automatically start the ", " after booting and a ROS-check. ", "There is ", ". ", "With these #defines you can access the PS3 buttons within the ", " without worrying about magic numbers: "], "package_tt": ["ps3joy.py", "sudo", "joy/set_feedback", "/diagnostics", "ps3joy.py", "ps3joy_node.py", "--inactivity-timeout", "--no-disable-bluetoothd", "ps3joy.py", "--redirect-output", "ps3joy.py", "--continuous-output", "ps3joy_node"], "package_code": ["sudo apt-get install ros-%ROSDISTRO%-joystick-drivers\n", "sudo apt-get install ros-indigo-joystick-drivers       (ROS Indigo for example)", "$ ./ps3joy.py --help\n", "usage: ps3joy.py [--inactivity-timeout=<n>] [--no-disable-bluetoothd] [--redirect-output]=<f>\n", "<n>: inactivity timeout in seconds (saves battery life).\n", "<f>: file name to redirect output to.\n", "Unless --no-disable-bluetoothd is specified, bluetoothd will be stopped.", ".../ps3joy$ sudo bash -c \"source /home/myself/.bashrc; ./scripts/ps3joy_node.py --inactivity-timeout=300\"", "rostopic pub  /joy/set_feedback sensor_msgs/JoyFeedbackArray '[ [0, 3, 1], [1, 1, 0.8] ]'", "// note on plain values:\n", "// buttons are either 0 or 1\n", "// button axes go from 0 to -1\n", "// stick axes go from 0 to +/-1\n", "\n", "#define PS3_BUTTON_SELECT            0\n", "#define PS3_BUTTON_STICK_LEFT        1\n", "#define PS3_BUTTON_STICK_RIGHT       2\n", "#define PS3_BUTTON_START             3\n", "#define PS3_BUTTON_CROSS_UP          4\n", "#define PS3_BUTTON_CROSS_RIGHT       5\n", "#define PS3_BUTTON_CROSS_DOWN        6\n", "#define PS3_BUTTON_CROSS_LEFT        7\n", "#define PS3_BUTTON_REAR_LEFT_2       8\n", "#define PS3_BUTTON_REAR_RIGHT_2      9\n", "#define PS3_BUTTON_REAR_LEFT_1       10\n", "#define PS3_BUTTON_REAR_RIGHT_1      11\n", "#define PS3_BUTTON_ACTION_TRIANGLE   12\n", "#define PS3_BUTTON_ACTION_CIRCLE     13\n", "#define PS3_BUTTON_ACTION_CROSS      14\n", "#define PS3_BUTTON_ACTION_SQUARE     15\n", "#define PS3_BUTTON_PAIRING           16\n", "\n", "#define PS3_AXIS_STICK_LEFT_LEFTWARDS    0\n", "#define PS3_AXIS_STICK_LEFT_UPWARDS      1\n", "#define PS3_AXIS_STICK_RIGHT_LEFTWARDS   2\n", "#define PS3_AXIS_STICK_RIGHT_UPWARDS     3\n", "#define PS3_AXIS_BUTTON_CROSS_UP         4\n", "#define PS3_AXIS_BUTTON_CROSS_RIGHT      5\n", "#define PS3_AXIS_BUTTON_CROSS_DOWN       6\n", "#define PS3_AXIS_BUTTON_CROSS_LEFT       7\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_2      8\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_2     9\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_1      10\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_1     11\n", "#define PS3_AXIS_BUTTON_ACTION_TRIANGLE  12\n", "#define PS3_AXIS_BUTTON_ACTION_CIRCLE    13\n", "#define PS3_AXIS_BUTTON_ACTION_CROSS     14\n", "#define PS3_AXIS_BUTTON_ACTION_SQUARE    15\n", "#define PS3_AXIS_ACCELEROMETER_LEFT      16\n", "#define PS3_AXIS_ACCELEROMETER_FORWARD   17\n", "#define PS3_AXIS_ACCELEROMETER_UP        18\n", "#define PS3_AXIS_GYRO_YAW                19"]},
{"url": "https://wiki.ros.org/turtlebot3_autorace_detect", "package": "turtlebot3_autorace_detect", "package_summary": ["AutoRace ROS packages for feature detection with TurtleBot3 Auto"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output_sub1/compressed", "detect/image_output_sub2/compressed", "detect/image_output", "detect/image_output_sub1", "detect/image_output_sub2", "detect/yellow_line_reliability", "detect/white_line_reliability", "detect/image_input/compressed", "detect/image_input", "detect/level_crossing_order", "control/level_crossing_finished", "detect/image_output/compressed", "detect/image_output_sub1/compressed", "detect/image_output", "detect/image_output_sub1", "detect/level_crossing_stamped", "control/level_crossing_start", "control/max_vel", "detect/parking_lot_order", "detect/scan", "control/parking_finished", "detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output", "detect/parking_lot_stamped", "control/parking_start", "control/max_vel", "detect/image_input/compressed", "detect/image_input", "detect/image_output/compressed", "detect/image_output", "detect/traffic_sign", "detect/image_input/compressed", "detect/image_input", "control/traffic_light_finished", "detect/image_output/compressed", "detect/image_output", "detect/image_output_sub1/compressed", "detect/image_output_sub2/compressed", "detect/image_output_sub3/compressed", "detect/image_output_sub1", "detect/image_output_sub2", "detect/image_output_sub3", "detect/traffic_light_stamped", "control/traffic_light_start", "control/max_vel", "detect/tunnel_order", "move_base/result", "odom", "detect/tunnel_stamped", "move_base_simple/goal", "control/cmd_vel", "control/max_vel"], "package_code": ["#------------------ parameter for HSL detection of withe lane ------------------#\n", "gen.add(\"hue_white_l\",         int_t,   0,   \"hue_white_l\",         0,   0, 179)\n", "gen.add(\"hue_white_h\",         int_t,   0,   \"hue_white_h\",         179, 0, 179)\n", "gen.add(\"saturation_white_l\",  int_t,   0,   \"saturation_white_l\",  0,   0, 255)\n", "gen.add(\"saturation_white_h\",  int_t,   0,   \"saturation_white_h\",  255, 0, 255)\n", "gen.add(\"lightness_white_l\",   int_t,   0,   \"lightness_white_l\",   0,   0, 255)\n", "gen.add(\"lightness_white_h\",   int_t,   0,   \"lightness_white_h\",   255, 0, 255)\n", "\n", " ------------------ parameter for HSL detection of yellow lane -----------------#\n", "gen.add(\"hue_yellow_l\",        int_t,   0,   \"hue_yellow_l\",        0,   0, 179)\n", "gen.add(\"hue_yellow_h\",        int_t,   0,   \"hue_yellow_h\",        179, 0, 179)\n", "gen.add(\"saturation_yellow_l\", int_t,   0,   \"saturation_yellow_l\", 0,   0, 255)\n", "gen.add(\"saturation_yellow_h\", int_t,   0,   \"saturation_yellow_h\", 255, 0, 255)\n", "gen.add(\"lightness_yellow_l\",  int_t,   0,   \"lightness_yellow_l\",  0,   0, 255)\n", "gen.add(\"lightness_yellow_h\",  int_t,   0,   \"lightness_yellow_h\",  255, 0, 255)", "#------------------ parameter for HSL detection of red color ------------------#\n", "gen.add(\"hue_red_l\",           int_t,   0,   \"hue_red_l\",           0,   0, 179)\n", "gen.add(\"hue_red_h\",           int_t,   0,   \"hue_red_h\",           179, 0, 179)\n", "gen.add(\"saturation_red_l\",    int_t,   0,   \"saturation_red_l\",    0,   0, 255)\n", "gen.add(\"saturation_red_h\",    int_t,   0,   \"saturation_red_h\",    255, 0, 255)\n", "gen.add(\"lightness_red_l\",     int_t,   0,   \"lightness_red_l\",     0,   0, 255)\n", "gen.add(\"lightness_red_h\",     int_t,   0,   \"lightness_red_h\",     255, 0, 255)", "#------------- parameter for HSL detection of traffic red light ---------------#\n", "gen.add(\"hue_red_l\",           int_t,   0,   \"hue_red_l\",           0,   0, 179)\n", "gen.add(\"hue_red_h\",           int_t,   0,   \"hue_red_h\",           179, 0, 179)\n", "gen.add(\"saturation_red_l\",    int_t,   0,   \"saturation_red_l\",    0,   0, 255)\n", "gen.add(\"saturation_red_h\",    int_t,   0,   \"saturation_red_h\",    255, 0, 255)\n", "gen.add(\"lightness_red_l\",     int_t,   0,   \"lightness_red_l\",     0,   0, 255)\n", "gen.add(\"lightness_red_h\",     int_t,   0,   \"lightness_red_h\",     255, 0, 255)\n", "\n", "#------------ parameter for HSL detection of traffic yellow light -------------#\n", "gen.add(\"hue_yellow_l\",        int_t,   0,   \"hue_yellow_l\",        0,   0, 179)\n", "gen.add(\"hue_yellow_h\",        int_t,   0,   \"hue_yellow_h\",        179, 0, 179)\n", "gen.add(\"saturation_yellow_l\", int_t,   0,   \"saturation_yellow_l\", 0,   0, 255)\n", "gen.add(\"saturation_yellow_h\", int_t,   0,   \"saturation_yellow_h\", 255, 0, 255)\n", "gen.add(\"lightness_yellow_l\",  int_t,   0,   \"lightness_yellow_l\",  0,   0, 255)\n", "gen.add(\"lightness_yellow_h\",  int_t,   0,   \"lightness_yellow_h\",  255, 0, 255)\n", "\n", "#------------ parameter for HSL detection of traffic green light --------------#\n", "gen.add(\"hue_green_l\",         int_t,   0,   \"hue_green_l\",         0,   0, 179)\n", "gen.add(\"hue_green_h\",         int_t,   0,   \"hue_green_h\",         179, 0, 179)\n", "gen.add(\"saturation_green_l\",  int_t,   0,   \"saturation_green_l\",  0,   0, 255)\n", "gen.add(\"saturation_green_h\",  int_t,   0,   \"saturation_green_h\",  255, 0, 255)\n", "gen.add(\"lightness_green_l\",   int_t,   0,   \"lightness_green_l\",   0,   0, 255)\n", "gen.add(\"lightness_green_h\",   int_t,   0,   \"lightness_green_h\",   255, 0, 255)"]},
{"url": "https://wiki.ros.org/webui", "package": "webui", "package_summary": ["A web interface to install and launch applications for the PR2."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Ergo, the easiest way to install the webui from the binary is to ", " the webui directory.  ", "... where <robot name> would usually be of the form prX and <robot type> would usually be pr2. ", "Add the following line to /etc/apache2/sites-available/default just above <", "> near the end of the file: "], "package_tt": ["ros-RELEASE-web-interface", "python-clearsilver", "apache2-mpm-prefork", "libapache2-mod-python", "ruby1.8-dev", "chown", "/etc/ros/env", "ROBOT", "ROBOT_NAME", "ROS_ROOT", "ROS_MASTER_URI", "ROS_PACKAGE_PATH"], "package_code": ["roscd webui\n", "make -f setup.make\n", "sudo ./install.py <robot name> <robot type> www-data", "sudo ./install_root", "Include /etc/ros/ros_webui_apache.cfg", "sudo cp varwww/index.html /var/www/index.html", "sudo apache2ctl restart", "    gPump.publish(\"/hoge\",\"std_msgs/String\",[\"hoga\"]);", "    gPump.service_call2(\"/service/knowrob\",\n", "                       {'str': command},\n", "                       function(res){\n", "                         document.getElementById('displaybox') , res.str);\n", "                       }\n", "                       );", "<div class=\"nav_element\" objtype=PercentTextWidget topic=\"/power_state\" num=\"a\" div=\"b\"/></div>", "var PercentTextWidget = Class.create({\n", "  initialize: function(domobj) {\n", "    this.pump = null;\n", "    this.domobj = domobj;\n", "    this.topics = [domobj.getAttribute(\"topic\")];\n", "    this.numerator = domobj.getAttribute(\"num\");\n", "    this.denominator = domobj.getAttribute(\"den\");\n", "  }, \n", "\n", "  init: function() {\n", "  }, \n", "\n", "  receive: function(topic, msg) {\n", "    if(msg[this.numerator] != null) {\n", "      var percent = parseFloat(msg[this.numerator]) / parseFloat(msg[this.denominator]);\n", "      this.domobj.innerHTML = (100. * percent).toFixed(2) + \"%\";\n", "    }\n", "  } \n", "});\n", "\n", "gRosClasses[\"PercentTextWidget\"] = function(dom){\n", "  return new PercentTextWidget(dom);\n", "}"]},
{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]},
{"url": "https://wiki.ros.org/rl_env", "package": "rl_env", "package_summary": ["rl_env is is a package containing reinforcement learning (RL) environments."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package contains a variety of environments that can be used for reinforcement learning experiments. These can be used with new RL agents written to use the ", " framework, or with existing agents from the ", " package. The package contains the following environments: ", "The environment can interact with an RL agent in two ways. It can use the ROS messages defined in ", ", or another method can call the agent and environment methods directly, as done in the ", " package. ", "The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (", "), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: ", "Experiments can also be run by calling the agent and environment methods directly (as done in the ", " package). Methods that all environments must implement are defined in the Environment interface in the ", " package (", ").  Seeds can be retrieved from the environment with the getSeedings() method. An action is applied to the environment with a call to apply(action). The current state can be retrieved by calling sensation() and terminal() will indicate if the agent is in a terminal state or not. "], "package_code": ["rosrun rl_env env --env type [options]", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_env env --env carrandom --lag --stochastic --prints"]},
{"url": "https://wiki.ros.org/rl_experiment", "package": "rl_experiment", "package_summary": ["rl_experiment is a package to run RL experiments using the rl_agent and rl_env packages."], "package_details": ["\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package provides a way of running reinforcement learning experiments with the agents from the ", " package and environments from the ", " package without using the ", " interface. Instead, the code instantiates agent and environment objects and calls their methods directly. It can be set to run for a particular number of episodes and trials, and prints out the sum of rewards for each episode to cerr. ", "There are a number of options available to set parameters of both the agent and environment used.  More details on the agent options are available in the ", " documentation, and more details on the env options are available in the ", " documentation. ", "In addition to these options, there a few variables that can be changed in the code, in the ", ". Near the top of the file are two variables: MAXSTEPS and NUMTRIALS. MAXSTEPS determines the maximum number of steps for an episode. A new episode will be started after this many steps even if the agent has not reached a terminal state. ", "As an example, here is how you would run Q-Learning (", ") on the stochastic Taxi task (", "): ", "Or to run real-time TEXPLORE (", ", ", ") at 10 Hz on the deterministic Fuel World task (", ") with 8 discrete trees: ", "While you should find that the qlearner, sarsa, dyna, and rmax agents work fine on the easier tasks (tworooms, taxi, etc), they will not converge within the default 1000 episodes on more complex tasks like Fuel World. As an example, here is how to run Q-Learning (", ") on the Fuel World task (", ") using the --nepisodes flag to run it for 1,000,000 episodes, which should be enough time for it to converge. ", "Another problem you may run into is when running these methods on the continuous domains (mcar, cartpole, car2to7, car7to2, and carrrandom). For these domains, the tabular RL methods (Q-Learning, SARSA, Dyna, R-Max) will need the state to be discretized. The following command will run Q-Learning (", ") on the Mountain Car task (", ") while discretizing each of the state features into 10 discrete values using the --nstates option. "], "package_code": ["rosrun rl_experiment experiment --agent type --env type [options]", "qlearner sarsa modelbased rmax texplore dyna savedpolicy", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_experiment experiment --agent qlearner --env taxi --stochastic", "rosrun rl_experiment experiment --agent texplore --nmodels 8 --planner parallel-uct --actrate 10 --env fuelworld --deterministic", "rosrun rl_experiment experiment --agent qlearner --env fuelworld --nepisodes 1000000", "rosrun rl_experiment experiment --agent qlearner --env mcar --nstates 10"]},
{"url": "https://wiki.ros.org/rospatlite", "package": "rospatlite", "package_summary": ["rospatlite"], "package_details": [" is a ROS driver for patlite Signal Tower NHx series. ", "\n", " ", "\n", "\n", "\n"], "package_tt": ["rospatlite", "roslaunch\u00a0rospatlite\u00a0patlite.launch\u00a0IP:=<patlite\u00a0ip>", "patlite\u00a0ip", "~set/red", "~set/yellow", "~set/green", "~set/blue", "~set/white", "~set/buzzer", "~host", "string", "~port", "int", "~timeout", "float"], "package_code": ["$ roslaunch rospatlite patlite.launch IP:=10.68.0.10", "$ rostopic pub /patlite/set/buzzer std_msgs/Int8 1 # <- buzzer ON\n", "$ rostopic pub /patlite/set/buzzer std_msgs/Int8 0 # <- buzzer OFF\n", "$ rostopic pub /patlite/set/red std_msgs/Int8 1 # <- red light ON\n", "$ rostopic pub /patlite/set/yellow std_msgs/Int8 2 # <- yellow light blink"]},
{"url": "https://wiki.ros.org/mavros", "package": "mavros", "package_summary": ["MAVROS -- MAVLink extendable communication node for ROS\n    with proxy for Ground Control Station."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " only. ", "\n", "\n", "\n", "\n", "\n", "\n", "Main node can be extended by plugins (see ", "). See also ", " package. ", "If you unsure what firmware your FCU runs start apm.launch and see ", ". ", "Starting from 0.11 mavros knows string representation for autopilot mavlink enum. ", "For older you shall manually find autopilot type value in mavlink documentation.  ", "All utilities provides ", " and ", " information. ", "Supported custom modes listed at ", ". ", "Standard set of communication plugins loaded by ", ". ", "Note: this list for ", " version. ", "Older versions: ", ", ", ", ", ", ", ", ", ", ", ", ", ". "], "package_tt": ["mavlink/to", "mavlink/from", "diagnostics", "~system_id", "int", "~component_id", "int", "~target_system_id", "int", "~target_component_id", "int", "~startup_px4_usb_quirk", "bool", "~plugin_blacklist", "string[]", "~plugin_whitelist", "string[]", "~fcu_url", "string", "~fcu_protocol", "string", "~gcs_url", "string", "ros_udp", "mavlink/from", "mavlink/to", "~gcs_url", "string", "mavros/state", "<trigger_event>", "~<event_name>/service", "string", "~<event_handler>/event", "string[]", "~<event_handler>/action", "string[]", "~<event_handler>/shell", "string", "~<event_handler>/logfile", "string", "/path/to/serial/device[:baudrate]", "serial:///path/to/serial/device[:baudrate][/?ids=sysid,compid]", "serial-hwfc:///path/to/serial/device[:baudrate][?ids=sysid,compid]", "udp://[bind_host][:port]@[remote_host][:port][/?ids=sysid,compid]", "udp-b://[bind_host][:port]@[:port][/?ids=sysid,compid]", "tcp://[server_host][:port][/?ids=sysid,compid]", "tcp-l://[bind_host][:port][/?ids=sysid,compid]", "~system_id", "~component_id", "baudrate", "bind_host", "remote_host", "server_host", "port", "<util>\u00a0--help", "<util>\u00a0<command>\u00a0--help", "~radio_status", "~actuator_control", "~hil_controls/hil_controls", "~frame_id", "string", "~cmd/command", "~cmd/command_int", "~cmd/arming", "~cmd/set_home", "~cmd/takeoff", "~cmd/land", "~cmd/trigger_control", "~cmd/use_comp_id_system_control", "bool", "SYSTEM_CONTROL", "~ftp/open", "~ftp/close", "~ftp/read", "~ftp/write", "~ftp/list", "~ftp/truncate", "~ftp/remove", "~ftp/rename", "~ftp/mkdir", "~ftp/rmdir", "~ftp/checksum", "~ftp/reset", "~global_position/global", "~global_position/local", "~global_position/gp_vel", "~global_position/rel_alt", "~global_position/compass_hdg", "~global_position/raw/fix", "~global_position/raw/gps_vel", "~global_position/frame_id", "string", "~global_position/tf/send", "bool", "~global_position/tf/frame_id", "string", "~global_position/tf/child_frame_id", "string", "~imu/data", "~imu/data_raw", "~imu/mag", "~imu/temperature", "~imu/atm_pressure", "~imu/frame_id", "string", "~imu/linear_acceleration_stdev", "double", "~imu/angular_velocity_stdev", "double", "~imu/orientation_stdev", "double", "~imu/magnetic_stdev", "double", "~local_position/pose", "~local_position/velocity", "~local_position/frame_id", "string", "~local_position/tf/send", "bool", "~local_position/tf/frame_id", "string", "~local_position/tf/child_frame_id", "string", "~manual_control/send", "~manual_control/control", "~param/", "~param/pull", "~param/push", "~param/get", "~param/set", "~rc/override", "SYSID_MYGCS", "~rc/in", "~rc/out", "~safety_area/set", "~safety_area/p1/x", "double", "~safety_area/p1/y", "double", "~safety_area/p1/z", "double", "~safety_area/p2/x", "double", "~safety_area/p2/y", "double", "~safety_area/p2/z", "double", "~setpoint_accel/accel", "~setpoint_accel/send_force", "bool", "~setpoint_attitude/cmd_vel", "~setpoint_attitude/attitude", "~setpoint_attitude/thrust", "~setpoint_attitude/reverse_throttle", "bool", "~setpoint_attitude/use_quaternion", "bool", "~setpoint_attitude/tf/listen", "bool", "~setpoint_attutude/tf/frame_id", "string", "~setpoint_attitude/tf/child_frame_id", "string", "~setpoint_attitude/tf/rate_limit", "double", "~setpoint_position/global", "~setpoint_position/local", "~setpoint_position/tf/listen", "bool", "~setpoint_position/tf/frame_id", "string", "~setpoint_position/tf/child_frame_id", "string", "~setpoint_position/tf/rate_limit", "double", "~setpoint_raw/local", "~setpoint_raw/global", "~setpoint_raw/attitude", "~setpoint_raw/target_local", "~setpoint_raw/target_global", "~setpoint_raw/target_attitude", "~setpoint_velocity/cmd_vel_unstamped", "~state", "~battery", "~battery", "~extended_state", "~set_stream_rate", "~set_mode", "~conn/timeout", "double", "~conn/heartbeat_rate", "double", "~sys/min_voltage", "double", "~sys/disable_diag", "bool", "~time_reference", "~conn/system_time_rate", "double", "SYSTEM_TIME", "~conn/timesync_rate", "double", "~time/time_ref_source", "string", "~time/timesync_avg_alpha", "double", "~vfr_hud", "~wind_estimation", "~mission/reached", "~mission/waypoints", "~mission/pull", "~mission/push", "~mission/clear", "~mission/set_current", "~mission/pull_after_gcs", "bool", "tf/"], "package_code": ["roslaunch mavros px4.launch", "roslaunch mavros apm.launch", "usage: mavcmd [-h] [-n MAVROS_NS] [-v] [--wait]\n", "              {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "              ...\n", "\n", "Commad line tool for sending commands to MAVLink device.\n", "\n", "positional arguments:\n", "  {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "    long                Send any command (COMMAND_LONG)\n", "    int                 Send any command (COMMAND_INT)\n", "    sethome             Request change home position\n", "    takeoff             Request takeoff\n", "    land                Request land\n", "    takeoffcur          Request takeoff from current GPS coordinates\n", "    landcur             Request land on current GPS coordinates\n", "    trigger_control     Control onboard camera trigerring system (PX4)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavftp [-h] [-n MAVROS_NS] [-v]\n", "              {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "              ...\n", "\n", "File manipulation tool for MAVLink-FTP.\n", "\n", "positional arguments:\n", "  {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "    cd                  change directory\n", "    list                list files and dirs\n", "    cat                 cat file\n", "    remove              remove file\n", "    mkdir               create direcotory\n", "    rmdir               remove directory\n", "    download            download file\n", "    upload              upload file\n", "    verify              verify files\n", "    reset               reset\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavparam [-h] [-n MAVROS_NS] [-v] {load,dump,get,set} ...\n", "\n", "Commad line tool for getting, setting, parameters from MAVLink device.\n", "\n", "positional arguments:\n", "  {load,dump,get,set}\n", "    load                load parameters from file\n", "    dump                dump parameters to file\n", "    get                 get parameter\n", "    set                 set parameter\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsafety [-h] [-n MAVROS_NS] [-v] {arm,disarm,safetyarea} ...\n", "\n", "Commad line tool for manipulating safty on MAVLink device.\n", "\n", "positional arguments:\n", "  {arm,disarm,safetyarea}\n", "    arm                 Arm motors\n", "    disarm              Disarm motors\n", "    safetyarea          Send safety area\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsetp [-h] [-n MAVROS_NS] [-V] {local} ...\n", "\n", "Commad line tool for control the device by setpoints.\n", "\n", "positional arguments:\n", "  {local}\n", "    local               Send local setpoint\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -V, --verbose         verbose output", "usage: mavsys [-h] [-n MAVROS_NS] [-v] [--wait] {mode,rate} ...\n", "\n", "Change mode and rate on MAVLink device.\n", "\n", "positional arguments:\n", "  {mode,rate}\n", "    mode                Set mode\n", "    rate                Set stream rate\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavwp [-h] [-n MAVROS_NS] [-v]\n", "             {show,load,pull,dump,clear,setcur,goto} ...\n", "\n", "Commad line tool for manipulating mission on MAVLink device.\n", "\n", "positional arguments:\n", "  {show,load,pull,dump,clear,setcur,goto}\n", "    show                Show waypoints\n", "    load                load waypoints from file\n", "    pull                pull waypoints from FCU\n", "    dump                dump waypoints to file\n", "    clear               clear waypoints on device\n", "    setcur              set current waypoints on device\n", "    goto                send goto waypoint (APM only)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output"]},
{"url": "https://wiki.ros.org/rosflight", "package": "rosflight", "package_summary": ["Package for interfacing to the ROSflight autopilot firmware over MAVLink"], "package_details": ["\n", "\n", "\n", " ", "\n", " ", "ROSflight provides a simple, low-latency interface between a flight controller running the ROSflight firmware and ROS. ROSflight can stream both sensor data and motor commands at high speed. ROSflight is written to work with a variety of airframes, including multirotor and fixed-wing aircraft. The ROSflight package provided the interface for autopilots, but does not include any control code. For examples of autopilots using ROSflight, see ", " or ", ". For documentation on the firmware, see ", ". "], "package_tt": ["command", "mode", "ignore", "aux_command", "type_array", "values", "external_attitude", "external_attitude", "attitude", "airspeed", "attitude", "attitude/euler", "baro", "battery", "gnss", "gnss_raw", "imu/data", "imu/temperature", "magnetometer", "navsat_compat/fix", "navsat_compat/time_reference", "time", "navsat_compat/vel", "linear", "output_raw", "rc_raw", "rosflight_errors", "sonar", "status", "unsaved_params", "version", "named_value/int/<name>", "named_value/float/<name>", "param_get", "param_set", "param_write", "param_save_to_file", "param_load_from_file", "calibrate_imu", "calibrate_rc_trim", "calibrate_baro", "calibrate_airspeed", "reboot", "reboot_to_bootloader", "~port", "string", "~baud_rate", "int", "~frame_id", "string", "~udp", "bool", "~bind_host", "string", "~bind_port", "int", "~remote_host", "string", "~remote_port", "int"], "package_code": ["$ rosrun rosflight rosflight_io _port:=/dev/ttyUSB0"]},
{"url": "https://wiki.ros.org/turtlebot3_bringup", "package": "turtlebot3_bringup", "package_summary": ["roslaunch scripts for starting the TurtleBot3"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "motor_power", "reset", "sound", "battery_state", "cmd_vel_rc100", "diagnostics", "imu", "joint_states", "magnetic_field", "odom", "sensor_state", "tf", "version_info", "~baud", "int", "~port", "string", "imu", "scan", "sensor_state", "version_info", "diagnostics", "rpms", "scan", "~frame_id", "string", "~port", "string"]},
{"url": "https://wiki.ros.org/linksys_access_point", "package": "linksys_access_point", "package_summary": ["\n    A ROS node that controls a Linksys access point with\n    a Linksys WRT610n-compatible web interface.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package implements the ", " dynamic_reconfigure interface for controlling an access point for Linksys access points.  "], "package_tt": ["txpower_auto", "False", "Manual", "Wireless/Basic\u00a0Wireless\u00a0Settings", "Wi-Fi\u00a0Protected\u00a0Setup", "update_configuration()", "wmm", "a", "b", "g", "n", "a", "a-only", "a", "n", "mixed", "b", "b-only", "b", "n", "g", "g-only", "g", "n", "mixed", "linksys_apcontrol_node.py", "~interface", "string", "wl0", "wl0", "wl1", "~ip", "string", "192.168.1.1", "~user", "string", "~password", "string", "admin"]},
{"url": "https://wiki.ros.org/xbot_node", "package": "xbot_node", "package_summary": ["ROS nodelet for Xbot: ROS wrapper for the Xbot driver."], "package_details": ["\n", "\n", "xbot_node\u529f\u80fd\u5305\u4e3a", "\u63d0\u4f9bROS API\u3002 "], "package_tt": ["/commands/motor_disable", "/commands/velocity", "/commands/yaw_platform", "/commands/pitch_platform", "/commands/sound_enable", "/commands/led", "/commands/lift", "/commands/reset_odometry", "/joint_states", "/sensors/core", "/sensors/extra", "/sensors/yaw_platform_degree", "/sensors/pitch_platform_degree", "/sensors/motor_disabled", "/sensors/sound_enabled", "/sensors/battery", "/sensors/echo", "/sensors/infrared", "/sensors/imu_data", "/sensors/raw_imu_data", "/xbot/state", "/commands/velocity", "/xbot/chat", "~base_path", "string", "\"$(find\u00a0xbot_talker)\""]},
{"url": "https://wiki.ros.org/realsense_camera", "package": "realsense_camera", "package_summary": ["RealSense Camera package allowing access to Intel 3D cameras and advanced modules"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This package provides ROS node(s) for using the Intel\u00ae ", "\u2122 R200, F200 and SR300 cameras. ", "This package requires the ", " package as the underlying camera drivers for all Intel\u00ae ", "\u2122 cameras. ", " installing the realsense-camera package, follow the ", ". ", "This will also install the required ros-<*distro*>-librealsense library on your system. ", "If a user needs to debug this package or contribute changes/bug fixes to the package, only then should the package need to be built from source. Please closely follow the directions provided on the ", " page. ", "To ensure you camera has the most current, supported firmware, please review the ", ". If the camera requires a firmware upgrade, please refer to the ", " page. ", ": Currently there is no native Linux tool for FW updates; all updates require a system with Microsoft Windows. ", "Please ", " concerning this package to the realsense_camera ", " Issues. ", "See the ", " for a complete list. "], "package_tt": ["color/camera_info", "color/image_raw", "depth/camera_info", "depth/image_raw", "uint16", "depth/points", "ir/camera_info", "ir/image_raw", "uint16", "ir/camera_info", "ir/image_raw", "uint16", "fisheye/camera_info", "ir/image_raw", "uint16", "imu/data_raw", "get_settings", "set_power", "true", "false", "false", "force_power", "true", "false", "false", "is_powered", "get_imu_info", "mode", "string", "preset", "serial_no", "string", "blank", "usb_port_id", "string", "blank", "camera_type", "string", "blank", "enable_ir", "bool", "enable_depth", "bool", "depth_width", "int", "depth_height", "int", "depth_fps", "int", "enable_color", "bool", "color_width", "int", "color_height", "int", "color_fps", "int", "enable_fisheye", "bool", "fisheye_width", "int", "fisheye_height", "int", "fisheye_fps", "int", "enable_imu", "bool", "enable_pointcloud", "bool", "enable_tf", "bool", "enable_tf_dynamic\u00a0('''Added\u00a0in\u00a01.7.0''')", "bool", "base_frame_id", "string", "depth_frame_id", "string", "depth_optical_frame_id", "string", "color_frame_id", "string", "color_optical_frame_id", "string", "ir_frame_id", "string", "ir_optical_frame_id", "string", "ir2_frame_id", "string", "ir2_optical_frame_id", "string", "fisheye_frame_id", "string", "fisheye_optical_frame_id", "string", "imu_frame_id", "string", "imu_optical_frame_id", "string", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_exposure", "int", "~r200_lr_gain", "int", "~r200_lr_exposure", "int", "~color_enable_auto_white_balance", "int", "~color_enable_auto_exposure", "int", "~r200_lr_auto_exposure_enabled", "int", "~r200_auto_exposure_top_edge", "int", "~r200_auto_exposure_bottom_edge", "int", "~r200_auto_exposure_left_edge", "int", "~r200_auto_exposure_right_edge", "int", "~r200_emitter_enabled", "int", "~r200_dc_preset", "int", "~r200_dc_estimate_median_decrement", "int", "~r200_dc_estimate_median_increment", "int", "~r200_dc_median_threshold", "int", "~r200_dc_score_minimum_threshold", "int", "~r200_dc_score_maximum_threshold", "int", "~r200_dc_texture_count_threshold", "int", "~r200_dc_texture_difference_threshold", "int", "~r200_dc_second_peak_threshold", "int", "~r200_dc_neighbor_threshold", "int", "~r200_dc_lr_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_exposure", "int", "~color_enable_auto_white_balance", "int", "~color_enable_auto_exposure", "int", "~f200_laser_power", "int", "~f200_accuracy", "int", "~f200_motion_range", "int", "~f200_filter_option", "int", "~f200_confidence_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~color_enable_auto_white_balance", "int", "~color_exposure", "int", "~color_enable_auto_exposure", "int", "~f200_laser_power", "int", "~f200_accuracy", "int", "~f200_motion_range", "int", "~f200_filter_option", "int", "~f200_confidence_threshold", "int", "~sr300_auto_range_enable_motion_versus_range", "int", "~sr300_auto_range_enable_laser", "int", "~sr300_auto_range_min_motion_versus_range", "int", "~sr300_auto_range_max_motion_versus_range", "int", "~sr300_auto_range_start_motion_versus_range", "int", "~sr300_auto_range_min_laser", "int", "~sr300_auto_range_max_laser", "int", "~sr300_auto_range_start_laser", "int", "~sr300_auto_range_upper_threshold", "int", "~sr300_auto_range_lower_threshold", "int", "~enable_depth", "bool", "~color_backlight_compensation", "int", "~color_brightness", "int", "~color_contrast", "int", "~color_exposure", "int", "~color_gain", "int", "~color_gamma", "int", "~color_hue", "int", "~color_saturation", "int", "~color_sharpness", "int", "~color_white_balance", "int", "~r200_lr_gain", "int", "~r200_lr_exposure", "int", "~color_enable_auto_exposure", "int", "~color_enable_auto_white_balance", "int", "~r200_lr_auto_exposure_enabled", "int", "~r200_emitter_enabled", "int", "~r200_depth_clamp_min", "int", "~r200_depth_clamp_max", "int", "~fisheye_exposure", "int", "~fisheye_gain", "int", "~fisheye_enable_auto_exposure", "int", "~fisheye_auto_exposure_mode", "int", "~fisheye_auto_exposure_antiflicker_rate", "int", "~fisheye_auto_exposure_pixel_sample_rate", "int", "~fisheye_auto_exposure_skip_frames", "int", "~frames_queue_size", "int", "~hardware_logger_enabled", "int", "~r200_dc_preset", "int", "~r200_dc_estimate_median_decrement", "int", "~r200_dc_estimate_median_increment", "int", "~r200_dc_median_threshold", "int", "~r200_dc_score_minimum_threshold", "int", "~r200_dc_score_maximum_threshold", "int", "~r200_dc_texture_count_threshold", "int", "~r200_dc_texture_difference_threshold", "int", "~r200_dc_second_peak_threshold", "int", "~r200_dc_neighbor_threshold", "int", "~r200_dc_lr_threshold", "int", "camera_link", "camera_rgb_frame", "camera_rgb_frame", "camera_rgb_optical_frame", "camera_link", "camera_depth_frame", "camera_depth_frame", "camera_depth_optical_frame", "camera_link", "camera_ir_frame", "camera_ir_frame", "camera_ir_optical_frame", "camera_link", "camera_ir2_frame", "camera_ir2_frame", "camera_ir2_optical_frame", "camera_link", "camera_fisheye_frame", "camera_fisheye_frame", "camera_fisheye_optical_frame", "camera_link", "camera_imu_frame", "camera_imu_frame", "camera_imu_optical_frame"], "package_code": ["sudo apt-get install 'ros-*-realsense-camera'", "$ roslaunch realsense_camera r200_nodelet_default.launch", "$ roslaunch realsense_camera f200_nodelet_default.launch", "$ roslaunch realsense_camera sr300_nodelet_default.launch", "$ roslaunch realsense_camera zr300_nodelet_default.launch", "/camera/depth_registered/hw_registered/image_rect_raw\n", "/camera/depth_registered/hw_registered/image_rect\n", "/camera/depth_registered/image\n", "/camera/depth/disparity\n", "/camera/depth_registered/disparity"]},
{"url": "https://wiki.ros.org/pr2_dashboard_aggregator", "package": "pr2_dashboard_aggregator", "package_summary": ["A simple script that aggregates all of the topics that a \"pr2_dashboard\" app might be interested in."], "package_details": ["\n", "\n"], "package_tt": ["pr2_dashboard_aggregator", "pr2.launch", "pr2_dashboard_aggregator", "power_board/state", "power_state", "ddwrt/accesspoint", "pr2_etherCAT/motors_halted", "dashboard_agg"]},
{"url": "https://wiki.ros.org/ueye_cam", "package": "ueye_cam", "package_summary": ["A ROS nodelet and node that wraps the driver API for UEye cameras\n    by IDS Imaging Development Systems GMBH."], "package_details": [" git clone ", " --branch fuerte ", "\n", "\n", " ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "This package provides a ROS interface for the ", ". This ROS interface exposes many of the features of the underlying ", ", and is compatible with ", ", ", ", and ", ". ", "This package has been tested with the ", ", on ", ", operating with ", " cameras. ", "(side-note: it is technically possible to ", "; see video caption for outline of instructions) ", "This implementation makes use of certain C++11 features (such as std::thread, std::to_string, etc), although the CMakeLists.txt is configured for GCC >= 4.6 (and hence uses the ", " flag). ", "The IDS camera API allows users to have fine-grain control over the camera on-board processor's clock rate, which determines the range of values for frame rates, exposures, and other camera settings. This can be adjusted at runtime alongside other parameters, via ", ". It is however not recommended to operate the camera at a fast clock rate for extended periods of time, as the onboard processor may get excessively hot. Thus, ideally one should adjust the clock rate to match a target frame rate and exposure setting. ", "You may choose to use the underlying IDS camera API to perform bayer decoding and publish images as 'rgb8' or 'mono8', or alternatively choose to publish images as 'bayer_rggb8' and rely on the standard ROS ", " package for decoding. Currently, this ROS interface does not expose fine-grain control over the bayer decoding engine from the underlying IDS camera API. ", "A common mistake is to interpret the 'image_width' and 'image_height' ROS parameters as the width and height of the resulting ROS image. Unfortunately, these names were chosen to be consistent with official camera interfaces provided by IDS, and they refer to the width and height of the camera sensor's Area of Interest (AOI). Therefore, values for 'image_width' and 'image_height' that are smaller than your camera's maximum values will result in ", " (a.k.a. reduced AOI). ", "1. Install the IDS Software Suite 4.xx for Linux from ", " ", "2. create catkin workspace ", ". ", "4. Run ", " under ", ". ", "Returns raw Bayer-encoded (RGGB encoding) images from the UEye camera, and uses ", " to convert to RGB images. Also publishes on /camera/image_raw. ", "Same as rgb8.launch, but spawns the nodelet (manager) in gdb on a separate screen. ", " ", "The ueye_cam wrapper fully supports ", ". You can refer to ", " for info on calibrating your own UEye cameras. ", "All calibration files are stored by default under: ", " ", "We have connected multiple cameras in hardware to an Arduino-compatible device (a ", "), which allows any camera to act as master and any number of other cameras to act as slaves, and achieve synchronization seamlessly with unified hardware add-on required. Please see ", " for further documentation and instructions. A video demonstration of UEye camera synchronization can be seen ", ". ", "Historically speaking, ueye_cam was based on an earlier ROS package for interfacing with ", " cameras. Given that the initial work on ueye_cam was done prior to the release of other similar ROS wrappers like ", " and ", ", the original intention was to keep this code internal so as to avoid contention. Nevertheless, this code has since been released as result of a number of recent requests, with the sole hope that it may benefit the ROS community. Please check out the other packages to see which one will best suite your needs. "], "package_tt": ["<camera_name>/<camera_topic>", "<camera_name>/camera_info", "<~camera_name>/<~camera_topic>", "<~camera_name>/set_camera_info", "~camera_name", "string", "~camera_topic", "string", "~camera_id", "int", "~camera_parameters_file", "string", "~camera_intrinsics_file", "string", "~image_width", "int", "~image_height", "int", "~image_left", "int", "~image_top", "int", "~color_mode", "str", "~subsampling", "int", "~binning", "int", "~sensor_scaling", "double", "~auto_gain", "bool", "~master_gain", "int", "~red_gain", "int", "~green_gain", "int", "~blue_gain", "int", "~gain_boost", "bool", "~auto_exposure", "bool", "~exposure", "double", "~auto_white_balance", "bool", "~white_balance_red_offset", "int", "~white_balance_blue_offset", "int", "~flash_delay", "int", "~flash_duration", "int", "~ext_trigger_mode", "bool", "~auto_frame_rate", "bool", "~frame_rate", "double", "~pixel_clock", "int"]},
{"url": "https://wiki.ros.org/access_point_control", "package": "access_point_control", "package_summary": ["\n    Defines an API for access point control based on \n    dynamic_reconfigure. Other packages must\n    implement the API for various access-point models: \n    for example: hostapd_access_point for hostapd-based control or\n    linksys_access_point for Linksys router web interface.\n  "], "package_details": ["\n", "\n", "The following dynamic_reconfigure API must be implemented by packages specific to access point model such as ", ", ", ", ", ". "], "package_tt": ["~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string"]},
{"url": "https://wiki.ros.org/rr_openrover_basic", "package": "rr_openrover_basic", "package_summary": ["The rr_openrover_basic package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_basic/fan_speed", "/rr_openrover_basic/odom_encoder", "/rr_openrover_basic/raw_fast_rate_data", "/rr_openrover_basic/raw_med_rate_data", "/rr_openrover_basic/raw_slow_rate_data", "/rr_openrover_basic/battery_status_a", "/rr_openrover_basic/battery_status_b", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["sudo apt-get install ros-kinetic-rr-openrover-basic", "roslaunch rr_openrover_basic example.launch", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_basic openrover_basic_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_basic\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"openrover_basic_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover InOrbit Diagnostics -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>"]},
{"url": "https://wiki.ros.org/pr2_gazebo_plugins", "package": "pr2_gazebo_plugins", "package_summary": ["Gazebo Plugins for various PR2-specific sensors and actuators on the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " plugin provides ROS topic and service interfaces similar to those provided by the ", " on PR2. ", "\n", "\n", "\n", " plugin provides ROS topics and services similar to those provided by ", " on physical PR2. ", "\n", "\n", "\n", "\n", "\n", "\n", " plugin provides similar ROS interface as ", " on the physical PR2 robot.  This plugin is written in a way that ", " works transparently with either this simulated plugin or the ", " hardware.  For more information on using ", " or ", " with this plugin, please see ", ". ", "\n", "\n", "This package contains dynamic plugins for ", " and ", " integration with simulated hardware. ", "Please see ", " for additional supported hardware components in simulation. ", "This stack will be updated with new features as the PR2 hardware itself is updated. Future versions will also incorporate ", " options to match ORS driver functionality. "], "package_tt": ["GazeboRosControllerManager", "GazeboRosProsilica", "GazeboRosPowerMonitor", "<robotParam>", "<robotNamespace>", "GazeboRosProsilica", "<robotNamespace>", "<imageTopicName>", "<cameraInfoTopicName>", "<pollServiceName>", "<frameName>", "<CxPrime>", "<Cx>", "<Cy>", "<focal_length>", "<distortion_k1>", "<distortion_k2>", "<distortion_k3>", "<distortion_t1>", "<distortion_t2>", "<hackBaseline>", "GazeboRosPowerNode", "<robotNamespace>", "<powerStateTopic>", "<powerStateRate>", "<fullChargeCapacity>", "<chargeRate>", "<dischargeVoltage>", "<dischargeRate>", "<chargeVoltage>", "plugged_in", "<powerStateTopic>", "<imageTopicName>", "<cameraInfoTopicName>", "request_image", "GazeboRosControllerManager"], "package_code": ["    <!-- GazeboMechanismControl -->\n", "    <controller:gazebo_ros_controller_manager name=\"gazebo_ros_controller_manager\" plugin=\"libgazebo_ros_controller_manager.so\">\n", "      <alwaysOn>true</alwaysOn>\n", "      <updateRate>1000.0</updateRate>\n", "      <robotParam>robot_description</robotParam>\n", "      <robotNamespace>/</robotNamespace>\n", "    </controller:gazebo_ros_controller_manager>", "  <body:empty name=\"camera_body_name\">\n", "    <sensor:camera name=\"high_def_sensor\">\n", "      <imageFormat>R8G8B8</imageFormat>\n", "      <imageSize>2448 2050</imageSize>\n", "      <hfov>45</hfov>\n", "      <nearClip>0.1</nearClip>\n", "      <farClip>100</farClip>\n", "      <updateRate>20.0</updateRate>\n", "      <controller:gazebo_ros_prosilica name=\"high_def_controller\" plugin=\"libgazebo_ros_prosilica.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>20.0</updateRate>\n", "        <imageTopicName>/prosilica/image_raw</imageTopicName>\n", "        <cameraInfoTopicName>/prosilica/camera_info</cameraInfoTopicName>\n", "        <pollServiceName>/prosilica/request_image</pollServiceName>\n", "        <frameName>high_def_frame</frameName>\n", "        <CxPrime>1224.5</CxPrime>\n", "        <Cx>1224.5</Cx>\n", "        <Cy>1025.5</Cy>\n", "        <focal_length>2955</focal_length> <!-- image_width / (2*tan(hfov_radian /2)) -->\n", "        <distortion_k1>0.00000001</distortion_k1>\n", "        <distortion_k2>0.00000001</distortion_k2>\n", "        <distortion_k3>0.00000001</distortion_k3>\n", "        <distortion_t1>0.00000001</distortion_t1>\n", "        <distortion_t2>0.00000001</distortion_t2>\n", "        <interface:camera name=\"high_def_iface\"/>\n", "      </controller:gazebo_ros_prosilica>\n", "    </sensor:camera>\n", "  </body:empty>", "    <controller:gazebo_ros_power_monitor name=\"gazebo_ros_power_monitor_controller\" plugin=\"libgazebo_ros_power_monitor.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>1.0</updateRate>\n", "        <timeout>5</timeout>\n", "        <interface:audio name=\"power_monitor_dummy_interface\" />\n", "        <powerStateTopic>power_state</powerStateTopic>\n", "        <powerStateRate>10.0</powerStateRate>\n", "        <fullChargeCapacity>87.78</fullChargeCapacity>\n", "        <dischargeRate>-474</dischargeRate>\n", "        <chargeRate>525</chargeRate>\n", "        <dischargeVoltage>15.52</dischargeVoltage>\n", "        <chargeVoltage>16.41</chargeVoltage>\n", "    </controller:gazebo_ros_power_monitor>"]},
{"url": "https://wiki.ros.org/pr2_run_stop_auto_restart", "package": "pr2_run_stop_auto_restart", "package_summary": ["This package provides a node that monitors the state of the run stops of the pr2_robot. When the state of the\n   run stop changes from off to on, this node will automatically enable the power to the motors, and reset\n   the motors. This allows you to use the run stop as a 'pause' button. By using the run stop as a tool to\n   power up the robot, the run stop is also in reach of the user once the robot starts moving."], "package_details": ["\n", "\n"], "package_tt": ["run_stop_auto_restart", "power_board/state", "power_board/control", "pr2_etherCAT/reset_motors"]},
{"url": "https://wiki.ros.org/kobuki_auto_docking", "package": "kobuki_auto_docking", "package_summary": ["Automatic docking for Kobuki:\n\t    Users owning a docking station for Kobuki can use this tool to let Kobuki find its nest autonomously."], "package_tt": ["~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~min_abs_v", "double", "~min_abs_w", "double"]},
{"url": "https://wiki.ros.org/power_monitor", "package": "power_monitor", "package_summary": ["The power_monitor collects messages from the ocean_battery_server and\n     the pr2_power_board, and publishes a summary of their data in a\n     friendlier message format."], "package_details": ["\n", "\n", " takes data from ", " and ", " and republishes it in a more user-friendly message format. ", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 0.1) ", "The estimation method that ", " uses is reconfigurable via ", ". Two methods are currently available: "], "package_tt": ["power_monitor", "power_monitor", "/var/ros/power_monitor/power.log", "battery/server2", "power_board/power_state", "power_state", "~frequency", "float", "power_state", "~estimation_method", "string", "~advanced_log_file", "string", "~battery_update_timeout", "double"]},
{"url": "https://wiki.ros.org/rr_openrover_driver", "package": "rr_openrover_driver", "package_summary": ["Provides an interface between ros and Rover Robotics rover hardware. Inputs to rr_openrover_driver\n    include emergency stop and velocity commands.  It outputs diagnostic data such as encoder\n    readings and battery charge."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_driver/fan_speed", "/rr_openrover_driver/soft_estop/enable", "/rr_openrover_driver/soft_estop/reset", "/rr_openrover_driver/odom_encoder", "/rr_openrover_driver/raw_fast_rate_data", "/rr_openrover_driver/raw_med_rate_data", "/rr_openrover_driver/raw_slow_rate_data", "/rr_openrover_driver/battery_status_a", "/rr_openrover_driver/battery_status_b", "~use_legacy", "bool", "false", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["roslaunch rr_openrover_driver example.launch", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_driver openrover_driver_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_driver\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"openrover_driver_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover Diagnostics -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>slow_rate_pub"]},
{"url": "https://wiki.ros.org/kobuki_node", "package": "kobuki_node", "package_summary": ["ROS nodelet for Kobuki: ROS wrapper for the Kobuki driver."], "package_details": [" "], "package_tt": ["~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool", "~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "~commands/controller_info", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~controller_info", "~debug/raw_data_stream", "~debug/raw_data_command", "~debug/raw_control_command", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~use_imu_heading", "bool", "True", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool"]},
{"url": "https://wiki.ros.org/rmp_base", "package": "rmp_base", "package_summary": ["The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform. \n    In addition, navigation and status data are also published such as odometry, imu, mottor and battery status, ..."], "package_details": ["\n", "\n", "\n", "\n", "The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform (", "). It supports USB and UDP interfaces. ", "This package has only been tested on the RMP 440LE (", "). "], "package_tt": ["/rmp440le/base/vel_cmd", "/rmp440le/deadman", "/rmp440le/audio_cmd", "/rmp440le/odom", "/rmp440le/joint_states", "/rmp440le/inertial", "/rmp440le/pse", "/rmp440le/motor_status", "/rmp440le/battery", "/rmp440le/fault_status", "transport_type", "string", "ip_address", "string", "port_number", "int", "device_port", "string", "update_frequency", "double", "odometry_topic", "string", "joint_states_topic", "string", "inertial_topic", "string", "pse_topic", "string", "motor_status_topic", "string", "battery_topic", "string", "velocity_command_topic", "string", "deadman_topic", "string", "audio_command_topic", "string", "fault_status_topic", "string", "max_translational_velocity", "double", "max_turn_rate", "string"], "package_code": ["$ roslaunch rmp_base rmp440le.launch"]},
{"url": "https://wiki.ros.org/actionlib_lisp", "package": "actionlib_lisp", "package_summary": ["actionlib_lisp is a native implementation of the famous actionlib\n   in Common Lisp. It provides a client and a simple server."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "actionlib_lisp is a native implementation of ", " in Common Lisp. It provides a simple server and a client. In contrast to the implementations of actionlib in C++ and Python which provide a simple action client/server and a complex one, the lisp equivalent provides only one server and client implementation. The server is similar to the simple action server and the client is a little bit more powerful than the simple action client but not as complex as the complex C++ equivalent. "], "package_tt": ["(make-action-client\u00a0action-name\u00a0action-type)", "action-name", "action-type", "(wait-for-server\u00a0action-client\u00a0&optional\u00a0timeout)", "timeout", "NIL", "T", "(send-goal\u00a0client\u00a0goal\u00a0&optional\u00a0done-cb\u00a0feedback-cb\u00a0active-cb\u00a0state-change-cb)", "client", "ACTION-CLIENT", "done-cb", "feedback-cb", "active-cb", "state-change-cb", "(cancel-goal\u00a0goal-handle)", "goal-handle", "(wait-for-result\u00a0goal-handle\u00a0&optional\u00a0timeout)", "(send-goal-and-wait\u00a0client\u00a0goal\u00a0&key\u00a0exec-timeout\u00a0result-timeout\u00a0feedback-cb)", "wait-for-result", "feedback-signal", "abort-goal", "client", "goal", "exec-timeout", "result-timeout", "feedback-cb", "send-goal-and-wait", "(call-goal\u00a0client\u00a0goal\u00a0&key\u00a0timeout\u00a0result-timeout\u00a0feedback-cb)", "(connected-to-server\u00a0client)", "T", "(make-action-goal\u00a0client\u00a0&rest\u00a0args)", "client", "make-msg", "(start-action-server\u00a0action-name\u00a0action-type\u00a0exec-callback\u00a0&key\u00a0separate-thread)", "action-name", "action-type", "exec-callback", "separate-thread", "(def-exec-callback\u00a0name\u00a0args\u00a0&body\u00a0body)", "preempt-current", "succeed-current", "abort-current", "cancel-request-received", "publish-feedback", "body", "(succeed-current\u00a0&rest\u00a0args)", "args", "make-msg", "(abort-current\u00a0&rest\u00a0args)", "args", "make-msg", "(preempt-current\u00a0&rest\u00a0args)", "args", "make-msg", "(publish-feedback\u00a0&rest\u00a0args)", "args", "make-msg", "(cancel-request-received)", "T"], "package_code": ["(defparameter *ac* (make-action-client \"/fibonacci\" \"actionlib_tutorials/FibonacciAction\"))\n", "\n", "(send-goal-and-wait *ac* (make-action-goal *ac* :order 10) :exec-timeout 20 :result-timeout 0.5)", "(def-exec-callback fib-callback (order)\n", "  \"This function takes in the FibonacciGoal message and pursues the action.\"\n", "  (ros-debug (fib callback) \"entering callback with goal ~a\" order)\n", "  (let ((a 1) (b 1) (seq (make-array 0 :adjustable t :fill-pointer 0)))\n", "    (dotimes (i order)\n", "      (when (cancel-request-received)\n", "        (ros-debug (fib callback) \"goal ~a canceled\" order)\n", "        (preempt-current :sequence seq)) ;; Note that this exits the callback\n", "        \n", "      (psetq a b b (+ a b))\n", "      (vector-push-extend a seq) \n", "      (ros-debug (fib callback) \"publishing feedback for goal ~a\" order)\n", "      (publish-feedback :sequence seq)\n", "      (sleep 1.0))\n", "    (ros-debug (fib callback) \"succeeding on goal ~a\" order)\n", "    (succeed-current :sequence seq)))\n", "\n", "      \n", "(defun fib-server ()\n", "  (with-ros-node (\"fib\")\n", "    (start-action-server \"fibonacci\" \"actionlib_tutorials/FibonacciAction\" #'fib-callback)))"]},
{"url": "https://wiki.ros.org/kdl_parser", "package": "kdl_parser", "package_summary": ["The Kinematics and Dynamics Library (KDL) defines a tree structure\n   to represent the kinematic and dynamic parameters of a robot\n   mechanism. ", " provides tools to construct a KDL\n   tree from an XML robot representation in URDF."], "package_details": [" ", "\n", "\n", " ", "If you want to take advantage of the powerful features of the ", ", the kdl parser provides an easy way to construct a full KDL Tree object. Starting from either a ", " or a Collada xml description of your robot, the kdl parser automatically generates a KDL Tree. "], "package_tt": ["kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser", "kdl_parser"]},
{"url": "https://wiki.ros.org/xacro", "package": "xacro", "package_summary": ["Xacro (XML Macros)\n\n    Xacro is an XML macro language. With xacro, you can construct shorter and more readable XML files by using macros that expand to larger XML expressions."], "package_details": ["\n", "\n", "\n", ": Properties are local if defined inside of a ", ". See ", ". ", "\n", ": ", "\n", ": The more powerful evaluation capabilities in ROS Jade allow for much more complex expression. Virtually any python expression that evaluates to a Boolean is feasible: ", "\n", ": Since ROS Indigo, it is also possible to define defaults like so: ", "\n", "Comments in front of macros will be removed during processing. ", "They are considered to be related to the macro (e.g. explaining the macro). If you want to keep a comment in the final document, separate it with an empty line from the macro. ", "\n", " Macro parameters can have default values: ", "Often, you need to pass external variables into local macro params (as above for x). To ease this task, you can employ the ^ syntax: ", "\n", "Properties and macros defined within a macro are local to this macro, i.e. not visible outside. Using the optional attribute ", ", a property definition can be exported to the parent scope of a macro (or the global scope). ", "\n", "\n", " Properties can be dictionaries or lists too - manually declared with python syntax, like so: ", "\n", ": While this cmake code provides full control over the target name and build order, there is a conveniency macro too: ", "\n", ": In order to add elements or attributes with a dynamically defined name, you can use the special xacro tags ", " and ", ": ", "\n", ": ", "\n", ": ", " ", "This package is most useful when working with large XML documents such as robot descriptions.  It is heavily used in packages such as the ", ".  See for example, ", " for how xacro is used to simplify urdf files. See ", ", for an example showing the use of the advanced features (python evaluation, yaml integration) introduced in Jade. ", "Many of the features highlighted as \"New in Jade\" below are also accessible from Indigo. To use them, the ", " flag is required. This flag is discussed ", ", and for some background information see this ", ". Put simply, this flag is used to trigger Jade-enabled xacro processing on Indigo. ", "Properties are named values that can be inserted anywhere into the XML document.  Property blocks are named snippets of XML that can be inserted anywhere that XML is allowed.  Both use the property tag to define values. Property tags cannot be declared inside of a ", ". ", "Since ROS Jade, Xacro employs ", " to evaluate expressions enclosed in dollared-braces, ", ". This allows for more complex arithmetic expressions. Functions and constants from the ", " math module (e.g. ", " and trigonometric functions) are available for use. Examples: ", "Xacro allows you to use certain rospack commands with dollared-parentheses (", "). ", "Xacro currently supports all the rospack commands that roslaunch supports using ", ". Arguments need to be specified on the command line using the ", " syntax. ", "You can include other xacro files using the ", " tag: ", "The file \"other_file.xacro\", will be included and expanded by xacro.  ", ": Relative filenames are interpreted relative to the currently processed file. ", ": When including files within a macro, not the macro-defining but the macro-calling file is the one that processes the include! $(cwd) explicitly allows to access files in the current working directory. ", "or loaded from ", " files like so: ", "If you want the generated files to have a ", " extension it is possible to provide input files terminating with ", ", the ", " suffix will be removed by the CMake function. This results in files with a ", " extension. ", "Usage example for ", ": ", "Classicly Xacro first loads all includes, then processes all property and macro definitions and finally instantiates macros and evaluates expressions. Thus, ", ". Additionally, the conditional tags, <if> and <unless>, have no effect on macro or property definitions nor the inclusion of additional files. ", "Since ROS Jade, Xacro provides the command-line option ", ", that allows to process the whole document in read order. Hence the latest definition of a property or macro ", ", will be used. This is a much more intuitive evaluation process that allows for some nice new features as well: ", "If there are any differences shown, you should check and adapt your xacro file. A common reason will be the late loading of calibration data (as properties). In this case, simply move them up front, i.e. before usage. To facilitate search for wrongly placed property definitions, you can run xacro with option ", ". If there are any problematic properties, they will be listed on stderr: ", "Using the command-line option ", " or ", " one can increase verbosity level to log all defintions of properties. ", "To suppress the legacy interpretation of sloppy xacro tags and allow their usage in the target XML, you can use the command line option ", ". "], "package_tt": ["--inorder", "xacro:macro", "xacro:macro", "python", "${}", "python", "pi", "$()", "myvar:=true", "scope=\"parent\u00a0|\u00a0global\"", "xacro:include", "props.yaml", "props", "val1", ".urdf", ".urdf.xacro", ".xacro", ".urdf", "<xacro:element>", "<xacro:attribute>", "<xacro:attribute>", "--inorder", "--check-order", "-vv", "-vvv", "--xacro-ns"], "package_code": ["<xacro:macro name=\"pr2_arm\" params=\"suffix parent reflect\">\n", "  <pr2_upperarm suffix=\"${suffix}\" reflect=\"${reflect}\" parent=\"${parent}\" />\n", "  <pr2_forearm suffix=\"${suffix}\" reflect=\"${reflect}\" parent=\"elbow_flex_${suffix}\" />\n", "</xacro:macro>\n", "\n", "<xacro:pr2_arm suffix=\"left\" reflect=\"1\" parent=\"torso\" />\n", "<xacro:pr2_arm suffix=\"right\" reflect=\"-1\" parent=\"torso\" />", "<pr2_upperarm suffix=\"left\" reflect=\"1\" parent=\"torso\" />\n", "<pr2_forearm suffix=\"left\" reflect=\"1\" parent=\"elbow_flex_left\" />\n", "<pr2_upperarm suffix=\"right\" reflect=\"-1\" parent=\"torso\" />\n", "<pr2_forearm suffix=\"right\" reflect=\"-1\" parent=\"elbow_flex_right\" />", "<xacro:property name=\"the_radius\" value=\"2.1\" />\n", "<xacro:property name=\"the_length\" value=\"4.5\" />\n", "\n", "<geometry type=\"cylinder\" radius=\"${the_radius}\" length=\"${the_length}\" />", "<xacro:property name=\"front_left_origin\">\n", "  <origin xyz=\"0.3 0 0\" rpy=\"0 0 0\" />\n", "</xacro:property>\n", "\n", "<pr2_wheel name=\"front_left_wheel\">\n", "  <xacro:insert_block name=\"front_left_origin\" />\n", "</pr2_wheel>", "<xacro:property name=\"radius\" value=\"4.3\" />\n", "<circle diameter=\"${2 * radius}\" />", "<xacro:property name=\"R\" value=\"2\" />\n", "<xacro:property name=\"alpha\" value=\"${30/180*pi}\" />\n", "<circle circumference=\"${2 * pi * R}\" pos=\"${sin(alpha)} ${cos(alpha)}\" />\n", "<limit lower=\"${radians(-90)}\" upper=\"${radians(90)}\" effort=\"0\" velocity=\"${radians(75)}\" />", "<xacro:if value=\"<expression>\">\n", "  <... some xml code here ...>\n", "</xacro:if>\n", "<xacro:unless value=\"<expression>\">\n", "  <... some xml code here ...>\n", "</xacro:unless>", "<xacro:property name=\"var\" value=\"useit\"/>\n", "<xacro:if value=\"${var == 'useit'}\"/>\n", "<xacro:if value=\"${var.startswith('use') and var.endswith('it')}\"/>\n", "\n", "<xacro:property name=\"allowed\" value=\"${[1,2,3]}\"/>\n", "<xacro:if value=\"${1 in allowed}\"/>", "<foo value=\"$(find xacro)\" />\n", "<foo value=\"$(arg myvar)\" />", "<xacro:arg name=\"myvar\" default=\"false\"/>", "<param name=\"robot_description\" command=\"$(find xacro)/xacro.py $(arg model) myvar:=true\" />", "<xacro:macro name=\"pr2_caster\" params=\"suffix *origin **content **anothercontent\">\n", "  <joint name=\"caster_${suffix}_joint\">\n", "    <axis xyz=\"0 0 1\" />\n", "  </joint>\n", "  <link name=\"caster_${suffix}\">\n", "    <xacro:insert_block name=\"origin\" />\n", "    <xacro:insert_block name=\"content\" />\n", "    <xacro:insert_block name=\"anothercontent\" />\n", "  </link>\n", "</xacro:macro>\n", "\n", "<xacro:pr2_caster suffix=\"front_left\">\n", "  <pose xyz=\"0 1 0\" rpy=\"0 0 0\" />\n", "  <container>\n", "    <color name=\"yellow\"/>\n", "    <mass>0.1</mass>\n", "  </container>\n", "  <another>\n", "    <inertial>\n", "      <origin xyz=\"0 0 0.5\" rpy=\"0 0 0\"/>\n", "      <mass value=\"1\"/>\n", "      <inertia ixx=\"100\"  ixy=\"0\"  ixz=\"0\" iyy=\"100\" iyz=\"0\" izz=\"100\" />\n", "    </inertial>\n", "  </another>\n", "</xacro:pr2_caster>", "<joint name=\"caster_front_left_joint\">\n", "  <axis xyz=\"0 0 1\" />\n", "</joint>\n", "<link name=\"caster_front_left\">\n", "  <pose xyz=\"0 1 0\" rpy=\"0 0 0\" />\n", "  <color name=\"yellow\" />\n", "  <mass>0.1</mass>\n", "  <inertial>\n", "    <origin xyz=\"0 0 0.5\" rpy=\"0 0 0\"/>\n", "    <mass value=\"1\"/>\n", "    <inertia ixx=\"100\"  ixy=\"0\"  ixz=\"0\" iyy=\"100\" iyz=\"0\" izz=\"100\" />\n", "  </inertial>\n", "</link>", "<xacro:macro name=\"reorder\" params=\"*first *second\">\n", "  <xacro:insert_block name=\"second\"/>\n", "  <xacro:insert_block name=\"first\"/>\n", "</xacro:macro>\n", "<reorder>\n", "  <first/>\n", "  <second/>\n", "</reorder>", "<a>\n", "  <xacro:macro name=\"foo\" params=\"x\">\n", "    <in_foo the_x=\"${x}\" />\n", "  </xacro:macro>\n", "\n", "  <xacro:macro name=\"bar\" params=\"y\">\n", "    <in_bar>\n", "      <xacro:foo x=\"${y}\" />\n", "    </in_bar>\n", "  </xacro:macro>\n", "\n", "  <xacro:bar y=\"12\" />\n", "</a>", "<a>\n", "  <in_bar>\n", "    <in_foo the_x=\"12.0\"/>\n", "  </in_bar>\n", "</a>", "<xacro:macro name=\"foo\" params=\"x:=${x} y:=${2*y} z:=0\"/>", "<xacro:macro name=\"foo\" params=\"p1 p2:=expr_a p3:=^ p4:=^|expr_b\">", "<xacro:include filename=\"$(find package)/other_file.xacro\" />\n", "<xacro:include filename=\"other_file.xacro\" />\n", "<xacro:include filename=\"$(cwd)/other_file.xacro\" />", "<xacro:include filename=\"other_file.xacro\" ns=\"namespace\"/>", "${namespace.property}", "<xacro:property name=\"props\" value=\"${dict(a=1, b=2, c=3)}\"/>\n", "<xacro:property name=\"numbers\" value=\"${[1,2,3,4]}\"/>", "<xacro:property name=\"yaml_file\" value=\"$(find package)/config/props.yaml\" />\n", "<xacro:property name=\"props\" value=\"${load_yaml(yaml_file)}\"/>", "val1: 10\n", "val2: 20", "<xacro:property name=\"val1\" value=\"${props['val1']}\" />", "# Generate .world files from .world.xacro files\n", "find_package(xacro REQUIRED)\n", "# You can also add xacro to the list of catkin packages:\n", "#   find_package(catkin REQUIRED COMPONENTS ... xacro)\n", "\n", "# Xacro files\n", "file(GLOB xacro_files ${CMAKE_CURRENT_SOURCE_DIR}/worlds/*.world.xacro)\n", "\n", "foreach(it ${xacro_files})\n", "  # remove .xacro extension\n", "  string(REGEX MATCH \"(.*)[.]xacro$\" unused ${it})\n", "  set(output_filename ${CMAKE_MATCH_1})\n", "\n", "  # create a rule to generate ${output_filename} from {it}\n", "  xacro_add_xacro_file(${it} ${output_filename})\n", "\n", "  list(APPEND world_files ${output_filename})\n", "endforeach(it)\n", "\n", "# add an abstract target to actually trigger the builds\n", "add_custom_target(media_files ALL DEPENDS ${world_files})", "file(GLOB xacro_files worlds/*.world.xacro)\n", "xacro_add_files(${xacro_files} TARGET media_files)", "<xacro:element xacro:name=\"${element_name}\" [other attributes]>\n", " [content]\n", "</xacro:element>\n", "<xacro:attribute name=\"${attribute_name}\" value=\"${attribute_value}\"/>", "<xacro:property name=\"foo\" value=\"my_attribute_name\"/>\n", "<tag>\n", "    <xacro:attribute name=\"${foo}\" value=\"my_attribute_value\"/>\n", "</tag>", "<tag my_attribute_name=\"my_attribute_value\" />", "rosrun xacro xacro file.xacro > /tmp/old.xml\n", "rosrun xacro xacro --inorder file.xacro > /tmp/new.xml\n", "diff /tmp/old.xml /tmp/new.xml", "Document is incompatible to --inorder processing.\n", "The following properties were redefined after usage:\n", "foo redefined in issues.xacro", "find . -iname \"*.xacro\" | xargs sed -i 's#<\\([/]\\?\\)\\(if\\|unless\\|include\\|arg\\|property\\|macro\\|insert_block\\)#<\\1xacro:\\2#g'"]},
{"url": "https://wiki.ros.org/velodyne_driver", "package": "velodyne_driver", "package_summary": ["ROS device driver for Velodyne 3D LIDARs."], "package_details": ["\n", "\n", ": the ", " parameter now expects an exact name: \"VLP16\", \"32C\", \"32E\", \"64E\", \"64E_S2\", \"64E_S2.1\", or \"64E_S3\", and generates the correct packet rates for them.", "\n ", ": The VLP-16 (\"Puck\") model is now supported.", "\n ", ": The VLP-32C (\"Ultra Puck\") model is now supported.", "\n ", ": The HDL-64E S3 model is now supported. ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "This package provides basic device handling for Velodyne 3D LIDARs. For a list of all supported models refer to the ", " section. ", "The driver publishes device-dependent ", " data. The ", " package provides nodes and nodelets to convert those data into more-convenient ", " messages. ", "The ", " describes the evolution of these interfaces. ", "Read the Velodyne HDL-64E (default) input socket as fast as possible. Publish each complete revolution to ", ". ", "Read the Velodyne Velodyne HDL-32E input socket as fast as possible. Publish each complete revolution to ", ". ", "Read previously captured Velodyne packets from dump.pcap file. Publish messages to ", " at approximately 10 Hz rate. Dump files can be grabbed by ", ", Velodyne's DSR software, ", ", ", ", ", ", or the ", " command. ", "The ", " command dumps raw data from the Velodyne LIDAR in PCAP format. It is a shell script wrapper providing some obscure options for the powerful ", " command. ", "Other methods of acquiring PCAP data include using ", " directly, ", ", Velodyne's DSR software, and programming with ", ". ", "Dump Velodyne packets from the ", " interface to a series of files named ", ", ", ", etc. Each file will be about 100MB. The time span that a single 100MB file covers depends on packet size and sampling rate of a particular model (for VLP-16 that is about 100 seconds worth of packets). Type ", " when finished. ", "Start a ", " process running the driver nodelet. Other nodelets using the same nodelet manager process will have zero-copy access to the raw data messages the driver publishes. ", "Start a ", " process for a Velodyne HDL-32E. ", "Start a driver nodelet with input from ", ", in the current directory. The ", " provides a full path name, as required for ", ". "], "package_tt": ["model", "/velodyne", "tf_prefix", "velodyne_packets", "velodyne_packets", "velodyne_packets", "libpcap", "ethereal", "wireshark", "tcpdump", "vdump", "tcpdump", "tcpdump", "wireshark", "libpcap", "eth1", "pcap-000", "pcap-001", "^C", "velodyne_nodelet_manager", "velodyne_nodelet_manager", "tcpdump.pcap", "pwd", "roslaunch"], "package_code": ["$ rosrun velodyne_driver velodyne_node", " $ rosrun velodyne_driver velodyne_node _model:=32E", "$ rosrun velodyne_driver velodyne_node _pcap:=dump.pcap", "  rosrun velodyne_driver vdump <file_prefix> [ <interface> ]\n", "\n", "        <file_prefix>   file name to dump (with 3-digit number suffix)\n", "        <interface>     interface to read from (default: \"eth0\")", "$ rosrun velodyne_driver vdump pcap- eth1", " $ roslaunch velodyne_driver nodelet_manager.launch", " $ roslaunch velodyne_driver nodelet_manager.launch model:=32E", " $ roslaunch velodyne_driver nodelet_manager.launch pcap:=$(pwd)/tcpdump.pcap"]},
{"url": "https://wiki.ros.org/ros_control", "package": "ros_control", "package_summary": ["A set of packages that include controller interfaces, controller managers, transmissions and hardware_interfaces."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ros_control packages are a rewrite of the ", " packages to make controllers generic to all robots beyond just the PR2. ", "A high-level overview of the project can be found in the ROScon 2014 talk entitled ", " (", ", ", "). ", "A short summary of CombinedRobotHW can be found in ", " ROScon 2016 talk. ", "Additional documentation is available at the ", " ", "A list of available controller plugins, contained in ", ", as of this writing. You can of course create your own and are not limited to the below list. All controllers use the ", " to send commands to a hardware interface. ", "Take a look at the ", " to understand how the joint_trajectory_controller is namespaced with the position_controller, velocity_controller, etc. ", "Also refer to the ", " of the hardware_interface and the ", ". ", "From the above it can be seen that power remains constant between input and output. Complementary ", " (first part will do). ", "See ", ". ", "Transmission-specific code (not robot-specific) implementing bidirectional (actuator <-> joint) effort and flow maps under a uniform interface shared across transmission types. This is hardware-interface-agnostic. A list of available transmission types as of this writing: ", "See ", " ", "The ", " contains data structures for representing joint limits, methods for populating them from common formats such as URDF and rosparam, and methods for enforcing limits on different kinds of joint commands. ", "The joint_limits_interface is not used by controllers themselves (it does not implement a ", ") but instead operates after the controllers have updated, in the ", " method (or equivalent) of the robot abstraction. Enforcing limits will ", " the commands set by the controllers, it does not operate on a separate raw data buffer. ", "See ", " ", "Or on Ubuntu and other platforms from source. To ease installing from source a ", " file is provided: ", "Not exactly a roadmap, but this ", " contains discussion and proposed solutions to allow ros_control to better accommodate more complex control setups and address shortcomings in the current implementation. ", "A ", " exists with a mailing list for discussing ros_control issues and features. You are encouraged to join and help with ros_control's development! "], "package_code": ["@article{ros_control,\n", "author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\\\"u}dtke, Mathias and Fern{\\'a}ndez Perdomo, Enrique},\n", "title = {ros\\_control: A generic and simple control framework for ROS},\n", "journal = {The Journal of Open Source Software},\n", "year = {2017},\n", "doi = {10.21105/joss.00456},\n", "URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}\n", "}", "P_in        = P_out\n", "\n", "F_in x V_in = F_out x V_out", "effort map: F_joint = F_actuator * n\n", "\n", "flow map:   V_joint = V_actuator / n", "sudo apt-get install ros-$ROS_DISTRO-ros-control ros-$ROS_DISTRO-ros-controllers", "cd CATKIN_WORKSPACE/src\n", "wstool init\n", "wstool merge https://raw.github.com/ros-controls/ros_control/$ROS_DISTRO-devel/ros_control.rosinstall\n", "wstool update\n", "cd ..\n", "rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO -y\n", "catkin_make"]},
{"url": "https://wiki.ros.org/wiimote", "package": "wiimote", "package_summary": ["The wiimote package allows ROS nodes to communicate with a Nintendo Wiimote\n    and its related peripherals, including the Nunchuk, Motion Plus, and\n    (experimentally) the Classic. The package implements a ROS node that uses\n    Bluetooth to communicate with the Wiimote device, obtaining accelerometer\n    and gyro data, the state of LEDs, the IR camera, rumble (vibrator),\n    buttons, joystick, and battery state. The node additionally enables ROS\n    nodes to control the Wiimote's LEDs and vibration for feedback to the human\n    Wiimote operator. LEDs and vibration may be switched on and off, or made to\n    operate according to a timed pattern."], "package_details": [" ", "\n", "\n", " The cwiid library currently only recognizes Wiimotes which report the name as \"Nintendo RVL-CNT-01\"; the latest Wiimotes will not be discovered. See ", ". ", "\n", "\n", "\n", " ", "\n", " ", "The ", " array shows which buttons are currently depressed on the ", "Wiimtoe device. The position mapping is as follows: ", "This package should be considered as ", " except for support of the Classic controller, which requires additional testing. ", "Check out the wiimote package, and ", " to ready the package for ", "operation. Plug the Bluetooth dongle into your machine's USB port. ", "The ", " message communicates all data that is available from ", "your Wiimote device. Samples are taken and broadcast at 100Hz. Here ", "are comments on some of the fields: ", "The message header's time ", " is set to reflect the time when the respective message's sample was taken from the Wiimote device. ", "The ", " shows the Motion+ gyroscope ", "reading. These values are valid only if the Motion+ attachment is ", "plugged into the Wiimote. Else they are held at constant zero, and ", "matrix entry [0,0] in message field angular_velocity_covariance is set ", "to -1. ", "The ", " are four sets of x/y/[z], and size measures, for the four ", "infrared light sources that the Wiimote device can track. When no ", "lights are detected, the respective values are set to -1. The z axis ", "is always -1, as it is not measured. ", "The ", " array are four intensity measures of the lights that ", "the camera observes. The meaning of these measures are unclear to the ", "author. ", "The ", " entry is the battery charge reading. The unit of ", "this number is unclear. Field ", " returns the remaining ", "charge as a percentage of full charge. ", "The ", " is the time of the most recent device calibration. ", "The ", " field is currently not used. "], "package_tt": ["cwiid", "rosmake", "wiimote_node.py", "set_feedback", "joy", "imu/data", "wiimote/state", "wiimote/nunchuk", "wiimote/classic", "imu/is_calibrated", "imu/calibrate", "State", "stamp", "angular_velocity_zeroed", "angular_velocity_raw", "buttons", "ir_tracking", "ir_sizes", "raw_battery", "percent_battery", "zeroing_time", "errors"], "package_code": ["Position   Button Name\n", "0         1\n", "1         2\n", "2         A\n", "3         B (toggle button on back of device)\n", "4         Plus\n", "5         Minus\n", "6         Rocker Left\n", "7         Rocker Right\n", "8         Rocker Up\n", "9         Rocker Down\n", "10        HOME"]},
{"url": "https://wiki.ros.org/rosmsg", "package": "rosmsg", "package_summary": ["rosmsg contains two command-line tools: ", " and\n    ", ". ", " is a command-line tool for\n    displaying information about ", ". ", " is a command-line tool for displaying\n    information about ", "."], "package_details": ["\n", " and ", " are handy command-line tools that provide reference information for developers and also serve as a powerful introspection tool for learning more about data being transmitted in ROS.  ", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", "\n", " and ", " are stable tools. There is currently no plan to add new features to them. ", "For example, if you are using a message in your code, you can type ", " at the command-line to look up its fields: ", "For even quicker typing, you can omit \"", "\", and ", " will search all packages for a matching message. ", "You can also use this in an online system with tools like ", ". For example, ", " will tell you the message type of a topic: ", "You can pass this to ", " to quickly see the fields of the message: ", "Once you know more about the fields of a particular message, you can then listen them at the command-line, e.g. ", "The ", " command-line tool displays information about ROS ", ". The following sections describe the commands that are available. ", "Note that messages in a subfolder may not be listed as of March 2017 (", "). ", "The ", " command-line tool displays information about ROS services. It has the exact same usage as ", " (see what it offers when it runs without sub-command below): "], "package_tt": ["rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg", "rossrv", "rosmsg\u00a0show", "my_pkg", "rosmsg", "rostopic\u00a0type", "rosmsg", "rosmsg", "show\u00a0<message\u00a0type>", "rosmsg", "-r", "-b\u00a0BAGFILE", "list", ".msg", "package\u00a0<package-name>", "-s", "packages", ".msg", "-s", "users\u00a0<message\u00a0type>", "rosmsg\u00a0users", "md5\u00a0<message\u00a0type>", "rossrv", "rosmsg", "rosmsg", "rossrv"], "package_code": ["$ rosmsg show sensor_msgs/CameraInfo\n", "Header header\n", "  uint32 seq\n", "  time stamp\n", "  string frame_id\n", "uint32 height\n", "uint32 width\n", "RegionOfInterest roi\n", "  uint32 x_offset\n", "  uint32 y_offset\n", "  uint32 height\n", "  uint32 width\n", "float64[5] D\n", "float64[9] K\n", "float64[9] R\n", "float64[12] P", "$ rostopic type rosout\n", "roslib/Log", "rostopic type rosout | rosmsg show\n", "byte DEBUG=1\n", "byte INFO=2\n", "byte WARN=4\n", "byte ERROR=8\n", "byte FATAL=16\n", "Header header\n", "  uint32 seq\n", "  time stamp\n", "  string frame_id\n", "byte level\n", "string name\n", "string msg\n", "string file\n", "string function\n", "uint32 line\n", "string[] topics", "$ rostopic echo rosout/msg", "$ rosmsg show std_msgs/String", "$ rosmsg show Pose", "$ rostopic type /topic_name | rosmsg show", "$ rosmsg show -r robot_msgs/Quaternion\n", "# xyz - vector rotation axis, w - scalar term (cos(ang/2))\n", "float64 x\n", "float64 y\n", "float64 z\n", "float64 w", "$ rosmsg list\n", "nav_msgs/GridCells\n", "nav_msgs/MapMetaData\n", "nav_msgs/OccupancyGrid\n", "nav_msgs/Odometry\n", "nav_msgs/Path\n", "...", "$ rosmsg package nav_msgs\n", "nav_msgs/OccupancyGrid\n", "nav_msgs/Path\n", "nav_msgs/MapMetaData\n", "nav_msgs/Odometry\n", "nav_msgs/GridCells", "$ rosmsg packages\n", "std_msgs\n", "roscpp\n", "roslib\n", "...", "$ rosmsg users sensor_msgs/CameraInfo\n", "Files using sensor_msgs/CameraInfo:\n", "Usages directly depended upon:sensor_msgs/CameraInfo\n", "/home/user/ros-pkg/pr2_simulator/pr2_gazebo_plugins/include/pr2_gazebo_plugins/gazebo_ros_prosilica.h\n", "...", "$ rossrv\n", "rossrv is a command-line tool for displaying information about ROS Service types.\n", "\n", "Commands:\n", "        rossrv show     Show service description\n", "        rossrv list     List all services\n", "        rossrv md5      Display service md5sum\n", "        rossrv package  List services in a package\n", "        rossrv packages List packages that contain services\n", "\n", "Type rossrv <command> -h for more detailed usage"]},
{"url": "https://wiki.ros.org/rosserial_embeddedlinux", "package": "rosserial_embeddedlinux", "package_summary": ["rosserial for embedded Linux enviroments"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the ", " support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  ", "Using the ", " package, you can use ROS directly with the these systems. ", " provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. ", "The ", " package supports the following major connection types and capabilities: ", "This package contains embedded-linux-specific extensions required to run ", " on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  ", "Go to the ", " to learn how to install and use the package to connect your embedded linux system to ROS. ", "Please file new bugs on the project's ", ". The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "]},
{"url": "https://wiki.ros.org/m4atx_battery_monitor", "package": "m4atx_battery_monitor", "package_summary": ["Battery Monitor for the M4-ATX Power Module"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package will read the information from a m4atx battery supply and publish it as a ros message. ", "Locate the bus and device number of the device called \"", " Technology, Inc.\". ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["m4atx_battery_monitor", "m4atx_battery_monitor_node", "battery_status_m4atx", "~diag_frequency", "~input_nominal", "~battery_dead_voltage", "m4atx_battery_monitor", "ros_ethernet_rmp", "m4atx-battery-monitor.launch", "m4atx_battery_monitor_node"], "package_code": ["lsusb ", "sudo chmod a+rw /dev/bus/usb/<bus_num>/<device_num>", "\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-m4atx-battery-monitor", "roslaunch m4atx_battery_monitor_node m4atx_battery_monitor_node.launch "]},
{"url": "https://wiki.ros.org/rc_visard_driver", "package": "rc_visard_driver", "package_summary": ["The rc_visard_driver provides data from a Roboception rc_visard 3D sensor on several ROS topics."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", " ", "Official ROS driver for ", " rc_visard 3D sensor. ", "See ", " and ", " for more details. ", "The ", " is the world\u2019s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. ", "The ", " is the official ROS driver for the ", " which provides ROS parameters (configuration), ROS services (control of rc_visards dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF).  ", "If the connected rc_visard has an ", " license, then the following ", "topics are additionally provided for images where the GPIO out1 is either low ", "or high. These topics only useful if ", " is set to the special mode ", ". ", "For color sensors with an ", " license, the following topics are ", "additionally available: ", "If the parameter ", " is set to true, the node subscribes to the ", "rc_visard's pose stream (same data published on ", " topic) and publishes them on tf. ", "The trajectory constructed and stored by the ", " node ", "can be retrieved by ", "The onboard map of the ", " node can be saved on the rc_visard for loading it ", "after a SLAM restart or power cycle: ", "The onboard ", " node can be \"reset\" (clears the internal state of the SLAM component, ", "including the trajectory) to free the memory with "], "package_tt": ["device", "02912345", ":02912345", "gev_access", "control", "exclusive", "off", "max_reconnects", "enable_tf", "enable_visualization_markers", "/dynamics_visualization_markers", "autostart_dynamics", "autostart_dynamics_with_slam", "autostop_dynamics", "autopublish_trajectory", "/trajectory", "ptp_enabled", "camera_fps", "camera_exp_auto", "camera_exp_max", "camera_exp_value", "camera_gain_value", "camera_exp_width", "camera_exp_height", "camera_exp_offset_x", "camera_exp_offset_y", "depth_acquisition_mode", "SingleFrame", "Continuous", "S", "C", "depth_quality", "Low", "Medium", "High", "StaticHigh", "L", "M", "H", "S", "StaticHigh", "High", "Medium", "Low", "High", "depth_static_scene", "depth_disprange", "depth_fill", "depth_seg", "depth_smooth", "depth_median", "depth_minconf", "depth_mindepth", "depth_maxdepth", "depth_maxdeptherr", "out1_mode", "Low", "High", "ExposureActive", "ExposureAlternateActive", "IO\u00a0Control", "ExposureActive", "out2_mode", "out1_mode", "Low", "camera_wb_auto", "camera_wb_ratio_red", "camera_wb_auto", "camera_wb_ratio_blue", "camera_wb_auto", "IO\u00a0Control", "out1_mode", "ExposureAlternateActive", "IO\u00a0Control", "enable_tf", "enable_tf", "/pose", "camera", "world", "camera", "imu", "my_visard", "my_visard_world", "my_visard_camera", "dynamics_start", "dynamics_restart", "dynamics_stop", "dynamics_start_slam", "dynamics_restart_slam", "dynamics_stop_slam", "rc_slam", "slam_get_trajectory", "rc_slam", "slam_save_map", "slam_load_map", "slam_remove_map", "rc_slam", "slam_reset", "my_visard", "my_visard_camera", "my_visard_world", "my_visard_imu"], "package_code": ["rosrun rc_visard_driver rc_visard_driver _device:=:02912345 _enable_tf:=True _autostart_dynamics:=True _autostop_dynamics:=True", "ROS_NAMESPACE=my_visard rosrun nodelet nodelet standalone rc_visard_driver _device:=:02912345"]},
{"url": "https://wiki.ros.org/schunk_powercube_chain", "package": "schunk_powercube_chain", "package_summary": ["This packages provides a configurable driver of a chain\n  of Schunk powercubes. The powercube chain is configured\n  through parameters. Most users will not directly interact\n  with this package but with the corresponding launch files\n  in other packages, e.g. schunk_bringup, cob_bringup, ..."], "package_details": ["\n", "\n", "\n", "\n", "To use this package you need one or more powercubes ", ". Alternatively you can use a simulated version without any hardware, see ", ". ", "The installation is tested for Ubuntu 14.04 using ROS ", ". If you discover problems installing them on other platforms, please ", ". ", "The ", " package provides a configurable node for operating a chain of powercube modules. ", "\n", "This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g. ", " in the ", " stack. ", "For starting only the lwa use ", "All hardware configuration is done in the ", " package. A sample parameter file in \"schunk_hardware_config/lwa/config/lwa.yaml\" could look like this "], "package_tt": ["schunk_powercube_chain", "joint_group_velocity_controller/command", "joint_group_position_controller/command", "/joint_states", "joint_trajectory_controller/state", "driver/current_operationmode", "/diagnostics", "driver/init", "driver/stop", "driver/recover", "driver/set_operation_mode", "can_module", "string", "can_device", "string", "can_baudrate", "int", "module_ids", "list\u00a0of\u00a0ints", "force_use_movevel", "bool", "joint_names", "list\u00a0of\u00a0strings", "max_accelerations", "list\u00a0of\u00a0doubles", "horizon", "double", "frequency", "double", "min_publish_duration", "double", "/robot_description", "urdf\u00a0model"], "package_code": ["roslaunch schunk_bringup lwa_solo.launch", "<include file=\"$(find schunk_bringup)/components/lwa.launch\" />", "can_module: PCAN\n", "can_device: /dev/pcan1\n", "can_baudrate: 1000\n", "modul_ids: [1,2,3,4,5,6,7]\n", "joint_names: [arm_1_joint, arm_2_joint, arm_3_joint, arm_4_joint, arm_5_joint, arm_6_joint, arm_7_joint]\n", "max_accelerations: [0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n", "frequency: 68\n", "OperationMode: position\n", "ptp_vel: 0.4 # rad/sec\n", "ptp_acc: 0.1 # rad/sec^2\n", "max_error: 0.2 # rad"]},
{"url": "https://wiki.ros.org/ridgeback_msgs", "package": "ridgeback_msgs", "package_summary": ["Messages exclusive to Ridgeback, especially for representing low-level motor commands and sensors."], "package_details": ["\n", "\n", "These messages are the low-level interface between ", "'s ARM MCU and integrated PC. Most users of Ridgeback should be able to use standard ROS interfaces (eg. ", ", ", ") to command and monitor the robot. A possible exception is to programmatically monitor system state such as voltage, current, battery, faults, etc. "]},
{"url": "https://wiki.ros.org/smart_battery_msgs", "package": "smart_battery_msgs", "package_summary": ["Smart Battery Messages"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"smart_battery_msgs\" in rosdoc: /home/rosbot/docs/api/smart_battery_msgs/manifest.yaml "]},
{"url": "https://wiki.ros.org/kobuki_dashboard", "package": "kobuki_dashboard", "package_summary": ["The Kobuki dashboard is a RQT-based plug-in for visualising data from Kobuki and giving easy access\n    to basic functionalities."], "package_details": [" ", "\n", "\n", "The kobuki_dashboard is also part of the ", ". In order to get the battery statuses, you need to launch the ", ". "], "package_code": ["$ roslaunch kobuki_node minimal.launch", "$ rosrun kobuki_dashboard kobuki_dashboard"]},
{"url": "https://wiki.ros.org/spatial_world_model", "package": "spatial_world_model", "package_summary": ["Spatial World Model for Object Tracking"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "As a basic example for the types of end-user interfaces that can be created with the Spatial World Model, we look at the Map annotation interface. Information on this interface can be found on the ", ". Below is a video demonstrating its capabilities: ", "The following steps are written for ", " but apply to most Linux systems. ", "To begin, we must install ", " and the Python libraries that will talk to it. To do so, run the following command: ", "Finally, we are able to install the database schema. This is provided in a script found in the ", " package. This script can be used to both install a new database and to update an existing one. ", "In many cases, you will be installing the Spatial World Model database on a central server so that multiple clients (and robots) can talk to it. As of now, the ROS nodes communicate via SQL to the database; however, due to security risks this will eventually be changed. To allow remote connections, we must modify the configuration scripts on the system. Using your choice of editor, modify ", " with root privileges and add the following line: ", "Next, modify ", " with root privileges and add the following line: ", "At its core, the Spatial World Model is designed to be a persistent, multi-robot model to keep track of both the robot's working memory as well as keeping track of properties, affordances, and activities that can be associated with each object. To manage persistence, the world model is stored in a ", " database  At a high level, currently the Spatial World Model allows for two sets of entities: a ", " and a ", ". ", "A ", ", defined in the ", " message, can be thought of as a robot's working memory. At a basic level, such an entity contains a relative pose in the world with associated tags and timestamps. These entities describe a particular, specific instance of an object in the world (e.g., the cup sitting on the desk in the conference room). Each instance is linked to a single ", " which contains a set of spatial descriptors for the object (e.g., mesh, bounding box, point-cloud cluster, etc...). Below is a detailed explanation of the fields in the ", ". Note that some fields will be blank depending on the type of object or what you know about the world.  ", "The second implemented entity is the ", ". This entity, defined in the ", " message, contains spatial descriptors of objects in the world. These are shared models that are common between all instances of such an object (e.g., a 3D mesh of the object itself). Each descriptions contains a set of tags and an array of actual ", "s. The genericness of the descriptor model allows for models to come from a variety of sources (point cloud segmentation, 3D model warehouses and databases) with few-to-no restrictions. The main idea is to associate an appropriate ", " and ", " field with each descriptor to determine how the data should be treated. In a sense, the ", " field can be thought up as a non-standard MIME type (PNG, Collada, but also ", " as a type). Future goals of the project set out to create a standard set of accepted type fields. Below is a detailed description of the fields associated with a ", ". ", "The first design decision was to use a ", " database for storage. Given the highly relational components associated with the world model (e.g., ", " and ", "), it made sense to use such a database over other types of databases. For efficiency in searching and storage, the database schema itself is broken into finer grains than the APIs allow for. It is intended that developers make user of these higher-level APIs when dealing with the Spatial World Model as apposed to making raw SQL queries. ", "The current implementation includes several layers of APIs. As mentioned previously, it is not intended for a developer to use the world model by directly making SQL queries. At the lowest level, the ", " Python API should be used. This level of the API is responsible for talking SQL to the world model database and is able to make basic insertion and search queries while maintaining the correct structure. This level of the API allows for non-ROS processes to make use of the world model (another future goal of the project). By using an SQL connection between this library and the database, remote connections can be made and a central database can be used (such as one hosted in the cloud). This, of course, requires your server to allow remote SQL connections which is not ideal. Therefore, future plans hope to create a server-side API to allow for remote queries (think REST as an example but this would require polling). With such an API in place, the interface between the robot or client and the database could be made with this new service. ", "Furthermore, a ", " library is provided in ", " to allow remote web clients to interact with the world model. This API currently uses ", " and ", " to communicate with the world mode; however, as discussed above, the eventual goal is to have a standard server-side API to communicate with directly instead of using ROS. ", "Within ROS, the intended use of the APIs into the world model was to create a series of what are being called listener nodes. Such nodes listen to a set of defined topics, make the appropriate inferences on the information, and update the world model accordingly. Below are three examples included in ", ".  ", "To allow for multiple robots, a notion of namespacing must be kept. To support this feature early on, this information is currently held inside of the ", " of the instance. It is up to the developer to maintain this namespace. For example, the above listeners take an optional argument to define the namespace. If no namespace is given, it will default to the hostname of the machine the node is running on. In most cases, this is good enough since the hostname of the robot is usually a good namepsace. Then, when searching for things like a particular robot, we can do a tag search for ", ". Future improvements should be made to make this clearer and enforce unique namespacing.  ", "One improvement to the current system would be to separate the ", " array into its own separate database. The idea behind properties is to define relationships such as ", " or ", " between entities in the world model. Current thoughts are to point to entries within a graph database. By doing so, powerful search queries to can written such as \"give me all the objects inside the bedroom?\" or \"is the book on my bookshelf?\" in an efficient way.  ", "One large piece of the world model that is missing is the notice of affordances. The goal of the Spatial World Model is to not only keep track of particular instances of objects, but to also manage what types of actions can be taken on certain objects. For example, a door can be opened, a cup can be grasped, and a robot can grasp (assuming it has a gripper, of course). Furthermore, pre-conditions should also be stored here. For example, the cup must be on the table to be picked up (or any number of other conditions). This would rely on the implementation of the graph database described above. These types of attributes should be stored in a separate table in the database and linked to a particular ", ".  ", "In addition to the affordances, a notion of activities, must be stored as well. Such a structure would be used to figure out how to perform such an action on such an object. For example, if you wanted to use a ", " action on a coffee cup, the associated activity would be some action call to a grasping pipeline. Each activity can be thought of as a node with some kind of transition model incorporated to provide feedback and belief states. An updated diagram of the Spatial World Model would be the following: ", "In addition to abstracting out the ", " as defined above, several improvements are needed with respect to the instances. For one, belief states should be associated with most attributes. While the current ", " does allow for this, beliefs about things just as timestamps are just as important.  ", "A second major component is a cleanser process for the database. Currently, descriptions can be linked to multiple instances. This is the main idea behind the descriptions itself. Additionally, these descriptions can potentially contain massive amounts of data (Collada models for example). If there are no longer any instances linked to a given description, it should be removed not only from the database itself, but from the disk as well (since the large data portions are kept in ", ". Care should be taken to ensure thread safety in the removal. ", "Perhaps the largest piece needed in the project is a more robust, efficient, and flexible server-side API for the world model. Currently, the ", " Python API is used by the main ROS node and speaks SQL to the database. For many reasons, security being one, this is not ideal. Efforts should be made to create a server-side API that allows for multiple remote connections to interact with the world model. Not only would this still allow the robots to communicate with the world model, but clients could now directly connect to the world model instead of using ", " as a \"proxy\". While at first glance it may seem appropriate, this API should not be response-based such as a REST API. A more robust socket-level connection should be made to allow for bi-directional communication. By standardizing a server-side interface, we can also create a more powerful query system. The protocol between clients and the server could include things like searching descriptions or descriptors without having to return the data associated with them. This allows clients to subscribe to changes in the world model without the need of polling. A diagram of the updated API levels is shown below. ", "Discussions and contributions are welcome! To get involved, check out the ", " for current feature requests and discussions.  ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["spatial_world_model", "/etc/postgresql/9.1/main/pg_hba.conf", "/etc/postgresql/9.1/main/postgresql.conf", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "instance_id", "name", "creation", "update", "expected_ttl", "perceived_end", "source", "origin", "creator", "pose", "frame_id", "instance_id", "description_id", "WorldObjectDescription", "properties", "on(45)", "tags", "WorldObjectDescription", "Discriptor", "type", "ref", "type", "nav_msgs/OccupancyGrid", "WorldObjectDescription", "description_id", "name", "descriptors", "type", "data", "ref", "tags", "tags", "WorldObjectInstance", "WorldObjectDescription", "JavaScript", "map_listener", "/map", "map", "robot_pose_listener", "robot_pose_listener", "/robot_pose", "/initpose", "tags", "[\"robot\",\u00a0\"myRobotName\"]", "properties", "on", "in", "WorldObjectDescription", "pickup", "properties", "pose"], "package_code": ["sudo apt-get install git postgresql python-psycopg2", "sudo -u postgres createdb world_model", "sudo -u postgres createuser -D -A -P <username>", "\n", "\n", "\n", "\n", "\n", "\n", "host     world_model     <username>      0.0.0.0/0               md5", "listen_addresses = '*'", "sudo service postgresql restart"]},
{"url": "https://wiki.ros.org/hostapd_access_point", "package": "hostapd_access_point", "package_summary": ["\n    A ROS node that controls a hostapd-based access\n    point. It is mainly intended for use with a wireless \n    network adapter running in master mode. It implements \n    the dynamic_reconfigure interface defined\n    in the [[access_point_control]] package.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", ":  ", "\n", "A ROS node for starting and controlling a hostapd-based access point. This node works with wifi adapters that have ", "-compatible drivers which support master mode (see ", " for more information). ", "This is an example that shows how to set up an access point and control its parameters using the ", " interface. ", "The following launch file starts an AP node on the ", " interface and the ", ": ", "The desired configuration is selected: mode ", ", channel 44, WPA security with the chosen password, a TX power level of 8 dBm and a TX bitrate of 24Mbit/s. Next the ", " checkbox is checked at the AP is started: ", "This script is useful for setting up a ", "-based setup. mac80211_hwsim is a 802.11 radio simulator. The script takes two parameters: ", "If the mac80211_hwsim is not loaded or if the number of radios it has currently spawned is smaller than ", " then it is re-loaded with the proper radio count. The script prints to its output the name of the ", "-th interface. ", "For example (this is taken from a real setup), suppose that the system has a real wireless interface with name ", " and we need to spawn three virtual interfaces. Their names will be ", ", ", " and ", ".  ", "Using ", ": ", "The script can be used to launch nodes on the ", " with roslaunch. The following example, launches two nodes on the first and second mac80211_hwsim interfaces while ensuring that there are at least three total interfaces: "], "package_tt": ["ap_hostapd_node.py", "~interface", "string", "wlan0", "wlan1", "~ip", "string", "~netmask", "string", "~hostapd_path", "string", "hostapd", "~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string", "reconfigure_gui", "wlan0", "reconfigure_gui", "a", "enabled", "mac80211_hwsim", "radio\u00a0index", "total\u00a0number\u00a0of\u00a0radios", "total\u00a0number\u00a0of\u00a0radios", "radio\u00a0index", "wlan1", "wlan0", "wlan1", "wlan2", "find_hwsim_iface.py", "wlan0", "hwsim_nat_setup.sh", "network_traffic_control", "ap_hostapd_node.py"], "package_code": ["<launch>\n", "    <node name=\"ap_wlan0\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" value=\"wlan0\"/>\n", "        <param name=\"ip\" value=\"192.168.68.1\"/>\n", "        <param name=\"netmask\" value=\"255.255.255.0\"/>\n", "    </node>\n", "    <node name=\"reconfigure_node\" pkg=\"dynamic_reconfigure\" type=\"reconfigure_gui\"/>\n", "</launch>", "import dynamic_reconfigure.client\n", "\n", "ap = dynamic_reconfigure.client.Client(\"ap_wlan0\")\n", "\n", "freq = IEEE80211_Channels.get_freq(44, IEEE80211_Channels.BAND_5000_MHz)\n", "config = ap.update_configuration({\"enabled\": True, \"mode\": 'a', \"freq\": freq, \"encryption_mode\": \"wpa\", \"encryption_pass\": \"sample_password\", \"txpower_auto\": False, \"txpower\": 8, \"bitrate\": 24*10**6})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])\n", "\n", "freq = IEEE80211_Channels.get_freq(1, IEEE80211_Channels.BAND_2400_MHz)\n", "config = ap.update_configuration({\"freq\": freq})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 1 3`\n", "wlan0\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 2 3`\n", "wlan1\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 3 3`\n", "wlan1", "<launch>\n", "    <node name=\"ap1\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 1 3\"/>\n", "    </node>\n", "\n", "    <node name=\"ap2\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 2 3\"/>\n", "    </node>\n", "</launch>", "# rosrun hostapd_access_point hwsim_nat_setup.sh wlan0 192.168.68.1 192.168.69.1 wlan1 192.168.69.2 192.168.68.2\n", "\n", "# ifconfig wlan0\n", "wlan0     Link encap:Ethernet  HWaddr 02:00:00:00:00:00  \n", "          inet addr:192.168.68.1  Bcast:192.168.68.255  Mask:255.255.255.0\n", "\n", "# ifconfig wlan1\n", "wlan1     Link encap:Ethernet  HWaddr 02:00:00:00:01:00  \n", "          inet addr:192.168.69.2  Bcast:192.168.69.255  Mask:255.255.255.0"]},
{"url": "https://wiki.ros.org/ros_ethernet_rmp", "package": "ros_ethernet_rmp", "package_summary": ["ROS Wrapper for the Segway RMP Ethernet Python Driver"], "package_details": ["\n", "\n", "\n", "\n", " broadcasts the robot frame ('/base_footprint') with respect to the odometry frame (", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package is used to bridge ROS and a Segway RMP. It will convert ", " topic messages to the RMPCommand format and then publish the feedback from the RMP. There is also a joint state publisher to read in the feedback and publish the changing joint states as necessary. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ", 'rmp_pose_updater.py' and ", " nodes. 'battery_monitor_rmp.launch' from 'battery_monitor_rmp' will also be launched if the argument, include_batt_monitor, is true. It is defaulted to true. To launch these nodes, ", " the battery monitor the following command can be used: ", "To launch these nodes ", " the battery monitor, the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["ros_ethernet_rmp", "cmd_vel", "ethernet_rmp.py", "cmd_vel", "rmp_command", "rmp_feedback", "~update_delay_sec", "~log_data", "~current_rmp_ip_addr", "~current_rmp_port_num", "~is_omni", "~my_velocity_limit_mps", "~my_accel_limit_mps2", "~my_decel_limit_mps2", "~my_dtz_rate_mps2", "~my_coastdown_accel_mps2", "~my_yaw_rate_limit_rps", "~my_yaw_accel_limit_rps2", "~my_tire_diameter_m", "~my_wheel_base_length_m", "~my_wheel_track_width_m", "~my_gear_ratio", "~my_config_bitmap", "~my_ip_address", "~my_port_num", "~my_subnet_mask", "~my_gateway", "~my_user_defined_feedback_bitmap_1", "~my_user_defined_feedback_bitmap_2", "~my_user_defined_feedback_bitmap_3", "~my_user_defined_feedback_bitmap_4", "rmp_pose_updater.py", "rmp_feedback", "odom", "~publish_tf", "rmp_pose_updater", "/odom", "rmp_joint_state.py", "rmp_feedback", "rmp_joint_states", "~has_two_wheels", "~link_left_front", "~link_right_front", "~link_left_rear", "~link_right_rear", "ros_ethernet_rmp", "ros_ethernet_rmp", "ros_ethernet_rmp.launch", "ethernet_rmp.py", "rmp_joint_states.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-ros-ethernet-rmp", "roslaunch ros_ethernet_rmp ros_ethernet_rmp.launch ", "roslaunch ros_etehrnet_rmp ros_ethernet_rmp.launch include_batt_monitor:=false"]},
{"url": "https://wiki.ros.org/stereo_slam", "package": "stereo_slam", "package_summary": ["Stereo Slam"], "package_details": [" ", "stereo_slam is a ROS node to execute Simultaneous Localization And Mapping (SLAM) using only one stereo camera. The algorithm was designed and tested for underwater robotics. This node is based on the ", " library for graph optimization and uses the power of ", " to find loop closures between graph nodes. It uses a keyframe to multi-keyframe loop closing mechanism, based on keypoint clustering, to improve the SLAM corrections on feature-poor environments. ", "See the documentation on ", ". "]},
{"url": "https://wiki.ros.org/tuw_multi_robot", "package": "tuw_multi_robot", "package_summary": ["This repository includes ros packages to plan routes for multiple robots on a search graph. It creates a search graph out of a pixel map and tries to find a path for multiple robots using an extended approach for prioritized planning. The inputs are the tuw_multi_robot_msgs/RobotInfo messages which include the robots pose, the map and the desired goal poses. The output are multiple synchronized routes given to the individual robots."], "package_details": ["\n", " ", "\n", "\n", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "The following figure represents the current state and planed developments on the tuw_multi_robot framework.  The green boxes show already existing modules while the red boxes are not yet implmented/released.  The framework is designed to cover all tools needed for an automated delivery system with autonomous vehicles. The current implementation of the system allows one to set goals for multiple vehicles using RViz or by a configuration file. In the future we also want a order management integrated which is capable to assign vehicles for specific deliveries and to generate goals needed by the multi robot route planner. The system provides a simple local motion controller for all robots, which allows a high number (> 100) of vehicles to be controlled in real time using stage. Furthermore, the design allows the usage of existing individual controllers running on each vehicle such as DWA implemented in move_base. "]},
{"url": "https://wiki.ros.org/lex_node", "package": "lex_node", "package_summary": ["Package providing a ROS node for interacting with Amazon Lex"], "package_details": ["\n", ": Amazon Lex is a service for building conversational interfaces into any application using voice and text. Amazon Lex provides the advanced deep learning functionality of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (\u201cchatbots\u201d). ", "\n", "\n", "The ROS ", " node enables a robot to comprehend natural language commands by voice or textual input and respond through a set of actions, which an Amazon Lex Bot maps to ROS messages. Out of the box this node provides a ROS interface to communicate with a specified Amazon Lex bot (configured via lex_config.yaml) and requires configuration of AWS credentials. The Amazon Lex bot needs to be defined with responses and slots for customer prompts. A set of default slots and mappings are demonstrated in the ", " and include actions as \u201cCreate <location_name>,\u201d \u201cGo to <location_name>\u201d and \u201cStop.\u201d Additional guides on configuring bots with are available at ", ". ", "The ROS ", "  wraps the ", " in a ROS service API. ", "The source code is released under an ", ". "], "package_tt": ["lex_node", "lex_node"]},
{"url": "https://wiki.ros.org/ocean_battery_driver", "package": "ocean_battery_driver", "package_summary": ["This is an interface to the Ocean Server Technology Intelligent Battery and Power System."], "package_details": ["\n", "\n", "\n", " controls an array of battery controllers.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data.  ", "\n", " (", ") ", "\n", " (", ", default: if no value specified on command-line, 4) ", "The ", " node will report the status of the batteries to diagnostics. It will warn on the diagnostics if a battery does not update within a timeout. "], "package_tt": ["ocean_server", "ocean_server", "/diagnostics", "/battery/server2", "/battery/server", "~number_of_ports", "int", "~debug_level", "int", "~port<ID>", "string", "\"/dev/ttyUSB<ID>\"", "~lag_timeout", "int", "60", "~stale_timeout", "int", "120"]},
{"url": "https://wiki.ros.org/robot_pose_ekf", "package": "robot_pose_ekf", "package_summary": ["The Robot Pose EKF package is used to estimate the 3D pose of a robot, based on (partial) pose measurements coming from different sources. It uses an extended Kalman filter with a 6D model (3D position and 3D orientation) to combine measurements from wheel odometry, IMU sensor and visual odometry. The basic idea is to offer loosely coupled integration with different sensors, where sensor signals are received as ROS messages."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "The ", " node does not require all three sensor sources to be available all the time. Each source gives a pose estimate and a covariance. The sources operate at different rates and with different latencies. A source can appear and disappear over time, and the node will automatically detect and use the available sensors.To add your own sensor inputs, check out ", " ", "All the sensor sources that send information to the filter node can have their own ", " reference frame, and each of these ", " reference frames can drift arbitrary over time. Therefore, the ", " sent by the different sensors cannot be compared to each other. The node uses the ", " of each sensor to update the extended Kalman filter. ", "As a robot moves around, the uncertainty on its pose in a world reference continues to grow larger and larger. Over time, the covariance would grow without bounds. Therefore it is not useful to publish the covariance on the pose itself, instead the sensor sources publish how the covariance changes over time, i.e. the covariance on the velocity. ", " ", "Imagine the robot pose filter was last updated at time t_0. The node will not update the robot pose filter until at least one measurement of ", " sensor arrived with a timestamp later than t_0. When e.g. a message was received on the ", " topic with timestamp t_1 > t_0, and on the ", " topic with timestamp t_2 > t_1 > t_0, the filter will now update to the latest time at which information about all sensors is available, in this case to time t_1. The odom pose at t_1 is directly given, and the imu pose at t_1 is obtained by linear interpolation of the imu pose between t_0 and t_2. The robot pose filter is updated with the relative poses of the odom and imu, between t_0 and t_1. ", "The above figure shows experimental results when the PR2 robot started from a given initial position (green dot), driven around, and returned to the initial position. A perfect odometry x-y plot should show an exact loop closure. The blue line shows the input from the wheel odometry, with the blue dot the estimated end position. The red line shows the output of the ", ", which combined information of wheel odometry and imu, with the red dot the estimated end position.  "], "package_tt": ["robot_pose_ekf", "odom", "imu_data", "vo", "robot_pose_ekf", "robot_pose_ekf/odom_combined", "odom_combined", "base_footprint", "odom", "imu_data", "robot_pose_ekf"], "package_code": [" <launch>\n", "  <node pkg=\"robot_pose_ekf\" type=\"robot_pose_ekf\" name=\"robot_pose_ekf\">\n", "    <param name=\"output_frame\" value=\"odom\"/>\n", "    <param name=\"freq\" value=\"30.0\"/>\n", "    <param name=\"sensor_timeout\" value=\"1.0\"/>\n", "    <param name=\"odom_used\" value=\"true\"/>\n", "    <param name=\"imu_used\" value=\"true\"/>\n", "    <param name=\"vo_used\" value=\"true\"/>\n", "    <param name=\"debug\" value=\"false\"/>\n", "    <param name=\"self_diagnose\" value=\"false\"/>\n", "  </node>\n", " </launch>", " $ rosdep install robot_pose_ekf\n", " $ roscd robot_pose_ekf\n", " $ rosmake", " $ roslaunch robot_pose_ekf.launch"]},
{"url": "https://wiki.ros.org/pr2_bringup", "package": "pr2_bringup", "package_summary": ["Launch files and scripts needed to bring a PR2 up into a running state."], "package_details": [" is a package that collects together the scripts, ", " files, and dependencies that are required to bring a PR2 robot into a running state. ", "\n", "\n", "\n", " ", " ", "\n", "The user's entry point for this package is the file ", ".  This launch file contains all nodes to run a complete PR2 system. However, you cannot use pr2.launch to start up the robot (see ", " for instructions), because pr2.launch requires another launch file to load the robot description and robot analyzer on the parameter server first. ", "To disable the ", " set the \"no-prosilica\" arg to \"true\" in \"/etc/ros/robot.launch\" when launching your PR2: ", "This manual will take you step by step through starting the PR2 robot, ", ". Note: If you have a PR2 that is running both ROS Groovy and ROS Hydro, this is then the start sequence: ", "When the PR2 starts up for the first time since a power down, it will move its arms, casters, head and later platform to find the reference position of each joint.  This is done by the calibration script ", ". When finished, the PR2 joint calibration script stores the joint reference positions locally in the motor controller board (MCB) of the corresponding joint.  So the next time you start the PR2, it will remember the reference positions and won't have to repeat the same calibration routine over and over again. "], "package_tt": ["pr2_bringup", "pr2.launch", "pr2_bringup/scripts/calibrate_pr2.py"], "package_code": ["<launch>\n", "  <arg name=\"no-prosilica\" value=\"true\" />\n", "  <include file=\"$(find pr2_bringup)/pr2.launch\" />\n", "\n", "  <!-- Other stuff -->\n", "</launch>", "robot groovy", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot hydro", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot start"]},
{"url": "https://wiki.ros.org/mongodb_log", "package": "mongodb_log", "package_summary": ["The mongodb_log package"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "This package provides nodes that can record any and all data transmitted via ROS topics and stores them in the document-oriented database ", " replicating the message type as document structure. Afterwards, data can be used and queried independently of a particular robot software framework using the existing MongoDB query features with indexes, data locality (sharding) and ", ". This means you can also freely mix in data acquired from other sources, for example using ", ". ", "This project is joint work of the ", " at The Robotics Institute of the Carnegie Mellon University and the ", " at the RWTH Aachen University. For more details please visit the ", ". ", "The logger regularly creates graphs based an a round-robin database (RRD) using ", ". Additionally, the ", " script can be run to create graphs showing the performance of MongoDB. Example graphs look like the following. ", "The ", " package provides two functionalities. For one there is a node to store all messags of one specific topic to the database, for another it provides a library for other nodes to interact with the database. This mongodb_log package compares to the former part. ", "The ", " node of the ", " package stores incoming messages as serialized blobs, much like rosbag does. This way, queries can only be made based on the time of the message. More powerful queries and usage of the data is only possible of a specific node has been created or modified to record data in more verbose documents. ", "The upper graphs shows CPU and memory usage of rosbag, the generic mongodb_log python logger, and the specific C++ logger mongodb_log_tf, all recording the /tf topic at the same time, with transform messages containing 5 transforms at a rate of 100 Hz. We see that the MongoDB C++ logger and rosbag perform with about the same overhead. However, MongoDB is more efficient when writing, because rosbag writes the message type specification for each recorded message (note that MongoDB was writing two topics, one for the Python and the C++ logger each, while rosbag logged only one). The generic Python logger is much more demanding in terms of both, CPU and memory usage. The problem is the inherent Python overhead for deserializing message, which we had also analyzed when developing roslua (cf. ", "). Hence, logging many unknown topics can put a considerable burden on your logging machine. ", "The data acquired can be useful for a plethora of tasks. We have used it for fault analysis and performance evaluation, as described on the ", " and in the ", ". More information will be provided at a later point in time. ", "If you want to get in touch please contact ", ". Feel free to fork the ", " and let us know about your changes. Please report issues on the ", ". "], "package_tt": ["mongodb_rrd", "record_to_db"], "package_code": ["git clone https://github.com/timn/ros-mongodb_log.git mongodb_log\n", "cd mongodb_log\n", "make", "rosrun mongodb_log mongodb_log -a", "  MongoDB document                          rostopic echo /tf\n", "------------------------------------------------------------------------------\n", "{                                        |\n", "  \"_id\" : ObjectId(\"5011...\"),           |\n", "  \"__topic\" : \"/tf\",                     |\n", "  \"__recorded\" : ISODate(\"2012-07...\"),  |\n", "  \"transforms\" : [                       |  transforms:\n", "    {                                    |  -\n", "      \"header\" : {                       |    header:\n", "        \"stamp\" : ISODate(\"2012-07...\"), |    stamp:\n", "                                         |      secs: 1343297357\n", "                                         |      nsecs: 291\n", "        \"frame_id\" : \"/from\",            |      frame_id: /from\n", "        \"seq\" : 0                        |      seq: 0\n", "      },                                 |\n", "      \"transform\" : {                    |    transform:\n", "        \"translation\" : {                |      translation:\n", "        \"x\" : 1,                         |        x: 1.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0                          |        z: 0.0\n", "      },                                 |\n", "      \"rotation\" : {                     |      rotation:\n", "        \"x\" : 0,                         |        x: 0.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0,                         |        z: 0.0\n", "        \"w\" : 1                          |        w: 1.0\n", "      },                                 |\n", "      \"child_frame_id\" : \"/some_other\"   |    child_frame_id: /some_other\n", "    }                                    |\n", "  ]                                      |\n", "}                                        |"]},
{"url": "https://wiki.ros.org/pr2_power_board", "package": "pr2_power_board", "package_summary": ["This provides a ROS node for the PR2 Power Board."], "package_details": ["\n", " controls with the PR2 power board.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data. ", "\n", "\n", "\n", "The ", " runs on the PR2 and controls the PR2 power board. The node regulates the main fan speed of the PR2 based on battery and power board temperature.  "], "package_tt": ["power_node2", "power_node2", "battery/server2", "/diagnostics", "~state", "~control2", "~control", "~sample_frequency", "float", "~transition_frequency", "float", "/diagnostics", "~state", "~control"]},
{"url": "https://wiki.ros.org/pr2_power_drivers", "package": "pr2_power_drivers", "package_summary": ["Power drivers for the PR2 robot."], "package_details": ["\n", " contains the drivers that control the PR2 power system.  You should look at ", " for reading the power state of the robot. ", "\n", "Report new issues on ", " "], "package_tt": ["pr2_power_drivers"]},
{"url": "https://wiki.ros.org/smacha", "package": "smacha", "package_summary": ["SMACHA (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of SMACH into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background."], "package_details": ["\n", " (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of ", " into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background. ", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "The ", " provides an overview of the functionalities and core concepts of SMACHA. "]},
{"url": "https://wiki.ros.org/retalis", "package": "retalis", "package_summary": ["Retalis Language for Information Processing and Management in Autonomous Robot Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", "\n", " ", "Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type ", " ", "Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with ", ".  The format of time-stampes are  ", " where ", " encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above ", " message contains a list of ", " messages (only one here). While each  ", " message is time-stamped, the ", " itself does not have a header. Therefore, the corresponding event is stamped with the current time. ", "The following rule calls  the ", " function for every ", " event received by retalis. ", "Each ", " message from ", " contains a list of recognized objects, each represented by a  ", " message. The following rule generates a separate event for each object. ", "where ", " represents a recognized object and ", " encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding ", " message. The events is also time stamped with ", ". ", "Retalis integrates the '", ". ", " supports temporal and logical reasoning on flow of events. Please see ", "  for publications and for examples of rules implementing various event-processing functionalities. ", "This memory instance keeps the history of events of the form ", ", specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. ", "The ", " event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as ", ". ", "We saw in Section 4.1.3 that the ", " and ", " functions are implemented as Prolog clauses. The ", " file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events ", "The Prolog program in ", " together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our ", " list). ", "An example of using ", " and ", " terms is in implementation of the ", " function, in the eventRules.txt. The input values to this function is the ", " of a memory instance, keeping the history of some ", " events, and a time point. The ", " events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time ", ". This is implemented as follows. The last observation before ", " and the first observation after ", " are found using the ", " and ", " terms. Then the position is linearly interpolated by making a function call to the ", " library that has been integrated with retalis. ", "The ", " function in eventRules.txt uses the ", " function to position an object in the world reference frame. Given ", ", the position of an object relative to the camera at time ", ", this function computes ", ", the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between ", ", ", ", ", ", ", " and ", " at the time ", ". Third, it applies these transformations on the ", " by making a function call to the ", " library. It is assumed that the ", " frame is aligned with the world reference frame. ", "We saw in Section 4.1.6 that how calling ", " function interpolates the position between the ", " and ", " coordination frames at time ", ". This function uses ", " and ", " terms to access the first and the last observations after and before ", ", respectively. To interpolate the position at ", ", the position should have been observed, at least once, after ", ". The observations, ", " messages here, are received asynchronously. Therefore, the ", " function should be evaluated only after the ", " memory instance has been updated with an event occurring after ", ". This is realized in retalis using a synchronized event, as follows. ", "The ", " function, performs the ", ", when the ", " are satisfied and then generate the ", ". Consider the following clause from eventRules.txt: ", "This rule computes the position of recognized markers in the world and is read as follows.   For each ", " event, specified in line 6, the position is computed by calling the ", " function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: ", "Such a ", " event encodes the marker's name, its position in the world and the time of recogntion. The ", " are the followings, specified in line 4: ", "These conditions specify that the ", " function should be evaluated, only after all ", ", ", ", ", ", ", " and ", " memory instances have been updated, at least once, with events occurring after time ", ". The time ", " is the time of recognition of the marker. ", "Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized ", " is posponed, until the ", " are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. ", "The subscription subscribes the topic ", " to the ", " events in which ", " is ", ". Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker ", " in the world coordination frame.  The id of the subscription is ", " which can be used to cancel the subscrition at any time. ", "The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the ", " and ", " ros topics. The retalis-ros-converter only subscribes retalis to the ", " topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to ", " and ", " topics in the pub-sub.xml file and instead, set the ", " boolean variable in the retalis_interface.cpp file to ", ". You should also recompile the package. ", "As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to ", " and ", " topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. ", "The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record ", " events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  ", "In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type ", " are added to the NAO example. These memory instances match all ", " events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type ", ". However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. ", "The following figure shows the CPU time for a number of runs where up to 40 memory instances of type ", " and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  ", "The following figure shows the CPU time for a number of runs where up to 640 memory instances of type ", " and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. ", "The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type ", ". The green line shows the CPU time for the case where there are 320 memory instances of type ", ". We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for ", " events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. ", "The brown line shows the CPU time for the case where there are 10 memory instances of type ", " and 320 memory instances of type ", ". ", "Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10 ", " memory instances and 320 ", " memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. ", "The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional ", " memory instance of size 128. This memory instance is queried by 1000 ", " terms for each recognition of an object. In average, 7000 ", " terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000 ", " terms are evaluated per seconds. The figure shows that the costs of the evaluations of ", " and ", " terms are similar. The purple line shows the CPU time of the case where 14,000 ", " terms are evaluated per second. We observe that the cost grows linearly, as expected. ", "The blue line in the following figure visualizes the CPU time of the case where 7000 ", " terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320 ", " memory instances. The purple line visualizes the CPU time of the case where 7000 ", " terms are evaluated per second and there are 320 ", " memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. ", "The green line in the following figure visualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     ", "The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000 ", " queries on a memory instance of size 2500 are evaluated. In addition, for each ", " query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. ", "Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see ", " for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. "], "package_tt": ["add_output_subscription", "delete_output_subscription", "add_memory", "delete_memory", "add_input_subscription", "delete_input_subscription", "__0__", "__0__", "__0__", "__0__", "'\"/odom\"','\"/base_link\"'", "'\u201c/odom\u201d',\u00a0'\u201c/base_link\u201d'", "ToDo", "Event", "RelativePos", "AbsolutePose", "RelativePos", "AbsolutePose", "CameraTop", "RelativePos", "SynchConditions", "Query", "SynchConditions", "Event", "PoseStamped", "SyncConditions", "PoseStamped", "'\"4x4_1\"'", "__0__", "__0__", "CameraTop_frame"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://wiki.ros.org/omip", "package": "omip", "package_summary": ["This metapackage groups all the packages for Online Multimodal Interactive Perception (OMIP)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "(Main author) Roberto Mart\u00edn-Martin (", ", ", ") ", "Sebastian H\u00f6fer (", ", ", ") ", "Oliver Brock (", ") ", "1. ", ". Three estimation levels: feature tracking, feature-based rigid body tracking, kinematic model estimation. This option can execute only using RGB-D images and therefore requires less computational power.  ", "To try this option, download one of the rosbags with the \"_imgs\" suffix and launch OMIP using the option \"--omip=1\" (or \"--omip=2\" if you want that the terminals  ", "remain open after finishing the execution, for debugging purposes). ", "More frequent problem: The feature tracking is not running and looks like frozen -> Check in feature_tracker/cfg/feature_tracker_cfg.yaml the depth_img_topic name. Depending if you are using ", "openni or openni2 (or rosbags generated from one or the other package) the name of the topic for the depth maps is different. ", "Based on the recursive estimation schema - prediction/correction -  our framework can cope with the high amount of data provided by the robot's sensors ", ". ", "The key (and the main idea of our framework) is to factorize the perceptual problem into smaller *perceptual units*, solve them with single recursive estimation loops and connect all the loops tightly.  ", "The connection of the loops defines a bidirectional information flow between loops: a bottom-up flow to pass estimations as measurements to more abstract levels, and a top-down flow to pass predicted measurements as predicted next states to less abstract levels. ", "By connecting the loops our framework can interpret the combined sensor-action stream as evidence of concepts of different level of abstraction. ", "Each recursive estimation level is realized as a ROS node that implements the interface ", ".  ", "A recursive estimation level is defined by: ", "* Measurement ", "* State ", "* Priors: ", "Internally, each level contains at least one recursive estimation filter. These filters implement the interface ", ". ", "The levels call the corresponding correct-predict methods of the filters and pass the measurements/states up and down. "], "package_tt": ["rosrun\u00a0omip_launch\u00a0omip.sh\u00a0--help"], "package_code": ["git clone https://github.com/tu-rbo/omip.git\n", "git clone https://github.com/tu-rbo/omip_msgs.git", "gsettings set org.gnome.desktop.default-applications.terminal exec 'gnome-terminal'", "cp ~/.config/terminator/config ~/.config/terminator/config.bak\n", "cp omip/omip_launch/cfg/terminator/config ~/.config/terminator/", "sudo apt-get install ros-indigo-pcl-ros ros-indigo-openni-launch ros-indigo-openni-camera\n", "ros-indigo-openni2-launch ros-indigo-openni2-camera ros-indigo-cmake-modules", "sudo apt-get install ros-indigo-bfl", "sudo cp omip/omip/third_party/bflConfig.cmake /opt/ros/indigo/share/bfl/", "git clone https://github.com/roberto-martinmartin/rviz_plugin_camerarenderpublisher.git", "git clone https://github.com/laas/rviz_plugin_covariance.git", "sudo apt-get install ros-indigo-libpointmatcher", "sudo cp your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake.bak", "sudo cp omip/omip/third_party/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/", "touch omip/shape_tracker/CATKIN_IGNORE", "catkin build (omip)", "rosbag decompress rosbagname.bag", "rosrun omip_launch omip.sh --omip=1 --rgbd=0", "rosrun omip_launch omip.sh --help", "rosbag play rosbagname.bag"]},
{"url": "https://wiki.ros.org/phm_tools", "package": "phm_tools", "package_summary": ["The phm_tools meta package"], "package_details": ["\n", "\n", " ", " ", " Autonomous Transfer Vehicle ", " ", "Use Case Scenario Module, Sub-Module and Components List ", " ", " Use Case General Block Diagram ", " ", " General Failure Rates and Reliabilities of Components ", " ", " System Hazard Rate and Reliability at Different Temperature Conditions ", " Reliability of System at Different Temperatures ", " ", " ", " GAZEBO Test Environment ", " Locations of Some Specific Points ", " Followed Paths and Distance Between Each Neighbour Points ", " System PoTC for Each Route Segment ", "\n", "In the motor sub-module, failure rate of this component is selected as ", ". In encoder sub-module, we selected magnetic rotary encoder unit. Only use parameters  \u03bb", " (other parameters are negligible), the failure rate of encoder unit selected as ", ". ", "In the sensor module, there is only one component which is SICK S300 Laser Sensor and the failure rate of this component selected as ", " using product datasheet.  ", "In order to calculate hazard rate of the power card sub-module, we utilized diodes, capacitors and inductors. In addition, hazard rate of the fuse in the power card sub-modules selected as ", ". Hazard rate of the selected buck converter (LM 2596), is found as ", ". There is one more component in the Power Module which is battery and the failure rate of this component selected as ", ". ", "General failure rates and reliabilities of the all components at 35 \u2103 are shown in Table 2.  ", "Using Table 2, hazard rate of the system \u03bb", " calculated as ", ". In order to calculate the reliability of the system, we use Exponential Distribution function with the system hazard rate and time. Usage time selected as 1000 hours. The reliability of the system  R", " calculated as ", ".  "]},
{"url": "https://wiki.ros.org/move_base_to_manip", "package": "move_base_to_manip", "package_summary": ["Move the robot base until a desired end-effector pose can be reached."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "For mobile manipulators, this package calculates a robot base location where the end-effector (EE) can reach a desired pose (a.k.a. inverse reachability). The method is computationally fast (since it depends on a ", " Cartesian motion plan), simple (~300 lines), and easy to use (requiring just a service to provide the desired pose). ", "Below, the first image shows a mobile manipulator which is too far to grasp the object of interest. The desired EE pose is shown in green. The second image shows the freshly-calculated base position (red cube) which will allow the robot to reach that pose. <<Please ignore the bad camera calibration>> ", "This package uses ", " for base commands and ", " for manipulator motion planning.  ", "^This launches a ROS service that will make a desired pose available to the move_base_to_manip node. It also displays this desired pose in Rviz. When the client sends ", " on the service request, this node will shut down after providing the pose. ", "^This node requests the desired pose from the other node. It then moves the end-effector to the desired height and orientation. From there, it plans a Cartesian move to the desired pose. The % completion of the Cartesian move informs the base on how far it must move. If the Cartesian move is able to complete 100%, the arm moves and the program exits. Otherwise, there is a call to ", " to get closer to the object: ", "The planner reads optional parameters on the ", ". They can be adjusted from the command line, programmatically, or left as their default values. They are: ", "* ", ": A fraction between 0 and 1. A value of 1 means the EE will barely be able to reach the desired pose when fully extended. A value of 0 means the base motion will bring the EE to the desired pose without additional arm motion. Default: 0.15.  ", "* ", ": Use a Cartesian motion for the final arm approach, or a regular ", " motion? The Cartesian motion may be useful if your task requires the gripper to maintain a constant orientation (like grasping often does). Default: false, i.e. do a regular motion. ", "* ", ": Clear the octomap collision scene before the final arm approach? This is often necessary for grasping -- otherwise sensor noise/resolution may lead the robot to expect a collision. Default: true, i.e. the collision scene will be cleared. ", "* ", ": Clear the move_base costmaps before base motion? Default: true. ", "* ", ": Ask the user before making any motion? This is useful if you're just starting to use the package and aren't sure what to expect. Default: true. ", "* ", ": This is the \"request\" part of the service call. Can be used as a signal that the server can shutdown. Default: true (which I use to signal the pose provider node to shut down). ", "* ", ": A smaller number results in a more accurate prediction of the distance to the pose of interest. Default: 0.005m ", "* ", ": Default \"right_ur5\" ", "* ", ": Default \"RRTConnectkConfigDefault\" ", "* ", ": % of maximum robot speed for all arm motions. Default: 0.1 ", "* ", ": Default \"base_link\" ", "* ", ": Position tolerance for arm motions. It may be useful to bump this up if you are having trouble finding plans. Default: 0.01 m ", "* ", ": Orientation tolerance for arm motions. Default: 0.0001 rad ", "* ", ": If true, the planner will try to flip the EE +/-180 deg about Z (i.e. ", ") when it cannot reach a desired pose. Then it will attempt to plan again. Useful for 2-finger grippers. Default: true ", "Here are some hints to get more suitable trajectories from ", ": ", "* Make sure the resolutions of your costmap and ", " planners are fine enough to get the accuracy you require. ", "Here are ", " from the creator of ", ". ", "This package only calculates one base position which can reach the desired pose. If the base is not able to move there, it fails. However, ", " has some built-in obstacle avoidance capabilities and if it fails, it will generally be close to the goal. ", "* (untested) Use the ", " package to calculate a good location for the manipulator's base. From the manipulator's position, calculate a mobile base location. This is the \"inverse reachability database\" approach. "], "package_code": ["$ sudo apt-get install ros-indigo-move-base-to-manip", "$ rosrun move_base_to_manip provide_target", "$ roslaunch move_base_to_manip move_base_to_manip.launch", "ac.sendGoal(goal);"]},
{"url": "https://wiki.ros.org/openni_tracker", "package": "openni_tracker", "package_summary": ["\n\nopenni_tracker broadcasts the OpenNI skeleton frames using tf.\n\n  "], "package_details": [" ", " is now a unary stack. Previously it was a package in ", ". ", " ", "\n", " - Independent node that does not require other nodes to run (however, make sure your ", " is powered. For example, on ", ", ", " needs to be run successfully). ", "\n", "Once running, stand in front of the Kinect and surrender (i.e. hit the ", ". You should see some variation on the following messages.  ", "The user's pose will be published as a set of transforms (", ") with the following frame names.  "], "package_tt": ["openni_tracker", "rosrun\u00a0openni_tracker\u00a0openni_tracker", "Kinect", "Turtlebot", "kinect.launch", "/tf", "/head", "/neck", "/torso", "/left_shoulder", "/left_elbow", "/left_hand", "/right_shoulder", "/right_elbow", "/right_hand", "/left_hip", "/left_knee", "/left_foot", "/right_hip", "/right_knee", "/right_foot", "camera_frame_id", "string", "/tf"], "package_code": ["New User 1\n", "Pose Psi detected for user 1\n", "Calibration started for user 1\n", "Calibration complete, start tracking user 1\n", "Lost User 1"]},
{"url": "https://wiki.ros.org/battery_monitor_rmp", "package": "battery_monitor_rmp", "package_summary": ["Monitor for the Segway Batteries"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package uses the feedback provided by the RMP to monitor the segway batteries and then uses espeak to tell the user if a battery is getting low. It also publishes this information. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["battery_monitor_rmp", "monitor_rmp.py", "rmp_feedback", "battery_status_rmp", "~front_base_batt_1", "~front_base_batt_2", "~rear_base_batt_1", "~rear_base_batt_2", "~aux_batt", "battery_monitor_rmp", "battery_monitor_rmp", "battery_monitor_rmp.launch", "battery_monitor_rmp.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-battery-monitor-rmp", "roslaunch battery_monitor_rmp battery_monitor_rmp.launch "]},
{"url": "https://wiki.ros.org/class_loader", "package": "class_loader", "package_summary": ["The class_loader package is a ROS-independent package for loading plugins during runtime and the foundation of the higher level ROS \"pluginlib\" library. class_loader utilizes the host operating system's runtime loader to open runtime libraries (e.g. .so/.dll files), introspect the library for exported plugin classes, and allows users to instantiate objects of said exported classes without the explicit declaration (i.e. header file) for those classes."], "package_details": [" ", "\n", " is a ROS-independent package that allows one to dynamically load exported C++ classes during runtime from a runtime library (i.e. .so/.dll file) and create objects of those classes. What makes a class loaded through ", " different from just linking against a runtime library and using classes from it is that your code does not require the definition of the class (i.e. the header file for the class) in your client code. Classes loaded in this fashion are also often called ", ".  ", "\n", " is used in the implementation of the higher-level ROS package ", " which is the encouraged method for loading plugins in the ROS  ", "ecosystem. ", " ", "\n", " is simple to use and requires linking against a single library (", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", " as of version 1.9 and class_loader HIGHLY discourage linking applications directly against libraries containing plugins. Often times users will place plugins into libraries along side code intended to directly be linked. Other times they want to be able to use classes as plugins as well as directly use them without a ", ". This was fine in previous versions of pluginlib, but as version 1.9, pluginlib sits on top of class_loader for plugin loading which cannot handle this.  ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "  ", "It is important to note that the ", " can only inspect classes and create objects of those classes if those classes are registered to be exportable.  For any classes you want to export, make sure to have a declaration of the following macro for each class within your source (.cpp) files: ", "where ", " refers to the name of the class to be exported and ", " refers to the name of the class from which it is derived. Though you do not need the definition of the Derived class in the code that will load the class, you still need to have a definition to its base class so as to be able to use the plugin. Notice in the code examples that when introspecting the library via ", " or creating a plugin via ", " that both methods require a template type argument indicating the base class. If the correct base class is not given, the class will not be seen or instantiable by the ", ". It is ok to have classes with different base classes registered or even register the same class multiple times with different bases in the same library and transitively the same ", ". Just note the base class argument must be provided at compile time via a template argument for methods where it matters. ", "Once you have built all your source files using the macro, you can package the object files into a runtime library and then load that library via the ", ". ", "All methods to ", " and ", " are thread safe. The use of templates allows for all types to be statically verified and it is impossible to load an invalid plugin with an incompatible interface. This is a powerful concept in guaranteeing the integrity of plugins at both compile and runtime which is of course very important in robotics. ", "When one uses the ", " to create and destroy plugins, it results in the opening and closing of the runtime libraries containing those plugins. When a runtime library is loaded by an operating system, symbols in the host executable that are stubs to the runtime library are resolved. When the library is unloaded, the symbols at those corresponding memory addresses are unavailable as the code has been removed from executable's address space and [possibly] unloaded from memory. If one attempts to use symbols that are unresolved, it leads to a runtime link error. This means if I create an object from a class defined within a runtime library, I then unload the library, and then I try to use the object...things will go bad.  ", "In the example code above, the library is loaded and unloaded by ", " automatically, though ", " provides methods for explicitly loading and unloading the underlying library (", " and ", " respectively). The ", " is smart in that it will automatically load a library when created and unload it when the ", " goes out of scope. One may wonder why the load and unload methods are then exposed. In order to understand that, we must first understand the ", "'s on-demand (lazy) load/unload mode. ", "The ", " constructor provides an optional boolean flag (", ") to indicate if the ", " is to perform on-demand (lazy) loading of a library as needed and automatically closing it after the last plugin in created by it is destroyed. By default, this flag is set to false. When set to false, the ", " loads the library at construction time and unloads it at destruction time. In on-demand mode, the library is only opened when the first plugin is created via ", " and unloaded when the only remaining plugin created by the ", " is destroyed. This mode is helpful when we want to minimize the number of libraries loaded in memory. ", "It is often useful, particularly in on-demand mode, to control when the library is loaded and unloaded. One can force this by calling ", ". When one calls ", " and ", ", the library is forcefully loaded into memory and cannot be unloaded automatically by the system until ", " is called. This allows multiple threads sharing the same ", " to force a shared library, even if it's open in on-demand mode, to stay in memory until it's done. This is not a thread safety issue, but rather one for performance to prevent a library from continuously being loaded/unloaded if a thread is going to need it heavily for some period of time and wants to guarantee the library stays in memory. ", "A ", " allows one to create objects in the form of ", " values so as to provide automatic cleanup of objects. Another one of the important reasons this is implemented is so that the user cannot unload the library prematurely. The user is free to create unmanaged objects via the alternate ", " method, but this will prevent the ", " from stopping the user on unloading the library when there are still objects in memory. This is because the ", " cannot be aware of the state of unmanaged instances. ", "Many ", " methods will raise an exception of base class type ", " if an error occurs. The subclasses of ", " are defined in ", " and indicate the various problems. These include: ", "The ", " is designed to be bound only to a single runtime library. Often it is convenient to have multiple libraries open and be able to load/unload classes from them through a uniform interface. That is why the class ", " is provided. This class provides as an almost identical interface to ", " but allows one to bind several libraries to a single loader object. Internally, the ", " is just a manager for a collection of ", " objects. ", "The issue is that the way class_loader implements plugin introspection is by having plugin ", "  automatically register themselves when the library is opened. This is not how pluginlib prior to version 1.9 operated. However, the problem is is that when you directly link an executable against a library with plugins, when that program starts up, all the plugin factories will be created outside the scope of a ", ". See ", " for more details. ", "For those interested in understanding the internals of ", ", go to the ", " page. "], "package_tt": ["class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader/class_loader.h", "class_loader::ClassLoader", "CLASS_LOADER_REGISTER_CLASS(Derived,\u00a0Base)", "getAvailableClasses()", "createInstance()", "class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "loadLibrary()", "unloadLibrary()", "ondemand_loadunload", "createInstance()", "loadLibrary", "loadLibary", "unloadLibrary", "unloadLibrary", "class_loader::ClassLoader", "boost::shared_ptr", "class_loader::ClassLoader::createUnmanagedInstance", "class_loader::ClassLoader::createInstance()", "class_loader::ClassLoaderException", "class_loader::ClassLoaderException", "class_loader/class_loader_exceptions.h", "class_loader::LibraryLoadException", "class_loader::LibraryUnloadException", "class_loader::CreateClassException", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "class_loader::MultiLibraryClassLoader", "class_loader::ClassLoader", "class_loader::ClassLoader"], "package_code": ["   class_loader::ClassLoader loader(\"libMyLibrary.so\");", "   std::vector<std::string> classes = loader.getAvailableClasses<MyBase>()", " for(unsigned int c = 0; c < classes.size(); ++c)\n", " {\n", "   boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);\n", "   plugin->someMethod();\n", "   //'plugin' will automatically be deleted when it goes out of scope\n", " }", "#include <class_loader/class_loader.h>\n", "#include \"MyBase.h\" //Defines class MyBase\n", "\n", "int main()\n", "{\n", "  class_loader::ClassLoader loader(\"libMyLibrary.so\");\n", "  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();\n", "  for(unsigned int c = 0; c < classes.size(); ++c)\n", "  {\n", "    boost::shared_ptr<MyBase> plugin = loader.createInstance<MyBase>(classes[c]);\n", "    plugin->someMethod();\n", "  }\n", "}", "#include <class_loader/multi_library_class_loader.h>\n", "#include \"MyBase.h\" //Defines class MyBase\n", "\n", "int main()\n", "{\n", "  class_loader::MultiLibraryClassLoader loader;\n", "  loader.loadLibrary(\"libSomeLib.so\");\n", "  loader.loadLibrary(\"libAnotherLib.so\");\n", "  std::vector<std::string> classes = loader.getAvailableClasses<MyBase>();\n", "  for(unsigned int c = 0; c < classes.size(); ++c)\n", "  {\n", "    boost::shared_ptr plugin<MyBase> = loader.createInstance<MyBase>(classes[c]);\n", "    plugin->someMethod();\n", "  }\n", "}"]}
]